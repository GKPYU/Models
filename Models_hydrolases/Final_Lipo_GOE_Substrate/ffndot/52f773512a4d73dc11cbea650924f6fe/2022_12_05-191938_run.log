2022-12-05 20:26:56,022 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/52f773512a4d73dc11cbea650924f6fe/2022_12_05-191938",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-05 20:26:56,031 INFO: Starting stage: BUILD FEATURIZERS
2022-12-05 20:26:56,033 INFO:   Creating esm representation model
2022-12-05 20:26:56,033 INFO:   Done esm representation model
2022-12-05 20:26:56,034 INFO: Done with stage: BUILD FEATURIZERS
2022-12-05 20:26:56,034 INFO: Starting stage: BUILDING DATASET
2022-12-05 20:26:56,087 INFO: Done with stage: BUILDING DATASET
2022-12-05 20:26:56,087 INFO: Starting stage: FEATURIZING DATA
2022-12-05 20:26:56,087 INFO:   Featurizing proteins
2022-12-05 20:26:56,089 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-05 20:26:56,104 INFO:   Loaded feature cache of size 204
2022-12-05 20:26:56,105 INFO:   Starting to pool ESM Embeddings
2022-12-05 20:26:56,232 INFO:   Featurizing molecules
2022-12-05 20:26:56,234 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-05 20:26:56,237 INFO:   Loaded feature cache of size 495
2022-12-05 20:26:57,595 INFO: Done with stage: FEATURIZING DATA
2022-12-05 20:26:57,595 INFO: Starting stage: RUNNING SPLITS
2022-12-05 20:26:57,603 INFO:   Leaving out SEQ value Fold_0
2022-12-05 20:26:57,617 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:26:57,617 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:26:58,276 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:26:58,276 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:26:58,344 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:26:58,344 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:26:58,344 INFO:     No hyperparam tuning for this model
2022-12-05 20:26:58,344 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:26:58,344 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:26:58,345 INFO:     None feature selector for col prot
2022-12-05 20:26:58,345 INFO:     None feature selector for col prot
2022-12-05 20:26:58,345 INFO:     None feature selector for col prot
2022-12-05 20:26:58,345 INFO:     None feature selector for col chem
2022-12-05 20:26:58,345 INFO:     None feature selector for col chem
2022-12-05 20:26:58,346 INFO:     None feature selector for col chem
2022-12-05 20:26:58,346 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:26:58,346 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:26:58,347 INFO:     Number of params in model 215821
2022-12-05 20:26:58,348 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:26:58,348 INFO:   Starting stage: TRAINING
2022-12-05 20:27:00,398 INFO:     Val loss before train {'Reaction outcome loss': 1.0182203484136005, 'Total loss': 1.0182203484136005}
2022-12-05 20:27:00,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:00,399 INFO:     Epoch: 0
2022-12-05 20:27:01,176 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.602653103512387, 'Total loss': 0.602653103512387} | train loss {'Reaction outcome loss': 0.7891856159587376, 'Total loss': 0.7891856159587376}
2022-12-05 20:27:01,176 INFO:     Found new best model at epoch 0
2022-12-05 20:27:01,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:01,177 INFO:     Epoch: 1
2022-12-05 20:27:01,951 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.523390457034111, 'Total loss': 0.523390457034111} | train loss {'Reaction outcome loss': 0.5350071782948541, 'Total loss': 0.5350071782948541}
2022-12-05 20:27:01,951 INFO:     Found new best model at epoch 1
2022-12-05 20:27:01,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:01,952 INFO:     Epoch: 2
2022-12-05 20:27:02,732 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.473607026560362, 'Total loss': 0.473607026560362} | train loss {'Reaction outcome loss': 0.4645770433984819, 'Total loss': 0.4645770433984819}
2022-12-05 20:27:02,732 INFO:     Found new best model at epoch 2
2022-12-05 20:27:02,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:02,733 INFO:     Epoch: 3
2022-12-05 20:27:03,515 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4530251504376877, 'Total loss': 0.4530251504376877} | train loss {'Reaction outcome loss': 0.4278797032769586, 'Total loss': 0.4278797032769586}
2022-12-05 20:27:03,515 INFO:     Found new best model at epoch 3
2022-12-05 20:27:03,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:03,516 INFO:     Epoch: 4
2022-12-05 20:27:04,293 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4428811319345652, 'Total loss': 0.4428811319345652} | train loss {'Reaction outcome loss': 0.3995480505657978, 'Total loss': 0.3995480505657978}
2022-12-05 20:27:04,293 INFO:     Found new best model at epoch 4
2022-12-05 20:27:04,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:04,294 INFO:     Epoch: 5
2022-12-05 20:27:05,075 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4396889448858971, 'Total loss': 0.4396889448858971} | train loss {'Reaction outcome loss': 0.3763419528354387, 'Total loss': 0.3763419528354387}
2022-12-05 20:27:05,075 INFO:     Found new best model at epoch 5
2022-12-05 20:27:05,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:05,076 INFO:     Epoch: 6
2022-12-05 20:27:05,852 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4318638256815977, 'Total loss': 0.4318638256815977} | train loss {'Reaction outcome loss': 0.3595316853435313, 'Total loss': 0.3595316853435313}
2022-12-05 20:27:05,852 INFO:     Found new best model at epoch 6
2022-12-05 20:27:05,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:05,853 INFO:     Epoch: 7
2022-12-05 20:27:06,630 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4266394920820414, 'Total loss': 0.4266394920820414} | train loss {'Reaction outcome loss': 0.3389025778189057, 'Total loss': 0.3389025778189057}
2022-12-05 20:27:06,631 INFO:     Found new best model at epoch 7
2022-12-05 20:27:06,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:06,632 INFO:     Epoch: 8
2022-12-05 20:27:07,412 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42495668176994766, 'Total loss': 0.42495668176994766} | train loss {'Reaction outcome loss': 0.32411880430872325, 'Total loss': 0.32411880430872325}
2022-12-05 20:27:07,412 INFO:     Found new best model at epoch 8
2022-12-05 20:27:07,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:07,413 INFO:     Epoch: 9
2022-12-05 20:27:08,192 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4199983186500017, 'Total loss': 0.4199983186500017} | train loss {'Reaction outcome loss': 0.30918773555303697, 'Total loss': 0.30918773555303697}
2022-12-05 20:27:08,192 INFO:     Found new best model at epoch 9
2022-12-05 20:27:08,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:08,192 INFO:     Epoch: 10
2022-12-05 20:27:08,971 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42662554216939347, 'Total loss': 0.42662554216939347} | train loss {'Reaction outcome loss': 0.29693412167004873, 'Total loss': 0.29693412167004873}
2022-12-05 20:27:08,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:08,971 INFO:     Epoch: 11
2022-12-05 20:27:09,749 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42156068149001097, 'Total loss': 0.42156068149001097} | train loss {'Reaction outcome loss': 0.29139746334709105, 'Total loss': 0.29139746334709105}
2022-12-05 20:27:09,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:09,749 INFO:     Epoch: 12
2022-12-05 20:27:10,535 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4277108127987662, 'Total loss': 0.4277108127987662} | train loss {'Reaction outcome loss': 0.27452957126327227, 'Total loss': 0.27452957126327227}
2022-12-05 20:27:10,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:10,536 INFO:     Epoch: 13
2022-12-05 20:27:11,317 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4289273186478504, 'Total loss': 0.4289273186478504} | train loss {'Reaction outcome loss': 0.2665743664762036, 'Total loss': 0.2665743664762036}
2022-12-05 20:27:11,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:11,317 INFO:     Epoch: 14
2022-12-05 20:27:12,097 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4186281267293664, 'Total loss': 0.4186281267293664} | train loss {'Reaction outcome loss': 0.2597325265743449, 'Total loss': 0.2597325265743449}
2022-12-05 20:27:12,097 INFO:     Found new best model at epoch 14
2022-12-05 20:27:12,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:12,098 INFO:     Epoch: 15
2022-12-05 20:27:12,876 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4102784714033437, 'Total loss': 0.4102784714033437} | train loss {'Reaction outcome loss': 0.2503301393484972, 'Total loss': 0.2503301393484972}
2022-12-05 20:27:12,876 INFO:     Found new best model at epoch 15
2022-12-05 20:27:12,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:12,877 INFO:     Epoch: 16
2022-12-05 20:27:13,653 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41963399114996885, 'Total loss': 0.41963399114996885} | train loss {'Reaction outcome loss': 0.24323094248405244, 'Total loss': 0.24323094248405244}
2022-12-05 20:27:13,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:13,653 INFO:     Epoch: 17
2022-12-05 20:27:14,432 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42857476999593336, 'Total loss': 0.42857476999593336} | train loss {'Reaction outcome loss': 0.23629502570409266, 'Total loss': 0.23629502570409266}
2022-12-05 20:27:14,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:14,432 INFO:     Epoch: 18
2022-12-05 20:27:15,213 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4186858316493589, 'Total loss': 0.4186858316493589} | train loss {'Reaction outcome loss': 0.2303621071528216, 'Total loss': 0.2303621071528216}
2022-12-05 20:27:15,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:15,213 INFO:     Epoch: 19
2022-12-05 20:27:15,999 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4271746482266936, 'Total loss': 0.4271746482266936} | train loss {'Reaction outcome loss': 0.22296474263316296, 'Total loss': 0.22296474263316296}
2022-12-05 20:27:15,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:15,999 INFO:     Epoch: 20
2022-12-05 20:27:16,781 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4368665190630181, 'Total loss': 0.4368665190630181} | train loss {'Reaction outcome loss': 0.2173638677255052, 'Total loss': 0.2173638677255052}
2022-12-05 20:27:16,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:16,781 INFO:     Epoch: 21
2022-12-05 20:27:17,558 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4285030073897783, 'Total loss': 0.4285030073897783} | train loss {'Reaction outcome loss': 0.21205074943174593, 'Total loss': 0.21205074943174593}
2022-12-05 20:27:17,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:17,558 INFO:     Epoch: 22
2022-12-05 20:27:18,338 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42509836201057877, 'Total loss': 0.42509836201057877} | train loss {'Reaction outcome loss': 0.20561690472799246, 'Total loss': 0.20561690472799246}
2022-12-05 20:27:18,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:18,339 INFO:     Epoch: 23
2022-12-05 20:27:19,121 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42741517497356546, 'Total loss': 0.42741517497356546} | train loss {'Reaction outcome loss': 0.20178228041126592, 'Total loss': 0.20178228041126592}
2022-12-05 20:27:19,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:19,122 INFO:     Epoch: 24
2022-12-05 20:27:19,904 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4316686150986095, 'Total loss': 0.4316686150986095} | train loss {'Reaction outcome loss': 0.1960581032650881, 'Total loss': 0.1960581032650881}
2022-12-05 20:27:19,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:19,904 INFO:     Epoch: 25
2022-12-05 20:27:20,685 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4322106775849365, 'Total loss': 0.4322106775849365} | train loss {'Reaction outcome loss': 0.1978293427983757, 'Total loss': 0.1978293427983757}
2022-12-05 20:27:20,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:20,685 INFO:     Epoch: 26
2022-12-05 20:27:21,462 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4426353684691496, 'Total loss': 0.4426353684691496} | train loss {'Reaction outcome loss': 0.19137663062142787, 'Total loss': 0.19137663062142787}
2022-12-05 20:27:21,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:21,463 INFO:     Epoch: 27
2022-12-05 20:27:22,237 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43031152008577833, 'Total loss': 0.43031152008577833} | train loss {'Reaction outcome loss': 0.18722489998355263, 'Total loss': 0.18722489998355263}
2022-12-05 20:27:22,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:22,237 INFO:     Epoch: 28
2022-12-05 20:27:23,014 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4363630069203155, 'Total loss': 0.4363630069203155} | train loss {'Reaction outcome loss': 0.1863477157092974, 'Total loss': 0.1863477157092974}
2022-12-05 20:27:23,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:23,014 INFO:     Epoch: 29
2022-12-05 20:27:23,793 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43522447624871896, 'Total loss': 0.43522447624871896} | train loss {'Reaction outcome loss': 0.1796526321912276, 'Total loss': 0.1796526321912276}
2022-12-05 20:27:23,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:23,794 INFO:     Epoch: 30
2022-12-05 20:27:24,569 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4387748385238093, 'Total loss': 0.4387748385238093} | train loss {'Reaction outcome loss': 0.17472832859112103, 'Total loss': 0.17472832859112103}
2022-12-05 20:27:24,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:24,569 INFO:     Epoch: 31
2022-12-05 20:27:25,344 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4370791825444199, 'Total loss': 0.4370791825444199} | train loss {'Reaction outcome loss': 0.17807563369879958, 'Total loss': 0.17807563369879958}
2022-12-05 20:27:25,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:25,344 INFO:     Epoch: 32
2022-12-05 20:27:26,118 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.442155267956645, 'Total loss': 0.442155267956645} | train loss {'Reaction outcome loss': 0.17131434040541044, 'Total loss': 0.17131434040541044}
2022-12-05 20:27:26,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:26,119 INFO:     Epoch: 33
2022-12-05 20:27:26,893 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4420894924984422, 'Total loss': 0.4420894924984422} | train loss {'Reaction outcome loss': 0.16849422047189513, 'Total loss': 0.16849422047189513}
2022-12-05 20:27:26,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:26,894 INFO:     Epoch: 34
2022-12-05 20:27:27,669 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4399109739203786, 'Total loss': 0.4399109739203786} | train loss {'Reaction outcome loss': 0.1660310476483991, 'Total loss': 0.1660310476483991}
2022-12-05 20:27:27,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:27,669 INFO:     Epoch: 35
2022-12-05 20:27:28,451 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.444490225162617, 'Total loss': 0.444490225162617} | train loss {'Reaction outcome loss': 0.1662214522051518, 'Total loss': 0.1662214522051518}
2022-12-05 20:27:28,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:28,451 INFO:     Epoch: 36
2022-12-05 20:27:29,229 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44473112322563346, 'Total loss': 0.44473112322563346} | train loss {'Reaction outcome loss': 0.16203286060605382, 'Total loss': 0.16203286060605382}
2022-12-05 20:27:29,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:29,229 INFO:     Epoch: 37
2022-12-05 20:27:30,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4522647310134976, 'Total loss': 0.4522647310134976} | train loss {'Reaction outcome loss': 0.1594055934931289, 'Total loss': 0.1594055934931289}
2022-12-05 20:27:30,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:30,007 INFO:     Epoch: 38
2022-12-05 20:27:30,782 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4501986427362575, 'Total loss': 0.4501986427362575} | train loss {'Reaction outcome loss': 0.15953405651065414, 'Total loss': 0.15953405651065414}
2022-12-05 20:27:30,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:30,782 INFO:     Epoch: 39
2022-12-05 20:27:31,557 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4570137050955795, 'Total loss': 0.4570137050955795} | train loss {'Reaction outcome loss': 0.1565036854370818, 'Total loss': 0.1565036854370818}
2022-12-05 20:27:31,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:31,557 INFO:     Epoch: 40
2022-12-05 20:27:32,338 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4453329556556635, 'Total loss': 0.4453329556556635} | train loss {'Reaction outcome loss': 0.15664470238519496, 'Total loss': 0.15664470238519496}
2022-12-05 20:27:32,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:32,339 INFO:     Epoch: 41
2022-12-05 20:27:33,123 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4405112838329271, 'Total loss': 0.4405112838329271} | train loss {'Reaction outcome loss': 0.1532295991773488, 'Total loss': 0.1532295991773488}
2022-12-05 20:27:33,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:33,123 INFO:     Epoch: 42
2022-12-05 20:27:33,901 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45848278112189716, 'Total loss': 0.45848278112189716} | train loss {'Reaction outcome loss': 0.15220075854878934, 'Total loss': 0.15220075854878934}
2022-12-05 20:27:33,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:33,901 INFO:     Epoch: 43
2022-12-05 20:27:34,680 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4503001577632372, 'Total loss': 0.4503001577632372} | train loss {'Reaction outcome loss': 0.15166430337140796, 'Total loss': 0.15166430337140796}
2022-12-05 20:27:34,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:34,680 INFO:     Epoch: 44
2022-12-05 20:27:35,469 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44748246739077013, 'Total loss': 0.44748246739077013} | train loss {'Reaction outcome loss': 0.14920103149183217, 'Total loss': 0.14920103149183217}
2022-12-05 20:27:35,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:35,469 INFO:     Epoch: 45
2022-12-05 20:27:36,245 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44021182074103243, 'Total loss': 0.44021182074103243} | train loss {'Reaction outcome loss': 0.14740191602346595, 'Total loss': 0.14740191602346595}
2022-12-05 20:27:36,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:36,246 INFO:     Epoch: 46
2022-12-05 20:27:37,022 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44656869457211607, 'Total loss': 0.44656869457211607} | train loss {'Reaction outcome loss': 0.14759284621257274, 'Total loss': 0.14759284621257274}
2022-12-05 20:27:37,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:37,022 INFO:     Epoch: 47
2022-12-05 20:27:37,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44999733913776485, 'Total loss': 0.44999733913776485} | train loss {'Reaction outcome loss': 0.1416850311177798, 'Total loss': 0.1416850311177798}
2022-12-05 20:27:37,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:37,799 INFO:     Epoch: 48
2022-12-05 20:27:38,581 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4554260248361632, 'Total loss': 0.4554260248361632} | train loss {'Reaction outcome loss': 0.14434442185934204, 'Total loss': 0.14434442185934204}
2022-12-05 20:27:38,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:38,582 INFO:     Epoch: 49
2022-12-05 20:27:39,361 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45068963599759476, 'Total loss': 0.45068963599759476} | train loss {'Reaction outcome loss': 0.1418296221689489, 'Total loss': 0.1418296221689489}
2022-12-05 20:27:39,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:39,361 INFO:     Epoch: 50
2022-12-05 20:27:40,145 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4542122677315113, 'Total loss': 0.4542122677315113} | train loss {'Reaction outcome loss': 0.1414452020468221, 'Total loss': 0.1414452020468221}
2022-12-05 20:27:40,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:40,145 INFO:     Epoch: 51
2022-12-05 20:27:40,923 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4554788231156593, 'Total loss': 0.4554788231156593} | train loss {'Reaction outcome loss': 0.14011524665764855, 'Total loss': 0.14011524665764855}
2022-12-05 20:27:40,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:40,924 INFO:     Epoch: 52
2022-12-05 20:27:41,713 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45582198403602425, 'Total loss': 0.45582198403602425} | train loss {'Reaction outcome loss': 0.1393890067454061, 'Total loss': 0.1393890067454061}
2022-12-05 20:27:41,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:41,713 INFO:     Epoch: 53
2022-12-05 20:27:42,488 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46576477379299874, 'Total loss': 0.46576477379299874} | train loss {'Reaction outcome loss': 0.1368991448353121, 'Total loss': 0.1368991448353121}
2022-12-05 20:27:42,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:42,488 INFO:     Epoch: 54
2022-12-05 20:27:43,267 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46478082447551017, 'Total loss': 0.46478082447551017} | train loss {'Reaction outcome loss': 0.13668223176548472, 'Total loss': 0.13668223176548472}
2022-12-05 20:27:43,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:43,267 INFO:     Epoch: 55
2022-12-05 20:27:44,042 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46299676458502925, 'Total loss': 0.46299676458502925} | train loss {'Reaction outcome loss': 0.13928255835761788, 'Total loss': 0.13928255835761788}
2022-12-05 20:27:44,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:44,042 INFO:     Epoch: 56
2022-12-05 20:27:44,820 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4463442979856979, 'Total loss': 0.4463442979856979} | train loss {'Reaction outcome loss': 0.1352494812654484, 'Total loss': 0.1352494812654484}
2022-12-05 20:27:44,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:44,820 INFO:     Epoch: 57
2022-12-05 20:27:45,598 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46041990799266236, 'Total loss': 0.46041990799266236} | train loss {'Reaction outcome loss': 0.13688645222926604, 'Total loss': 0.13688645222926604}
2022-12-05 20:27:45,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:45,598 INFO:     Epoch: 58
2022-12-05 20:27:46,375 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.457454604464908, 'Total loss': 0.457454604464908} | train loss {'Reaction outcome loss': 0.13246464637703584, 'Total loss': 0.13246464637703584}
2022-12-05 20:27:46,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:46,375 INFO:     Epoch: 59
2022-12-05 20:27:47,147 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4729550648913827, 'Total loss': 0.4729550648913827} | train loss {'Reaction outcome loss': 0.13270616390146925, 'Total loss': 0.13270616390146925}
2022-12-05 20:27:47,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:47,148 INFO:     Epoch: 60
2022-12-05 20:27:47,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45708104552224627, 'Total loss': 0.45708104552224627} | train loss {'Reaction outcome loss': 0.13593093508885043, 'Total loss': 0.13593093508885043}
2022-12-05 20:27:47,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:47,921 INFO:     Epoch: 61
2022-12-05 20:27:48,694 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4661741426517797, 'Total loss': 0.4661741426517797} | train loss {'Reaction outcome loss': 0.13222416656733046, 'Total loss': 0.13222416656733046}
2022-12-05 20:27:48,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:48,694 INFO:     Epoch: 62
2022-12-05 20:27:49,467 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46014597630778026, 'Total loss': 0.46014597630778026} | train loss {'Reaction outcome loss': 0.13085204041868326, 'Total loss': 0.13085204041868326}
2022-12-05 20:27:49,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:49,467 INFO:     Epoch: 63
2022-12-05 20:27:50,240 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45626380000003547, 'Total loss': 0.45626380000003547} | train loss {'Reaction outcome loss': 0.1307108333395397, 'Total loss': 0.1307108333395397}
2022-12-05 20:27:50,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:50,240 INFO:     Epoch: 64
2022-12-05 20:27:51,017 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4555196166038513, 'Total loss': 0.4555196166038513} | train loss {'Reaction outcome loss': 0.1320643185210399, 'Total loss': 0.1320643185210399}
2022-12-05 20:27:51,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:51,018 INFO:     Epoch: 65
2022-12-05 20:27:51,792 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46366008440422457, 'Total loss': 0.46366008440422457} | train loss {'Reaction outcome loss': 0.12779349404707796, 'Total loss': 0.12779349404707796}
2022-12-05 20:27:51,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:51,792 INFO:     Epoch: 66
2022-12-05 20:27:52,566 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47385507614113564, 'Total loss': 0.47385507614113564} | train loss {'Reaction outcome loss': 0.12835102276418542, 'Total loss': 0.12835102276418542}
2022-12-05 20:27:52,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:52,566 INFO:     Epoch: 67
2022-12-05 20:27:53,342 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46695288877154506, 'Total loss': 0.46695288877154506} | train loss {'Reaction outcome loss': 0.12632355792447925, 'Total loss': 0.12632355792447925}
2022-12-05 20:27:53,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:53,342 INFO:     Epoch: 68
2022-12-05 20:27:54,125 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46778289090062297, 'Total loss': 0.46778289090062297} | train loss {'Reaction outcome loss': 0.12943047158740706, 'Total loss': 0.12943047158740706}
2022-12-05 20:27:54,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:54,125 INFO:     Epoch: 69
2022-12-05 20:27:54,897 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44271246118600976, 'Total loss': 0.44271246118600976} | train loss {'Reaction outcome loss': 0.12699659187804724, 'Total loss': 0.12699659187804724}
2022-12-05 20:27:54,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:54,898 INFO:     Epoch: 70
2022-12-05 20:27:55,671 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4549854643816172, 'Total loss': 0.4549854643816172} | train loss {'Reaction outcome loss': 0.12522796001743342, 'Total loss': 0.12522796001743342}
2022-12-05 20:27:55,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:55,671 INFO:     Epoch: 71
2022-12-05 20:27:56,444 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4688347713198773, 'Total loss': 0.4688347713198773} | train loss {'Reaction outcome loss': 0.1250843854934038, 'Total loss': 0.1250843854934038}
2022-12-05 20:27:56,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:56,445 INFO:     Epoch: 72
2022-12-05 20:27:57,220 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47146380814008937, 'Total loss': 0.47146380814008937} | train loss {'Reaction outcome loss': 0.12559609507500638, 'Total loss': 0.12559609507500638}
2022-12-05 20:27:57,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:57,220 INFO:     Epoch: 73
2022-12-05 20:27:57,993 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4544586587783902, 'Total loss': 0.4544586587783902} | train loss {'Reaction outcome loss': 0.12361341824022229, 'Total loss': 0.12361341824022229}
2022-12-05 20:27:57,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:57,994 INFO:     Epoch: 74
2022-12-05 20:27:58,773 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4513098063857056, 'Total loss': 0.4513098063857056} | train loss {'Reaction outcome loss': 0.12288964335180697, 'Total loss': 0.12288964335180697}
2022-12-05 20:27:58,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:58,773 INFO:     Epoch: 75
2022-12-05 20:27:59,547 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46087656915187836, 'Total loss': 0.46087656915187836} | train loss {'Reaction outcome loss': 0.12216802007427104, 'Total loss': 0.12216802007427104}
2022-12-05 20:27:59,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:27:59,547 INFO:     Epoch: 76
2022-12-05 20:28:00,320 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4503014217628989, 'Total loss': 0.4503014217628989} | train loss {'Reaction outcome loss': 0.1240871746596865, 'Total loss': 0.1240871746596865}
2022-12-05 20:28:00,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:00,320 INFO:     Epoch: 77
2022-12-05 20:28:01,092 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46436493064081946, 'Total loss': 0.46436493064081946} | train loss {'Reaction outcome loss': 0.12464170072792617, 'Total loss': 0.12464170072792617}
2022-12-05 20:28:01,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:01,092 INFO:     Epoch: 78
2022-12-05 20:28:01,868 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46193135529756546, 'Total loss': 0.46193135529756546} | train loss {'Reaction outcome loss': 0.12466278403127169, 'Total loss': 0.12466278403127169}
2022-12-05 20:28:01,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:01,868 INFO:     Epoch: 79
2022-12-05 20:28:02,642 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4628958362479543, 'Total loss': 0.4628958362479543} | train loss {'Reaction outcome loss': 0.11959913845525169, 'Total loss': 0.11959913845525169}
2022-12-05 20:28:02,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:02,642 INFO:     Epoch: 80
2022-12-05 20:28:03,415 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4578682286448257, 'Total loss': 0.4578682286448257} | train loss {'Reaction outcome loss': 0.11990986344954152, 'Total loss': 0.11990986344954152}
2022-12-05 20:28:03,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:03,416 INFO:     Epoch: 81
2022-12-05 20:28:04,190 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4598665970355965, 'Total loss': 0.4598665970355965} | train loss {'Reaction outcome loss': 0.11982503022662684, 'Total loss': 0.11982503022662684}
2022-12-05 20:28:04,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:04,190 INFO:     Epoch: 82
2022-12-05 20:28:04,967 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4626380517039188, 'Total loss': 0.4626380517039188} | train loss {'Reaction outcome loss': 0.11852172635434592, 'Total loss': 0.11852172635434592}
2022-12-05 20:28:04,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:04,968 INFO:     Epoch: 83
2022-12-05 20:28:05,748 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4660796945871309, 'Total loss': 0.4660796945871309} | train loss {'Reaction outcome loss': 0.11974103336191935, 'Total loss': 0.11974103336191935}
2022-12-05 20:28:05,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:05,748 INFO:     Epoch: 84
2022-12-05 20:28:06,522 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4696719085061273, 'Total loss': 0.4696719085061273} | train loss {'Reaction outcome loss': 0.12291762632791137, 'Total loss': 0.12291762632791137}
2022-12-05 20:28:06,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:06,523 INFO:     Epoch: 85
2022-12-05 20:28:07,301 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4542636434699214, 'Total loss': 0.4542636434699214} | train loss {'Reaction outcome loss': 0.11885905147102646, 'Total loss': 0.11885905147102646}
2022-12-05 20:28:07,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:07,301 INFO:     Epoch: 86
2022-12-05 20:28:08,077 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4583025080866592, 'Total loss': 0.4583025080866592} | train loss {'Reaction outcome loss': 0.12178414346283821, 'Total loss': 0.12178414346283821}
2022-12-05 20:28:08,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:08,077 INFO:     Epoch: 87
2022-12-05 20:28:08,852 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4594504230244215, 'Total loss': 0.4594504230244215} | train loss {'Reaction outcome loss': 0.11699960988442429, 'Total loss': 0.11699960988442429}
2022-12-05 20:28:08,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:08,852 INFO:     Epoch: 88
2022-12-05 20:28:09,627 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.453816847572493, 'Total loss': 0.453816847572493} | train loss {'Reaction outcome loss': 0.11874359025482516, 'Total loss': 0.11874359025482516}
2022-12-05 20:28:09,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:09,628 INFO:     Epoch: 89
2022-12-05 20:28:10,401 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4698761464204899, 'Total loss': 0.4698761464204899} | train loss {'Reaction outcome loss': 0.11953862329380067, 'Total loss': 0.11953862329380067}
2022-12-05 20:28:10,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:10,401 INFO:     Epoch: 90
2022-12-05 20:28:11,179 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45464708950630456, 'Total loss': 0.45464708950630456} | train loss {'Reaction outcome loss': 0.12043633038697184, 'Total loss': 0.12043633038697184}
2022-12-05 20:28:11,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:11,180 INFO:     Epoch: 91
2022-12-05 20:28:11,955 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47406340962232546, 'Total loss': 0.47406340962232546} | train loss {'Reaction outcome loss': 0.11615524298251896, 'Total loss': 0.11615524298251896}
2022-12-05 20:28:11,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:11,955 INFO:     Epoch: 92
2022-12-05 20:28:12,728 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45506943034571273, 'Total loss': 0.45506943034571273} | train loss {'Reaction outcome loss': 0.11723709150721304, 'Total loss': 0.11723709150721304}
2022-12-05 20:28:12,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:12,728 INFO:     Epoch: 93
2022-12-05 20:28:13,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4551445536835249, 'Total loss': 0.4551445536835249} | train loss {'Reaction outcome loss': 0.11660544696019688, 'Total loss': 0.11660544696019688}
2022-12-05 20:28:13,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:13,501 INFO:     Epoch: 94
2022-12-05 20:28:14,273 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4544691495424093, 'Total loss': 0.4544691495424093} | train loss {'Reaction outcome loss': 0.11863222802592227, 'Total loss': 0.11863222802592227}
2022-12-05 20:28:14,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:14,273 INFO:     Epoch: 95
2022-12-05 20:28:15,050 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4637745622285577, 'Total loss': 0.4637745622285577} | train loss {'Reaction outcome loss': 0.1166921192818306, 'Total loss': 0.1166921192818306}
2022-12-05 20:28:15,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:15,050 INFO:     Epoch: 96
2022-12-05 20:28:15,826 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47037349121515143, 'Total loss': 0.47037349121515143} | train loss {'Reaction outcome loss': 0.11687260415771457, 'Total loss': 0.11687260415771457}
2022-12-05 20:28:15,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:15,826 INFO:     Epoch: 97
2022-12-05 20:28:16,602 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46534272543219635, 'Total loss': 0.46534272543219635} | train loss {'Reaction outcome loss': 0.11536277858845767, 'Total loss': 0.11536277858845767}
2022-12-05 20:28:16,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:16,602 INFO:     Epoch: 98
2022-12-05 20:28:17,389 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4544057686661565, 'Total loss': 0.4544057686661565} | train loss {'Reaction outcome loss': 0.11732357885062572, 'Total loss': 0.11732357885062572}
2022-12-05 20:28:17,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:17,390 INFO:     Epoch: 99
2022-12-05 20:28:18,174 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.464147541758626, 'Total loss': 0.464147541758626} | train loss {'Reaction outcome loss': 0.11506047728471458, 'Total loss': 0.11506047728471458}
2022-12-05 20:28:18,174 INFO:     Best model found after epoch 16 of 100.
2022-12-05 20:28:18,174 INFO:   Done with stage: TRAINING
2022-12-05 20:28:18,174 INFO:   Starting stage: EVALUATION
2022-12-05 20:28:18,311 INFO:   Done with stage: EVALUATION
2022-12-05 20:28:18,311 INFO:   Leaving out SEQ value Fold_1
2022-12-05 20:28:18,324 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:28:18,324 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:28:18,977 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:28:18,978 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:28:19,047 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:28:19,047 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:28:19,047 INFO:     No hyperparam tuning for this model
2022-12-05 20:28:19,047 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:28:19,047 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:28:19,048 INFO:     None feature selector for col prot
2022-12-05 20:28:19,048 INFO:     None feature selector for col prot
2022-12-05 20:28:19,048 INFO:     None feature selector for col prot
2022-12-05 20:28:19,049 INFO:     None feature selector for col chem
2022-12-05 20:28:19,049 INFO:     None feature selector for col chem
2022-12-05 20:28:19,049 INFO:     None feature selector for col chem
2022-12-05 20:28:19,049 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:28:19,049 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:28:19,051 INFO:     Number of params in model 215821
2022-12-05 20:28:19,054 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:28:19,054 INFO:   Starting stage: TRAINING
2022-12-05 20:28:19,114 INFO:     Val loss before train {'Reaction outcome loss': 1.009069790894335, 'Total loss': 1.009069790894335}
2022-12-05 20:28:19,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:19,115 INFO:     Epoch: 0
2022-12-05 20:28:19,912 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6226321160793304, 'Total loss': 0.6226321160793304} | train loss {'Reaction outcome loss': 0.7926013441944895, 'Total loss': 0.7926013441944895}
2022-12-05 20:28:19,912 INFO:     Found new best model at epoch 0
2022-12-05 20:28:19,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:19,913 INFO:     Epoch: 1
2022-12-05 20:28:20,707 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5369305278767239, 'Total loss': 0.5369305278767239} | train loss {'Reaction outcome loss': 0.5484954239385813, 'Total loss': 0.5484954239385813}
2022-12-05 20:28:20,708 INFO:     Found new best model at epoch 1
2022-12-05 20:28:20,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:20,708 INFO:     Epoch: 2
2022-12-05 20:28:21,506 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49618707597255707, 'Total loss': 0.49618707597255707} | train loss {'Reaction outcome loss': 0.4871942845554004, 'Total loss': 0.4871942845554004}
2022-12-05 20:28:21,507 INFO:     Found new best model at epoch 2
2022-12-05 20:28:21,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:21,507 INFO:     Epoch: 3
2022-12-05 20:28:22,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4616832472383976, 'Total loss': 0.4616832472383976} | train loss {'Reaction outcome loss': 0.44408610058940856, 'Total loss': 0.44408610058940856}
2022-12-05 20:28:22,305 INFO:     Found new best model at epoch 3
2022-12-05 20:28:22,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:22,306 INFO:     Epoch: 4
2022-12-05 20:28:23,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44735294207930565, 'Total loss': 0.44735294207930565} | train loss {'Reaction outcome loss': 0.4139227544425078, 'Total loss': 0.4139227544425078}
2022-12-05 20:28:23,100 INFO:     Found new best model at epoch 4
2022-12-05 20:28:23,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:23,101 INFO:     Epoch: 5
2022-12-05 20:28:23,894 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4293720265003768, 'Total loss': 0.4293720265003768} | train loss {'Reaction outcome loss': 0.39202202127318875, 'Total loss': 0.39202202127318875}
2022-12-05 20:28:23,894 INFO:     Found new best model at epoch 5
2022-12-05 20:28:23,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:23,895 INFO:     Epoch: 6
2022-12-05 20:28:24,694 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42894243550571526, 'Total loss': 0.42894243550571526} | train loss {'Reaction outcome loss': 0.36992800766639866, 'Total loss': 0.36992800766639866}
2022-12-05 20:28:24,694 INFO:     Found new best model at epoch 6
2022-12-05 20:28:24,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:24,695 INFO:     Epoch: 7
2022-12-05 20:28:25,489 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43109276823022147, 'Total loss': 0.43109276823022147} | train loss {'Reaction outcome loss': 0.3607294097965063, 'Total loss': 0.3607294097965063}
2022-12-05 20:28:25,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:25,490 INFO:     Epoch: 8
2022-12-05 20:28:26,285 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41510194540023804, 'Total loss': 0.41510194540023804} | train loss {'Reaction outcome loss': 0.3465558643403806, 'Total loss': 0.3465558643403806}
2022-12-05 20:28:26,285 INFO:     Found new best model at epoch 8
2022-12-05 20:28:26,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:26,286 INFO:     Epoch: 9
2022-12-05 20:28:27,081 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.414945838464932, 'Total loss': 0.414945838464932} | train loss {'Reaction outcome loss': 0.3271418286907875, 'Total loss': 0.3271418286907875}
2022-12-05 20:28:27,081 INFO:     Found new best model at epoch 9
2022-12-05 20:28:27,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:27,082 INFO:     Epoch: 10
2022-12-05 20:28:27,877 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.412104970690879, 'Total loss': 0.412104970690879} | train loss {'Reaction outcome loss': 0.31571221499428576, 'Total loss': 0.31571221499428576}
2022-12-05 20:28:27,877 INFO:     Found new best model at epoch 10
2022-12-05 20:28:27,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:27,878 INFO:     Epoch: 11
2022-12-05 20:28:28,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40054235099391505, 'Total loss': 0.40054235099391505} | train loss {'Reaction outcome loss': 0.306817711968171, 'Total loss': 0.306817711968171}
2022-12-05 20:28:28,675 INFO:     Found new best model at epoch 11
2022-12-05 20:28:28,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:28,676 INFO:     Epoch: 12
2022-12-05 20:28:29,472 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3988346630199389, 'Total loss': 0.3988346630199389} | train loss {'Reaction outcome loss': 0.29714268940663047, 'Total loss': 0.29714268940663047}
2022-12-05 20:28:29,472 INFO:     Found new best model at epoch 12
2022-12-05 20:28:29,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:29,473 INFO:     Epoch: 13
2022-12-05 20:28:30,266 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.411297007040544, 'Total loss': 0.411297007040544} | train loss {'Reaction outcome loss': 0.2810985553361144, 'Total loss': 0.2810985553361144}
2022-12-05 20:28:30,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:30,267 INFO:     Epoch: 14
2022-12-05 20:28:31,061 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39797159081155603, 'Total loss': 0.39797159081155603} | train loss {'Reaction outcome loss': 0.27578452742292814, 'Total loss': 0.27578452742292814}
2022-12-05 20:28:31,061 INFO:     Found new best model at epoch 14
2022-12-05 20:28:31,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:31,062 INFO:     Epoch: 15
2022-12-05 20:28:31,859 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4128033244474368, 'Total loss': 0.4128033244474368} | train loss {'Reaction outcome loss': 0.2662864873404445, 'Total loss': 0.2662864873404445}
2022-12-05 20:28:31,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:31,859 INFO:     Epoch: 16
2022-12-05 20:28:32,654 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.419518073851412, 'Total loss': 0.419518073851412} | train loss {'Reaction outcome loss': 0.26223795568412134, 'Total loss': 0.26223795568412134}
2022-12-05 20:28:32,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:32,655 INFO:     Epoch: 17
2022-12-05 20:28:33,447 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3965834900736809, 'Total loss': 0.3965834900736809} | train loss {'Reaction outcome loss': 0.25389616824837347, 'Total loss': 0.25389616824837347}
2022-12-05 20:28:33,447 INFO:     Found new best model at epoch 17
2022-12-05 20:28:33,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:33,448 INFO:     Epoch: 18
2022-12-05 20:28:34,243 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3967147616838867, 'Total loss': 0.3967147616838867} | train loss {'Reaction outcome loss': 0.24722134206455337, 'Total loss': 0.24722134206455337}
2022-12-05 20:28:34,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:34,244 INFO:     Epoch: 19
2022-12-05 20:28:35,038 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3971403899856589, 'Total loss': 0.3971403899856589} | train loss {'Reaction outcome loss': 0.2379155038301701, 'Total loss': 0.2379155038301701}
2022-12-05 20:28:35,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:35,039 INFO:     Epoch: 20
2022-12-05 20:28:35,832 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39090239900079643, 'Total loss': 0.39090239900079643} | train loss {'Reaction outcome loss': 0.2363168669314037, 'Total loss': 0.2363168669314037}
2022-12-05 20:28:35,832 INFO:     Found new best model at epoch 20
2022-12-05 20:28:35,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:35,833 INFO:     Epoch: 21
2022-12-05 20:28:36,626 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4011863009496169, 'Total loss': 0.4011863009496169} | train loss {'Reaction outcome loss': 0.2326386818164575, 'Total loss': 0.2326386818164575}
2022-12-05 20:28:36,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:36,627 INFO:     Epoch: 22
2022-12-05 20:28:37,420 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39881746809590946, 'Total loss': 0.39881746809590946} | train loss {'Reaction outcome loss': 0.22281683077998007, 'Total loss': 0.22281683077998007}
2022-12-05 20:28:37,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:37,421 INFO:     Epoch: 23
2022-12-05 20:28:38,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41311582042412326, 'Total loss': 0.41311582042412326} | train loss {'Reaction outcome loss': 0.21759860188915178, 'Total loss': 0.21759860188915178}
2022-12-05 20:28:38,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:38,218 INFO:     Epoch: 24
2022-12-05 20:28:39,011 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.400716323744167, 'Total loss': 0.400716323744167} | train loss {'Reaction outcome loss': 0.21546989885961962, 'Total loss': 0.21546989885961962}
2022-12-05 20:28:39,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:39,012 INFO:     Epoch: 25
2022-12-05 20:28:39,811 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3958769449117509, 'Total loss': 0.3958769449117509} | train loss {'Reaction outcome loss': 0.21333152802306632, 'Total loss': 0.21333152802306632}
2022-12-05 20:28:39,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:39,812 INFO:     Epoch: 26
2022-12-05 20:28:40,607 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40477139299566095, 'Total loss': 0.40477139299566095} | train loss {'Reaction outcome loss': 0.20606177006112902, 'Total loss': 0.20606177006112902}
2022-12-05 20:28:40,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:40,608 INFO:     Epoch: 27
2022-12-05 20:28:41,403 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4022596867924387, 'Total loss': 0.4022596867924387} | train loss {'Reaction outcome loss': 0.20259842534477895, 'Total loss': 0.20259842534477895}
2022-12-05 20:28:41,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:41,403 INFO:     Epoch: 28
2022-12-05 20:28:42,197 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40006712079048157, 'Total loss': 0.40006712079048157} | train loss {'Reaction outcome loss': 0.19965006411169856, 'Total loss': 0.19965006411169856}
2022-12-05 20:28:42,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:42,197 INFO:     Epoch: 29
2022-12-05 20:28:42,995 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4118266694925048, 'Total loss': 0.4118266694925048} | train loss {'Reaction outcome loss': 0.19958339921134685, 'Total loss': 0.19958339921134685}
2022-12-05 20:28:42,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:42,995 INFO:     Epoch: 30
2022-12-05 20:28:43,790 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39669408225877717, 'Total loss': 0.39669408225877717} | train loss {'Reaction outcome loss': 0.1992005272523353, 'Total loss': 0.1992005272523353}
2022-12-05 20:28:43,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:43,790 INFO:     Epoch: 31
2022-12-05 20:28:44,594 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4018533361906355, 'Total loss': 0.4018533361906355} | train loss {'Reaction outcome loss': 0.19047379722962013, 'Total loss': 0.19047379722962013}
2022-12-05 20:28:44,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:44,594 INFO:     Epoch: 32
2022-12-05 20:28:45,392 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40532607483592903, 'Total loss': 0.40532607483592903} | train loss {'Reaction outcome loss': 0.1872977417882396, 'Total loss': 0.1872977417882396}
2022-12-05 20:28:45,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:45,392 INFO:     Epoch: 33
2022-12-05 20:28:46,188 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41863997585394164, 'Total loss': 0.41863997585394164} | train loss {'Reaction outcome loss': 0.18464817501876035, 'Total loss': 0.18464817501876035}
2022-12-05 20:28:46,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:46,188 INFO:     Epoch: 34
2022-12-05 20:28:46,987 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4060025987300006, 'Total loss': 0.4060025987300006} | train loss {'Reaction outcome loss': 0.18464371920864925, 'Total loss': 0.18464371920864925}
2022-12-05 20:28:46,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:46,988 INFO:     Epoch: 35
2022-12-05 20:28:47,787 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4175611629404805, 'Total loss': 0.4175611629404805} | train loss {'Reaction outcome loss': 0.1789541962417031, 'Total loss': 0.1789541962417031}
2022-12-05 20:28:47,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:47,787 INFO:     Epoch: 36
2022-12-05 20:28:48,582 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4100788662379438, 'Total loss': 0.4100788662379438} | train loss {'Reaction outcome loss': 0.1789779766775698, 'Total loss': 0.1789779766775698}
2022-12-05 20:28:48,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:48,582 INFO:     Epoch: 37
2022-12-05 20:28:49,379 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4155045114457607, 'Total loss': 0.4155045114457607} | train loss {'Reaction outcome loss': 0.17399117329557565, 'Total loss': 0.17399117329557565}
2022-12-05 20:28:49,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:49,379 INFO:     Epoch: 38
2022-12-05 20:28:50,178 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4280108521607789, 'Total loss': 0.4280108521607789} | train loss {'Reaction outcome loss': 0.17289954927271073, 'Total loss': 0.17289954927271073}
2022-12-05 20:28:50,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:50,178 INFO:     Epoch: 39
2022-12-05 20:28:50,973 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42085386982018297, 'Total loss': 0.42085386982018297} | train loss {'Reaction outcome loss': 0.16915726964361966, 'Total loss': 0.16915726964361966}
2022-12-05 20:28:50,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:50,973 INFO:     Epoch: 40
2022-12-05 20:28:51,768 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.423616762696342, 'Total loss': 0.423616762696342} | train loss {'Reaction outcome loss': 0.16854987407917618, 'Total loss': 0.16854987407917618}
2022-12-05 20:28:51,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:51,769 INFO:     Epoch: 41
2022-12-05 20:28:52,564 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.424148422411897, 'Total loss': 0.424148422411897} | train loss {'Reaction outcome loss': 0.16672768641398986, 'Total loss': 0.16672768641398986}
2022-12-05 20:28:52,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:52,564 INFO:     Epoch: 42
2022-12-05 20:28:53,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42261589589444076, 'Total loss': 0.42261589589444076} | train loss {'Reaction outcome loss': 0.16680795458797743, 'Total loss': 0.16680795458797743}
2022-12-05 20:28:53,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:53,361 INFO:     Epoch: 43
2022-12-05 20:28:54,165 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43212097680026834, 'Total loss': 0.43212097680026834} | train loss {'Reaction outcome loss': 0.16586939257528135, 'Total loss': 0.16586939257528135}
2022-12-05 20:28:54,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:54,165 INFO:     Epoch: 44
2022-12-05 20:28:54,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4416800784793767, 'Total loss': 0.4416800784793767} | train loss {'Reaction outcome loss': 0.16553129586824764, 'Total loss': 0.16553129586824764}
2022-12-05 20:28:54,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:54,965 INFO:     Epoch: 45
2022-12-05 20:28:55,763 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4318112182346257, 'Total loss': 0.4318112182346257} | train loss {'Reaction outcome loss': 0.16145184016428316, 'Total loss': 0.16145184016428316}
2022-12-05 20:28:55,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:55,763 INFO:     Epoch: 46
2022-12-05 20:28:56,560 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4323740056292577, 'Total loss': 0.4323740056292577} | train loss {'Reaction outcome loss': 0.15549521993724102, 'Total loss': 0.15549521993724102}
2022-12-05 20:28:56,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:56,560 INFO:     Epoch: 47
2022-12-05 20:28:57,355 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42438788737424393, 'Total loss': 0.42438788737424393} | train loss {'Reaction outcome loss': 0.15828164203869186, 'Total loss': 0.15828164203869186}
2022-12-05 20:28:57,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:57,356 INFO:     Epoch: 48
2022-12-05 20:28:58,152 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41479120911522344, 'Total loss': 0.41479120911522344} | train loss {'Reaction outcome loss': 0.1554646127204965, 'Total loss': 0.1554646127204965}
2022-12-05 20:28:58,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:58,152 INFO:     Epoch: 49
2022-12-05 20:28:58,947 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.435729751278731, 'Total loss': 0.435729751278731} | train loss {'Reaction outcome loss': 0.15529133136636816, 'Total loss': 0.15529133136636816}
2022-12-05 20:28:58,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:58,948 INFO:     Epoch: 50
2022-12-05 20:28:59,746 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4549771427092227, 'Total loss': 0.4549771427092227} | train loss {'Reaction outcome loss': 0.1524565059188301, 'Total loss': 0.1524565059188301}
2022-12-05 20:28:59,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:28:59,746 INFO:     Epoch: 51
2022-12-05 20:29:00,545 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43119892511855473, 'Total loss': 0.43119892511855473} | train loss {'Reaction outcome loss': 0.15185582062402958, 'Total loss': 0.15185582062402958}
2022-12-05 20:29:00,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:00,546 INFO:     Epoch: 52
2022-12-05 20:29:01,340 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42978391220623796, 'Total loss': 0.42978391220623796} | train loss {'Reaction outcome loss': 0.15718674491563064, 'Total loss': 0.15718674491563064}
2022-12-05 20:29:01,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:01,340 INFO:     Epoch: 53
2022-12-05 20:29:02,134 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43414466320113704, 'Total loss': 0.43414466320113704} | train loss {'Reaction outcome loss': 0.15714473755434458, 'Total loss': 0.15714473755434458}
2022-12-05 20:29:02,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:02,134 INFO:     Epoch: 54
2022-12-05 20:29:02,932 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4291526035151698, 'Total loss': 0.4291526035151698} | train loss {'Reaction outcome loss': 0.14915866987696785, 'Total loss': 0.14915866987696785}
2022-12-05 20:29:02,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:02,932 INFO:     Epoch: 55
2022-12-05 20:29:03,727 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4470391687513752, 'Total loss': 0.4470391687513752} | train loss {'Reaction outcome loss': 0.14737268077277463, 'Total loss': 0.14737268077277463}
2022-12-05 20:29:03,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:03,727 INFO:     Epoch: 56
2022-12-05 20:29:04,522 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44129464673725044, 'Total loss': 0.44129464673725044} | train loss {'Reaction outcome loss': 0.14667914822878625, 'Total loss': 0.14667914822878625}
2022-12-05 20:29:04,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:04,523 INFO:     Epoch: 57
2022-12-05 20:29:05,320 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44640552455728705, 'Total loss': 0.44640552455728705} | train loss {'Reaction outcome loss': 0.1454512905329466, 'Total loss': 0.1454512905329466}
2022-12-05 20:29:05,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:05,321 INFO:     Epoch: 58
2022-12-05 20:29:06,116 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43068866296248004, 'Total loss': 0.43068866296248004} | train loss {'Reaction outcome loss': 0.1452236688028463, 'Total loss': 0.1452236688028463}
2022-12-05 20:29:06,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:06,118 INFO:     Epoch: 59
2022-12-05 20:29:06,912 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4376150242645632, 'Total loss': 0.4376150242645632} | train loss {'Reaction outcome loss': 0.14496853287418482, 'Total loss': 0.14496853287418482}
2022-12-05 20:29:06,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:06,913 INFO:     Epoch: 60
2022-12-05 20:29:07,707 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4533658406951211, 'Total loss': 0.4533658406951211} | train loss {'Reaction outcome loss': 0.14472198740627262, 'Total loss': 0.14472198740627262}
2022-12-05 20:29:07,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:07,707 INFO:     Epoch: 61
2022-12-05 20:29:08,504 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43798441372134467, 'Total loss': 0.43798441372134467} | train loss {'Reaction outcome loss': 0.14406480624101045, 'Total loss': 0.14406480624101045}
2022-12-05 20:29:08,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:08,504 INFO:     Epoch: 62
2022-12-05 20:29:09,302 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46358733488754794, 'Total loss': 0.46358733488754794} | train loss {'Reaction outcome loss': 0.14163926560884182, 'Total loss': 0.14163926560884182}
2022-12-05 20:29:09,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:09,303 INFO:     Epoch: 63
2022-12-05 20:29:10,105 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4522228186780756, 'Total loss': 0.4522228186780756} | train loss {'Reaction outcome loss': 0.14306037383802567, 'Total loss': 0.14306037383802567}
2022-12-05 20:29:10,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:10,105 INFO:     Epoch: 64
2022-12-05 20:29:10,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44437130337411707, 'Total loss': 0.44437130337411707} | train loss {'Reaction outcome loss': 0.14022515818235362, 'Total loss': 0.14022515818235362}
2022-12-05 20:29:10,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:10,904 INFO:     Epoch: 65
2022-12-05 20:29:11,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4519506110386415, 'Total loss': 0.4519506110386415} | train loss {'Reaction outcome loss': 0.1430546821864239, 'Total loss': 0.1430546821864239}
2022-12-05 20:29:11,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:11,702 INFO:     Epoch: 66
2022-12-05 20:29:12,499 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45431941358203237, 'Total loss': 0.45431941358203237} | train loss {'Reaction outcome loss': 0.13615636996970124, 'Total loss': 0.13615636996970124}
2022-12-05 20:29:12,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:12,500 INFO:     Epoch: 67
2022-12-05 20:29:13,297 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4407065348191695, 'Total loss': 0.4407065348191695} | train loss {'Reaction outcome loss': 0.13947453115112807, 'Total loss': 0.13947453115112807}
2022-12-05 20:29:13,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:13,297 INFO:     Epoch: 68
2022-12-05 20:29:14,092 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4556032615629109, 'Total loss': 0.4556032615629109} | train loss {'Reaction outcome loss': 0.13698563882364675, 'Total loss': 0.13698563882364675}
2022-12-05 20:29:14,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:14,092 INFO:     Epoch: 69
2022-12-05 20:29:14,893 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4454188881949945, 'Total loss': 0.4454188881949945} | train loss {'Reaction outcome loss': 0.1422051426460627, 'Total loss': 0.1422051426460627}
2022-12-05 20:29:14,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:14,893 INFO:     Epoch: 70
2022-12-05 20:29:15,690 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4408707903190093, 'Total loss': 0.4408707903190093} | train loss {'Reaction outcome loss': 0.14116628928042133, 'Total loss': 0.14116628928042133}
2022-12-05 20:29:15,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:15,690 INFO:     Epoch: 71
2022-12-05 20:29:16,489 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.451693651012399, 'Total loss': 0.451693651012399} | train loss {'Reaction outcome loss': 0.1349679241107724, 'Total loss': 0.1349679241107724}
2022-12-05 20:29:16,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:16,489 INFO:     Epoch: 72
2022-12-05 20:29:17,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4433758184313774, 'Total loss': 0.4433758184313774} | train loss {'Reaction outcome loss': 0.13461795545782637, 'Total loss': 0.13461795545782637}
2022-12-05 20:29:17,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:17,290 INFO:     Epoch: 73
2022-12-05 20:29:18,089 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4517699033021927, 'Total loss': 0.4517699033021927} | train loss {'Reaction outcome loss': 0.13520011890996322, 'Total loss': 0.13520011890996322}
2022-12-05 20:29:18,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:18,089 INFO:     Epoch: 74
2022-12-05 20:29:18,888 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4810896370221268, 'Total loss': 0.4810896370221268} | train loss {'Reaction outcome loss': 0.1341087964819631, 'Total loss': 0.1341087964819631}
2022-12-05 20:29:18,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:18,888 INFO:     Epoch: 75
2022-12-05 20:29:19,684 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45701677978716115, 'Total loss': 0.45701677978716115} | train loss {'Reaction outcome loss': 0.13288297008738104, 'Total loss': 0.13288297008738104}
2022-12-05 20:29:19,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:19,685 INFO:     Epoch: 76
2022-12-05 20:29:20,482 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44599101252176543, 'Total loss': 0.44599101252176543} | train loss {'Reaction outcome loss': 0.13686740057173408, 'Total loss': 0.13686740057173408}
2022-12-05 20:29:20,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:20,482 INFO:     Epoch: 77
2022-12-05 20:29:21,279 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43937877870418807, 'Total loss': 0.43937877870418807} | train loss {'Reaction outcome loss': 0.13321061203584286, 'Total loss': 0.13321061203584286}
2022-12-05 20:29:21,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:21,280 INFO:     Epoch: 78
2022-12-05 20:29:22,077 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46290377527475357, 'Total loss': 0.46290377527475357} | train loss {'Reaction outcome loss': 0.13127986897491975, 'Total loss': 0.13127986897491975}
2022-12-05 20:29:22,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:22,077 INFO:     Epoch: 79
2022-12-05 20:29:22,876 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4429040612144904, 'Total loss': 0.4429040612144904} | train loss {'Reaction outcome loss': 0.13021479562482974, 'Total loss': 0.13021479562482974}
2022-12-05 20:29:22,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:22,876 INFO:     Epoch: 80
2022-12-05 20:29:23,677 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45272932235490193, 'Total loss': 0.45272932235490193} | train loss {'Reaction outcome loss': 0.130231065586066, 'Total loss': 0.130231065586066}
2022-12-05 20:29:23,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:23,677 INFO:     Epoch: 81
2022-12-05 20:29:24,480 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43546825207092543, 'Total loss': 0.43546825207092543} | train loss {'Reaction outcome loss': 0.12966646723683004, 'Total loss': 0.12966646723683004}
2022-12-05 20:29:24,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:24,480 INFO:     Epoch: 82
2022-12-05 20:29:25,279 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46101480891758745, 'Total loss': 0.46101480891758745} | train loss {'Reaction outcome loss': 0.1302906113414203, 'Total loss': 0.1302906113414203}
2022-12-05 20:29:25,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:25,280 INFO:     Epoch: 83
2022-12-05 20:29:26,081 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44930644434961403, 'Total loss': 0.44930644434961403} | train loss {'Reaction outcome loss': 0.13253180162702133, 'Total loss': 0.13253180162702133}
2022-12-05 20:29:26,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:26,081 INFO:     Epoch: 84
2022-12-05 20:29:26,876 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45067933862182225, 'Total loss': 0.45067933862182225} | train loss {'Reaction outcome loss': 0.12943413737889847, 'Total loss': 0.12943413737889847}
2022-12-05 20:29:26,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:26,876 INFO:     Epoch: 85
2022-12-05 20:29:27,670 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45836878737265413, 'Total loss': 0.45836878737265413} | train loss {'Reaction outcome loss': 0.13426008952502538, 'Total loss': 0.13426008952502538}
2022-12-05 20:29:27,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:27,670 INFO:     Epoch: 86
2022-12-05 20:29:28,463 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4413004263558171, 'Total loss': 0.4413004263558171} | train loss {'Reaction outcome loss': 0.13370210373480068, 'Total loss': 0.13370210373480068}
2022-12-05 20:29:28,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:28,464 INFO:     Epoch: 87
2022-12-05 20:29:29,258 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43495795130729675, 'Total loss': 0.43495795130729675} | train loss {'Reaction outcome loss': 0.1314217932220654, 'Total loss': 0.1314217932220654}
2022-12-05 20:29:29,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:29,258 INFO:     Epoch: 88
2022-12-05 20:29:30,055 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45343970642848447, 'Total loss': 0.45343970642848447} | train loss {'Reaction outcome loss': 0.12652007759612824, 'Total loss': 0.12652007759612824}
2022-12-05 20:29:30,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:30,055 INFO:     Epoch: 89
2022-12-05 20:29:30,849 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4484429685398936, 'Total loss': 0.4484429685398936} | train loss {'Reaction outcome loss': 0.13016827999866806, 'Total loss': 0.13016827999866806}
2022-12-05 20:29:30,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:30,849 INFO:     Epoch: 90
2022-12-05 20:29:31,646 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4425606510855935, 'Total loss': 0.4425606510855935} | train loss {'Reaction outcome loss': 0.12859181170672299, 'Total loss': 0.12859181170672299}
2022-12-05 20:29:31,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:31,647 INFO:     Epoch: 91
2022-12-05 20:29:32,440 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4442016709257256, 'Total loss': 0.4442016709257256} | train loss {'Reaction outcome loss': 0.12659653718866076, 'Total loss': 0.12659653718866076}
2022-12-05 20:29:32,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:32,441 INFO:     Epoch: 92
2022-12-05 20:29:33,236 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4633184539323503, 'Total loss': 0.4633184539323503} | train loss {'Reaction outcome loss': 0.13031099821527597, 'Total loss': 0.13031099821527597}
2022-12-05 20:29:33,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:33,237 INFO:     Epoch: 93
2022-12-05 20:29:34,041 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4399994080039588, 'Total loss': 0.4399994080039588} | train loss {'Reaction outcome loss': 0.12775923084724045, 'Total loss': 0.12775923084724045}
2022-12-05 20:29:34,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:34,041 INFO:     Epoch: 94
2022-12-05 20:29:34,845 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4459344041957097, 'Total loss': 0.4459344041957097} | train loss {'Reaction outcome loss': 0.129187472945132, 'Total loss': 0.129187472945132}
2022-12-05 20:29:34,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:34,845 INFO:     Epoch: 95
2022-12-05 20:29:35,642 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43401041152802383, 'Total loss': 0.43401041152802383} | train loss {'Reaction outcome loss': 0.12458555242763115, 'Total loss': 0.12458555242763115}
2022-12-05 20:29:35,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:35,642 INFO:     Epoch: 96
2022-12-05 20:29:36,441 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45546255057508295, 'Total loss': 0.45546255057508295} | train loss {'Reaction outcome loss': 0.12934730298862404, 'Total loss': 0.12934730298862404}
2022-12-05 20:29:36,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:36,441 INFO:     Epoch: 97
2022-12-05 20:29:37,238 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43109886669977143, 'Total loss': 0.43109886669977143} | train loss {'Reaction outcome loss': 0.12718531431683042, 'Total loss': 0.12718531431683042}
2022-12-05 20:29:37,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:37,239 INFO:     Epoch: 98
2022-12-05 20:29:38,034 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45663181269033387, 'Total loss': 0.45663181269033387} | train loss {'Reaction outcome loss': 0.12086878494106927, 'Total loss': 0.12086878494106927}
2022-12-05 20:29:38,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:38,034 INFO:     Epoch: 99
2022-12-05 20:29:38,829 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45444882864301855, 'Total loss': 0.45444882864301855} | train loss {'Reaction outcome loss': 0.12548490530888545, 'Total loss': 0.12548490530888545}
2022-12-05 20:29:38,829 INFO:     Best model found after epoch 21 of 100.
2022-12-05 20:29:38,830 INFO:   Done with stage: TRAINING
2022-12-05 20:29:38,830 INFO:   Starting stage: EVALUATION
2022-12-05 20:29:38,955 INFO:   Done with stage: EVALUATION
2022-12-05 20:29:38,955 INFO:   Leaving out SEQ value Fold_2
2022-12-05 20:29:38,969 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:29:38,969 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:29:39,614 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:29:39,615 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:29:39,685 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:29:39,685 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:29:39,685 INFO:     No hyperparam tuning for this model
2022-12-05 20:29:39,685 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:29:39,685 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:29:39,686 INFO:     None feature selector for col prot
2022-12-05 20:29:39,686 INFO:     None feature selector for col prot
2022-12-05 20:29:39,686 INFO:     None feature selector for col prot
2022-12-05 20:29:39,686 INFO:     None feature selector for col chem
2022-12-05 20:29:39,687 INFO:     None feature selector for col chem
2022-12-05 20:29:39,687 INFO:     None feature selector for col chem
2022-12-05 20:29:39,687 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:29:39,687 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:29:39,688 INFO:     Number of params in model 215821
2022-12-05 20:29:39,691 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:29:39,691 INFO:   Starting stage: TRAINING
2022-12-05 20:29:39,752 INFO:     Val loss before train {'Reaction outcome loss': 0.9676476567983627, 'Total loss': 0.9676476567983627}
2022-12-05 20:29:39,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:39,752 INFO:     Epoch: 0
2022-12-05 20:29:40,548 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6069838055832819, 'Total loss': 0.6069838055832819} | train loss {'Reaction outcome loss': 0.8003069349697658, 'Total loss': 0.8003069349697658}
2022-12-05 20:29:40,548 INFO:     Found new best model at epoch 0
2022-12-05 20:29:40,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:40,549 INFO:     Epoch: 1
2022-12-05 20:29:41,343 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.518751598386602, 'Total loss': 0.518751598386602} | train loss {'Reaction outcome loss': 0.5383720478841236, 'Total loss': 0.5383720478841236}
2022-12-05 20:29:41,343 INFO:     Found new best model at epoch 1
2022-12-05 20:29:41,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:41,344 INFO:     Epoch: 2
2022-12-05 20:29:42,133 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5046044713394209, 'Total loss': 0.5046044713394209} | train loss {'Reaction outcome loss': 0.472144176765364, 'Total loss': 0.472144176765364}
2022-12-05 20:29:42,133 INFO:     Found new best model at epoch 2
2022-12-05 20:29:42,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:42,134 INFO:     Epoch: 3
2022-12-05 20:29:42,923 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4783723327246579, 'Total loss': 0.4783723327246579} | train loss {'Reaction outcome loss': 0.42845476950917927, 'Total loss': 0.42845476950917927}
2022-12-05 20:29:42,924 INFO:     Found new best model at epoch 3
2022-12-05 20:29:42,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:42,924 INFO:     Epoch: 4
2022-12-05 20:29:43,714 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4661819819699634, 'Total loss': 0.4661819819699634} | train loss {'Reaction outcome loss': 0.39915844676445944, 'Total loss': 0.39915844676445944}
2022-12-05 20:29:43,715 INFO:     Found new best model at epoch 4
2022-12-05 20:29:43,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:43,716 INFO:     Epoch: 5
2022-12-05 20:29:44,508 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46073250709609553, 'Total loss': 0.46073250709609553} | train loss {'Reaction outcome loss': 0.37556619546851333, 'Total loss': 0.37556619546851333}
2022-12-05 20:29:44,508 INFO:     Found new best model at epoch 5
2022-12-05 20:29:44,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:44,509 INFO:     Epoch: 6
2022-12-05 20:29:45,300 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4432245201685212, 'Total loss': 0.4432245201685212} | train loss {'Reaction outcome loss': 0.35384262985720927, 'Total loss': 0.35384262985720927}
2022-12-05 20:29:45,300 INFO:     Found new best model at epoch 6
2022-12-05 20:29:45,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:45,301 INFO:     Epoch: 7
2022-12-05 20:29:46,092 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4497795917771079, 'Total loss': 0.4497795917771079} | train loss {'Reaction outcome loss': 0.3379702570487042, 'Total loss': 0.3379702570487042}
2022-12-05 20:29:46,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:46,093 INFO:     Epoch: 8
2022-12-05 20:29:46,886 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41638849387792026, 'Total loss': 0.41638849387792026} | train loss {'Reaction outcome loss': 0.32011619377501155, 'Total loss': 0.32011619377501155}
2022-12-05 20:29:46,886 INFO:     Found new best model at epoch 8
2022-12-05 20:29:46,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:46,887 INFO:     Epoch: 9
2022-12-05 20:29:47,678 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42734376984563743, 'Total loss': 0.42734376984563743} | train loss {'Reaction outcome loss': 0.3100183673963255, 'Total loss': 0.3100183673963255}
2022-12-05 20:29:47,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:47,678 INFO:     Epoch: 10
2022-12-05 20:29:48,470 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.432513701306148, 'Total loss': 0.432513701306148} | train loss {'Reaction outcome loss': 0.2928863243180878, 'Total loss': 0.2928863243180878}
2022-12-05 20:29:48,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:48,470 INFO:     Epoch: 11
2022-12-05 20:29:49,261 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4312318353490396, 'Total loss': 0.4312318353490396} | train loss {'Reaction outcome loss': 0.2837680195971411, 'Total loss': 0.2837680195971411}
2022-12-05 20:29:49,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:49,261 INFO:     Epoch: 12
2022-12-05 20:29:50,054 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43265121193094686, 'Total loss': 0.43265121193094686} | train loss {'Reaction outcome loss': 0.2694925582226442, 'Total loss': 0.2694925582226442}
2022-12-05 20:29:50,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:50,054 INFO:     Epoch: 13
2022-12-05 20:29:50,843 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44611294669183815, 'Total loss': 0.44611294669183815} | train loss {'Reaction outcome loss': 0.263404892613085, 'Total loss': 0.263404892613085}
2022-12-05 20:29:50,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:50,843 INFO:     Epoch: 14
2022-12-05 20:29:51,633 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4289202866229144, 'Total loss': 0.4289202866229144} | train loss {'Reaction outcome loss': 0.2531802628113299, 'Total loss': 0.2531802628113299}
2022-12-05 20:29:51,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:51,633 INFO:     Epoch: 15
2022-12-05 20:29:52,422 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4091410741887309, 'Total loss': 0.4091410741887309} | train loss {'Reaction outcome loss': 0.2439125375480068, 'Total loss': 0.2439125375480068}
2022-12-05 20:29:52,422 INFO:     Found new best model at epoch 15
2022-12-05 20:29:52,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:52,423 INFO:     Epoch: 16
2022-12-05 20:29:53,217 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4263127293776382, 'Total loss': 0.4263127293776382} | train loss {'Reaction outcome loss': 0.2384524787643126, 'Total loss': 0.2384524787643126}
2022-12-05 20:29:53,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:53,217 INFO:     Epoch: 17
2022-12-05 20:29:54,016 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4184332039545883, 'Total loss': 0.4184332039545883} | train loss {'Reaction outcome loss': 0.2289926647987901, 'Total loss': 0.2289926647987901}
2022-12-05 20:29:54,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:54,016 INFO:     Epoch: 18
2022-12-05 20:29:54,811 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4278258982707154, 'Total loss': 0.4278258982707154} | train loss {'Reaction outcome loss': 0.22374916853649277, 'Total loss': 0.22374916853649277}
2022-12-05 20:29:54,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:54,812 INFO:     Epoch: 19
2022-12-05 20:29:55,607 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4523054852404378, 'Total loss': 0.4523054852404378} | train loss {'Reaction outcome loss': 0.21544816602705694, 'Total loss': 0.21544816602705694}
2022-12-05 20:29:55,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:55,607 INFO:     Epoch: 20
2022-12-05 20:29:56,397 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41927302730354393, 'Total loss': 0.41927302730354393} | train loss {'Reaction outcome loss': 0.21192209912197932, 'Total loss': 0.21192209912197932}
2022-12-05 20:29:56,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:56,398 INFO:     Epoch: 21
2022-12-05 20:29:57,190 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.441500284793702, 'Total loss': 0.441500284793702} | train loss {'Reaction outcome loss': 0.20502742828459156, 'Total loss': 0.20502742828459156}
2022-12-05 20:29:57,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:57,190 INFO:     Epoch: 22
2022-12-05 20:29:57,982 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4358497214588252, 'Total loss': 0.4358497214588252} | train loss {'Reaction outcome loss': 0.2011129583175085, 'Total loss': 0.2011129583175085}
2022-12-05 20:29:57,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:57,982 INFO:     Epoch: 23
2022-12-05 20:29:58,772 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.430009839548306, 'Total loss': 0.430009839548306} | train loss {'Reaction outcome loss': 0.1958331908802597, 'Total loss': 0.1958331908802597}
2022-12-05 20:29:58,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:58,772 INFO:     Epoch: 24
2022-12-05 20:29:59,563 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43022382293235173, 'Total loss': 0.43022382293235173} | train loss {'Reaction outcome loss': 0.19195757357745755, 'Total loss': 0.19195757357745755}
2022-12-05 20:29:59,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:29:59,563 INFO:     Epoch: 25
2022-12-05 20:30:00,356 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43082827659831807, 'Total loss': 0.43082827659831807} | train loss {'Reaction outcome loss': 0.18834510901752782, 'Total loss': 0.18834510901752782}
2022-12-05 20:30:00,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:00,356 INFO:     Epoch: 26
2022-12-05 20:30:01,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43069685995578766, 'Total loss': 0.43069685995578766} | train loss {'Reaction outcome loss': 0.1851845886482268, 'Total loss': 0.1851845886482268}
2022-12-05 20:30:01,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:01,151 INFO:     Epoch: 27
2022-12-05 20:30:01,952 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4500660276548429, 'Total loss': 0.4500660276548429} | train loss {'Reaction outcome loss': 0.179363842521395, 'Total loss': 0.179363842521395}
2022-12-05 20:30:01,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:01,953 INFO:     Epoch: 28
2022-12-05 20:30:02,744 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4369510605253957, 'Total loss': 0.4369510605253957} | train loss {'Reaction outcome loss': 0.17780705658452853, 'Total loss': 0.17780705658452853}
2022-12-05 20:30:02,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:02,744 INFO:     Epoch: 29
2022-12-05 20:30:03,534 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4395947883074934, 'Total loss': 0.4395947883074934} | train loss {'Reaction outcome loss': 0.17570448249426424, 'Total loss': 0.17570448249426424}
2022-12-05 20:30:03,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:03,534 INFO:     Epoch: 30
2022-12-05 20:30:04,324 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4458790167488835, 'Total loss': 0.4458790167488835} | train loss {'Reaction outcome loss': 0.17350312256235248, 'Total loss': 0.17350312256235248}
2022-12-05 20:30:04,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:04,324 INFO:     Epoch: 31
2022-12-05 20:30:05,122 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45475802452049474, 'Total loss': 0.45475802452049474} | train loss {'Reaction outcome loss': 0.16855182228039722, 'Total loss': 0.16855182228039722}
2022-12-05 20:30:05,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:05,122 INFO:     Epoch: 32
2022-12-05 20:30:05,921 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46693659776991064, 'Total loss': 0.46693659776991064} | train loss {'Reaction outcome loss': 0.16697978688289924, 'Total loss': 0.16697978688289924}
2022-12-05 20:30:05,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:05,921 INFO:     Epoch: 33
2022-12-05 20:30:06,712 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4415989125316793, 'Total loss': 0.4415989125316793} | train loss {'Reaction outcome loss': 0.1651594899138626, 'Total loss': 0.1651594899138626}
2022-12-05 20:30:06,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:06,713 INFO:     Epoch: 34
2022-12-05 20:30:07,507 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45364596864039247, 'Total loss': 0.45364596864039247} | train loss {'Reaction outcome loss': 0.1640854157431393, 'Total loss': 0.1640854157431393}
2022-12-05 20:30:07,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:07,507 INFO:     Epoch: 35
2022-12-05 20:30:08,306 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4303032676265998, 'Total loss': 0.4303032676265998} | train loss {'Reaction outcome loss': 0.16041891608311207, 'Total loss': 0.16041891608311207}
2022-12-05 20:30:08,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:08,307 INFO:     Epoch: 36
2022-12-05 20:30:09,104 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4486122680616311, 'Total loss': 0.4486122680616311} | train loss {'Reaction outcome loss': 0.1628429144772948, 'Total loss': 0.1628429144772948}
2022-12-05 20:30:09,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:09,104 INFO:     Epoch: 37
2022-12-05 20:30:09,902 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4491764413700862, 'Total loss': 0.4491764413700862} | train loss {'Reaction outcome loss': 0.15581621861427414, 'Total loss': 0.15581621861427414}
2022-12-05 20:30:09,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:09,902 INFO:     Epoch: 38
2022-12-05 20:30:10,704 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4646578712219542, 'Total loss': 0.4646578712219542} | train loss {'Reaction outcome loss': 0.15673611202106183, 'Total loss': 0.15673611202106183}
2022-12-05 20:30:10,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:10,705 INFO:     Epoch: 39
2022-12-05 20:30:11,499 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44832783632657747, 'Total loss': 0.44832783632657747} | train loss {'Reaction outcome loss': 0.1522989270942552, 'Total loss': 0.1522989270942552}
2022-12-05 20:30:11,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:11,499 INFO:     Epoch: 40
2022-12-05 20:30:12,300 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4716410774060271, 'Total loss': 0.4716410774060271} | train loss {'Reaction outcome loss': 0.15298625093181523, 'Total loss': 0.15298625093181523}
2022-12-05 20:30:12,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:12,300 INFO:     Epoch: 41
2022-12-05 20:30:13,102 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4442034120756117, 'Total loss': 0.4442034120756117} | train loss {'Reaction outcome loss': 0.15340714177154766, 'Total loss': 0.15340714177154766}
2022-12-05 20:30:13,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:13,103 INFO:     Epoch: 42
2022-12-05 20:30:13,899 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4541052613746036, 'Total loss': 0.4541052613746036} | train loss {'Reaction outcome loss': 0.15058847727178007, 'Total loss': 0.15058847727178007}
2022-12-05 20:30:13,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:13,899 INFO:     Epoch: 43
2022-12-05 20:30:14,694 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45627676153724844, 'Total loss': 0.45627676153724844} | train loss {'Reaction outcome loss': 0.1506991898374898, 'Total loss': 0.1506991898374898}
2022-12-05 20:30:14,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:14,695 INFO:     Epoch: 44
2022-12-05 20:30:15,494 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44272852838251064, 'Total loss': 0.44272852838251064} | train loss {'Reaction outcome loss': 0.14797632748983344, 'Total loss': 0.14797632748983344}
2022-12-05 20:30:15,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:15,495 INFO:     Epoch: 45
2022-12-05 20:30:16,286 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4581813541325656, 'Total loss': 0.4581813541325656} | train loss {'Reaction outcome loss': 0.1471703637201263, 'Total loss': 0.1471703637201263}
2022-12-05 20:30:16,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:16,286 INFO:     Epoch: 46
2022-12-05 20:30:17,082 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47405162250453775, 'Total loss': 0.47405162250453775} | train loss {'Reaction outcome loss': 0.14557184323820532, 'Total loss': 0.14557184323820532}
2022-12-05 20:30:17,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:17,082 INFO:     Epoch: 47
2022-12-05 20:30:17,875 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46530445190993225, 'Total loss': 0.46530445190993225} | train loss {'Reaction outcome loss': 0.14418056664076082, 'Total loss': 0.14418056664076082}
2022-12-05 20:30:17,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:17,875 INFO:     Epoch: 48
2022-12-05 20:30:18,671 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4765538400547071, 'Total loss': 0.4765538400547071} | train loss {'Reaction outcome loss': 0.14586520388874472, 'Total loss': 0.14586520388874472}
2022-12-05 20:30:18,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:18,671 INFO:     Epoch: 49
2022-12-05 20:30:19,463 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4557764181359248, 'Total loss': 0.4557764181359248} | train loss {'Reaction outcome loss': 0.14377675539224732, 'Total loss': 0.14377675539224732}
2022-12-05 20:30:19,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:19,464 INFO:     Epoch: 50
2022-12-05 20:30:20,256 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4599814780733802, 'Total loss': 0.4599814780733802} | train loss {'Reaction outcome loss': 0.141459618379571, 'Total loss': 0.141459618379571}
2022-12-05 20:30:20,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:20,256 INFO:     Epoch: 51
2022-12-05 20:30:21,056 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4623749354346232, 'Total loss': 0.4623749354346232} | train loss {'Reaction outcome loss': 0.14175136184357867, 'Total loss': 0.14175136184357867}
2022-12-05 20:30:21,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:21,056 INFO:     Epoch: 52
2022-12-05 20:30:21,861 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4486634998836301, 'Total loss': 0.4486634998836301} | train loss {'Reaction outcome loss': 0.137823862316353, 'Total loss': 0.137823862316353}
2022-12-05 20:30:21,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:21,861 INFO:     Epoch: 53
2022-12-05 20:30:22,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4541328988376666, 'Total loss': 0.4541328988376666} | train loss {'Reaction outcome loss': 0.1373405138676872, 'Total loss': 0.1373405138676872}
2022-12-05 20:30:22,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:22,659 INFO:     Epoch: 54
2022-12-05 20:30:23,457 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.460784797641364, 'Total loss': 0.460784797641364} | train loss {'Reaction outcome loss': 0.13686281993833124, 'Total loss': 0.13686281993833124}
2022-12-05 20:30:23,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:23,457 INFO:     Epoch: 55
2022-12-05 20:30:24,254 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4689225859262727, 'Total loss': 0.4689225859262727} | train loss {'Reaction outcome loss': 0.1346267764779682, 'Total loss': 0.1346267764779682}
2022-12-05 20:30:24,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:24,254 INFO:     Epoch: 56
2022-12-05 20:30:25,053 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4334485969421538, 'Total loss': 0.4334485969421538} | train loss {'Reaction outcome loss': 0.13586518402610506, 'Total loss': 0.13586518402610506}
2022-12-05 20:30:25,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:25,054 INFO:     Epoch: 57
2022-12-05 20:30:25,850 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45796058022163133, 'Total loss': 0.45796058022163133} | train loss {'Reaction outcome loss': 0.13419335473861013, 'Total loss': 0.13419335473861013}
2022-12-05 20:30:25,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:25,850 INFO:     Epoch: 58
2022-12-05 20:30:26,643 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47351145337928424, 'Total loss': 0.47351145337928424} | train loss {'Reaction outcome loss': 0.13366522197516598, 'Total loss': 0.13366522197516598}
2022-12-05 20:30:26,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:26,643 INFO:     Epoch: 59
2022-12-05 20:30:27,429 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46620612049644644, 'Total loss': 0.46620612049644644} | train loss {'Reaction outcome loss': 0.13439626777164487, 'Total loss': 0.13439626777164487}
2022-12-05 20:30:27,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:27,430 INFO:     Epoch: 60
2022-12-05 20:30:28,221 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44817866960709746, 'Total loss': 0.44817866960709746} | train loss {'Reaction outcome loss': 0.1322202437690326, 'Total loss': 0.1322202437690326}
2022-12-05 20:30:28,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:28,221 INFO:     Epoch: 61
2022-12-05 20:30:29,013 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44051784344694833, 'Total loss': 0.44051784344694833} | train loss {'Reaction outcome loss': 0.13400163377578161, 'Total loss': 0.13400163377578161}
2022-12-05 20:30:29,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:29,014 INFO:     Epoch: 62
2022-12-05 20:30:29,804 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4639159082011743, 'Total loss': 0.4639159082011743} | train loss {'Reaction outcome loss': 0.13139177649757083, 'Total loss': 0.13139177649757083}
2022-12-05 20:30:29,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:29,804 INFO:     Epoch: 63
2022-12-05 20:30:30,594 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45633572204546496, 'Total loss': 0.45633572204546496} | train loss {'Reaction outcome loss': 0.13196844614053868, 'Total loss': 0.13196844614053868}
2022-12-05 20:30:30,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:30,595 INFO:     Epoch: 64
2022-12-05 20:30:31,393 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.463984533467076, 'Total loss': 0.463984533467076} | train loss {'Reaction outcome loss': 0.13159094063223017, 'Total loss': 0.13159094063223017}
2022-12-05 20:30:31,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:31,393 INFO:     Epoch: 65
2022-12-05 20:30:32,174 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47688906165686523, 'Total loss': 0.47688906165686523} | train loss {'Reaction outcome loss': 0.12934563568964297, 'Total loss': 0.12934563568964297}
2022-12-05 20:30:32,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:32,175 INFO:     Epoch: 66
2022-12-05 20:30:32,957 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46591027840887284, 'Total loss': 0.46591027840887284} | train loss {'Reaction outcome loss': 0.1304454121168475, 'Total loss': 0.1304454121168475}
2022-12-05 20:30:32,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:32,957 INFO:     Epoch: 67
2022-12-05 20:30:33,740 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4743935689330101, 'Total loss': 0.4743935689330101} | train loss {'Reaction outcome loss': 0.13002752768141881, 'Total loss': 0.13002752768141881}
2022-12-05 20:30:33,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:33,740 INFO:     Epoch: 68
2022-12-05 20:30:34,521 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47535834630781953, 'Total loss': 0.47535834630781953} | train loss {'Reaction outcome loss': 0.12848579190215287, 'Total loss': 0.12848579190215287}
2022-12-05 20:30:34,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:34,521 INFO:     Epoch: 69
2022-12-05 20:30:35,305 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4403886602006175, 'Total loss': 0.4403886602006175} | train loss {'Reaction outcome loss': 0.12982652023890798, 'Total loss': 0.12982652023890798}
2022-12-05 20:30:35,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:35,305 INFO:     Epoch: 70
2022-12-05 20:30:36,089 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45285994694991544, 'Total loss': 0.45285994694991544} | train loss {'Reaction outcome loss': 0.12755472248762237, 'Total loss': 0.12755472248762237}
2022-12-05 20:30:36,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:36,090 INFO:     Epoch: 71
2022-12-05 20:30:36,878 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46894654885611753, 'Total loss': 0.46894654885611753} | train loss {'Reaction outcome loss': 0.12709787159169816, 'Total loss': 0.12709787159169816}
2022-12-05 20:30:36,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:36,878 INFO:     Epoch: 72
2022-12-05 20:30:37,664 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4604217487980019, 'Total loss': 0.4604217487980019} | train loss {'Reaction outcome loss': 0.12880963402020992, 'Total loss': 0.12880963402020992}
2022-12-05 20:30:37,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:37,664 INFO:     Epoch: 73
2022-12-05 20:30:38,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.470995935018767, 'Total loss': 0.470995935018767} | train loss {'Reaction outcome loss': 0.12545895067860885, 'Total loss': 0.12545895067860885}
2022-12-05 20:30:38,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:38,445 INFO:     Epoch: 74
2022-12-05 20:30:39,238 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47621052542870695, 'Total loss': 0.47621052542870695} | train loss {'Reaction outcome loss': 0.12525406104455494, 'Total loss': 0.12525406104455494}
2022-12-05 20:30:39,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:39,240 INFO:     Epoch: 75
2022-12-05 20:30:40,024 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45475222281212074, 'Total loss': 0.45475222281212074} | train loss {'Reaction outcome loss': 0.1272362967534941, 'Total loss': 0.1272362967534941}
2022-12-05 20:30:40,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:40,024 INFO:     Epoch: 76
2022-12-05 20:30:40,806 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4514710764315995, 'Total loss': 0.4514710764315995} | train loss {'Reaction outcome loss': 0.127167563208816, 'Total loss': 0.127167563208816}
2022-12-05 20:30:40,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:40,806 INFO:     Epoch: 77
2022-12-05 20:30:41,587 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45741584936199203, 'Total loss': 0.45741584936199203} | train loss {'Reaction outcome loss': 0.12301261260041169, 'Total loss': 0.12301261260041169}
2022-12-05 20:30:41,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:41,587 INFO:     Epoch: 78
2022-12-05 20:30:42,369 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4612909491089257, 'Total loss': 0.4612909491089257} | train loss {'Reaction outcome loss': 0.12361530400432494, 'Total loss': 0.12361530400432494}
2022-12-05 20:30:42,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:42,369 INFO:     Epoch: 79
2022-12-05 20:30:43,149 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46173984388058836, 'Total loss': 0.46173984388058836} | train loss {'Reaction outcome loss': 0.12380739920677579, 'Total loss': 0.12380739920677579}
2022-12-05 20:30:43,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:43,150 INFO:     Epoch: 80
2022-12-05 20:30:43,928 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4567562212998217, 'Total loss': 0.4567562212998217} | train loss {'Reaction outcome loss': 0.12303881166236741, 'Total loss': 0.12303881166236741}
2022-12-05 20:30:43,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:43,929 INFO:     Epoch: 81
2022-12-05 20:30:44,712 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47476555390114134, 'Total loss': 0.47476555390114134} | train loss {'Reaction outcome loss': 0.12301360256969929, 'Total loss': 0.12301360256969929}
2022-12-05 20:30:44,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:44,712 INFO:     Epoch: 82
2022-12-05 20:30:45,493 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4593184884235432, 'Total loss': 0.4593184884235432} | train loss {'Reaction outcome loss': 0.12137853183726571, 'Total loss': 0.12137853183726571}
2022-12-05 20:30:45,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:45,494 INFO:     Epoch: 83
2022-12-05 20:30:46,274 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47138710658658634, 'Total loss': 0.47138710658658634} | train loss {'Reaction outcome loss': 0.12174897495733232, 'Total loss': 0.12174897495733232}
2022-12-05 20:30:46,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:46,274 INFO:     Epoch: 84
2022-12-05 20:30:47,054 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47641726583242416, 'Total loss': 0.47641726583242416} | train loss {'Reaction outcome loss': 0.12013552461047562, 'Total loss': 0.12013552461047562}
2022-12-05 20:30:47,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:47,055 INFO:     Epoch: 85
2022-12-05 20:30:47,837 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44781333952083846, 'Total loss': 0.44781333952083846} | train loss {'Reaction outcome loss': 0.12144475725992601, 'Total loss': 0.12144475725992601}
2022-12-05 20:30:47,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:47,837 INFO:     Epoch: 86
2022-12-05 20:30:48,618 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.458209806897106, 'Total loss': 0.458209806897106} | train loss {'Reaction outcome loss': 0.1223389907949129, 'Total loss': 0.1223389907949129}
2022-12-05 20:30:48,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:48,618 INFO:     Epoch: 87
2022-12-05 20:30:49,400 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46463052928447723, 'Total loss': 0.46463052928447723} | train loss {'Reaction outcome loss': 0.12100610135845384, 'Total loss': 0.12100610135845384}
2022-12-05 20:30:49,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:49,400 INFO:     Epoch: 88
2022-12-05 20:30:50,186 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46925496784123505, 'Total loss': 0.46925496784123505} | train loss {'Reaction outcome loss': 0.12104686265241127, 'Total loss': 0.12104686265241127}
2022-12-05 20:30:50,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:50,186 INFO:     Epoch: 89
2022-12-05 20:30:50,968 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45868776010518725, 'Total loss': 0.45868776010518725} | train loss {'Reaction outcome loss': 0.11741766367791867, 'Total loss': 0.11741766367791867}
2022-12-05 20:30:50,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:50,968 INFO:     Epoch: 90
2022-12-05 20:30:51,749 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44453583149747417, 'Total loss': 0.44453583149747417} | train loss {'Reaction outcome loss': 0.11951672264507839, 'Total loss': 0.11951672264507839}
2022-12-05 20:30:51,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:51,750 INFO:     Epoch: 91
2022-12-05 20:30:52,538 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44999291764741595, 'Total loss': 0.44999291764741595} | train loss {'Reaction outcome loss': 0.11962879550624259, 'Total loss': 0.11962879550624259}
2022-12-05 20:30:52,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:52,539 INFO:     Epoch: 92
2022-12-05 20:30:53,323 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4817383404482495, 'Total loss': 0.4817383404482495} | train loss {'Reaction outcome loss': 0.11809845310920963, 'Total loss': 0.11809845310920963}
2022-12-05 20:30:53,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:53,323 INFO:     Epoch: 93
2022-12-05 20:30:54,106 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4581522128798745, 'Total loss': 0.4581522128798745} | train loss {'Reaction outcome loss': 0.11909181797610861, 'Total loss': 0.11909181797610861}
2022-12-05 20:30:54,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:54,107 INFO:     Epoch: 94
2022-12-05 20:30:54,894 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4621190753188619, 'Total loss': 0.4621190753188619} | train loss {'Reaction outcome loss': 0.11978015245831743, 'Total loss': 0.11978015245831743}
2022-12-05 20:30:54,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:54,894 INFO:     Epoch: 95
2022-12-05 20:30:55,679 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45054789463227446, 'Total loss': 0.45054789463227446} | train loss {'Reaction outcome loss': 0.11967757051924661, 'Total loss': 0.11967757051924661}
2022-12-05 20:30:55,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:55,679 INFO:     Epoch: 96
2022-12-05 20:30:56,461 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4496107003228231, 'Total loss': 0.4496107003228231} | train loss {'Reaction outcome loss': 0.12161734632539506, 'Total loss': 0.12161734632539506}
2022-12-05 20:30:56,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:56,461 INFO:     Epoch: 97
2022-12-05 20:30:57,246 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.488634775985371, 'Total loss': 0.488634775985371} | train loss {'Reaction outcome loss': 0.11476990643660633, 'Total loss': 0.11476990643660633}
2022-12-05 20:30:57,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:57,246 INFO:     Epoch: 98
2022-12-05 20:30:58,031 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46032863533632323, 'Total loss': 0.46032863533632323} | train loss {'Reaction outcome loss': 0.11696879983100356, 'Total loss': 0.11696879983100356}
2022-12-05 20:30:58,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:58,032 INFO:     Epoch: 99
2022-12-05 20:30:58,818 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45759982209314, 'Total loss': 0.45759982209314} | train loss {'Reaction outcome loss': 0.11495987676768278, 'Total loss': 0.11495987676768278}
2022-12-05 20:30:58,818 INFO:     Best model found after epoch 16 of 100.
2022-12-05 20:30:58,818 INFO:   Done with stage: TRAINING
2022-12-05 20:30:58,818 INFO:   Starting stage: EVALUATION
2022-12-05 20:30:58,949 INFO:   Done with stage: EVALUATION
2022-12-05 20:30:58,949 INFO:   Leaving out SEQ value Fold_3
2022-12-05 20:30:58,962 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:30:58,962 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:30:59,611 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:30:59,611 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:30:59,681 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:30:59,682 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:30:59,682 INFO:     No hyperparam tuning for this model
2022-12-05 20:30:59,682 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:30:59,682 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:30:59,682 INFO:     None feature selector for col prot
2022-12-05 20:30:59,683 INFO:     None feature selector for col prot
2022-12-05 20:30:59,683 INFO:     None feature selector for col prot
2022-12-05 20:30:59,683 INFO:     None feature selector for col chem
2022-12-05 20:30:59,683 INFO:     None feature selector for col chem
2022-12-05 20:30:59,683 INFO:     None feature selector for col chem
2022-12-05 20:30:59,683 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:30:59,684 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:30:59,685 INFO:     Number of params in model 215821
2022-12-05 20:30:59,688 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:30:59,688 INFO:   Starting stage: TRAINING
2022-12-05 20:30:59,747 INFO:     Val loss before train {'Reaction outcome loss': 0.9940554069918256, 'Total loss': 0.9940554069918256}
2022-12-05 20:30:59,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:30:59,747 INFO:     Epoch: 0
2022-12-05 20:31:00,525 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6069218460903612, 'Total loss': 0.6069218460903612} | train loss {'Reaction outcome loss': 0.7994922058748417, 'Total loss': 0.7994922058748417}
2022-12-05 20:31:00,525 INFO:     Found new best model at epoch 0
2022-12-05 20:31:00,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:00,526 INFO:     Epoch: 1
2022-12-05 20:31:01,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.512288325054701, 'Total loss': 0.512288325054701} | train loss {'Reaction outcome loss': 0.5447547725844578, 'Total loss': 0.5447547725844578}
2022-12-05 20:31:01,304 INFO:     Found new best model at epoch 1
2022-12-05 20:31:01,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:01,305 INFO:     Epoch: 2
2022-12-05 20:31:02,081 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47779728091040324, 'Total loss': 0.47779728091040324} | train loss {'Reaction outcome loss': 0.47864997106008844, 'Total loss': 0.47864997106008844}
2022-12-05 20:31:02,081 INFO:     Found new best model at epoch 2
2022-12-05 20:31:02,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:02,082 INFO:     Epoch: 3
2022-12-05 20:31:02,867 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.461778252623802, 'Total loss': 0.461778252623802} | train loss {'Reaction outcome loss': 0.43718348046550987, 'Total loss': 0.43718348046550987}
2022-12-05 20:31:02,867 INFO:     Found new best model at epoch 3
2022-12-05 20:31:02,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:02,868 INFO:     Epoch: 4
2022-12-05 20:31:03,652 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44681577315164167, 'Total loss': 0.44681577315164167} | train loss {'Reaction outcome loss': 0.40751927773483465, 'Total loss': 0.40751927773483465}
2022-12-05 20:31:03,652 INFO:     Found new best model at epoch 4
2022-12-05 20:31:03,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:03,653 INFO:     Epoch: 5
2022-12-05 20:31:04,433 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4304613737865936, 'Total loss': 0.4304613737865936} | train loss {'Reaction outcome loss': 0.3828118070960045, 'Total loss': 0.3828118070960045}
2022-12-05 20:31:04,434 INFO:     Found new best model at epoch 5
2022-12-05 20:31:04,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:04,434 INFO:     Epoch: 6
2022-12-05 20:31:05,214 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42024003419765205, 'Total loss': 0.42024003419765205} | train loss {'Reaction outcome loss': 0.3616945047969701, 'Total loss': 0.3616945047969701}
2022-12-05 20:31:05,214 INFO:     Found new best model at epoch 6
2022-12-05 20:31:05,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:05,215 INFO:     Epoch: 7
2022-12-05 20:31:05,996 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41389752647211386, 'Total loss': 0.41389752647211386} | train loss {'Reaction outcome loss': 0.33885765063469525, 'Total loss': 0.33885765063469525}
2022-12-05 20:31:05,997 INFO:     Found new best model at epoch 7
2022-12-05 20:31:05,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:05,997 INFO:     Epoch: 8
2022-12-05 20:31:06,780 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4209850021573, 'Total loss': 0.4209850021573} | train loss {'Reaction outcome loss': 0.3283408716565273, 'Total loss': 0.3283408716565273}
2022-12-05 20:31:06,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:06,781 INFO:     Epoch: 9
2022-12-05 20:31:07,559 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4057107793037282, 'Total loss': 0.4057107793037282} | train loss {'Reaction outcome loss': 0.3145644090397925, 'Total loss': 0.3145644090397925}
2022-12-05 20:31:07,559 INFO:     Found new best model at epoch 9
2022-12-05 20:31:07,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:07,560 INFO:     Epoch: 10
2022-12-05 20:31:08,339 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4090418302735617, 'Total loss': 0.4090418302735617} | train loss {'Reaction outcome loss': 0.2983302901819593, 'Total loss': 0.2983302901819593}
2022-12-05 20:31:08,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:08,339 INFO:     Epoch: 11
2022-12-05 20:31:09,124 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41516063500975453, 'Total loss': 0.41516063500975453} | train loss {'Reaction outcome loss': 0.2901401728330577, 'Total loss': 0.2901401728330577}
2022-12-05 20:31:09,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:09,124 INFO:     Epoch: 12
2022-12-05 20:31:09,911 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4119744844907938, 'Total loss': 0.4119744844907938} | train loss {'Reaction outcome loss': 0.2765327004990617, 'Total loss': 0.2765327004990617}
2022-12-05 20:31:09,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:09,912 INFO:     Epoch: 13
2022-12-05 20:31:10,697 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4019417849391006, 'Total loss': 0.4019417849391006} | train loss {'Reaction outcome loss': 0.2690118328805585, 'Total loss': 0.2690118328805585}
2022-12-05 20:31:10,698 INFO:     Found new best model at epoch 13
2022-12-05 20:31:10,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:10,698 INFO:     Epoch: 14
2022-12-05 20:31:11,479 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4034153108679971, 'Total loss': 0.4034153108679971} | train loss {'Reaction outcome loss': 0.26011772886620926, 'Total loss': 0.26011772886620926}
2022-12-05 20:31:11,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:11,479 INFO:     Epoch: 15
2022-12-05 20:31:12,263 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40730633292087287, 'Total loss': 0.40730633292087287} | train loss {'Reaction outcome loss': 0.2519264704257738, 'Total loss': 0.2519264704257738}
2022-12-05 20:31:12,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:12,264 INFO:     Epoch: 16
2022-12-05 20:31:13,046 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4064423947833305, 'Total loss': 0.4064423947833305} | train loss {'Reaction outcome loss': 0.24583245432157008, 'Total loss': 0.24583245432157008}
2022-12-05 20:31:13,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:13,046 INFO:     Epoch: 17
2022-12-05 20:31:13,828 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41881716736527375, 'Total loss': 0.41881716736527375} | train loss {'Reaction outcome loss': 0.2354705757843178, 'Total loss': 0.2354705757843178}
2022-12-05 20:31:13,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:13,828 INFO:     Epoch: 18
2022-12-05 20:31:14,608 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43216049480576846, 'Total loss': 0.43216049480576846} | train loss {'Reaction outcome loss': 0.23155714557735158, 'Total loss': 0.23155714557735158}
2022-12-05 20:31:14,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:14,608 INFO:     Epoch: 19
2022-12-05 20:31:15,398 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42590535518734957, 'Total loss': 0.42590535518734957} | train loss {'Reaction outcome loss': 0.2261219288940068, 'Total loss': 0.2261219288940068}
2022-12-05 20:31:15,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:15,398 INFO:     Epoch: 20
2022-12-05 20:31:16,181 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4170376807451248, 'Total loss': 0.4170376807451248} | train loss {'Reaction outcome loss': 0.2204649147165359, 'Total loss': 0.2204649147165359}
2022-12-05 20:31:16,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:16,182 INFO:     Epoch: 21
2022-12-05 20:31:16,961 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4259717471377794, 'Total loss': 0.4259717471377794} | train loss {'Reaction outcome loss': 0.2128777746721858, 'Total loss': 0.2128777746721858}
2022-12-05 20:31:16,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:16,962 INFO:     Epoch: 22
2022-12-05 20:31:17,742 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4089790461368339, 'Total loss': 0.4089790461368339} | train loss {'Reaction outcome loss': 0.2103405079697488, 'Total loss': 0.2103405079697488}
2022-12-05 20:31:17,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:17,742 INFO:     Epoch: 23
2022-12-05 20:31:18,525 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4366216999153758, 'Total loss': 0.4366216999153758} | train loss {'Reaction outcome loss': 0.2062819268340703, 'Total loss': 0.2062819268340703}
2022-12-05 20:31:18,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:18,526 INFO:     Epoch: 24
2022-12-05 20:31:19,308 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42101459101189015, 'Total loss': 0.42101459101189015} | train loss {'Reaction outcome loss': 0.20310146560068013, 'Total loss': 0.20310146560068013}
2022-12-05 20:31:19,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:19,308 INFO:     Epoch: 25
2022-12-05 20:31:20,084 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43133864950302037, 'Total loss': 0.43133864950302037} | train loss {'Reaction outcome loss': 0.20003947622493887, 'Total loss': 0.20003947622493887}
2022-12-05 20:31:20,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:20,084 INFO:     Epoch: 26
2022-12-05 20:31:20,863 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4302785791629969, 'Total loss': 0.4302785791629969} | train loss {'Reaction outcome loss': 0.1922753030647997, 'Total loss': 0.1922753030647997}
2022-12-05 20:31:20,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:20,863 INFO:     Epoch: 27
2022-12-05 20:31:21,648 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44345824697683023, 'Total loss': 0.44345824697683023} | train loss {'Reaction outcome loss': 0.19407409681465293, 'Total loss': 0.19407409681465293}
2022-12-05 20:31:21,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:21,649 INFO:     Epoch: 28
2022-12-05 20:31:22,428 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43788634413896604, 'Total loss': 0.43788634413896604} | train loss {'Reaction outcome loss': 0.1914858235061535, 'Total loss': 0.1914858235061535}
2022-12-05 20:31:22,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:22,428 INFO:     Epoch: 29
2022-12-05 20:31:23,203 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43255103951276735, 'Total loss': 0.43255103951276735} | train loss {'Reaction outcome loss': 0.18486114098217155, 'Total loss': 0.18486114098217155}
2022-12-05 20:31:23,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:23,203 INFO:     Epoch: 30
2022-12-05 20:31:23,982 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4214232092679933, 'Total loss': 0.4214232092679933} | train loss {'Reaction outcome loss': 0.1833312361287411, 'Total loss': 0.1833312361287411}
2022-12-05 20:31:23,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:23,982 INFO:     Epoch: 31
2022-12-05 20:31:24,759 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4389963344086048, 'Total loss': 0.4389963344086048} | train loss {'Reaction outcome loss': 0.18128053416482737, 'Total loss': 0.18128053416482737}
2022-12-05 20:31:24,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:24,759 INFO:     Epoch: 32
2022-12-05 20:31:25,536 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44084175138972526, 'Total loss': 0.44084175138972526} | train loss {'Reaction outcome loss': 0.17960985741562774, 'Total loss': 0.17960985741562774}
2022-12-05 20:31:25,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:25,536 INFO:     Epoch: 33
2022-12-05 20:31:26,312 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44824127402416497, 'Total loss': 0.44824127402416497} | train loss {'Reaction outcome loss': 0.17535110795870423, 'Total loss': 0.17535110795870423}
2022-12-05 20:31:26,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:26,312 INFO:     Epoch: 34
2022-12-05 20:31:27,087 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4385243876035823, 'Total loss': 0.4385243876035823} | train loss {'Reaction outcome loss': 0.17598454312222903, 'Total loss': 0.17598454312222903}
2022-12-05 20:31:27,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:27,087 INFO:     Epoch: 35
2022-12-05 20:31:27,863 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43986058096553005, 'Total loss': 0.43986058096553005} | train loss {'Reaction outcome loss': 0.17461215471848845, 'Total loss': 0.17461215471848845}
2022-12-05 20:31:27,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:27,864 INFO:     Epoch: 36
2022-12-05 20:31:28,640 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4293404256188592, 'Total loss': 0.4293404256188592} | train loss {'Reaction outcome loss': 0.1722830706886703, 'Total loss': 0.1722830706886703}
2022-12-05 20:31:28,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:28,640 INFO:     Epoch: 37
2022-12-05 20:31:29,417 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43862872934618663, 'Total loss': 0.43862872934618663} | train loss {'Reaction outcome loss': 0.16925916806260338, 'Total loss': 0.16925916806260338}
2022-12-05 20:31:29,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:29,417 INFO:     Epoch: 38
2022-12-05 20:31:30,196 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44536543100379233, 'Total loss': 0.44536543100379233} | train loss {'Reaction outcome loss': 0.17131408636045994, 'Total loss': 0.17131408636045994}
2022-12-05 20:31:30,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:30,196 INFO:     Epoch: 39
2022-12-05 20:31:30,981 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4407563400129939, 'Total loss': 0.4407563400129939} | train loss {'Reaction outcome loss': 0.16508553543540297, 'Total loss': 0.16508553543540297}
2022-12-05 20:31:30,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:30,981 INFO:     Epoch: 40
2022-12-05 20:31:31,762 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43465634695319244, 'Total loss': 0.43465634695319244} | train loss {'Reaction outcome loss': 0.16471980448781712, 'Total loss': 0.16471980448781712}
2022-12-05 20:31:31,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:31,762 INFO:     Epoch: 41
2022-12-05 20:31:32,536 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4513998130379721, 'Total loss': 0.4513998130379721} | train loss {'Reaction outcome loss': 0.16190824922571173, 'Total loss': 0.16190824922571173}
2022-12-05 20:31:32,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:32,537 INFO:     Epoch: 42
2022-12-05 20:31:33,315 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4370403899702915, 'Total loss': 0.4370403899702915} | train loss {'Reaction outcome loss': 0.16111958211623742, 'Total loss': 0.16111958211623742}
2022-12-05 20:31:33,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:33,315 INFO:     Epoch: 43
2022-12-05 20:31:34,090 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4447063498718794, 'Total loss': 0.4447063498718794} | train loss {'Reaction outcome loss': 0.15918448447539915, 'Total loss': 0.15918448447539915}
2022-12-05 20:31:34,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:34,091 INFO:     Epoch: 44
2022-12-05 20:31:34,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4628062865068746, 'Total loss': 0.4628062865068746} | train loss {'Reaction outcome loss': 0.15839078084596234, 'Total loss': 0.15839078084596234}
2022-12-05 20:31:34,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:34,869 INFO:     Epoch: 45
2022-12-05 20:31:35,649 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45010207073633063, 'Total loss': 0.45010207073633063} | train loss {'Reaction outcome loss': 0.15715139704283143, 'Total loss': 0.15715139704283143}
2022-12-05 20:31:35,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:35,649 INFO:     Epoch: 46
2022-12-05 20:31:36,425 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4283521445684655, 'Total loss': 0.4283521445684655} | train loss {'Reaction outcome loss': 0.1537848276651052, 'Total loss': 0.1537848276651052}
2022-12-05 20:31:36,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:36,425 INFO:     Epoch: 47
2022-12-05 20:31:37,205 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4539804777433706, 'Total loss': 0.4539804777433706} | train loss {'Reaction outcome loss': 0.15299362761396, 'Total loss': 0.15299362761396}
2022-12-05 20:31:37,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:37,205 INFO:     Epoch: 48
2022-12-05 20:31:37,981 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44381965696811676, 'Total loss': 0.44381965696811676} | train loss {'Reaction outcome loss': 0.15058068712012934, 'Total loss': 0.15058068712012934}
2022-12-05 20:31:37,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:37,981 INFO:     Epoch: 49
2022-12-05 20:31:38,755 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4499801958716193, 'Total loss': 0.4499801958716193} | train loss {'Reaction outcome loss': 0.15298946604102118, 'Total loss': 0.15298946604102118}
2022-12-05 20:31:38,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:38,755 INFO:     Epoch: 50
2022-12-05 20:31:39,533 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4513363931761232, 'Total loss': 0.4513363931761232} | train loss {'Reaction outcome loss': 0.15200717422775314, 'Total loss': 0.15200717422775314}
2022-12-05 20:31:39,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:39,533 INFO:     Epoch: 51
2022-12-05 20:31:40,312 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45851924911487935, 'Total loss': 0.45851924911487935} | train loss {'Reaction outcome loss': 0.15160496315353963, 'Total loss': 0.15160496315353963}
2022-12-05 20:31:40,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:40,313 INFO:     Epoch: 52
2022-12-05 20:31:41,088 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44774496624636095, 'Total loss': 0.44774496624636095} | train loss {'Reaction outcome loss': 0.14833082406033501, 'Total loss': 0.14833082406033501}
2022-12-05 20:31:41,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:41,088 INFO:     Epoch: 53
2022-12-05 20:31:41,863 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4472182559412579, 'Total loss': 0.4472182559412579} | train loss {'Reaction outcome loss': 0.14775387077119018, 'Total loss': 0.14775387077119018}
2022-12-05 20:31:41,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:41,864 INFO:     Epoch: 54
2022-12-05 20:31:42,644 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4601757467486138, 'Total loss': 0.4601757467486138} | train loss {'Reaction outcome loss': 0.14639655463244827, 'Total loss': 0.14639655463244827}
2022-12-05 20:31:42,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:42,644 INFO:     Epoch: 55
2022-12-05 20:31:43,421 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4989992255388304, 'Total loss': 0.4989992255388304} | train loss {'Reaction outcome loss': 0.14217094465571103, 'Total loss': 0.14217094465571103}
2022-12-05 20:31:43,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:43,421 INFO:     Epoch: 56
2022-12-05 20:31:44,200 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4545828263426936, 'Total loss': 0.4545828263426936} | train loss {'Reaction outcome loss': 0.14374480904538, 'Total loss': 0.14374480904538}
2022-12-05 20:31:44,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:44,201 INFO:     Epoch: 57
2022-12-05 20:31:44,980 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45713275982890017, 'Total loss': 0.45713275982890017} | train loss {'Reaction outcome loss': 0.14191370644438706, 'Total loss': 0.14191370644438706}
2022-12-05 20:31:44,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:44,980 INFO:     Epoch: 58
2022-12-05 20:31:45,762 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46079454276450843, 'Total loss': 0.46079454276450843} | train loss {'Reaction outcome loss': 0.1405875239154843, 'Total loss': 0.1405875239154843}
2022-12-05 20:31:45,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:45,762 INFO:     Epoch: 59
2022-12-05 20:31:46,541 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44981995952683823, 'Total loss': 0.44981995952683823} | train loss {'Reaction outcome loss': 0.14170124100093714, 'Total loss': 0.14170124100093714}
2022-12-05 20:31:46,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:46,542 INFO:     Epoch: 60
2022-12-05 20:31:47,320 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4543203611013501, 'Total loss': 0.4543203611013501} | train loss {'Reaction outcome loss': 0.1406037779753936, 'Total loss': 0.1406037779753936}
2022-12-05 20:31:47,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:47,320 INFO:     Epoch: 61
2022-12-05 20:31:48,096 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4567455410264259, 'Total loss': 0.4567455410264259} | train loss {'Reaction outcome loss': 0.14091613462774968, 'Total loss': 0.14091613462774968}
2022-12-05 20:31:48,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:48,097 INFO:     Epoch: 62
2022-12-05 20:31:48,874 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4444181465132292, 'Total loss': 0.4444181465132292} | train loss {'Reaction outcome loss': 0.13915975563625088, 'Total loss': 0.13915975563625088}
2022-12-05 20:31:48,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:48,874 INFO:     Epoch: 63
2022-12-05 20:31:49,653 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4559975425864375, 'Total loss': 0.4559975425864375} | train loss {'Reaction outcome loss': 0.13837566432833184, 'Total loss': 0.13837566432833184}
2022-12-05 20:31:49,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:49,653 INFO:     Epoch: 64
2022-12-05 20:31:50,433 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4684603758329569, 'Total loss': 0.4684603758329569} | train loss {'Reaction outcome loss': 0.13882241422524216, 'Total loss': 0.13882241422524216}
2022-12-05 20:31:50,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:50,433 INFO:     Epoch: 65
2022-12-05 20:31:51,213 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4623716159961944, 'Total loss': 0.4623716159961944} | train loss {'Reaction outcome loss': 0.13830310313153218, 'Total loss': 0.13830310313153218}
2022-12-05 20:31:51,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:51,213 INFO:     Epoch: 66
2022-12-05 20:31:51,989 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44776183747968007, 'Total loss': 0.44776183747968007} | train loss {'Reaction outcome loss': 0.13695099753648288, 'Total loss': 0.13695099753648288}
2022-12-05 20:31:51,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:51,989 INFO:     Epoch: 67
2022-12-05 20:31:52,772 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4558247116416, 'Total loss': 0.4558247116416} | train loss {'Reaction outcome loss': 0.13674127405746, 'Total loss': 0.13674127405746}
2022-12-05 20:31:52,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:52,772 INFO:     Epoch: 68
2022-12-05 20:31:53,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44800028620764265, 'Total loss': 0.44800028620764265} | train loss {'Reaction outcome loss': 0.13708523669867914, 'Total loss': 0.13708523669867914}
2022-12-05 20:31:53,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:53,558 INFO:     Epoch: 69
2022-12-05 20:31:54,340 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44286868894516035, 'Total loss': 0.44286868894516035} | train loss {'Reaction outcome loss': 0.13479374949896678, 'Total loss': 0.13479374949896678}
2022-12-05 20:31:54,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:54,340 INFO:     Epoch: 70
2022-12-05 20:31:55,121 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44750213415123696, 'Total loss': 0.44750213415123696} | train loss {'Reaction outcome loss': 0.13348169696563092, 'Total loss': 0.13348169696563092}
2022-12-05 20:31:55,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:55,121 INFO:     Epoch: 71
2022-12-05 20:31:55,896 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4571510584548462, 'Total loss': 0.4571510584548462} | train loss {'Reaction outcome loss': 0.13370937050595025, 'Total loss': 0.13370937050595025}
2022-12-05 20:31:55,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:55,896 INFO:     Epoch: 72
2022-12-05 20:31:56,673 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46242991471013356, 'Total loss': 0.46242991471013356} | train loss {'Reaction outcome loss': 0.13145505376236483, 'Total loss': 0.13145505376236483}
2022-12-05 20:31:56,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:56,673 INFO:     Epoch: 73
2022-12-05 20:31:57,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4492785622214162, 'Total loss': 0.4492785622214162} | train loss {'Reaction outcome loss': 0.1308410911225393, 'Total loss': 0.1308410911225393}
2022-12-05 20:31:57,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:57,457 INFO:     Epoch: 74
2022-12-05 20:31:58,237 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4569252564810043, 'Total loss': 0.4569252564810043} | train loss {'Reaction outcome loss': 0.13022677758021556, 'Total loss': 0.13022677758021556}
2022-12-05 20:31:58,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:58,237 INFO:     Epoch: 75
2022-12-05 20:31:59,015 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4506212050138518, 'Total loss': 0.4506212050138518} | train loss {'Reaction outcome loss': 0.13125288147540365, 'Total loss': 0.13125288147540365}
2022-12-05 20:31:59,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:59,015 INFO:     Epoch: 76
2022-12-05 20:31:59,796 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44300978856031287, 'Total loss': 0.44300978856031287} | train loss {'Reaction outcome loss': 0.13440712710811956, 'Total loss': 0.13440712710811956}
2022-12-05 20:31:59,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:31:59,797 INFO:     Epoch: 77
2022-12-05 20:32:00,573 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47017907264620756, 'Total loss': 0.47017907264620756} | train loss {'Reaction outcome loss': 0.13216365944235356, 'Total loss': 0.13216365944235356}
2022-12-05 20:32:00,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:00,574 INFO:     Epoch: 78
2022-12-05 20:32:01,349 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46133010020089704, 'Total loss': 0.46133010020089704} | train loss {'Reaction outcome loss': 0.1296637421397523, 'Total loss': 0.1296637421397523}
2022-12-05 20:32:01,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:01,349 INFO:     Epoch: 79
2022-12-05 20:32:02,131 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4646229043949482, 'Total loss': 0.4646229043949482} | train loss {'Reaction outcome loss': 0.12896949603207042, 'Total loss': 0.12896949603207042}
2022-12-05 20:32:02,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:02,132 INFO:     Epoch: 80
2022-12-05 20:32:02,916 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4640712939029516, 'Total loss': 0.4640712939029516} | train loss {'Reaction outcome loss': 0.12814470869489014, 'Total loss': 0.12814470869489014}
2022-12-05 20:32:02,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:02,916 INFO:     Epoch: 81
2022-12-05 20:32:03,705 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4500993091699689, 'Total loss': 0.4500993091699689} | train loss {'Reaction outcome loss': 0.12891433735332283, 'Total loss': 0.12891433735332283}
2022-12-05 20:32:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:03,706 INFO:     Epoch: 82
2022-12-05 20:32:04,496 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.462297331455142, 'Total loss': 0.462297331455142} | train loss {'Reaction outcome loss': 0.13012068963716508, 'Total loss': 0.13012068963716508}
2022-12-05 20:32:04,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:04,496 INFO:     Epoch: 83
2022-12-05 20:32:05,280 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4631410208205844, 'Total loss': 0.4631410208205844} | train loss {'Reaction outcome loss': 0.1297692931524371, 'Total loss': 0.1297692931524371}
2022-12-05 20:32:05,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:05,281 INFO:     Epoch: 84
2022-12-05 20:32:06,065 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46568686445785124, 'Total loss': 0.46568686445785124} | train loss {'Reaction outcome loss': 0.12705624902422433, 'Total loss': 0.12705624902422433}
2022-12-05 20:32:06,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:06,065 INFO:     Epoch: 85
2022-12-05 20:32:06,851 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46330616224643795, 'Total loss': 0.46330616224643795} | train loss {'Reaction outcome loss': 0.12768840215733793, 'Total loss': 0.12768840215733793}
2022-12-05 20:32:06,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:06,852 INFO:     Epoch: 86
2022-12-05 20:32:07,639 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45840771669565245, 'Total loss': 0.45840771669565245} | train loss {'Reaction outcome loss': 0.13081452074903446, 'Total loss': 0.13081452074903446}
2022-12-05 20:32:07,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:07,639 INFO:     Epoch: 87
2022-12-05 20:32:08,435 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45726406002460523, 'Total loss': 0.45726406002460523} | train loss {'Reaction outcome loss': 0.12846210945901446, 'Total loss': 0.12846210945901446}
2022-12-05 20:32:08,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:08,435 INFO:     Epoch: 88
2022-12-05 20:32:09,229 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48817672337903534, 'Total loss': 0.48817672337903534} | train loss {'Reaction outcome loss': 0.12629155567694517, 'Total loss': 0.12629155567694517}
2022-12-05 20:32:09,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:09,229 INFO:     Epoch: 89
2022-12-05 20:32:10,023 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4564567703840344, 'Total loss': 0.4564567703840344} | train loss {'Reaction outcome loss': 0.12687730551773652, 'Total loss': 0.12687730551773652}
2022-12-05 20:32:10,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:10,023 INFO:     Epoch: 90
2022-12-05 20:32:10,810 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46455517099347227, 'Total loss': 0.46455517099347227} | train loss {'Reaction outcome loss': 0.12695456990880555, 'Total loss': 0.12695456990880555}
2022-12-05 20:32:10,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:10,811 INFO:     Epoch: 91
2022-12-05 20:32:11,596 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45809690342393034, 'Total loss': 0.45809690342393034} | train loss {'Reaction outcome loss': 0.12611399658146452, 'Total loss': 0.12611399658146452}
2022-12-05 20:32:11,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:11,596 INFO:     Epoch: 92
2022-12-05 20:32:12,383 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4493625032347302, 'Total loss': 0.4493625032347302} | train loss {'Reaction outcome loss': 0.12503173924051225, 'Total loss': 0.12503173924051225}
2022-12-05 20:32:12,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:12,383 INFO:     Epoch: 93
2022-12-05 20:32:13,174 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.462174769057784, 'Total loss': 0.462174769057784} | train loss {'Reaction outcome loss': 0.12701893679522833, 'Total loss': 0.12701893679522833}
2022-12-05 20:32:13,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:13,175 INFO:     Epoch: 94
2022-12-05 20:32:13,963 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.483384926998338, 'Total loss': 0.483384926998338} | train loss {'Reaction outcome loss': 0.12639783241892935, 'Total loss': 0.12639783241892935}
2022-12-05 20:32:13,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:13,964 INFO:     Epoch: 95
2022-12-05 20:32:14,747 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4640768196347148, 'Total loss': 0.4640768196347148} | train loss {'Reaction outcome loss': 0.12578473079445787, 'Total loss': 0.12578473079445787}
2022-12-05 20:32:14,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:14,748 INFO:     Epoch: 96
2022-12-05 20:32:15,533 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4580044288967931, 'Total loss': 0.4580044288967931} | train loss {'Reaction outcome loss': 0.12198032999457029, 'Total loss': 0.12198032999457029}
2022-12-05 20:32:15,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:15,533 INFO:     Epoch: 97
2022-12-05 20:32:16,316 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4644895351903383, 'Total loss': 0.4644895351903383} | train loss {'Reaction outcome loss': 0.12251233103776686, 'Total loss': 0.12251233103776686}
2022-12-05 20:32:16,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:16,317 INFO:     Epoch: 98
2022-12-05 20:32:17,100 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4536291021247243, 'Total loss': 0.4536291021247243} | train loss {'Reaction outcome loss': 0.12246263506211584, 'Total loss': 0.12246263506211584}
2022-12-05 20:32:17,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:17,100 INFO:     Epoch: 99
2022-12-05 20:32:17,886 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4632090972519891, 'Total loss': 0.4632090972519891} | train loss {'Reaction outcome loss': 0.1252116220468869, 'Total loss': 0.1252116220468869}
2022-12-05 20:32:17,887 INFO:     Best model found after epoch 14 of 100.
2022-12-05 20:32:17,887 INFO:   Done with stage: TRAINING
2022-12-05 20:32:17,887 INFO:   Starting stage: EVALUATION
2022-12-05 20:32:18,024 INFO:   Done with stage: EVALUATION
2022-12-05 20:32:18,024 INFO:   Leaving out SEQ value Fold_4
2022-12-05 20:32:18,036 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:32:18,036 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:32:18,686 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:32:18,686 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:32:18,756 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:32:18,756 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:32:18,756 INFO:     No hyperparam tuning for this model
2022-12-05 20:32:18,756 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:32:18,757 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:32:18,757 INFO:     None feature selector for col prot
2022-12-05 20:32:18,757 INFO:     None feature selector for col prot
2022-12-05 20:32:18,757 INFO:     None feature selector for col prot
2022-12-05 20:32:18,758 INFO:     None feature selector for col chem
2022-12-05 20:32:18,758 INFO:     None feature selector for col chem
2022-12-05 20:32:18,758 INFO:     None feature selector for col chem
2022-12-05 20:32:18,758 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:32:18,758 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:32:18,760 INFO:     Number of params in model 215821
2022-12-05 20:32:18,763 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:32:18,763 INFO:   Starting stage: TRAINING
2022-12-05 20:32:18,824 INFO:     Val loss before train {'Reaction outcome loss': 1.0115967094898224, 'Total loss': 1.0115967094898224}
2022-12-05 20:32:18,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:18,824 INFO:     Epoch: 0
2022-12-05 20:32:19,622 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6042144508524374, 'Total loss': 0.6042144508524374} | train loss {'Reaction outcome loss': 0.7840188127611915, 'Total loss': 0.7840188127611915}
2022-12-05 20:32:19,623 INFO:     Found new best model at epoch 0
2022-12-05 20:32:19,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:19,624 INFO:     Epoch: 1
2022-12-05 20:32:20,422 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5392266708341512, 'Total loss': 0.5392266708341512} | train loss {'Reaction outcome loss': 0.5360512112778041, 'Total loss': 0.5360512112778041}
2022-12-05 20:32:20,422 INFO:     Found new best model at epoch 1
2022-12-05 20:32:20,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:20,423 INFO:     Epoch: 2
2022-12-05 20:32:21,223 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4936005300418897, 'Total loss': 0.4936005300418897} | train loss {'Reaction outcome loss': 0.46518524279517515, 'Total loss': 0.46518524279517515}
2022-12-05 20:32:21,223 INFO:     Found new best model at epoch 2
2022-12-05 20:32:21,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:21,224 INFO:     Epoch: 3
2022-12-05 20:32:22,021 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47142213786190207, 'Total loss': 0.47142213786190207} | train loss {'Reaction outcome loss': 0.42674960165975556, 'Total loss': 0.42674960165975556}
2022-12-05 20:32:22,021 INFO:     Found new best model at epoch 3
2022-12-05 20:32:22,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:22,022 INFO:     Epoch: 4
2022-12-05 20:32:22,823 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45188766345381737, 'Total loss': 0.45188766345381737} | train loss {'Reaction outcome loss': 0.3950976072660377, 'Total loss': 0.3950976072660377}
2022-12-05 20:32:22,823 INFO:     Found new best model at epoch 4
2022-12-05 20:32:22,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:22,824 INFO:     Epoch: 5
2022-12-05 20:32:23,621 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4487838836556131, 'Total loss': 0.4487838836556131} | train loss {'Reaction outcome loss': 0.3696873861575319, 'Total loss': 0.3696873861575319}
2022-12-05 20:32:23,621 INFO:     Found new best model at epoch 5
2022-12-05 20:32:23,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:23,622 INFO:     Epoch: 6
2022-12-05 20:32:24,422 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44817503236911516, 'Total loss': 0.44817503236911516} | train loss {'Reaction outcome loss': 0.35181868421815093, 'Total loss': 0.35181868421815093}
2022-12-05 20:32:24,422 INFO:     Found new best model at epoch 6
2022-12-05 20:32:24,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:24,423 INFO:     Epoch: 7
2022-12-05 20:32:25,226 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44012920727783983, 'Total loss': 0.44012920727783983} | train loss {'Reaction outcome loss': 0.3354309677116333, 'Total loss': 0.3354309677116333}
2022-12-05 20:32:25,226 INFO:     Found new best model at epoch 7
2022-12-05 20:32:25,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:25,227 INFO:     Epoch: 8
2022-12-05 20:32:26,034 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43372996659441426, 'Total loss': 0.43372996659441426} | train loss {'Reaction outcome loss': 0.31881450254830623, 'Total loss': 0.31881450254830623}
2022-12-05 20:32:26,034 INFO:     Found new best model at epoch 8
2022-12-05 20:32:26,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:26,035 INFO:     Epoch: 9
2022-12-05 20:32:26,839 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42611719701777806, 'Total loss': 0.42611719701777806} | train loss {'Reaction outcome loss': 0.30222611997516885, 'Total loss': 0.30222611997516885}
2022-12-05 20:32:26,839 INFO:     Found new best model at epoch 9
2022-12-05 20:32:26,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:26,840 INFO:     Epoch: 10
2022-12-05 20:32:27,641 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41481792147863994, 'Total loss': 0.41481792147863994} | train loss {'Reaction outcome loss': 0.292802128730522, 'Total loss': 0.292802128730522}
2022-12-05 20:32:27,641 INFO:     Found new best model at epoch 10
2022-12-05 20:32:27,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:27,642 INFO:     Epoch: 11
2022-12-05 20:32:28,443 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.414706157351082, 'Total loss': 0.414706157351082} | train loss {'Reaction outcome loss': 0.28193488104208825, 'Total loss': 0.28193488104208825}
2022-12-05 20:32:28,443 INFO:     Found new best model at epoch 11
2022-12-05 20:32:28,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:28,444 INFO:     Epoch: 12
2022-12-05 20:32:29,240 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4203583056276495, 'Total loss': 0.4203583056276495} | train loss {'Reaction outcome loss': 0.27406022619576226, 'Total loss': 0.27406022619576226}
2022-12-05 20:32:29,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:29,241 INFO:     Epoch: 13
2022-12-05 20:32:30,038 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42450848729773, 'Total loss': 0.42450848729773} | train loss {'Reaction outcome loss': 0.25796375997484694, 'Total loss': 0.25796375997484694}
2022-12-05 20:32:30,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:30,038 INFO:     Epoch: 14
2022-12-05 20:32:30,839 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43172923424704507, 'Total loss': 0.43172923424704507} | train loss {'Reaction outcome loss': 0.25377124648601296, 'Total loss': 0.25377124648601296}
2022-12-05 20:32:30,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:30,839 INFO:     Epoch: 15
2022-12-05 20:32:31,639 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4202753569592129, 'Total loss': 0.4202753569592129} | train loss {'Reaction outcome loss': 0.24456960135590164, 'Total loss': 0.24456960135590164}
2022-12-05 20:32:31,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:31,640 INFO:     Epoch: 16
2022-12-05 20:32:32,442 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42799759351394395, 'Total loss': 0.42799759351394395} | train loss {'Reaction outcome loss': 0.2381579703801582, 'Total loss': 0.2381579703801582}
2022-12-05 20:32:32,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:32,442 INFO:     Epoch: 17
2022-12-05 20:32:33,244 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4241157775236802, 'Total loss': 0.4241157775236802} | train loss {'Reaction outcome loss': 0.2345855584247939, 'Total loss': 0.2345855584247939}
2022-12-05 20:32:33,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:33,245 INFO:     Epoch: 18
2022-12-05 20:32:34,047 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42132217437028885, 'Total loss': 0.42132217437028885} | train loss {'Reaction outcome loss': 0.22839752297788377, 'Total loss': 0.22839752297788377}
2022-12-05 20:32:34,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:34,047 INFO:     Epoch: 19
2022-12-05 20:32:34,843 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42530123821713706, 'Total loss': 0.42530123821713706} | train loss {'Reaction outcome loss': 0.22309865855101135, 'Total loss': 0.22309865855101135}
2022-12-05 20:32:34,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:34,844 INFO:     Epoch: 20
2022-12-05 20:32:35,643 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42623569003560324, 'Total loss': 0.42623569003560324} | train loss {'Reaction outcome loss': 0.21645354349616794, 'Total loss': 0.21645354349616794}
2022-12-05 20:32:35,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:35,643 INFO:     Epoch: 21
2022-12-05 20:32:36,448 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42780533839355817, 'Total loss': 0.42780533839355817} | train loss {'Reaction outcome loss': 0.21306811213012664, 'Total loss': 0.21306811213012664}
2022-12-05 20:32:36,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:36,448 INFO:     Epoch: 22
2022-12-05 20:32:37,249 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43107991631735454, 'Total loss': 0.43107991631735454} | train loss {'Reaction outcome loss': 0.20482132918832283, 'Total loss': 0.20482132918832283}
2022-12-05 20:32:37,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:37,250 INFO:     Epoch: 23
2022-12-05 20:32:38,053 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43202375349673355, 'Total loss': 0.43202375349673355} | train loss {'Reaction outcome loss': 0.20423833600756142, 'Total loss': 0.20423833600756142}
2022-12-05 20:32:38,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:38,053 INFO:     Epoch: 24
2022-12-05 20:32:38,856 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4285123273730278, 'Total loss': 0.4285123273730278} | train loss {'Reaction outcome loss': 0.2027904608196789, 'Total loss': 0.2027904608196789}
2022-12-05 20:32:38,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:38,856 INFO:     Epoch: 25
2022-12-05 20:32:39,661 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42039124769243325, 'Total loss': 0.42039124769243325} | train loss {'Reaction outcome loss': 0.19622140174971953, 'Total loss': 0.19622140174971953}
2022-12-05 20:32:39,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:39,662 INFO:     Epoch: 26
2022-12-05 20:32:40,467 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.430691717361862, 'Total loss': 0.430691717361862} | train loss {'Reaction outcome loss': 0.19653588117310597, 'Total loss': 0.19653588117310597}
2022-12-05 20:32:40,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:40,468 INFO:     Epoch: 27
2022-12-05 20:32:41,272 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42190890708430245, 'Total loss': 0.42190890708430245} | train loss {'Reaction outcome loss': 0.19196047026273463, 'Total loss': 0.19196047026273463}
2022-12-05 20:32:41,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:41,272 INFO:     Epoch: 28
2022-12-05 20:32:42,079 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41913201388987625, 'Total loss': 0.41913201388987625} | train loss {'Reaction outcome loss': 0.18762407327191002, 'Total loss': 0.18762407327191002}
2022-12-05 20:32:42,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:42,079 INFO:     Epoch: 29
2022-12-05 20:32:42,893 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4330761236223308, 'Total loss': 0.4330761236223308} | train loss {'Reaction outcome loss': 0.18267222810085984, 'Total loss': 0.18267222810085984}
2022-12-05 20:32:42,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:42,894 INFO:     Epoch: 30
2022-12-05 20:32:43,708 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4414309957488017, 'Total loss': 0.4414309957488017} | train loss {'Reaction outcome loss': 0.1811622428377309, 'Total loss': 0.1811622428377309}
2022-12-05 20:32:43,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:43,708 INFO:     Epoch: 31
2022-12-05 20:32:44,510 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4366739548065446, 'Total loss': 0.4366739548065446} | train loss {'Reaction outcome loss': 0.17523291053610943, 'Total loss': 0.17523291053610943}
2022-12-05 20:32:44,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:44,511 INFO:     Epoch: 32
2022-12-05 20:32:45,316 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44780086793682794, 'Total loss': 0.44780086793682794} | train loss {'Reaction outcome loss': 0.17741430495234747, 'Total loss': 0.17741430495234747}
2022-12-05 20:32:45,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:45,317 INFO:     Epoch: 33
2022-12-05 20:32:46,125 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.441755109551278, 'Total loss': 0.441755109551278} | train loss {'Reaction outcome loss': 0.175629724538134, 'Total loss': 0.175629724538134}
2022-12-05 20:32:46,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:46,125 INFO:     Epoch: 34
2022-12-05 20:32:46,930 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4389474400403825, 'Total loss': 0.4389474400403825} | train loss {'Reaction outcome loss': 0.17096908989873144, 'Total loss': 0.17096908989873144}
2022-12-05 20:32:46,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:46,930 INFO:     Epoch: 35
2022-12-05 20:32:47,735 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4476915282959288, 'Total loss': 0.4476915282959288} | train loss {'Reaction outcome loss': 0.17138084893926017, 'Total loss': 0.17138084893926017}
2022-12-05 20:32:47,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:47,735 INFO:     Epoch: 36
2022-12-05 20:32:48,542 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44525018537586386, 'Total loss': 0.44525018537586386} | train loss {'Reaction outcome loss': 0.16601561928438324, 'Total loss': 0.16601561928438324}
2022-12-05 20:32:48,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:48,542 INFO:     Epoch: 37
2022-12-05 20:32:49,347 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4409903169355609, 'Total loss': 0.4409903169355609} | train loss {'Reaction outcome loss': 0.16326453242330782, 'Total loss': 0.16326453242330782}
2022-12-05 20:32:49,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:49,348 INFO:     Epoch: 38
2022-12-05 20:32:50,154 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44176292487166147, 'Total loss': 0.44176292487166147} | train loss {'Reaction outcome loss': 0.16515942023045593, 'Total loss': 0.16515942023045593}
2022-12-05 20:32:50,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:50,154 INFO:     Epoch: 39
2022-12-05 20:32:50,958 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.453699731183323, 'Total loss': 0.453699731183323} | train loss {'Reaction outcome loss': 0.1607937580875812, 'Total loss': 0.1607937580875812}
2022-12-05 20:32:50,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:50,959 INFO:     Epoch: 40
2022-12-05 20:32:51,762 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43582086806947534, 'Total loss': 0.43582086806947534} | train loss {'Reaction outcome loss': 0.16002198552802926, 'Total loss': 0.16002198552802926}
2022-12-05 20:32:51,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:51,762 INFO:     Epoch: 41
2022-12-05 20:32:52,570 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4475157508118586, 'Total loss': 0.4475157508118586} | train loss {'Reaction outcome loss': 0.15939538831251762, 'Total loss': 0.15939538831251762}
2022-12-05 20:32:52,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:52,571 INFO:     Epoch: 42
2022-12-05 20:32:53,377 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46161487766287546, 'Total loss': 0.46161487766287546} | train loss {'Reaction outcome loss': 0.15835973763868452, 'Total loss': 0.15835973763868452}
2022-12-05 20:32:53,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:53,377 INFO:     Epoch: 43
2022-12-05 20:32:54,184 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43944976004687225, 'Total loss': 0.43944976004687225} | train loss {'Reaction outcome loss': 0.15487519355731144, 'Total loss': 0.15487519355731144}
2022-12-05 20:32:54,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:54,184 INFO:     Epoch: 44
2022-12-05 20:32:54,986 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44051310301504354, 'Total loss': 0.44051310301504354} | train loss {'Reaction outcome loss': 0.15391935692769626, 'Total loss': 0.15391935692769626}
2022-12-05 20:32:54,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:54,986 INFO:     Epoch: 45
2022-12-05 20:32:55,796 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42916772311384027, 'Total loss': 0.42916772311384027} | train loss {'Reaction outcome loss': 0.15415498158413796, 'Total loss': 0.15415498158413796}
2022-12-05 20:32:55,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:55,796 INFO:     Epoch: 46
2022-12-05 20:32:56,600 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.450781564143571, 'Total loss': 0.450781564143571} | train loss {'Reaction outcome loss': 0.1521761956955156, 'Total loss': 0.1521761956955156}
2022-12-05 20:32:56,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:56,600 INFO:     Epoch: 47
2022-12-05 20:32:57,406 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.443577971986749, 'Total loss': 0.443577971986749} | train loss {'Reaction outcome loss': 0.1535407373110854, 'Total loss': 0.1535407373110854}
2022-12-05 20:32:57,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:57,406 INFO:     Epoch: 48
2022-12-05 20:32:58,216 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45370848883282056, 'Total loss': 0.45370848883282056} | train loss {'Reaction outcome loss': 0.15034286474298325, 'Total loss': 0.15034286474298325}
2022-12-05 20:32:58,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:58,216 INFO:     Epoch: 49
2022-12-05 20:32:59,020 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4519486694850705, 'Total loss': 0.4519486694850705} | train loss {'Reaction outcome loss': 0.1468746914648481, 'Total loss': 0.1468746914648481}
2022-12-05 20:32:59,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:59,020 INFO:     Epoch: 50
2022-12-05 20:32:59,826 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44569336385889485, 'Total loss': 0.44569336385889485} | train loss {'Reaction outcome loss': 0.1466247519222839, 'Total loss': 0.1466247519222839}
2022-12-05 20:32:59,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:32:59,826 INFO:     Epoch: 51
2022-12-05 20:33:00,631 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4515921967950734, 'Total loss': 0.4515921967950734} | train loss {'Reaction outcome loss': 0.14741953297127638, 'Total loss': 0.14741953297127638}
2022-12-05 20:33:00,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:00,631 INFO:     Epoch: 52
2022-12-05 20:33:01,434 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44997337833046913, 'Total loss': 0.44997337833046913} | train loss {'Reaction outcome loss': 0.14824452197119112, 'Total loss': 0.14824452197119112}
2022-12-05 20:33:01,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:01,434 INFO:     Epoch: 53
2022-12-05 20:33:02,239 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45175832374529407, 'Total loss': 0.45175832374529407} | train loss {'Reaction outcome loss': 0.14585852231680146, 'Total loss': 0.14585852231680146}
2022-12-05 20:33:02,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:02,240 INFO:     Epoch: 54
2022-12-05 20:33:03,045 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44246845319867134, 'Total loss': 0.44246845319867134} | train loss {'Reaction outcome loss': 0.1452556599922959, 'Total loss': 0.1452556599922959}
2022-12-05 20:33:03,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:03,046 INFO:     Epoch: 55
2022-12-05 20:33:03,848 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44711798056960106, 'Total loss': 0.44711798056960106} | train loss {'Reaction outcome loss': 0.1450966523073974, 'Total loss': 0.1450966523073974}
2022-12-05 20:33:03,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:03,848 INFO:     Epoch: 56
2022-12-05 20:33:04,651 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4493153061379086, 'Total loss': 0.4493153061379086} | train loss {'Reaction outcome loss': 0.14065699831342265, 'Total loss': 0.14065699831342265}
2022-12-05 20:33:04,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:04,651 INFO:     Epoch: 57
2022-12-05 20:33:05,457 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4531916464594277, 'Total loss': 0.4531916464594277} | train loss {'Reaction outcome loss': 0.14094165745641915, 'Total loss': 0.14094165745641915}
2022-12-05 20:33:05,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:05,457 INFO:     Epoch: 58
2022-12-05 20:33:06,264 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4471323097294027, 'Total loss': 0.4471323097294027} | train loss {'Reaction outcome loss': 0.14152744145042473, 'Total loss': 0.14152744145042473}
2022-12-05 20:33:06,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:06,265 INFO:     Epoch: 59
2022-12-05 20:33:07,071 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44415544312108646, 'Total loss': 0.44415544312108646} | train loss {'Reaction outcome loss': 0.14140625743405713, 'Total loss': 0.14140625743405713}
2022-12-05 20:33:07,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:07,071 INFO:     Epoch: 60
2022-12-05 20:33:07,876 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45206196132031357, 'Total loss': 0.45206196132031357} | train loss {'Reaction outcome loss': 0.13802827419074734, 'Total loss': 0.13802827419074734}
2022-12-05 20:33:07,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:07,877 INFO:     Epoch: 61
2022-12-05 20:33:08,681 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45941746404225176, 'Total loss': 0.45941746404225176} | train loss {'Reaction outcome loss': 0.13951667082015304, 'Total loss': 0.13951667082015304}
2022-12-05 20:33:08,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:08,681 INFO:     Epoch: 62
2022-12-05 20:33:09,483 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45237585563551297, 'Total loss': 0.45237585563551297} | train loss {'Reaction outcome loss': 0.13567055032528455, 'Total loss': 0.13567055032528455}
2022-12-05 20:33:09,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:09,484 INFO:     Epoch: 63
2022-12-05 20:33:10,285 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4438365006988699, 'Total loss': 0.4438365006988699} | train loss {'Reaction outcome loss': 0.13555868647451844, 'Total loss': 0.13555868647451844}
2022-12-05 20:33:10,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:10,286 INFO:     Epoch: 64
2022-12-05 20:33:11,086 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44803961129351094, 'Total loss': 0.44803961129351094} | train loss {'Reaction outcome loss': 0.13872438099896234, 'Total loss': 0.13872438099896234}
2022-12-05 20:33:11,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:11,086 INFO:     Epoch: 65
2022-12-05 20:33:11,888 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44116916405883705, 'Total loss': 0.44116916405883705} | train loss {'Reaction outcome loss': 0.1349635482502861, 'Total loss': 0.1349635482502861}
2022-12-05 20:33:11,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:11,889 INFO:     Epoch: 66
2022-12-05 20:33:12,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44170909916812723, 'Total loss': 0.44170909916812723} | train loss {'Reaction outcome loss': 0.13375967169075362, 'Total loss': 0.13375967169075362}
2022-12-05 20:33:12,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:12,693 INFO:     Epoch: 67
2022-12-05 20:33:13,496 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46434263309294527, 'Total loss': 0.46434263309294527} | train loss {'Reaction outcome loss': 0.13191687788123324, 'Total loss': 0.13191687788123324}
2022-12-05 20:33:13,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:13,496 INFO:     Epoch: 68
2022-12-05 20:33:14,296 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4594081162729047, 'Total loss': 0.4594081162729047} | train loss {'Reaction outcome loss': 0.1320419554455927, 'Total loss': 0.1320419554455927}
2022-12-05 20:33:14,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:14,297 INFO:     Epoch: 69
2022-12-05 20:33:15,095 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44762384451248427, 'Total loss': 0.44762384451248427} | train loss {'Reaction outcome loss': 0.1330480881546053, 'Total loss': 0.1330480881546053}
2022-12-05 20:33:15,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:15,096 INFO:     Epoch: 70
2022-12-05 20:33:15,901 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45162855613638053, 'Total loss': 0.45162855613638053} | train loss {'Reaction outcome loss': 0.13144401961847418, 'Total loss': 0.13144401961847418}
2022-12-05 20:33:15,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:15,902 INFO:     Epoch: 71
2022-12-05 20:33:16,703 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4532431330193173, 'Total loss': 0.4532431330193173} | train loss {'Reaction outcome loss': 0.1307552591522014, 'Total loss': 0.1307552591522014}
2022-12-05 20:33:16,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:16,703 INFO:     Epoch: 72
2022-12-05 20:33:17,503 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44722449813376774, 'Total loss': 0.44722449813376774} | train loss {'Reaction outcome loss': 0.12832156300259334, 'Total loss': 0.12832156300259334}
2022-12-05 20:33:17,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:17,503 INFO:     Epoch: 73
2022-12-05 20:33:18,303 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45928601311011746, 'Total loss': 0.45928601311011746} | train loss {'Reaction outcome loss': 0.1300967097500219, 'Total loss': 0.1300967097500219}
2022-12-05 20:33:18,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:18,303 INFO:     Epoch: 74
2022-12-05 20:33:19,102 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44267390346662566, 'Total loss': 0.44267390346662566} | train loss {'Reaction outcome loss': 0.1295447944393081, 'Total loss': 0.1295447944393081}
2022-12-05 20:33:19,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:19,102 INFO:     Epoch: 75
2022-12-05 20:33:19,900 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4495825113897974, 'Total loss': 0.4495825113897974} | train loss {'Reaction outcome loss': 0.12738638135394262, 'Total loss': 0.12738638135394262}
2022-12-05 20:33:19,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:19,901 INFO:     Epoch: 76
2022-12-05 20:33:20,700 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4507649358023297, 'Total loss': 0.4507649358023297} | train loss {'Reaction outcome loss': 0.13044070806955138, 'Total loss': 0.13044070806955138}
2022-12-05 20:33:20,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:20,700 INFO:     Epoch: 77
2022-12-05 20:33:21,498 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44038198414173996, 'Total loss': 0.44038198414173996} | train loss {'Reaction outcome loss': 0.128088062632859, 'Total loss': 0.128088062632859}
2022-12-05 20:33:21,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:21,499 INFO:     Epoch: 78
2022-12-05 20:33:22,298 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4519881765273484, 'Total loss': 0.4519881765273484} | train loss {'Reaction outcome loss': 0.12832676769880158, 'Total loss': 0.12832676769880158}
2022-12-05 20:33:22,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:22,298 INFO:     Epoch: 79
2022-12-05 20:33:23,097 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4643482941795479, 'Total loss': 0.4643482941795479} | train loss {'Reaction outcome loss': 0.12943167471507144, 'Total loss': 0.12943167471507144}
2022-12-05 20:33:23,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:23,097 INFO:     Epoch: 80
2022-12-05 20:33:23,897 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.446119083260948, 'Total loss': 0.446119083260948} | train loss {'Reaction outcome loss': 0.12730616686354962, 'Total loss': 0.12730616686354962}
2022-12-05 20:33:23,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:23,897 INFO:     Epoch: 81
2022-12-05 20:33:24,696 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44939597763798456, 'Total loss': 0.44939597763798456} | train loss {'Reaction outcome loss': 0.12598798923558677, 'Total loss': 0.12598798923558677}
2022-12-05 20:33:24,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:24,696 INFO:     Epoch: 82
2022-12-05 20:33:25,497 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4625157310881398, 'Total loss': 0.4625157310881398} | train loss {'Reaction outcome loss': 0.12546614910505952, 'Total loss': 0.12546614910505952}
2022-12-05 20:33:25,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:25,497 INFO:     Epoch: 83
2022-12-05 20:33:26,296 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45102925395423715, 'Total loss': 0.45102925395423715} | train loss {'Reaction outcome loss': 0.12737285129485593, 'Total loss': 0.12737285129485593}
2022-12-05 20:33:26,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:26,296 INFO:     Epoch: 84
2022-12-05 20:33:27,097 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44953975216908887, 'Total loss': 0.44953975216908887} | train loss {'Reaction outcome loss': 0.12563016815035935, 'Total loss': 0.12563016815035935}
2022-12-05 20:33:27,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:27,097 INFO:     Epoch: 85
2022-12-05 20:33:27,901 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4572821875864809, 'Total loss': 0.4572821875864809} | train loss {'Reaction outcome loss': 0.12442677620527966, 'Total loss': 0.12442677620527966}
2022-12-05 20:33:27,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:27,902 INFO:     Epoch: 86
2022-12-05 20:33:28,700 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.460245511748574, 'Total loss': 0.460245511748574} | train loss {'Reaction outcome loss': 0.12432990022634546, 'Total loss': 0.12432990022634546}
2022-12-05 20:33:28,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:28,700 INFO:     Epoch: 87
2022-12-05 20:33:29,504 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45636157191951165, 'Total loss': 0.45636157191951165} | train loss {'Reaction outcome loss': 0.12511068139781034, 'Total loss': 0.12511068139781034}
2022-12-05 20:33:29,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:29,504 INFO:     Epoch: 88
2022-12-05 20:33:30,303 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4379137541082772, 'Total loss': 0.4379137541082772} | train loss {'Reaction outcome loss': 0.1266883384256113, 'Total loss': 0.1266883384256113}
2022-12-05 20:33:30,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:30,303 INFO:     Epoch: 89
2022-12-05 20:33:31,101 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44702928073026915, 'Total loss': 0.44702928073026915} | train loss {'Reaction outcome loss': 0.12531508766340033, 'Total loss': 0.12531508766340033}
2022-12-05 20:33:31,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:31,101 INFO:     Epoch: 90
2022-12-05 20:33:31,899 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4565320990302346, 'Total loss': 0.4565320990302346} | train loss {'Reaction outcome loss': 0.1223554291326793, 'Total loss': 0.1223554291326793}
2022-12-05 20:33:31,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:31,899 INFO:     Epoch: 91
2022-12-05 20:33:32,697 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46101622605188325, 'Total loss': 0.46101622605188325} | train loss {'Reaction outcome loss': 0.1217022643484656, 'Total loss': 0.1217022643484656}
2022-12-05 20:33:32,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:32,697 INFO:     Epoch: 92
2022-12-05 20:33:33,497 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45535551316358824, 'Total loss': 0.45535551316358824} | train loss {'Reaction outcome loss': 0.12260228338380975, 'Total loss': 0.12260228338380975}
2022-12-05 20:33:33,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:33,498 INFO:     Epoch: 93
2022-12-05 20:33:34,296 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45852758413688705, 'Total loss': 0.45852758413688705} | train loss {'Reaction outcome loss': 0.12172873544641921, 'Total loss': 0.12172873544641921}
2022-12-05 20:33:34,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:34,297 INFO:     Epoch: 94
2022-12-05 20:33:35,095 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4412196505476128, 'Total loss': 0.4412196505476128} | train loss {'Reaction outcome loss': 0.12322108892558684, 'Total loss': 0.12322108892558684}
2022-12-05 20:33:35,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:35,096 INFO:     Epoch: 95
2022-12-05 20:33:35,887 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45496287467804825, 'Total loss': 0.45496287467804825} | train loss {'Reaction outcome loss': 0.12393695535889317, 'Total loss': 0.12393695535889317}
2022-12-05 20:33:35,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:35,887 INFO:     Epoch: 96
2022-12-05 20:33:36,679 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4459277672523802, 'Total loss': 0.4459277672523802} | train loss {'Reaction outcome loss': 0.12231602859608229, 'Total loss': 0.12231602859608229}
2022-12-05 20:33:36,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:36,680 INFO:     Epoch: 97
2022-12-05 20:33:37,474 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4591267274861986, 'Total loss': 0.4591267274861986} | train loss {'Reaction outcome loss': 0.12360667011084696, 'Total loss': 0.12360667011084696}
2022-12-05 20:33:37,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:37,475 INFO:     Epoch: 98
2022-12-05 20:33:38,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45960029654882173, 'Total loss': 0.45960029654882173} | train loss {'Reaction outcome loss': 0.11954390851315111, 'Total loss': 0.11954390851315111}
2022-12-05 20:33:38,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:38,268 INFO:     Epoch: 99
2022-12-05 20:33:39,065 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4581636048176072, 'Total loss': 0.4581636048176072} | train loss {'Reaction outcome loss': 0.1218176678333792, 'Total loss': 0.1218176678333792}
2022-12-05 20:33:39,065 INFO:     Best model found after epoch 12 of 100.
2022-12-05 20:33:39,065 INFO:   Done with stage: TRAINING
2022-12-05 20:33:39,065 INFO:   Starting stage: EVALUATION
2022-12-05 20:33:39,183 INFO:   Done with stage: EVALUATION
2022-12-05 20:33:39,183 INFO:   Leaving out SEQ value Fold_5
2022-12-05 20:33:39,195 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:33:39,196 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:33:39,829 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:33:39,829 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:33:39,899 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:33:39,899 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:33:39,899 INFO:     No hyperparam tuning for this model
2022-12-05 20:33:39,899 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:33:39,899 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:33:39,900 INFO:     None feature selector for col prot
2022-12-05 20:33:39,900 INFO:     None feature selector for col prot
2022-12-05 20:33:39,900 INFO:     None feature selector for col prot
2022-12-05 20:33:39,900 INFO:     None feature selector for col chem
2022-12-05 20:33:39,901 INFO:     None feature selector for col chem
2022-12-05 20:33:39,901 INFO:     None feature selector for col chem
2022-12-05 20:33:39,901 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:33:39,901 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:33:39,902 INFO:     Number of params in model 215821
2022-12-05 20:33:39,905 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:33:39,905 INFO:   Starting stage: TRAINING
2022-12-05 20:33:39,966 INFO:     Val loss before train {'Reaction outcome loss': 1.0190004814754834, 'Total loss': 1.0190004814754834}
2022-12-05 20:33:39,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:39,966 INFO:     Epoch: 0
2022-12-05 20:33:40,765 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6176201084798033, 'Total loss': 0.6176201084798033} | train loss {'Reaction outcome loss': 0.8054626330492958, 'Total loss': 0.8054626330492958}
2022-12-05 20:33:40,765 INFO:     Found new best model at epoch 0
2022-12-05 20:33:40,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:40,766 INFO:     Epoch: 1
2022-12-05 20:33:41,557 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.522748328237371, 'Total loss': 0.522748328237371} | train loss {'Reaction outcome loss': 0.5512126903500287, 'Total loss': 0.5512126903500287}
2022-12-05 20:33:41,557 INFO:     Found new best model at epoch 1
2022-12-05 20:33:41,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:41,558 INFO:     Epoch: 2
2022-12-05 20:33:42,349 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4847331443293528, 'Total loss': 0.4847331443293528} | train loss {'Reaction outcome loss': 0.4757572535665766, 'Total loss': 0.4757572535665766}
2022-12-05 20:33:42,349 INFO:     Found new best model at epoch 2
2022-12-05 20:33:42,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:42,350 INFO:     Epoch: 3
2022-12-05 20:33:43,141 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4652529379183596, 'Total loss': 0.4652529379183596} | train loss {'Reaction outcome loss': 0.4353274323286549, 'Total loss': 0.4353274323286549}
2022-12-05 20:33:43,141 INFO:     Found new best model at epoch 3
2022-12-05 20:33:43,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:43,142 INFO:     Epoch: 4
2022-12-05 20:33:43,937 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4534423581578515, 'Total loss': 0.4534423581578515} | train loss {'Reaction outcome loss': 0.4018244784806044, 'Total loss': 0.4018244784806044}
2022-12-05 20:33:43,937 INFO:     Found new best model at epoch 4
2022-12-05 20:33:43,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:43,937 INFO:     Epoch: 5
2022-12-05 20:33:44,731 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4438562386415221, 'Total loss': 0.4438562386415221} | train loss {'Reaction outcome loss': 0.3776116142830541, 'Total loss': 0.3776116142830541}
2022-12-05 20:33:44,731 INFO:     Found new best model at epoch 5
2022-12-05 20:33:44,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:44,732 INFO:     Epoch: 6
2022-12-05 20:33:45,527 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44769037582657556, 'Total loss': 0.44769037582657556} | train loss {'Reaction outcome loss': 0.35789106981528385, 'Total loss': 0.35789106981528385}
2022-12-05 20:33:45,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:45,527 INFO:     Epoch: 7
2022-12-05 20:33:46,349 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4380105740644715, 'Total loss': 0.4380105740644715} | train loss {'Reaction outcome loss': 0.3434179783348114, 'Total loss': 0.3434179783348114}
2022-12-05 20:33:46,349 INFO:     Found new best model at epoch 7
2022-12-05 20:33:46,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:46,350 INFO:     Epoch: 8
2022-12-05 20:33:47,169 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45020676675167953, 'Total loss': 0.45020676675167953} | train loss {'Reaction outcome loss': 0.32765556015675107, 'Total loss': 0.32765556015675107}
2022-12-05 20:33:47,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:47,170 INFO:     Epoch: 9
2022-12-05 20:33:47,971 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42688002674417064, 'Total loss': 0.42688002674417064} | train loss {'Reaction outcome loss': 0.3148900033725846, 'Total loss': 0.3148900033725846}
2022-12-05 20:33:47,971 INFO:     Found new best model at epoch 9
2022-12-05 20:33:47,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:47,972 INFO:     Epoch: 10
2022-12-05 20:33:48,775 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4259020567617633, 'Total loss': 0.4259020567617633} | train loss {'Reaction outcome loss': 0.3029234683772008, 'Total loss': 0.3029234683772008}
2022-12-05 20:33:48,775 INFO:     Found new best model at epoch 10
2022-12-05 20:33:48,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:48,776 INFO:     Epoch: 11
2022-12-05 20:33:49,579 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42905908213420346, 'Total loss': 0.42905908213420346} | train loss {'Reaction outcome loss': 0.29117850355443453, 'Total loss': 0.29117850355443453}
2022-12-05 20:33:49,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:49,579 INFO:     Epoch: 12
2022-12-05 20:33:50,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4260735230689699, 'Total loss': 0.4260735230689699} | train loss {'Reaction outcome loss': 0.2845313342047795, 'Total loss': 0.2845313342047795}
2022-12-05 20:33:50,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:50,379 INFO:     Epoch: 13
2022-12-05 20:33:51,180 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42336736246943474, 'Total loss': 0.42336736246943474} | train loss {'Reaction outcome loss': 0.2728796126621385, 'Total loss': 0.2728796126621385}
2022-12-05 20:33:51,180 INFO:     Found new best model at epoch 13
2022-12-05 20:33:51,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:51,181 INFO:     Epoch: 14
2022-12-05 20:33:51,979 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4247558807784861, 'Total loss': 0.4247558807784861} | train loss {'Reaction outcome loss': 0.26476082713493415, 'Total loss': 0.26476082713493415}
2022-12-05 20:33:51,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:51,979 INFO:     Epoch: 15
2022-12-05 20:33:52,781 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42959549819881265, 'Total loss': 0.42959549819881265} | train loss {'Reaction outcome loss': 0.2560952568366643, 'Total loss': 0.2560952568366643}
2022-12-05 20:33:52,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:52,781 INFO:     Epoch: 16
2022-12-05 20:33:53,585 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43147527832876553, 'Total loss': 0.43147527832876553} | train loss {'Reaction outcome loss': 0.2507453921341127, 'Total loss': 0.2507453921341127}
2022-12-05 20:33:53,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:53,586 INFO:     Epoch: 17
2022-12-05 20:33:54,389 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4212543585083701, 'Total loss': 0.4212543585083701} | train loss {'Reaction outcome loss': 0.2416592975627751, 'Total loss': 0.2416592975627751}
2022-12-05 20:33:54,389 INFO:     Found new best model at epoch 17
2022-12-05 20:33:54,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:54,390 INFO:     Epoch: 18
2022-12-05 20:33:55,192 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4145300865850665, 'Total loss': 0.4145300865850665} | train loss {'Reaction outcome loss': 0.23832573891887743, 'Total loss': 0.23832573891887743}
2022-12-05 20:33:55,192 INFO:     Found new best model at epoch 18
2022-12-05 20:33:55,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:55,193 INFO:     Epoch: 19
2022-12-05 20:33:55,993 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43050019307570025, 'Total loss': 0.43050019307570025} | train loss {'Reaction outcome loss': 0.22952687803415522, 'Total loss': 0.22952687803415522}
2022-12-05 20:33:55,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:55,993 INFO:     Epoch: 20
2022-12-05 20:33:56,791 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43887670744549145, 'Total loss': 0.43887670744549145} | train loss {'Reaction outcome loss': 0.22529203347080656, 'Total loss': 0.22529203347080656}
2022-12-05 20:33:56,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:56,791 INFO:     Epoch: 21
2022-12-05 20:33:57,590 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43972402438521385, 'Total loss': 0.43972402438521385} | train loss {'Reaction outcome loss': 0.21767490227977115, 'Total loss': 0.21767490227977115}
2022-12-05 20:33:57,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:57,590 INFO:     Epoch: 22
2022-12-05 20:33:58,391 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42505737326361914, 'Total loss': 0.42505737326361914} | train loss {'Reaction outcome loss': 0.2159062065259223, 'Total loss': 0.2159062065259223}
2022-12-05 20:33:58,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:58,391 INFO:     Epoch: 23
2022-12-05 20:33:59,190 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4277161954140121, 'Total loss': 0.4277161954140121} | train loss {'Reaction outcome loss': 0.20672161240250833, 'Total loss': 0.20672161240250833}
2022-12-05 20:33:59,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:59,191 INFO:     Epoch: 24
2022-12-05 20:33:59,992 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44793393327431247, 'Total loss': 0.44793393327431247} | train loss {'Reaction outcome loss': 0.20269039159850968, 'Total loss': 0.20269039159850968}
2022-12-05 20:33:59,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:33:59,992 INFO:     Epoch: 25
2022-12-05 20:34:00,791 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.431423005732623, 'Total loss': 0.431423005732623} | train loss {'Reaction outcome loss': 0.20257894486008632, 'Total loss': 0.20257894486008632}
2022-12-05 20:34:00,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:00,791 INFO:     Epoch: 26
2022-12-05 20:34:01,590 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4244276893071153, 'Total loss': 0.4244276893071153} | train loss {'Reaction outcome loss': 0.20026822428729746, 'Total loss': 0.20026822428729746}
2022-12-05 20:34:01,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:01,591 INFO:     Epoch: 27
2022-12-05 20:34:02,391 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4340309189124541, 'Total loss': 0.4340309189124541} | train loss {'Reaction outcome loss': 0.19745450731997768, 'Total loss': 0.19745450731997768}
2022-12-05 20:34:02,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:02,391 INFO:     Epoch: 28
2022-12-05 20:34:03,190 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4384675747291608, 'Total loss': 0.4384675747291608} | train loss {'Reaction outcome loss': 0.1905874137075678, 'Total loss': 0.1905874137075678}
2022-12-05 20:34:03,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:03,191 INFO:     Epoch: 29
2022-12-05 20:34:03,988 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4431552971628579, 'Total loss': 0.4431552971628579} | train loss {'Reaction outcome loss': 0.1894728334079827, 'Total loss': 0.1894728334079827}
2022-12-05 20:34:03,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:03,989 INFO:     Epoch: 30
2022-12-05 20:34:04,787 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4445653466338461, 'Total loss': 0.4445653466338461} | train loss {'Reaction outcome loss': 0.1853826630770439, 'Total loss': 0.1853826630770439}
2022-12-05 20:34:04,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:04,787 INFO:     Epoch: 31
2022-12-05 20:34:05,587 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4377538809044795, 'Total loss': 0.4377538809044795} | train loss {'Reaction outcome loss': 0.18529240186175994, 'Total loss': 0.18529240186175994}
2022-12-05 20:34:05,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:05,588 INFO:     Epoch: 32
2022-12-05 20:34:06,386 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44621144607663155, 'Total loss': 0.44621144607663155} | train loss {'Reaction outcome loss': 0.18109011593004387, 'Total loss': 0.18109011593004387}
2022-12-05 20:34:06,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:06,387 INFO:     Epoch: 33
2022-12-05 20:34:07,188 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42834808000109414, 'Total loss': 0.42834808000109414} | train loss {'Reaction outcome loss': 0.17764098667389444, 'Total loss': 0.17764098667389444}
2022-12-05 20:34:07,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:07,188 INFO:     Epoch: 34
2022-12-05 20:34:07,986 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4419337118213827, 'Total loss': 0.4419337118213827} | train loss {'Reaction outcome loss': 0.17432398649473343, 'Total loss': 0.17432398649473343}
2022-12-05 20:34:07,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:07,986 INFO:     Epoch: 35
2022-12-05 20:34:08,787 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4433567710220814, 'Total loss': 0.4433567710220814} | train loss {'Reaction outcome loss': 0.1765209673828776, 'Total loss': 0.1765209673828776}
2022-12-05 20:34:08,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:08,788 INFO:     Epoch: 36
2022-12-05 20:34:09,585 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4448064203289422, 'Total loss': 0.4448064203289422} | train loss {'Reaction outcome loss': 0.17443868989169958, 'Total loss': 0.17443868989169958}
2022-12-05 20:34:09,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:09,585 INFO:     Epoch: 37
2022-12-05 20:34:10,387 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44904819469560275, 'Total loss': 0.44904819469560275} | train loss {'Reaction outcome loss': 0.17203133594575187, 'Total loss': 0.17203133594575187}
2022-12-05 20:34:10,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:10,387 INFO:     Epoch: 38
2022-12-05 20:34:11,191 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4433837417851795, 'Total loss': 0.4433837417851795} | train loss {'Reaction outcome loss': 0.16775200054830602, 'Total loss': 0.16775200054830602}
2022-12-05 20:34:11,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:11,192 INFO:     Epoch: 39
2022-12-05 20:34:11,990 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43529941446401854, 'Total loss': 0.43529941446401854} | train loss {'Reaction outcome loss': 0.16387697614939703, 'Total loss': 0.16387697614939703}
2022-12-05 20:34:11,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:11,990 INFO:     Epoch: 40
2022-12-05 20:34:12,790 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4584323008629409, 'Total loss': 0.4584323008629409} | train loss {'Reaction outcome loss': 0.16543573874139017, 'Total loss': 0.16543573874139017}
2022-12-05 20:34:12,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:12,791 INFO:     Epoch: 41
2022-12-05 20:34:13,589 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43663658354092727, 'Total loss': 0.43663658354092727} | train loss {'Reaction outcome loss': 0.16502969471677656, 'Total loss': 0.16502969471677656}
2022-12-05 20:34:13,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:13,590 INFO:     Epoch: 42
2022-12-05 20:34:14,390 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45691189711744135, 'Total loss': 0.45691189711744135} | train loss {'Reaction outcome loss': 0.1645652599362356, 'Total loss': 0.1645652599362356}
2022-12-05 20:34:14,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:14,390 INFO:     Epoch: 43
2022-12-05 20:34:15,191 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45316876301711256, 'Total loss': 0.45316876301711256} | train loss {'Reaction outcome loss': 0.16101838551431655, 'Total loss': 0.16101838551431655}
2022-12-05 20:34:15,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:15,191 INFO:     Epoch: 44
2022-12-05 20:34:15,993 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4287935605441982, 'Total loss': 0.4287935605441982} | train loss {'Reaction outcome loss': 0.15920568267334131, 'Total loss': 0.15920568267334131}
2022-12-05 20:34:15,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:15,993 INFO:     Epoch: 45
2022-12-05 20:34:16,791 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44633910127661447, 'Total loss': 0.44633910127661447} | train loss {'Reaction outcome loss': 0.15676121412956667, 'Total loss': 0.15676121412956667}
2022-12-05 20:34:16,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:16,791 INFO:     Epoch: 46
2022-12-05 20:34:17,590 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4291736022992568, 'Total loss': 0.4291736022992568} | train loss {'Reaction outcome loss': 0.1577669309767624, 'Total loss': 0.1577669309767624}
2022-12-05 20:34:17,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:17,591 INFO:     Epoch: 47
2022-12-05 20:34:18,388 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45789148015054787, 'Total loss': 0.45789148015054787} | train loss {'Reaction outcome loss': 0.15677777341296595, 'Total loss': 0.15677777341296595}
2022-12-05 20:34:18,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:18,389 INFO:     Epoch: 48
2022-12-05 20:34:19,192 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.455520014193925, 'Total loss': 0.455520014193925} | train loss {'Reaction outcome loss': 0.15364541138161816, 'Total loss': 0.15364541138161816}
2022-12-05 20:34:19,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:19,193 INFO:     Epoch: 49
2022-12-05 20:34:19,993 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4525163199075244, 'Total loss': 0.4525163199075244} | train loss {'Reaction outcome loss': 0.15543553518927505, 'Total loss': 0.15543553518927505}
2022-12-05 20:34:19,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:19,993 INFO:     Epoch: 50
2022-12-05 20:34:20,792 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46256754107095976, 'Total loss': 0.46256754107095976} | train loss {'Reaction outcome loss': 0.1534576688427478, 'Total loss': 0.1534576688427478}
2022-12-05 20:34:20,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:20,793 INFO:     Epoch: 51
2022-12-05 20:34:21,595 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45862721584059973, 'Total loss': 0.45862721584059973} | train loss {'Reaction outcome loss': 0.1511659142274913, 'Total loss': 0.1511659142274913}
2022-12-05 20:34:21,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:21,595 INFO:     Epoch: 52
2022-12-05 20:34:22,394 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46069935184310784, 'Total loss': 0.46069935184310784} | train loss {'Reaction outcome loss': 0.15097804837709955, 'Total loss': 0.15097804837709955}
2022-12-05 20:34:22,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:22,394 INFO:     Epoch: 53
2022-12-05 20:34:23,189 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4457241699776866, 'Total loss': 0.4457241699776866} | train loss {'Reaction outcome loss': 0.149130632477482, 'Total loss': 0.149130632477482}
2022-12-05 20:34:23,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:23,189 INFO:     Epoch: 54
2022-12-05 20:34:23,984 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44640120965513314, 'Total loss': 0.44640120965513314} | train loss {'Reaction outcome loss': 0.15011514462680825, 'Total loss': 0.15011514462680825}
2022-12-05 20:34:23,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:23,984 INFO:     Epoch: 55
2022-12-05 20:34:24,782 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47576742788607423, 'Total loss': 0.47576742788607423} | train loss {'Reaction outcome loss': 0.14448086980489955, 'Total loss': 0.14448086980489955}
2022-12-05 20:34:24,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:24,783 INFO:     Epoch: 56
2022-12-05 20:34:25,581 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44426548006859695, 'Total loss': 0.44426548006859695} | train loss {'Reaction outcome loss': 0.14751389881806268, 'Total loss': 0.14751389881806268}
2022-12-05 20:34:25,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:25,582 INFO:     Epoch: 57
2022-12-05 20:34:26,376 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46486577950417995, 'Total loss': 0.46486577950417995} | train loss {'Reaction outcome loss': 0.14669799911338957, 'Total loss': 0.14669799911338957}
2022-12-05 20:34:26,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:26,376 INFO:     Epoch: 58
2022-12-05 20:34:27,173 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4543772495605729, 'Total loss': 0.4543772495605729} | train loss {'Reaction outcome loss': 0.1421598644416419, 'Total loss': 0.1421598644416419}
2022-12-05 20:34:27,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:27,173 INFO:     Epoch: 59
2022-12-05 20:34:27,970 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45197155326604843, 'Total loss': 0.45197155326604843} | train loss {'Reaction outcome loss': 0.1440678429564521, 'Total loss': 0.1440678429564521}
2022-12-05 20:34:27,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:27,970 INFO:     Epoch: 60
2022-12-05 20:34:28,765 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44553147527304565, 'Total loss': 0.44553147527304565} | train loss {'Reaction outcome loss': 0.14222102014407997, 'Total loss': 0.14222102014407997}
2022-12-05 20:34:28,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:28,765 INFO:     Epoch: 61
2022-12-05 20:34:29,565 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44829966060139914, 'Total loss': 0.44829966060139914} | train loss {'Reaction outcome loss': 0.1411167744607214, 'Total loss': 0.1411167744607214}
2022-12-05 20:34:29,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:29,566 INFO:     Epoch: 62
2022-12-05 20:34:30,361 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4585721804337068, 'Total loss': 0.4585721804337068} | train loss {'Reaction outcome loss': 0.14002946646688808, 'Total loss': 0.14002946646688808}
2022-12-05 20:34:30,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:30,361 INFO:     Epoch: 63
2022-12-05 20:34:31,159 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4449653923511505, 'Total loss': 0.4449653923511505} | train loss {'Reaction outcome loss': 0.13898589183020615, 'Total loss': 0.13898589183020615}
2022-12-05 20:34:31,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:31,160 INFO:     Epoch: 64
2022-12-05 20:34:31,959 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46960020302371547, 'Total loss': 0.46960020302371547} | train loss {'Reaction outcome loss': 0.13827196946517833, 'Total loss': 0.13827196946517833}
2022-12-05 20:34:31,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:31,960 INFO:     Epoch: 65
2022-12-05 20:34:32,761 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44646667350422253, 'Total loss': 0.44646667350422253} | train loss {'Reaction outcome loss': 0.14224839566515818, 'Total loss': 0.14224839566515818}
2022-12-05 20:34:32,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:32,762 INFO:     Epoch: 66
2022-12-05 20:34:33,556 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4590478879822926, 'Total loss': 0.4590478879822926} | train loss {'Reaction outcome loss': 0.14003749933063744, 'Total loss': 0.14003749933063744}
2022-12-05 20:34:33,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:33,556 INFO:     Epoch: 67
2022-12-05 20:34:34,349 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46195754544301465, 'Total loss': 0.46195754544301465} | train loss {'Reaction outcome loss': 0.1395224637667378, 'Total loss': 0.1395224637667378}
2022-12-05 20:34:34,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:34,349 INFO:     Epoch: 68
2022-12-05 20:34:35,146 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44471518796953285, 'Total loss': 0.44471518796953285} | train loss {'Reaction outcome loss': 0.13619410284915037, 'Total loss': 0.13619410284915037}
2022-12-05 20:34:35,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:35,146 INFO:     Epoch: 69
2022-12-05 20:34:35,940 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45939790389754553, 'Total loss': 0.45939790389754553} | train loss {'Reaction outcome loss': 0.13583958945086888, 'Total loss': 0.13583958945086888}
2022-12-05 20:34:35,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:35,941 INFO:     Epoch: 70
2022-12-05 20:34:36,740 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4562858338044448, 'Total loss': 0.4562858338044448} | train loss {'Reaction outcome loss': 0.1390078568177658, 'Total loss': 0.1390078568177658}
2022-12-05 20:34:36,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:36,740 INFO:     Epoch: 71
2022-12-05 20:34:37,536 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46905235573649406, 'Total loss': 0.46905235573649406} | train loss {'Reaction outcome loss': 0.13749328144495526, 'Total loss': 0.13749328144495526}
2022-12-05 20:34:37,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:37,537 INFO:     Epoch: 72
2022-12-05 20:34:38,330 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4697179279544137, 'Total loss': 0.4697179279544137} | train loss {'Reaction outcome loss': 0.13550708643461187, 'Total loss': 0.13550708643461187}
2022-12-05 20:34:38,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:38,330 INFO:     Epoch: 73
2022-12-05 20:34:39,124 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4672180255028335, 'Total loss': 0.4672180255028335} | train loss {'Reaction outcome loss': 0.13217759707702265, 'Total loss': 0.13217759707702265}
2022-12-05 20:34:39,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:39,124 INFO:     Epoch: 74
2022-12-05 20:34:39,921 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45747087828137656, 'Total loss': 0.45747087828137656} | train loss {'Reaction outcome loss': 0.13525646234366803, 'Total loss': 0.13525646234366803}
2022-12-05 20:34:39,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:39,921 INFO:     Epoch: 75
2022-12-05 20:34:40,718 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46932520158588886, 'Total loss': 0.46932520158588886} | train loss {'Reaction outcome loss': 0.13550941715948284, 'Total loss': 0.13550941715948284}
2022-12-05 20:34:40,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:40,719 INFO:     Epoch: 76
2022-12-05 20:34:41,516 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45740626752376556, 'Total loss': 0.45740626752376556} | train loss {'Reaction outcome loss': 0.13228379656380462, 'Total loss': 0.13228379656380462}
2022-12-05 20:34:41,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:41,517 INFO:     Epoch: 77
2022-12-05 20:34:42,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45418341356244957, 'Total loss': 0.45418341356244957} | train loss {'Reaction outcome loss': 0.13077087256486616, 'Total loss': 0.13077087256486616}
2022-12-05 20:34:42,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:42,312 INFO:     Epoch: 78
2022-12-05 20:34:43,108 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46652898006141186, 'Total loss': 0.46652898006141186} | train loss {'Reaction outcome loss': 0.13329824808639504, 'Total loss': 0.13329824808639504}
2022-12-05 20:34:43,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:43,108 INFO:     Epoch: 79
2022-12-05 20:34:43,906 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.463970574465665, 'Total loss': 0.463970574465665} | train loss {'Reaction outcome loss': 0.13085610248268612, 'Total loss': 0.13085610248268612}
2022-12-05 20:34:43,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:43,906 INFO:     Epoch: 80
2022-12-05 20:34:44,703 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45841093496842816, 'Total loss': 0.45841093496842816} | train loss {'Reaction outcome loss': 0.13230106810618553, 'Total loss': 0.13230106810618553}
2022-12-05 20:34:44,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:44,703 INFO:     Epoch: 81
2022-12-05 20:34:45,497 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4670996455983682, 'Total loss': 0.4670996455983682} | train loss {'Reaction outcome loss': 0.1334834367322225, 'Total loss': 0.1334834367322225}
2022-12-05 20:34:45,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:45,498 INFO:     Epoch: 82
2022-12-05 20:34:46,293 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.461658180098642, 'Total loss': 0.461658180098642} | train loss {'Reaction outcome loss': 0.13283482417013617, 'Total loss': 0.13283482417013617}
2022-12-05 20:34:46,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:46,293 INFO:     Epoch: 83
2022-12-05 20:34:47,084 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48188447986136784, 'Total loss': 0.48188447986136784} | train loss {'Reaction outcome loss': 0.1292740166442649, 'Total loss': 0.1292740166442649}
2022-12-05 20:34:47,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:47,084 INFO:     Epoch: 84
2022-12-05 20:34:47,874 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4706731140613556, 'Total loss': 0.4706731140613556} | train loss {'Reaction outcome loss': 0.13069950752410917, 'Total loss': 0.13069950752410917}
2022-12-05 20:34:47,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:47,874 INFO:     Epoch: 85
2022-12-05 20:34:48,664 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46578513221307233, 'Total loss': 0.46578513221307233} | train loss {'Reaction outcome loss': 0.1318884650620842, 'Total loss': 0.1318884650620842}
2022-12-05 20:34:48,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:48,664 INFO:     Epoch: 86
2022-12-05 20:34:49,455 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4726050580767068, 'Total loss': 0.4726050580767068} | train loss {'Reaction outcome loss': 0.1294426610543122, 'Total loss': 0.1294426610543122}
2022-12-05 20:34:49,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:49,456 INFO:     Epoch: 87
2022-12-05 20:34:50,255 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4597827365452593, 'Total loss': 0.4597827365452593} | train loss {'Reaction outcome loss': 0.12853035847506217, 'Total loss': 0.12853035847506217}
2022-12-05 20:34:50,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:50,255 INFO:     Epoch: 88
2022-12-05 20:34:51,054 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4729103716936978, 'Total loss': 0.4729103716936978} | train loss {'Reaction outcome loss': 0.12878683691604004, 'Total loss': 0.12878683691604004}
2022-12-05 20:34:51,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:51,054 INFO:     Epoch: 89
2022-12-05 20:34:51,848 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4711587523872202, 'Total loss': 0.4711587523872202} | train loss {'Reaction outcome loss': 0.12857284247424575, 'Total loss': 0.12857284247424575}
2022-12-05 20:34:51,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:51,849 INFO:     Epoch: 90
2022-12-05 20:34:52,640 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47360365702347323, 'Total loss': 0.47360365702347323} | train loss {'Reaction outcome loss': 0.125335700160283, 'Total loss': 0.125335700160283}
2022-12-05 20:34:52,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:52,640 INFO:     Epoch: 91
2022-12-05 20:34:53,434 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48543076996098866, 'Total loss': 0.48543076996098866} | train loss {'Reaction outcome loss': 0.12853337985448418, 'Total loss': 0.12853337985448418}
2022-12-05 20:34:53,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:53,434 INFO:     Epoch: 92
2022-12-05 20:34:54,227 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47606142288581893, 'Total loss': 0.47606142288581893} | train loss {'Reaction outcome loss': 0.12749601923109544, 'Total loss': 0.12749601923109544}
2022-12-05 20:34:54,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:54,227 INFO:     Epoch: 93
2022-12-05 20:34:55,022 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46610475636341353, 'Total loss': 0.46610475636341353} | train loss {'Reaction outcome loss': 0.12588341227702557, 'Total loss': 0.12588341227702557}
2022-12-05 20:34:55,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:55,022 INFO:     Epoch: 94
2022-12-05 20:34:55,820 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.465918551791798, 'Total loss': 0.465918551791798} | train loss {'Reaction outcome loss': 0.12635880332034563, 'Total loss': 0.12635880332034563}
2022-12-05 20:34:55,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:55,821 INFO:     Epoch: 95
2022-12-05 20:34:56,620 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47033132883635437, 'Total loss': 0.47033132883635437} | train loss {'Reaction outcome loss': 0.12576872131772218, 'Total loss': 0.12576872131772218}
2022-12-05 20:34:56,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:56,620 INFO:     Epoch: 96
2022-12-05 20:34:57,416 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4799998900429769, 'Total loss': 0.4799998900429769} | train loss {'Reaction outcome loss': 0.12429700729121725, 'Total loss': 0.12429700729121725}
2022-12-05 20:34:57,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:57,416 INFO:     Epoch: 97
2022-12-05 20:34:58,216 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48962261087515135, 'Total loss': 0.48962261087515135} | train loss {'Reaction outcome loss': 0.12453946705171538, 'Total loss': 0.12453946705171538}
2022-12-05 20:34:58,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:58,216 INFO:     Epoch: 98
2022-12-05 20:34:59,011 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46745483712716535, 'Total loss': 0.46745483712716535} | train loss {'Reaction outcome loss': 0.1275156873518661, 'Total loss': 0.1275156873518661}
2022-12-05 20:34:59,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:34:59,011 INFO:     Epoch: 99
2022-12-05 20:34:59,804 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4780218523334373, 'Total loss': 0.4780218523334373} | train loss {'Reaction outcome loss': 0.1258785268517151, 'Total loss': 0.1258785268517151}
2022-12-05 20:34:59,804 INFO:     Best model found after epoch 19 of 100.
2022-12-05 20:34:59,804 INFO:   Done with stage: TRAINING
2022-12-05 20:34:59,804 INFO:   Starting stage: EVALUATION
2022-12-05 20:34:59,923 INFO:   Done with stage: EVALUATION
2022-12-05 20:34:59,923 INFO:   Leaving out SEQ value Fold_6
2022-12-05 20:34:59,936 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:34:59,936 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:35:00,574 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:35:00,574 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:35:00,645 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:35:00,645 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:35:00,645 INFO:     No hyperparam tuning for this model
2022-12-05 20:35:00,646 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:35:00,646 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:35:00,646 INFO:     None feature selector for col prot
2022-12-05 20:35:00,646 INFO:     None feature selector for col prot
2022-12-05 20:35:00,647 INFO:     None feature selector for col prot
2022-12-05 20:35:00,647 INFO:     None feature selector for col chem
2022-12-05 20:35:00,647 INFO:     None feature selector for col chem
2022-12-05 20:35:00,647 INFO:     None feature selector for col chem
2022-12-05 20:35:00,647 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:35:00,647 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:35:00,649 INFO:     Number of params in model 215821
2022-12-05 20:35:00,652 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:35:00,652 INFO:   Starting stage: TRAINING
2022-12-05 20:35:00,713 INFO:     Val loss before train {'Reaction outcome loss': 0.9969562197273428, 'Total loss': 0.9969562197273428}
2022-12-05 20:35:00,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:00,713 INFO:     Epoch: 0
2022-12-05 20:35:01,506 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6033841554414142, 'Total loss': 0.6033841554414142} | train loss {'Reaction outcome loss': 0.7895916691951214, 'Total loss': 0.7895916691951214}
2022-12-05 20:35:01,506 INFO:     Found new best model at epoch 0
2022-12-05 20:35:01,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:01,507 INFO:     Epoch: 1
2022-12-05 20:35:02,299 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5179624726826494, 'Total loss': 0.5179624726826494} | train loss {'Reaction outcome loss': 0.5381307323132792, 'Total loss': 0.5381307323132792}
2022-12-05 20:35:02,299 INFO:     Found new best model at epoch 1
2022-12-05 20:35:02,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:02,300 INFO:     Epoch: 2
2022-12-05 20:35:03,095 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47488246722654864, 'Total loss': 0.47488246722654864} | train loss {'Reaction outcome loss': 0.4698935967659758, 'Total loss': 0.4698935967659758}
2022-12-05 20:35:03,095 INFO:     Found new best model at epoch 2
2022-12-05 20:35:03,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:03,096 INFO:     Epoch: 3
2022-12-05 20:35:03,891 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44686189564791595, 'Total loss': 0.44686189564791595} | train loss {'Reaction outcome loss': 0.4302430000877188, 'Total loss': 0.4302430000877188}
2022-12-05 20:35:03,891 INFO:     Found new best model at epoch 3
2022-12-05 20:35:03,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:03,892 INFO:     Epoch: 4
2022-12-05 20:35:04,689 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44215540757233446, 'Total loss': 0.44215540757233446} | train loss {'Reaction outcome loss': 0.40479583377318995, 'Total loss': 0.40479583377318995}
2022-12-05 20:35:04,689 INFO:     Found new best model at epoch 4
2022-12-05 20:35:04,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:04,690 INFO:     Epoch: 5
2022-12-05 20:35:05,487 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4284811389039863, 'Total loss': 0.4284811389039863} | train loss {'Reaction outcome loss': 0.3801284241940706, 'Total loss': 0.3801284241940706}
2022-12-05 20:35:05,487 INFO:     Found new best model at epoch 5
2022-12-05 20:35:05,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:05,488 INFO:     Epoch: 6
2022-12-05 20:35:06,286 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4204718731343746, 'Total loss': 0.4204718731343746} | train loss {'Reaction outcome loss': 0.3645140441254743, 'Total loss': 0.3645140441254743}
2022-12-05 20:35:06,286 INFO:     Found new best model at epoch 6
2022-12-05 20:35:06,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:06,287 INFO:     Epoch: 7
2022-12-05 20:35:07,080 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41860152984207327, 'Total loss': 0.41860152984207327} | train loss {'Reaction outcome loss': 0.3462157548675614, 'Total loss': 0.3462157548675614}
2022-12-05 20:35:07,080 INFO:     Found new best model at epoch 7
2022-12-05 20:35:07,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:07,081 INFO:     Epoch: 8
2022-12-05 20:35:07,874 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4071429448032921, 'Total loss': 0.4071429448032921} | train loss {'Reaction outcome loss': 0.3321106963520569, 'Total loss': 0.3321106963520569}
2022-12-05 20:35:07,875 INFO:     Found new best model at epoch 8
2022-12-05 20:35:07,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:07,876 INFO:     Epoch: 9
2022-12-05 20:35:08,675 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40403045917099173, 'Total loss': 0.40403045917099173} | train loss {'Reaction outcome loss': 0.3185219980415798, 'Total loss': 0.3185219980415798}
2022-12-05 20:35:08,676 INFO:     Found new best model at epoch 9
2022-12-05 20:35:08,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:08,676 INFO:     Epoch: 10
2022-12-05 20:35:09,472 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4083608883348378, 'Total loss': 0.4083608883348378} | train loss {'Reaction outcome loss': 0.3069115116771671, 'Total loss': 0.3069115116771671}
2022-12-05 20:35:09,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:09,472 INFO:     Epoch: 11
2022-12-05 20:35:10,266 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4229152128100395, 'Total loss': 0.4229152128100395} | train loss {'Reaction outcome loss': 0.29424635402017063, 'Total loss': 0.29424635402017063}
2022-12-05 20:35:10,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:10,266 INFO:     Epoch: 12
2022-12-05 20:35:11,062 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40367157655683433, 'Total loss': 0.40367157655683433} | train loss {'Reaction outcome loss': 0.2877819311144131, 'Total loss': 0.2877819311144131}
2022-12-05 20:35:11,062 INFO:     Found new best model at epoch 12
2022-12-05 20:35:11,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:11,063 INFO:     Epoch: 13
2022-12-05 20:35:11,859 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41030501845208084, 'Total loss': 0.41030501845208084} | train loss {'Reaction outcome loss': 0.2751237744946153, 'Total loss': 0.2751237744946153}
2022-12-05 20:35:11,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:11,859 INFO:     Epoch: 14
2022-12-05 20:35:12,655 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41358992558988655, 'Total loss': 0.41358992558988655} | train loss {'Reaction outcome loss': 0.2679550064307067, 'Total loss': 0.2679550064307067}
2022-12-05 20:35:12,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:12,655 INFO:     Epoch: 15
2022-12-05 20:35:13,452 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.410821796818213, 'Total loss': 0.410821796818213} | train loss {'Reaction outcome loss': 0.2631369171543948, 'Total loss': 0.2631369171543948}
2022-12-05 20:35:13,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:13,452 INFO:     Epoch: 16
2022-12-05 20:35:14,245 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4054704901169647, 'Total loss': 0.4054704901169647} | train loss {'Reaction outcome loss': 0.25191206635246355, 'Total loss': 0.25191206635246355}
2022-12-05 20:35:14,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:14,246 INFO:     Epoch: 17
2022-12-05 20:35:15,042 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4249277094548399, 'Total loss': 0.4249277094548399} | train loss {'Reaction outcome loss': 0.2470587773639108, 'Total loss': 0.2470587773639108}
2022-12-05 20:35:15,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:15,042 INFO:     Epoch: 18
2022-12-05 20:35:15,836 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41422935676845635, 'Total loss': 0.41422935676845635} | train loss {'Reaction outcome loss': 0.24319508332278458, 'Total loss': 0.24319508332278458}
2022-12-05 20:35:15,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:15,836 INFO:     Epoch: 19
2022-12-05 20:35:16,638 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41860336234623735, 'Total loss': 0.41860336234623735} | train loss {'Reaction outcome loss': 0.23276582896529185, 'Total loss': 0.23276582896529185}
2022-12-05 20:35:16,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:16,638 INFO:     Epoch: 20
2022-12-05 20:35:17,437 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41648023846474563, 'Total loss': 0.41648023846474563} | train loss {'Reaction outcome loss': 0.2284671382137364, 'Total loss': 0.2284671382137364}
2022-12-05 20:35:17,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:17,437 INFO:     Epoch: 21
2022-12-05 20:35:18,235 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4173879931596192, 'Total loss': 0.4173879931596192} | train loss {'Reaction outcome loss': 0.22358643693188507, 'Total loss': 0.22358643693188507}
2022-12-05 20:35:18,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:18,236 INFO:     Epoch: 22
2022-12-05 20:35:19,038 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40830347551540896, 'Total loss': 0.40830347551540896} | train loss {'Reaction outcome loss': 0.22155465020407591, 'Total loss': 0.22155465020407591}
2022-12-05 20:35:19,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:19,038 INFO:     Epoch: 23
2022-12-05 20:35:19,841 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4066405821252953, 'Total loss': 0.4066405821252953} | train loss {'Reaction outcome loss': 0.2138732576502427, 'Total loss': 0.2138732576502427}
2022-12-05 20:35:19,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:19,841 INFO:     Epoch: 24
2022-12-05 20:35:20,641 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4180844825777141, 'Total loss': 0.4180844825777141} | train loss {'Reaction outcome loss': 0.2118323972869304, 'Total loss': 0.2118323972869304}
2022-12-05 20:35:20,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:20,642 INFO:     Epoch: 25
2022-12-05 20:35:21,439 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4145066345279867, 'Total loss': 0.4145066345279867} | train loss {'Reaction outcome loss': 0.208226349309928, 'Total loss': 0.208226349309928}
2022-12-05 20:35:21,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:21,439 INFO:     Epoch: 26
2022-12-05 20:35:22,238 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4118995756249536, 'Total loss': 0.4118995756249536} | train loss {'Reaction outcome loss': 0.20207083564732345, 'Total loss': 0.20207083564732345}
2022-12-05 20:35:22,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:22,238 INFO:     Epoch: 27
2022-12-05 20:35:23,033 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42226227813146333, 'Total loss': 0.42226227813146333} | train loss {'Reaction outcome loss': 0.20023060224259331, 'Total loss': 0.20023060224259331}
2022-12-05 20:35:23,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:23,033 INFO:     Epoch: 28
2022-12-05 20:35:23,830 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4190183027901433, 'Total loss': 0.4190183027901433} | train loss {'Reaction outcome loss': 0.1963169741774759, 'Total loss': 0.1963169741774759}
2022-12-05 20:35:23,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:23,830 INFO:     Epoch: 29
2022-12-05 20:35:24,624 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41103511439128354, 'Total loss': 0.41103511439128354} | train loss {'Reaction outcome loss': 0.19153181839013292, 'Total loss': 0.19153181839013292}
2022-12-05 20:35:24,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:24,624 INFO:     Epoch: 30
2022-12-05 20:35:25,416 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4356530017473481, 'Total loss': 0.4356530017473481} | train loss {'Reaction outcome loss': 0.1871191454871047, 'Total loss': 0.1871191454871047}
2022-12-05 20:35:25,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:25,417 INFO:     Epoch: 31
2022-12-05 20:35:26,213 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4145377188582312, 'Total loss': 0.4145377188582312} | train loss {'Reaction outcome loss': 0.18795600147437183, 'Total loss': 0.18795600147437183}
2022-12-05 20:35:26,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:26,213 INFO:     Epoch: 32
2022-12-05 20:35:27,006 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41121787120672787, 'Total loss': 0.41121787120672787} | train loss {'Reaction outcome loss': 0.1826662352579015, 'Total loss': 0.1826662352579015}
2022-12-05 20:35:27,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:27,007 INFO:     Epoch: 33
2022-12-05 20:35:27,801 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4176960052414374, 'Total loss': 0.4176960052414374} | train loss {'Reaction outcome loss': 0.18118971220457986, 'Total loss': 0.18118971220457986}
2022-12-05 20:35:27,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:27,802 INFO:     Epoch: 34
2022-12-05 20:35:28,601 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42256733538074925, 'Total loss': 0.42256733538074925} | train loss {'Reaction outcome loss': 0.1803951061841461, 'Total loss': 0.1803951061841461}
2022-12-05 20:35:28,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:28,601 INFO:     Epoch: 35
2022-12-05 20:35:29,396 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4295895008200949, 'Total loss': 0.4295895008200949} | train loss {'Reaction outcome loss': 0.17669711775717237, 'Total loss': 0.17669711775717237}
2022-12-05 20:35:29,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:29,396 INFO:     Epoch: 36
2022-12-05 20:35:30,193 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4223421613939784, 'Total loss': 0.4223421613939784} | train loss {'Reaction outcome loss': 0.17542670011490344, 'Total loss': 0.17542670011490344}
2022-12-05 20:35:30,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:30,193 INFO:     Epoch: 37
2022-12-05 20:35:30,992 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4296840571544387, 'Total loss': 0.4296840571544387} | train loss {'Reaction outcome loss': 0.17291639339659484, 'Total loss': 0.17291639339659484}
2022-12-05 20:35:30,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:30,992 INFO:     Epoch: 38
2022-12-05 20:35:31,791 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42056189104914665, 'Total loss': 0.42056189104914665} | train loss {'Reaction outcome loss': 0.1712097269633124, 'Total loss': 0.1712097269633124}
2022-12-05 20:35:31,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:31,791 INFO:     Epoch: 39
2022-12-05 20:35:32,595 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4151674559847875, 'Total loss': 0.4151674559847875} | train loss {'Reaction outcome loss': 0.17093427468752187, 'Total loss': 0.17093427468752187}
2022-12-05 20:35:32,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:32,595 INFO:     Epoch: 40
2022-12-05 20:35:33,396 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4176597505469214, 'Total loss': 0.4176597505469214} | train loss {'Reaction outcome loss': 0.16857511420253543, 'Total loss': 0.16857511420253543}
2022-12-05 20:35:33,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:33,396 INFO:     Epoch: 41
2022-12-05 20:35:34,192 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41487235338850453, 'Total loss': 0.41487235338850453} | train loss {'Reaction outcome loss': 0.1649417679366325, 'Total loss': 0.1649417679366325}
2022-12-05 20:35:34,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:34,192 INFO:     Epoch: 42
2022-12-05 20:35:34,992 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4073565592142669, 'Total loss': 0.4073565592142669} | train loss {'Reaction outcome loss': 0.1610003404709841, 'Total loss': 0.1610003404709841}
2022-12-05 20:35:34,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:34,993 INFO:     Epoch: 43
2022-12-05 20:35:35,785 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4186021533202041, 'Total loss': 0.4186021533202041} | train loss {'Reaction outcome loss': 0.16170616323624046, 'Total loss': 0.16170616323624046}
2022-12-05 20:35:35,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:35,786 INFO:     Epoch: 44
2022-12-05 20:35:36,583 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43568585863844916, 'Total loss': 0.43568585863844916} | train loss {'Reaction outcome loss': 0.16085582737240098, 'Total loss': 0.16085582737240098}
2022-12-05 20:35:36,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:36,583 INFO:     Epoch: 45
2022-12-05 20:35:37,379 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4173512096432122, 'Total loss': 0.4173512096432122} | train loss {'Reaction outcome loss': 0.16047961700467334, 'Total loss': 0.16047961700467334}
2022-12-05 20:35:37,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:37,379 INFO:     Epoch: 46
2022-12-05 20:35:38,174 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42499543878842483, 'Total loss': 0.42499543878842483} | train loss {'Reaction outcome loss': 0.1556963664404447, 'Total loss': 0.1556963664404447}
2022-12-05 20:35:38,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:38,174 INFO:     Epoch: 47
2022-12-05 20:35:38,971 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4048284004357728, 'Total loss': 0.4048284004357728} | train loss {'Reaction outcome loss': 0.15771132685063827, 'Total loss': 0.15771132685063827}
2022-12-05 20:35:38,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:38,971 INFO:     Epoch: 48
2022-12-05 20:35:39,771 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4427979994903911, 'Total loss': 0.4427979994903911} | train loss {'Reaction outcome loss': 0.15351378947736755, 'Total loss': 0.15351378947736755}
2022-12-05 20:35:39,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:39,772 INFO:     Epoch: 49
2022-12-05 20:35:40,570 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4179851094430143, 'Total loss': 0.4179851094430143} | train loss {'Reaction outcome loss': 0.15216614259406924, 'Total loss': 0.15216614259406924}
2022-12-05 20:35:40,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:40,570 INFO:     Epoch: 50
2022-12-05 20:35:41,363 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4032511345364831, 'Total loss': 0.4032511345364831} | train loss {'Reaction outcome loss': 0.15434245576691483, 'Total loss': 0.15434245576691483}
2022-12-05 20:35:41,363 INFO:     Found new best model at epoch 50
2022-12-05 20:35:41,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:41,364 INFO:     Epoch: 51
2022-12-05 20:35:42,155 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4109816535968672, 'Total loss': 0.4109816535968672} | train loss {'Reaction outcome loss': 0.1547721341748031, 'Total loss': 0.1547721341748031}
2022-12-05 20:35:42,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:42,155 INFO:     Epoch: 52
2022-12-05 20:35:42,947 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4291998686438257, 'Total loss': 0.4291998686438257} | train loss {'Reaction outcome loss': 0.15153063216336793, 'Total loss': 0.15153063216336793}
2022-12-05 20:35:42,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:42,947 INFO:     Epoch: 53
2022-12-05 20:35:43,735 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40308608317917044, 'Total loss': 0.40308608317917044} | train loss {'Reaction outcome loss': 0.15460049418071586, 'Total loss': 0.15460049418071586}
2022-12-05 20:35:43,735 INFO:     Found new best model at epoch 53
2022-12-05 20:35:43,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:43,736 INFO:     Epoch: 54
2022-12-05 20:35:44,529 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4114608398892663, 'Total loss': 0.4114608398892663} | train loss {'Reaction outcome loss': 0.14875838250642823, 'Total loss': 0.14875838250642823}
2022-12-05 20:35:44,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:44,529 INFO:     Epoch: 55
2022-12-05 20:35:45,323 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.429320825771852, 'Total loss': 0.429320825771852} | train loss {'Reaction outcome loss': 0.14892427016410134, 'Total loss': 0.14892427016410134}
2022-12-05 20:35:45,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:45,323 INFO:     Epoch: 56
2022-12-05 20:35:46,116 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42733724787831306, 'Total loss': 0.42733724787831306} | train loss {'Reaction outcome loss': 0.1468701233050876, 'Total loss': 0.1468701233050876}
2022-12-05 20:35:46,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:46,116 INFO:     Epoch: 57
2022-12-05 20:35:46,907 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42103581536899914, 'Total loss': 0.42103581536899914} | train loss {'Reaction outcome loss': 0.14759234082885087, 'Total loss': 0.14759234082885087}
2022-12-05 20:35:46,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:46,907 INFO:     Epoch: 58
2022-12-05 20:35:47,699 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4129887169057673, 'Total loss': 0.4129887169057673} | train loss {'Reaction outcome loss': 0.14769398924263735, 'Total loss': 0.14769398924263735}
2022-12-05 20:35:47,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:47,700 INFO:     Epoch: 59
2022-12-05 20:35:48,496 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4123674295419319, 'Total loss': 0.4123674295419319} | train loss {'Reaction outcome loss': 0.14670552670459955, 'Total loss': 0.14670552670459955}
2022-12-05 20:35:48,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:48,496 INFO:     Epoch: 60
2022-12-05 20:35:49,293 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4298295929011973, 'Total loss': 0.4298295929011973} | train loss {'Reaction outcome loss': 0.1442524965086411, 'Total loss': 0.1442524965086411}
2022-12-05 20:35:49,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:49,294 INFO:     Epoch: 61
2022-12-05 20:35:50,090 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42508789456703444, 'Total loss': 0.42508789456703444} | train loss {'Reaction outcome loss': 0.14827694038244627, 'Total loss': 0.14827694038244627}
2022-12-05 20:35:50,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:50,090 INFO:     Epoch: 62
2022-12-05 20:35:50,894 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42494961179115553, 'Total loss': 0.42494961179115553} | train loss {'Reaction outcome loss': 0.1433356115894933, 'Total loss': 0.1433356115894933}
2022-12-05 20:35:50,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:50,894 INFO:     Epoch: 63
2022-12-05 20:35:51,689 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4144854267889803, 'Total loss': 0.4144854267889803} | train loss {'Reaction outcome loss': 0.14205838547411165, 'Total loss': 0.14205838547411165}
2022-12-05 20:35:51,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:51,691 INFO:     Epoch: 64
2022-12-05 20:35:52,485 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4270806143229658, 'Total loss': 0.4270806143229658} | train loss {'Reaction outcome loss': 0.14177254892344918, 'Total loss': 0.14177254892344918}
2022-12-05 20:35:52,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:52,485 INFO:     Epoch: 65
2022-12-05 20:35:53,275 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43212939460169186, 'Total loss': 0.43212939460169186} | train loss {'Reaction outcome loss': 0.14153382291025932, 'Total loss': 0.14153382291025932}
2022-12-05 20:35:53,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:53,275 INFO:     Epoch: 66
2022-12-05 20:35:54,064 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.432654739103534, 'Total loss': 0.432654739103534} | train loss {'Reaction outcome loss': 0.14163232640168, 'Total loss': 0.14163232640168}
2022-12-05 20:35:54,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:54,064 INFO:     Epoch: 67
2022-12-05 20:35:54,853 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4385377199135043, 'Total loss': 0.4385377199135043} | train loss {'Reaction outcome loss': 0.1401736702875144, 'Total loss': 0.1401736702875144}
2022-12-05 20:35:54,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:54,854 INFO:     Epoch: 68
2022-12-05 20:35:55,648 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4144588986581022, 'Total loss': 0.4144588986581022} | train loss {'Reaction outcome loss': 0.14048052363608393, 'Total loss': 0.14048052363608393}
2022-12-05 20:35:55,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:55,648 INFO:     Epoch: 69
2022-12-05 20:35:56,442 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40872792357748206, 'Total loss': 0.40872792357748206} | train loss {'Reaction outcome loss': 0.14020269802365934, 'Total loss': 0.14020269802365934}
2022-12-05 20:35:56,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:56,442 INFO:     Epoch: 70
2022-12-05 20:35:57,236 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4275580813938921, 'Total loss': 0.4275580813938921} | train loss {'Reaction outcome loss': 0.1381567071469861, 'Total loss': 0.1381567071469861}
2022-12-05 20:35:57,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:57,236 INFO:     Epoch: 71
2022-12-05 20:35:58,028 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42378032952547073, 'Total loss': 0.42378032952547073} | train loss {'Reaction outcome loss': 0.1401895297308182, 'Total loss': 0.1401895297308182}
2022-12-05 20:35:58,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:58,029 INFO:     Epoch: 72
2022-12-05 20:35:58,824 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44211414185437287, 'Total loss': 0.44211414185437287} | train loss {'Reaction outcome loss': 0.13634994393214583, 'Total loss': 0.13634994393214583}
2022-12-05 20:35:58,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:58,825 INFO:     Epoch: 73
2022-12-05 20:35:59,620 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42076905901459133, 'Total loss': 0.42076905901459133} | train loss {'Reaction outcome loss': 0.13828463379984662, 'Total loss': 0.13828463379984662}
2022-12-05 20:35:59,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:35:59,620 INFO:     Epoch: 74
2022-12-05 20:36:00,416 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4209256534549323, 'Total loss': 0.4209256534549323} | train loss {'Reaction outcome loss': 0.13701448822394013, 'Total loss': 0.13701448822394013}
2022-12-05 20:36:00,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:00,416 INFO:     Epoch: 75
2022-12-05 20:36:01,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4206674332645806, 'Total loss': 0.4206674332645806} | train loss {'Reaction outcome loss': 0.132176928950714, 'Total loss': 0.132176928950714}
2022-12-05 20:36:01,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:01,207 INFO:     Epoch: 76
2022-12-05 20:36:02,005 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4388387602838603, 'Total loss': 0.4388387602838603} | train loss {'Reaction outcome loss': 0.13638316928559252, 'Total loss': 0.13638316928559252}
2022-12-05 20:36:02,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:02,005 INFO:     Epoch: 77
2022-12-05 20:36:02,803 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43403628637844865, 'Total loss': 0.43403628637844865} | train loss {'Reaction outcome loss': 0.13686154862760655, 'Total loss': 0.13686154862760655}
2022-12-05 20:36:02,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:02,804 INFO:     Epoch: 78
2022-12-05 20:36:03,594 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4225729311054403, 'Total loss': 0.4225729311054403} | train loss {'Reaction outcome loss': 0.13326153770134214, 'Total loss': 0.13326153770134214}
2022-12-05 20:36:03,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:03,594 INFO:     Epoch: 79
2022-12-05 20:36:04,384 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43676819804717193, 'Total loss': 0.43676819804717193} | train loss {'Reaction outcome loss': 0.13287696775214206, 'Total loss': 0.13287696775214206}
2022-12-05 20:36:04,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:04,385 INFO:     Epoch: 80
2022-12-05 20:36:05,177 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4176262742416425, 'Total loss': 0.4176262742416425} | train loss {'Reaction outcome loss': 0.13640980738695832, 'Total loss': 0.13640980738695832}
2022-12-05 20:36:05,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:05,177 INFO:     Epoch: 81
2022-12-05 20:36:05,969 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43309817734089767, 'Total loss': 0.43309817734089767} | train loss {'Reaction outcome loss': 0.13077236488912133, 'Total loss': 0.13077236488912133}
2022-12-05 20:36:05,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:05,969 INFO:     Epoch: 82
2022-12-05 20:36:06,763 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4207426387478005, 'Total loss': 0.4207426387478005} | train loss {'Reaction outcome loss': 0.13225982270594086, 'Total loss': 0.13225982270594086}
2022-12-05 20:36:06,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:06,763 INFO:     Epoch: 83
2022-12-05 20:36:07,560 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43374238620427524, 'Total loss': 0.43374238620427524} | train loss {'Reaction outcome loss': 0.1317498817393977, 'Total loss': 0.1317498817393977}
2022-12-05 20:36:07,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:07,561 INFO:     Epoch: 84
2022-12-05 20:36:08,360 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42927904054522514, 'Total loss': 0.42927904054522514} | train loss {'Reaction outcome loss': 0.13179244079266586, 'Total loss': 0.13179244079266586}
2022-12-05 20:36:08,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:08,360 INFO:     Epoch: 85
2022-12-05 20:36:09,154 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44932833076878026, 'Total loss': 0.44932833076878026} | train loss {'Reaction outcome loss': 0.13255857482492442, 'Total loss': 0.13255857482492442}
2022-12-05 20:36:09,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:09,154 INFO:     Epoch: 86
2022-12-05 20:36:09,948 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4234735877676444, 'Total loss': 0.4234735877676444} | train loss {'Reaction outcome loss': 0.1326646493267148, 'Total loss': 0.1326646493267148}
2022-12-05 20:36:09,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:09,948 INFO:     Epoch: 87
2022-12-05 20:36:10,745 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42426673898642714, 'Total loss': 0.42426673898642714} | train loss {'Reaction outcome loss': 0.13059171306855616, 'Total loss': 0.13059171306855616}
2022-12-05 20:36:10,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:10,746 INFO:     Epoch: 88
2022-12-05 20:36:11,543 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4293360943821343, 'Total loss': 0.4293360943821343} | train loss {'Reaction outcome loss': 0.13030639385068488, 'Total loss': 0.13030639385068488}
2022-12-05 20:36:11,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:11,544 INFO:     Epoch: 89
2022-12-05 20:36:12,337 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4276968782598322, 'Total loss': 0.4276968782598322} | train loss {'Reaction outcome loss': 0.12760133459796047, 'Total loss': 0.12760133459796047}
2022-12-05 20:36:12,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:12,337 INFO:     Epoch: 90
2022-12-05 20:36:13,128 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42603813552043657, 'Total loss': 0.42603813552043657} | train loss {'Reaction outcome loss': 0.12974006494116638, 'Total loss': 0.12974006494116638}
2022-12-05 20:36:13,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:13,129 INFO:     Epoch: 91
2022-12-05 20:36:13,920 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.427053712816401, 'Total loss': 0.427053712816401} | train loss {'Reaction outcome loss': 0.12958408276280087, 'Total loss': 0.12958408276280087}
2022-12-05 20:36:13,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:13,920 INFO:     Epoch: 92
2022-12-05 20:36:14,713 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4421757906675339, 'Total loss': 0.4421757906675339} | train loss {'Reaction outcome loss': 0.13038772528600548, 'Total loss': 0.13038772528600548}
2022-12-05 20:36:14,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:14,713 INFO:     Epoch: 93
2022-12-05 20:36:15,507 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4449234679341316, 'Total loss': 0.4449234679341316} | train loss {'Reaction outcome loss': 0.1267655224186338, 'Total loss': 0.1267655224186338}
2022-12-05 20:36:15,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:15,507 INFO:     Epoch: 94
2022-12-05 20:36:16,306 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4391132698140361, 'Total loss': 0.4391132698140361} | train loss {'Reaction outcome loss': 0.12854292920054566, 'Total loss': 0.12854292920054566}
2022-12-05 20:36:16,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:16,306 INFO:     Epoch: 95
2022-12-05 20:36:17,101 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41948974488133733, 'Total loss': 0.41948974488133733} | train loss {'Reaction outcome loss': 0.12811849540242204, 'Total loss': 0.12811849540242204}
2022-12-05 20:36:17,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:17,101 INFO:     Epoch: 96
2022-12-05 20:36:17,893 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42626232450658624, 'Total loss': 0.42626232450658624} | train loss {'Reaction outcome loss': 0.12747518196626897, 'Total loss': 0.12747518196626897}
2022-12-05 20:36:17,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:17,893 INFO:     Epoch: 97
2022-12-05 20:36:18,689 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4249858028170737, 'Total loss': 0.4249858028170737} | train loss {'Reaction outcome loss': 0.12525452415068303, 'Total loss': 0.12525452415068303}
2022-12-05 20:36:18,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:18,689 INFO:     Epoch: 98
2022-12-05 20:36:19,484 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42963301559740846, 'Total loss': 0.42963301559740846} | train loss {'Reaction outcome loss': 0.1261392016744902, 'Total loss': 0.1261392016744902}
2022-12-05 20:36:19,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:19,484 INFO:     Epoch: 99
2022-12-05 20:36:20,279 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4400249049067497, 'Total loss': 0.4400249049067497} | train loss {'Reaction outcome loss': 0.12713301704160027, 'Total loss': 0.12713301704160027}
2022-12-05 20:36:20,279 INFO:     Best model found after epoch 54 of 100.
2022-12-05 20:36:20,279 INFO:   Done with stage: TRAINING
2022-12-05 20:36:20,279 INFO:   Starting stage: EVALUATION
2022-12-05 20:36:20,398 INFO:   Done with stage: EVALUATION
2022-12-05 20:36:20,398 INFO:   Leaving out SEQ value Fold_7
2022-12-05 20:36:20,411 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:36:20,412 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:36:21,042 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:36:21,042 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:36:21,111 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:36:21,111 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:36:21,111 INFO:     No hyperparam tuning for this model
2022-12-05 20:36:21,111 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:36:21,111 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:36:21,112 INFO:     None feature selector for col prot
2022-12-05 20:36:21,112 INFO:     None feature selector for col prot
2022-12-05 20:36:21,112 INFO:     None feature selector for col prot
2022-12-05 20:36:21,113 INFO:     None feature selector for col chem
2022-12-05 20:36:21,113 INFO:     None feature selector for col chem
2022-12-05 20:36:21,113 INFO:     None feature selector for col chem
2022-12-05 20:36:21,113 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:36:21,113 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:36:21,115 INFO:     Number of params in model 215821
2022-12-05 20:36:21,118 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:36:21,118 INFO:   Starting stage: TRAINING
2022-12-05 20:36:21,177 INFO:     Val loss before train {'Reaction outcome loss': 1.0377166978148527, 'Total loss': 1.0377166978148527}
2022-12-05 20:36:21,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:21,178 INFO:     Epoch: 0
2022-12-05 20:36:21,966 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6000569795453271, 'Total loss': 0.6000569795453271} | train loss {'Reaction outcome loss': 0.7811904065921659, 'Total loss': 0.7811904065921659}
2022-12-05 20:36:21,966 INFO:     Found new best model at epoch 0
2022-12-05 20:36:21,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:21,967 INFO:     Epoch: 1
2022-12-05 20:36:22,759 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.520506027826043, 'Total loss': 0.520506027826043} | train loss {'Reaction outcome loss': 0.5277279236766158, 'Total loss': 0.5277279236766158}
2022-12-05 20:36:22,760 INFO:     Found new best model at epoch 1
2022-12-05 20:36:22,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:22,761 INFO:     Epoch: 2
2022-12-05 20:36:23,549 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4826510808495588, 'Total loss': 0.4826510808495588} | train loss {'Reaction outcome loss': 0.4570411164008203, 'Total loss': 0.4570411164008203}
2022-12-05 20:36:23,549 INFO:     Found new best model at epoch 2
2022-12-05 20:36:23,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:23,550 INFO:     Epoch: 3
2022-12-05 20:36:24,338 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4681604622408401, 'Total loss': 0.4681604622408401} | train loss {'Reaction outcome loss': 0.41967139735085063, 'Total loss': 0.41967139735085063}
2022-12-05 20:36:24,338 INFO:     Found new best model at epoch 3
2022-12-05 20:36:24,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:24,339 INFO:     Epoch: 4
2022-12-05 20:36:25,126 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4573512479316357, 'Total loss': 0.4573512479316357} | train loss {'Reaction outcome loss': 0.3909886192957886, 'Total loss': 0.3909886192957886}
2022-12-05 20:36:25,126 INFO:     Found new best model at epoch 4
2022-12-05 20:36:25,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:25,127 INFO:     Epoch: 5
2022-12-05 20:36:25,908 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45646314981371855, 'Total loss': 0.45646314981371855} | train loss {'Reaction outcome loss': 0.37227223889871697, 'Total loss': 0.37227223889871697}
2022-12-05 20:36:25,908 INFO:     Found new best model at epoch 5
2022-12-05 20:36:25,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:25,909 INFO:     Epoch: 6
2022-12-05 20:36:26,693 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44743523070978564, 'Total loss': 0.44743523070978564} | train loss {'Reaction outcome loss': 0.35207628357972276, 'Total loss': 0.35207628357972276}
2022-12-05 20:36:26,693 INFO:     Found new best model at epoch 6
2022-12-05 20:36:26,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:26,694 INFO:     Epoch: 7
2022-12-05 20:36:27,474 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4414676341206528, 'Total loss': 0.4414676341206528} | train loss {'Reaction outcome loss': 0.3387935385718697, 'Total loss': 0.3387935385718697}
2022-12-05 20:36:27,474 INFO:     Found new best model at epoch 7
2022-12-05 20:36:27,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:27,475 INFO:     Epoch: 8
2022-12-05 20:36:28,259 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4420300758508749, 'Total loss': 0.4420300758508749} | train loss {'Reaction outcome loss': 0.3222798385703173, 'Total loss': 0.3222798385703173}
2022-12-05 20:36:28,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:28,259 INFO:     Epoch: 9
2022-12-05 20:36:29,042 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43837154362090797, 'Total loss': 0.43837154362090797} | train loss {'Reaction outcome loss': 0.30852668082005663, 'Total loss': 0.30852668082005663}
2022-12-05 20:36:29,043 INFO:     Found new best model at epoch 9
2022-12-05 20:36:29,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:29,044 INFO:     Epoch: 10
2022-12-05 20:36:29,839 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44484962696252867, 'Total loss': 0.44484962696252867} | train loss {'Reaction outcome loss': 0.2945126459674268, 'Total loss': 0.2945126459674268}
2022-12-05 20:36:29,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:29,839 INFO:     Epoch: 11
2022-12-05 20:36:30,639 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.442234905306683, 'Total loss': 0.442234905306683} | train loss {'Reaction outcome loss': 0.28359640253799373, 'Total loss': 0.28359640253799373}
2022-12-05 20:36:30,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:30,640 INFO:     Epoch: 12
2022-12-05 20:36:31,437 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.450815707098606, 'Total loss': 0.450815707098606} | train loss {'Reaction outcome loss': 0.2750219479508576, 'Total loss': 0.2750219479508576}
2022-12-05 20:36:31,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:31,438 INFO:     Epoch: 13
2022-12-05 20:36:32,223 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44974641744480576, 'Total loss': 0.44974641744480576} | train loss {'Reaction outcome loss': 0.26639286813433055, 'Total loss': 0.26639286813433055}
2022-12-05 20:36:32,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:32,223 INFO:     Epoch: 14
2022-12-05 20:36:33,003 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4495763418286346, 'Total loss': 0.4495763418286346} | train loss {'Reaction outcome loss': 0.2553612195169095, 'Total loss': 0.2553612195169095}
2022-12-05 20:36:33,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:33,003 INFO:     Epoch: 15
2022-12-05 20:36:33,791 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4552769595107367, 'Total loss': 0.4552769595107367} | train loss {'Reaction outcome loss': 0.24839813651547568, 'Total loss': 0.24839813651547568}
2022-12-05 20:36:33,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:33,791 INFO:     Epoch: 16
2022-12-05 20:36:34,570 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45852067234904265, 'Total loss': 0.45852067234904265} | train loss {'Reaction outcome loss': 0.24134317779394446, 'Total loss': 0.24134317779394446}
2022-12-05 20:36:34,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:34,570 INFO:     Epoch: 17
2022-12-05 20:36:35,350 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4430933345195859, 'Total loss': 0.4430933345195859} | train loss {'Reaction outcome loss': 0.23385082356265333, 'Total loss': 0.23385082356265333}
2022-12-05 20:36:35,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:35,350 INFO:     Epoch: 18
2022-12-05 20:36:36,131 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4561997250069019, 'Total loss': 0.4561997250069019} | train loss {'Reaction outcome loss': 0.23005482559016005, 'Total loss': 0.23005482559016005}
2022-12-05 20:36:36,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:36,131 INFO:     Epoch: 19
2022-12-05 20:36:36,918 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.458428451834723, 'Total loss': 0.458428451834723} | train loss {'Reaction outcome loss': 0.22463148435364005, 'Total loss': 0.22463148435364005}
2022-12-05 20:36:36,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:36,919 INFO:     Epoch: 20
2022-12-05 20:36:37,696 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44978035258692367, 'Total loss': 0.44978035258692367} | train loss {'Reaction outcome loss': 0.21957312641879084, 'Total loss': 0.21957312641879084}
2022-12-05 20:36:37,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:37,697 INFO:     Epoch: 21
2022-12-05 20:36:38,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4650319471608761, 'Total loss': 0.4650319471608761} | train loss {'Reaction outcome loss': 0.21332647669755045, 'Total loss': 0.21332647669755045}
2022-12-05 20:36:38,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:38,480 INFO:     Epoch: 22
2022-12-05 20:36:39,263 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4594000383865002, 'Total loss': 0.4594000383865002} | train loss {'Reaction outcome loss': 0.2069846532903001, 'Total loss': 0.2069846532903001}
2022-12-05 20:36:39,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:39,264 INFO:     Epoch: 23
2022-12-05 20:36:40,046 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45715313283509984, 'Total loss': 0.45715313283509984} | train loss {'Reaction outcome loss': 0.20369062189501327, 'Total loss': 0.20369062189501327}
2022-12-05 20:36:40,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:40,046 INFO:     Epoch: 24
2022-12-05 20:36:40,832 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46200344139753385, 'Total loss': 0.46200344139753385} | train loss {'Reaction outcome loss': 0.197770501013662, 'Total loss': 0.197770501013662}
2022-12-05 20:36:40,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:40,832 INFO:     Epoch: 25
2022-12-05 20:36:41,628 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4800450670164685, 'Total loss': 0.4800450670164685} | train loss {'Reaction outcome loss': 0.19735111148844733, 'Total loss': 0.19735111148844733}
2022-12-05 20:36:41,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:41,629 INFO:     Epoch: 26
2022-12-05 20:36:42,416 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46688979898774347, 'Total loss': 0.46688979898774347} | train loss {'Reaction outcome loss': 0.1923729678860209, 'Total loss': 0.1923729678860209}
2022-12-05 20:36:42,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:42,416 INFO:     Epoch: 27
2022-12-05 20:36:43,208 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46654086438722386, 'Total loss': 0.46654086438722386} | train loss {'Reaction outcome loss': 0.18815756131146774, 'Total loss': 0.18815756131146774}
2022-12-05 20:36:43,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:43,208 INFO:     Epoch: 28
2022-12-05 20:36:43,995 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4705529982267424, 'Total loss': 0.4705529982267424} | train loss {'Reaction outcome loss': 0.18426698052370158, 'Total loss': 0.18426698052370158}
2022-12-05 20:36:43,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:43,995 INFO:     Epoch: 29
2022-12-05 20:36:44,784 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47399451133123666, 'Total loss': 0.47399451133123666} | train loss {'Reaction outcome loss': 0.1810292360891939, 'Total loss': 0.1810292360891939}
2022-12-05 20:36:44,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:44,784 INFO:     Epoch: 30
2022-12-05 20:36:45,569 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4667668477740399, 'Total loss': 0.4667668477740399} | train loss {'Reaction outcome loss': 0.17922161976028173, 'Total loss': 0.17922161976028173}
2022-12-05 20:36:45,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:45,569 INFO:     Epoch: 31
2022-12-05 20:36:46,367 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48490486415319667, 'Total loss': 0.48490486415319667} | train loss {'Reaction outcome loss': 0.17570404735867118, 'Total loss': 0.17570404735867118}
2022-12-05 20:36:46,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:46,367 INFO:     Epoch: 32
2022-12-05 20:36:47,153 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49397824392762296, 'Total loss': 0.49397824392762296} | train loss {'Reaction outcome loss': 0.17432058236149492, 'Total loss': 0.17432058236149492}
2022-12-05 20:36:47,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:47,153 INFO:     Epoch: 33
2022-12-05 20:36:47,942 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4715749274852664, 'Total loss': 0.4715749274852664} | train loss {'Reaction outcome loss': 0.17184037702982544, 'Total loss': 0.17184037702982544}
2022-12-05 20:36:47,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:47,942 INFO:     Epoch: 34
2022-12-05 20:36:48,723 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47487512438796287, 'Total loss': 0.47487512438796287} | train loss {'Reaction outcome loss': 0.17003554683255, 'Total loss': 0.17003554683255}
2022-12-05 20:36:48,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:48,724 INFO:     Epoch: 35
2022-12-05 20:36:49,510 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.481659245698951, 'Total loss': 0.481659245698951} | train loss {'Reaction outcome loss': 0.16892982597203285, 'Total loss': 0.16892982597203285}
2022-12-05 20:36:49,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:49,510 INFO:     Epoch: 36
2022-12-05 20:36:50,292 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4708432274502377, 'Total loss': 0.4708432274502377} | train loss {'Reaction outcome loss': 0.16773644489709472, 'Total loss': 0.16773644489709472}
2022-12-05 20:36:50,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:50,292 INFO:     Epoch: 37
2022-12-05 20:36:51,070 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4787597139907438, 'Total loss': 0.4787597139907438} | train loss {'Reaction outcome loss': 0.1612738039894182, 'Total loss': 0.1612738039894182}
2022-12-05 20:36:51,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:51,071 INFO:     Epoch: 38
2022-12-05 20:36:51,854 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4940993425457977, 'Total loss': 0.4940993425457977} | train loss {'Reaction outcome loss': 0.1598698674456873, 'Total loss': 0.1598698674456873}
2022-12-05 20:36:51,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:51,854 INFO:     Epoch: 39
2022-12-05 20:36:52,632 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4775624098472817, 'Total loss': 0.4775624098472817} | train loss {'Reaction outcome loss': 0.16083165638331995, 'Total loss': 0.16083165638331995}
2022-12-05 20:36:52,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:52,633 INFO:     Epoch: 40
2022-12-05 20:36:53,411 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47462849249673444, 'Total loss': 0.47462849249673444} | train loss {'Reaction outcome loss': 0.15648767120036922, 'Total loss': 0.15648767120036922}
2022-12-05 20:36:53,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:53,412 INFO:     Epoch: 41
2022-12-05 20:36:54,191 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4909097753291906, 'Total loss': 0.4909097753291906} | train loss {'Reaction outcome loss': 0.15510073010275355, 'Total loss': 0.15510073010275355}
2022-12-05 20:36:54,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:54,191 INFO:     Epoch: 42
2022-12-05 20:36:54,968 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47779965470003527, 'Total loss': 0.47779965470003527} | train loss {'Reaction outcome loss': 0.15855418810559835, 'Total loss': 0.15855418810559835}
2022-12-05 20:36:54,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:54,968 INFO:     Epoch: 43
2022-12-05 20:36:55,747 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4757832690726879, 'Total loss': 0.4757832690726879} | train loss {'Reaction outcome loss': 0.15215370015500754, 'Total loss': 0.15215370015500754}
2022-12-05 20:36:55,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:55,748 INFO:     Epoch: 44
2022-12-05 20:36:56,534 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4857910753682602, 'Total loss': 0.4857910753682602} | train loss {'Reaction outcome loss': 0.15521778874709957, 'Total loss': 0.15521778874709957}
2022-12-05 20:36:56,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:56,534 INFO:     Epoch: 45
2022-12-05 20:36:57,313 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.502372569816057, 'Total loss': 0.502372569816057} | train loss {'Reaction outcome loss': 0.14863762409105652, 'Total loss': 0.14863762409105652}
2022-12-05 20:36:57,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:57,314 INFO:     Epoch: 46
2022-12-05 20:36:58,090 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4919792472623115, 'Total loss': 0.4919792472623115} | train loss {'Reaction outcome loss': 0.14919453565809937, 'Total loss': 0.14919453565809937}
2022-12-05 20:36:58,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:58,091 INFO:     Epoch: 47
2022-12-05 20:36:58,866 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4933782952815987, 'Total loss': 0.4933782952815987} | train loss {'Reaction outcome loss': 0.14550595305722636, 'Total loss': 0.14550595305722636}
2022-12-05 20:36:58,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:58,866 INFO:     Epoch: 48
2022-12-05 20:36:59,643 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4777815761261208, 'Total loss': 0.4777815761261208} | train loss {'Reaction outcome loss': 0.14759623778785472, 'Total loss': 0.14759623778785472}
2022-12-05 20:36:59,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:36:59,644 INFO:     Epoch: 49
2022-12-05 20:37:00,424 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4956629324791043, 'Total loss': 0.4956629324791043} | train loss {'Reaction outcome loss': 0.14558209224649873, 'Total loss': 0.14558209224649873}
2022-12-05 20:37:00,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:00,425 INFO:     Epoch: 50
2022-12-05 20:37:01,205 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5010111480951309, 'Total loss': 0.5010111480951309} | train loss {'Reaction outcome loss': 0.14589816449423793, 'Total loss': 0.14589816449423793}
2022-12-05 20:37:01,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:01,206 INFO:     Epoch: 51
2022-12-05 20:37:01,984 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4910028438235438, 'Total loss': 0.4910028438235438} | train loss {'Reaction outcome loss': 0.14671249628891467, 'Total loss': 0.14671249628891467}
2022-12-05 20:37:01,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:01,985 INFO:     Epoch: 52
2022-12-05 20:37:02,763 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48048440661541253, 'Total loss': 0.48048440661541253} | train loss {'Reaction outcome loss': 0.1446345614223573, 'Total loss': 0.1446345614223573}
2022-12-05 20:37:02,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:02,763 INFO:     Epoch: 53
2022-12-05 20:37:03,542 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4916789791611738, 'Total loss': 0.4916789791611738} | train loss {'Reaction outcome loss': 0.14039203792535623, 'Total loss': 0.14039203792535623}
2022-12-05 20:37:03,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:03,542 INFO:     Epoch: 54
2022-12-05 20:37:04,317 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4888487950313923, 'Total loss': 0.4888487950313923} | train loss {'Reaction outcome loss': 0.14016773312001443, 'Total loss': 0.14016773312001443}
2022-12-05 20:37:04,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:04,317 INFO:     Epoch: 55
2022-12-05 20:37:05,098 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48713767424572346, 'Total loss': 0.48713767424572346} | train loss {'Reaction outcome loss': 0.14305769819308256, 'Total loss': 0.14305769819308256}
2022-12-05 20:37:05,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:05,098 INFO:     Epoch: 56
2022-12-05 20:37:05,875 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5031347538149634, 'Total loss': 0.5031347538149634} | train loss {'Reaction outcome loss': 0.13821584945086574, 'Total loss': 0.13821584945086574}
2022-12-05 20:37:05,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:05,876 INFO:     Epoch: 57
2022-12-05 20:37:06,651 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47791959865148675, 'Total loss': 0.47791959865148675} | train loss {'Reaction outcome loss': 0.13648511186913878, 'Total loss': 0.13648511186913878}
2022-12-05 20:37:06,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:06,651 INFO:     Epoch: 58
2022-12-05 20:37:07,432 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49430699923703836, 'Total loss': 0.49430699923703836} | train loss {'Reaction outcome loss': 0.13799653485508973, 'Total loss': 0.13799653485508973}
2022-12-05 20:37:07,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:07,432 INFO:     Epoch: 59
2022-12-05 20:37:08,208 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4939071123683175, 'Total loss': 0.4939071123683175} | train loss {'Reaction outcome loss': 0.13389412867912992, 'Total loss': 0.13389412867912992}
2022-12-05 20:37:08,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:08,208 INFO:     Epoch: 60
2022-12-05 20:37:08,984 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49443690444147864, 'Total loss': 0.49443690444147864} | train loss {'Reaction outcome loss': 0.1347810817943489, 'Total loss': 0.1347810817943489}
2022-12-05 20:37:08,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:08,985 INFO:     Epoch: 61
2022-12-05 20:37:09,762 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.486463024172672, 'Total loss': 0.486463024172672} | train loss {'Reaction outcome loss': 0.13447912954954339, 'Total loss': 0.13447912954954339}
2022-12-05 20:37:09,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:09,762 INFO:     Epoch: 62
2022-12-05 20:37:10,538 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48477162004903307, 'Total loss': 0.48477162004903307} | train loss {'Reaction outcome loss': 0.13463504990318514, 'Total loss': 0.13463504990318514}
2022-12-05 20:37:10,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:10,538 INFO:     Epoch: 63
2022-12-05 20:37:11,322 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48723364430804583, 'Total loss': 0.48723364430804583} | train loss {'Reaction outcome loss': 0.13143215249445228, 'Total loss': 0.13143215249445228}
2022-12-05 20:37:11,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:11,322 INFO:     Epoch: 64
2022-12-05 20:37:12,101 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4796269875626231, 'Total loss': 0.4796269875626231} | train loss {'Reaction outcome loss': 0.1347656356338717, 'Total loss': 0.1347656356338717}
2022-12-05 20:37:12,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:12,102 INFO:     Epoch: 65
2022-12-05 20:37:12,881 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4841157534094744, 'Total loss': 0.4841157534094744} | train loss {'Reaction outcome loss': 0.13172062442897528, 'Total loss': 0.13172062442897528}
2022-12-05 20:37:12,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:12,881 INFO:     Epoch: 66
2022-12-05 20:37:13,663 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4891524810430615, 'Total loss': 0.4891524810430615} | train loss {'Reaction outcome loss': 0.1302109555280233, 'Total loss': 0.1302109555280233}
2022-12-05 20:37:13,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:13,663 INFO:     Epoch: 67
2022-12-05 20:37:14,443 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4860278679880985, 'Total loss': 0.4860278679880985} | train loss {'Reaction outcome loss': 0.12914505197865064, 'Total loss': 0.12914505197865064}
2022-12-05 20:37:14,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:14,443 INFO:     Epoch: 68
2022-12-05 20:37:15,221 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48651399168857307, 'Total loss': 0.48651399168857307} | train loss {'Reaction outcome loss': 0.13284721736582455, 'Total loss': 0.13284721736582455}
2022-12-05 20:37:15,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:15,222 INFO:     Epoch: 69
2022-12-05 20:37:15,997 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4975447633931803, 'Total loss': 0.4975447633931803} | train loss {'Reaction outcome loss': 0.12701436137536265, 'Total loss': 0.12701436137536265}
2022-12-05 20:37:15,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:15,997 INFO:     Epoch: 70
2022-12-05 20:37:16,776 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47530845362086627, 'Total loss': 0.47530845362086627} | train loss {'Reaction outcome loss': 0.1309692780868929, 'Total loss': 0.1309692780868929}
2022-12-05 20:37:16,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:16,776 INFO:     Epoch: 71
2022-12-05 20:37:17,554 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4892285875109739, 'Total loss': 0.4892285875109739} | train loss {'Reaction outcome loss': 0.12862327484200237, 'Total loss': 0.12862327484200237}
2022-12-05 20:37:17,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:17,554 INFO:     Epoch: 72
2022-12-05 20:37:18,332 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4996326142965361, 'Total loss': 0.4996326142965361} | train loss {'Reaction outcome loss': 0.130064871643105, 'Total loss': 0.130064871643105}
2022-12-05 20:37:18,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:18,333 INFO:     Epoch: 73
2022-12-05 20:37:19,108 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47709331158981766, 'Total loss': 0.47709331158981766} | train loss {'Reaction outcome loss': 0.12620527653374755, 'Total loss': 0.12620527653374755}
2022-12-05 20:37:19,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:19,108 INFO:     Epoch: 74
2022-12-05 20:37:19,882 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4897303699060928, 'Total loss': 0.4897303699060928} | train loss {'Reaction outcome loss': 0.12942903931634347, 'Total loss': 0.12942903931634347}
2022-12-05 20:37:19,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:19,882 INFO:     Epoch: 75
2022-12-05 20:37:20,656 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48297133244747337, 'Total loss': 0.48297133244747337} | train loss {'Reaction outcome loss': 0.1305128260301884, 'Total loss': 0.1305128260301884}
2022-12-05 20:37:20,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:20,657 INFO:     Epoch: 76
2022-12-05 20:37:21,430 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5047174345615298, 'Total loss': 0.5047174345615298} | train loss {'Reaction outcome loss': 0.12701910388747567, 'Total loss': 0.12701910388747567}
2022-12-05 20:37:21,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:21,430 INFO:     Epoch: 77
2022-12-05 20:37:22,204 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4865786651539248, 'Total loss': 0.4865786651539248} | train loss {'Reaction outcome loss': 0.12522959856881347, 'Total loss': 0.12522959856881347}
2022-12-05 20:37:22,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:22,205 INFO:     Epoch: 78
2022-12-05 20:37:22,980 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49133998883325, 'Total loss': 0.49133998883325} | train loss {'Reaction outcome loss': 0.12728149304548125, 'Total loss': 0.12728149304548125}
2022-12-05 20:37:22,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:22,980 INFO:     Epoch: 79
2022-12-05 20:37:23,760 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4990890566692796, 'Total loss': 0.4990890566692796} | train loss {'Reaction outcome loss': 0.12575902168440525, 'Total loss': 0.12575902168440525}
2022-12-05 20:37:23,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:23,760 INFO:     Epoch: 80
2022-12-05 20:37:24,542 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.50063847074675, 'Total loss': 0.50063847074675} | train loss {'Reaction outcome loss': 0.12684083158974765, 'Total loss': 0.12684083158974765}
2022-12-05 20:37:24,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:24,542 INFO:     Epoch: 81
2022-12-05 20:37:25,321 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4957787768785344, 'Total loss': 0.4957787768785344} | train loss {'Reaction outcome loss': 0.12479936193338916, 'Total loss': 0.12479936193338916}
2022-12-05 20:37:25,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:25,322 INFO:     Epoch: 82
2022-12-05 20:37:26,101 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4885321543660275, 'Total loss': 0.4885321543660275} | train loss {'Reaction outcome loss': 0.12560797159819573, 'Total loss': 0.12560797159819573}
2022-12-05 20:37:26,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:26,101 INFO:     Epoch: 83
2022-12-05 20:37:26,880 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.502329275358555, 'Total loss': 0.502329275358555} | train loss {'Reaction outcome loss': 0.12323592724965611, 'Total loss': 0.12323592724965611}
2022-12-05 20:37:26,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:26,881 INFO:     Epoch: 84
2022-12-05 20:37:27,659 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49073263725569083, 'Total loss': 0.49073263725569083} | train loss {'Reaction outcome loss': 0.12408432237742865, 'Total loss': 0.12408432237742865}
2022-12-05 20:37:27,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:27,660 INFO:     Epoch: 85
2022-12-05 20:37:28,438 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49020503288091616, 'Total loss': 0.49020503288091616} | train loss {'Reaction outcome loss': 0.12310369751706231, 'Total loss': 0.12310369751706231}
2022-12-05 20:37:28,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:28,438 INFO:     Epoch: 86
2022-12-05 20:37:29,221 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49328700054523555, 'Total loss': 0.49328700054523555} | train loss {'Reaction outcome loss': 0.1222735427045187, 'Total loss': 0.1222735427045187}
2022-12-05 20:37:29,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:29,221 INFO:     Epoch: 87
2022-12-05 20:37:29,999 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4960177048694256, 'Total loss': 0.4960177048694256} | train loss {'Reaction outcome loss': 0.12433137068883746, 'Total loss': 0.12433137068883746}
2022-12-05 20:37:30,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:30,000 INFO:     Epoch: 88
2022-12-05 20:37:30,788 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4809974005749059, 'Total loss': 0.4809974005749059} | train loss {'Reaction outcome loss': 0.12239728474867392, 'Total loss': 0.12239728474867392}
2022-12-05 20:37:30,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:30,788 INFO:     Epoch: 89
2022-12-05 20:37:31,587 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49679192484811296, 'Total loss': 0.49679192484811296} | train loss {'Reaction outcome loss': 0.12191871034179921, 'Total loss': 0.12191871034179921}
2022-12-05 20:37:31,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:31,588 INFO:     Epoch: 90
2022-12-05 20:37:32,383 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49221484640309976, 'Total loss': 0.49221484640309976} | train loss {'Reaction outcome loss': 0.12255781375589307, 'Total loss': 0.12255781375589307}
2022-12-05 20:37:32,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:32,383 INFO:     Epoch: 91
2022-12-05 20:37:33,177 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48975147064342056, 'Total loss': 0.48975147064342056} | train loss {'Reaction outcome loss': 0.12306683909789216, 'Total loss': 0.12306683909789216}
2022-12-05 20:37:33,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:33,177 INFO:     Epoch: 92
2022-12-05 20:37:33,974 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5012405854324962, 'Total loss': 0.5012405854324962} | train loss {'Reaction outcome loss': 0.12176131880765811, 'Total loss': 0.12176131880765811}
2022-12-05 20:37:33,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:33,974 INFO:     Epoch: 93
2022-12-05 20:37:34,767 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48816599679547684, 'Total loss': 0.48816599679547684} | train loss {'Reaction outcome loss': 0.11907681123903174, 'Total loss': 0.11907681123903174}
2022-12-05 20:37:34,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:34,767 INFO:     Epoch: 94
2022-12-05 20:37:35,560 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4940338370411895, 'Total loss': 0.4940338370411895} | train loss {'Reaction outcome loss': 0.1196329250519515, 'Total loss': 0.1196329250519515}
2022-12-05 20:37:35,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:35,560 INFO:     Epoch: 95
2022-12-05 20:37:36,347 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4787735973679742, 'Total loss': 0.4787735973679742} | train loss {'Reaction outcome loss': 0.1185341132747498, 'Total loss': 0.1185341132747498}
2022-12-05 20:37:36,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:36,347 INFO:     Epoch: 96
2022-12-05 20:37:37,136 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.510874371542487, 'Total loss': 0.510874371542487} | train loss {'Reaction outcome loss': 0.11965608461301958, 'Total loss': 0.11965608461301958}
2022-12-05 20:37:37,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:37,136 INFO:     Epoch: 97
2022-12-05 20:37:37,928 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49844180601973864, 'Total loss': 0.49844180601973864} | train loss {'Reaction outcome loss': 0.12150202949958869, 'Total loss': 0.12150202949958869}
2022-12-05 20:37:37,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:37,928 INFO:     Epoch: 98
2022-12-05 20:37:38,715 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5208348274924034, 'Total loss': 0.5208348274924034} | train loss {'Reaction outcome loss': 0.11757257420447517, 'Total loss': 0.11757257420447517}
2022-12-05 20:37:38,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:38,715 INFO:     Epoch: 99
2022-12-05 20:37:39,502 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4979708141019178, 'Total loss': 0.4979708141019178} | train loss {'Reaction outcome loss': 0.12014716262852804, 'Total loss': 0.12014716262852804}
2022-12-05 20:37:39,502 INFO:     Best model found after epoch 10 of 100.
2022-12-05 20:37:39,502 INFO:   Done with stage: TRAINING
2022-12-05 20:37:39,502 INFO:   Starting stage: EVALUATION
2022-12-05 20:37:39,638 INFO:   Done with stage: EVALUATION
2022-12-05 20:37:39,639 INFO:   Leaving out SEQ value Fold_8
2022-12-05 20:37:39,651 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:37:39,651 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:37:40,295 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:37:40,295 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:37:40,364 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:37:40,364 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:37:40,364 INFO:     No hyperparam tuning for this model
2022-12-05 20:37:40,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:37:40,364 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:37:40,365 INFO:     None feature selector for col prot
2022-12-05 20:37:40,365 INFO:     None feature selector for col prot
2022-12-05 20:37:40,365 INFO:     None feature selector for col prot
2022-12-05 20:37:40,366 INFO:     None feature selector for col chem
2022-12-05 20:37:40,366 INFO:     None feature selector for col chem
2022-12-05 20:37:40,366 INFO:     None feature selector for col chem
2022-12-05 20:37:40,366 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:37:40,366 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:37:40,367 INFO:     Number of params in model 215821
2022-12-05 20:37:40,371 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:37:40,371 INFO:   Starting stage: TRAINING
2022-12-05 20:37:40,432 INFO:     Val loss before train {'Reaction outcome loss': 0.9835038367997516, 'Total loss': 0.9835038367997516}
2022-12-05 20:37:40,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:40,433 INFO:     Epoch: 0
2022-12-05 20:37:41,231 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5691855566745455, 'Total loss': 0.5691855566745455} | train loss {'Reaction outcome loss': 0.8041916618704313, 'Total loss': 0.8041916618704313}
2022-12-05 20:37:41,231 INFO:     Found new best model at epoch 0
2022-12-05 20:37:41,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:41,232 INFO:     Epoch: 1
2022-12-05 20:37:42,031 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5015227002176371, 'Total loss': 0.5015227002176371} | train loss {'Reaction outcome loss': 0.532189621443027, 'Total loss': 0.532189621443027}
2022-12-05 20:37:42,031 INFO:     Found new best model at epoch 1
2022-12-05 20:37:42,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:42,032 INFO:     Epoch: 2
2022-12-05 20:37:42,831 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4702435034242543, 'Total loss': 0.4702435034242543} | train loss {'Reaction outcome loss': 0.46437955255571167, 'Total loss': 0.46437955255571167}
2022-12-05 20:37:42,832 INFO:     Found new best model at epoch 2
2022-12-05 20:37:42,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:42,832 INFO:     Epoch: 3
2022-12-05 20:37:43,636 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4436468393965201, 'Total loss': 0.4436468393965201} | train loss {'Reaction outcome loss': 0.42598421134145154, 'Total loss': 0.42598421134145154}
2022-12-05 20:37:43,637 INFO:     Found new best model at epoch 3
2022-12-05 20:37:43,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:43,638 INFO:     Epoch: 4
2022-12-05 20:37:44,434 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42423119429837575, 'Total loss': 0.42423119429837575} | train loss {'Reaction outcome loss': 0.40173588469926164, 'Total loss': 0.40173588469926164}
2022-12-05 20:37:44,434 INFO:     Found new best model at epoch 4
2022-12-05 20:37:44,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:44,435 INFO:     Epoch: 5
2022-12-05 20:37:45,233 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4196439663117582, 'Total loss': 0.4196439663117582} | train loss {'Reaction outcome loss': 0.3801416315530476, 'Total loss': 0.3801416315530476}
2022-12-05 20:37:45,233 INFO:     Found new best model at epoch 5
2022-12-05 20:37:45,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:45,234 INFO:     Epoch: 6
2022-12-05 20:37:46,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4185789149593223, 'Total loss': 0.4185789149593223} | train loss {'Reaction outcome loss': 0.36139096615285526, 'Total loss': 0.36139096615285526}
2022-12-05 20:37:46,038 INFO:     Found new best model at epoch 6
2022-12-05 20:37:46,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:46,039 INFO:     Epoch: 7
2022-12-05 20:37:46,836 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40676444870504463, 'Total loss': 0.40676444870504463} | train loss {'Reaction outcome loss': 0.3384568090380927, 'Total loss': 0.3384568090380927}
2022-12-05 20:37:46,836 INFO:     Found new best model at epoch 7
2022-12-05 20:37:46,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:46,837 INFO:     Epoch: 8
2022-12-05 20:37:47,641 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40698347748680547, 'Total loss': 0.40698347748680547} | train loss {'Reaction outcome loss': 0.3274463339735139, 'Total loss': 0.3274463339735139}
2022-12-05 20:37:47,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:47,641 INFO:     Epoch: 9
2022-12-05 20:37:48,449 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40898980877616187, 'Total loss': 0.40898980877616187} | train loss {'Reaction outcome loss': 0.3134038112001863, 'Total loss': 0.3134038112001863}
2022-12-05 20:37:48,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:48,449 INFO:     Epoch: 10
2022-12-05 20:37:49,256 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3989099822938442, 'Total loss': 0.3989099822938442} | train loss {'Reaction outcome loss': 0.29881798595506776, 'Total loss': 0.29881798595506776}
2022-12-05 20:37:49,256 INFO:     Found new best model at epoch 10
2022-12-05 20:37:49,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:49,257 INFO:     Epoch: 11
2022-12-05 20:37:50,058 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38793696446174925, 'Total loss': 0.38793696446174925} | train loss {'Reaction outcome loss': 0.28625218273114095, 'Total loss': 0.28625218273114095}
2022-12-05 20:37:50,058 INFO:     Found new best model at epoch 11
2022-12-05 20:37:50,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:50,059 INFO:     Epoch: 12
2022-12-05 20:37:50,864 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4076969115571542, 'Total loss': 0.4076969115571542} | train loss {'Reaction outcome loss': 0.28078549738355013, 'Total loss': 0.28078549738355013}
2022-12-05 20:37:50,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:50,864 INFO:     Epoch: 13
2022-12-05 20:37:51,665 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38910948197272693, 'Total loss': 0.38910948197272693} | train loss {'Reaction outcome loss': 0.26686336457548354, 'Total loss': 0.26686336457548354}
2022-12-05 20:37:51,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:51,665 INFO:     Epoch: 14
2022-12-05 20:37:52,461 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41058181192387233, 'Total loss': 0.41058181192387233} | train loss {'Reaction outcome loss': 0.25665224204782533, 'Total loss': 0.25665224204782533}
2022-12-05 20:37:52,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:52,461 INFO:     Epoch: 15
2022-12-05 20:37:53,259 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4024569090794433, 'Total loss': 0.4024569090794433} | train loss {'Reaction outcome loss': 0.25113335987816937, 'Total loss': 0.25113335987816937}
2022-12-05 20:37:53,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:53,259 INFO:     Epoch: 16
2022-12-05 20:37:54,055 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39368086714636197, 'Total loss': 0.39368086714636197} | train loss {'Reaction outcome loss': 0.24015042936685776, 'Total loss': 0.24015042936685776}
2022-12-05 20:37:54,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:54,055 INFO:     Epoch: 17
2022-12-05 20:37:54,853 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.398726281455972, 'Total loss': 0.398726281455972} | train loss {'Reaction outcome loss': 0.23256762741653905, 'Total loss': 0.23256762741653905}
2022-12-05 20:37:54,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:54,854 INFO:     Epoch: 18
2022-12-05 20:37:55,652 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39207175407897343, 'Total loss': 0.39207175407897343} | train loss {'Reaction outcome loss': 0.22621377065743845, 'Total loss': 0.22621377065743845}
2022-12-05 20:37:55,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:55,652 INFO:     Epoch: 19
2022-12-05 20:37:56,449 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39761157435449684, 'Total loss': 0.39761157435449684} | train loss {'Reaction outcome loss': 0.22293393790480578, 'Total loss': 0.22293393790480578}
2022-12-05 20:37:56,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:56,451 INFO:     Epoch: 20
2022-12-05 20:37:57,249 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41446692107075994, 'Total loss': 0.41446692107075994} | train loss {'Reaction outcome loss': 0.21816410393518235, 'Total loss': 0.21816410393518235}
2022-12-05 20:37:57,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:57,249 INFO:     Epoch: 21
2022-12-05 20:37:58,049 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4016826532103799, 'Total loss': 0.4016826532103799} | train loss {'Reaction outcome loss': 0.21026918884396914, 'Total loss': 0.21026918884396914}
2022-12-05 20:37:58,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:58,049 INFO:     Epoch: 22
2022-12-05 20:37:58,847 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41251427375457506, 'Total loss': 0.41251427375457506} | train loss {'Reaction outcome loss': 0.20612371878826666, 'Total loss': 0.20612371878826666}
2022-12-05 20:37:58,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:58,848 INFO:     Epoch: 23
2022-12-05 20:37:59,647 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40402363308451394, 'Total loss': 0.40402363308451394} | train loss {'Reaction outcome loss': 0.20154798916929406, 'Total loss': 0.20154798916929406}
2022-12-05 20:37:59,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:37:59,648 INFO:     Epoch: 24
2022-12-05 20:38:00,449 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.412644223394719, 'Total loss': 0.412644223394719} | train loss {'Reaction outcome loss': 0.19518086167150422, 'Total loss': 0.19518086167150422}
2022-12-05 20:38:00,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:00,449 INFO:     Epoch: 25
2022-12-05 20:38:01,245 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4018627530471845, 'Total loss': 0.4018627530471845} | train loss {'Reaction outcome loss': 0.198641177658972, 'Total loss': 0.198641177658972}
2022-12-05 20:38:01,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:01,245 INFO:     Epoch: 26
2022-12-05 20:38:02,040 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3990578180686994, 'Total loss': 0.3990578180686994} | train loss {'Reaction outcome loss': 0.1974343971503891, 'Total loss': 0.1974343971503891}
2022-12-05 20:38:02,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:02,040 INFO:     Epoch: 27
2022-12-05 20:38:02,837 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40267256274819374, 'Total loss': 0.40267256274819374} | train loss {'Reaction outcome loss': 0.19161590868946513, 'Total loss': 0.19161590868946513}
2022-12-05 20:38:02,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:02,838 INFO:     Epoch: 28
2022-12-05 20:38:03,634 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40382271192290564, 'Total loss': 0.40382271192290564} | train loss {'Reaction outcome loss': 0.18988227894009366, 'Total loss': 0.18988227894009366}
2022-12-05 20:38:03,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:03,634 INFO:     Epoch: 29
2022-12-05 20:38:04,430 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40785054286772554, 'Total loss': 0.40785054286772554} | train loss {'Reaction outcome loss': 0.176282933408862, 'Total loss': 0.176282933408862}
2022-12-05 20:38:04,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:04,430 INFO:     Epoch: 30
2022-12-05 20:38:05,229 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4025256630371917, 'Total loss': 0.4025256630371917} | train loss {'Reaction outcome loss': 0.17564569287726028, 'Total loss': 0.17564569287726028}
2022-12-05 20:38:05,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:05,229 INFO:     Epoch: 31
2022-12-05 20:38:06,025 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4131377600133419, 'Total loss': 0.4131377600133419} | train loss {'Reaction outcome loss': 0.17331239031363838, 'Total loss': 0.17331239031363838}
2022-12-05 20:38:06,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:06,025 INFO:     Epoch: 32
2022-12-05 20:38:06,822 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41328939609229565, 'Total loss': 0.41328939609229565} | train loss {'Reaction outcome loss': 0.1759584791249471, 'Total loss': 0.1759584791249471}
2022-12-05 20:38:06,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:06,822 INFO:     Epoch: 33
2022-12-05 20:38:07,619 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41226581297814846, 'Total loss': 0.41226581297814846} | train loss {'Reaction outcome loss': 0.17687711392827182, 'Total loss': 0.17687711392827182}
2022-12-05 20:38:07,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:07,620 INFO:     Epoch: 34
2022-12-05 20:38:08,418 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4226607058874585, 'Total loss': 0.4226607058874585} | train loss {'Reaction outcome loss': 0.16629010154620597, 'Total loss': 0.16629010154620597}
2022-12-05 20:38:08,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:08,419 INFO:     Epoch: 35
2022-12-05 20:38:09,217 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.432184329087084, 'Total loss': 0.432184329087084} | train loss {'Reaction outcome loss': 0.16962404267321368, 'Total loss': 0.16962404267321368}
2022-12-05 20:38:09,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:09,217 INFO:     Epoch: 36
2022-12-05 20:38:10,017 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42030423744158313, 'Total loss': 0.42030423744158313} | train loss {'Reaction outcome loss': 0.16296302529451576, 'Total loss': 0.16296302529451576}
2022-12-05 20:38:10,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:10,017 INFO:     Epoch: 37
2022-12-05 20:38:10,819 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4091112518852407, 'Total loss': 0.4091112518852407} | train loss {'Reaction outcome loss': 0.16238081874514398, 'Total loss': 0.16238081874514398}
2022-12-05 20:38:10,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:10,819 INFO:     Epoch: 38
2022-12-05 20:38:11,619 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4110743740404194, 'Total loss': 0.4110743740404194} | train loss {'Reaction outcome loss': 0.15982284280188713, 'Total loss': 0.15982284280188713}
2022-12-05 20:38:11,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:11,620 INFO:     Epoch: 39
2022-12-05 20:38:12,420 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41846511309797113, 'Total loss': 0.41846511309797113} | train loss {'Reaction outcome loss': 0.15937009699612495, 'Total loss': 0.15937009699612495}
2022-12-05 20:38:12,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:12,420 INFO:     Epoch: 40
2022-12-05 20:38:13,216 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43226665614003484, 'Total loss': 0.43226665614003484} | train loss {'Reaction outcome loss': 0.15743307660707095, 'Total loss': 0.15743307660707095}
2022-12-05 20:38:13,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:13,217 INFO:     Epoch: 41
2022-12-05 20:38:14,013 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4036465216089379, 'Total loss': 0.4036465216089379} | train loss {'Reaction outcome loss': 0.15876116537251453, 'Total loss': 0.15876116537251453}
2022-12-05 20:38:14,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:14,013 INFO:     Epoch: 42
2022-12-05 20:38:14,817 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4322383231060071, 'Total loss': 0.4322383231060071} | train loss {'Reaction outcome loss': 0.15413925724164376, 'Total loss': 0.15413925724164376}
2022-12-05 20:38:14,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:14,817 INFO:     Epoch: 43
2022-12-05 20:38:15,616 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4149721911685033, 'Total loss': 0.4149721911685033} | train loss {'Reaction outcome loss': 0.15284951228784163, 'Total loss': 0.15284951228784163}
2022-12-05 20:38:15,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:15,617 INFO:     Epoch: 44
2022-12-05 20:38:16,412 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4245940466326746, 'Total loss': 0.4245940466326746} | train loss {'Reaction outcome loss': 0.15439775039400408, 'Total loss': 0.15439775039400408}
2022-12-05 20:38:16,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:16,413 INFO:     Epoch: 45
2022-12-05 20:38:17,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42168552919544955, 'Total loss': 0.42168552919544955} | train loss {'Reaction outcome loss': 0.14943919527091779, 'Total loss': 0.14943919527091779}
2022-12-05 20:38:17,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:17,212 INFO:     Epoch: 46
2022-12-05 20:38:18,010 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42581271854313935, 'Total loss': 0.42581271854313935} | train loss {'Reaction outcome loss': 0.1461815372305481, 'Total loss': 0.1461815372305481}
2022-12-05 20:38:18,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:18,010 INFO:     Epoch: 47
2022-12-05 20:38:18,809 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43523795022205874, 'Total loss': 0.43523795022205874} | train loss {'Reaction outcome loss': 0.14859009157820993, 'Total loss': 0.14859009157820993}
2022-12-05 20:38:18,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:18,809 INFO:     Epoch: 48
2022-12-05 20:38:19,607 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41564892122352665, 'Total loss': 0.41564892122352665} | train loss {'Reaction outcome loss': 0.15242689780830612, 'Total loss': 0.15242689780830612}
2022-12-05 20:38:19,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:19,607 INFO:     Epoch: 49
2022-12-05 20:38:20,403 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42492057162929664, 'Total loss': 0.42492057162929664} | train loss {'Reaction outcome loss': 0.16191486505648264, 'Total loss': 0.16191486505648264}
2022-12-05 20:38:20,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:20,403 INFO:     Epoch: 50
2022-12-05 20:38:21,201 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4103685004467314, 'Total loss': 0.4103685004467314} | train loss {'Reaction outcome loss': 0.1478490939642857, 'Total loss': 0.1478490939642857}
2022-12-05 20:38:21,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:21,202 INFO:     Epoch: 51
2022-12-05 20:38:21,997 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4183724912052805, 'Total loss': 0.4183724912052805} | train loss {'Reaction outcome loss': 0.15369998105530164, 'Total loss': 0.15369998105530164}
2022-12-05 20:38:21,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:21,997 INFO:     Epoch: 52
2022-12-05 20:38:22,794 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41853180155158043, 'Total loss': 0.41853180155158043} | train loss {'Reaction outcome loss': 0.14843596827223715, 'Total loss': 0.14843596827223715}
2022-12-05 20:38:22,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:22,794 INFO:     Epoch: 53
2022-12-05 20:38:23,592 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41747369295494124, 'Total loss': 0.41747369295494124} | train loss {'Reaction outcome loss': 0.15356185388287552, 'Total loss': 0.15356185388287552}
2022-12-05 20:38:23,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:23,593 INFO:     Epoch: 54
2022-12-05 20:38:24,388 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4226603450422937, 'Total loss': 0.4226603450422937} | train loss {'Reaction outcome loss': 0.14608396262874043, 'Total loss': 0.14608396262874043}
2022-12-05 20:38:24,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:24,388 INFO:     Epoch: 55
2022-12-05 20:38:25,184 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4264558599415151, 'Total loss': 0.4264558599415151} | train loss {'Reaction outcome loss': 0.13852523447877843, 'Total loss': 0.13852523447877843}
2022-12-05 20:38:25,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:25,184 INFO:     Epoch: 56
2022-12-05 20:38:25,981 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.424781743098389, 'Total loss': 0.424781743098389} | train loss {'Reaction outcome loss': 0.13628831265215208, 'Total loss': 0.13628831265215208}
2022-12-05 20:38:25,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:25,982 INFO:     Epoch: 57
2022-12-05 20:38:26,779 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41373940294777806, 'Total loss': 0.41373940294777806} | train loss {'Reaction outcome loss': 0.1382606129222342, 'Total loss': 0.1382606129222342}
2022-12-05 20:38:26,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:26,779 INFO:     Epoch: 58
2022-12-05 20:38:27,576 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4189605340361595, 'Total loss': 0.4189605340361595} | train loss {'Reaction outcome loss': 0.13618522582326822, 'Total loss': 0.13618522582326822}
2022-12-05 20:38:27,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:27,577 INFO:     Epoch: 59
2022-12-05 20:38:28,382 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42241397974166, 'Total loss': 0.42241397974166} | train loss {'Reaction outcome loss': 0.1359719803051548, 'Total loss': 0.1359719803051548}
2022-12-05 20:38:28,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:28,382 INFO:     Epoch: 60
2022-12-05 20:38:29,183 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.430711249566891, 'Total loss': 0.430711249566891} | train loss {'Reaction outcome loss': 0.13608241059180154, 'Total loss': 0.13608241059180154}
2022-12-05 20:38:29,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:29,183 INFO:     Epoch: 61
2022-12-05 20:38:29,987 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42056414027783, 'Total loss': 0.42056414027783} | train loss {'Reaction outcome loss': 0.13697953122528458, 'Total loss': 0.13697953122528458}
2022-12-05 20:38:29,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:29,987 INFO:     Epoch: 62
2022-12-05 20:38:30,785 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.408936701037667, 'Total loss': 0.408936701037667} | train loss {'Reaction outcome loss': 0.14325523619146013, 'Total loss': 0.14325523619146013}
2022-12-05 20:38:30,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:30,785 INFO:     Epoch: 63
2022-12-05 20:38:31,581 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42840165238488803, 'Total loss': 0.42840165238488803} | train loss {'Reaction outcome loss': 0.13713501616256682, 'Total loss': 0.13713501616256682}
2022-12-05 20:38:31,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:31,581 INFO:     Epoch: 64
2022-12-05 20:38:32,382 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43781510266390716, 'Total loss': 0.43781510266390716} | train loss {'Reaction outcome loss': 0.14100701015005226, 'Total loss': 0.14100701015005226}
2022-12-05 20:38:32,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:32,382 INFO:     Epoch: 65
2022-12-05 20:38:33,180 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43572534349831665, 'Total loss': 0.43572534349831665} | train loss {'Reaction outcome loss': 0.13762975697168092, 'Total loss': 0.13762975697168092}
2022-12-05 20:38:33,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:33,180 INFO:     Epoch: 66
2022-12-05 20:38:33,982 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42626605318351224, 'Total loss': 0.42626605318351224} | train loss {'Reaction outcome loss': 0.1340518386370921, 'Total loss': 0.1340518386370921}
2022-12-05 20:38:33,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:33,983 INFO:     Epoch: 67
2022-12-05 20:38:34,780 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43571680276231334, 'Total loss': 0.43571680276231334} | train loss {'Reaction outcome loss': 0.134416907298028, 'Total loss': 0.134416907298028}
2022-12-05 20:38:34,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:34,780 INFO:     Epoch: 68
2022-12-05 20:38:35,577 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4287978288802234, 'Total loss': 0.4287978288802234} | train loss {'Reaction outcome loss': 0.13355842966073558, 'Total loss': 0.13355842966073558}
2022-12-05 20:38:35,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:35,577 INFO:     Epoch: 69
2022-12-05 20:38:36,375 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4313687878576192, 'Total loss': 0.4313687878576192} | train loss {'Reaction outcome loss': 0.13258995626287662, 'Total loss': 0.13258995626287662}
2022-12-05 20:38:36,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:36,375 INFO:     Epoch: 70
2022-12-05 20:38:37,173 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.434676453132521, 'Total loss': 0.434676453132521} | train loss {'Reaction outcome loss': 0.13154287097140438, 'Total loss': 0.13154287097140438}
2022-12-05 20:38:37,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:37,173 INFO:     Epoch: 71
2022-12-05 20:38:37,976 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4401390220631253, 'Total loss': 0.4401390220631253} | train loss {'Reaction outcome loss': 0.12992619919149498, 'Total loss': 0.12992619919149498}
2022-12-05 20:38:37,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:37,976 INFO:     Epoch: 72
2022-12-05 20:38:38,772 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4424671567976475, 'Total loss': 0.4424671567976475} | train loss {'Reaction outcome loss': 0.12634523352419558, 'Total loss': 0.12634523352419558}
2022-12-05 20:38:38,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:38,773 INFO:     Epoch: 73
2022-12-05 20:38:39,568 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4186390723017129, 'Total loss': 0.4186390723017129} | train loss {'Reaction outcome loss': 0.12723716185145412, 'Total loss': 0.12723716185145412}
2022-12-05 20:38:39,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:39,568 INFO:     Epoch: 74
2022-12-05 20:38:40,368 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42626832967454736, 'Total loss': 0.42626832967454736} | train loss {'Reaction outcome loss': 0.1276618556226962, 'Total loss': 0.1276618556226962}
2022-12-05 20:38:40,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:40,368 INFO:     Epoch: 75
2022-12-05 20:38:41,167 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4201442140196873, 'Total loss': 0.4201442140196873} | train loss {'Reaction outcome loss': 0.12705370950086517, 'Total loss': 0.12705370950086517}
2022-12-05 20:38:41,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:41,167 INFO:     Epoch: 76
2022-12-05 20:38:41,966 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4208599698137153, 'Total loss': 0.4208599698137153} | train loss {'Reaction outcome loss': 0.12816469920308968, 'Total loss': 0.12816469920308968}
2022-12-05 20:38:41,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:41,966 INFO:     Epoch: 77
2022-12-05 20:38:42,766 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43096753785556013, 'Total loss': 0.43096753785556013} | train loss {'Reaction outcome loss': 0.12746447313441198, 'Total loss': 0.12746447313441198}
2022-12-05 20:38:42,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:42,766 INFO:     Epoch: 78
2022-12-05 20:38:43,567 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4194965931502255, 'Total loss': 0.4194965931502255} | train loss {'Reaction outcome loss': 0.12776764411750713, 'Total loss': 0.12776764411750713}
2022-12-05 20:38:43,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:43,567 INFO:     Epoch: 79
2022-12-05 20:38:44,368 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43195932087573136, 'Total loss': 0.43195932087573136} | train loss {'Reaction outcome loss': 0.12645525172063402, 'Total loss': 0.12645525172063402}
2022-12-05 20:38:44,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:44,368 INFO:     Epoch: 80
2022-12-05 20:38:45,166 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4356452497568997, 'Total loss': 0.4356452497568997} | train loss {'Reaction outcome loss': 0.12481502554688588, 'Total loss': 0.12481502554688588}
2022-12-05 20:38:45,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:45,167 INFO:     Epoch: 81
2022-12-05 20:38:45,965 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4399742463772947, 'Total loss': 0.4399742463772947} | train loss {'Reaction outcome loss': 0.12364396678004791, 'Total loss': 0.12364396678004791}
2022-12-05 20:38:45,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:45,965 INFO:     Epoch: 82
2022-12-05 20:38:46,772 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42696367305788124, 'Total loss': 0.42696367305788124} | train loss {'Reaction outcome loss': 0.1288369938124137, 'Total loss': 0.1288369938124137}
2022-12-05 20:38:46,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:46,773 INFO:     Epoch: 83
2022-12-05 20:38:47,573 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4395681719549678, 'Total loss': 0.4395681719549678} | train loss {'Reaction outcome loss': 0.12293561054431354, 'Total loss': 0.12293561054431354}
2022-12-05 20:38:47,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:47,573 INFO:     Epoch: 84
2022-12-05 20:38:48,374 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43486225842074916, 'Total loss': 0.43486225842074916} | train loss {'Reaction outcome loss': 0.12453525536787896, 'Total loss': 0.12453525536787896}
2022-12-05 20:38:48,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:48,374 INFO:     Epoch: 85
2022-12-05 20:38:49,173 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4415803895416585, 'Total loss': 0.4415803895416585} | train loss {'Reaction outcome loss': 0.12599316009731307, 'Total loss': 0.12599316009731307}
2022-12-05 20:38:49,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:49,174 INFO:     Epoch: 86
2022-12-05 20:38:49,972 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4322124865244735, 'Total loss': 0.4322124865244735} | train loss {'Reaction outcome loss': 0.1291243173163158, 'Total loss': 0.1291243173163158}
2022-12-05 20:38:49,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:49,972 INFO:     Epoch: 87
2022-12-05 20:38:50,771 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43276427483016794, 'Total loss': 0.43276427483016794} | train loss {'Reaction outcome loss': 0.1276058389537549, 'Total loss': 0.1276058389537549}
2022-12-05 20:38:50,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:50,771 INFO:     Epoch: 88
2022-12-05 20:38:51,567 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4395102401348678, 'Total loss': 0.4395102401348678} | train loss {'Reaction outcome loss': 0.14233883064210054, 'Total loss': 0.14233883064210054}
2022-12-05 20:38:51,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:51,568 INFO:     Epoch: 89
2022-12-05 20:38:52,367 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.438416211950508, 'Total loss': 0.438416211950508} | train loss {'Reaction outcome loss': 0.1254767797731673, 'Total loss': 0.1254767797731673}
2022-12-05 20:38:52,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:52,368 INFO:     Epoch: 90
2022-12-05 20:38:53,163 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4389947737482461, 'Total loss': 0.4389947737482461} | train loss {'Reaction outcome loss': 0.1198848721869139, 'Total loss': 0.1198848721869139}
2022-12-05 20:38:53,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:53,163 INFO:     Epoch: 91
2022-12-05 20:38:53,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44069998609748756, 'Total loss': 0.44069998609748756} | train loss {'Reaction outcome loss': 0.12256657724435581, 'Total loss': 0.12256657724435581}
2022-12-05 20:38:53,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:53,958 INFO:     Epoch: 92
2022-12-05 20:38:54,754 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44424908743663266, 'Total loss': 0.44424908743663266} | train loss {'Reaction outcome loss': 0.12299955398483421, 'Total loss': 0.12299955398483421}
2022-12-05 20:38:54,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:54,754 INFO:     Epoch: 93
2022-12-05 20:38:55,550 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43277057260274887, 'Total loss': 0.43277057260274887} | train loss {'Reaction outcome loss': 0.12372043080673165, 'Total loss': 0.12372043080673165}
2022-12-05 20:38:55,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:55,550 INFO:     Epoch: 94
2022-12-05 20:38:56,348 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4311836246739734, 'Total loss': 0.4311836246739734} | train loss {'Reaction outcome loss': 0.12672911396604558, 'Total loss': 0.12672911396604558}
2022-12-05 20:38:56,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:56,349 INFO:     Epoch: 95
2022-12-05 20:38:57,145 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4254352260719646, 'Total loss': 0.4254352260719646} | train loss {'Reaction outcome loss': 0.12376506251626108, 'Total loss': 0.12376506251626108}
2022-12-05 20:38:57,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:57,145 INFO:     Epoch: 96
2022-12-05 20:38:57,941 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42178636721589347, 'Total loss': 0.42178636721589347} | train loss {'Reaction outcome loss': 0.12319757916440487, 'Total loss': 0.12319757916440487}
2022-12-05 20:38:57,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:57,941 INFO:     Epoch: 97
2022-12-05 20:38:58,736 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4200291286899962, 'Total loss': 0.4200291286899962} | train loss {'Reaction outcome loss': 0.12083421852665874, 'Total loss': 0.12083421852665874}
2022-12-05 20:38:58,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:58,737 INFO:     Epoch: 98
2022-12-05 20:38:59,538 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43050621365281666, 'Total loss': 0.43050621365281666} | train loss {'Reaction outcome loss': 0.11964194320127187, 'Total loss': 0.11964194320127187}
2022-12-05 20:38:59,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:38:59,539 INFO:     Epoch: 99
2022-12-05 20:39:00,340 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4314378345893188, 'Total loss': 0.4314378345893188} | train loss {'Reaction outcome loss': 0.11913947969192436, 'Total loss': 0.11913947969192436}
2022-12-05 20:39:00,340 INFO:     Best model found after epoch 12 of 100.
2022-12-05 20:39:00,340 INFO:   Done with stage: TRAINING
2022-12-05 20:39:00,340 INFO:   Starting stage: EVALUATION
2022-12-05 20:39:00,465 INFO:   Done with stage: EVALUATION
2022-12-05 20:39:00,465 INFO:   Leaving out SEQ value Fold_9
2022-12-05 20:39:00,477 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:39:00,478 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:39:01,130 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:39:01,130 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:39:01,200 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:39:01,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:39:01,200 INFO:     No hyperparam tuning for this model
2022-12-05 20:39:01,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:39:01,200 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:39:01,201 INFO:     None feature selector for col prot
2022-12-05 20:39:01,201 INFO:     None feature selector for col prot
2022-12-05 20:39:01,201 INFO:     None feature selector for col prot
2022-12-05 20:39:01,202 INFO:     None feature selector for col chem
2022-12-05 20:39:01,202 INFO:     None feature selector for col chem
2022-12-05 20:39:01,202 INFO:     None feature selector for col chem
2022-12-05 20:39:01,202 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:39:01,202 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:39:01,204 INFO:     Number of params in model 215821
2022-12-05 20:39:01,207 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:39:01,207 INFO:   Starting stage: TRAINING
2022-12-05 20:39:01,268 INFO:     Val loss before train {'Reaction outcome loss': 0.9876178001815622, 'Total loss': 0.9876178001815622}
2022-12-05 20:39:01,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:01,269 INFO:     Epoch: 0
2022-12-05 20:39:02,066 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5957400067286058, 'Total loss': 0.5957400067286058} | train loss {'Reaction outcome loss': 0.7930916667225872, 'Total loss': 0.7930916667225872}
2022-12-05 20:39:02,066 INFO:     Found new best model at epoch 0
2022-12-05 20:39:02,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:02,067 INFO:     Epoch: 1
2022-12-05 20:39:02,866 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47858523441986606, 'Total loss': 0.47858523441986606} | train loss {'Reaction outcome loss': 0.5447952538608056, 'Total loss': 0.5447952538608056}
2022-12-05 20:39:02,866 INFO:     Found new best model at epoch 1
2022-12-05 20:39:02,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:02,867 INFO:     Epoch: 2
2022-12-05 20:39:03,663 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44542406126856804, 'Total loss': 0.44542406126856804} | train loss {'Reaction outcome loss': 0.4690495413022968, 'Total loss': 0.4690495413022968}
2022-12-05 20:39:03,663 INFO:     Found new best model at epoch 2
2022-12-05 20:39:03,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:03,664 INFO:     Epoch: 3
2022-12-05 20:39:04,471 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4201531349257989, 'Total loss': 0.4201531349257989} | train loss {'Reaction outcome loss': 0.43497234275225205, 'Total loss': 0.43497234275225205}
2022-12-05 20:39:04,471 INFO:     Found new best model at epoch 3
2022-12-05 20:39:04,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:04,472 INFO:     Epoch: 4
2022-12-05 20:39:05,271 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4096857424486767, 'Total loss': 0.4096857424486767} | train loss {'Reaction outcome loss': 0.39936690636757793, 'Total loss': 0.39936690636757793}
2022-12-05 20:39:05,272 INFO:     Found new best model at epoch 4
2022-12-05 20:39:05,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:05,273 INFO:     Epoch: 5
2022-12-05 20:39:06,071 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39570439471439883, 'Total loss': 0.39570439471439883} | train loss {'Reaction outcome loss': 0.3808145804504151, 'Total loss': 0.3808145804504151}
2022-12-05 20:39:06,071 INFO:     Found new best model at epoch 5
2022-12-05 20:39:06,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:06,072 INFO:     Epoch: 6
2022-12-05 20:39:06,868 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40155312520536507, 'Total loss': 0.40155312520536507} | train loss {'Reaction outcome loss': 0.3607077455593024, 'Total loss': 0.3607077455593024}
2022-12-05 20:39:06,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:06,868 INFO:     Epoch: 7
2022-12-05 20:39:07,662 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3956222612072121, 'Total loss': 0.3956222612072121} | train loss {'Reaction outcome loss': 0.33740564503590104, 'Total loss': 0.33740564503590104}
2022-12-05 20:39:07,662 INFO:     Found new best model at epoch 7
2022-12-05 20:39:07,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:07,663 INFO:     Epoch: 8
2022-12-05 20:39:08,456 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3842817284166813, 'Total loss': 0.3842817284166813} | train loss {'Reaction outcome loss': 0.32278955084185007, 'Total loss': 0.32278955084185007}
2022-12-05 20:39:08,456 INFO:     Found new best model at epoch 8
2022-12-05 20:39:08,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:08,457 INFO:     Epoch: 9
2022-12-05 20:39:09,251 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3995461060919545, 'Total loss': 0.3995461060919545} | train loss {'Reaction outcome loss': 0.3057070309635599, 'Total loss': 0.3057070309635599}
2022-12-05 20:39:09,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:09,251 INFO:     Epoch: 10
2022-12-05 20:39:10,046 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39001748710870743, 'Total loss': 0.39001748710870743} | train loss {'Reaction outcome loss': 0.2951379197570477, 'Total loss': 0.2951379197570477}
2022-12-05 20:39:10,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:10,046 INFO:     Epoch: 11
2022-12-05 20:39:10,842 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3790871280838143, 'Total loss': 0.3790871280838143} | train loss {'Reaction outcome loss': 0.2837544929402077, 'Total loss': 0.2837544929402077}
2022-12-05 20:39:10,842 INFO:     Found new best model at epoch 11
2022-12-05 20:39:10,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:10,843 INFO:     Epoch: 12
2022-12-05 20:39:11,644 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38802251660011033, 'Total loss': 0.38802251660011033} | train loss {'Reaction outcome loss': 0.271854469730794, 'Total loss': 0.271854469730794}
2022-12-05 20:39:11,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:11,645 INFO:     Epoch: 13
2022-12-05 20:39:12,439 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3986006621271372, 'Total loss': 0.3986006621271372} | train loss {'Reaction outcome loss': 0.26298859166471583, 'Total loss': 0.26298859166471583}
2022-12-05 20:39:12,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:12,439 INFO:     Epoch: 14
2022-12-05 20:39:13,235 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3937707638198679, 'Total loss': 0.3937707638198679} | train loss {'Reaction outcome loss': 0.25124642801912206, 'Total loss': 0.25124642801912206}
2022-12-05 20:39:13,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:13,236 INFO:     Epoch: 15
2022-12-05 20:39:14,032 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3959681842137467, 'Total loss': 0.3959681842137467} | train loss {'Reaction outcome loss': 0.24309849930617974, 'Total loss': 0.24309849930617974}
2022-12-05 20:39:14,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:14,032 INFO:     Epoch: 16
2022-12-05 20:39:14,829 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39156564528291876, 'Total loss': 0.39156564528291876} | train loss {'Reaction outcome loss': 0.23566346683422565, 'Total loss': 0.23566346683422565}
2022-12-05 20:39:14,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:14,829 INFO:     Epoch: 17
2022-12-05 20:39:15,624 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39931361682035704, 'Total loss': 0.39931361682035704} | train loss {'Reaction outcome loss': 0.22829167012441978, 'Total loss': 0.22829167012441978}
2022-12-05 20:39:15,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:15,625 INFO:     Epoch: 18
2022-12-05 20:39:16,418 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39871585030447354, 'Total loss': 0.39871585030447354} | train loss {'Reaction outcome loss': 0.22174537783631912, 'Total loss': 0.22174537783631912}
2022-12-05 20:39:16,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:16,418 INFO:     Epoch: 19
2022-12-05 20:39:17,211 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39124519818208436, 'Total loss': 0.39124519818208436} | train loss {'Reaction outcome loss': 0.21807633750781658, 'Total loss': 0.21807633750781658}
2022-12-05 20:39:17,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:17,212 INFO:     Epoch: 20
2022-12-05 20:39:18,010 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3942752013152296, 'Total loss': 0.3942752013152296} | train loss {'Reaction outcome loss': 0.21622168369259429, 'Total loss': 0.21622168369259429}
2022-12-05 20:39:18,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:18,011 INFO:     Epoch: 21
2022-12-05 20:39:18,808 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4053230302577669, 'Total loss': 0.4053230302577669} | train loss {'Reaction outcome loss': 0.21142263150951157, 'Total loss': 0.21142263150951157}
2022-12-05 20:39:18,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:18,808 INFO:     Epoch: 22
2022-12-05 20:39:19,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4036601824177937, 'Total loss': 0.4036601824177937} | train loss {'Reaction outcome loss': 0.2045155699526974, 'Total loss': 0.2045155699526974}
2022-12-05 20:39:19,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:19,605 INFO:     Epoch: 23
2022-12-05 20:39:20,407 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41021639007059013, 'Total loss': 0.41021639007059013} | train loss {'Reaction outcome loss': 0.1967912061349206, 'Total loss': 0.1967912061349206}
2022-12-05 20:39:20,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:20,407 INFO:     Epoch: 24
2022-12-05 20:39:21,208 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4015814535827799, 'Total loss': 0.4015814535827799} | train loss {'Reaction outcome loss': 0.1925756218070202, 'Total loss': 0.1925756218070202}
2022-12-05 20:39:21,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:21,208 INFO:     Epoch: 25
2022-12-05 20:39:22,005 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4004318785261024, 'Total loss': 0.4004318785261024} | train loss {'Reaction outcome loss': 0.1911937181690806, 'Total loss': 0.1911937181690806}
2022-12-05 20:39:22,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:22,005 INFO:     Epoch: 26
2022-12-05 20:39:22,799 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43042862381447444, 'Total loss': 0.43042862381447444} | train loss {'Reaction outcome loss': 0.19291716708466108, 'Total loss': 0.19291716708466108}
2022-12-05 20:39:22,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:22,800 INFO:     Epoch: 27
2022-12-05 20:39:23,593 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4179737815125422, 'Total loss': 0.4179737815125422} | train loss {'Reaction outcome loss': 0.18766247315204096, 'Total loss': 0.18766247315204096}
2022-12-05 20:39:23,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:23,593 INFO:     Epoch: 28
2022-12-05 20:39:24,388 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4020605476742441, 'Total loss': 0.4020605476742441} | train loss {'Reaction outcome loss': 0.18363012142690568, 'Total loss': 0.18363012142690568}
2022-12-05 20:39:24,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:24,389 INFO:     Epoch: 29
2022-12-05 20:39:25,188 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4198681363327937, 'Total loss': 0.4198681363327937} | train loss {'Reaction outcome loss': 0.18547907823165086, 'Total loss': 0.18547907823165086}
2022-12-05 20:39:25,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:25,188 INFO:     Epoch: 30
2022-12-05 20:39:25,992 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40733192691748793, 'Total loss': 0.40733192691748793} | train loss {'Reaction outcome loss': 0.17596871664357344, 'Total loss': 0.17596871664357344}
2022-12-05 20:39:25,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:25,993 INFO:     Epoch: 31
2022-12-05 20:39:26,793 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40916421145878057, 'Total loss': 0.40916421145878057} | train loss {'Reaction outcome loss': 0.17455490950027458, 'Total loss': 0.17455490950027458}
2022-12-05 20:39:26,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:26,793 INFO:     Epoch: 32
2022-12-05 20:39:27,589 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42584351619536226, 'Total loss': 0.42584351619536226} | train loss {'Reaction outcome loss': 0.1716939296407497, 'Total loss': 0.1716939296407497}
2022-12-05 20:39:27,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:27,589 INFO:     Epoch: 33
2022-12-05 20:39:28,388 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4296987300569361, 'Total loss': 0.4296987300569361} | train loss {'Reaction outcome loss': 0.16923142940952227, 'Total loss': 0.16923142940952227}
2022-12-05 20:39:28,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:28,388 INFO:     Epoch: 34
2022-12-05 20:39:29,185 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4155674320222302, 'Total loss': 0.4155674320222302} | train loss {'Reaction outcome loss': 0.1723428293911793, 'Total loss': 0.1723428293911793}
2022-12-05 20:39:29,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:29,185 INFO:     Epoch: 35
2022-12-05 20:39:29,981 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42658068815415556, 'Total loss': 0.42658068815415556} | train loss {'Reaction outcome loss': 0.16555521168523593, 'Total loss': 0.16555521168523593}
2022-12-05 20:39:29,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:29,982 INFO:     Epoch: 36
2022-12-05 20:39:30,779 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41808323993940244, 'Total loss': 0.41808323993940244} | train loss {'Reaction outcome loss': 0.16171008400215584, 'Total loss': 0.16171008400215584}
2022-12-05 20:39:30,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:30,779 INFO:     Epoch: 37
2022-12-05 20:39:31,579 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42213390124115074, 'Total loss': 0.42213390124115074} | train loss {'Reaction outcome loss': 0.1578146336936705, 'Total loss': 0.1578146336936705}
2022-12-05 20:39:31,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:31,579 INFO:     Epoch: 38
2022-12-05 20:39:32,378 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43051646785302594, 'Total loss': 0.43051646785302594} | train loss {'Reaction outcome loss': 0.15616430176293802, 'Total loss': 0.15616430176293802}
2022-12-05 20:39:32,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:32,378 INFO:     Epoch: 39
2022-12-05 20:39:33,174 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4262581674212759, 'Total loss': 0.4262581674212759} | train loss {'Reaction outcome loss': 0.15759272915631653, 'Total loss': 0.15759272915631653}
2022-12-05 20:39:33,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:33,174 INFO:     Epoch: 40
2022-12-05 20:39:33,967 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4327294707975604, 'Total loss': 0.4327294707975604} | train loss {'Reaction outcome loss': 0.15566194234956726, 'Total loss': 0.15566194234956726}
2022-12-05 20:39:33,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:33,968 INFO:     Epoch: 41
2022-12-05 20:39:34,764 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4277756905013865, 'Total loss': 0.4277756905013865} | train loss {'Reaction outcome loss': 0.15088169805343576, 'Total loss': 0.15088169805343576}
2022-12-05 20:39:34,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:34,765 INFO:     Epoch: 42
2022-12-05 20:39:35,558 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4483256031843749, 'Total loss': 0.4483256031843749} | train loss {'Reaction outcome loss': 0.1476225330822381, 'Total loss': 0.1476225330822381}
2022-12-05 20:39:35,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:35,559 INFO:     Epoch: 43
2022-12-05 20:39:36,353 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4341344680975784, 'Total loss': 0.4341344680975784} | train loss {'Reaction outcome loss': 0.14682583678287534, 'Total loss': 0.14682583678287534}
2022-12-05 20:39:36,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:36,354 INFO:     Epoch: 44
2022-12-05 20:39:37,152 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44047824174843053, 'Total loss': 0.44047824174843053} | train loss {'Reaction outcome loss': 0.14527602699257222, 'Total loss': 0.14527602699257222}
2022-12-05 20:39:37,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:37,152 INFO:     Epoch: 45
2022-12-05 20:39:37,951 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42670564048669557, 'Total loss': 0.42670564048669557} | train loss {'Reaction outcome loss': 0.1419841059170633, 'Total loss': 0.1419841059170633}
2022-12-05 20:39:37,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:37,952 INFO:     Epoch: 46
2022-12-05 20:39:38,748 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4277720319276506, 'Total loss': 0.4277720319276506} | train loss {'Reaction outcome loss': 0.14541748065552354, 'Total loss': 0.14541748065552354}
2022-12-05 20:39:38,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:38,748 INFO:     Epoch: 47
2022-12-05 20:39:39,542 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44700399515303696, 'Total loss': 0.44700399515303696} | train loss {'Reaction outcome loss': 0.13988593129086713, 'Total loss': 0.13988593129086713}
2022-12-05 20:39:39,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:39,542 INFO:     Epoch: 48
2022-12-05 20:39:40,345 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4308644055642865, 'Total loss': 0.4308644055642865} | train loss {'Reaction outcome loss': 0.1408394678921895, 'Total loss': 0.1408394678921895}
2022-12-05 20:39:40,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:40,345 INFO:     Epoch: 49
2022-12-05 20:39:41,142 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4261346740478819, 'Total loss': 0.4261346740478819} | train loss {'Reaction outcome loss': 0.14245069172866792, 'Total loss': 0.14245069172866792}
2022-12-05 20:39:41,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:41,143 INFO:     Epoch: 50
2022-12-05 20:39:41,938 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4381961575285955, 'Total loss': 0.4381961575285955} | train loss {'Reaction outcome loss': 0.13634496630661505, 'Total loss': 0.13634496630661505}
2022-12-05 20:39:41,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:41,939 INFO:     Epoch: 51
2022-12-05 20:39:42,735 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44817996702410956, 'Total loss': 0.44817996702410956} | train loss {'Reaction outcome loss': 0.13969272649224831, 'Total loss': 0.13969272649224831}
2022-12-05 20:39:42,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:42,736 INFO:     Epoch: 52
2022-12-05 20:39:43,531 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43733920055356895, 'Total loss': 0.43733920055356895} | train loss {'Reaction outcome loss': 0.14320638703124838, 'Total loss': 0.14320638703124838}
2022-12-05 20:39:43,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:43,531 INFO:     Epoch: 53
2022-12-05 20:39:44,323 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44399386779828504, 'Total loss': 0.44399386779828504} | train loss {'Reaction outcome loss': 0.1366903867364224, 'Total loss': 0.1366903867364224}
2022-12-05 20:39:44,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:44,323 INFO:     Epoch: 54
2022-12-05 20:39:45,112 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4496493043208664, 'Total loss': 0.4496493043208664} | train loss {'Reaction outcome loss': 0.13414093399955798, 'Total loss': 0.13414093399955798}
2022-12-05 20:39:45,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:45,112 INFO:     Epoch: 55
2022-12-05 20:39:45,903 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43480095064098184, 'Total loss': 0.43480095064098184} | train loss {'Reaction outcome loss': 0.13578424428548166, 'Total loss': 0.13578424428548166}
2022-12-05 20:39:45,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:45,903 INFO:     Epoch: 56
2022-12-05 20:39:46,697 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46089953455058014, 'Total loss': 0.46089953455058014} | train loss {'Reaction outcome loss': 0.12992349320170488, 'Total loss': 0.12992349320170488}
2022-12-05 20:39:46,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:46,697 INFO:     Epoch: 57
2022-12-05 20:39:47,489 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4489924249196933, 'Total loss': 0.4489924249196933} | train loss {'Reaction outcome loss': 0.13106832276984506, 'Total loss': 0.13106832276984506}
2022-12-05 20:39:47,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:47,490 INFO:     Epoch: 58
2022-12-05 20:39:48,278 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.452121225270358, 'Total loss': 0.452121225270358} | train loss {'Reaction outcome loss': 0.13385790273611273, 'Total loss': 0.13385790273611273}
2022-12-05 20:39:48,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:48,279 INFO:     Epoch: 59
2022-12-05 20:39:49,069 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4397588678720323, 'Total loss': 0.4397588678720323} | train loss {'Reaction outcome loss': 0.12739695351088215, 'Total loss': 0.12739695351088215}
2022-12-05 20:39:49,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:49,070 INFO:     Epoch: 60
2022-12-05 20:39:49,860 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44551814245906746, 'Total loss': 0.44551814245906746} | train loss {'Reaction outcome loss': 0.12556604301247762, 'Total loss': 0.12556604301247762}
2022-12-05 20:39:49,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:49,861 INFO:     Epoch: 61
2022-12-05 20:39:50,650 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45372165604071185, 'Total loss': 0.45372165604071185} | train loss {'Reaction outcome loss': 0.12828607902473765, 'Total loss': 0.12828607902473765}
2022-12-05 20:39:50,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:50,650 INFO:     Epoch: 62
2022-12-05 20:39:51,438 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4382960897955028, 'Total loss': 0.4382960897955028} | train loss {'Reaction outcome loss': 0.13233143918999557, 'Total loss': 0.13233143918999557}
2022-12-05 20:39:51,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:51,438 INFO:     Epoch: 63
2022-12-05 20:39:52,229 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43471523543650453, 'Total loss': 0.43471523543650453} | train loss {'Reaction outcome loss': 0.12577973585505123, 'Total loss': 0.12577973585505123}
2022-12-05 20:39:52,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:52,230 INFO:     Epoch: 64
2022-12-05 20:39:53,024 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45050535757433285, 'Total loss': 0.45050535757433285} | train loss {'Reaction outcome loss': 0.12512789368780278, 'Total loss': 0.12512789368780278}
2022-12-05 20:39:53,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:53,025 INFO:     Epoch: 65
2022-12-05 20:39:53,814 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45629018104889174, 'Total loss': 0.45629018104889174} | train loss {'Reaction outcome loss': 0.12868873420197832, 'Total loss': 0.12868873420197832}
2022-12-05 20:39:53,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:53,814 INFO:     Epoch: 66
2022-12-05 20:39:54,606 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44617239284244453, 'Total loss': 0.44617239284244453} | train loss {'Reaction outcome loss': 0.12463112828333067, 'Total loss': 0.12463112828333067}
2022-12-05 20:39:54,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:54,606 INFO:     Epoch: 67
2022-12-05 20:39:55,395 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44463077966462483, 'Total loss': 0.44463077966462483} | train loss {'Reaction outcome loss': 0.12184066643376612, 'Total loss': 0.12184066643376612}
2022-12-05 20:39:55,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:55,395 INFO:     Epoch: 68
2022-12-05 20:39:56,190 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4626414179801941, 'Total loss': 0.4626414179801941} | train loss {'Reaction outcome loss': 0.12339768904875889, 'Total loss': 0.12339768904875889}
2022-12-05 20:39:56,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:56,190 INFO:     Epoch: 69
2022-12-05 20:39:56,981 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.449301188219, 'Total loss': 0.449301188219} | train loss {'Reaction outcome loss': 0.12807643893155973, 'Total loss': 0.12807643893155973}
2022-12-05 20:39:56,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:56,981 INFO:     Epoch: 70
2022-12-05 20:39:57,770 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46072918379848654, 'Total loss': 0.46072918379848654} | train loss {'Reaction outcome loss': 0.12233525634882783, 'Total loss': 0.12233525634882783}
2022-12-05 20:39:57,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:57,770 INFO:     Epoch: 71
2022-12-05 20:39:58,559 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4367993998933922, 'Total loss': 0.4367993998933922} | train loss {'Reaction outcome loss': 0.12717832213782362, 'Total loss': 0.12717832213782362}
2022-12-05 20:39:58,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:58,559 INFO:     Epoch: 72
2022-12-05 20:39:59,347 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.448739214038307, 'Total loss': 0.448739214038307} | train loss {'Reaction outcome loss': 0.11887937304205619, 'Total loss': 0.11887937304205619}
2022-12-05 20:39:59,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:39:59,348 INFO:     Epoch: 73
2022-12-05 20:40:00,139 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44443283873525535, 'Total loss': 0.44443283873525535} | train loss {'Reaction outcome loss': 0.12172404086209743, 'Total loss': 0.12172404086209743}
2022-12-05 20:40:00,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:00,139 INFO:     Epoch: 74
2022-12-05 20:40:00,929 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4585115420208736, 'Total loss': 0.4585115420208736} | train loss {'Reaction outcome loss': 0.12401984318306572, 'Total loss': 0.12401984318306572}
2022-12-05 20:40:00,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:00,930 INFO:     Epoch: 75
2022-12-05 20:40:01,719 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4463900205763904, 'Total loss': 0.4463900205763904} | train loss {'Reaction outcome loss': 0.11963152211642096, 'Total loss': 0.11963152211642096}
2022-12-05 20:40:01,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:01,719 INFO:     Epoch: 76
2022-12-05 20:40:02,509 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4511394649744034, 'Total loss': 0.4511394649744034} | train loss {'Reaction outcome loss': 0.11592898905458238, 'Total loss': 0.11592898905458238}
2022-12-05 20:40:02,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:02,509 INFO:     Epoch: 77
2022-12-05 20:40:03,302 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4716200029308146, 'Total loss': 0.4716200029308146} | train loss {'Reaction outcome loss': 0.11379669879908157, 'Total loss': 0.11379669879908157}
2022-12-05 20:40:03,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:03,303 INFO:     Epoch: 78
2022-12-05 20:40:04,089 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46458293294364755, 'Total loss': 0.46458293294364755} | train loss {'Reaction outcome loss': 0.11743452288361214, 'Total loss': 0.11743452288361214}
2022-12-05 20:40:04,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:04,089 INFO:     Epoch: 79
2022-12-05 20:40:04,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44300290137868037, 'Total loss': 0.44300290137868037} | train loss {'Reaction outcome loss': 0.11453674722327153, 'Total loss': 0.11453674722327153}
2022-12-05 20:40:04,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:04,877 INFO:     Epoch: 80
2022-12-05 20:40:05,667 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44958177784627135, 'Total loss': 0.44958177784627135} | train loss {'Reaction outcome loss': 0.11743716403525248, 'Total loss': 0.11743716403525248}
2022-12-05 20:40:05,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:05,667 INFO:     Epoch: 81
2022-12-05 20:40:06,456 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44633905217051506, 'Total loss': 0.44633905217051506} | train loss {'Reaction outcome loss': 0.11701873924040239, 'Total loss': 0.11701873924040239}
2022-12-05 20:40:06,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:06,457 INFO:     Epoch: 82
2022-12-05 20:40:07,247 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4595835567875342, 'Total loss': 0.4595835567875342} | train loss {'Reaction outcome loss': 0.11837163626740456, 'Total loss': 0.11837163626740456}
2022-12-05 20:40:07,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:07,248 INFO:     Epoch: 83
2022-12-05 20:40:08,037 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4463048614561558, 'Total loss': 0.4463048614561558} | train loss {'Reaction outcome loss': 0.11345421039284422, 'Total loss': 0.11345421039284422}
2022-12-05 20:40:08,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:08,037 INFO:     Epoch: 84
2022-12-05 20:40:08,824 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45965381745587697, 'Total loss': 0.45965381745587697} | train loss {'Reaction outcome loss': 0.11522554693298663, 'Total loss': 0.11522554693298663}
2022-12-05 20:40:08,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:08,824 INFO:     Epoch: 85
2022-12-05 20:40:09,610 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4679897055029869, 'Total loss': 0.4679897055029869} | train loss {'Reaction outcome loss': 0.11674391313527639, 'Total loss': 0.11674391313527639}
2022-12-05 20:40:09,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:09,610 INFO:     Epoch: 86
2022-12-05 20:40:10,400 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4578951434655623, 'Total loss': 0.4578951434655623} | train loss {'Reaction outcome loss': 0.11520174411898441, 'Total loss': 0.11520174411898441}
2022-12-05 20:40:10,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:10,400 INFO:     Epoch: 87
2022-12-05 20:40:11,187 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4504208944060586, 'Total loss': 0.4504208944060586} | train loss {'Reaction outcome loss': 0.11196996758198026, 'Total loss': 0.11196996758198026}
2022-12-05 20:40:11,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:11,187 INFO:     Epoch: 88
2022-12-05 20:40:11,973 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46402167732065375, 'Total loss': 0.46402167732065375} | train loss {'Reaction outcome loss': 0.11385025322128102, 'Total loss': 0.11385025322128102}
2022-12-05 20:40:11,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:11,974 INFO:     Epoch: 89
2022-12-05 20:40:12,760 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4607556252316995, 'Total loss': 0.4607556252316995} | train loss {'Reaction outcome loss': 0.11733164340408467, 'Total loss': 0.11733164340408467}
2022-12-05 20:40:12,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:12,761 INFO:     Epoch: 90
2022-12-05 20:40:13,555 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.442236548458988, 'Total loss': 0.442236548458988} | train loss {'Reaction outcome loss': 0.11330750781801427, 'Total loss': 0.11330750781801427}
2022-12-05 20:40:13,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:13,555 INFO:     Epoch: 91
2022-12-05 20:40:14,342 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44774138487198134, 'Total loss': 0.44774138487198134} | train loss {'Reaction outcome loss': 0.11184012558620408, 'Total loss': 0.11184012558620408}
2022-12-05 20:40:14,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:14,343 INFO:     Epoch: 92
2022-12-05 20:40:15,130 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47377986122261395, 'Total loss': 0.47377986122261395} | train loss {'Reaction outcome loss': 0.1142271653624621, 'Total loss': 0.1142271653624621}
2022-12-05 20:40:15,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:15,130 INFO:     Epoch: 93
2022-12-05 20:40:15,916 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4535185091874816, 'Total loss': 0.4535185091874816} | train loss {'Reaction outcome loss': 0.11390550030387847, 'Total loss': 0.11390550030387847}
2022-12-05 20:40:15,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:15,917 INFO:     Epoch: 94
2022-12-05 20:40:16,707 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44024452109905804, 'Total loss': 0.44024452109905804} | train loss {'Reaction outcome loss': 0.10767543646704918, 'Total loss': 0.10767543646704918}
2022-12-05 20:40:16,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:16,707 INFO:     Epoch: 95
2022-12-05 20:40:17,500 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44379878077994694, 'Total loss': 0.44379878077994694} | train loss {'Reaction outcome loss': 0.10928368766844906, 'Total loss': 0.10928368766844906}
2022-12-05 20:40:17,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:17,500 INFO:     Epoch: 96
2022-12-05 20:40:18,292 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45676840672438795, 'Total loss': 0.45676840672438795} | train loss {'Reaction outcome loss': 0.11154641391641577, 'Total loss': 0.11154641391641577}
2022-12-05 20:40:18,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:18,292 INFO:     Epoch: 97
2022-12-05 20:40:19,088 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4622015865011649, 'Total loss': 0.4622015865011649} | train loss {'Reaction outcome loss': 0.10789384090879282, 'Total loss': 0.10789384090879282}
2022-12-05 20:40:19,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:19,089 INFO:     Epoch: 98
2022-12-05 20:40:19,881 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4545170956037261, 'Total loss': 0.4545170956037261} | train loss {'Reaction outcome loss': 0.10919953432492158, 'Total loss': 0.10919953432492158}
2022-12-05 20:40:19,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:19,882 INFO:     Epoch: 99
2022-12-05 20:40:20,677 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4584380906413902, 'Total loss': 0.4584380906413902} | train loss {'Reaction outcome loss': 0.11242556951653498, 'Total loss': 0.11242556951653498}
2022-12-05 20:40:20,678 INFO:     Best model found after epoch 12 of 100.
2022-12-05 20:40:20,678 INFO:   Done with stage: TRAINING
2022-12-05 20:40:20,678 INFO:   Starting stage: EVALUATION
2022-12-05 20:40:20,803 INFO:   Done with stage: EVALUATION
2022-12-05 20:40:20,811 INFO:   Leaving out SEQ value Fold_0
2022-12-05 20:40:20,824 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:40:20,824 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:40:21,469 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:40:21,469 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:40:21,538 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:40:21,539 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:40:21,539 INFO:     No hyperparam tuning for this model
2022-12-05 20:40:21,539 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:40:21,539 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:40:21,539 INFO:     None feature selector for col prot
2022-12-05 20:40:21,540 INFO:     None feature selector for col prot
2022-12-05 20:40:21,540 INFO:     None feature selector for col prot
2022-12-05 20:40:21,540 INFO:     None feature selector for col chem
2022-12-05 20:40:21,540 INFO:     None feature selector for col chem
2022-12-05 20:40:21,540 INFO:     None feature selector for col chem
2022-12-05 20:40:21,540 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:40:21,540 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:40:21,542 INFO:     Number of params in model 215821
2022-12-05 20:40:21,545 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:40:21,545 INFO:   Starting stage: TRAINING
2022-12-05 20:40:21,606 INFO:     Val loss before train {'Reaction outcome loss': 0.9936998269774697, 'Total loss': 0.9936998269774697}
2022-12-05 20:40:21,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:21,606 INFO:     Epoch: 0
2022-12-05 20:40:22,408 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5790216597643766, 'Total loss': 0.5790216597643766} | train loss {'Reaction outcome loss': 0.7881117651638715, 'Total loss': 0.7881117651638715}
2022-12-05 20:40:22,408 INFO:     Found new best model at epoch 0
2022-12-05 20:40:22,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:22,409 INFO:     Epoch: 1
2022-12-05 20:40:23,207 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47178206592798233, 'Total loss': 0.47178206592798233} | train loss {'Reaction outcome loss': 0.5406347002215713, 'Total loss': 0.5406347002215713}
2022-12-05 20:40:23,207 INFO:     Found new best model at epoch 1
2022-12-05 20:40:23,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:23,208 INFO:     Epoch: 2
2022-12-05 20:40:24,001 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44207324426282535, 'Total loss': 0.44207324426282535} | train loss {'Reaction outcome loss': 0.46161094037929046, 'Total loss': 0.46161094037929046}
2022-12-05 20:40:24,001 INFO:     Found new best model at epoch 2
2022-12-05 20:40:24,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:24,002 INFO:     Epoch: 3
2022-12-05 20:40:24,796 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43603760173374956, 'Total loss': 0.43603760173374956} | train loss {'Reaction outcome loss': 0.42606941161126743, 'Total loss': 0.42606941161126743}
2022-12-05 20:40:24,796 INFO:     Found new best model at epoch 3
2022-12-05 20:40:24,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:24,797 INFO:     Epoch: 4
2022-12-05 20:40:25,596 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4143354371190071, 'Total loss': 0.4143354371190071} | train loss {'Reaction outcome loss': 0.39874681540828966, 'Total loss': 0.39874681540828966}
2022-12-05 20:40:25,596 INFO:     Found new best model at epoch 4
2022-12-05 20:40:25,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:25,597 INFO:     Epoch: 5
2022-12-05 20:40:26,390 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41157168556343426, 'Total loss': 0.41157168556343426} | train loss {'Reaction outcome loss': 0.3748030231790504, 'Total loss': 0.3748030231790504}
2022-12-05 20:40:26,390 INFO:     Found new best model at epoch 5
2022-12-05 20:40:26,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:26,391 INFO:     Epoch: 6
2022-12-05 20:40:27,185 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40715147825804626, 'Total loss': 0.40715147825804626} | train loss {'Reaction outcome loss': 0.3544552038067401, 'Total loss': 0.3544552038067401}
2022-12-05 20:40:27,185 INFO:     Found new best model at epoch 6
2022-12-05 20:40:27,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:27,186 INFO:     Epoch: 7
2022-12-05 20:40:27,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4064051881432533, 'Total loss': 0.4064051881432533} | train loss {'Reaction outcome loss': 0.339461773332314, 'Total loss': 0.339461773332314}
2022-12-05 20:40:27,981 INFO:     Found new best model at epoch 7
2022-12-05 20:40:27,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:27,982 INFO:     Epoch: 8
2022-12-05 20:40:28,782 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3909953917292031, 'Total loss': 0.3909953917292031} | train loss {'Reaction outcome loss': 0.3325434082191483, 'Total loss': 0.3325434082191483}
2022-12-05 20:40:28,782 INFO:     Found new best model at epoch 8
2022-12-05 20:40:28,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:28,783 INFO:     Epoch: 9
2022-12-05 20:40:29,579 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38716692240400746, 'Total loss': 0.38716692240400746} | train loss {'Reaction outcome loss': 0.3142684149114709, 'Total loss': 0.3142684149114709}
2022-12-05 20:40:29,579 INFO:     Found new best model at epoch 9
2022-12-05 20:40:29,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:29,580 INFO:     Epoch: 10
2022-12-05 20:40:30,378 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3951306603848934, 'Total loss': 0.3951306603848934} | train loss {'Reaction outcome loss': 0.29732823856024126, 'Total loss': 0.29732823856024126}
2022-12-05 20:40:30,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:30,378 INFO:     Epoch: 11
2022-12-05 20:40:31,175 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40549753403121774, 'Total loss': 0.40549753403121774} | train loss {'Reaction outcome loss': 0.28978299883454434, 'Total loss': 0.28978299883454434}
2022-12-05 20:40:31,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:31,176 INFO:     Epoch: 12
2022-12-05 20:40:31,974 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39702987332235684, 'Total loss': 0.39702987332235684} | train loss {'Reaction outcome loss': 0.2790733715783247, 'Total loss': 0.2790733715783247}
2022-12-05 20:40:31,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:31,975 INFO:     Epoch: 13
2022-12-05 20:40:32,772 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3998798639936881, 'Total loss': 0.3998798639936881} | train loss {'Reaction outcome loss': 0.2703908288828757, 'Total loss': 0.2703908288828757}
2022-12-05 20:40:32,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:32,772 INFO:     Epoch: 14
2022-12-05 20:40:33,572 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4032841185954484, 'Total loss': 0.4032841185954484} | train loss {'Reaction outcome loss': 0.2595433461355415, 'Total loss': 0.2595433461355415}
2022-12-05 20:40:33,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:33,573 INFO:     Epoch: 15
2022-12-05 20:40:34,369 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3942364982583306, 'Total loss': 0.3942364982583306} | train loss {'Reaction outcome loss': 0.25295805602300503, 'Total loss': 0.25295805602300503}
2022-12-05 20:40:34,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:34,369 INFO:     Epoch: 16
2022-12-05 20:40:35,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38267597589980473, 'Total loss': 0.38267597589980473} | train loss {'Reaction outcome loss': 0.24450095516708698, 'Total loss': 0.24450095516708698}
2022-12-05 20:40:35,166 INFO:     Found new best model at epoch 16
2022-12-05 20:40:35,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:35,167 INFO:     Epoch: 17
2022-12-05 20:40:35,960 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3979363097724589, 'Total loss': 0.3979363097724589} | train loss {'Reaction outcome loss': 0.23955341986557732, 'Total loss': 0.23955341986557732}
2022-12-05 20:40:35,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:35,960 INFO:     Epoch: 18
2022-12-05 20:40:36,760 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3847747260535305, 'Total loss': 0.3847747260535305} | train loss {'Reaction outcome loss': 0.2351618150497979, 'Total loss': 0.2351618150497979}
2022-12-05 20:40:36,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:36,760 INFO:     Epoch: 19
2022-12-05 20:40:37,555 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38848049295219506, 'Total loss': 0.38848049295219506} | train loss {'Reaction outcome loss': 0.22626788368229925, 'Total loss': 0.22626788368229925}
2022-12-05 20:40:37,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:37,555 INFO:     Epoch: 20
2022-12-05 20:40:38,348 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.396753669123758, 'Total loss': 0.396753669123758} | train loss {'Reaction outcome loss': 0.22187150165114386, 'Total loss': 0.22187150165114386}
2022-12-05 20:40:38,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:38,349 INFO:     Epoch: 21
2022-12-05 20:40:39,145 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3951105119829828, 'Total loss': 0.3951105119829828} | train loss {'Reaction outcome loss': 0.2183686514584883, 'Total loss': 0.2183686514584883}
2022-12-05 20:40:39,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:39,145 INFO:     Epoch: 22
2022-12-05 20:40:39,940 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39732280102643097, 'Total loss': 0.39732280102643097} | train loss {'Reaction outcome loss': 0.21452874583211023, 'Total loss': 0.21452874583211023}
2022-12-05 20:40:39,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:39,940 INFO:     Epoch: 23
2022-12-05 20:40:40,740 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40289726988835767, 'Total loss': 0.40289726988835767} | train loss {'Reaction outcome loss': 0.20585065107294906, 'Total loss': 0.20585065107294906}
2022-12-05 20:40:40,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:40,740 INFO:     Epoch: 24
2022-12-05 20:40:41,536 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4102940655906092, 'Total loss': 0.4102940655906092} | train loss {'Reaction outcome loss': 0.20181702801331816, 'Total loss': 0.20181702801331816}
2022-12-05 20:40:41,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:41,536 INFO:     Epoch: 25
2022-12-05 20:40:42,339 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40904946151104843, 'Total loss': 0.40904946151104843} | train loss {'Reaction outcome loss': 0.2035834572093207, 'Total loss': 0.2035834572093207}
2022-12-05 20:40:42,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:42,340 INFO:     Epoch: 26
2022-12-05 20:40:43,137 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3927738131447272, 'Total loss': 0.3927738131447272} | train loss {'Reaction outcome loss': 0.19318777960743982, 'Total loss': 0.19318777960743982}
2022-12-05 20:40:43,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:43,137 INFO:     Epoch: 27
2022-12-05 20:40:43,940 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3925076486034827, 'Total loss': 0.3925076486034827} | train loss {'Reaction outcome loss': 0.1882607021523632, 'Total loss': 0.1882607021523632}
2022-12-05 20:40:43,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:43,941 INFO:     Epoch: 28
2022-12-05 20:40:44,737 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39455035972324287, 'Total loss': 0.39455035972324287} | train loss {'Reaction outcome loss': 0.1889349554442925, 'Total loss': 0.1889349554442925}
2022-12-05 20:40:44,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:44,738 INFO:     Epoch: 29
2022-12-05 20:40:45,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40015061131932517, 'Total loss': 0.40015061131932517} | train loss {'Reaction outcome loss': 0.1815837760897059, 'Total loss': 0.1815837760897059}
2022-12-05 20:40:45,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:45,532 INFO:     Epoch: 30
2022-12-05 20:40:46,332 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3982370932671157, 'Total loss': 0.3982370932671157} | train loss {'Reaction outcome loss': 0.17862665092927, 'Total loss': 0.17862665092927}
2022-12-05 20:40:46,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:46,332 INFO:     Epoch: 31
2022-12-05 20:40:47,127 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37964448908513243, 'Total loss': 0.37964448908513243} | train loss {'Reaction outcome loss': 0.1768152121669398, 'Total loss': 0.1768152121669398}
2022-12-05 20:40:47,128 INFO:     Found new best model at epoch 31
2022-12-05 20:40:47,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:47,128 INFO:     Epoch: 32
2022-12-05 20:40:47,928 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3953298087316481, 'Total loss': 0.3953298087316481} | train loss {'Reaction outcome loss': 0.17236723370252927, 'Total loss': 0.17236723370252927}
2022-12-05 20:40:47,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:47,928 INFO:     Epoch: 33
2022-12-05 20:40:48,729 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39726752923293546, 'Total loss': 0.39726752923293546} | train loss {'Reaction outcome loss': 0.17048165920051003, 'Total loss': 0.17048165920051003}
2022-12-05 20:40:48,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:48,729 INFO:     Epoch: 34
2022-12-05 20:40:49,533 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40640064599839126, 'Total loss': 0.40640064599839126} | train loss {'Reaction outcome loss': 0.16779798679506247, 'Total loss': 0.16779798679506247}
2022-12-05 20:40:49,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:49,533 INFO:     Epoch: 35
2022-12-05 20:40:50,333 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40891936743123963, 'Total loss': 0.40891936743123963} | train loss {'Reaction outcome loss': 0.16809888169176967, 'Total loss': 0.16809888169176967}
2022-12-05 20:40:50,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:50,333 INFO:     Epoch: 36
2022-12-05 20:40:51,130 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41607581434602087, 'Total loss': 0.41607581434602087} | train loss {'Reaction outcome loss': 0.1634409328176063, 'Total loss': 0.1634409328176063}
2022-12-05 20:40:51,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:51,131 INFO:     Epoch: 37
2022-12-05 20:40:51,932 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41450166228142654, 'Total loss': 0.41450166228142654} | train loss {'Reaction outcome loss': 0.1629480597627187, 'Total loss': 0.1629480597627187}
2022-12-05 20:40:51,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:51,932 INFO:     Epoch: 38
2022-12-05 20:40:52,732 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41484973748976534, 'Total loss': 0.41484973748976534} | train loss {'Reaction outcome loss': 0.16110804908520537, 'Total loss': 0.16110804908520537}
2022-12-05 20:40:52,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:52,732 INFO:     Epoch: 39
2022-12-05 20:40:53,531 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41068919375538826, 'Total loss': 0.41068919375538826} | train loss {'Reaction outcome loss': 0.16009967373721753, 'Total loss': 0.16009967373721753}
2022-12-05 20:40:53,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:53,532 INFO:     Epoch: 40
2022-12-05 20:40:54,331 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4314656105231155, 'Total loss': 0.4314656105231155} | train loss {'Reaction outcome loss': 0.15650316166431316, 'Total loss': 0.15650316166431316}
2022-12-05 20:40:54,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:54,332 INFO:     Epoch: 41
2022-12-05 20:40:55,128 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4216933893886479, 'Total loss': 0.4216933893886479} | train loss {'Reaction outcome loss': 0.15651969077736744, 'Total loss': 0.15651969077736744}
2022-12-05 20:40:55,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:55,129 INFO:     Epoch: 42
2022-12-05 20:40:55,923 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42315505986863916, 'Total loss': 0.42315505986863916} | train loss {'Reaction outcome loss': 0.1561084739516983, 'Total loss': 0.1561084739516983}
2022-12-05 20:40:55,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:55,924 INFO:     Epoch: 43
2022-12-05 20:40:56,718 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4149207046086138, 'Total loss': 0.4149207046086138} | train loss {'Reaction outcome loss': 0.15313248941109248, 'Total loss': 0.15313248941109248}
2022-12-05 20:40:56,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:56,718 INFO:     Epoch: 44
2022-12-05 20:40:57,515 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42200719903815875, 'Total loss': 0.42200719903815875} | train loss {'Reaction outcome loss': 0.1501755389151152, 'Total loss': 0.1501755389151152}
2022-12-05 20:40:57,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:57,516 INFO:     Epoch: 45
2022-12-05 20:40:58,311 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42598779584196483, 'Total loss': 0.42598779584196483} | train loss {'Reaction outcome loss': 0.14693297356035304, 'Total loss': 0.14693297356035304}
2022-12-05 20:40:58,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:58,311 INFO:     Epoch: 46
2022-12-05 20:40:59,115 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4295000738718293, 'Total loss': 0.4295000738718293} | train loss {'Reaction outcome loss': 0.1543035939230248, 'Total loss': 0.1543035939230248}
2022-12-05 20:40:59,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:59,115 INFO:     Epoch: 47
2022-12-05 20:40:59,914 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4279255581681024, 'Total loss': 0.4279255581681024} | train loss {'Reaction outcome loss': 0.1464619448819473, 'Total loss': 0.1464619448819473}
2022-12-05 20:40:59,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:40:59,914 INFO:     Epoch: 48
2022-12-05 20:41:00,711 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42642330496825953, 'Total loss': 0.42642330496825953} | train loss {'Reaction outcome loss': 0.14319887653988625, 'Total loss': 0.14319887653988625}
2022-12-05 20:41:00,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:00,712 INFO:     Epoch: 49
2022-12-05 20:41:01,512 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42170743542638695, 'Total loss': 0.42170743542638695} | train loss {'Reaction outcome loss': 0.14485354823951593, 'Total loss': 0.14485354823951593}
2022-12-05 20:41:01,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:01,512 INFO:     Epoch: 50
2022-12-05 20:41:02,309 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41584920781579887, 'Total loss': 0.41584920781579887} | train loss {'Reaction outcome loss': 0.1399500827467152, 'Total loss': 0.1399500827467152}
2022-12-05 20:41:02,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:02,309 INFO:     Epoch: 51
2022-12-05 20:41:03,107 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42557271840897476, 'Total loss': 0.42557271840897476} | train loss {'Reaction outcome loss': 0.149314775610501, 'Total loss': 0.149314775610501}
2022-12-05 20:41:03,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:03,108 INFO:     Epoch: 52
2022-12-05 20:41:03,906 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4196403380483389, 'Total loss': 0.4196403380483389} | train loss {'Reaction outcome loss': 0.14947258855399076, 'Total loss': 0.14947258855399076}
2022-12-05 20:41:03,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:03,906 INFO:     Epoch: 53
2022-12-05 20:41:04,702 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4240558877248656, 'Total loss': 0.4240558877248656} | train loss {'Reaction outcome loss': 0.14094204234283583, 'Total loss': 0.14094204234283583}
2022-12-05 20:41:04,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:04,702 INFO:     Epoch: 54
2022-12-05 20:41:05,499 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41956888952038507, 'Total loss': 0.41956888952038507} | train loss {'Reaction outcome loss': 0.13771144775786864, 'Total loss': 0.13771144775786864}
2022-12-05 20:41:05,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:05,499 INFO:     Epoch: 55
2022-12-05 20:41:06,302 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41999125421385874, 'Total loss': 0.41999125421385874} | train loss {'Reaction outcome loss': 0.13732418078582295, 'Total loss': 0.13732418078582295}
2022-12-05 20:41:06,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:06,303 INFO:     Epoch: 56
2022-12-05 20:41:07,108 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4135866263373332, 'Total loss': 0.4135866263373332} | train loss {'Reaction outcome loss': 0.13432931646644344, 'Total loss': 0.13432931646644344}
2022-12-05 20:41:07,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:07,109 INFO:     Epoch: 57
2022-12-05 20:41:07,909 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4326280121776191, 'Total loss': 0.4326280121776191} | train loss {'Reaction outcome loss': 0.13726660102862215, 'Total loss': 0.13726660102862215}
2022-12-05 20:41:07,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:07,909 INFO:     Epoch: 58
2022-12-05 20:41:08,712 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43281637420031155, 'Total loss': 0.43281637420031155} | train loss {'Reaction outcome loss': 0.13404547025898267, 'Total loss': 0.13404547025898267}
2022-12-05 20:41:08,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:08,712 INFO:     Epoch: 59
2022-12-05 20:41:09,509 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43637980182062497, 'Total loss': 0.43637980182062497} | train loss {'Reaction outcome loss': 0.1354198837200338, 'Total loss': 0.1354198837200338}
2022-12-05 20:41:09,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:09,510 INFO:     Epoch: 60
2022-12-05 20:41:10,305 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4223958345299417, 'Total loss': 0.4223958345299417} | train loss {'Reaction outcome loss': 0.13757709578162264, 'Total loss': 0.13757709578162264}
2022-12-05 20:41:10,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:10,305 INFO:     Epoch: 61
2022-12-05 20:41:11,101 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4322566765953194, 'Total loss': 0.4322566765953194} | train loss {'Reaction outcome loss': 0.13885223594973023, 'Total loss': 0.13885223594973023}
2022-12-05 20:41:11,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:11,101 INFO:     Epoch: 62
2022-12-05 20:41:11,895 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42327671667391603, 'Total loss': 0.42327671667391603} | train loss {'Reaction outcome loss': 0.13640829828013534, 'Total loss': 0.13640829828013534}
2022-12-05 20:41:11,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:11,895 INFO:     Epoch: 63
2022-12-05 20:41:12,690 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42099355652251025, 'Total loss': 0.42099355652251025} | train loss {'Reaction outcome loss': 0.13226672092090674, 'Total loss': 0.13226672092090674}
2022-12-05 20:41:12,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:12,690 INFO:     Epoch: 64
2022-12-05 20:41:13,492 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42757814851674164, 'Total loss': 0.42757814851674164} | train loss {'Reaction outcome loss': 0.13124053417855822, 'Total loss': 0.13124053417855822}
2022-12-05 20:41:13,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:13,492 INFO:     Epoch: 65
2022-12-05 20:41:14,291 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4468467523428527, 'Total loss': 0.4468467523428527} | train loss {'Reaction outcome loss': 0.13117278922303968, 'Total loss': 0.13117278922303968}
2022-12-05 20:41:14,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:14,291 INFO:     Epoch: 66
2022-12-05 20:41:15,085 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4263837456025861, 'Total loss': 0.4263837456025861} | train loss {'Reaction outcome loss': 0.12951495202243146, 'Total loss': 0.12951495202243146}
2022-12-05 20:41:15,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:15,085 INFO:     Epoch: 67
2022-12-05 20:41:15,878 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4331399547782811, 'Total loss': 0.4331399547782811} | train loss {'Reaction outcome loss': 0.1288060704849449, 'Total loss': 0.1288060704849449}
2022-12-05 20:41:15,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:15,879 INFO:     Epoch: 68
2022-12-05 20:41:16,672 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4245123812420802, 'Total loss': 0.4245123812420802} | train loss {'Reaction outcome loss': 0.12630922948707815, 'Total loss': 0.12630922948707815}
2022-12-05 20:41:16,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:16,672 INFO:     Epoch: 69
2022-12-05 20:41:17,476 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4193560481071472, 'Total loss': 0.4193560481071472} | train loss {'Reaction outcome loss': 0.129239212389779, 'Total loss': 0.129239212389779}
2022-12-05 20:41:17,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:17,476 INFO:     Epoch: 70
2022-12-05 20:41:18,283 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4401689405468377, 'Total loss': 0.4401689405468377} | train loss {'Reaction outcome loss': 0.1292986567921631, 'Total loss': 0.1292986567921631}
2022-12-05 20:41:18,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:18,283 INFO:     Epoch: 71
2022-12-05 20:41:19,086 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4383161135695197, 'Total loss': 0.4383161135695197} | train loss {'Reaction outcome loss': 0.12694358686173735, 'Total loss': 0.12694358686173735}
2022-12-05 20:41:19,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:19,086 INFO:     Epoch: 72
2022-12-05 20:41:19,889 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4326558245176619, 'Total loss': 0.4326558245176619} | train loss {'Reaction outcome loss': 0.1299325677788692, 'Total loss': 0.1299325677788692}
2022-12-05 20:41:19,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:19,890 INFO:     Epoch: 73
2022-12-05 20:41:20,688 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4343995167450471, 'Total loss': 0.4343995167450471} | train loss {'Reaction outcome loss': 0.13521557625926095, 'Total loss': 0.13521557625926095}
2022-12-05 20:41:20,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:20,689 INFO:     Epoch: 74
2022-12-05 20:41:21,493 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4459136873483658, 'Total loss': 0.4459136873483658} | train loss {'Reaction outcome loss': 0.12899512866971946, 'Total loss': 0.12899512866971946}
2022-12-05 20:41:21,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:21,493 INFO:     Epoch: 75
2022-12-05 20:41:22,293 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42099577154625545, 'Total loss': 0.42099577154625545} | train loss {'Reaction outcome loss': 0.1290675951031259, 'Total loss': 0.1290675951031259}
2022-12-05 20:41:22,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:22,294 INFO:     Epoch: 76
2022-12-05 20:41:23,092 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43937719156118954, 'Total loss': 0.43937719156118954} | train loss {'Reaction outcome loss': 0.12467269517617066, 'Total loss': 0.12467269517617066}
2022-12-05 20:41:23,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:23,092 INFO:     Epoch: 77
2022-12-05 20:41:23,891 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43252139462327416, 'Total loss': 0.43252139462327416} | train loss {'Reaction outcome loss': 0.12361652384368846, 'Total loss': 0.12361652384368846}
2022-12-05 20:41:23,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:23,892 INFO:     Epoch: 78
2022-12-05 20:41:24,693 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.430528917603872, 'Total loss': 0.430528917603872} | train loss {'Reaction outcome loss': 0.12651265771524142, 'Total loss': 0.12651265771524142}
2022-12-05 20:41:24,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:24,693 INFO:     Epoch: 79
2022-12-05 20:41:25,491 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4376364506103776, 'Total loss': 0.4376364506103776} | train loss {'Reaction outcome loss': 0.13083284925141556, 'Total loss': 0.13083284925141556}
2022-12-05 20:41:25,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:25,491 INFO:     Epoch: 80
2022-12-05 20:41:26,294 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44225842658091674, 'Total loss': 0.44225842658091674} | train loss {'Reaction outcome loss': 0.13056586037404308, 'Total loss': 0.13056586037404308}
2022-12-05 20:41:26,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:26,294 INFO:     Epoch: 81
2022-12-05 20:41:27,098 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43587185425514524, 'Total loss': 0.43587185425514524} | train loss {'Reaction outcome loss': 0.12168386923186933, 'Total loss': 0.12168386923186933}
2022-12-05 20:41:27,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:27,098 INFO:     Epoch: 82
2022-12-05 20:41:27,898 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4347186562689868, 'Total loss': 0.4347186562689868} | train loss {'Reaction outcome loss': 0.12180646383656031, 'Total loss': 0.12180646383656031}
2022-12-05 20:41:27,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:27,898 INFO:     Epoch: 83
2022-12-05 20:41:28,699 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43530894206328824, 'Total loss': 0.43530894206328824} | train loss {'Reaction outcome loss': 0.11925728136092907, 'Total loss': 0.11925728136092907}
2022-12-05 20:41:28,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:28,700 INFO:     Epoch: 84
2022-12-05 20:41:29,497 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43482226370410487, 'Total loss': 0.43482226370410487} | train loss {'Reaction outcome loss': 0.12274873068156512, 'Total loss': 0.12274873068156512}
2022-12-05 20:41:29,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:29,498 INFO:     Epoch: 85
2022-12-05 20:41:30,296 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43687484379519115, 'Total loss': 0.43687484379519115} | train loss {'Reaction outcome loss': 0.12997371378743094, 'Total loss': 0.12997371378743094}
2022-12-05 20:41:30,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:30,296 INFO:     Epoch: 86
2022-12-05 20:41:31,096 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42645625803958287, 'Total loss': 0.42645625803958287} | train loss {'Reaction outcome loss': 0.12564559999536648, 'Total loss': 0.12564559999536648}
2022-12-05 20:41:31,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:31,096 INFO:     Epoch: 87
2022-12-05 20:41:31,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43832588314332743, 'Total loss': 0.43832588314332743} | train loss {'Reaction outcome loss': 0.129501207814616, 'Total loss': 0.129501207814616}
2022-12-05 20:41:31,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:31,898 INFO:     Epoch: 88
2022-12-05 20:41:32,699 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4295269667424939, 'Total loss': 0.4295269667424939} | train loss {'Reaction outcome loss': 0.13074521491914867, 'Total loss': 0.13074521491914867}
2022-12-05 20:41:32,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:32,699 INFO:     Epoch: 89
2022-12-05 20:41:33,497 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4142070304263722, 'Total loss': 0.4142070304263722} | train loss {'Reaction outcome loss': 0.12085431492095625, 'Total loss': 0.12085431492095625}
2022-12-05 20:41:33,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:33,497 INFO:     Epoch: 90
2022-12-05 20:41:34,295 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42845728079026396, 'Total loss': 0.42845728079026396} | train loss {'Reaction outcome loss': 0.11993771783917057, 'Total loss': 0.11993771783917057}
2022-12-05 20:41:34,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:34,296 INFO:     Epoch: 91
2022-12-05 20:41:35,095 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4372570091350512, 'Total loss': 0.4372570091350512} | train loss {'Reaction outcome loss': 0.12161610609576529, 'Total loss': 0.12161610609576529}
2022-12-05 20:41:35,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:35,095 INFO:     Epoch: 92
2022-12-05 20:41:35,894 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4314543813128363, 'Total loss': 0.4314543813128363} | train loss {'Reaction outcome loss': 0.12267369340713087, 'Total loss': 0.12267369340713087}
2022-12-05 20:41:35,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:35,894 INFO:     Epoch: 93
2022-12-05 20:41:36,701 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45044762742790306, 'Total loss': 0.45044762742790306} | train loss {'Reaction outcome loss': 0.12180944158825721, 'Total loss': 0.12180944158825721}
2022-12-05 20:41:36,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:36,702 INFO:     Epoch: 94
2022-12-05 20:41:37,505 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4416756477545608, 'Total loss': 0.4416756477545608} | train loss {'Reaction outcome loss': 0.11901279093946522, 'Total loss': 0.11901279093946522}
2022-12-05 20:41:37,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:37,506 INFO:     Epoch: 95
2022-12-05 20:41:38,300 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43600588224150916, 'Total loss': 0.43600588224150916} | train loss {'Reaction outcome loss': 0.11950936294368163, 'Total loss': 0.11950936294368163}
2022-12-05 20:41:38,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:38,300 INFO:     Epoch: 96
2022-12-05 20:41:39,100 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43169379691508686, 'Total loss': 0.43169379691508686} | train loss {'Reaction outcome loss': 0.11782563409130824, 'Total loss': 0.11782563409130824}
2022-12-05 20:41:39,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:39,100 INFO:     Epoch: 97
2022-12-05 20:41:39,893 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44006629000333225, 'Total loss': 0.44006629000333225} | train loss {'Reaction outcome loss': 0.11986865523753891, 'Total loss': 0.11986865523753891}
2022-12-05 20:41:39,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:39,894 INFO:     Epoch: 98
2022-12-05 20:41:40,687 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4457438892938874, 'Total loss': 0.4457438892938874} | train loss {'Reaction outcome loss': 0.12135149655780691, 'Total loss': 0.12135149655780691}
2022-12-05 20:41:40,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:40,688 INFO:     Epoch: 99
2022-12-05 20:41:41,485 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4405134723267772, 'Total loss': 0.4405134723267772} | train loss {'Reaction outcome loss': 0.12374638903345007, 'Total loss': 0.12374638903345007}
2022-12-05 20:41:41,485 INFO:     Best model found after epoch 32 of 100.
2022-12-05 20:41:41,485 INFO:   Done with stage: TRAINING
2022-12-05 20:41:41,485 INFO:   Starting stage: EVALUATION
2022-12-05 20:41:41,611 INFO:   Done with stage: EVALUATION
2022-12-05 20:41:41,611 INFO:   Leaving out SEQ value Fold_1
2022-12-05 20:41:41,625 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:41:41,625 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:41:42,271 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:41:42,271 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:41:42,342 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:41:42,342 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:41:42,342 INFO:     No hyperparam tuning for this model
2022-12-05 20:41:42,342 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:41:42,342 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:41:42,343 INFO:     None feature selector for col prot
2022-12-05 20:41:42,343 INFO:     None feature selector for col prot
2022-12-05 20:41:42,343 INFO:     None feature selector for col prot
2022-12-05 20:41:42,344 INFO:     None feature selector for col chem
2022-12-05 20:41:42,344 INFO:     None feature selector for col chem
2022-12-05 20:41:42,344 INFO:     None feature selector for col chem
2022-12-05 20:41:42,344 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:41:42,344 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:41:42,346 INFO:     Number of params in model 215821
2022-12-05 20:41:42,349 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:41:42,349 INFO:   Starting stage: TRAINING
2022-12-05 20:41:42,410 INFO:     Val loss before train {'Reaction outcome loss': 0.9860548092560335, 'Total loss': 0.9860548092560335}
2022-12-05 20:41:42,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:42,411 INFO:     Epoch: 0
2022-12-05 20:41:43,204 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6216502724723383, 'Total loss': 0.6216502724723383} | train loss {'Reaction outcome loss': 0.8248353932912533, 'Total loss': 0.8248353932912533}
2022-12-05 20:41:43,204 INFO:     Found new best model at epoch 0
2022-12-05 20:41:43,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:43,205 INFO:     Epoch: 1
2022-12-05 20:41:43,996 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5274037264964797, 'Total loss': 0.5274037264964797} | train loss {'Reaction outcome loss': 0.554910730495144, 'Total loss': 0.554910730495144}
2022-12-05 20:41:43,996 INFO:     Found new best model at epoch 1
2022-12-05 20:41:43,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:43,997 INFO:     Epoch: 2
2022-12-05 20:41:44,789 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47808053547685797, 'Total loss': 0.47808053547685797} | train loss {'Reaction outcome loss': 0.4862229413228479, 'Total loss': 0.4862229413228479}
2022-12-05 20:41:44,789 INFO:     Found new best model at epoch 2
2022-12-05 20:41:44,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:44,790 INFO:     Epoch: 3
2022-12-05 20:41:45,586 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4570812098681927, 'Total loss': 0.4570812098681927} | train loss {'Reaction outcome loss': 0.43881822959614186, 'Total loss': 0.43881822959614186}
2022-12-05 20:41:45,586 INFO:     Found new best model at epoch 3
2022-12-05 20:41:45,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:45,587 INFO:     Epoch: 4
2022-12-05 20:41:46,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4370217550207268, 'Total loss': 0.4370217550207268} | train loss {'Reaction outcome loss': 0.40921994380140114, 'Total loss': 0.40921994380140114}
2022-12-05 20:41:46,382 INFO:     Found new best model at epoch 4
2022-12-05 20:41:46,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:46,382 INFO:     Epoch: 5
2022-12-05 20:41:47,172 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41974792697212915, 'Total loss': 0.41974792697212915} | train loss {'Reaction outcome loss': 0.3882134290117967, 'Total loss': 0.3882134290117967}
2022-12-05 20:41:47,172 INFO:     Found new best model at epoch 5
2022-12-05 20:41:47,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:47,173 INFO:     Epoch: 6
2022-12-05 20:41:47,968 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4267201532017101, 'Total loss': 0.4267201532017101} | train loss {'Reaction outcome loss': 0.3628979827492283, 'Total loss': 0.3628979827492283}
2022-12-05 20:41:47,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:47,969 INFO:     Epoch: 7
2022-12-05 20:41:48,761 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4274665273048661, 'Total loss': 0.4274665273048661} | train loss {'Reaction outcome loss': 0.3454019232626688, 'Total loss': 0.3454019232626688}
2022-12-05 20:41:48,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:48,761 INFO:     Epoch: 8
2022-12-05 20:41:49,558 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42463484982197935, 'Total loss': 0.42463484982197935} | train loss {'Reaction outcome loss': 0.3285636924478689, 'Total loss': 0.3285636924478689}
2022-12-05 20:41:49,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:49,558 INFO:     Epoch: 9
2022-12-05 20:41:50,352 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40565904196013103, 'Total loss': 0.40565904196013103} | train loss {'Reaction outcome loss': 0.3172962241749532, 'Total loss': 0.3172962241749532}
2022-12-05 20:41:50,352 INFO:     Found new best model at epoch 9
2022-12-05 20:41:50,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:50,353 INFO:     Epoch: 10
2022-12-05 20:41:51,149 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41284345903179864, 'Total loss': 0.41284345903179864} | train loss {'Reaction outcome loss': 0.30547444287099335, 'Total loss': 0.30547444287099335}
2022-12-05 20:41:51,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:51,149 INFO:     Epoch: 11
2022-12-05 20:41:51,942 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4128570140085437, 'Total loss': 0.4128570140085437} | train loss {'Reaction outcome loss': 0.29183276688401033, 'Total loss': 0.29183276688401033}
2022-12-05 20:41:51,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:51,943 INFO:     Epoch: 12
2022-12-05 20:41:52,736 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39869463071227074, 'Total loss': 0.39869463071227074} | train loss {'Reaction outcome loss': 0.2779248182469534, 'Total loss': 0.2779248182469534}
2022-12-05 20:41:52,736 INFO:     Found new best model at epoch 12
2022-12-05 20:41:52,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:52,737 INFO:     Epoch: 13
2022-12-05 20:41:53,533 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40187928486954083, 'Total loss': 0.40187928486954083} | train loss {'Reaction outcome loss': 0.2686347568648969, 'Total loss': 0.2686347568648969}
2022-12-05 20:41:53,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:53,533 INFO:     Epoch: 14
2022-12-05 20:41:54,332 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41204787977039814, 'Total loss': 0.41204787977039814} | train loss {'Reaction outcome loss': 0.2595510977180863, 'Total loss': 0.2595510977180863}
2022-12-05 20:41:54,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:54,332 INFO:     Epoch: 15
2022-12-05 20:41:55,128 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41783482141115447, 'Total loss': 0.41783482141115447} | train loss {'Reaction outcome loss': 0.25205250529323514, 'Total loss': 0.25205250529323514}
2022-12-05 20:41:55,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:55,128 INFO:     Epoch: 16
2022-12-05 20:41:55,922 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4109091071242636, 'Total loss': 0.4109091071242636} | train loss {'Reaction outcome loss': 0.24474611612949293, 'Total loss': 0.24474611612949293}
2022-12-05 20:41:55,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:55,922 INFO:     Epoch: 17
2022-12-05 20:41:56,715 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4101329262961041, 'Total loss': 0.4101329262961041} | train loss {'Reaction outcome loss': 0.23705883473459527, 'Total loss': 0.23705883473459527}
2022-12-05 20:41:56,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:56,715 INFO:     Epoch: 18
2022-12-05 20:41:57,509 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4319418660280379, 'Total loss': 0.4319418660280379} | train loss {'Reaction outcome loss': 0.23293679109529444, 'Total loss': 0.23293679109529444}
2022-12-05 20:41:57,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:57,509 INFO:     Epoch: 19
2022-12-05 20:41:58,306 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4148761240596121, 'Total loss': 0.4148761240596121} | train loss {'Reaction outcome loss': 0.22897605377019417, 'Total loss': 0.22897605377019417}
2022-12-05 20:41:58,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:58,306 INFO:     Epoch: 20
2022-12-05 20:41:59,105 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41685438833453436, 'Total loss': 0.41685438833453436} | train loss {'Reaction outcome loss': 0.22219005049119595, 'Total loss': 0.22219005049119595}
2022-12-05 20:41:59,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:59,105 INFO:     Epoch: 21
2022-12-05 20:41:59,897 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40952639434147964, 'Total loss': 0.40952639434147964} | train loss {'Reaction outcome loss': 0.21613285734284263, 'Total loss': 0.21613285734284263}
2022-12-05 20:41:59,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:41:59,897 INFO:     Epoch: 22
2022-12-05 20:42:00,692 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4235263405875726, 'Total loss': 0.4235263405875726} | train loss {'Reaction outcome loss': 0.21163887711551024, 'Total loss': 0.21163887711551024}
2022-12-05 20:42:00,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:00,692 INFO:     Epoch: 23
2022-12-05 20:42:01,486 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42129483073949814, 'Total loss': 0.42129483073949814} | train loss {'Reaction outcome loss': 0.20714520617776555, 'Total loss': 0.20714520617776555}
2022-12-05 20:42:01,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:01,487 INFO:     Epoch: 24
2022-12-05 20:42:02,279 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4329996481537819, 'Total loss': 0.4329996481537819} | train loss {'Reaction outcome loss': 0.20388101786375046, 'Total loss': 0.20388101786375046}
2022-12-05 20:42:02,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:02,280 INFO:     Epoch: 25
2022-12-05 20:42:03,072 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.422974708405408, 'Total loss': 0.422974708405408} | train loss {'Reaction outcome loss': 0.19722428418076615, 'Total loss': 0.19722428418076615}
2022-12-05 20:42:03,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:03,073 INFO:     Epoch: 26
2022-12-05 20:42:03,865 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41870929063721135, 'Total loss': 0.41870929063721135} | train loss {'Reaction outcome loss': 0.19835179895615046, 'Total loss': 0.19835179895615046}
2022-12-05 20:42:03,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:03,865 INFO:     Epoch: 27
2022-12-05 20:42:04,658 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42512336813590745, 'Total loss': 0.42512336813590745} | train loss {'Reaction outcome loss': 0.19387035807104488, 'Total loss': 0.19387035807104488}
2022-12-05 20:42:04,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:04,658 INFO:     Epoch: 28
2022-12-05 20:42:05,459 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42086248235269025, 'Total loss': 0.42086248235269025} | train loss {'Reaction outcome loss': 0.18845937229119814, 'Total loss': 0.18845937229119814}
2022-12-05 20:42:05,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:05,460 INFO:     Epoch: 29
2022-12-05 20:42:06,257 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.416302118789066, 'Total loss': 0.416302118789066} | train loss {'Reaction outcome loss': 0.1863803780950636, 'Total loss': 0.1863803780950636}
2022-12-05 20:42:06,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:06,257 INFO:     Epoch: 30
2022-12-05 20:42:07,059 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4137985875660723, 'Total loss': 0.4137985875660723} | train loss {'Reaction outcome loss': 0.18191940327239062, 'Total loss': 0.18191940327239062}
2022-12-05 20:42:07,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:07,059 INFO:     Epoch: 31
2022-12-05 20:42:07,856 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41909766129472037, 'Total loss': 0.41909766129472037} | train loss {'Reaction outcome loss': 0.18142877019157536, 'Total loss': 0.18142877019157536}
2022-12-05 20:42:07,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:07,856 INFO:     Epoch: 32
2022-12-05 20:42:08,650 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4134848229587078, 'Total loss': 0.4134848229587078} | train loss {'Reaction outcome loss': 0.18077232992570652, 'Total loss': 0.18077232992570652}
2022-12-05 20:42:08,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:08,651 INFO:     Epoch: 33
2022-12-05 20:42:09,444 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41791344942017034, 'Total loss': 0.41791344942017034} | train loss {'Reaction outcome loss': 0.18330300621205736, 'Total loss': 0.18330300621205736}
2022-12-05 20:42:09,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:09,444 INFO:     Epoch: 34
2022-12-05 20:42:10,241 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41234441982074216, 'Total loss': 0.41234441982074216} | train loss {'Reaction outcome loss': 0.18116521767457486, 'Total loss': 0.18116521767457486}
2022-12-05 20:42:10,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:10,241 INFO:     Epoch: 35
2022-12-05 20:42:11,038 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4312165763906457, 'Total loss': 0.4312165763906457} | train loss {'Reaction outcome loss': 0.17413565194468025, 'Total loss': 0.17413565194468025}
2022-12-05 20:42:11,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:11,038 INFO:     Epoch: 36
2022-12-05 20:42:11,833 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4169067342511632, 'Total loss': 0.4169067342511632} | train loss {'Reaction outcome loss': 0.17009402950283004, 'Total loss': 0.17009402950283004}
2022-12-05 20:42:11,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:11,834 INFO:     Epoch: 37
2022-12-05 20:42:12,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41695239767432213, 'Total loss': 0.41695239767432213} | train loss {'Reaction outcome loss': 0.1654860903527814, 'Total loss': 0.1654860903527814}
2022-12-05 20:42:12,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:12,631 INFO:     Epoch: 38
2022-12-05 20:42:13,430 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41585456681522454, 'Total loss': 0.41585456681522454} | train loss {'Reaction outcome loss': 0.16617920124141672, 'Total loss': 0.16617920124141672}
2022-12-05 20:42:13,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:13,431 INFO:     Epoch: 39
2022-12-05 20:42:14,227 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41000900934027, 'Total loss': 0.41000900934027} | train loss {'Reaction outcome loss': 0.16660696013947487, 'Total loss': 0.16660696013947487}
2022-12-05 20:42:14,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:14,227 INFO:     Epoch: 40
2022-12-05 20:42:15,028 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4202708601951599, 'Total loss': 0.4202708601951599} | train loss {'Reaction outcome loss': 0.16577700755807764, 'Total loss': 0.16577700755807764}
2022-12-05 20:42:15,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:15,029 INFO:     Epoch: 41
2022-12-05 20:42:15,825 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41907344555312936, 'Total loss': 0.41907344555312936} | train loss {'Reaction outcome loss': 0.16670367682752338, 'Total loss': 0.16670367682752338}
2022-12-05 20:42:15,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:15,826 INFO:     Epoch: 42
2022-12-05 20:42:16,626 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41479308903217316, 'Total loss': 0.41479308903217316} | train loss {'Reaction outcome loss': 0.16074318472703217, 'Total loss': 0.16074318472703217}
2022-12-05 20:42:16,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:16,627 INFO:     Epoch: 43
2022-12-05 20:42:17,422 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4132865945046598, 'Total loss': 0.4132865945046598} | train loss {'Reaction outcome loss': 0.15837220342684658, 'Total loss': 0.15837220342684658}
2022-12-05 20:42:17,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:17,423 INFO:     Epoch: 44
2022-12-05 20:42:18,222 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44011041860688815, 'Total loss': 0.44011041860688815} | train loss {'Reaction outcome loss': 0.15713075614017755, 'Total loss': 0.15713075614017755}
2022-12-05 20:42:18,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:18,222 INFO:     Epoch: 45
2022-12-05 20:42:19,022 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42359511249444703, 'Total loss': 0.42359511249444703} | train loss {'Reaction outcome loss': 0.1567579521401691, 'Total loss': 0.1567579521401691}
2022-12-05 20:42:19,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:19,023 INFO:     Epoch: 46
2022-12-05 20:42:19,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43214587968858803, 'Total loss': 0.43214587968858803} | train loss {'Reaction outcome loss': 0.1578178747146115, 'Total loss': 0.1578178747146115}
2022-12-05 20:42:19,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:19,817 INFO:     Epoch: 47
2022-12-05 20:42:20,615 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41856213862245734, 'Total loss': 0.41856213862245734} | train loss {'Reaction outcome loss': 0.15854954703707203, 'Total loss': 0.15854954703707203}
2022-12-05 20:42:20,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:20,615 INFO:     Epoch: 48
2022-12-05 20:42:21,412 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4243106555870988, 'Total loss': 0.4243106555870988} | train loss {'Reaction outcome loss': 0.15049717271123608, 'Total loss': 0.15049717271123608}
2022-12-05 20:42:21,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:21,413 INFO:     Epoch: 49
2022-12-05 20:42:22,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41680497980930586, 'Total loss': 0.41680497980930586} | train loss {'Reaction outcome loss': 0.1497200644888014, 'Total loss': 0.1497200644888014}
2022-12-05 20:42:22,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:22,212 INFO:     Epoch: 50
2022-12-05 20:42:23,015 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41628381982445717, 'Total loss': 0.41628381982445717} | train loss {'Reaction outcome loss': 0.14909322968182656, 'Total loss': 0.14909322968182656}
2022-12-05 20:42:23,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:23,015 INFO:     Epoch: 51
2022-12-05 20:42:23,814 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.418978230858391, 'Total loss': 0.418978230858391} | train loss {'Reaction outcome loss': 0.15355862058540767, 'Total loss': 0.15355862058540767}
2022-12-05 20:42:23,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:23,815 INFO:     Epoch: 52
2022-12-05 20:42:24,613 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4107856855473735, 'Total loss': 0.4107856855473735} | train loss {'Reaction outcome loss': 0.14674515656887474, 'Total loss': 0.14674515656887474}
2022-12-05 20:42:24,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:24,614 INFO:     Epoch: 53
2022-12-05 20:42:25,410 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4219390448521484, 'Total loss': 0.4219390448521484} | train loss {'Reaction outcome loss': 0.14657534036251832, 'Total loss': 0.14657534036251832}
2022-12-05 20:42:25,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:25,410 INFO:     Epoch: 54
2022-12-05 20:42:26,205 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4130468756299127, 'Total loss': 0.4130468756299127} | train loss {'Reaction outcome loss': 0.1450605895596477, 'Total loss': 0.1450605895596477}
2022-12-05 20:42:26,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:26,205 INFO:     Epoch: 55
2022-12-05 20:42:27,005 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4273778007111766, 'Total loss': 0.4273778007111766} | train loss {'Reaction outcome loss': 0.14884978012457067, 'Total loss': 0.14884978012457067}
2022-12-05 20:42:27,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:27,005 INFO:     Epoch: 56
2022-12-05 20:42:27,804 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4243790761313655, 'Total loss': 0.4243790761313655} | train loss {'Reaction outcome loss': 0.14749318889770205, 'Total loss': 0.14749318889770205}
2022-12-05 20:42:27,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:27,804 INFO:     Epoch: 57
2022-12-05 20:42:28,600 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42831685495647515, 'Total loss': 0.42831685495647515} | train loss {'Reaction outcome loss': 0.14141985394724227, 'Total loss': 0.14141985394724227}
2022-12-05 20:42:28,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:28,600 INFO:     Epoch: 58
2022-12-05 20:42:29,394 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43971534784544597, 'Total loss': 0.43971534784544597} | train loss {'Reaction outcome loss': 0.14292206697784335, 'Total loss': 0.14292206697784335}
2022-12-05 20:42:29,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:29,394 INFO:     Epoch: 59
2022-12-05 20:42:30,190 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4224954250861298, 'Total loss': 0.4224954250861298} | train loss {'Reaction outcome loss': 0.14035168846292415, 'Total loss': 0.14035168846292415}
2022-12-05 20:42:30,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:30,190 INFO:     Epoch: 60
2022-12-05 20:42:30,988 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42626517096703703, 'Total loss': 0.42626517096703703} | train loss {'Reaction outcome loss': 0.13946666210033903, 'Total loss': 0.13946666210033903}
2022-12-05 20:42:30,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:30,988 INFO:     Epoch: 61
2022-12-05 20:42:31,786 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4228732514787804, 'Total loss': 0.4228732514787804} | train loss {'Reaction outcome loss': 0.13956663474018274, 'Total loss': 0.13956663474018274}
2022-12-05 20:42:31,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:31,786 INFO:     Epoch: 62
2022-12-05 20:42:32,585 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42230318960818375, 'Total loss': 0.42230318960818375} | train loss {'Reaction outcome loss': 0.13799263898901612, 'Total loss': 0.13799263898901612}
2022-12-05 20:42:32,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:32,585 INFO:     Epoch: 63
2022-12-05 20:42:33,381 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42806846072727983, 'Total loss': 0.42806846072727983} | train loss {'Reaction outcome loss': 0.13951649666982532, 'Total loss': 0.13951649666982532}
2022-12-05 20:42:33,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:33,381 INFO:     Epoch: 64
2022-12-05 20:42:34,177 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4113633287223903, 'Total loss': 0.4113633287223903} | train loss {'Reaction outcome loss': 0.1402052505854291, 'Total loss': 0.1402052505854291}
2022-12-05 20:42:34,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:34,177 INFO:     Epoch: 65
2022-12-05 20:42:34,972 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4123590219427239, 'Total loss': 0.4123590219427239} | train loss {'Reaction outcome loss': 0.13686048944559898, 'Total loss': 0.13686048944559898}
2022-12-05 20:42:34,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:34,973 INFO:     Epoch: 66
2022-12-05 20:42:35,771 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.422889210622419, 'Total loss': 0.422889210622419} | train loss {'Reaction outcome loss': 0.13529366803089693, 'Total loss': 0.13529366803089693}
2022-12-05 20:42:35,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:35,771 INFO:     Epoch: 67
2022-12-05 20:42:36,566 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41490225663239305, 'Total loss': 0.41490225663239305} | train loss {'Reaction outcome loss': 0.13691271625474277, 'Total loss': 0.13691271625474277}
2022-12-05 20:42:36,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:36,567 INFO:     Epoch: 68
2022-12-05 20:42:37,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41477022421630944, 'Total loss': 0.41477022421630944} | train loss {'Reaction outcome loss': 0.13481834520461408, 'Total loss': 0.13481834520461408}
2022-12-05 20:42:37,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:37,370 INFO:     Epoch: 69
2022-12-05 20:42:38,169 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41886780241673643, 'Total loss': 0.41886780241673643} | train loss {'Reaction outcome loss': 0.13594545949974401, 'Total loss': 0.13594545949974401}
2022-12-05 20:42:38,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:38,169 INFO:     Epoch: 70
2022-12-05 20:42:38,961 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41863144358450716, 'Total loss': 0.41863144358450716} | train loss {'Reaction outcome loss': 0.13290020571206226, 'Total loss': 0.13290020571206226}
2022-12-05 20:42:38,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:38,961 INFO:     Epoch: 71
2022-12-05 20:42:39,750 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41881834410808305, 'Total loss': 0.41881834410808305} | train loss {'Reaction outcome loss': 0.13318972698476936, 'Total loss': 0.13318972698476936}
2022-12-05 20:42:39,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:39,750 INFO:     Epoch: 72
2022-12-05 20:42:40,541 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4195196416906335, 'Total loss': 0.4195196416906335} | train loss {'Reaction outcome loss': 0.1356399156575502, 'Total loss': 0.1356399156575502}
2022-12-05 20:42:40,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:40,541 INFO:     Epoch: 73
2022-12-05 20:42:41,333 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4204727607694539, 'Total loss': 0.4204727607694539} | train loss {'Reaction outcome loss': 0.13076070709689427, 'Total loss': 0.13076070709689427}
2022-12-05 20:42:41,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:41,334 INFO:     Epoch: 74
2022-12-05 20:42:42,123 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42621988362886687, 'Total loss': 0.42621988362886687} | train loss {'Reaction outcome loss': 0.12868469835519186, 'Total loss': 0.12868469835519186}
2022-12-05 20:42:42,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:42,123 INFO:     Epoch: 75
2022-12-05 20:42:42,916 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4199071719565175, 'Total loss': 0.4199071719565175} | train loss {'Reaction outcome loss': 0.13489359185883873, 'Total loss': 0.13489359185883873}
2022-12-05 20:42:42,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:42,917 INFO:     Epoch: 76
2022-12-05 20:42:43,707 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41653901880437677, 'Total loss': 0.41653901880437677} | train loss {'Reaction outcome loss': 0.13721997609837094, 'Total loss': 0.13721997609837094}
2022-12-05 20:42:43,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:43,707 INFO:     Epoch: 77
2022-12-05 20:42:44,496 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4180218611251224, 'Total loss': 0.4180218611251224} | train loss {'Reaction outcome loss': 0.13197945921987234, 'Total loss': 0.13197945921987234}
2022-12-05 20:42:44,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:44,497 INFO:     Epoch: 78
2022-12-05 20:42:45,289 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4085304571146315, 'Total loss': 0.4085304571146315} | train loss {'Reaction outcome loss': 0.12945856345755705, 'Total loss': 0.12945856345755705}
2022-12-05 20:42:45,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:45,289 INFO:     Epoch: 79
2022-12-05 20:42:46,079 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42884130335666915, 'Total loss': 0.42884130335666915} | train loss {'Reaction outcome loss': 0.12883493533124205, 'Total loss': 0.12883493533124205}
2022-12-05 20:42:46,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:46,079 INFO:     Epoch: 80
2022-12-05 20:42:46,868 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41379527866163035, 'Total loss': 0.41379527866163035} | train loss {'Reaction outcome loss': 0.12883961919378414, 'Total loss': 0.12883961919378414}
2022-12-05 20:42:46,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:46,868 INFO:     Epoch: 81
2022-12-05 20:42:47,657 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4199370401488109, 'Total loss': 0.4199370401488109} | train loss {'Reaction outcome loss': 0.12717347635476575, 'Total loss': 0.12717347635476575}
2022-12-05 20:42:47,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:47,657 INFO:     Epoch: 82
2022-12-05 20:42:48,450 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4133912864225832, 'Total loss': 0.4133912864225832} | train loss {'Reaction outcome loss': 0.1257051589638598, 'Total loss': 0.1257051589638598}
2022-12-05 20:42:48,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:48,450 INFO:     Epoch: 83
2022-12-05 20:42:49,239 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4076448160816323, 'Total loss': 0.4076448160816323} | train loss {'Reaction outcome loss': 0.1240802192419526, 'Total loss': 0.1240802192419526}
2022-12-05 20:42:49,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:49,239 INFO:     Epoch: 84
2022-12-05 20:42:50,031 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4126795046031475, 'Total loss': 0.4126795046031475} | train loss {'Reaction outcome loss': 0.12671636704823025, 'Total loss': 0.12671636704823025}
2022-12-05 20:42:50,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:50,031 INFO:     Epoch: 85
2022-12-05 20:42:50,823 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41376480273902416, 'Total loss': 0.41376480273902416} | train loss {'Reaction outcome loss': 0.12527148500424226, 'Total loss': 0.12527148500424226}
2022-12-05 20:42:50,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:50,824 INFO:     Epoch: 86
2022-12-05 20:42:51,613 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41278021088378, 'Total loss': 0.41278021088378} | train loss {'Reaction outcome loss': 0.13223729024712855, 'Total loss': 0.13223729024712855}
2022-12-05 20:42:51,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:51,613 INFO:     Epoch: 87
2022-12-05 20:42:52,402 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4208307962187312, 'Total loss': 0.4208307962187312} | train loss {'Reaction outcome loss': 0.1345101258215996, 'Total loss': 0.1345101258215996}
2022-12-05 20:42:52,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:52,402 INFO:     Epoch: 88
2022-12-05 20:42:53,193 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4239565333859487, 'Total loss': 0.4239565333859487} | train loss {'Reaction outcome loss': 0.1261060876613445, 'Total loss': 0.1261060876613445}
2022-12-05 20:42:53,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:53,194 INFO:     Epoch: 89
2022-12-05 20:42:53,982 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4176186445084485, 'Total loss': 0.4176186445084485} | train loss {'Reaction outcome loss': 0.12361202684234873, 'Total loss': 0.12361202684234873}
2022-12-05 20:42:53,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:53,983 INFO:     Epoch: 90
2022-12-05 20:42:54,774 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4111435061151331, 'Total loss': 0.4111435061151331} | train loss {'Reaction outcome loss': 0.12208622944379142, 'Total loss': 0.12208622944379142}
2022-12-05 20:42:54,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:54,774 INFO:     Epoch: 91
2022-12-05 20:42:55,570 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42075142603028903, 'Total loss': 0.42075142603028903} | train loss {'Reaction outcome loss': 0.12186184569228033, 'Total loss': 0.12186184569228033}
2022-12-05 20:42:55,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:55,571 INFO:     Epoch: 92
2022-12-05 20:42:56,359 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4214008166031404, 'Total loss': 0.4214008166031404} | train loss {'Reaction outcome loss': 0.12467442949534382, 'Total loss': 0.12467442949534382}
2022-12-05 20:42:56,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:56,360 INFO:     Epoch: 93
2022-12-05 20:42:57,148 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4193704426288605, 'Total loss': 0.4193704426288605} | train loss {'Reaction outcome loss': 0.12152018132459312, 'Total loss': 0.12152018132459312}
2022-12-05 20:42:57,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:57,149 INFO:     Epoch: 94
2022-12-05 20:42:57,942 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4015044038268653, 'Total loss': 0.4015044038268653} | train loss {'Reaction outcome loss': 0.12051875679282403, 'Total loss': 0.12051875679282403}
2022-12-05 20:42:57,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:57,942 INFO:     Epoch: 95
2022-12-05 20:42:58,736 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40773266219449317, 'Total loss': 0.40773266219449317} | train loss {'Reaction outcome loss': 0.12483221029312264, 'Total loss': 0.12483221029312264}
2022-12-05 20:42:58,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:58,736 INFO:     Epoch: 96
2022-12-05 20:42:59,527 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4144450646232475, 'Total loss': 0.4144450646232475} | train loss {'Reaction outcome loss': 0.1192300035655951, 'Total loss': 0.1192300035655951}
2022-12-05 20:42:59,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:42:59,527 INFO:     Epoch: 97
2022-12-05 20:43:00,322 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4294344542378729, 'Total loss': 0.4294344542378729} | train loss {'Reaction outcome loss': 0.12209027959222374, 'Total loss': 0.12209027959222374}
2022-12-05 20:43:00,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:00,323 INFO:     Epoch: 98
2022-12-05 20:43:01,114 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4236823706464334, 'Total loss': 0.4236823706464334} | train loss {'Reaction outcome loss': 0.1229471974527305, 'Total loss': 0.1229471974527305}
2022-12-05 20:43:01,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:01,115 INFO:     Epoch: 99
2022-12-05 20:43:01,905 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4253039106049321, 'Total loss': 0.4253039106049321} | train loss {'Reaction outcome loss': 0.12273628750310736, 'Total loss': 0.12273628750310736}
2022-12-05 20:43:01,905 INFO:     Best model found after epoch 13 of 100.
2022-12-05 20:43:01,905 INFO:   Done with stage: TRAINING
2022-12-05 20:43:01,905 INFO:   Starting stage: EVALUATION
2022-12-05 20:43:02,030 INFO:   Done with stage: EVALUATION
2022-12-05 20:43:02,030 INFO:   Leaving out SEQ value Fold_2
2022-12-05 20:43:02,043 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:43:02,043 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:43:02,677 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:43:02,678 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:43:02,746 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:43:02,746 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:43:02,746 INFO:     No hyperparam tuning for this model
2022-12-05 20:43:02,746 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:43:02,746 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:43:02,747 INFO:     None feature selector for col prot
2022-12-05 20:43:02,747 INFO:     None feature selector for col prot
2022-12-05 20:43:02,747 INFO:     None feature selector for col prot
2022-12-05 20:43:02,748 INFO:     None feature selector for col chem
2022-12-05 20:43:02,748 INFO:     None feature selector for col chem
2022-12-05 20:43:02,748 INFO:     None feature selector for col chem
2022-12-05 20:43:02,748 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:43:02,748 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:43:02,750 INFO:     Number of params in model 215821
2022-12-05 20:43:02,753 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:43:02,753 INFO:   Starting stage: TRAINING
2022-12-05 20:43:02,812 INFO:     Val loss before train {'Reaction outcome loss': 1.0309084931085275, 'Total loss': 1.0309084931085275}
2022-12-05 20:43:02,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:02,813 INFO:     Epoch: 0
2022-12-05 20:43:03,602 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6272231652293094, 'Total loss': 0.6272231652293094} | train loss {'Reaction outcome loss': 0.7864977777248523, 'Total loss': 0.7864977777248523}
2022-12-05 20:43:03,602 INFO:     Found new best model at epoch 0
2022-12-05 20:43:03,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:03,603 INFO:     Epoch: 1
2022-12-05 20:43:04,388 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5313045708246009, 'Total loss': 0.5313045708246009} | train loss {'Reaction outcome loss': 0.5370803056437461, 'Total loss': 0.5370803056437461}
2022-12-05 20:43:04,388 INFO:     Found new best model at epoch 1
2022-12-05 20:43:04,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:04,389 INFO:     Epoch: 2
2022-12-05 20:43:05,173 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5047721717246744, 'Total loss': 0.5047721717246744} | train loss {'Reaction outcome loss': 0.46805333346128464, 'Total loss': 0.46805333346128464}
2022-12-05 20:43:05,173 INFO:     Found new best model at epoch 2
2022-12-05 20:43:05,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:05,174 INFO:     Epoch: 3
2022-12-05 20:43:05,957 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4703786432049995, 'Total loss': 0.4703786432049995} | train loss {'Reaction outcome loss': 0.4284539641659768, 'Total loss': 0.4284539641659768}
2022-12-05 20:43:05,957 INFO:     Found new best model at epoch 3
2022-12-05 20:43:05,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:05,958 INFO:     Epoch: 4
2022-12-05 20:43:06,743 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46105016490747763, 'Total loss': 0.46105016490747763} | train loss {'Reaction outcome loss': 0.40076969838777526, 'Total loss': 0.40076969838777526}
2022-12-05 20:43:06,743 INFO:     Found new best model at epoch 4
2022-12-05 20:43:06,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:06,744 INFO:     Epoch: 5
2022-12-05 20:43:07,526 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4426430456860121, 'Total loss': 0.4426430456860121} | train loss {'Reaction outcome loss': 0.37850937164831355, 'Total loss': 0.37850937164831355}
2022-12-05 20:43:07,527 INFO:     Found new best model at epoch 5
2022-12-05 20:43:07,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:07,528 INFO:     Epoch: 6
2022-12-05 20:43:08,316 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44580884936243986, 'Total loss': 0.44580884936243986} | train loss {'Reaction outcome loss': 0.357924114485256, 'Total loss': 0.357924114485256}
2022-12-05 20:43:08,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:08,316 INFO:     Epoch: 7
2022-12-05 20:43:09,104 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4435231148503547, 'Total loss': 0.4435231148503547} | train loss {'Reaction outcome loss': 0.3433589273911031, 'Total loss': 0.3433589273911031}
2022-12-05 20:43:09,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:09,104 INFO:     Epoch: 8
2022-12-05 20:43:09,885 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42725637312545334, 'Total loss': 0.42725637312545334} | train loss {'Reaction outcome loss': 0.3300721133585836, 'Total loss': 0.3300721133585836}
2022-12-05 20:43:09,885 INFO:     Found new best model at epoch 8
2022-12-05 20:43:09,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:09,886 INFO:     Epoch: 9
2022-12-05 20:43:10,667 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43258503425953, 'Total loss': 0.43258503425953} | train loss {'Reaction outcome loss': 0.31576477446150586, 'Total loss': 0.31576477446150586}
2022-12-05 20:43:10,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:10,668 INFO:     Epoch: 10
2022-12-05 20:43:11,449 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41577352687369945, 'Total loss': 0.41577352687369945} | train loss {'Reaction outcome loss': 0.3034978198101286, 'Total loss': 0.3034978198101286}
2022-12-05 20:43:11,449 INFO:     Found new best model at epoch 10
2022-12-05 20:43:11,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:11,450 INFO:     Epoch: 11
2022-12-05 20:43:12,230 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4129332019839176, 'Total loss': 0.4129332019839176} | train loss {'Reaction outcome loss': 0.29349928749267196, 'Total loss': 0.29349928749267196}
2022-12-05 20:43:12,230 INFO:     Found new best model at epoch 11
2022-12-05 20:43:12,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:12,231 INFO:     Epoch: 12
2022-12-05 20:43:13,012 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40940097346901894, 'Total loss': 0.40940097346901894} | train loss {'Reaction outcome loss': 0.2839585279465699, 'Total loss': 0.2839585279465699}
2022-12-05 20:43:13,012 INFO:     Found new best model at epoch 12
2022-12-05 20:43:13,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:13,013 INFO:     Epoch: 13
2022-12-05 20:43:13,794 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.415684710408366, 'Total loss': 0.415684710408366} | train loss {'Reaction outcome loss': 0.2756091092148277, 'Total loss': 0.2756091092148277}
2022-12-05 20:43:13,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:13,795 INFO:     Epoch: 14
2022-12-05 20:43:14,579 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41564338636952775, 'Total loss': 0.41564338636952775} | train loss {'Reaction outcome loss': 0.26378021509859895, 'Total loss': 0.26378021509859895}
2022-12-05 20:43:14,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:14,579 INFO:     Epoch: 15
2022-12-05 20:43:15,362 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42034671178390814, 'Total loss': 0.42034671178390814} | train loss {'Reaction outcome loss': 0.25846319573885596, 'Total loss': 0.25846319573885596}
2022-12-05 20:43:15,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:15,362 INFO:     Epoch: 16
2022-12-05 20:43:16,143 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4120794496563978, 'Total loss': 0.4120794496563978} | train loss {'Reaction outcome loss': 0.24938174004315353, 'Total loss': 0.24938174004315353}
2022-12-05 20:43:16,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:16,143 INFO:     Epoch: 17
2022-12-05 20:43:16,925 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4080426131570062, 'Total loss': 0.4080426131570062} | train loss {'Reaction outcome loss': 0.24250015289690652, 'Total loss': 0.24250015289690652}
2022-12-05 20:43:16,925 INFO:     Found new best model at epoch 17
2022-12-05 20:43:16,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:16,926 INFO:     Epoch: 18
2022-12-05 20:43:17,708 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41230155631553295, 'Total loss': 0.41230155631553295} | train loss {'Reaction outcome loss': 0.2377271167017886, 'Total loss': 0.2377271167017886}
2022-12-05 20:43:17,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:17,709 INFO:     Epoch: 19
2022-12-05 20:43:18,492 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4149335764868315, 'Total loss': 0.4149335764868315} | train loss {'Reaction outcome loss': 0.23110628528062438, 'Total loss': 0.23110628528062438}
2022-12-05 20:43:18,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:18,493 INFO:     Epoch: 20
2022-12-05 20:43:19,274 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42269973526167315, 'Total loss': 0.42269973526167315} | train loss {'Reaction outcome loss': 0.22487207355557895, 'Total loss': 0.22487207355557895}
2022-12-05 20:43:19,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:19,274 INFO:     Epoch: 21
2022-12-05 20:43:20,055 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4069802750681722, 'Total loss': 0.4069802750681722} | train loss {'Reaction outcome loss': 0.21988641101195186, 'Total loss': 0.21988641101195186}
2022-12-05 20:43:20,055 INFO:     Found new best model at epoch 21
2022-12-05 20:43:20,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:20,056 INFO:     Epoch: 22
2022-12-05 20:43:20,836 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4212066004442614, 'Total loss': 0.4212066004442614} | train loss {'Reaction outcome loss': 0.21556175316943496, 'Total loss': 0.21556175316943496}
2022-12-05 20:43:20,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:20,836 INFO:     Epoch: 23
2022-12-05 20:43:21,620 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4138359157151954, 'Total loss': 0.4138359157151954} | train loss {'Reaction outcome loss': 0.21255495341219863, 'Total loss': 0.21255495341219863}
2022-12-05 20:43:21,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:21,620 INFO:     Epoch: 24
2022-12-05 20:43:22,400 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4291576341141102, 'Total loss': 0.4291576341141102} | train loss {'Reaction outcome loss': 0.2042210283460187, 'Total loss': 0.2042210283460187}
2022-12-05 20:43:22,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:22,401 INFO:     Epoch: 25
2022-12-05 20:43:23,182 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4121327348226725, 'Total loss': 0.4121327348226725} | train loss {'Reaction outcome loss': 0.20461568563840674, 'Total loss': 0.20461568563840674}
2022-12-05 20:43:23,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:23,182 INFO:     Epoch: 26
2022-12-05 20:43:23,963 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4111604586590168, 'Total loss': 0.4111604586590168} | train loss {'Reaction outcome loss': 0.19771462822424585, 'Total loss': 0.19771462822424585}
2022-12-05 20:43:23,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:23,963 INFO:     Epoch: 27
2022-12-05 20:43:24,747 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4138645751531734, 'Total loss': 0.4138645751531734} | train loss {'Reaction outcome loss': 0.1955476847675736, 'Total loss': 0.1955476847675736}
2022-12-05 20:43:24,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:24,748 INFO:     Epoch: 28
2022-12-05 20:43:25,528 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4173632510179697, 'Total loss': 0.4173632510179697} | train loss {'Reaction outcome loss': 0.19229223328779954, 'Total loss': 0.19229223328779954}
2022-12-05 20:43:25,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:25,529 INFO:     Epoch: 29
2022-12-05 20:43:26,313 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4341323597486629, 'Total loss': 0.4341323597486629} | train loss {'Reaction outcome loss': 0.19029634321474884, 'Total loss': 0.19029634321474884}
2022-12-05 20:43:26,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:26,313 INFO:     Epoch: 30
2022-12-05 20:43:27,100 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42426482951918315, 'Total loss': 0.42426482951918315} | train loss {'Reaction outcome loss': 0.18511215853886526, 'Total loss': 0.18511215853886526}
2022-12-05 20:43:27,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:27,100 INFO:     Epoch: 31
2022-12-05 20:43:27,888 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42291195101516194, 'Total loss': 0.42291195101516194} | train loss {'Reaction outcome loss': 0.18258971113284103, 'Total loss': 0.18258971113284103}
2022-12-05 20:43:27,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:27,888 INFO:     Epoch: 32
2022-12-05 20:43:28,679 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42732042316780533, 'Total loss': 0.42732042316780533} | train loss {'Reaction outcome loss': 0.1801024704377671, 'Total loss': 0.1801024704377671}
2022-12-05 20:43:28,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:28,679 INFO:     Epoch: 33
2022-12-05 20:43:29,464 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42245226440041567, 'Total loss': 0.42245226440041567} | train loss {'Reaction outcome loss': 0.175758361862209, 'Total loss': 0.175758361862209}
2022-12-05 20:43:29,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:29,464 INFO:     Epoch: 34
2022-12-05 20:43:30,251 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4324175057023071, 'Total loss': 0.4324175057023071} | train loss {'Reaction outcome loss': 0.17492983494808928, 'Total loss': 0.17492983494808928}
2022-12-05 20:43:30,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:30,251 INFO:     Epoch: 35
2022-12-05 20:43:31,033 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4404974361491758, 'Total loss': 0.4404974361491758} | train loss {'Reaction outcome loss': 0.17207700756118924, 'Total loss': 0.17207700756118924}
2022-12-05 20:43:31,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:31,033 INFO:     Epoch: 36
2022-12-05 20:43:31,814 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4339265608510306, 'Total loss': 0.4339265608510306} | train loss {'Reaction outcome loss': 0.16810617127196223, 'Total loss': 0.16810617127196223}
2022-12-05 20:43:31,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:31,814 INFO:     Epoch: 37
2022-12-05 20:43:32,598 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42843098072118535, 'Total loss': 0.42843098072118535} | train loss {'Reaction outcome loss': 0.16806782986663404, 'Total loss': 0.16806782986663404}
2022-12-05 20:43:32,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:32,599 INFO:     Epoch: 38
2022-12-05 20:43:33,381 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4286286889813667, 'Total loss': 0.4286286889813667} | train loss {'Reaction outcome loss': 0.16720820282448512, 'Total loss': 0.16720820282448512}
2022-12-05 20:43:33,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:33,381 INFO:     Epoch: 39
2022-12-05 20:43:34,166 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44103035590676376, 'Total loss': 0.44103035590676376} | train loss {'Reaction outcome loss': 0.16386218525499838, 'Total loss': 0.16386218525499838}
2022-12-05 20:43:34,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:34,166 INFO:     Epoch: 40
2022-12-05 20:43:34,947 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4335458249200222, 'Total loss': 0.4335458249200222} | train loss {'Reaction outcome loss': 0.16045235705058106, 'Total loss': 0.16045235705058106}
2022-12-05 20:43:34,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:34,947 INFO:     Epoch: 41
2022-12-05 20:43:35,728 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43246134561161664, 'Total loss': 0.43246134561161664} | train loss {'Reaction outcome loss': 0.16154433454035735, 'Total loss': 0.16154433454035735}
2022-12-05 20:43:35,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:35,729 INFO:     Epoch: 42
2022-12-05 20:43:36,514 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44088417499564414, 'Total loss': 0.44088417499564414} | train loss {'Reaction outcome loss': 0.1603979716291193, 'Total loss': 0.1603979716291193}
2022-12-05 20:43:36,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:36,515 INFO:     Epoch: 43
2022-12-05 20:43:37,294 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4339386630196904, 'Total loss': 0.4339386630196904} | train loss {'Reaction outcome loss': 0.15866288855732952, 'Total loss': 0.15866288855732952}
2022-12-05 20:43:37,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:37,294 INFO:     Epoch: 44
2022-12-05 20:43:38,077 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44274503824322725, 'Total loss': 0.44274503824322725} | train loss {'Reaction outcome loss': 0.15470652802099213, 'Total loss': 0.15470652802099213}
2022-12-05 20:43:38,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:38,078 INFO:     Epoch: 45
2022-12-05 20:43:38,861 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44724586813948874, 'Total loss': 0.44724586813948874} | train loss {'Reaction outcome loss': 0.15720222265169512, 'Total loss': 0.15720222265169512}
2022-12-05 20:43:38,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:38,861 INFO:     Epoch: 46
2022-12-05 20:43:39,639 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4429863861133886, 'Total loss': 0.4429863861133886} | train loss {'Reaction outcome loss': 0.15451089074438223, 'Total loss': 0.15451089074438223}
2022-12-05 20:43:39,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:39,639 INFO:     Epoch: 47
2022-12-05 20:43:40,421 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4387482508670452, 'Total loss': 0.4387482508670452} | train loss {'Reaction outcome loss': 0.15497272845632473, 'Total loss': 0.15497272845632473}
2022-12-05 20:43:40,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:40,421 INFO:     Epoch: 48
2022-12-05 20:43:41,202 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4474336106416791, 'Total loss': 0.4474336106416791} | train loss {'Reaction outcome loss': 0.1520517780445516, 'Total loss': 0.1520517780445516}
2022-12-05 20:43:41,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:41,203 INFO:     Epoch: 49
2022-12-05 20:43:41,982 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44361647963523865, 'Total loss': 0.44361647963523865} | train loss {'Reaction outcome loss': 0.1503181534926178, 'Total loss': 0.1503181534926178}
2022-12-05 20:43:41,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:41,982 INFO:     Epoch: 50
2022-12-05 20:43:42,765 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43339910028978834, 'Total loss': 0.43339910028978834} | train loss {'Reaction outcome loss': 0.14781163948527004, 'Total loss': 0.14781163948527004}
2022-12-05 20:43:42,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:42,765 INFO:     Epoch: 51
2022-12-05 20:43:43,543 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44569793863351953, 'Total loss': 0.44569793863351953} | train loss {'Reaction outcome loss': 0.14572144615021151, 'Total loss': 0.14572144615021151}
2022-12-05 20:43:43,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:43,543 INFO:     Epoch: 52
2022-12-05 20:43:44,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4537999293831892, 'Total loss': 0.4537999293831892} | train loss {'Reaction outcome loss': 0.14669695704961655, 'Total loss': 0.14669695704961655}
2022-12-05 20:43:44,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:44,319 INFO:     Epoch: 53
2022-12-05 20:43:45,096 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4384065121412277, 'Total loss': 0.4384065121412277} | train loss {'Reaction outcome loss': 0.14415264232313169, 'Total loss': 0.14415264232313169}
2022-12-05 20:43:45,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:45,096 INFO:     Epoch: 54
2022-12-05 20:43:45,872 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45078891203847044, 'Total loss': 0.45078891203847044} | train loss {'Reaction outcome loss': 0.1435217544757074, 'Total loss': 0.1435217544757074}
2022-12-05 20:43:45,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:45,872 INFO:     Epoch: 55
2022-12-05 20:43:46,657 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4528006429589072, 'Total loss': 0.4528006429589072} | train loss {'Reaction outcome loss': 0.14344449918411795, 'Total loss': 0.14344449918411795}
2022-12-05 20:43:46,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:46,657 INFO:     Epoch: 56
2022-12-05 20:43:47,444 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4527105640533359, 'Total loss': 0.4527105640533359} | train loss {'Reaction outcome loss': 0.14329520657231085, 'Total loss': 0.14329520657231085}
2022-12-05 20:43:47,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:47,444 INFO:     Epoch: 57
2022-12-05 20:43:48,221 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44446458719497506, 'Total loss': 0.44446458719497506} | train loss {'Reaction outcome loss': 0.14140849741420053, 'Total loss': 0.14140849741420053}
2022-12-05 20:43:48,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:48,221 INFO:     Epoch: 58
2022-12-05 20:43:49,001 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4429357488488042, 'Total loss': 0.4429357488488042} | train loss {'Reaction outcome loss': 0.14052789401812632, 'Total loss': 0.14052789401812632}
2022-12-05 20:43:49,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:49,001 INFO:     Epoch: 59
2022-12-05 20:43:49,778 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4504248163727827, 'Total loss': 0.4504248163727827} | train loss {'Reaction outcome loss': 0.13811693292447044, 'Total loss': 0.13811693292447044}
2022-12-05 20:43:49,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:49,779 INFO:     Epoch: 60
2022-12-05 20:43:50,556 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46786626480346505, 'Total loss': 0.46786626480346505} | train loss {'Reaction outcome loss': 0.1374846783726186, 'Total loss': 0.1374846783726186}
2022-12-05 20:43:50,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:50,557 INFO:     Epoch: 61
2022-12-05 20:43:51,333 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4651572077080261, 'Total loss': 0.4651572077080261} | train loss {'Reaction outcome loss': 0.14046056758704, 'Total loss': 0.14046056758704}
2022-12-05 20:43:51,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:51,333 INFO:     Epoch: 62
2022-12-05 20:43:52,110 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45357859515866567, 'Total loss': 0.45357859515866567} | train loss {'Reaction outcome loss': 0.1402733975288565, 'Total loss': 0.1402733975288565}
2022-12-05 20:43:52,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:52,110 INFO:     Epoch: 63
2022-12-05 20:43:52,886 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4427809715270996, 'Total loss': 0.4427809715270996} | train loss {'Reaction outcome loss': 0.13294928119380456, 'Total loss': 0.13294928119380456}
2022-12-05 20:43:52,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:52,887 INFO:     Epoch: 64
2022-12-05 20:43:53,671 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45892755999121554, 'Total loss': 0.45892755999121554} | train loss {'Reaction outcome loss': 0.13519247734277953, 'Total loss': 0.13519247734277953}
2022-12-05 20:43:53,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:53,671 INFO:     Epoch: 65
2022-12-05 20:43:54,450 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45140524607065113, 'Total loss': 0.45140524607065113} | train loss {'Reaction outcome loss': 0.13487847298231037, 'Total loss': 0.13487847298231037}
2022-12-05 20:43:54,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:54,450 INFO:     Epoch: 66
2022-12-05 20:43:55,233 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4522441247867983, 'Total loss': 0.4522441247867983} | train loss {'Reaction outcome loss': 0.13412796742603428, 'Total loss': 0.13412796742603428}
2022-12-05 20:43:55,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:55,233 INFO:     Epoch: 67
2022-12-05 20:43:56,012 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44011605201765547, 'Total loss': 0.44011605201765547} | train loss {'Reaction outcome loss': 0.1351391836374876, 'Total loss': 0.1351391836374876}
2022-12-05 20:43:56,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:56,012 INFO:     Epoch: 68
2022-12-05 20:43:56,795 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45729383687640346, 'Total loss': 0.45729383687640346} | train loss {'Reaction outcome loss': 0.13427723902583, 'Total loss': 0.13427723902583}
2022-12-05 20:43:56,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:56,795 INFO:     Epoch: 69
2022-12-05 20:43:57,583 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44652578234672546, 'Total loss': 0.44652578234672546} | train loss {'Reaction outcome loss': 0.13162292439689036, 'Total loss': 0.13162292439689036}
2022-12-05 20:43:57,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:57,583 INFO:     Epoch: 70
2022-12-05 20:43:58,371 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44224993052870726, 'Total loss': 0.44224993052870726} | train loss {'Reaction outcome loss': 0.1347834661786185, 'Total loss': 0.1347834661786185}
2022-12-05 20:43:58,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:58,371 INFO:     Epoch: 71
2022-12-05 20:43:59,152 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44933067227518836, 'Total loss': 0.44933067227518836} | train loss {'Reaction outcome loss': 0.12913034211264038, 'Total loss': 0.12913034211264038}
2022-12-05 20:43:59,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:59,152 INFO:     Epoch: 72
2022-12-05 20:43:59,933 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45514557216056556, 'Total loss': 0.45514557216056556} | train loss {'Reaction outcome loss': 0.1289951183459126, 'Total loss': 0.1289951183459126}
2022-12-05 20:43:59,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:43:59,934 INFO:     Epoch: 73
2022-12-05 20:44:00,717 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.461991285515386, 'Total loss': 0.461991285515386} | train loss {'Reaction outcome loss': 0.12956317327916622, 'Total loss': 0.12956317327916622}
2022-12-05 20:44:00,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:00,717 INFO:     Epoch: 74
2022-12-05 20:44:01,499 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44947577735712363, 'Total loss': 0.44947577735712363} | train loss {'Reaction outcome loss': 0.13136265639856945, 'Total loss': 0.13136265639856945}
2022-12-05 20:44:01,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:01,499 INFO:     Epoch: 75
2022-12-05 20:44:02,283 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45507536031479057, 'Total loss': 0.45507536031479057} | train loss {'Reaction outcome loss': 0.1304241706823289, 'Total loss': 0.1304241706823289}
2022-12-05 20:44:02,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:02,283 INFO:     Epoch: 76
2022-12-05 20:44:03,068 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4520097572443097, 'Total loss': 0.4520097572443097} | train loss {'Reaction outcome loss': 0.1267978296554113, 'Total loss': 0.1267978296554113}
2022-12-05 20:44:03,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:03,069 INFO:     Epoch: 77
2022-12-05 20:44:03,852 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45303308409313825, 'Total loss': 0.45303308409313825} | train loss {'Reaction outcome loss': 0.12319310712551729, 'Total loss': 0.12319310712551729}
2022-12-05 20:44:03,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:03,853 INFO:     Epoch: 78
2022-12-05 20:44:04,634 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45333630158457644, 'Total loss': 0.45333630158457644} | train loss {'Reaction outcome loss': 0.12582665786803623, 'Total loss': 0.12582665786803623}
2022-12-05 20:44:04,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:04,635 INFO:     Epoch: 79
2022-12-05 20:44:05,422 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45258025027984794, 'Total loss': 0.45258025027984794} | train loss {'Reaction outcome loss': 0.1269155697148965, 'Total loss': 0.1269155697148965}
2022-12-05 20:44:05,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:05,422 INFO:     Epoch: 80
2022-12-05 20:44:06,205 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45280350536801095, 'Total loss': 0.45280350536801095} | train loss {'Reaction outcome loss': 0.1276046870596951, 'Total loss': 0.1276046870596951}
2022-12-05 20:44:06,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:06,206 INFO:     Epoch: 81
2022-12-05 20:44:06,987 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4564765251653139, 'Total loss': 0.4564765251653139} | train loss {'Reaction outcome loss': 0.12571102640683168, 'Total loss': 0.12571102640683168}
2022-12-05 20:44:06,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:06,987 INFO:     Epoch: 82
2022-12-05 20:44:07,770 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4493014784746392, 'Total loss': 0.4493014784746392} | train loss {'Reaction outcome loss': 0.12943266578720974, 'Total loss': 0.12943266578720974}
2022-12-05 20:44:07,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:07,770 INFO:     Epoch: 83
2022-12-05 20:44:08,553 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46110544648281365, 'Total loss': 0.46110544648281365} | train loss {'Reaction outcome loss': 0.1267773523262595, 'Total loss': 0.1267773523262595}
2022-12-05 20:44:08,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:08,553 INFO:     Epoch: 84
2022-12-05 20:44:09,334 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45638218937918196, 'Total loss': 0.45638218937918196} | train loss {'Reaction outcome loss': 0.1263846191844796, 'Total loss': 0.1263846191844796}
2022-12-05 20:44:09,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:09,334 INFO:     Epoch: 85
2022-12-05 20:44:10,120 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45144074670104095, 'Total loss': 0.45144074670104095} | train loss {'Reaction outcome loss': 0.12311651612647244, 'Total loss': 0.12311651612647244}
2022-12-05 20:44:10,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:10,121 INFO:     Epoch: 86
2022-12-05 20:44:10,906 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45306615791348526, 'Total loss': 0.45306615791348526} | train loss {'Reaction outcome loss': 0.12442144282070584, 'Total loss': 0.12442144282070584}
2022-12-05 20:44:10,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:10,906 INFO:     Epoch: 87
2022-12-05 20:44:11,692 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4699570638842361, 'Total loss': 0.4699570638842361} | train loss {'Reaction outcome loss': 0.12425102647699293, 'Total loss': 0.12425102647699293}
2022-12-05 20:44:11,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:11,692 INFO:     Epoch: 88
2022-12-05 20:44:12,473 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45479807898748753, 'Total loss': 0.45479807898748753} | train loss {'Reaction outcome loss': 0.12220997769828336, 'Total loss': 0.12220997769828336}
2022-12-05 20:44:12,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:12,473 INFO:     Epoch: 89
2022-12-05 20:44:13,256 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47194246185380356, 'Total loss': 0.47194246185380356} | train loss {'Reaction outcome loss': 0.12281584980912873, 'Total loss': 0.12281584980912873}
2022-12-05 20:44:13,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:13,256 INFO:     Epoch: 90
2022-12-05 20:44:14,040 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4512819398281186, 'Total loss': 0.4512819398281186} | train loss {'Reaction outcome loss': 0.12444054836514176, 'Total loss': 0.12444054836514176}
2022-12-05 20:44:14,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:14,041 INFO:     Epoch: 91
2022-12-05 20:44:14,826 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48351402788661246, 'Total loss': 0.48351402788661246} | train loss {'Reaction outcome loss': 0.12369723676047364, 'Total loss': 0.12369723676047364}
2022-12-05 20:44:14,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:14,826 INFO:     Epoch: 92
2022-12-05 20:44:15,608 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4589177293832912, 'Total loss': 0.4589177293832912} | train loss {'Reaction outcome loss': 0.1216079986837433, 'Total loss': 0.1216079986837433}
2022-12-05 20:44:15,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:15,608 INFO:     Epoch: 93
2022-12-05 20:44:16,389 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44316504497167675, 'Total loss': 0.44316504497167675} | train loss {'Reaction outcome loss': 0.1224295050821832, 'Total loss': 0.1224295050821832}
2022-12-05 20:44:16,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:16,390 INFO:     Epoch: 94
2022-12-05 20:44:17,171 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.457789336179578, 'Total loss': 0.457789336179578} | train loss {'Reaction outcome loss': 0.12241336415888222, 'Total loss': 0.12241336415888222}
2022-12-05 20:44:17,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:17,171 INFO:     Epoch: 95
2022-12-05 20:44:17,952 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4590457962002865, 'Total loss': 0.4590457962002865} | train loss {'Reaction outcome loss': 0.12243446169924907, 'Total loss': 0.12243446169924907}
2022-12-05 20:44:17,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:17,953 INFO:     Epoch: 96
2022-12-05 20:44:18,736 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46291892559722414, 'Total loss': 0.46291892559722414} | train loss {'Reaction outcome loss': 0.12200224565601618, 'Total loss': 0.12200224565601618}
2022-12-05 20:44:18,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:18,736 INFO:     Epoch: 97
2022-12-05 20:44:19,517 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.453694291239561, 'Total loss': 0.453694291239561} | train loss {'Reaction outcome loss': 0.12058788938753184, 'Total loss': 0.12058788938753184}
2022-12-05 20:44:19,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:19,518 INFO:     Epoch: 98
2022-12-05 20:44:20,298 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45431014410285064, 'Total loss': 0.45431014410285064} | train loss {'Reaction outcome loss': 0.11995370959153125, 'Total loss': 0.11995370959153125}
2022-12-05 20:44:20,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:20,298 INFO:     Epoch: 99
2022-12-05 20:44:21,080 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4572867518940637, 'Total loss': 0.4572867518940637} | train loss {'Reaction outcome loss': 0.11859282942824677, 'Total loss': 0.11859282942824677}
2022-12-05 20:44:21,081 INFO:     Best model found after epoch 22 of 100.
2022-12-05 20:44:21,081 INFO:   Done with stage: TRAINING
2022-12-05 20:44:21,081 INFO:   Starting stage: EVALUATION
2022-12-05 20:44:21,217 INFO:   Done with stage: EVALUATION
2022-12-05 20:44:21,217 INFO:   Leaving out SEQ value Fold_3
2022-12-05 20:44:21,230 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:44:21,230 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:44:21,868 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:44:21,868 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:44:21,937 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:44:21,937 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:44:21,937 INFO:     No hyperparam tuning for this model
2022-12-05 20:44:21,937 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:44:21,937 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:44:21,938 INFO:     None feature selector for col prot
2022-12-05 20:44:21,938 INFO:     None feature selector for col prot
2022-12-05 20:44:21,938 INFO:     None feature selector for col prot
2022-12-05 20:44:21,938 INFO:     None feature selector for col chem
2022-12-05 20:44:21,939 INFO:     None feature selector for col chem
2022-12-05 20:44:21,939 INFO:     None feature selector for col chem
2022-12-05 20:44:21,939 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:44:21,939 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:44:21,940 INFO:     Number of params in model 215821
2022-12-05 20:44:21,943 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:44:21,944 INFO:   Starting stage: TRAINING
2022-12-05 20:44:22,004 INFO:     Val loss before train {'Reaction outcome loss': 0.9891292601823807, 'Total loss': 0.9891292601823807}
2022-12-05 20:44:22,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:22,004 INFO:     Epoch: 0
2022-12-05 20:44:22,790 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6118008338592269, 'Total loss': 0.6118008338592269} | train loss {'Reaction outcome loss': 0.8005728637685581, 'Total loss': 0.8005728637685581}
2022-12-05 20:44:22,790 INFO:     Found new best model at epoch 0
2022-12-05 20:44:22,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:22,791 INFO:     Epoch: 1
2022-12-05 20:44:23,577 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5218147408555854, 'Total loss': 0.5218147408555854} | train loss {'Reaction outcome loss': 0.5475047038525951, 'Total loss': 0.5475047038525951}
2022-12-05 20:44:23,577 INFO:     Found new best model at epoch 1
2022-12-05 20:44:23,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:23,578 INFO:     Epoch: 2
2022-12-05 20:44:24,364 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4982901581309058, 'Total loss': 0.4982901581309058} | train loss {'Reaction outcome loss': 0.477025246376894, 'Total loss': 0.477025246376894}
2022-12-05 20:44:24,364 INFO:     Found new best model at epoch 2
2022-12-05 20:44:24,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:24,365 INFO:     Epoch: 3
2022-12-05 20:44:25,153 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4806375801563263, 'Total loss': 0.4806375801563263} | train loss {'Reaction outcome loss': 0.4380804466957949, 'Total loss': 0.4380804466957949}
2022-12-05 20:44:25,153 INFO:     Found new best model at epoch 3
2022-12-05 20:44:25,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:25,154 INFO:     Epoch: 4
2022-12-05 20:44:25,938 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45648126219483937, 'Total loss': 0.45648126219483937} | train loss {'Reaction outcome loss': 0.4068750962310908, 'Total loss': 0.4068750962310908}
2022-12-05 20:44:25,939 INFO:     Found new best model at epoch 4
2022-12-05 20:44:25,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:25,939 INFO:     Epoch: 5
2022-12-05 20:44:26,723 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43705465170470154, 'Total loss': 0.43705465170470154} | train loss {'Reaction outcome loss': 0.38241582664908197, 'Total loss': 0.38241582664908197}
2022-12-05 20:44:26,723 INFO:     Found new best model at epoch 5
2022-12-05 20:44:26,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:26,724 INFO:     Epoch: 6
2022-12-05 20:44:27,508 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4408103224228729, 'Total loss': 0.4408103224228729} | train loss {'Reaction outcome loss': 0.362201175276114, 'Total loss': 0.362201175276114}
2022-12-05 20:44:27,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:27,508 INFO:     Epoch: 7
2022-12-05 20:44:28,292 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4339145344089378, 'Total loss': 0.4339145344089378} | train loss {'Reaction outcome loss': 0.34239145620745054, 'Total loss': 0.34239145620745054}
2022-12-05 20:44:28,292 INFO:     Found new best model at epoch 7
2022-12-05 20:44:28,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:28,293 INFO:     Epoch: 8
2022-12-05 20:44:29,077 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4478394483978098, 'Total loss': 0.4478394483978098} | train loss {'Reaction outcome loss': 0.32809881578598704, 'Total loss': 0.32809881578598704}
2022-12-05 20:44:29,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:29,078 INFO:     Epoch: 9
2022-12-05 20:44:29,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4191682768816298, 'Total loss': 0.4191682768816298} | train loss {'Reaction outcome loss': 0.3124699557922324, 'Total loss': 0.3124699557922324}
2022-12-05 20:44:29,867 INFO:     Found new best model at epoch 9
2022-12-05 20:44:29,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:29,868 INFO:     Epoch: 10
2022-12-05 20:44:30,655 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4201373788104816, 'Total loss': 0.4201373788104816} | train loss {'Reaction outcome loss': 0.2975514453892805, 'Total loss': 0.2975514453892805}
2022-12-05 20:44:30,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:30,655 INFO:     Epoch: 11
2022-12-05 20:44:31,438 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42351957342841406, 'Total loss': 0.42351957342841406} | train loss {'Reaction outcome loss': 0.2867906496536975, 'Total loss': 0.2867906496536975}
2022-12-05 20:44:31,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:31,438 INFO:     Epoch: 12
2022-12-05 20:44:32,223 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4271009081805294, 'Total loss': 0.4271009081805294} | train loss {'Reaction outcome loss': 0.27677256884623547, 'Total loss': 0.27677256884623547}
2022-12-05 20:44:32,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:32,223 INFO:     Epoch: 13
2022-12-05 20:44:33,007 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43311340565031226, 'Total loss': 0.43311340565031226} | train loss {'Reaction outcome loss': 0.26453406816842606, 'Total loss': 0.26453406816842606}
2022-12-05 20:44:33,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:33,007 INFO:     Epoch: 14
2022-12-05 20:44:33,791 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42115009258585895, 'Total loss': 0.42115009258585895} | train loss {'Reaction outcome loss': 0.2565680158685665, 'Total loss': 0.2565680158685665}
2022-12-05 20:44:33,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:33,791 INFO:     Epoch: 15
2022-12-05 20:44:34,575 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42829417234117334, 'Total loss': 0.42829417234117334} | train loss {'Reaction outcome loss': 0.2513577107264071, 'Total loss': 0.2513577107264071}
2022-12-05 20:44:34,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:34,575 INFO:     Epoch: 16
2022-12-05 20:44:35,358 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4380719607526606, 'Total loss': 0.4380719607526606} | train loss {'Reaction outcome loss': 0.24040981411021584, 'Total loss': 0.24040981411021584}
2022-12-05 20:44:35,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:35,358 INFO:     Epoch: 17
2022-12-05 20:44:36,147 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4316578664901582, 'Total loss': 0.4316578664901582} | train loss {'Reaction outcome loss': 0.23687047243726497, 'Total loss': 0.23687047243726497}
2022-12-05 20:44:36,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:36,148 INFO:     Epoch: 18
2022-12-05 20:44:36,934 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4260004631836306, 'Total loss': 0.4260004631836306} | train loss {'Reaction outcome loss': 0.22825905025309445, 'Total loss': 0.22825905025309445}
2022-12-05 20:44:36,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:36,935 INFO:     Epoch: 19
2022-12-05 20:44:37,724 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4335119074041193, 'Total loss': 0.4335119074041193} | train loss {'Reaction outcome loss': 0.22224246651238325, 'Total loss': 0.22224246651238325}
2022-12-05 20:44:37,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:37,724 INFO:     Epoch: 20
2022-12-05 20:44:38,507 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43777295100418007, 'Total loss': 0.43777295100418007} | train loss {'Reaction outcome loss': 0.21524936429091862, 'Total loss': 0.21524936429091862}
2022-12-05 20:44:38,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:38,508 INFO:     Epoch: 21
2022-12-05 20:44:39,291 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44348260963504965, 'Total loss': 0.44348260963504965} | train loss {'Reaction outcome loss': 0.21056323734169102, 'Total loss': 0.21056323734169102}
2022-12-05 20:44:39,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:39,291 INFO:     Epoch: 22
2022-12-05 20:44:40,079 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4481293708086014, 'Total loss': 0.4481293708086014} | train loss {'Reaction outcome loss': 0.2062493045415197, 'Total loss': 0.2062493045415197}
2022-12-05 20:44:40,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:40,079 INFO:     Epoch: 23
2022-12-05 20:44:40,865 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44697823392396624, 'Total loss': 0.44697823392396624} | train loss {'Reaction outcome loss': 0.20332339579353528, 'Total loss': 0.20332339579353528}
2022-12-05 20:44:40,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:40,866 INFO:     Epoch: 24
2022-12-05 20:44:41,651 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4441626173528758, 'Total loss': 0.4441626173528758} | train loss {'Reaction outcome loss': 0.19767774396709034, 'Total loss': 0.19767774396709034}
2022-12-05 20:44:41,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:41,652 INFO:     Epoch: 25
2022-12-05 20:44:42,439 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45179802585731854, 'Total loss': 0.45179802585731854} | train loss {'Reaction outcome loss': 0.19265042385276482, 'Total loss': 0.19265042385276482}
2022-12-05 20:44:42,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:42,439 INFO:     Epoch: 26
2022-12-05 20:44:43,223 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4386008219285445, 'Total loss': 0.4386008219285445} | train loss {'Reaction outcome loss': 0.1899555341321595, 'Total loss': 0.1899555341321595}
2022-12-05 20:44:43,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:43,223 INFO:     Epoch: 27
2022-12-05 20:44:44,015 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45222148434682324, 'Total loss': 0.45222148434682324} | train loss {'Reaction outcome loss': 0.18621804104471693, 'Total loss': 0.18621804104471693}
2022-12-05 20:44:44,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:44,015 INFO:     Epoch: 28
2022-12-05 20:44:44,799 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45256461135365744, 'Total loss': 0.45256461135365744} | train loss {'Reaction outcome loss': 0.18352345065498837, 'Total loss': 0.18352345065498837}
2022-12-05 20:44:44,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:44,799 INFO:     Epoch: 29
2022-12-05 20:44:45,586 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47393274713646283, 'Total loss': 0.47393274713646283} | train loss {'Reaction outcome loss': 0.18038102380779325, 'Total loss': 0.18038102380779325}
2022-12-05 20:44:45,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:45,586 INFO:     Epoch: 30
2022-12-05 20:44:46,374 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47032919424501335, 'Total loss': 0.47032919424501335} | train loss {'Reaction outcome loss': 0.17700435011362542, 'Total loss': 0.17700435011362542}
2022-12-05 20:44:46,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:46,375 INFO:     Epoch: 31
2022-12-05 20:44:47,158 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45356340435418213, 'Total loss': 0.45356340435418213} | train loss {'Reaction outcome loss': 0.1718095942571455, 'Total loss': 0.1718095942571455}
2022-12-05 20:44:47,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:47,159 INFO:     Epoch: 32
2022-12-05 20:44:47,944 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46285235932604835, 'Total loss': 0.46285235932604835} | train loss {'Reaction outcome loss': 0.172073069108384, 'Total loss': 0.172073069108384}
2022-12-05 20:44:47,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:47,944 INFO:     Epoch: 33
2022-12-05 20:44:48,728 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4653449481014501, 'Total loss': 0.4653449481014501} | train loss {'Reaction outcome loss': 0.16903952810229086, 'Total loss': 0.16903952810229086}
2022-12-05 20:44:48,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:48,728 INFO:     Epoch: 34
2022-12-05 20:44:49,515 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47368509390137414, 'Total loss': 0.47368509390137414} | train loss {'Reaction outcome loss': 0.16858607167188003, 'Total loss': 0.16858607167188003}
2022-12-05 20:44:49,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:49,515 INFO:     Epoch: 35
2022-12-05 20:44:50,305 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46421046047048137, 'Total loss': 0.46421046047048137} | train loss {'Reaction outcome loss': 0.16379873576973167, 'Total loss': 0.16379873576973167}
2022-12-05 20:44:50,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:50,305 INFO:     Epoch: 36
2022-12-05 20:44:51,093 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46893867376175796, 'Total loss': 0.46893867376175796} | train loss {'Reaction outcome loss': 0.16721081282867462, 'Total loss': 0.16721081282867462}
2022-12-05 20:44:51,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:51,093 INFO:     Epoch: 37
2022-12-05 20:44:51,876 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46630934151736175, 'Total loss': 0.46630934151736175} | train loss {'Reaction outcome loss': 0.16281805601047009, 'Total loss': 0.16281805601047009}
2022-12-05 20:44:51,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:51,876 INFO:     Epoch: 38
2022-12-05 20:44:52,660 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47049886817959224, 'Total loss': 0.47049886817959224} | train loss {'Reaction outcome loss': 0.1576828065423333, 'Total loss': 0.1576828065423333}
2022-12-05 20:44:52,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:52,660 INFO:     Epoch: 39
2022-12-05 20:44:53,443 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4640699852765961, 'Total loss': 0.4640699852765961} | train loss {'Reaction outcome loss': 0.15693166461602157, 'Total loss': 0.15693166461602157}
2022-12-05 20:44:53,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:53,444 INFO:     Epoch: 40
2022-12-05 20:44:54,230 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4811411767520688, 'Total loss': 0.4811411767520688} | train loss {'Reaction outcome loss': 0.15664684086733935, 'Total loss': 0.15664684086733935}
2022-12-05 20:44:54,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:54,230 INFO:     Epoch: 41
2022-12-05 20:44:55,020 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46998101980848744, 'Total loss': 0.46998101980848744} | train loss {'Reaction outcome loss': 0.1566956218103973, 'Total loss': 0.1566956218103973}
2022-12-05 20:44:55,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:55,021 INFO:     Epoch: 42
2022-12-05 20:44:55,814 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48556759919632564, 'Total loss': 0.48556759919632564} | train loss {'Reaction outcome loss': 0.15229144108918857, 'Total loss': 0.15229144108918857}
2022-12-05 20:44:55,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:55,814 INFO:     Epoch: 43
2022-12-05 20:44:56,602 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47511856494979426, 'Total loss': 0.47511856494979426} | train loss {'Reaction outcome loss': 0.15251021111498073, 'Total loss': 0.15251021111498073}
2022-12-05 20:44:56,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:56,602 INFO:     Epoch: 44
2022-12-05 20:44:57,394 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48225082558664406, 'Total loss': 0.48225082558664406} | train loss {'Reaction outcome loss': 0.15059939362108707, 'Total loss': 0.15059939362108707}
2022-12-05 20:44:57,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:57,394 INFO:     Epoch: 45
2022-12-05 20:44:58,183 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4782251051881097, 'Total loss': 0.4782251051881097} | train loss {'Reaction outcome loss': 0.14991756397090397, 'Total loss': 0.14991756397090397}
2022-12-05 20:44:58,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:58,183 INFO:     Epoch: 46
2022-12-05 20:44:58,971 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47870911302478897, 'Total loss': 0.47870911302478897} | train loss {'Reaction outcome loss': 0.14776945315605525, 'Total loss': 0.14776945315605525}
2022-12-05 20:44:58,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:58,971 INFO:     Epoch: 47
2022-12-05 20:44:59,758 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46841556612740864, 'Total loss': 0.46841556612740864} | train loss {'Reaction outcome loss': 0.14539162003416187, 'Total loss': 0.14539162003416187}
2022-12-05 20:44:59,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:44:59,759 INFO:     Epoch: 48
2022-12-05 20:45:00,552 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4899357296526432, 'Total loss': 0.4899357296526432} | train loss {'Reaction outcome loss': 0.1433890866533834, 'Total loss': 0.1433890866533834}
2022-12-05 20:45:00,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:00,552 INFO:     Epoch: 49
2022-12-05 20:45:01,345 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47380688194640574, 'Total loss': 0.47380688194640574} | train loss {'Reaction outcome loss': 0.14095735985937777, 'Total loss': 0.14095735985937777}
2022-12-05 20:45:01,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:01,346 INFO:     Epoch: 50
2022-12-05 20:45:02,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47994858026504517, 'Total loss': 0.47994858026504517} | train loss {'Reaction outcome loss': 0.14299034019742085, 'Total loss': 0.14299034019742085}
2022-12-05 20:45:02,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:02,135 INFO:     Epoch: 51
2022-12-05 20:45:02,923 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4866134471852671, 'Total loss': 0.4866134471852671} | train loss {'Reaction outcome loss': 0.1407583781651088, 'Total loss': 0.1407583781651088}
2022-12-05 20:45:02,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:02,923 INFO:     Epoch: 52
2022-12-05 20:45:03,715 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4872734905220568, 'Total loss': 0.4872734905220568} | train loss {'Reaction outcome loss': 0.1422835993409461, 'Total loss': 0.1422835993409461}
2022-12-05 20:45:03,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:03,715 INFO:     Epoch: 53
2022-12-05 20:45:04,505 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4749121354384856, 'Total loss': 0.4749121354384856} | train loss {'Reaction outcome loss': 0.1416305544120925, 'Total loss': 0.1416305544120925}
2022-12-05 20:45:04,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:04,505 INFO:     Epoch: 54
2022-12-05 20:45:05,296 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5000682161612944, 'Total loss': 0.5000682161612944} | train loss {'Reaction outcome loss': 0.14038015416234123, 'Total loss': 0.14038015416234123}
2022-12-05 20:45:05,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:05,296 INFO:     Epoch: 55
2022-12-05 20:45:06,090 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4749723664400252, 'Total loss': 0.4749723664400252} | train loss {'Reaction outcome loss': 0.13638920240788435, 'Total loss': 0.13638920240788435}
2022-12-05 20:45:06,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:06,090 INFO:     Epoch: 56
2022-12-05 20:45:06,878 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49182534793561156, 'Total loss': 0.49182534793561156} | train loss {'Reaction outcome loss': 0.1397430653018611, 'Total loss': 0.1397430653018611}
2022-12-05 20:45:06,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:06,878 INFO:     Epoch: 57
2022-12-05 20:45:07,667 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4838061329316009, 'Total loss': 0.4838061329316009} | train loss {'Reaction outcome loss': 0.13635604629026993, 'Total loss': 0.13635604629026993}
2022-12-05 20:45:07,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:07,667 INFO:     Epoch: 58
2022-12-05 20:45:08,455 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49332412146031857, 'Total loss': 0.49332412146031857} | train loss {'Reaction outcome loss': 0.13396954217697588, 'Total loss': 0.13396954217697588}
2022-12-05 20:45:08,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:08,455 INFO:     Epoch: 59
2022-12-05 20:45:09,242 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4671613668006929, 'Total loss': 0.4671613668006929} | train loss {'Reaction outcome loss': 0.13572825728630533, 'Total loss': 0.13572825728630533}
2022-12-05 20:45:09,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:09,242 INFO:     Epoch: 60
2022-12-05 20:45:10,029 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49119431457736273, 'Total loss': 0.49119431457736273} | train loss {'Reaction outcome loss': 0.13597887454136293, 'Total loss': 0.13597887454136293}
2022-12-05 20:45:10,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:10,030 INFO:     Epoch: 61
2022-12-05 20:45:10,823 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48330713605338876, 'Total loss': 0.48330713605338876} | train loss {'Reaction outcome loss': 0.13413679257643465, 'Total loss': 0.13413679257643465}
2022-12-05 20:45:10,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:10,823 INFO:     Epoch: 62
2022-12-05 20:45:11,621 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5050449056381529, 'Total loss': 0.5050449056381529} | train loss {'Reaction outcome loss': 0.13615712607849617, 'Total loss': 0.13615712607849617}
2022-12-05 20:45:11,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:11,621 INFO:     Epoch: 63
2022-12-05 20:45:12,414 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.537763440812176, 'Total loss': 0.537763440812176} | train loss {'Reaction outcome loss': 0.13051833511919392, 'Total loss': 0.13051833511919392}
2022-12-05 20:45:12,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:12,416 INFO:     Epoch: 64
2022-12-05 20:45:13,213 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5106597532602873, 'Total loss': 0.5106597532602873} | train loss {'Reaction outcome loss': 0.13245987605911735, 'Total loss': 0.13245987605911735}
2022-12-05 20:45:13,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:13,213 INFO:     Epoch: 65
2022-12-05 20:45:14,004 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4885739209977063, 'Total loss': 0.4885739209977063} | train loss {'Reaction outcome loss': 0.13037524833819086, 'Total loss': 0.13037524833819086}
2022-12-05 20:45:14,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:14,005 INFO:     Epoch: 66
2022-12-05 20:45:14,799 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.503489104861563, 'Total loss': 0.503489104861563} | train loss {'Reaction outcome loss': 0.1285237756956901, 'Total loss': 0.1285237756956901}
2022-12-05 20:45:14,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:14,799 INFO:     Epoch: 67
2022-12-05 20:45:15,590 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4869838763367046, 'Total loss': 0.4869838763367046} | train loss {'Reaction outcome loss': 0.13197634085176552, 'Total loss': 0.13197634085176552}
2022-12-05 20:45:15,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:15,590 INFO:     Epoch: 68
2022-12-05 20:45:16,381 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49938749605842697, 'Total loss': 0.49938749605842697} | train loss {'Reaction outcome loss': 0.12997208697227192, 'Total loss': 0.12997208697227192}
2022-12-05 20:45:16,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:16,381 INFO:     Epoch: 69
2022-12-05 20:45:17,176 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49472789805043826, 'Total loss': 0.49472789805043826} | train loss {'Reaction outcome loss': 0.1307118682646934, 'Total loss': 0.1307118682646934}
2022-12-05 20:45:17,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:17,176 INFO:     Epoch: 70
2022-12-05 20:45:17,969 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5173324846069921, 'Total loss': 0.5173324846069921} | train loss {'Reaction outcome loss': 0.12964678491864887, 'Total loss': 0.12964678491864887}
2022-12-05 20:45:17,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:17,969 INFO:     Epoch: 71
2022-12-05 20:45:18,763 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5144445865669034, 'Total loss': 0.5144445865669034} | train loss {'Reaction outcome loss': 0.12876634810652052, 'Total loss': 0.12876634810652052}
2022-12-05 20:45:18,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:18,763 INFO:     Epoch: 72
2022-12-05 20:45:19,554 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49479704282500525, 'Total loss': 0.49479704282500525} | train loss {'Reaction outcome loss': 0.12953832754675224, 'Total loss': 0.12953832754675224}
2022-12-05 20:45:19,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:19,555 INFO:     Epoch: 73
2022-12-05 20:45:20,347 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48432885110378265, 'Total loss': 0.48432885110378265} | train loss {'Reaction outcome loss': 0.1283330947198734, 'Total loss': 0.1283330947198734}
2022-12-05 20:45:20,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:20,347 INFO:     Epoch: 74
2022-12-05 20:45:21,138 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.492688482796604, 'Total loss': 0.492688482796604} | train loss {'Reaction outcome loss': 0.1275834961699284, 'Total loss': 0.1275834961699284}
2022-12-05 20:45:21,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:21,138 INFO:     Epoch: 75
2022-12-05 20:45:21,937 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5100365189666097, 'Total loss': 0.5100365189666097} | train loss {'Reaction outcome loss': 0.12679863535628028, 'Total loss': 0.12679863535628028}
2022-12-05 20:45:21,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:21,938 INFO:     Epoch: 76
2022-12-05 20:45:22,736 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49597862938588316, 'Total loss': 0.49597862938588316} | train loss {'Reaction outcome loss': 0.1252271331390556, 'Total loss': 0.1252271331390556}
2022-12-05 20:45:22,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:22,736 INFO:     Epoch: 77
2022-12-05 20:45:23,537 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4924863441423936, 'Total loss': 0.4924863441423936} | train loss {'Reaction outcome loss': 0.12403215182831093, 'Total loss': 0.12403215182831093}
2022-12-05 20:45:23,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:23,537 INFO:     Epoch: 78
2022-12-05 20:45:24,336 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4871864373880354, 'Total loss': 0.4871864373880354} | train loss {'Reaction outcome loss': 0.12540644580612378, 'Total loss': 0.12540644580612378}
2022-12-05 20:45:24,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:24,336 INFO:     Epoch: 79
2022-12-05 20:45:25,128 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.504537433385849, 'Total loss': 0.504537433385849} | train loss {'Reaction outcome loss': 0.12251092289783516, 'Total loss': 0.12251092289783516}
2022-12-05 20:45:25,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:25,128 INFO:     Epoch: 80
2022-12-05 20:45:25,921 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49672818183898926, 'Total loss': 0.49672818183898926} | train loss {'Reaction outcome loss': 0.12521349681655364, 'Total loss': 0.12521349681655364}
2022-12-05 20:45:25,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:25,922 INFO:     Epoch: 81
2022-12-05 20:45:26,713 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5137649449435148, 'Total loss': 0.5137649449435148} | train loss {'Reaction outcome loss': 0.12497769510373473, 'Total loss': 0.12497769510373473}
2022-12-05 20:45:26,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:26,713 INFO:     Epoch: 82
2022-12-05 20:45:27,507 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5039706463840875, 'Total loss': 0.5039706463840875} | train loss {'Reaction outcome loss': 0.1260837646695424, 'Total loss': 0.1260837646695424}
2022-12-05 20:45:27,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:27,507 INFO:     Epoch: 83
2022-12-05 20:45:28,298 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49783993715589697, 'Total loss': 0.49783993715589697} | train loss {'Reaction outcome loss': 0.12425802353465436, 'Total loss': 0.12425802353465436}
2022-12-05 20:45:28,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:28,298 INFO:     Epoch: 84
2022-12-05 20:45:29,089 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49776204269040714, 'Total loss': 0.49776204269040714} | train loss {'Reaction outcome loss': 0.12264315923865961, 'Total loss': 0.12264315923865961}
2022-12-05 20:45:29,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:29,089 INFO:     Epoch: 85
2022-12-05 20:45:29,879 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4992431392893195, 'Total loss': 0.4992431392893195} | train loss {'Reaction outcome loss': 0.12041803311024393, 'Total loss': 0.12041803311024393}
2022-12-05 20:45:29,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:29,880 INFO:     Epoch: 86
2022-12-05 20:45:30,676 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4886904230171984, 'Total loss': 0.4886904230171984} | train loss {'Reaction outcome loss': 0.12217503041409108, 'Total loss': 0.12217503041409108}
2022-12-05 20:45:30,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:30,676 INFO:     Epoch: 87
2022-12-05 20:45:31,469 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48745765604756097, 'Total loss': 0.48745765604756097} | train loss {'Reaction outcome loss': 0.1214990276995362, 'Total loss': 0.1214990276995362}
2022-12-05 20:45:31,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:31,470 INFO:     Epoch: 88
2022-12-05 20:45:32,265 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5149810026315126, 'Total loss': 0.5149810026315126} | train loss {'Reaction outcome loss': 0.12364514671190052, 'Total loss': 0.12364514671190052}
2022-12-05 20:45:32,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:32,265 INFO:     Epoch: 89
2022-12-05 20:45:33,058 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4972784637727521, 'Total loss': 0.4972784637727521} | train loss {'Reaction outcome loss': 0.1232159440804805, 'Total loss': 0.1232159440804805}
2022-12-05 20:45:33,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:33,058 INFO:     Epoch: 90
2022-12-05 20:45:33,849 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4908355510878292, 'Total loss': 0.4908355510878292} | train loss {'Reaction outcome loss': 0.12110381481826914, 'Total loss': 0.12110381481826914}
2022-12-05 20:45:33,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:33,849 INFO:     Epoch: 91
2022-12-05 20:45:34,641 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5057934319431131, 'Total loss': 0.5057934319431131} | train loss {'Reaction outcome loss': 0.12294408269606683, 'Total loss': 0.12294408269606683}
2022-12-05 20:45:34,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:34,641 INFO:     Epoch: 92
2022-12-05 20:45:35,438 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5055254000154409, 'Total loss': 0.5055254000154409} | train loss {'Reaction outcome loss': 0.11952105010954701, 'Total loss': 0.11952105010954701}
2022-12-05 20:45:35,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:35,439 INFO:     Epoch: 93
2022-12-05 20:45:36,233 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5086193308234215, 'Total loss': 0.5086193308234215} | train loss {'Reaction outcome loss': 0.12170791889407805, 'Total loss': 0.12170791889407805}
2022-12-05 20:45:36,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:36,234 INFO:     Epoch: 94
2022-12-05 20:45:37,029 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49436395581473, 'Total loss': 0.49436395581473} | train loss {'Reaction outcome loss': 0.12201640033068098, 'Total loss': 0.12201640033068098}
2022-12-05 20:45:37,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:37,029 INFO:     Epoch: 95
2022-12-05 20:45:37,824 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5045034313066439, 'Total loss': 0.5045034313066439} | train loss {'Reaction outcome loss': 0.11903644443622657, 'Total loss': 0.11903644443622657}
2022-12-05 20:45:37,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:37,825 INFO:     Epoch: 96
2022-12-05 20:45:38,618 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5299260541796684, 'Total loss': 0.5299260541796684} | train loss {'Reaction outcome loss': 0.1183042121404896, 'Total loss': 0.1183042121404896}
2022-12-05 20:45:38,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:38,618 INFO:     Epoch: 97
2022-12-05 20:45:39,422 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5010586519810286, 'Total loss': 0.5010586519810286} | train loss {'Reaction outcome loss': 0.12295397486613721, 'Total loss': 0.12295397486613721}
2022-12-05 20:45:39,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:39,422 INFO:     Epoch: 98
2022-12-05 20:45:40,223 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47319492494518106, 'Total loss': 0.47319492494518106} | train loss {'Reaction outcome loss': 0.1195605114672561, 'Total loss': 0.1195605114672561}
2022-12-05 20:45:40,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:40,223 INFO:     Epoch: 99
2022-12-05 20:45:41,021 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4950368043712594, 'Total loss': 0.4950368043712594} | train loss {'Reaction outcome loss': 0.12091658928108459, 'Total loss': 0.12091658928108459}
2022-12-05 20:45:41,021 INFO:     Best model found after epoch 10 of 100.
2022-12-05 20:45:41,021 INFO:   Done with stage: TRAINING
2022-12-05 20:45:41,021 INFO:   Starting stage: EVALUATION
2022-12-05 20:45:41,153 INFO:   Done with stage: EVALUATION
2022-12-05 20:45:41,153 INFO:   Leaving out SEQ value Fold_4
2022-12-05 20:45:41,166 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:45:41,166 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:45:41,818 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:45:41,819 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:45:41,889 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:45:41,890 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:45:41,890 INFO:     No hyperparam tuning for this model
2022-12-05 20:45:41,890 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:45:41,890 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:45:41,891 INFO:     None feature selector for col prot
2022-12-05 20:45:41,891 INFO:     None feature selector for col prot
2022-12-05 20:45:41,891 INFO:     None feature selector for col prot
2022-12-05 20:45:41,891 INFO:     None feature selector for col chem
2022-12-05 20:45:41,891 INFO:     None feature selector for col chem
2022-12-05 20:45:41,891 INFO:     None feature selector for col chem
2022-12-05 20:45:41,892 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:45:41,892 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:45:41,893 INFO:     Number of params in model 215821
2022-12-05 20:45:41,896 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:45:41,897 INFO:   Starting stage: TRAINING
2022-12-05 20:45:41,958 INFO:     Val loss before train {'Reaction outcome loss': 1.0329716530713169, 'Total loss': 1.0329716530713169}
2022-12-05 20:45:41,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:41,958 INFO:     Epoch: 0
2022-12-05 20:45:42,757 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6232686510140245, 'Total loss': 0.6232686510140245} | train loss {'Reaction outcome loss': 0.7937400696972604, 'Total loss': 0.7937400696972604}
2022-12-05 20:45:42,757 INFO:     Found new best model at epoch 0
2022-12-05 20:45:42,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:42,758 INFO:     Epoch: 1
2022-12-05 20:45:43,544 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5220576815984466, 'Total loss': 0.5220576815984466} | train loss {'Reaction outcome loss': 0.5489274065504189, 'Total loss': 0.5489274065504189}
2022-12-05 20:45:43,544 INFO:     Found new best model at epoch 1
2022-12-05 20:45:43,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:43,545 INFO:     Epoch: 2
2022-12-05 20:45:44,328 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47975950518792326, 'Total loss': 0.47975950518792326} | train loss {'Reaction outcome loss': 0.48099227038472286, 'Total loss': 0.48099227038472286}
2022-12-05 20:45:44,329 INFO:     Found new best model at epoch 2
2022-12-05 20:45:44,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:44,330 INFO:     Epoch: 3
2022-12-05 20:45:45,114 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45410816303708335, 'Total loss': 0.45410816303708335} | train loss {'Reaction outcome loss': 0.4405292514485386, 'Total loss': 0.4405292514485386}
2022-12-05 20:45:45,114 INFO:     Found new best model at epoch 3
2022-12-05 20:45:45,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:45,115 INFO:     Epoch: 4
2022-12-05 20:45:45,902 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4525720646435564, 'Total loss': 0.4525720646435564} | train loss {'Reaction outcome loss': 0.4129396652282491, 'Total loss': 0.4129396652282491}
2022-12-05 20:45:45,902 INFO:     Found new best model at epoch 4
2022-12-05 20:45:45,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:45,903 INFO:     Epoch: 5
2022-12-05 20:45:46,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4253639622845433, 'Total loss': 0.4253639622845433} | train loss {'Reaction outcome loss': 0.39007315119570085, 'Total loss': 0.39007315119570085}
2022-12-05 20:45:46,700 INFO:     Found new best model at epoch 5
2022-12-05 20:45:46,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:46,701 INFO:     Epoch: 6
2022-12-05 20:45:47,497 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42713022977113724, 'Total loss': 0.42713022977113724} | train loss {'Reaction outcome loss': 0.3738682949349948, 'Total loss': 0.3738682949349948}
2022-12-05 20:45:47,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:47,497 INFO:     Epoch: 7
2022-12-05 20:45:48,285 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4250766502862627, 'Total loss': 0.4250766502862627} | train loss {'Reaction outcome loss': 0.3597965187389358, 'Total loss': 0.3597965187389358}
2022-12-05 20:45:48,285 INFO:     Found new best model at epoch 7
2022-12-05 20:45:48,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:48,286 INFO:     Epoch: 8
2022-12-05 20:45:49,072 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4109305024824359, 'Total loss': 0.4109305024824359} | train loss {'Reaction outcome loss': 0.3447415458890591, 'Total loss': 0.3447415458890591}
2022-12-05 20:45:49,072 INFO:     Found new best model at epoch 8
2022-12-05 20:45:49,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:49,073 INFO:     Epoch: 9
2022-12-05 20:45:49,858 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4094530557366935, 'Total loss': 0.4094530557366935} | train loss {'Reaction outcome loss': 0.33355075497979575, 'Total loss': 0.33355075497979575}
2022-12-05 20:45:49,858 INFO:     Found new best model at epoch 9
2022-12-05 20:45:49,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:49,859 INFO:     Epoch: 10
2022-12-05 20:45:50,650 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41071615571325476, 'Total loss': 0.41071615571325476} | train loss {'Reaction outcome loss': 0.31851666977229387, 'Total loss': 0.31851666977229387}
2022-12-05 20:45:50,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:50,651 INFO:     Epoch: 11
2022-12-05 20:45:51,439 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4004034904593771, 'Total loss': 0.4004034904593771} | train loss {'Reaction outcome loss': 0.30382866499877653, 'Total loss': 0.30382866499877653}
2022-12-05 20:45:51,439 INFO:     Found new best model at epoch 11
2022-12-05 20:45:51,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:51,440 INFO:     Epoch: 12
2022-12-05 20:45:52,226 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4125582247295163, 'Total loss': 0.4125582247295163} | train loss {'Reaction outcome loss': 0.2938153028548488, 'Total loss': 0.2938153028548488}
2022-12-05 20:45:52,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:52,226 INFO:     Epoch: 13
2022-12-05 20:45:53,016 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4080206521532752, 'Total loss': 0.4080206521532752} | train loss {'Reaction outcome loss': 0.2852643849215044, 'Total loss': 0.2852643849215044}
2022-12-05 20:45:53,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:53,016 INFO:     Epoch: 14
2022-12-05 20:45:53,802 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3862540051341057, 'Total loss': 0.3862540051341057} | train loss {'Reaction outcome loss': 0.27782055231844366, 'Total loss': 0.27782055231844366}
2022-12-05 20:45:53,802 INFO:     Found new best model at epoch 14
2022-12-05 20:45:53,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:53,803 INFO:     Epoch: 15
2022-12-05 20:45:54,595 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3956855660812421, 'Total loss': 0.3956855660812421} | train loss {'Reaction outcome loss': 0.2694797460970126, 'Total loss': 0.2694797460970126}
2022-12-05 20:45:54,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:54,595 INFO:     Epoch: 16
2022-12-05 20:45:55,386 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4037344841794534, 'Total loss': 0.4037344841794534} | train loss {'Reaction outcome loss': 0.2634430899009531, 'Total loss': 0.2634430899009531}
2022-12-05 20:45:55,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:55,386 INFO:     Epoch: 17
2022-12-05 20:45:56,173 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4134084369817918, 'Total loss': 0.4134084369817918} | train loss {'Reaction outcome loss': 0.25427403143015104, 'Total loss': 0.25427403143015104}
2022-12-05 20:45:56,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:56,173 INFO:     Epoch: 18
2022-12-05 20:45:56,962 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4010271010073749, 'Total loss': 0.4010271010073749} | train loss {'Reaction outcome loss': 0.2474707616606222, 'Total loss': 0.2474707616606222}
2022-12-05 20:45:56,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:56,963 INFO:     Epoch: 19
2022-12-05 20:45:57,753 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39942938732829963, 'Total loss': 0.39942938732829963} | train loss {'Reaction outcome loss': 0.24237666923085205, 'Total loss': 0.24237666923085205}
2022-12-05 20:45:57,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:57,753 INFO:     Epoch: 20
2022-12-05 20:45:58,541 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40581170096993446, 'Total loss': 0.40581170096993446} | train loss {'Reaction outcome loss': 0.2369122099506514, 'Total loss': 0.2369122099506514}
2022-12-05 20:45:58,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:58,541 INFO:     Epoch: 21
2022-12-05 20:45:59,334 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4143594093620777, 'Total loss': 0.4143594093620777} | train loss {'Reaction outcome loss': 0.2292665973388654, 'Total loss': 0.2292665973388654}
2022-12-05 20:45:59,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:45:59,335 INFO:     Epoch: 22
2022-12-05 20:46:00,125 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40978260710835457, 'Total loss': 0.40978260710835457} | train loss {'Reaction outcome loss': 0.22500083941461044, 'Total loss': 0.22500083941461044}
2022-12-05 20:46:00,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:00,125 INFO:     Epoch: 23
2022-12-05 20:46:00,912 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40192535655065015, 'Total loss': 0.40192535655065015} | train loss {'Reaction outcome loss': 0.21944389760735547, 'Total loss': 0.21944389760735547}
2022-12-05 20:46:00,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:00,912 INFO:     Epoch: 24
2022-12-05 20:46:01,699 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40785041807050054, 'Total loss': 0.40785041807050054} | train loss {'Reaction outcome loss': 0.21975786266056632, 'Total loss': 0.21975786266056632}
2022-12-05 20:46:01,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:01,699 INFO:     Epoch: 25
2022-12-05 20:46:02,488 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40732036937366833, 'Total loss': 0.40732036937366833} | train loss {'Reaction outcome loss': 0.21603378210111185, 'Total loss': 0.21603378210111185}
2022-12-05 20:46:02,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:02,488 INFO:     Epoch: 26
2022-12-05 20:46:03,277 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40566613084890624, 'Total loss': 0.40566613084890624} | train loss {'Reaction outcome loss': 0.20778254704429253, 'Total loss': 0.20778254704429253}
2022-12-05 20:46:03,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:03,278 INFO:     Epoch: 27
2022-12-05 20:46:04,065 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4091610668057745, 'Total loss': 0.4091610668057745} | train loss {'Reaction outcome loss': 0.20678993700607587, 'Total loss': 0.20678993700607587}
2022-12-05 20:46:04,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:04,065 INFO:     Epoch: 28
2022-12-05 20:46:04,852 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.405917111445557, 'Total loss': 0.405917111445557} | train loss {'Reaction outcome loss': 0.19999584221933414, 'Total loss': 0.19999584221933414}
2022-12-05 20:46:04,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:04,852 INFO:     Epoch: 29
2022-12-05 20:46:05,639 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41818534151058306, 'Total loss': 0.41818534151058306} | train loss {'Reaction outcome loss': 0.1970599567298947, 'Total loss': 0.1970599567298947}
2022-12-05 20:46:05,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:05,639 INFO:     Epoch: 30
2022-12-05 20:46:06,427 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40642276406288147, 'Total loss': 0.40642276406288147} | train loss {'Reaction outcome loss': 0.20382863753720334, 'Total loss': 0.20382863753720334}
2022-12-05 20:46:06,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:06,427 INFO:     Epoch: 31
2022-12-05 20:46:07,217 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40678399885919964, 'Total loss': 0.40678399885919964} | train loss {'Reaction outcome loss': 0.19476066398536146, 'Total loss': 0.19476066398536146}
2022-12-05 20:46:07,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:07,217 INFO:     Epoch: 32
2022-12-05 20:46:08,006 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4327558336610144, 'Total loss': 0.4327558336610144} | train loss {'Reaction outcome loss': 0.19484249054857714, 'Total loss': 0.19484249054857714}
2022-12-05 20:46:08,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:08,006 INFO:     Epoch: 33
2022-12-05 20:46:08,799 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41292847659100185, 'Total loss': 0.41292847659100185} | train loss {'Reaction outcome loss': 0.1861351761469233, 'Total loss': 0.1861351761469233}
2022-12-05 20:46:08,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:08,799 INFO:     Epoch: 34
2022-12-05 20:46:09,591 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42440225929021835, 'Total loss': 0.42440225929021835} | train loss {'Reaction outcome loss': 0.19285362574313333, 'Total loss': 0.19285362574313333}
2022-12-05 20:46:09,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:09,591 INFO:     Epoch: 35
2022-12-05 20:46:10,391 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41942518509247084, 'Total loss': 0.41942518509247084} | train loss {'Reaction outcome loss': 0.1815843423866188, 'Total loss': 0.1815843423866188}
2022-12-05 20:46:10,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:10,391 INFO:     Epoch: 36
2022-12-05 20:46:11,192 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41855317523533647, 'Total loss': 0.41855317523533647} | train loss {'Reaction outcome loss': 0.17928484375569742, 'Total loss': 0.17928484375569742}
2022-12-05 20:46:11,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:11,192 INFO:     Epoch: 37
2022-12-05 20:46:11,991 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41318714737214823, 'Total loss': 0.41318714737214823} | train loss {'Reaction outcome loss': 0.17892265589794648, 'Total loss': 0.17892265589794648}
2022-12-05 20:46:11,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:11,992 INFO:     Epoch: 38
2022-12-05 20:46:12,794 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4163766320456158, 'Total loss': 0.4163766320456158} | train loss {'Reaction outcome loss': 0.17136374330864504, 'Total loss': 0.17136374330864504}
2022-12-05 20:46:12,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:12,794 INFO:     Epoch: 39
2022-12-05 20:46:13,599 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4238149232485078, 'Total loss': 0.4238149232485078} | train loss {'Reaction outcome loss': 0.1744909278901392, 'Total loss': 0.1744909278901392}
2022-12-05 20:46:13,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:13,599 INFO:     Epoch: 40
2022-12-05 20:46:14,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.429836975579912, 'Total loss': 0.429836975579912} | train loss {'Reaction outcome loss': 0.16981148870609067, 'Total loss': 0.16981148870609067}
2022-12-05 20:46:14,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:14,404 INFO:     Epoch: 41
2022-12-05 20:46:15,205 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42621372877196834, 'Total loss': 0.42621372877196834} | train loss {'Reaction outcome loss': 0.16754333979567052, 'Total loss': 0.16754333979567052}
2022-12-05 20:46:15,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:15,206 INFO:     Epoch: 42
2022-12-05 20:46:16,010 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41502690670842474, 'Total loss': 0.41502690670842474} | train loss {'Reaction outcome loss': 0.16565414466084497, 'Total loss': 0.16565414466084497}
2022-12-05 20:46:16,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:16,011 INFO:     Epoch: 43
2022-12-05 20:46:16,813 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43470347503369505, 'Total loss': 0.43470347503369505} | train loss {'Reaction outcome loss': 0.16978113075740908, 'Total loss': 0.16978113075740908}
2022-12-05 20:46:16,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:16,814 INFO:     Epoch: 44
2022-12-05 20:46:17,616 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43294217132709245, 'Total loss': 0.43294217132709245} | train loss {'Reaction outcome loss': 0.1619877987475274, 'Total loss': 0.1619877987475274}
2022-12-05 20:46:17,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:17,616 INFO:     Epoch: 45
2022-12-05 20:46:18,416 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4190643514421853, 'Total loss': 0.4190643514421853} | train loss {'Reaction outcome loss': 0.16115786391027603, 'Total loss': 0.16115786391027603}
2022-12-05 20:46:18,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:18,416 INFO:     Epoch: 46
2022-12-05 20:46:19,216 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.434466382319277, 'Total loss': 0.434466382319277} | train loss {'Reaction outcome loss': 0.15760344322506897, 'Total loss': 0.15760344322506897}
2022-12-05 20:46:19,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:19,216 INFO:     Epoch: 47
2022-12-05 20:46:20,018 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4292700041762807, 'Total loss': 0.4292700041762807} | train loss {'Reaction outcome loss': 0.1595850309228849, 'Total loss': 0.1595850309228849}
2022-12-05 20:46:20,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:20,018 INFO:     Epoch: 48
2022-12-05 20:46:20,822 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4324674660509283, 'Total loss': 0.4324674660509283} | train loss {'Reaction outcome loss': 0.15856911903195392, 'Total loss': 0.15856911903195392}
2022-12-05 20:46:20,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:20,822 INFO:     Epoch: 49
2022-12-05 20:46:21,626 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4288480827076869, 'Total loss': 0.4288480827076869} | train loss {'Reaction outcome loss': 0.1543782061580493, 'Total loss': 0.1543782061580493}
2022-12-05 20:46:21,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:21,627 INFO:     Epoch: 50
2022-12-05 20:46:22,433 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43045293912291527, 'Total loss': 0.43045293912291527} | train loss {'Reaction outcome loss': 0.15653029227486023, 'Total loss': 0.15653029227486023}
2022-12-05 20:46:22,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:22,433 INFO:     Epoch: 51
2022-12-05 20:46:23,234 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44117177379402245, 'Total loss': 0.44117177379402245} | train loss {'Reaction outcome loss': 0.15543028378957197, 'Total loss': 0.15543028378957197}
2022-12-05 20:46:23,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:23,234 INFO:     Epoch: 52
2022-12-05 20:46:24,041 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.450677098875696, 'Total loss': 0.450677098875696} | train loss {'Reaction outcome loss': 0.15842684278423005, 'Total loss': 0.15842684278423005}
2022-12-05 20:46:24,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:24,041 INFO:     Epoch: 53
2022-12-05 20:46:24,843 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4367820732295513, 'Total loss': 0.4367820732295513} | train loss {'Reaction outcome loss': 0.15538181557587766, 'Total loss': 0.15538181557587766}
2022-12-05 20:46:24,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:24,843 INFO:     Epoch: 54
2022-12-05 20:46:25,644 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4274907381358472, 'Total loss': 0.4274907381358472} | train loss {'Reaction outcome loss': 0.15094228377396068, 'Total loss': 0.15094228377396068}
2022-12-05 20:46:25,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:25,644 INFO:     Epoch: 55
2022-12-05 20:46:26,444 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43476717986843805, 'Total loss': 0.43476717986843805} | train loss {'Reaction outcome loss': 0.14840822123926178, 'Total loss': 0.14840822123926178}
2022-12-05 20:46:26,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:26,444 INFO:     Epoch: 56
2022-12-05 20:46:27,244 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4543746482919563, 'Total loss': 0.4543746482919563} | train loss {'Reaction outcome loss': 0.15274012309729088, 'Total loss': 0.15274012309729088}
2022-12-05 20:46:27,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:27,244 INFO:     Epoch: 57
2022-12-05 20:46:28,049 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43904283337972383, 'Total loss': 0.43904283337972383} | train loss {'Reaction outcome loss': 0.15173277304437566, 'Total loss': 0.15173277304437566}
2022-12-05 20:46:28,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:28,049 INFO:     Epoch: 58
2022-12-05 20:46:28,849 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4238949174230749, 'Total loss': 0.4238949174230749} | train loss {'Reaction outcome loss': 0.14673275641176986, 'Total loss': 0.14673275641176986}
2022-12-05 20:46:28,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:28,849 INFO:     Epoch: 59
2022-12-05 20:46:29,649 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44847533343867824, 'Total loss': 0.44847533343867824} | train loss {'Reaction outcome loss': 0.14647929573258167, 'Total loss': 0.14647929573258167}
2022-12-05 20:46:29,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:29,649 INFO:     Epoch: 60
2022-12-05 20:46:30,449 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4273548468270085, 'Total loss': 0.4273548468270085} | train loss {'Reaction outcome loss': 0.14561409129938374, 'Total loss': 0.14561409129938374}
2022-12-05 20:46:30,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:30,449 INFO:     Epoch: 61
2022-12-05 20:46:31,252 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4342801981732588, 'Total loss': 0.4342801981732588} | train loss {'Reaction outcome loss': 0.14528131194866115, 'Total loss': 0.14528131194866115}
2022-12-05 20:46:31,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:31,253 INFO:     Epoch: 62
2022-12-05 20:46:32,056 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43824136223305354, 'Total loss': 0.43824136223305354} | train loss {'Reaction outcome loss': 0.1415145169408155, 'Total loss': 0.1415145169408155}
2022-12-05 20:46:32,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:32,056 INFO:     Epoch: 63
2022-12-05 20:46:32,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.464087926698002, 'Total loss': 0.464087926698002} | train loss {'Reaction outcome loss': 0.1433609466667962, 'Total loss': 0.1433609466667962}
2022-12-05 20:46:32,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:32,861 INFO:     Epoch: 64
2022-12-05 20:46:33,664 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4381437444720756, 'Total loss': 0.4381437444720756} | train loss {'Reaction outcome loss': 0.14097114567369645, 'Total loss': 0.14097114567369645}
2022-12-05 20:46:33,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:33,665 INFO:     Epoch: 65
2022-12-05 20:46:34,467 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44191316108811984, 'Total loss': 0.44191316108811984} | train loss {'Reaction outcome loss': 0.14112156752481875, 'Total loss': 0.14112156752481875}
2022-12-05 20:46:34,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:34,468 INFO:     Epoch: 66
2022-12-05 20:46:35,268 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43097768994894897, 'Total loss': 0.43097768994894897} | train loss {'Reaction outcome loss': 0.14366668974038077, 'Total loss': 0.14366668974038077}
2022-12-05 20:46:35,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:35,268 INFO:     Epoch: 67
2022-12-05 20:46:36,069 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4543181119317358, 'Total loss': 0.4543181119317358} | train loss {'Reaction outcome loss': 0.14206813805574467, 'Total loss': 0.14206813805574467}
2022-12-05 20:46:36,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:36,069 INFO:     Epoch: 68
2022-12-05 20:46:36,873 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.437104789709503, 'Total loss': 0.437104789709503} | train loss {'Reaction outcome loss': 0.14408830176239554, 'Total loss': 0.14408830176239554}
2022-12-05 20:46:36,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:36,874 INFO:     Epoch: 69
2022-12-05 20:46:37,681 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4548274403945966, 'Total loss': 0.4548274403945966} | train loss {'Reaction outcome loss': 0.14149427801551606, 'Total loss': 0.14149427801551606}
2022-12-05 20:46:37,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:37,682 INFO:     Epoch: 70
2022-12-05 20:46:38,488 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43498112938620825, 'Total loss': 0.43498112938620825} | train loss {'Reaction outcome loss': 0.14038764307584597, 'Total loss': 0.14038764307584597}
2022-12-05 20:46:38,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:38,488 INFO:     Epoch: 71
2022-12-05 20:46:39,294 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45190401697023347, 'Total loss': 0.45190401697023347} | train loss {'Reaction outcome loss': 0.13745998417362873, 'Total loss': 0.13745998417362873}
2022-12-05 20:46:39,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:39,294 INFO:     Epoch: 72
2022-12-05 20:46:40,101 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45930359986695374, 'Total loss': 0.45930359986695374} | train loss {'Reaction outcome loss': 0.1372344305098758, 'Total loss': 0.1372344305098758}
2022-12-05 20:46:40,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:40,101 INFO:     Epoch: 73
2022-12-05 20:46:40,904 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4505554019388827, 'Total loss': 0.4505554019388827} | train loss {'Reaction outcome loss': 0.1372217703233605, 'Total loss': 0.1372217703233605}
2022-12-05 20:46:40,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:40,904 INFO:     Epoch: 74
2022-12-05 20:46:41,705 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44654433395374904, 'Total loss': 0.44654433395374904} | train loss {'Reaction outcome loss': 0.13671581635651317, 'Total loss': 0.13671581635651317}
2022-12-05 20:46:41,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:41,705 INFO:     Epoch: 75
2022-12-05 20:46:42,508 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4442506864328276, 'Total loss': 0.4442506864328276} | train loss {'Reaction outcome loss': 0.1366701313117255, 'Total loss': 0.1366701313117255}
2022-12-05 20:46:42,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:42,508 INFO:     Epoch: 76
2022-12-05 20:46:43,309 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4424920128658414, 'Total loss': 0.4424920128658414} | train loss {'Reaction outcome loss': 0.13741588226787232, 'Total loss': 0.13741588226787232}
2022-12-05 20:46:43,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:43,309 INFO:     Epoch: 77
2022-12-05 20:46:44,113 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4568208246068521, 'Total loss': 0.4568208246068521} | train loss {'Reaction outcome loss': 0.13993376684620193, 'Total loss': 0.13993376684620193}
2022-12-05 20:46:44,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:44,113 INFO:     Epoch: 78
2022-12-05 20:46:44,914 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45343567803502083, 'Total loss': 0.45343567803502083} | train loss {'Reaction outcome loss': 0.13867299194798355, 'Total loss': 0.13867299194798355}
2022-12-05 20:46:44,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:44,915 INFO:     Epoch: 79
2022-12-05 20:46:45,719 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4369895180517977, 'Total loss': 0.4369895180517977} | train loss {'Reaction outcome loss': 0.13370647490531704, 'Total loss': 0.13370647490531704}
2022-12-05 20:46:45,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:45,720 INFO:     Epoch: 80
2022-12-05 20:46:46,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4585183611647649, 'Total loss': 0.4585183611647649} | train loss {'Reaction outcome loss': 0.13178083033636515, 'Total loss': 0.13178083033636515}
2022-12-05 20:46:46,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:46,524 INFO:     Epoch: 81
2022-12-05 20:46:47,325 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44056602296504105, 'Total loss': 0.44056602296504105} | train loss {'Reaction outcome loss': 0.13134493309955456, 'Total loss': 0.13134493309955456}
2022-12-05 20:46:47,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:47,326 INFO:     Epoch: 82
2022-12-05 20:46:48,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44404582103545015, 'Total loss': 0.44404582103545015} | train loss {'Reaction outcome loss': 0.1322003755348957, 'Total loss': 0.1322003755348957}
2022-12-05 20:46:48,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:48,128 INFO:     Epoch: 83
2022-12-05 20:46:48,928 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4615207211199132, 'Total loss': 0.4615207211199132} | train loss {'Reaction outcome loss': 0.13379199868482858, 'Total loss': 0.13379199868482858}
2022-12-05 20:46:48,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:48,929 INFO:     Epoch: 84
2022-12-05 20:46:49,731 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.439674972133203, 'Total loss': 0.439674972133203} | train loss {'Reaction outcome loss': 0.13257759113924253, 'Total loss': 0.13257759113924253}
2022-12-05 20:46:49,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:49,731 INFO:     Epoch: 85
2022-12-05 20:46:50,535 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4401510561054403, 'Total loss': 0.4401510561054403} | train loss {'Reaction outcome loss': 0.13371272025034134, 'Total loss': 0.13371272025034134}
2022-12-05 20:46:50,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:50,535 INFO:     Epoch: 86
2022-12-05 20:46:51,337 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4641870934177529, 'Total loss': 0.4641870934177529} | train loss {'Reaction outcome loss': 0.1413277168494276, 'Total loss': 0.1413277168494276}
2022-12-05 20:46:51,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:51,337 INFO:     Epoch: 87
2022-12-05 20:46:52,138 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.449636204845526, 'Total loss': 0.449636204845526} | train loss {'Reaction outcome loss': 0.1354651177162493, 'Total loss': 0.1354651177162493}
2022-12-05 20:46:52,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:52,139 INFO:     Epoch: 88
2022-12-05 20:46:52,938 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4465682608160106, 'Total loss': 0.4465682608160106} | train loss {'Reaction outcome loss': 0.13311559610400606, 'Total loss': 0.13311559610400606}
2022-12-05 20:46:52,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:52,938 INFO:     Epoch: 89
2022-12-05 20:46:53,740 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45859406380490825, 'Total loss': 0.45859406380490825} | train loss {'Reaction outcome loss': 0.13544412914603224, 'Total loss': 0.13544412914603224}
2022-12-05 20:46:53,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:53,740 INFO:     Epoch: 90
2022-12-05 20:46:54,537 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43654178421605716, 'Total loss': 0.43654178421605716} | train loss {'Reaction outcome loss': 0.13328327960240455, 'Total loss': 0.13328327960240455}
2022-12-05 20:46:54,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:54,538 INFO:     Epoch: 91
2022-12-05 20:46:55,337 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4437834474850785, 'Total loss': 0.4437834474850785} | train loss {'Reaction outcome loss': 0.13015603929426264, 'Total loss': 0.13015603929426264}
2022-12-05 20:46:55,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:55,338 INFO:     Epoch: 92
2022-12-05 20:46:56,139 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4417320347645066, 'Total loss': 0.4417320347645066} | train loss {'Reaction outcome loss': 0.13048961087080993, 'Total loss': 0.13048961087080993}
2022-12-05 20:46:56,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:56,139 INFO:     Epoch: 93
2022-12-05 20:46:56,936 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4575913181020455, 'Total loss': 0.4575913181020455} | train loss {'Reaction outcome loss': 0.12865813365130713, 'Total loss': 0.12865813365130713}
2022-12-05 20:46:56,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:56,936 INFO:     Epoch: 94
2022-12-05 20:46:57,735 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45812197774648666, 'Total loss': 0.45812197774648666} | train loss {'Reaction outcome loss': 0.12771943789955817, 'Total loss': 0.12771943789955817}
2022-12-05 20:46:57,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:57,735 INFO:     Epoch: 95
2022-12-05 20:46:58,538 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4550217508592389, 'Total loss': 0.4550217508592389} | train loss {'Reaction outcome loss': 0.12618771518169627, 'Total loss': 0.12618771518169627}
2022-12-05 20:46:58,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:58,538 INFO:     Epoch: 96
2022-12-05 20:46:59,338 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4642528827217492, 'Total loss': 0.4642528827217492} | train loss {'Reaction outcome loss': 0.1315186926831118, 'Total loss': 0.1315186926831118}
2022-12-05 20:46:59,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:46:59,338 INFO:     Epoch: 97
2022-12-05 20:47:00,135 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44575975903055887, 'Total loss': 0.44575975903055887} | train loss {'Reaction outcome loss': 0.13485524549265862, 'Total loss': 0.13485524549265862}
2022-12-05 20:47:00,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:00,135 INFO:     Epoch: 98
2022-12-05 20:47:00,931 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45952084254134784, 'Total loss': 0.45952084254134784} | train loss {'Reaction outcome loss': 0.1358664043903773, 'Total loss': 0.1358664043903773}
2022-12-05 20:47:00,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:00,931 INFO:     Epoch: 99
2022-12-05 20:47:01,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4625676458024166, 'Total loss': 0.4625676458024166} | train loss {'Reaction outcome loss': 0.13903314889472748, 'Total loss': 0.13903314889472748}
2022-12-05 20:47:01,727 INFO:     Best model found after epoch 15 of 100.
2022-12-05 20:47:01,727 INFO:   Done with stage: TRAINING
2022-12-05 20:47:01,727 INFO:   Starting stage: EVALUATION
2022-12-05 20:47:01,853 INFO:   Done with stage: EVALUATION
2022-12-05 20:47:01,853 INFO:   Leaving out SEQ value Fold_5
2022-12-05 20:47:01,865 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:47:01,865 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:47:02,517 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:47:02,517 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:47:02,588 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:47:02,588 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:47:02,588 INFO:     No hyperparam tuning for this model
2022-12-05 20:47:02,588 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:47:02,588 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:47:02,589 INFO:     None feature selector for col prot
2022-12-05 20:47:02,589 INFO:     None feature selector for col prot
2022-12-05 20:47:02,589 INFO:     None feature selector for col prot
2022-12-05 20:47:02,590 INFO:     None feature selector for col chem
2022-12-05 20:47:02,590 INFO:     None feature selector for col chem
2022-12-05 20:47:02,590 INFO:     None feature selector for col chem
2022-12-05 20:47:02,590 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:47:02,590 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:47:02,592 INFO:     Number of params in model 215821
2022-12-05 20:47:02,595 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:47:02,595 INFO:   Starting stage: TRAINING
2022-12-05 20:47:02,657 INFO:     Val loss before train {'Reaction outcome loss': 0.967761987989599, 'Total loss': 0.967761987989599}
2022-12-05 20:47:02,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:02,657 INFO:     Epoch: 0
2022-12-05 20:47:03,457 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6222247542305426, 'Total loss': 0.6222247542305426} | train loss {'Reaction outcome loss': 0.8103105460684146, 'Total loss': 0.8103105460684146}
2022-12-05 20:47:03,457 INFO:     Found new best model at epoch 0
2022-12-05 20:47:03,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:03,458 INFO:     Epoch: 1
2022-12-05 20:47:04,258 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5097470209002495, 'Total loss': 0.5097470209002495} | train loss {'Reaction outcome loss': 0.5531995631754398, 'Total loss': 0.5531995631754398}
2022-12-05 20:47:04,258 INFO:     Found new best model at epoch 1
2022-12-05 20:47:04,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:04,259 INFO:     Epoch: 2
2022-12-05 20:47:05,064 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46910008415579796, 'Total loss': 0.46910008415579796} | train loss {'Reaction outcome loss': 0.4768326884556201, 'Total loss': 0.4768326884556201}
2022-12-05 20:47:05,064 INFO:     Found new best model at epoch 2
2022-12-05 20:47:05,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:05,065 INFO:     Epoch: 3
2022-12-05 20:47:05,864 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46161947162313893, 'Total loss': 0.46161947162313893} | train loss {'Reaction outcome loss': 0.42747628631731194, 'Total loss': 0.42747628631731194}
2022-12-05 20:47:05,864 INFO:     Found new best model at epoch 3
2022-12-05 20:47:05,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:05,865 INFO:     Epoch: 4
2022-12-05 20:47:06,666 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4447744285518473, 'Total loss': 0.4447744285518473} | train loss {'Reaction outcome loss': 0.3969534088466917, 'Total loss': 0.3969534088466917}
2022-12-05 20:47:06,666 INFO:     Found new best model at epoch 4
2022-12-05 20:47:06,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:06,667 INFO:     Epoch: 5
2022-12-05 20:47:07,466 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4370677640492266, 'Total loss': 0.4370677640492266} | train loss {'Reaction outcome loss': 0.3734251167174549, 'Total loss': 0.3734251167174549}
2022-12-05 20:47:07,467 INFO:     Found new best model at epoch 5
2022-12-05 20:47:07,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:07,468 INFO:     Epoch: 6
2022-12-05 20:47:08,267 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4263572567565875, 'Total loss': 0.4263572567565875} | train loss {'Reaction outcome loss': 0.35213911314044266, 'Total loss': 0.35213911314044266}
2022-12-05 20:47:08,267 INFO:     Found new best model at epoch 6
2022-12-05 20:47:08,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:08,268 INFO:     Epoch: 7
2022-12-05 20:47:09,068 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4194326495582407, 'Total loss': 0.4194326495582407} | train loss {'Reaction outcome loss': 0.33509077621443617, 'Total loss': 0.33509077621443617}
2022-12-05 20:47:09,068 INFO:     Found new best model at epoch 7
2022-12-05 20:47:09,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:09,069 INFO:     Epoch: 8
2022-12-05 20:47:09,871 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42261437665332446, 'Total loss': 0.42261437665332446} | train loss {'Reaction outcome loss': 0.31696385911275304, 'Total loss': 0.31696385911275304}
2022-12-05 20:47:09,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:09,871 INFO:     Epoch: 9
2022-12-05 20:47:10,671 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4235966249623082, 'Total loss': 0.4235966249623082} | train loss {'Reaction outcome loss': 0.30462081982724126, 'Total loss': 0.30462081982724126}
2022-12-05 20:47:10,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:10,671 INFO:     Epoch: 10
2022-12-05 20:47:11,470 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4217220179059289, 'Total loss': 0.4217220179059289} | train loss {'Reaction outcome loss': 0.29014360476585643, 'Total loss': 0.29014360476585643}
2022-12-05 20:47:11,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:11,470 INFO:     Epoch: 11
2022-12-05 20:47:12,270 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4094349504871802, 'Total loss': 0.4094349504871802} | train loss {'Reaction outcome loss': 0.2812364059049756, 'Total loss': 0.2812364059049756}
2022-12-05 20:47:12,270 INFO:     Found new best model at epoch 11
2022-12-05 20:47:12,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:12,271 INFO:     Epoch: 12
2022-12-05 20:47:13,070 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4124840658835389, 'Total loss': 0.4124840658835389} | train loss {'Reaction outcome loss': 0.2693904042844811, 'Total loss': 0.2693904042844811}
2022-12-05 20:47:13,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:13,071 INFO:     Epoch: 13
2022-12-05 20:47:13,873 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39959274706515396, 'Total loss': 0.39959274706515396} | train loss {'Reaction outcome loss': 0.2608597801938172, 'Total loss': 0.2608597801938172}
2022-12-05 20:47:13,873 INFO:     Found new best model at epoch 13
2022-12-05 20:47:13,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:13,874 INFO:     Epoch: 14
2022-12-05 20:47:14,674 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42658931931311433, 'Total loss': 0.42658931931311433} | train loss {'Reaction outcome loss': 0.24822825912926946, 'Total loss': 0.24822825912926946}
2022-12-05 20:47:14,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:14,674 INFO:     Epoch: 15
2022-12-05 20:47:15,475 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4248958480629054, 'Total loss': 0.4248958480629054} | train loss {'Reaction outcome loss': 0.24577751635543763, 'Total loss': 0.24577751635543763}
2022-12-05 20:47:15,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:15,475 INFO:     Epoch: 16
2022-12-05 20:47:16,277 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40373661335219035, 'Total loss': 0.40373661335219035} | train loss {'Reaction outcome loss': 0.23496631773248797, 'Total loss': 0.23496631773248797}
2022-12-05 20:47:16,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:16,277 INFO:     Epoch: 17
2022-12-05 20:47:17,079 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4149685170162808, 'Total loss': 0.4149685170162808} | train loss {'Reaction outcome loss': 0.22866731494544976, 'Total loss': 0.22866731494544976}
2022-12-05 20:47:17,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:17,080 INFO:     Epoch: 18
2022-12-05 20:47:17,881 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.408753092316064, 'Total loss': 0.408753092316064} | train loss {'Reaction outcome loss': 0.22207098448228452, 'Total loss': 0.22207098448228452}
2022-12-05 20:47:17,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:17,881 INFO:     Epoch: 19
2022-12-05 20:47:18,680 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4103830277242444, 'Total loss': 0.4103830277242444} | train loss {'Reaction outcome loss': 0.21471136066341592, 'Total loss': 0.21471136066341592}
2022-12-05 20:47:18,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:18,681 INFO:     Epoch: 20
2022-12-05 20:47:19,481 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4170794073830951, 'Total loss': 0.4170794073830951} | train loss {'Reaction outcome loss': 0.21014250618135255, 'Total loss': 0.21014250618135255}
2022-12-05 20:47:19,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:19,481 INFO:     Epoch: 21
2022-12-05 20:47:20,284 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.443137873980132, 'Total loss': 0.443137873980132} | train loss {'Reaction outcome loss': 0.20503679972382322, 'Total loss': 0.20503679972382322}
2022-12-05 20:47:20,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:20,284 INFO:     Epoch: 22
2022-12-05 20:47:21,083 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4250038645484231, 'Total loss': 0.4250038645484231} | train loss {'Reaction outcome loss': 0.20321999666761728, 'Total loss': 0.20321999666761728}
2022-12-05 20:47:21,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:21,084 INFO:     Epoch: 23
2022-12-05 20:47:21,888 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.419666316698898, 'Total loss': 0.419666316698898} | train loss {'Reaction outcome loss': 0.20024636724302847, 'Total loss': 0.20024636724302847}
2022-12-05 20:47:21,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:21,888 INFO:     Epoch: 24
2022-12-05 20:47:22,688 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42521889304572885, 'Total loss': 0.42521889304572885} | train loss {'Reaction outcome loss': 0.19541688035092047, 'Total loss': 0.19541688035092047}
2022-12-05 20:47:22,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:22,688 INFO:     Epoch: 25
2022-12-05 20:47:23,489 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4312582388520241, 'Total loss': 0.4312582388520241} | train loss {'Reaction outcome loss': 0.18943885294344998, 'Total loss': 0.18943885294344998}
2022-12-05 20:47:23,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:23,490 INFO:     Epoch: 26
2022-12-05 20:47:24,293 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4256224134428935, 'Total loss': 0.4256224134428935} | train loss {'Reaction outcome loss': 0.18638229709599288, 'Total loss': 0.18638229709599288}
2022-12-05 20:47:24,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:24,293 INFO:     Epoch: 27
2022-12-05 20:47:25,093 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.446382501585917, 'Total loss': 0.446382501585917} | train loss {'Reaction outcome loss': 0.18231788482667216, 'Total loss': 0.18231788482667216}
2022-12-05 20:47:25,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:25,094 INFO:     Epoch: 28
2022-12-05 20:47:25,893 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4160241257737983, 'Total loss': 0.4160241257737983} | train loss {'Reaction outcome loss': 0.17996637893450115, 'Total loss': 0.17996637893450115}
2022-12-05 20:47:25,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:25,893 INFO:     Epoch: 29
2022-12-05 20:47:26,695 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4194902309470556, 'Total loss': 0.4194902309470556} | train loss {'Reaction outcome loss': 0.17990308254206133, 'Total loss': 0.17990308254206133}
2022-12-05 20:47:26,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:26,695 INFO:     Epoch: 30
2022-12-05 20:47:27,498 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4266855410215529, 'Total loss': 0.4266855410215529} | train loss {'Reaction outcome loss': 0.1794506186213825, 'Total loss': 0.1794506186213825}
2022-12-05 20:47:27,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:27,498 INFO:     Epoch: 31
2022-12-05 20:47:28,301 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4245213256640868, 'Total loss': 0.4245213256640868} | train loss {'Reaction outcome loss': 0.17219094437877497, 'Total loss': 0.17219094437877497}
2022-12-05 20:47:28,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:28,301 INFO:     Epoch: 32
2022-12-05 20:47:29,101 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43340186605399306, 'Total loss': 0.43340186605399306} | train loss {'Reaction outcome loss': 0.1675704529493927, 'Total loss': 0.1675704529493927}
2022-12-05 20:47:29,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:29,102 INFO:     Epoch: 33
2022-12-05 20:47:29,909 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4363630639219826, 'Total loss': 0.4363630639219826} | train loss {'Reaction outcome loss': 0.16630631991692127, 'Total loss': 0.16630631991692127}
2022-12-05 20:47:29,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:29,909 INFO:     Epoch: 34
2022-12-05 20:47:30,713 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4232603103261102, 'Total loss': 0.4232603103261102} | train loss {'Reaction outcome loss': 0.16600074821091707, 'Total loss': 0.16600074821091707}
2022-12-05 20:47:30,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:30,713 INFO:     Epoch: 35
2022-12-05 20:47:31,517 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4229165461253036, 'Total loss': 0.4229165461253036} | train loss {'Reaction outcome loss': 0.16403049811901105, 'Total loss': 0.16403049811901105}
2022-12-05 20:47:31,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:31,517 INFO:     Epoch: 36
2022-12-05 20:47:32,320 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43505929681387817, 'Total loss': 0.43505929681387817} | train loss {'Reaction outcome loss': 0.16216603010862826, 'Total loss': 0.16216603010862826}
2022-12-05 20:47:32,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:32,320 INFO:     Epoch: 37
2022-12-05 20:47:33,122 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44105567258190026, 'Total loss': 0.44105567258190026} | train loss {'Reaction outcome loss': 0.16058946149273506, 'Total loss': 0.16058946149273506}
2022-12-05 20:47:33,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:33,122 INFO:     Epoch: 38
2022-12-05 20:47:33,928 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4258530309254473, 'Total loss': 0.4258530309254473} | train loss {'Reaction outcome loss': 0.15444100185507728, 'Total loss': 0.15444100185507728}
2022-12-05 20:47:33,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:33,929 INFO:     Epoch: 39
2022-12-05 20:47:34,729 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43124267628247087, 'Total loss': 0.43124267628247087} | train loss {'Reaction outcome loss': 0.1533909584696014, 'Total loss': 0.1533909584696014}
2022-12-05 20:47:34,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:34,730 INFO:     Epoch: 40
2022-12-05 20:47:35,532 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.432507282292301, 'Total loss': 0.432507282292301} | train loss {'Reaction outcome loss': 0.1500509881279281, 'Total loss': 0.1500509881279281}
2022-12-05 20:47:35,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:35,532 INFO:     Epoch: 41
2022-12-05 20:47:36,338 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43447712673382327, 'Total loss': 0.43447712673382327} | train loss {'Reaction outcome loss': 0.15132467250054282, 'Total loss': 0.15132467250054282}
2022-12-05 20:47:36,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:36,338 INFO:     Epoch: 42
2022-12-05 20:47:37,141 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43900747648016974, 'Total loss': 0.43900747648016974} | train loss {'Reaction outcome loss': 0.14852107719953864, 'Total loss': 0.14852107719953864}
2022-12-05 20:47:37,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:37,141 INFO:     Epoch: 43
2022-12-05 20:47:37,948 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42054311084476387, 'Total loss': 0.42054311084476387} | train loss {'Reaction outcome loss': 0.14935140884030731, 'Total loss': 0.14935140884030731}
2022-12-05 20:47:37,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:37,948 INFO:     Epoch: 44
2022-12-05 20:47:38,749 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4261556010354649, 'Total loss': 0.4261556010354649} | train loss {'Reaction outcome loss': 0.14407694378056593, 'Total loss': 0.14407694378056593}
2022-12-05 20:47:38,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:38,749 INFO:     Epoch: 45
2022-12-05 20:47:39,554 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4409988353198225, 'Total loss': 0.4409988353198225} | train loss {'Reaction outcome loss': 0.14897595598332344, 'Total loss': 0.14897595598332344}
2022-12-05 20:47:39,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:39,554 INFO:     Epoch: 46
2022-12-05 20:47:40,360 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4396119811995463, 'Total loss': 0.4396119811995463} | train loss {'Reaction outcome loss': 0.14424271910120884, 'Total loss': 0.14424271910120884}
2022-12-05 20:47:40,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:40,360 INFO:     Epoch: 47
2022-12-05 20:47:41,165 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45165010406212375, 'Total loss': 0.45165010406212375} | train loss {'Reaction outcome loss': 0.14359891754124435, 'Total loss': 0.14359891754124435}
2022-12-05 20:47:41,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:41,166 INFO:     Epoch: 48
2022-12-05 20:47:41,967 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44481072507121344, 'Total loss': 0.44481072507121344} | train loss {'Reaction outcome loss': 0.14267594609484677, 'Total loss': 0.14267594609484677}
2022-12-05 20:47:41,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:41,967 INFO:     Epoch: 49
2022-12-05 20:47:42,768 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44740410250696266, 'Total loss': 0.44740410250696266} | train loss {'Reaction outcome loss': 0.14261535465747358, 'Total loss': 0.14261535465747358}
2022-12-05 20:47:42,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:42,768 INFO:     Epoch: 50
2022-12-05 20:47:43,570 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44344054043970327, 'Total loss': 0.44344054043970327} | train loss {'Reaction outcome loss': 0.13925452824426635, 'Total loss': 0.13925452824426635}
2022-12-05 20:47:43,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:43,570 INFO:     Epoch: 51
2022-12-05 20:47:44,379 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43757888166741893, 'Total loss': 0.43757888166741893} | train loss {'Reaction outcome loss': 0.1388213056770544, 'Total loss': 0.1388213056770544}
2022-12-05 20:47:44,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:44,379 INFO:     Epoch: 52
2022-12-05 20:47:45,187 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44130686204880476, 'Total loss': 0.44130686204880476} | train loss {'Reaction outcome loss': 0.1392578647862519, 'Total loss': 0.1392578647862519}
2022-12-05 20:47:45,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:45,188 INFO:     Epoch: 53
2022-12-05 20:47:45,995 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44590045664120803, 'Total loss': 0.44590045664120803} | train loss {'Reaction outcome loss': 0.13799714298558333, 'Total loss': 0.13799714298558333}
2022-12-05 20:47:45,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:45,995 INFO:     Epoch: 54
2022-12-05 20:47:46,806 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4414497261697596, 'Total loss': 0.4414497261697596} | train loss {'Reaction outcome loss': 0.13559211475113708, 'Total loss': 0.13559211475113708}
2022-12-05 20:47:46,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:46,807 INFO:     Epoch: 55
2022-12-05 20:47:47,609 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4420022906904871, 'Total loss': 0.4420022906904871} | train loss {'Reaction outcome loss': 0.13476598294707196, 'Total loss': 0.13476598294707196}
2022-12-05 20:47:47,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:47,609 INFO:     Epoch: 56
2022-12-05 20:47:48,413 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44244478236545215, 'Total loss': 0.44244478236545215} | train loss {'Reaction outcome loss': 0.13147962918775458, 'Total loss': 0.13147962918775458}
2022-12-05 20:47:48,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:48,413 INFO:     Epoch: 57
2022-12-05 20:47:49,214 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4306676699356599, 'Total loss': 0.4306676699356599} | train loss {'Reaction outcome loss': 0.13282620755114383, 'Total loss': 0.13282620755114383}
2022-12-05 20:47:49,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:49,215 INFO:     Epoch: 58
2022-12-05 20:47:50,018 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4357560310851444, 'Total loss': 0.4357560310851444} | train loss {'Reaction outcome loss': 0.13107891915170777, 'Total loss': 0.13107891915170777}
2022-12-05 20:47:50,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:50,018 INFO:     Epoch: 59
2022-12-05 20:47:50,817 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4360404039987109, 'Total loss': 0.4360404039987109} | train loss {'Reaction outcome loss': 0.12917282725984772, 'Total loss': 0.12917282725984772}
2022-12-05 20:47:50,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:50,817 INFO:     Epoch: 60
2022-12-05 20:47:51,611 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43950562026690354, 'Total loss': 0.43950562026690354} | train loss {'Reaction outcome loss': 0.1314618836021832, 'Total loss': 0.1314618836021832}
2022-12-05 20:47:51,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:51,611 INFO:     Epoch: 61
2022-12-05 20:47:52,407 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4441403162411668, 'Total loss': 0.4441403162411668} | train loss {'Reaction outcome loss': 0.13143444882195082, 'Total loss': 0.13143444882195082}
2022-12-05 20:47:52,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:52,407 INFO:     Epoch: 62
2022-12-05 20:47:53,201 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44292156262831256, 'Total loss': 0.44292156262831256} | train loss {'Reaction outcome loss': 0.12981162739226654, 'Total loss': 0.12981162739226654}
2022-12-05 20:47:53,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:53,201 INFO:     Epoch: 63
2022-12-05 20:47:53,999 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44690835950049485, 'Total loss': 0.44690835950049485} | train loss {'Reaction outcome loss': 0.12725993296161534, 'Total loss': 0.12725993296161534}
2022-12-05 20:47:53,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:54,000 INFO:     Epoch: 64
2022-12-05 20:47:54,795 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4315038190477274, 'Total loss': 0.4315038190477274} | train loss {'Reaction outcome loss': 0.12778733326723019, 'Total loss': 0.12778733326723019}
2022-12-05 20:47:54,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:54,795 INFO:     Epoch: 65
2022-12-05 20:47:55,589 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42806755514307454, 'Total loss': 0.42806755514307454} | train loss {'Reaction outcome loss': 0.12663119679857646, 'Total loss': 0.12663119679857646}
2022-12-05 20:47:55,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:55,590 INFO:     Epoch: 66
2022-12-05 20:47:56,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43931487253443763, 'Total loss': 0.43931487253443763} | train loss {'Reaction outcome loss': 0.12610626140526765, 'Total loss': 0.12610626140526765}
2022-12-05 20:47:56,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:56,385 INFO:     Epoch: 67
2022-12-05 20:47:57,179 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4416669911958955, 'Total loss': 0.4416669911958955} | train loss {'Reaction outcome loss': 0.1250647865648892, 'Total loss': 0.1250647865648892}
2022-12-05 20:47:57,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:57,179 INFO:     Epoch: 68
2022-12-05 20:47:57,974 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42271088961173187, 'Total loss': 0.42271088961173187} | train loss {'Reaction outcome loss': 0.12610060977749527, 'Total loss': 0.12610060977749527}
2022-12-05 20:47:57,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:57,974 INFO:     Epoch: 69
2022-12-05 20:47:58,767 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43438531746241177, 'Total loss': 0.43438531746241177} | train loss {'Reaction outcome loss': 0.1251582996469111, 'Total loss': 0.1251582996469111}
2022-12-05 20:47:58,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:58,768 INFO:     Epoch: 70
2022-12-05 20:47:59,557 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45851585184308613, 'Total loss': 0.45851585184308613} | train loss {'Reaction outcome loss': 0.12280785831652823, 'Total loss': 0.12280785831652823}
2022-12-05 20:47:59,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:47:59,557 INFO:     Epoch: 71
2022-12-05 20:48:00,349 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4442497244612737, 'Total loss': 0.4442497244612737} | train loss {'Reaction outcome loss': 0.1217693476224198, 'Total loss': 0.1217693476224198}
2022-12-05 20:48:00,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:00,350 INFO:     Epoch: 72
2022-12-05 20:48:01,140 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.438646636903286, 'Total loss': 0.438646636903286} | train loss {'Reaction outcome loss': 0.123962055043047, 'Total loss': 0.123962055043047}
2022-12-05 20:48:01,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:01,140 INFO:     Epoch: 73
2022-12-05 20:48:01,930 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44507192041386257, 'Total loss': 0.44507192041386257} | train loss {'Reaction outcome loss': 0.12222700186952527, 'Total loss': 0.12222700186952527}
2022-12-05 20:48:01,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:01,931 INFO:     Epoch: 74
2022-12-05 20:48:02,719 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4520572727038102, 'Total loss': 0.4520572727038102} | train loss {'Reaction outcome loss': 0.12109312281057599, 'Total loss': 0.12109312281057599}
2022-12-05 20:48:02,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:02,720 INFO:     Epoch: 75
2022-12-05 20:48:03,511 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4408756728199395, 'Total loss': 0.4408756728199395} | train loss {'Reaction outcome loss': 0.12210398474182453, 'Total loss': 0.12210398474182453}
2022-12-05 20:48:03,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:03,511 INFO:     Epoch: 76
2022-12-05 20:48:04,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44300955398516223, 'Total loss': 0.44300955398516223} | train loss {'Reaction outcome loss': 0.11864824113135616, 'Total loss': 0.11864824113135616}
2022-12-05 20:48:04,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:04,299 INFO:     Epoch: 77
2022-12-05 20:48:05,088 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43744712085886434, 'Total loss': 0.43744712085886434} | train loss {'Reaction outcome loss': 0.12195760464941661, 'Total loss': 0.12195760464941661}
2022-12-05 20:48:05,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:05,088 INFO:     Epoch: 78
2022-12-05 20:48:05,880 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4441409134729342, 'Total loss': 0.4441409134729342} | train loss {'Reaction outcome loss': 0.11962672180285858, 'Total loss': 0.11962672180285858}
2022-12-05 20:48:05,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:05,880 INFO:     Epoch: 79
2022-12-05 20:48:06,669 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4413154155693271, 'Total loss': 0.4413154155693271} | train loss {'Reaction outcome loss': 0.12007260014633497, 'Total loss': 0.12007260014633497}
2022-12-05 20:48:06,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:06,669 INFO:     Epoch: 80
2022-12-05 20:48:07,458 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45195906914093276, 'Total loss': 0.45195906914093276} | train loss {'Reaction outcome loss': 0.12007525474614193, 'Total loss': 0.12007525474614193}
2022-12-05 20:48:07,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:07,459 INFO:     Epoch: 81
2022-12-05 20:48:08,246 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43998402035371825, 'Total loss': 0.43998402035371825} | train loss {'Reaction outcome loss': 0.1177677275395141, 'Total loss': 0.1177677275395141}
2022-12-05 20:48:08,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:08,247 INFO:     Epoch: 82
2022-12-05 20:48:09,041 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4570872394198721, 'Total loss': 0.4570872394198721} | train loss {'Reaction outcome loss': 0.11761071846910542, 'Total loss': 0.11761071846910542}
2022-12-05 20:48:09,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:09,041 INFO:     Epoch: 83
2022-12-05 20:48:09,830 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45546441965482454, 'Total loss': 0.45546441965482454} | train loss {'Reaction outcome loss': 0.11614549796908133, 'Total loss': 0.11614549796908133}
2022-12-05 20:48:09,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:09,830 INFO:     Epoch: 84
2022-12-05 20:48:10,618 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44604351168329065, 'Total loss': 0.44604351168329065} | train loss {'Reaction outcome loss': 0.11897149624963922, 'Total loss': 0.11897149624963922}
2022-12-05 20:48:10,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:10,619 INFO:     Epoch: 85
2022-12-05 20:48:11,407 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44801386242563074, 'Total loss': 0.44801386242563074} | train loss {'Reaction outcome loss': 0.11780777801909754, 'Total loss': 0.11780777801909754}
2022-12-05 20:48:11,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:11,407 INFO:     Epoch: 86
2022-12-05 20:48:12,212 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.438019449737939, 'Total loss': 0.438019449737939} | train loss {'Reaction outcome loss': 0.116112322865745, 'Total loss': 0.116112322865745}
2022-12-05 20:48:12,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:12,213 INFO:     Epoch: 87
2022-12-05 20:48:13,016 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4360530007291924, 'Total loss': 0.4360530007291924} | train loss {'Reaction outcome loss': 0.1190066741546616, 'Total loss': 0.1190066741546616}
2022-12-05 20:48:13,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:13,017 INFO:     Epoch: 88
2022-12-05 20:48:13,826 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4380742006681182, 'Total loss': 0.4380742006681182} | train loss {'Reaction outcome loss': 0.11508554521001756, 'Total loss': 0.11508554521001756}
2022-12-05 20:48:13,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:13,826 INFO:     Epoch: 89
2022-12-05 20:48:14,633 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4422113899649544, 'Total loss': 0.4422113899649544} | train loss {'Reaction outcome loss': 0.11405111515834447, 'Total loss': 0.11405111515834447}
2022-12-05 20:48:14,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:14,634 INFO:     Epoch: 90
2022-12-05 20:48:15,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4401120462200858, 'Total loss': 0.4401120462200858} | train loss {'Reaction outcome loss': 0.11396467969133219, 'Total loss': 0.11396467969133219}
2022-12-05 20:48:15,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:15,441 INFO:     Epoch: 91
2022-12-05 20:48:16,253 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4438917181369933, 'Total loss': 0.4438917181369933} | train loss {'Reaction outcome loss': 0.11633967806870539, 'Total loss': 0.11633967806870539}
2022-12-05 20:48:16,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:16,253 INFO:     Epoch: 92
2022-12-05 20:48:17,059 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4396100611510602, 'Total loss': 0.4396100611510602} | train loss {'Reaction outcome loss': 0.11393126065001613, 'Total loss': 0.11393126065001613}
2022-12-05 20:48:17,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:17,059 INFO:     Epoch: 93
2022-12-05 20:48:17,867 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4534101708030159, 'Total loss': 0.4534101708030159} | train loss {'Reaction outcome loss': 0.11276138830374205, 'Total loss': 0.11276138830374205}
2022-12-05 20:48:17,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:17,867 INFO:     Epoch: 94
2022-12-05 20:48:18,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4465987076136199, 'Total loss': 0.4465987076136199} | train loss {'Reaction outcome loss': 0.114770163100348, 'Total loss': 0.114770163100348}
2022-12-05 20:48:18,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:18,677 INFO:     Epoch: 95
2022-12-05 20:48:19,473 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44442987543615425, 'Total loss': 0.44442987543615425} | train loss {'Reaction outcome loss': 0.1135487514782712, 'Total loss': 0.1135487514782712}
2022-12-05 20:48:19,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:19,473 INFO:     Epoch: 96
2022-12-05 20:48:20,271 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44159198298373004, 'Total loss': 0.44159198298373004} | train loss {'Reaction outcome loss': 0.11426817352372792, 'Total loss': 0.11426817352372792}
2022-12-05 20:48:20,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:20,272 INFO:     Epoch: 97
2022-12-05 20:48:21,064 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44795272550122306, 'Total loss': 0.44795272550122306} | train loss {'Reaction outcome loss': 0.11250715703523208, 'Total loss': 0.11250715703523208}
2022-12-05 20:48:21,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:21,064 INFO:     Epoch: 98
2022-12-05 20:48:21,854 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44416089123114944, 'Total loss': 0.44416089123114944} | train loss {'Reaction outcome loss': 0.11131009575535333, 'Total loss': 0.11131009575535333}
2022-12-05 20:48:21,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:21,855 INFO:     Epoch: 99
2022-12-05 20:48:22,651 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4333088577470996, 'Total loss': 0.4333088577470996} | train loss {'Reaction outcome loss': 0.11182867432944477, 'Total loss': 0.11182867432944477}
2022-12-05 20:48:22,651 INFO:     Best model found after epoch 14 of 100.
2022-12-05 20:48:22,651 INFO:   Done with stage: TRAINING
2022-12-05 20:48:22,651 INFO:   Starting stage: EVALUATION
2022-12-05 20:48:22,770 INFO:   Done with stage: EVALUATION
2022-12-05 20:48:22,770 INFO:   Leaving out SEQ value Fold_6
2022-12-05 20:48:22,783 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:48:22,783 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:48:23,416 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:48:23,417 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:48:23,486 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:48:23,486 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:48:23,487 INFO:     No hyperparam tuning for this model
2022-12-05 20:48:23,487 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:48:23,487 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:48:23,487 INFO:     None feature selector for col prot
2022-12-05 20:48:23,488 INFO:     None feature selector for col prot
2022-12-05 20:48:23,488 INFO:     None feature selector for col prot
2022-12-05 20:48:23,488 INFO:     None feature selector for col chem
2022-12-05 20:48:23,488 INFO:     None feature selector for col chem
2022-12-05 20:48:23,488 INFO:     None feature selector for col chem
2022-12-05 20:48:23,488 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:48:23,488 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:48:23,490 INFO:     Number of params in model 215821
2022-12-05 20:48:23,494 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:48:23,494 INFO:   Starting stage: TRAINING
2022-12-05 20:48:23,554 INFO:     Val loss before train {'Reaction outcome loss': 1.0123779502781955, 'Total loss': 1.0123779502781955}
2022-12-05 20:48:23,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:23,554 INFO:     Epoch: 0
2022-12-05 20:48:24,341 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.566770083524964, 'Total loss': 0.566770083524964} | train loss {'Reaction outcome loss': 0.7857242485698388, 'Total loss': 0.7857242485698388}
2022-12-05 20:48:24,341 INFO:     Found new best model at epoch 0
2022-12-05 20:48:24,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:24,342 INFO:     Epoch: 1
2022-12-05 20:48:25,122 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48731496693058446, 'Total loss': 0.48731496693058446} | train loss {'Reaction outcome loss': 0.5289856434476619, 'Total loss': 0.5289856434476619}
2022-12-05 20:48:25,122 INFO:     Found new best model at epoch 1
2022-12-05 20:48:25,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:25,123 INFO:     Epoch: 2
2022-12-05 20:48:25,904 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4495895369486375, 'Total loss': 0.4495895369486375} | train loss {'Reaction outcome loss': 0.46120650707458966, 'Total loss': 0.46120650707458966}
2022-12-05 20:48:25,904 INFO:     Found new best model at epoch 2
2022-12-05 20:48:25,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:25,905 INFO:     Epoch: 3
2022-12-05 20:48:26,686 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4274001873352311, 'Total loss': 0.4274001873352311} | train loss {'Reaction outcome loss': 0.42100479858262196, 'Total loss': 0.42100479858262196}
2022-12-05 20:48:26,686 INFO:     Found new best model at epoch 3
2022-12-05 20:48:26,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:26,687 INFO:     Epoch: 4
2022-12-05 20:48:27,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4191813993860375, 'Total loss': 0.4191813993860375} | train loss {'Reaction outcome loss': 0.3923962104685452, 'Total loss': 0.3923962104685452}
2022-12-05 20:48:27,466 INFO:     Found new best model at epoch 4
2022-12-05 20:48:27,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:27,467 INFO:     Epoch: 5
2022-12-05 20:48:28,252 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4096641181544824, 'Total loss': 0.4096641181544824} | train loss {'Reaction outcome loss': 0.36866781550402544, 'Total loss': 0.36866781550402544}
2022-12-05 20:48:28,252 INFO:     Found new best model at epoch 5
2022-12-05 20:48:28,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:28,253 INFO:     Epoch: 6
2022-12-05 20:48:29,039 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41006201708858664, 'Total loss': 0.41006201708858664} | train loss {'Reaction outcome loss': 0.3467823069618673, 'Total loss': 0.3467823069618673}
2022-12-05 20:48:29,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:29,039 INFO:     Epoch: 7
2022-12-05 20:48:29,829 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39050944217226724, 'Total loss': 0.39050944217226724} | train loss {'Reaction outcome loss': 0.32885456462295687, 'Total loss': 0.32885456462295687}
2022-12-05 20:48:29,829 INFO:     Found new best model at epoch 7
2022-12-05 20:48:29,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:29,830 INFO:     Epoch: 8
2022-12-05 20:48:30,620 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3972026238387281, 'Total loss': 0.3972026238387281} | train loss {'Reaction outcome loss': 0.31693644855095415, 'Total loss': 0.31693644855095415}
2022-12-05 20:48:30,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:30,620 INFO:     Epoch: 9
2022-12-05 20:48:31,410 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3991140508177606, 'Total loss': 0.3991140508177606} | train loss {'Reaction outcome loss': 0.30506374297701583, 'Total loss': 0.30506374297701583}
2022-12-05 20:48:31,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:31,410 INFO:     Epoch: 10
2022-12-05 20:48:32,198 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39750041033733974, 'Total loss': 0.39750041033733974} | train loss {'Reaction outcome loss': 0.2875844561627933, 'Total loss': 0.2875844561627933}
2022-12-05 20:48:32,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:32,198 INFO:     Epoch: 11
2022-12-05 20:48:32,987 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40000439096580853, 'Total loss': 0.40000439096580853} | train loss {'Reaction outcome loss': 0.2775289372522004, 'Total loss': 0.2775289372522004}
2022-12-05 20:48:32,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:32,987 INFO:     Epoch: 12
2022-12-05 20:48:33,780 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4043062689968131, 'Total loss': 0.4043062689968131} | train loss {'Reaction outcome loss': 0.2686565906113508, 'Total loss': 0.2686565906113508}
2022-12-05 20:48:33,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:33,780 INFO:     Epoch: 13
2022-12-05 20:48:34,570 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4069857724349607, 'Total loss': 0.4069857724349607} | train loss {'Reaction outcome loss': 0.2603577703541639, 'Total loss': 0.2603577703541639}
2022-12-05 20:48:34,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:34,570 INFO:     Epoch: 14
2022-12-05 20:48:35,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38912862310694024, 'Total loss': 0.38912862310694024} | train loss {'Reaction outcome loss': 0.25033472089134917, 'Total loss': 0.25033472089134917}
2022-12-05 20:48:35,361 INFO:     Found new best model at epoch 14
2022-12-05 20:48:35,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:35,361 INFO:     Epoch: 15
2022-12-05 20:48:36,147 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4075396406379613, 'Total loss': 0.4075396406379613} | train loss {'Reaction outcome loss': 0.2404894389820342, 'Total loss': 0.2404894389820342}
2022-12-05 20:48:36,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:36,148 INFO:     Epoch: 16
2022-12-05 20:48:36,936 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3889977071772922, 'Total loss': 0.3889977071772922} | train loss {'Reaction outcome loss': 0.23604162221356315, 'Total loss': 0.23604162221356315}
2022-12-05 20:48:36,937 INFO:     Found new best model at epoch 16
2022-12-05 20:48:36,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:36,938 INFO:     Epoch: 17
2022-12-05 20:48:37,727 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38519826802340423, 'Total loss': 0.38519826802340423} | train loss {'Reaction outcome loss': 0.2285724263410179, 'Total loss': 0.2285724263410179}
2022-12-05 20:48:37,727 INFO:     Found new best model at epoch 17
2022-12-05 20:48:37,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:37,728 INFO:     Epoch: 18
2022-12-05 20:48:38,517 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4056090753186833, 'Total loss': 0.4056090753186833} | train loss {'Reaction outcome loss': 0.22477395514748535, 'Total loss': 0.22477395514748535}
2022-12-05 20:48:38,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:38,517 INFO:     Epoch: 19
2022-12-05 20:48:39,302 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3990522819486531, 'Total loss': 0.3990522819486531} | train loss {'Reaction outcome loss': 0.2179909572005272, 'Total loss': 0.2179909572005272}
2022-12-05 20:48:39,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:39,304 INFO:     Epoch: 20
2022-12-05 20:48:40,093 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3916500314054164, 'Total loss': 0.3916500314054164} | train loss {'Reaction outcome loss': 0.21229075419963622, 'Total loss': 0.21229075419963622}
2022-12-05 20:48:40,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:40,093 INFO:     Epoch: 21
2022-12-05 20:48:40,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.394341064278375, 'Total loss': 0.394341064278375} | train loss {'Reaction outcome loss': 0.20783606718997566, 'Total loss': 0.20783606718997566}
2022-12-05 20:48:40,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:40,881 INFO:     Epoch: 22
2022-12-05 20:48:41,673 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4054906191304326, 'Total loss': 0.4054906191304326} | train loss {'Reaction outcome loss': 0.20492354407146268, 'Total loss': 0.20492354407146268}
2022-12-05 20:48:41,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:41,673 INFO:     Epoch: 23
2022-12-05 20:48:42,464 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40320176394148305, 'Total loss': 0.40320176394148305} | train loss {'Reaction outcome loss': 0.20005410637478438, 'Total loss': 0.20005410637478438}
2022-12-05 20:48:42,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:42,464 INFO:     Epoch: 24
2022-12-05 20:48:43,251 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44020063938065007, 'Total loss': 0.44020063938065007} | train loss {'Reaction outcome loss': 0.1944920733419, 'Total loss': 0.1944920733419}
2022-12-05 20:48:43,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:43,251 INFO:     Epoch: 25
2022-12-05 20:48:44,038 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4222081696445292, 'Total loss': 0.4222081696445292} | train loss {'Reaction outcome loss': 0.18820794550131778, 'Total loss': 0.18820794550131778}
2022-12-05 20:48:44,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:44,039 INFO:     Epoch: 26
2022-12-05 20:48:44,826 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4149118277498267, 'Total loss': 0.4149118277498267} | train loss {'Reaction outcome loss': 0.1856110117645288, 'Total loss': 0.1856110117645288}
2022-12-05 20:48:44,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:44,826 INFO:     Epoch: 27
2022-12-05 20:48:45,614 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40178977054628456, 'Total loss': 0.40178977054628456} | train loss {'Reaction outcome loss': 0.18656415992549488, 'Total loss': 0.18656415992549488}
2022-12-05 20:48:45,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:45,615 INFO:     Epoch: 28
2022-12-05 20:48:46,412 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4037066972391172, 'Total loss': 0.4037066972391172} | train loss {'Reaction outcome loss': 0.18284610525837966, 'Total loss': 0.18284610525837966}
2022-12-05 20:48:46,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:46,412 INFO:     Epoch: 29
2022-12-05 20:48:47,200 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4263258112425154, 'Total loss': 0.4263258112425154} | train loss {'Reaction outcome loss': 0.17902977014986837, 'Total loss': 0.17902977014986837}
2022-12-05 20:48:47,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:47,200 INFO:     Epoch: 30
2022-12-05 20:48:47,991 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39386439814486285, 'Total loss': 0.39386439814486285} | train loss {'Reaction outcome loss': 0.17683225381283127, 'Total loss': 0.17683225381283127}
2022-12-05 20:48:47,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:47,992 INFO:     Epoch: 31
2022-12-05 20:48:48,779 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4202944607558576, 'Total loss': 0.4202944607558576} | train loss {'Reaction outcome loss': 0.17158228696456979, 'Total loss': 0.17158228696456979}
2022-12-05 20:48:48,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:48,780 INFO:     Epoch: 32
2022-12-05 20:48:49,570 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4174402119083838, 'Total loss': 0.4174402119083838} | train loss {'Reaction outcome loss': 0.17097951828369073, 'Total loss': 0.17097951828369073}
2022-12-05 20:48:49,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:49,570 INFO:     Epoch: 33
2022-12-05 20:48:50,361 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42186864905736665, 'Total loss': 0.42186864905736665} | train loss {'Reaction outcome loss': 0.169957139867605, 'Total loss': 0.169957139867605}
2022-12-05 20:48:50,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:50,361 INFO:     Epoch: 34
2022-12-05 20:48:51,153 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4071715463968841, 'Total loss': 0.4071715463968841} | train loss {'Reaction outcome loss': 0.16790579591630672, 'Total loss': 0.16790579591630672}
2022-12-05 20:48:51,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:51,154 INFO:     Epoch: 35
2022-12-05 20:48:51,943 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4145478419959545, 'Total loss': 0.4145478419959545} | train loss {'Reaction outcome loss': 0.16300426984623986, 'Total loss': 0.16300426984623986}
2022-12-05 20:48:51,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:51,943 INFO:     Epoch: 36
2022-12-05 20:48:52,731 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41296365700492804, 'Total loss': 0.41296365700492804} | train loss {'Reaction outcome loss': 0.16341078746683743, 'Total loss': 0.16341078746683743}
2022-12-05 20:48:52,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:52,732 INFO:     Epoch: 37
2022-12-05 20:48:53,521 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41540835526856507, 'Total loss': 0.41540835526856507} | train loss {'Reaction outcome loss': 0.15980302787252834, 'Total loss': 0.15980302787252834}
2022-12-05 20:48:53,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:53,521 INFO:     Epoch: 38
2022-12-05 20:48:54,310 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4250248423354192, 'Total loss': 0.4250248423354192} | train loss {'Reaction outcome loss': 0.15588073081964132, 'Total loss': 0.15588073081964132}
2022-12-05 20:48:54,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:54,310 INFO:     Epoch: 39
2022-12-05 20:48:55,102 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42415826383512467, 'Total loss': 0.42415826383512467} | train loss {'Reaction outcome loss': 0.15750914517866105, 'Total loss': 0.15750914517866105}
2022-12-05 20:48:55,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:55,102 INFO:     Epoch: 40
2022-12-05 20:48:55,890 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.418195389973169, 'Total loss': 0.418195389973169} | train loss {'Reaction outcome loss': 0.15452645253009942, 'Total loss': 0.15452645253009942}
2022-12-05 20:48:55,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:55,890 INFO:     Epoch: 41
2022-12-05 20:48:56,677 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4150811897760088, 'Total loss': 0.4150811897760088} | train loss {'Reaction outcome loss': 0.1543272698792268, 'Total loss': 0.1543272698792268}
2022-12-05 20:48:56,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:56,678 INFO:     Epoch: 42
2022-12-05 20:48:57,467 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4019515980775891, 'Total loss': 0.4019515980775891} | train loss {'Reaction outcome loss': 0.1554959450829394, 'Total loss': 0.1554959450829394}
2022-12-05 20:48:57,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:57,468 INFO:     Epoch: 43
2022-12-05 20:48:58,261 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4234871948984536, 'Total loss': 0.4234871948984536} | train loss {'Reaction outcome loss': 0.1504074717130588, 'Total loss': 0.1504074717130588}
2022-12-05 20:48:58,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:58,261 INFO:     Epoch: 44
2022-12-05 20:48:59,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4128333909267729, 'Total loss': 0.4128333909267729} | train loss {'Reaction outcome loss': 0.15257386115132546, 'Total loss': 0.15257386115132546}
2022-12-05 20:48:59,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:59,050 INFO:     Epoch: 45
2022-12-05 20:48:59,845 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43674431030045857, 'Total loss': 0.43674431030045857} | train loss {'Reaction outcome loss': 0.14910391772888146, 'Total loss': 0.14910391772888146}
2022-12-05 20:48:59,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:48:59,845 INFO:     Epoch: 46
2022-12-05 20:49:00,636 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4155612239106135, 'Total loss': 0.4155612239106135} | train loss {'Reaction outcome loss': 0.14573358397702782, 'Total loss': 0.14573358397702782}
2022-12-05 20:49:00,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:00,636 INFO:     Epoch: 47
2022-12-05 20:49:01,431 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4143353521146558, 'Total loss': 0.4143353521146558} | train loss {'Reaction outcome loss': 0.14694734523643035, 'Total loss': 0.14694734523643035}
2022-12-05 20:49:01,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:01,431 INFO:     Epoch: 48
2022-12-05 20:49:02,219 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43571569601243193, 'Total loss': 0.43571569601243193} | train loss {'Reaction outcome loss': 0.14541777929633248, 'Total loss': 0.14541777929633248}
2022-12-05 20:49:02,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:02,219 INFO:     Epoch: 49
2022-12-05 20:49:03,016 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4271963656223802, 'Total loss': 0.4271963656223802} | train loss {'Reaction outcome loss': 0.1445189755181877, 'Total loss': 0.1445189755181877}
2022-12-05 20:49:03,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:03,016 INFO:     Epoch: 50
2022-12-05 20:49:03,804 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4359969019212506, 'Total loss': 0.4359969019212506} | train loss {'Reaction outcome loss': 0.14118189496197261, 'Total loss': 0.14118189496197261}
2022-12-05 20:49:03,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:03,805 INFO:     Epoch: 51
2022-12-05 20:49:04,591 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4209743252193386, 'Total loss': 0.4209743252193386} | train loss {'Reaction outcome loss': 0.14491674052361322, 'Total loss': 0.14491674052361322}
2022-12-05 20:49:04,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:04,591 INFO:     Epoch: 52
2022-12-05 20:49:05,379 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4158920830285007, 'Total loss': 0.4158920830285007} | train loss {'Reaction outcome loss': 0.13839118727387822, 'Total loss': 0.13839118727387822}
2022-12-05 20:49:05,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:05,380 INFO:     Epoch: 53
2022-12-05 20:49:06,168 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43086106567220256, 'Total loss': 0.43086106567220256} | train loss {'Reaction outcome loss': 0.14007647999999476, 'Total loss': 0.14007647999999476}
2022-12-05 20:49:06,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:06,168 INFO:     Epoch: 54
2022-12-05 20:49:06,955 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42956184866753494, 'Total loss': 0.42956184866753494} | train loss {'Reaction outcome loss': 0.13614836915263107, 'Total loss': 0.13614836915263107}
2022-12-05 20:49:06,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:06,956 INFO:     Epoch: 55
2022-12-05 20:49:07,743 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45770143243399536, 'Total loss': 0.45770143243399536} | train loss {'Reaction outcome loss': 0.13826233286562623, 'Total loss': 0.13826233286562623}
2022-12-05 20:49:07,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:07,743 INFO:     Epoch: 56
2022-12-05 20:49:08,531 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4328569732606411, 'Total loss': 0.4328569732606411} | train loss {'Reaction outcome loss': 0.13295681543116059, 'Total loss': 0.13295681543116059}
2022-12-05 20:49:08,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:08,532 INFO:     Epoch: 57
2022-12-05 20:49:09,319 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4111599495888434, 'Total loss': 0.4111599495888434} | train loss {'Reaction outcome loss': 0.1355553573035464, 'Total loss': 0.1355553573035464}
2022-12-05 20:49:09,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:09,319 INFO:     Epoch: 58
2022-12-05 20:49:10,112 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4203804838047786, 'Total loss': 0.4203804838047786} | train loss {'Reaction outcome loss': 0.13723383033458067, 'Total loss': 0.13723383033458067}
2022-12-05 20:49:10,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:10,113 INFO:     Epoch: 59
2022-12-05 20:49:10,903 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4193474365906282, 'Total loss': 0.4193474365906282} | train loss {'Reaction outcome loss': 0.13479682586098812, 'Total loss': 0.13479682586098812}
2022-12-05 20:49:10,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:10,903 INFO:     Epoch: 60
2022-12-05 20:49:11,696 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41473155841231346, 'Total loss': 0.41473155841231346} | train loss {'Reaction outcome loss': 0.13426805132885977, 'Total loss': 0.13426805132885977}
2022-12-05 20:49:11,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:11,696 INFO:     Epoch: 61
2022-12-05 20:49:12,485 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42092496156692505, 'Total loss': 0.42092496156692505} | train loss {'Reaction outcome loss': 0.13432589225014863, 'Total loss': 0.13432589225014863}
2022-12-05 20:49:12,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:12,485 INFO:     Epoch: 62
2022-12-05 20:49:13,275 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4291231259703636, 'Total loss': 0.4291231259703636} | train loss {'Reaction outcome loss': 0.13207134707849852, 'Total loss': 0.13207134707849852}
2022-12-05 20:49:13,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:13,275 INFO:     Epoch: 63
2022-12-05 20:49:14,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4210303830490871, 'Total loss': 0.4210303830490871} | train loss {'Reaction outcome loss': 0.1325273296586713, 'Total loss': 0.1325273296586713}
2022-12-05 20:49:14,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:14,067 INFO:     Epoch: 64
2022-12-05 20:49:14,859 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41955031793225894, 'Total loss': 0.41955031793225894} | train loss {'Reaction outcome loss': 0.13076078008708297, 'Total loss': 0.13076078008708297}
2022-12-05 20:49:14,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:14,859 INFO:     Epoch: 65
2022-12-05 20:49:15,651 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41153210994194855, 'Total loss': 0.41153210994194855} | train loss {'Reaction outcome loss': 0.1294085514104488, 'Total loss': 0.1294085514104488}
2022-12-05 20:49:15,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:15,652 INFO:     Epoch: 66
2022-12-05 20:49:16,440 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42227839543060824, 'Total loss': 0.42227839543060824} | train loss {'Reaction outcome loss': 0.13010860755279355, 'Total loss': 0.13010860755279355}
2022-12-05 20:49:16,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:16,440 INFO:     Epoch: 67
2022-12-05 20:49:17,233 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41592069207531907, 'Total loss': 0.41592069207531907} | train loss {'Reaction outcome loss': 0.12910191041550467, 'Total loss': 0.12910191041550467}
2022-12-05 20:49:17,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:17,233 INFO:     Epoch: 68
2022-12-05 20:49:18,021 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43615432422269473, 'Total loss': 0.43615432422269473} | train loss {'Reaction outcome loss': 0.1288109526342275, 'Total loss': 0.1288109526342275}
2022-12-05 20:49:18,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:18,021 INFO:     Epoch: 69
2022-12-05 20:49:18,810 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42624683712016453, 'Total loss': 0.42624683712016453} | train loss {'Reaction outcome loss': 0.12537432836786824, 'Total loss': 0.12537432836786824}
2022-12-05 20:49:18,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:18,810 INFO:     Epoch: 70
2022-12-05 20:49:19,600 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4349053361537782, 'Total loss': 0.4349053361537782} | train loss {'Reaction outcome loss': 0.12821819530609918, 'Total loss': 0.12821819530609918}
2022-12-05 20:49:19,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:19,601 INFO:     Epoch: 71
2022-12-05 20:49:20,392 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41792461106723006, 'Total loss': 0.41792461106723006} | train loss {'Reaction outcome loss': 0.12634370824588195, 'Total loss': 0.12634370824588195}
2022-12-05 20:49:20,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:20,392 INFO:     Epoch: 72
2022-12-05 20:49:21,186 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42745039628987963, 'Total loss': 0.42745039628987963} | train loss {'Reaction outcome loss': 0.12490884907999818, 'Total loss': 0.12490884907999818}
2022-12-05 20:49:21,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:21,186 INFO:     Epoch: 73
2022-12-05 20:49:21,985 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41056574640837923, 'Total loss': 0.41056574640837923} | train loss {'Reaction outcome loss': 0.126968924967306, 'Total loss': 0.126968924967306}
2022-12-05 20:49:21,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:21,986 INFO:     Epoch: 74
2022-12-05 20:49:22,780 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4390935433859175, 'Total loss': 0.4390935433859175} | train loss {'Reaction outcome loss': 0.1271120877594364, 'Total loss': 0.1271120877594364}
2022-12-05 20:49:22,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:22,780 INFO:     Epoch: 75
2022-12-05 20:49:23,571 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4241218634627082, 'Total loss': 0.4241218634627082} | train loss {'Reaction outcome loss': 0.12489560690271306, 'Total loss': 0.12489560690271306}
2022-12-05 20:49:23,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:23,571 INFO:     Epoch: 76
2022-12-05 20:49:24,366 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4245955097404393, 'Total loss': 0.4245955097404393} | train loss {'Reaction outcome loss': 0.12390617233301912, 'Total loss': 0.12390617233301912}
2022-12-05 20:49:24,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:24,366 INFO:     Epoch: 77
2022-12-05 20:49:25,159 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4270061291754246, 'Total loss': 0.4270061291754246} | train loss {'Reaction outcome loss': 0.12534106770644382, 'Total loss': 0.12534106770644382}
2022-12-05 20:49:25,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:25,159 INFO:     Epoch: 78
2022-12-05 20:49:25,951 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41887042739174585, 'Total loss': 0.41887042739174585} | train loss {'Reaction outcome loss': 0.12436635781611716, 'Total loss': 0.12436635781611716}
2022-12-05 20:49:25,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:25,952 INFO:     Epoch: 79
2022-12-05 20:49:26,747 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4235326485200362, 'Total loss': 0.4235326485200362} | train loss {'Reaction outcome loss': 0.1226462241832395, 'Total loss': 0.1226462241832395}
2022-12-05 20:49:26,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:26,747 INFO:     Epoch: 80
2022-12-05 20:49:27,540 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4141102966598489, 'Total loss': 0.4141102966598489} | train loss {'Reaction outcome loss': 0.12127486933402869, 'Total loss': 0.12127486933402869}
2022-12-05 20:49:27,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:27,540 INFO:     Epoch: 81
2022-12-05 20:49:28,333 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4289677366614342, 'Total loss': 0.4289677366614342} | train loss {'Reaction outcome loss': 0.12009547111027095, 'Total loss': 0.12009547111027095}
2022-12-05 20:49:28,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:28,334 INFO:     Epoch: 82
2022-12-05 20:49:29,126 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4297317694025961, 'Total loss': 0.4297317694025961} | train loss {'Reaction outcome loss': 0.12154023776933247, 'Total loss': 0.12154023776933247}
2022-12-05 20:49:29,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:29,126 INFO:     Epoch: 83
2022-12-05 20:49:29,917 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4233581041070548, 'Total loss': 0.4233581041070548} | train loss {'Reaction outcome loss': 0.12240573605712579, 'Total loss': 0.12240573605712579}
2022-12-05 20:49:29,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:29,917 INFO:     Epoch: 84
2022-12-05 20:49:30,705 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4142163531346755, 'Total loss': 0.4142163531346755} | train loss {'Reaction outcome loss': 0.1224221175232408, 'Total loss': 0.1224221175232408}
2022-12-05 20:49:30,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:30,705 INFO:     Epoch: 85
2022-12-05 20:49:31,495 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4690451906485991, 'Total loss': 0.4690451906485991} | train loss {'Reaction outcome loss': 0.1184205980591324, 'Total loss': 0.1184205980591324}
2022-12-05 20:49:31,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:31,495 INFO:     Epoch: 86
2022-12-05 20:49:32,283 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4435205208984288, 'Total loss': 0.4435205208984288} | train loss {'Reaction outcome loss': 0.12157095532522214, 'Total loss': 0.12157095532522214}
2022-12-05 20:49:32,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:32,284 INFO:     Epoch: 87
2022-12-05 20:49:33,074 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43006993186744774, 'Total loss': 0.43006993186744774} | train loss {'Reaction outcome loss': 0.11688548135666214, 'Total loss': 0.11688548135666214}
2022-12-05 20:49:33,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:33,074 INFO:     Epoch: 88
2022-12-05 20:49:33,865 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44360693442550575, 'Total loss': 0.44360693442550575} | train loss {'Reaction outcome loss': 0.11750359242325839, 'Total loss': 0.11750359242325839}
2022-12-05 20:49:33,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:33,865 INFO:     Epoch: 89
2022-12-05 20:49:34,654 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44162546572360123, 'Total loss': 0.44162546572360123} | train loss {'Reaction outcome loss': 0.11606827290082464, 'Total loss': 0.11606827290082464}
2022-12-05 20:49:34,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:34,654 INFO:     Epoch: 90
2022-12-05 20:49:35,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4135875749317082, 'Total loss': 0.4135875749317082} | train loss {'Reaction outcome loss': 0.11942366019879677, 'Total loss': 0.11942366019879677}
2022-12-05 20:49:35,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:35,441 INFO:     Epoch: 91
2022-12-05 20:49:36,234 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45922103778205137, 'Total loss': 0.45922103778205137} | train loss {'Reaction outcome loss': 0.11671111539994576, 'Total loss': 0.11671111539994576}
2022-12-05 20:49:36,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:36,235 INFO:     Epoch: 92
2022-12-05 20:49:37,026 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4282501172089145, 'Total loss': 0.4282501172089145} | train loss {'Reaction outcome loss': 0.11845580206765813, 'Total loss': 0.11845580206765813}
2022-12-05 20:49:37,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:37,026 INFO:     Epoch: 93
2022-12-05 20:49:37,817 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43761834502220154, 'Total loss': 0.43761834502220154} | train loss {'Reaction outcome loss': 0.11743784026831997, 'Total loss': 0.11743784026831997}
2022-12-05 20:49:37,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:37,817 INFO:     Epoch: 94
2022-12-05 20:49:38,609 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40013577129205014, 'Total loss': 0.40013577129205014} | train loss {'Reaction outcome loss': 0.11698364227706072, 'Total loss': 0.11698364227706072}
2022-12-05 20:49:38,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:38,609 INFO:     Epoch: 95
2022-12-05 20:49:39,400 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4211785945702683, 'Total loss': 0.4211785945702683} | train loss {'Reaction outcome loss': 0.11344747060567749, 'Total loss': 0.11344747060567749}
2022-12-05 20:49:39,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:39,400 INFO:     Epoch: 96
2022-12-05 20:49:40,190 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42731906033375044, 'Total loss': 0.42731906033375044} | train loss {'Reaction outcome loss': 0.11578120169210798, 'Total loss': 0.11578120169210798}
2022-12-05 20:49:40,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:40,190 INFO:     Epoch: 97
2022-12-05 20:49:40,980 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41235395138474734, 'Total loss': 0.41235395138474734} | train loss {'Reaction outcome loss': 0.11521020682566628, 'Total loss': 0.11521020682566628}
2022-12-05 20:49:40,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:40,981 INFO:     Epoch: 98
2022-12-05 20:49:41,773 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42399181391705165, 'Total loss': 0.42399181391705165} | train loss {'Reaction outcome loss': 0.11394845882468686, 'Total loss': 0.11394845882468686}
2022-12-05 20:49:41,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:41,774 INFO:     Epoch: 99
2022-12-05 20:49:42,565 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40887895091013476, 'Total loss': 0.40887895091013476} | train loss {'Reaction outcome loss': 0.11386986411347681, 'Total loss': 0.11386986411347681}
2022-12-05 20:49:42,565 INFO:     Best model found after epoch 18 of 100.
2022-12-05 20:49:42,566 INFO:   Done with stage: TRAINING
2022-12-05 20:49:42,566 INFO:   Starting stage: EVALUATION
2022-12-05 20:49:42,697 INFO:   Done with stage: EVALUATION
2022-12-05 20:49:42,697 INFO:   Leaving out SEQ value Fold_7
2022-12-05 20:49:42,709 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:49:42,709 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:49:43,354 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:49:43,354 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:49:43,423 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:49:43,424 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:49:43,424 INFO:     No hyperparam tuning for this model
2022-12-05 20:49:43,424 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:49:43,424 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:49:43,424 INFO:     None feature selector for col prot
2022-12-05 20:49:43,425 INFO:     None feature selector for col prot
2022-12-05 20:49:43,425 INFO:     None feature selector for col prot
2022-12-05 20:49:43,425 INFO:     None feature selector for col chem
2022-12-05 20:49:43,425 INFO:     None feature selector for col chem
2022-12-05 20:49:43,425 INFO:     None feature selector for col chem
2022-12-05 20:49:43,425 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:49:43,425 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:49:43,427 INFO:     Number of params in model 215821
2022-12-05 20:49:43,430 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:49:43,430 INFO:   Starting stage: TRAINING
2022-12-05 20:49:43,491 INFO:     Val loss before train {'Reaction outcome loss': 1.0394143936308948, 'Total loss': 1.0394143936308948}
2022-12-05 20:49:43,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:43,491 INFO:     Epoch: 0
2022-12-05 20:49:44,281 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6396816535429521, 'Total loss': 0.6396816535429521} | train loss {'Reaction outcome loss': 0.8090551367827824, 'Total loss': 0.8090551367827824}
2022-12-05 20:49:44,281 INFO:     Found new best model at epoch 0
2022-12-05 20:49:44,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:44,282 INFO:     Epoch: 1
2022-12-05 20:49:45,076 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5288889834826643, 'Total loss': 0.5288889834826643} | train loss {'Reaction outcome loss': 0.5505217119139068, 'Total loss': 0.5505217119139068}
2022-12-05 20:49:45,076 INFO:     Found new best model at epoch 1
2022-12-05 20:49:45,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:45,077 INFO:     Epoch: 2
2022-12-05 20:49:45,868 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48984615809538146, 'Total loss': 0.48984615809538146} | train loss {'Reaction outcome loss': 0.47306246270938795, 'Total loss': 0.47306246270938795}
2022-12-05 20:49:45,868 INFO:     Found new best model at epoch 2
2022-12-05 20:49:45,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:45,869 INFO:     Epoch: 3
2022-12-05 20:49:46,665 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4819183518940752, 'Total loss': 0.4819183518940752} | train loss {'Reaction outcome loss': 0.4329841958624976, 'Total loss': 0.4329841958624976}
2022-12-05 20:49:46,665 INFO:     Found new best model at epoch 3
2022-12-05 20:49:46,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:46,666 INFO:     Epoch: 4
2022-12-05 20:49:47,459 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4683690169318156, 'Total loss': 0.4683690169318156} | train loss {'Reaction outcome loss': 0.4032647098813738, 'Total loss': 0.4032647098813738}
2022-12-05 20:49:47,459 INFO:     Found new best model at epoch 4
2022-12-05 20:49:47,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:47,460 INFO:     Epoch: 5
2022-12-05 20:49:48,252 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45180983197959984, 'Total loss': 0.45180983197959984} | train loss {'Reaction outcome loss': 0.3805582009407939, 'Total loss': 0.3805582009407939}
2022-12-05 20:49:48,253 INFO:     Found new best model at epoch 5
2022-12-05 20:49:48,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:48,253 INFO:     Epoch: 6
2022-12-05 20:49:49,048 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4464868131009015, 'Total loss': 0.4464868131009015} | train loss {'Reaction outcome loss': 0.35974972941437544, 'Total loss': 0.35974972941437544}
2022-12-05 20:49:49,048 INFO:     Found new best model at epoch 6
2022-12-05 20:49:49,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:49,049 INFO:     Epoch: 7
2022-12-05 20:49:49,845 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4334387813102115, 'Total loss': 0.4334387813102115} | train loss {'Reaction outcome loss': 0.3447544218021996, 'Total loss': 0.3447544218021996}
2022-12-05 20:49:49,845 INFO:     Found new best model at epoch 7
2022-12-05 20:49:49,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:49,846 INFO:     Epoch: 8
2022-12-05 20:49:50,646 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4405757100744681, 'Total loss': 0.4405757100744681} | train loss {'Reaction outcome loss': 0.3254714516352634, 'Total loss': 0.3254714516352634}
2022-12-05 20:49:50,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:50,647 INFO:     Epoch: 9
2022-12-05 20:49:51,449 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43629870225082745, 'Total loss': 0.43629870225082745} | train loss {'Reaction outcome loss': 0.31262556585122125, 'Total loss': 0.31262556585122125}
2022-12-05 20:49:51,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:51,450 INFO:     Epoch: 10
2022-12-05 20:49:52,245 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41635443744334305, 'Total loss': 0.41635443744334305} | train loss {'Reaction outcome loss': 0.3010093463014583, 'Total loss': 0.3010093463014583}
2022-12-05 20:49:52,245 INFO:     Found new best model at epoch 10
2022-12-05 20:49:52,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:52,246 INFO:     Epoch: 11
2022-12-05 20:49:53,040 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42837297239086847, 'Total loss': 0.42837297239086847} | train loss {'Reaction outcome loss': 0.28655212378623535, 'Total loss': 0.28655212378623535}
2022-12-05 20:49:53,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:53,041 INFO:     Epoch: 12
2022-12-05 20:49:53,837 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41598244659094646, 'Total loss': 0.41598244659094646} | train loss {'Reaction outcome loss': 0.27788958084218357, 'Total loss': 0.27788958084218357}
2022-12-05 20:49:53,837 INFO:     Found new best model at epoch 12
2022-12-05 20:49:53,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:53,838 INFO:     Epoch: 13
2022-12-05 20:49:54,632 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4169326434758576, 'Total loss': 0.4169326434758576} | train loss {'Reaction outcome loss': 0.26799284627242964, 'Total loss': 0.26799284627242964}
2022-12-05 20:49:54,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:54,632 INFO:     Epoch: 14
2022-12-05 20:49:55,430 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40805701640519226, 'Total loss': 0.40805701640519226} | train loss {'Reaction outcome loss': 0.2553510768072946, 'Total loss': 0.2553510768072946}
2022-12-05 20:49:55,430 INFO:     Found new best model at epoch 14
2022-12-05 20:49:55,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:55,431 INFO:     Epoch: 15
2022-12-05 20:49:56,227 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42872078953818843, 'Total loss': 0.42872078953818843} | train loss {'Reaction outcome loss': 0.2508843131667497, 'Total loss': 0.2508843131667497}
2022-12-05 20:49:56,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:56,227 INFO:     Epoch: 16
2022-12-05 20:49:57,023 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41573561829599465, 'Total loss': 0.41573561829599465} | train loss {'Reaction outcome loss': 0.24084796583165927, 'Total loss': 0.24084796583165927}
2022-12-05 20:49:57,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:57,023 INFO:     Epoch: 17
2022-12-05 20:49:57,819 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3985360064967112, 'Total loss': 0.3985360064967112} | train loss {'Reaction outcome loss': 0.23286698722109503, 'Total loss': 0.23286698722109503}
2022-12-05 20:49:57,819 INFO:     Found new best model at epoch 17
2022-12-05 20:49:57,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:57,820 INFO:     Epoch: 18
2022-12-05 20:49:58,618 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4178345084867694, 'Total loss': 0.4178345084867694} | train loss {'Reaction outcome loss': 0.22510853204496054, 'Total loss': 0.22510853204496054}
2022-12-05 20:49:58,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:58,618 INFO:     Epoch: 19
2022-12-05 20:49:59,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4004489856941456, 'Total loss': 0.4004489856941456} | train loss {'Reaction outcome loss': 0.21866215739627273, 'Total loss': 0.21866215739627273}
2022-12-05 20:49:59,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:49:59,414 INFO:     Epoch: 20
2022-12-05 20:50:00,202 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41623259437355126, 'Total loss': 0.41623259437355126} | train loss {'Reaction outcome loss': 0.21642188522584585, 'Total loss': 0.21642188522584585}
2022-12-05 20:50:00,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:00,202 INFO:     Epoch: 21
2022-12-05 20:50:00,992 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4057467384263873, 'Total loss': 0.4057467384263873} | train loss {'Reaction outcome loss': 0.20951105623829122, 'Total loss': 0.20951105623829122}
2022-12-05 20:50:00,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:00,993 INFO:     Epoch: 22
2022-12-05 20:50:01,786 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4154828353202902, 'Total loss': 0.4154828353202902} | train loss {'Reaction outcome loss': 0.20124648911308268, 'Total loss': 0.20124648911308268}
2022-12-05 20:50:01,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:01,787 INFO:     Epoch: 23
2022-12-05 20:50:02,580 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4050773653117093, 'Total loss': 0.4050773653117093} | train loss {'Reaction outcome loss': 0.20076355040833657, 'Total loss': 0.20076355040833657}
2022-12-05 20:50:02,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:02,580 INFO:     Epoch: 24
2022-12-05 20:50:03,370 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4228506792675365, 'Total loss': 0.4228506792675365} | train loss {'Reaction outcome loss': 0.195864671940098, 'Total loss': 0.195864671940098}
2022-12-05 20:50:03,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:03,370 INFO:     Epoch: 25
2022-12-05 20:50:04,165 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42242066765373404, 'Total loss': 0.42242066765373404} | train loss {'Reaction outcome loss': 0.19302519468628632, 'Total loss': 0.19302519468628632}
2022-12-05 20:50:04,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:04,165 INFO:     Epoch: 26
2022-12-05 20:50:04,960 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42900675027207896, 'Total loss': 0.42900675027207896} | train loss {'Reaction outcome loss': 0.18859891923410552, 'Total loss': 0.18859891923410552}
2022-12-05 20:50:04,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:04,960 INFO:     Epoch: 27
2022-12-05 20:50:05,753 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4276618840680881, 'Total loss': 0.4276618840680881} | train loss {'Reaction outcome loss': 0.18080162367194283, 'Total loss': 0.18080162367194283}
2022-12-05 20:50:05,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:05,753 INFO:     Epoch: 28
2022-12-05 20:50:06,543 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42347779632969335, 'Total loss': 0.42347779632969335} | train loss {'Reaction outcome loss': 0.1791420494187243, 'Total loss': 0.1791420494187243}
2022-12-05 20:50:06,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:06,543 INFO:     Epoch: 29
2022-12-05 20:50:07,339 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4081563697281209, 'Total loss': 0.4081563697281209} | train loss {'Reaction outcome loss': 0.18097365094082696, 'Total loss': 0.18097365094082696}
2022-12-05 20:50:07,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:07,339 INFO:     Epoch: 30
2022-12-05 20:50:08,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44005976820533926, 'Total loss': 0.44005976820533926} | train loss {'Reaction outcome loss': 0.17336121352047337, 'Total loss': 0.17336121352047337}
2022-12-05 20:50:08,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:08,129 INFO:     Epoch: 31
2022-12-05 20:50:08,923 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.412164907394485, 'Total loss': 0.412164907394485} | train loss {'Reaction outcome loss': 0.171583695033071, 'Total loss': 0.171583695033071}
2022-12-05 20:50:08,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:08,923 INFO:     Epoch: 32
2022-12-05 20:50:09,715 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41889132356101816, 'Total loss': 0.41889132356101816} | train loss {'Reaction outcome loss': 0.1697118481811212, 'Total loss': 0.1697118481811212}
2022-12-05 20:50:09,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:09,715 INFO:     Epoch: 33
2022-12-05 20:50:10,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4264478835869919, 'Total loss': 0.4264478835869919} | train loss {'Reaction outcome loss': 0.16731835992968813, 'Total loss': 0.16731835992968813}
2022-12-05 20:50:10,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:10,509 INFO:     Epoch: 34
2022-12-05 20:50:11,308 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42154318534515123, 'Total loss': 0.42154318534515123} | train loss {'Reaction outcome loss': 0.1664727032868838, 'Total loss': 0.1664727032868838}
2022-12-05 20:50:11,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:11,308 INFO:     Epoch: 35
2022-12-05 20:50:12,097 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43002558787438, 'Total loss': 0.43002558787438} | train loss {'Reaction outcome loss': 0.16219264772169445, 'Total loss': 0.16219264772169445}
2022-12-05 20:50:12,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:12,098 INFO:     Epoch: 36
2022-12-05 20:50:12,889 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4340225315906785, 'Total loss': 0.4340225315906785} | train loss {'Reaction outcome loss': 0.15952907355160129, 'Total loss': 0.15952907355160129}
2022-12-05 20:50:12,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:12,889 INFO:     Epoch: 37
2022-12-05 20:50:13,682 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4140508897623725, 'Total loss': 0.4140508897623725} | train loss {'Reaction outcome loss': 0.1598370260578029, 'Total loss': 0.1598370260578029}
2022-12-05 20:50:13,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:13,683 INFO:     Epoch: 38
2022-12-05 20:50:14,474 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42159961231730203, 'Total loss': 0.42159961231730203} | train loss {'Reaction outcome loss': 0.15895204635298982, 'Total loss': 0.15895204635298982}
2022-12-05 20:50:14,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:14,475 INFO:     Epoch: 39
2022-12-05 20:50:15,259 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4120185107670047, 'Total loss': 0.4120185107670047} | train loss {'Reaction outcome loss': 0.1577939510345459, 'Total loss': 0.1577939510345459}
2022-12-05 20:50:15,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:15,259 INFO:     Epoch: 40
2022-12-05 20:50:16,041 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4277690200304443, 'Total loss': 0.4277690200304443} | train loss {'Reaction outcome loss': 0.15461212381416437, 'Total loss': 0.15461212381416437}
2022-12-05 20:50:16,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:16,042 INFO:     Epoch: 41
2022-12-05 20:50:16,827 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44237230184741994, 'Total loss': 0.44237230184741994} | train loss {'Reaction outcome loss': 0.15261438082219386, 'Total loss': 0.15261438082219386}
2022-12-05 20:50:16,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:16,827 INFO:     Epoch: 42
2022-12-05 20:50:17,611 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4307332662018863, 'Total loss': 0.4307332662018863} | train loss {'Reaction outcome loss': 0.15064869256195973, 'Total loss': 0.15064869256195973}
2022-12-05 20:50:17,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:17,611 INFO:     Epoch: 43
2022-12-05 20:50:18,397 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43949980288743973, 'Total loss': 0.43949980288743973} | train loss {'Reaction outcome loss': 0.14793112377579115, 'Total loss': 0.14793112377579115}
2022-12-05 20:50:18,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:18,397 INFO:     Epoch: 44
2022-12-05 20:50:19,184 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43282600365240465, 'Total loss': 0.43282600365240465} | train loss {'Reaction outcome loss': 0.14622718826392475, 'Total loss': 0.14622718826392475}
2022-12-05 20:50:19,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:19,184 INFO:     Epoch: 45
2022-12-05 20:50:19,975 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43905496097762475, 'Total loss': 0.43905496097762475} | train loss {'Reaction outcome loss': 0.14484213747236194, 'Total loss': 0.14484213747236194}
2022-12-05 20:50:19,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:19,976 INFO:     Epoch: 46
2022-12-05 20:50:20,764 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4301357878880067, 'Total loss': 0.4301357878880067} | train loss {'Reaction outcome loss': 0.14445155413479221, 'Total loss': 0.14445155413479221}
2022-12-05 20:50:20,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:20,764 INFO:     Epoch: 47
2022-12-05 20:50:21,549 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4233729354190556, 'Total loss': 0.4233729354190556} | train loss {'Reaction outcome loss': 0.14440413197996665, 'Total loss': 0.14440413197996665}
2022-12-05 20:50:21,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:21,550 INFO:     Epoch: 48
2022-12-05 20:50:22,336 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42498746378855273, 'Total loss': 0.42498746378855273} | train loss {'Reaction outcome loss': 0.1407687626474974, 'Total loss': 0.1407687626474974}
2022-12-05 20:50:22,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:22,336 INFO:     Epoch: 49
2022-12-05 20:50:23,119 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44892936978827824, 'Total loss': 0.44892936978827824} | train loss {'Reaction outcome loss': 0.14140930646384248, 'Total loss': 0.14140930646384248}
2022-12-05 20:50:23,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:23,119 INFO:     Epoch: 50
2022-12-05 20:50:23,902 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4233577841871672, 'Total loss': 0.4233577841871672} | train loss {'Reaction outcome loss': 0.14037673430783407, 'Total loss': 0.14037673430783407}
2022-12-05 20:50:23,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:23,903 INFO:     Epoch: 51
2022-12-05 20:50:24,686 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43279054862531746, 'Total loss': 0.43279054862531746} | train loss {'Reaction outcome loss': 0.1419626897010876, 'Total loss': 0.1419626897010876}
2022-12-05 20:50:24,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:24,686 INFO:     Epoch: 52
2022-12-05 20:50:25,474 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41704530277374113, 'Total loss': 0.41704530277374113} | train loss {'Reaction outcome loss': 0.13866774567535944, 'Total loss': 0.13866774567535944}
2022-12-05 20:50:25,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:25,475 INFO:     Epoch: 53
2022-12-05 20:50:26,258 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4381220532073216, 'Total loss': 0.4381220532073216} | train loss {'Reaction outcome loss': 0.13693034945778093, 'Total loss': 0.13693034945778093}
2022-12-05 20:50:26,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:26,258 INFO:     Epoch: 54
2022-12-05 20:50:27,043 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4392994398420507, 'Total loss': 0.4392994398420507} | train loss {'Reaction outcome loss': 0.13557592794603232, 'Total loss': 0.13557592794603232}
2022-12-05 20:50:27,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:27,044 INFO:     Epoch: 55
2022-12-05 20:50:27,829 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4279821559956128, 'Total loss': 0.4279821559956128} | train loss {'Reaction outcome loss': 0.13195656705267575, 'Total loss': 0.13195656705267575}
2022-12-05 20:50:27,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:27,829 INFO:     Epoch: 56
2022-12-05 20:50:28,613 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42825584519993176, 'Total loss': 0.42825584519993176} | train loss {'Reaction outcome loss': 0.1369907281380527, 'Total loss': 0.1369907281380527}
2022-12-05 20:50:28,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:28,613 INFO:     Epoch: 57
2022-12-05 20:50:29,399 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44101900268684735, 'Total loss': 0.44101900268684735} | train loss {'Reaction outcome loss': 0.13301091316555227, 'Total loss': 0.13301091316555227}
2022-12-05 20:50:29,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:29,399 INFO:     Epoch: 58
2022-12-05 20:50:30,190 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4406062447550622, 'Total loss': 0.4406062447550622} | train loss {'Reaction outcome loss': 0.13190288332347966, 'Total loss': 0.13190288332347966}
2022-12-05 20:50:30,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:30,191 INFO:     Epoch: 59
2022-12-05 20:50:30,977 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46094869619066065, 'Total loss': 0.46094869619066065} | train loss {'Reaction outcome loss': 0.13110938428197894, 'Total loss': 0.13110938428197894}
2022-12-05 20:50:30,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:30,978 INFO:     Epoch: 60
2022-12-05 20:50:31,764 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4380472702058879, 'Total loss': 0.4380472702058879} | train loss {'Reaction outcome loss': 0.13126376798870612, 'Total loss': 0.13126376798870612}
2022-12-05 20:50:31,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:31,764 INFO:     Epoch: 61
2022-12-05 20:50:32,553 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4331561560657891, 'Total loss': 0.4331561560657891} | train loss {'Reaction outcome loss': 0.13240986094258878, 'Total loss': 0.13240986094258878}
2022-12-05 20:50:32,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:32,553 INFO:     Epoch: 62
2022-12-05 20:50:33,341 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4287704407152804, 'Total loss': 0.4287704407152804} | train loss {'Reaction outcome loss': 0.12995076704846353, 'Total loss': 0.12995076704846353}
2022-12-05 20:50:33,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:33,342 INFO:     Epoch: 63
2022-12-05 20:50:34,126 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4280799800022082, 'Total loss': 0.4280799800022082} | train loss {'Reaction outcome loss': 0.13079484289093893, 'Total loss': 0.13079484289093893}
2022-12-05 20:50:34,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:34,126 INFO:     Epoch: 64
2022-12-05 20:50:34,909 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42769677606834605, 'Total loss': 0.42769677606834605} | train loss {'Reaction outcome loss': 0.1269331697032464, 'Total loss': 0.1269331697032464}
2022-12-05 20:50:34,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:34,910 INFO:     Epoch: 65
2022-12-05 20:50:35,693 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4321967387063937, 'Total loss': 0.4321967387063937} | train loss {'Reaction outcome loss': 0.1252756846764562, 'Total loss': 0.1252756846764562}
2022-12-05 20:50:35,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:35,694 INFO:     Epoch: 66
2022-12-05 20:50:36,482 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4311862996017391, 'Total loss': 0.4311862996017391} | train loss {'Reaction outcome loss': 0.12561569698154926, 'Total loss': 0.12561569698154926}
2022-12-05 20:50:36,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:36,482 INFO:     Epoch: 67
2022-12-05 20:50:37,270 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4264832285486839, 'Total loss': 0.4264832285486839} | train loss {'Reaction outcome loss': 0.12829163923707543, 'Total loss': 0.12829163923707543}
2022-12-05 20:50:37,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:37,270 INFO:     Epoch: 68
2022-12-05 20:50:38,055 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43368478542701766, 'Total loss': 0.43368478542701766} | train loss {'Reaction outcome loss': 0.12448238397055135, 'Total loss': 0.12448238397055135}
2022-12-05 20:50:38,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:38,056 INFO:     Epoch: 69
2022-12-05 20:50:38,840 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42895428726280277, 'Total loss': 0.42895428726280277} | train loss {'Reaction outcome loss': 0.12390898681644882, 'Total loss': 0.12390898681644882}
2022-12-05 20:50:38,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:38,841 INFO:     Epoch: 70
2022-12-05 20:50:39,624 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4405598794533448, 'Total loss': 0.4405598794533448} | train loss {'Reaction outcome loss': 0.12428547339894029, 'Total loss': 0.12428547339894029}
2022-12-05 20:50:39,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:39,625 INFO:     Epoch: 71
2022-12-05 20:50:40,411 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4469134374098344, 'Total loss': 0.4469134374098344} | train loss {'Reaction outcome loss': 0.12563825361430644, 'Total loss': 0.12563825361430644}
2022-12-05 20:50:40,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:40,412 INFO:     Epoch: 72
2022-12-05 20:50:41,198 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4390236669304696, 'Total loss': 0.4390236669304696} | train loss {'Reaction outcome loss': 0.12220368879486103, 'Total loss': 0.12220368879486103}
2022-12-05 20:50:41,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:41,198 INFO:     Epoch: 73
2022-12-05 20:50:41,985 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4302001917226748, 'Total loss': 0.4302001917226748} | train loss {'Reaction outcome loss': 0.12156690083140013, 'Total loss': 0.12156690083140013}
2022-12-05 20:50:41,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:41,985 INFO:     Epoch: 74
2022-12-05 20:50:42,775 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4308023307133805, 'Total loss': 0.4308023307133805} | train loss {'Reaction outcome loss': 0.12465690237336925, 'Total loss': 0.12465690237336925}
2022-12-05 20:50:42,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:42,776 INFO:     Epoch: 75
2022-12-05 20:50:43,564 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43997262147339905, 'Total loss': 0.43997262147339905} | train loss {'Reaction outcome loss': 0.12636964156159333, 'Total loss': 0.12636964156159333}
2022-12-05 20:50:43,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:43,564 INFO:     Epoch: 76
2022-12-05 20:50:44,349 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43691018647090957, 'Total loss': 0.43691018647090957} | train loss {'Reaction outcome loss': 0.12035798087183919, 'Total loss': 0.12035798087183919}
2022-12-05 20:50:44,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:44,349 INFO:     Epoch: 77
2022-12-05 20:50:45,135 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41643906139176, 'Total loss': 0.41643906139176} | train loss {'Reaction outcome loss': 0.11964396374414162, 'Total loss': 0.11964396374414162}
2022-12-05 20:50:45,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:45,135 INFO:     Epoch: 78
2022-12-05 20:50:45,921 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4552140691402284, 'Total loss': 0.4552140691402284} | train loss {'Reaction outcome loss': 0.12174515738247, 'Total loss': 0.12174515738247}
2022-12-05 20:50:45,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:45,921 INFO:     Epoch: 79
2022-12-05 20:50:46,711 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.431387394328009, 'Total loss': 0.431387394328009} | train loss {'Reaction outcome loss': 0.11898074529076717, 'Total loss': 0.11898074529076717}
2022-12-05 20:50:46,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:46,711 INFO:     Epoch: 80
2022-12-05 20:50:47,498 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4587289399721406, 'Total loss': 0.4587289399721406} | train loss {'Reaction outcome loss': 0.11920789064725443, 'Total loss': 0.11920789064725443}
2022-12-05 20:50:47,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:47,498 INFO:     Epoch: 81
2022-12-05 20:50:48,283 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44186443818563764, 'Total loss': 0.44186443818563764} | train loss {'Reaction outcome loss': 0.11932847719943646, 'Total loss': 0.11932847719943646}
2022-12-05 20:50:48,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:48,283 INFO:     Epoch: 82
2022-12-05 20:50:49,068 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4197717769579454, 'Total loss': 0.4197717769579454} | train loss {'Reaction outcome loss': 0.1183773556572138, 'Total loss': 0.1183773556572138}
2022-12-05 20:50:49,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:49,068 INFO:     Epoch: 83
2022-12-05 20:50:49,858 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41588924526744947, 'Total loss': 0.41588924526744947} | train loss {'Reaction outcome loss': 0.11798836461895583, 'Total loss': 0.11798836461895583}
2022-12-05 20:50:49,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:49,859 INFO:     Epoch: 84
2022-12-05 20:50:50,650 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41821711002425715, 'Total loss': 0.41821711002425715} | train loss {'Reaction outcome loss': 0.11756736485059469, 'Total loss': 0.11756736485059469}
2022-12-05 20:50:50,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:50,650 INFO:     Epoch: 85
2022-12-05 20:50:51,436 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42791184986179526, 'Total loss': 0.42791184986179526} | train loss {'Reaction outcome loss': 0.11480209761280186, 'Total loss': 0.11480209761280186}
2022-12-05 20:50:51,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:51,436 INFO:     Epoch: 86
2022-12-05 20:50:52,222 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4311768053607507, 'Total loss': 0.4311768053607507} | train loss {'Reaction outcome loss': 0.11762943036702214, 'Total loss': 0.11762943036702214}
2022-12-05 20:50:52,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:52,222 INFO:     Epoch: 87
2022-12-05 20:50:53,008 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4315178851512345, 'Total loss': 0.4315178851512345} | train loss {'Reaction outcome loss': 0.11812178429824358, 'Total loss': 0.11812178429824358}
2022-12-05 20:50:53,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:53,008 INFO:     Epoch: 88
2022-12-05 20:50:53,795 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44392563571984117, 'Total loss': 0.44392563571984117} | train loss {'Reaction outcome loss': 0.11755452302037453, 'Total loss': 0.11755452302037453}
2022-12-05 20:50:53,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:53,795 INFO:     Epoch: 89
2022-12-05 20:50:54,584 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4328098578209227, 'Total loss': 0.4328098578209227} | train loss {'Reaction outcome loss': 0.11562437027388689, 'Total loss': 0.11562437027388689}
2022-12-05 20:50:54,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:54,585 INFO:     Epoch: 90
2022-12-05 20:50:55,372 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42452763647518377, 'Total loss': 0.42452763647518377} | train loss {'Reaction outcome loss': 0.11386746571836423, 'Total loss': 0.11386746571836423}
2022-12-05 20:50:55,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:55,372 INFO:     Epoch: 91
2022-12-05 20:50:56,158 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41479593862525443, 'Total loss': 0.41479593862525443} | train loss {'Reaction outcome loss': 0.11260947509079564, 'Total loss': 0.11260947509079564}
2022-12-05 20:50:56,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:56,159 INFO:     Epoch: 92
2022-12-05 20:50:56,949 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4403108609231739, 'Total loss': 0.4403108609231739} | train loss {'Reaction outcome loss': 0.11440083895981008, 'Total loss': 0.11440083895981008}
2022-12-05 20:50:56,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:56,950 INFO:     Epoch: 93
2022-12-05 20:50:57,741 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4399924940344962, 'Total loss': 0.4399924940344962} | train loss {'Reaction outcome loss': 0.11498790359010502, 'Total loss': 0.11498790359010502}
2022-12-05 20:50:57,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:57,741 INFO:     Epoch: 94
2022-12-05 20:50:58,532 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43060606125403533, 'Total loss': 0.43060606125403533} | train loss {'Reaction outcome loss': 0.11008488353417845, 'Total loss': 0.11008488353417845}
2022-12-05 20:50:58,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:58,532 INFO:     Epoch: 95
2022-12-05 20:50:59,324 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42119844342497265, 'Total loss': 0.42119844342497265} | train loss {'Reaction outcome loss': 0.1132305565062074, 'Total loss': 0.1132305565062074}
2022-12-05 20:50:59,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:50:59,324 INFO:     Epoch: 96
2022-12-05 20:51:00,120 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4358411319553852, 'Total loss': 0.4358411319553852} | train loss {'Reaction outcome loss': 0.1164562949454602, 'Total loss': 0.1164562949454602}
2022-12-05 20:51:00,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:00,120 INFO:     Epoch: 97
2022-12-05 20:51:00,909 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41986493834040384, 'Total loss': 0.41986493834040384} | train loss {'Reaction outcome loss': 0.11497903680238797, 'Total loss': 0.11497903680238797}
2022-12-05 20:51:00,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:00,910 INFO:     Epoch: 98
2022-12-05 20:51:01,697 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44458125260743225, 'Total loss': 0.44458125260743225} | train loss {'Reaction outcome loss': 0.1125309822643746, 'Total loss': 0.1125309822643746}
2022-12-05 20:51:01,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:01,697 INFO:     Epoch: 99
2022-12-05 20:51:02,488 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43031625754453917, 'Total loss': 0.43031625754453917} | train loss {'Reaction outcome loss': 0.11091585826052695, 'Total loss': 0.11091585826052695}
2022-12-05 20:51:02,489 INFO:     Best model found after epoch 18 of 100.
2022-12-05 20:51:02,489 INFO:   Done with stage: TRAINING
2022-12-05 20:51:02,489 INFO:   Starting stage: EVALUATION
2022-12-05 20:51:02,619 INFO:   Done with stage: EVALUATION
2022-12-05 20:51:02,620 INFO:   Leaving out SEQ value Fold_8
2022-12-05 20:51:02,632 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 20:51:02,632 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:51:03,270 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:51:03,271 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:51:03,340 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:51:03,340 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:51:03,340 INFO:     No hyperparam tuning for this model
2022-12-05 20:51:03,341 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:51:03,341 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:51:03,341 INFO:     None feature selector for col prot
2022-12-05 20:51:03,341 INFO:     None feature selector for col prot
2022-12-05 20:51:03,342 INFO:     None feature selector for col prot
2022-12-05 20:51:03,342 INFO:     None feature selector for col chem
2022-12-05 20:51:03,342 INFO:     None feature selector for col chem
2022-12-05 20:51:03,342 INFO:     None feature selector for col chem
2022-12-05 20:51:03,342 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:51:03,342 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:51:03,344 INFO:     Number of params in model 215821
2022-12-05 20:51:03,347 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:51:03,347 INFO:   Starting stage: TRAINING
2022-12-05 20:51:03,408 INFO:     Val loss before train {'Reaction outcome loss': 0.9767938229170713, 'Total loss': 0.9767938229170713}
2022-12-05 20:51:03,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:03,408 INFO:     Epoch: 0
2022-12-05 20:51:04,203 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6303972730582411, 'Total loss': 0.6303972730582411} | train loss {'Reaction outcome loss': 0.8100143047350068, 'Total loss': 0.8100143047350068}
2022-12-05 20:51:04,203 INFO:     Found new best model at epoch 0
2022-12-05 20:51:04,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:04,204 INFO:     Epoch: 1
2022-12-05 20:51:04,999 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.536228724162687, 'Total loss': 0.536228724162687} | train loss {'Reaction outcome loss': 0.5539500542105206, 'Total loss': 0.5539500542105206}
2022-12-05 20:51:04,999 INFO:     Found new best model at epoch 1
2022-12-05 20:51:05,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:05,000 INFO:     Epoch: 2
2022-12-05 20:51:05,804 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4974099255420945, 'Total loss': 0.4974099255420945} | train loss {'Reaction outcome loss': 0.47989581224899136, 'Total loss': 0.47989581224899136}
2022-12-05 20:51:05,804 INFO:     Found new best model at epoch 2
2022-12-05 20:51:05,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:05,805 INFO:     Epoch: 3
2022-12-05 20:51:06,602 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4853475361385129, 'Total loss': 0.4853475361385129} | train loss {'Reaction outcome loss': 0.43398814648389816, 'Total loss': 0.43398814648389816}
2022-12-05 20:51:06,602 INFO:     Found new best model at epoch 3
2022-12-05 20:51:06,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:06,603 INFO:     Epoch: 4
2022-12-05 20:51:07,403 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4548389454456893, 'Total loss': 0.4548389454456893} | train loss {'Reaction outcome loss': 0.40296502023815145, 'Total loss': 0.40296502023815145}
2022-12-05 20:51:07,403 INFO:     Found new best model at epoch 4
2022-12-05 20:51:07,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:07,404 INFO:     Epoch: 5
2022-12-05 20:51:08,200 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4526438692753965, 'Total loss': 0.4526438692753965} | train loss {'Reaction outcome loss': 0.3770592368898853, 'Total loss': 0.3770592368898853}
2022-12-05 20:51:08,201 INFO:     Found new best model at epoch 5
2022-12-05 20:51:08,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:08,201 INFO:     Epoch: 6
2022-12-05 20:51:09,000 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43587567657232285, 'Total loss': 0.43587567657232285} | train loss {'Reaction outcome loss': 0.3575588411561424, 'Total loss': 0.3575588411561424}
2022-12-05 20:51:09,000 INFO:     Found new best model at epoch 6
2022-12-05 20:51:09,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:09,001 INFO:     Epoch: 7
2022-12-05 20:51:09,803 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4327556003223766, 'Total loss': 0.4327556003223766} | train loss {'Reaction outcome loss': 0.34163532418108755, 'Total loss': 0.34163532418108755}
2022-12-05 20:51:09,803 INFO:     Found new best model at epoch 7
2022-12-05 20:51:09,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:09,804 INFO:     Epoch: 8
2022-12-05 20:51:10,607 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4325985580005429, 'Total loss': 0.4325985580005429} | train loss {'Reaction outcome loss': 0.32332294716710047, 'Total loss': 0.32332294716710047}
2022-12-05 20:51:10,607 INFO:     Found new best model at epoch 8
2022-12-05 20:51:10,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:10,608 INFO:     Epoch: 9
2022-12-05 20:51:11,412 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41380172730846837, 'Total loss': 0.41380172730846837} | train loss {'Reaction outcome loss': 0.3087365571109037, 'Total loss': 0.3087365571109037}
2022-12-05 20:51:11,412 INFO:     Found new best model at epoch 9
2022-12-05 20:51:11,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:11,413 INFO:     Epoch: 10
2022-12-05 20:51:12,215 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42381188239563594, 'Total loss': 0.42381188239563594} | train loss {'Reaction outcome loss': 0.29696455229854873, 'Total loss': 0.29696455229854873}
2022-12-05 20:51:12,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:12,215 INFO:     Epoch: 11
2022-12-05 20:51:13,016 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42858359386975114, 'Total loss': 0.42858359386975114} | train loss {'Reaction outcome loss': 0.28749343650715964, 'Total loss': 0.28749343650715964}
2022-12-05 20:51:13,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:13,017 INFO:     Epoch: 12
2022-12-05 20:51:13,814 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4167706109583378, 'Total loss': 0.4167706109583378} | train loss {'Reaction outcome loss': 0.2723851874095177, 'Total loss': 0.2723851874095177}
2022-12-05 20:51:13,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:13,814 INFO:     Epoch: 13
2022-12-05 20:51:14,615 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4267235625196587, 'Total loss': 0.4267235625196587} | train loss {'Reaction outcome loss': 0.2620070821215068, 'Total loss': 0.2620070821215068}
2022-12-05 20:51:14,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:14,615 INFO:     Epoch: 14
2022-12-05 20:51:15,415 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42801419577815314, 'Total loss': 0.42801419577815314} | train loss {'Reaction outcome loss': 0.25399602973653423, 'Total loss': 0.25399602973653423}
2022-12-05 20:51:15,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:15,415 INFO:     Epoch: 15
2022-12-05 20:51:16,216 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4162808152085001, 'Total loss': 0.4162808152085001} | train loss {'Reaction outcome loss': 0.2468863265108197, 'Total loss': 0.2468863265108197}
2022-12-05 20:51:16,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:16,216 INFO:     Epoch: 16
2022-12-05 20:51:17,018 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4352506013079123, 'Total loss': 0.4352506013079123} | train loss {'Reaction outcome loss': 0.23877722536393953, 'Total loss': 0.23877722536393953}
2022-12-05 20:51:17,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:17,018 INFO:     Epoch: 17
2022-12-05 20:51:17,818 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.423765072429722, 'Total loss': 0.423765072429722} | train loss {'Reaction outcome loss': 0.2312153753103508, 'Total loss': 0.2312153753103508}
2022-12-05 20:51:17,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:17,818 INFO:     Epoch: 18
2022-12-05 20:51:18,618 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.439147852699865, 'Total loss': 0.439147852699865} | train loss {'Reaction outcome loss': 0.22298145489466767, 'Total loss': 0.22298145489466767}
2022-12-05 20:51:18,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:18,618 INFO:     Epoch: 19
2022-12-05 20:51:19,421 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4269387000663714, 'Total loss': 0.4269387000663714} | train loss {'Reaction outcome loss': 0.22183164013850112, 'Total loss': 0.22183164013850112}
2022-12-05 20:51:19,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:19,421 INFO:     Epoch: 20
2022-12-05 20:51:20,224 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4283209531144662, 'Total loss': 0.4283209531144662} | train loss {'Reaction outcome loss': 0.21372299083328294, 'Total loss': 0.21372299083328294}
2022-12-05 20:51:20,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:20,224 INFO:     Epoch: 21
2022-12-05 20:51:21,026 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45080377466299315, 'Total loss': 0.45080377466299315} | train loss {'Reaction outcome loss': 0.20982164221124783, 'Total loss': 0.20982164221124783}
2022-12-05 20:51:21,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:21,026 INFO:     Epoch: 22
2022-12-05 20:51:21,829 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44505963525311515, 'Total loss': 0.44505963525311515} | train loss {'Reaction outcome loss': 0.20408791323162376, 'Total loss': 0.20408791323162376}
2022-12-05 20:51:21,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:21,829 INFO:     Epoch: 23
2022-12-05 20:51:22,627 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43804711814631114, 'Total loss': 0.43804711814631114} | train loss {'Reaction outcome loss': 0.2014747548457836, 'Total loss': 0.2014747548457836}
2022-12-05 20:51:22,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:22,627 INFO:     Epoch: 24
2022-12-05 20:51:23,423 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43690805103291164, 'Total loss': 0.43690805103291164} | train loss {'Reaction outcome loss': 0.19414229420644621, 'Total loss': 0.19414229420644621}
2022-12-05 20:51:23,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:23,423 INFO:     Epoch: 25
2022-12-05 20:51:24,216 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44753647019917314, 'Total loss': 0.44753647019917314} | train loss {'Reaction outcome loss': 0.19180226345516502, 'Total loss': 0.19180226345516502}
2022-12-05 20:51:24,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:24,216 INFO:     Epoch: 26
2022-12-05 20:51:25,009 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45754842494021764, 'Total loss': 0.45754842494021764} | train loss {'Reaction outcome loss': 0.18845217635915165, 'Total loss': 0.18845217635915165}
2022-12-05 20:51:25,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:25,009 INFO:     Epoch: 27
2022-12-05 20:51:25,803 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43699397620829666, 'Total loss': 0.43699397620829666} | train loss {'Reaction outcome loss': 0.1862602082847227, 'Total loss': 0.1862602082847227}
2022-12-05 20:51:25,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:25,803 INFO:     Epoch: 28
2022-12-05 20:51:26,603 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45412721230902453, 'Total loss': 0.45412721230902453} | train loss {'Reaction outcome loss': 0.18217256614157268, 'Total loss': 0.18217256614157268}
2022-12-05 20:51:26,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:26,604 INFO:     Epoch: 29
2022-12-05 20:51:27,398 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44364133409478446, 'Total loss': 0.44364133409478446} | train loss {'Reaction outcome loss': 0.18028225820331323, 'Total loss': 0.18028225820331323}
2022-12-05 20:51:27,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:27,398 INFO:     Epoch: 30
2022-12-05 20:51:28,191 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4413849376142025, 'Total loss': 0.4413849376142025} | train loss {'Reaction outcome loss': 0.17658909239746148, 'Total loss': 0.17658909239746148}
2022-12-05 20:51:28,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:28,192 INFO:     Epoch: 31
2022-12-05 20:51:28,984 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4502965916286815, 'Total loss': 0.4502965916286815} | train loss {'Reaction outcome loss': 0.176724313728271, 'Total loss': 0.176724313728271}
2022-12-05 20:51:28,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:28,985 INFO:     Epoch: 32
2022-12-05 20:51:29,778 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44618608125231485, 'Total loss': 0.44618608125231485} | train loss {'Reaction outcome loss': 0.17017136808604963, 'Total loss': 0.17017136808604963}
2022-12-05 20:51:29,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:29,778 INFO:     Epoch: 33
2022-12-05 20:51:30,575 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45715011046691373, 'Total loss': 0.45715011046691373} | train loss {'Reaction outcome loss': 0.16785631287888053, 'Total loss': 0.16785631287888053}
2022-12-05 20:51:30,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:30,576 INFO:     Epoch: 34
2022-12-05 20:51:31,374 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46102705564011226, 'Total loss': 0.46102705564011226} | train loss {'Reaction outcome loss': 0.16698695984368603, 'Total loss': 0.16698695984368603}
2022-12-05 20:51:31,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:31,374 INFO:     Epoch: 35
2022-12-05 20:51:32,168 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4600999665192582, 'Total loss': 0.4600999665192582} | train loss {'Reaction outcome loss': 0.16542491364863612, 'Total loss': 0.16542491364863612}
2022-12-05 20:51:32,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:32,168 INFO:     Epoch: 36
2022-12-05 20:51:32,967 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4491636363620108, 'Total loss': 0.4491636363620108} | train loss {'Reaction outcome loss': 0.1648810118466856, 'Total loss': 0.1648810118466856}
2022-12-05 20:51:32,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:32,968 INFO:     Epoch: 37
2022-12-05 20:51:33,761 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4540577581660314, 'Total loss': 0.4540577581660314} | train loss {'Reaction outcome loss': 0.16182173324388363, 'Total loss': 0.16182173324388363}
2022-12-05 20:51:33,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:33,761 INFO:     Epoch: 38
2022-12-05 20:51:34,556 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46827304938977415, 'Total loss': 0.46827304938977415} | train loss {'Reaction outcome loss': 0.15737635408332873, 'Total loss': 0.15737635408332873}
2022-12-05 20:51:34,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:34,556 INFO:     Epoch: 39
2022-12-05 20:51:35,350 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46546281603249634, 'Total loss': 0.46546281603249634} | train loss {'Reaction outcome loss': 0.15595148801202735, 'Total loss': 0.15595148801202735}
2022-12-05 20:51:35,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:35,350 INFO:     Epoch: 40
2022-12-05 20:51:36,145 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4584597223861651, 'Total loss': 0.4584597223861651} | train loss {'Reaction outcome loss': 0.15642255454158951, 'Total loss': 0.15642255454158951}
2022-12-05 20:51:36,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:36,145 INFO:     Epoch: 41
2022-12-05 20:51:36,943 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4578675651414828, 'Total loss': 0.4578675651414828} | train loss {'Reaction outcome loss': 0.15532729212915705, 'Total loss': 0.15532729212915705}
2022-12-05 20:51:36,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:36,943 INFO:     Epoch: 42
2022-12-05 20:51:37,742 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44011273268948903, 'Total loss': 0.44011273268948903} | train loss {'Reaction outcome loss': 0.15240576034862427, 'Total loss': 0.15240576034862427}
2022-12-05 20:51:37,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:37,742 INFO:     Epoch: 43
2022-12-05 20:51:38,537 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4672206017104062, 'Total loss': 0.4672206017104062} | train loss {'Reaction outcome loss': 0.15506885968328965, 'Total loss': 0.15506885968328965}
2022-12-05 20:51:38,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:38,538 INFO:     Epoch: 44
2022-12-05 20:51:39,333 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46691012755036354, 'Total loss': 0.46691012755036354} | train loss {'Reaction outcome loss': 0.14945694065142062, 'Total loss': 0.14945694065142062}
2022-12-05 20:51:39,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:39,333 INFO:     Epoch: 45
2022-12-05 20:51:40,132 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44236047396605666, 'Total loss': 0.44236047396605666} | train loss {'Reaction outcome loss': 0.14955233618046246, 'Total loss': 0.14955233618046246}
2022-12-05 20:51:40,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:40,132 INFO:     Epoch: 46
2022-12-05 20:51:40,937 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45862443338740955, 'Total loss': 0.45862443338740955} | train loss {'Reaction outcome loss': 0.14690602085583152, 'Total loss': 0.14690602085583152}
2022-12-05 20:51:40,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:40,937 INFO:     Epoch: 47
2022-12-05 20:51:41,733 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45419701832261955, 'Total loss': 0.45419701832261955} | train loss {'Reaction outcome loss': 0.1467956228917765, 'Total loss': 0.1467956228917765}
2022-12-05 20:51:41,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:41,734 INFO:     Epoch: 48
2022-12-05 20:51:42,533 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46262269941243256, 'Total loss': 0.46262269941243256} | train loss {'Reaction outcome loss': 0.14682491413588006, 'Total loss': 0.14682491413588006}
2022-12-05 20:51:42,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:42,533 INFO:     Epoch: 49
2022-12-05 20:51:43,329 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46072435853156174, 'Total loss': 0.46072435853156174} | train loss {'Reaction outcome loss': 0.14440091557410215, 'Total loss': 0.14440091557410215}
2022-12-05 20:51:43,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:43,330 INFO:     Epoch: 50
2022-12-05 20:51:44,128 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45790656994689594, 'Total loss': 0.45790656994689594} | train loss {'Reaction outcome loss': 0.14228295895361132, 'Total loss': 0.14228295895361132}
2022-12-05 20:51:44,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:44,128 INFO:     Epoch: 51
2022-12-05 20:51:44,922 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4596178155731071, 'Total loss': 0.4596178155731071} | train loss {'Reaction outcome loss': 0.14508819528630063, 'Total loss': 0.14508819528630063}
2022-12-05 20:51:44,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:44,922 INFO:     Epoch: 52
2022-12-05 20:51:45,717 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4632204913280227, 'Total loss': 0.4632204913280227} | train loss {'Reaction outcome loss': 0.13982018492665263, 'Total loss': 0.13982018492665263}
2022-12-05 20:51:45,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:45,718 INFO:     Epoch: 53
2022-12-05 20:51:46,516 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4488423194058917, 'Total loss': 0.4488423194058917} | train loss {'Reaction outcome loss': 0.1412841709285614, 'Total loss': 0.1412841709285614}
2022-12-05 20:51:46,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:46,516 INFO:     Epoch: 54
2022-12-05 20:51:47,310 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43866975571621547, 'Total loss': 0.43866975571621547} | train loss {'Reaction outcome loss': 0.14092490200944727, 'Total loss': 0.14092490200944727}
2022-12-05 20:51:47,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:47,310 INFO:     Epoch: 55
2022-12-05 20:51:48,104 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4664672308347442, 'Total loss': 0.4664672308347442} | train loss {'Reaction outcome loss': 0.13727189973747778, 'Total loss': 0.13727189973747778}
2022-12-05 20:51:48,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:48,104 INFO:     Epoch: 56
2022-12-05 20:51:48,900 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44998025318438356, 'Total loss': 0.44998025318438356} | train loss {'Reaction outcome loss': 0.13750991747984964, 'Total loss': 0.13750991747984964}
2022-12-05 20:51:48,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:48,901 INFO:     Epoch: 57
2022-12-05 20:51:49,693 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4775633933869275, 'Total loss': 0.4775633933869275} | train loss {'Reaction outcome loss': 0.1379380691984308, 'Total loss': 0.1379380691984308}
2022-12-05 20:51:49,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:49,693 INFO:     Epoch: 58
2022-12-05 20:51:50,489 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44979326325384056, 'Total loss': 0.44979326325384056} | train loss {'Reaction outcome loss': 0.1389971341404523, 'Total loss': 0.1389971341404523}
2022-12-05 20:51:50,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:50,489 INFO:     Epoch: 59
2022-12-05 20:51:51,289 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44917923686179245, 'Total loss': 0.44917923686179245} | train loss {'Reaction outcome loss': 0.1363560648807775, 'Total loss': 0.1363560648807775}
2022-12-05 20:51:51,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:51,289 INFO:     Epoch: 60
2022-12-05 20:51:52,087 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4498127560046586, 'Total loss': 0.4498127560046586} | train loss {'Reaction outcome loss': 0.13546347048043483, 'Total loss': 0.13546347048043483}
2022-12-05 20:51:52,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:52,087 INFO:     Epoch: 61
2022-12-05 20:51:52,881 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4721954803575169, 'Total loss': 0.4721954803575169} | train loss {'Reaction outcome loss': 0.13360999737896265, 'Total loss': 0.13360999737896265}
2022-12-05 20:51:52,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:52,881 INFO:     Epoch: 62
2022-12-05 20:51:53,675 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4612238625572486, 'Total loss': 0.4612238625572486} | train loss {'Reaction outcome loss': 0.13481730343248213, 'Total loss': 0.13481730343248213}
2022-12-05 20:51:53,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:53,675 INFO:     Epoch: 63
2022-12-05 20:51:54,476 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4683486312966455, 'Total loss': 0.4683486312966455} | train loss {'Reaction outcome loss': 0.13371017946290872, 'Total loss': 0.13371017946290872}
2022-12-05 20:51:54,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:54,476 INFO:     Epoch: 64
2022-12-05 20:51:55,273 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4555166604166681, 'Total loss': 0.4555166604166681} | train loss {'Reaction outcome loss': 0.13292811656626122, 'Total loss': 0.13292811656626122}
2022-12-05 20:51:55,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:55,273 INFO:     Epoch: 65
2022-12-05 20:51:56,067 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4627142687412826, 'Total loss': 0.4627142687412826} | train loss {'Reaction outcome loss': 0.132560592666719, 'Total loss': 0.132560592666719}
2022-12-05 20:51:56,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:56,067 INFO:     Epoch: 66
2022-12-05 20:51:56,862 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4496455490589142, 'Total loss': 0.4496455490589142} | train loss {'Reaction outcome loss': 0.13372667021899215, 'Total loss': 0.13372667021899215}
2022-12-05 20:51:56,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:56,863 INFO:     Epoch: 67
2022-12-05 20:51:57,654 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47036087343638594, 'Total loss': 0.47036087343638594} | train loss {'Reaction outcome loss': 0.13065820680968765, 'Total loss': 0.13065820680968765}
2022-12-05 20:51:57,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:57,655 INFO:     Epoch: 68
2022-12-05 20:51:58,444 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4523389949039979, 'Total loss': 0.4523389949039979} | train loss {'Reaction outcome loss': 0.13001631192051835, 'Total loss': 0.13001631192051835}
2022-12-05 20:51:58,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:58,444 INFO:     Epoch: 69
2022-12-05 20:51:59,238 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44891717759045685, 'Total loss': 0.44891717759045685} | train loss {'Reaction outcome loss': 0.13210709853428265, 'Total loss': 0.13210709853428265}
2022-12-05 20:51:59,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:51:59,238 INFO:     Epoch: 70
2022-12-05 20:52:00,028 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45069694315845316, 'Total loss': 0.45069694315845316} | train loss {'Reaction outcome loss': 0.12958484563616016, 'Total loss': 0.12958484563616016}
2022-12-05 20:52:00,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:00,028 INFO:     Epoch: 71
2022-12-05 20:52:00,818 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45599789324809203, 'Total loss': 0.45599789324809203} | train loss {'Reaction outcome loss': 0.12654861387225888, 'Total loss': 0.12654861387225888}
2022-12-05 20:52:00,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:00,818 INFO:     Epoch: 72
2022-12-05 20:52:01,610 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45737513120878825, 'Total loss': 0.45737513120878825} | train loss {'Reaction outcome loss': 0.12936430245322444, 'Total loss': 0.12936430245322444}
2022-12-05 20:52:01,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:01,610 INFO:     Epoch: 73
2022-12-05 20:52:02,403 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4467598155818202, 'Total loss': 0.4467598155818202} | train loss {'Reaction outcome loss': 0.1281257662922144, 'Total loss': 0.1281257662922144}
2022-12-05 20:52:02,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:02,403 INFO:     Epoch: 74
2022-12-05 20:52:03,195 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.446889304979281, 'Total loss': 0.446889304979281} | train loss {'Reaction outcome loss': 0.12816248190093546, 'Total loss': 0.12816248190093546}
2022-12-05 20:52:03,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:03,195 INFO:     Epoch: 75
2022-12-05 20:52:03,984 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4542933362112804, 'Total loss': 0.4542933362112804} | train loss {'Reaction outcome loss': 0.1262102318108983, 'Total loss': 0.1262102318108983}
2022-12-05 20:52:03,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:03,985 INFO:     Epoch: 76
2022-12-05 20:52:04,778 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4632517051967708, 'Total loss': 0.4632517051967708} | train loss {'Reaction outcome loss': 0.12572922024335112, 'Total loss': 0.12572922024335112}
2022-12-05 20:52:04,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:04,778 INFO:     Epoch: 77
2022-12-05 20:52:05,576 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44966323199597275, 'Total loss': 0.44966323199597275} | train loss {'Reaction outcome loss': 0.12368507214611577, 'Total loss': 0.12368507214611577}
2022-12-05 20:52:05,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:05,576 INFO:     Epoch: 78
2022-12-05 20:52:06,372 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44786107675595715, 'Total loss': 0.44786107675595715} | train loss {'Reaction outcome loss': 0.12386622742539452, 'Total loss': 0.12386622742539452}
2022-12-05 20:52:06,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:06,372 INFO:     Epoch: 79
2022-12-05 20:52:07,168 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46030173924836243, 'Total loss': 0.46030173924836243} | train loss {'Reaction outcome loss': 0.125162270520964, 'Total loss': 0.125162270520964}
2022-12-05 20:52:07,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:07,168 INFO:     Epoch: 80
2022-12-05 20:52:07,958 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4661149446937171, 'Total loss': 0.4661149446937171} | train loss {'Reaction outcome loss': 0.12423656649902583, 'Total loss': 0.12423656649902583}
2022-12-05 20:52:07,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:07,959 INFO:     Epoch: 81
2022-12-05 20:52:08,754 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4612834094600244, 'Total loss': 0.4612834094600244} | train loss {'Reaction outcome loss': 0.12638553329593233, 'Total loss': 0.12638553329593233}
2022-12-05 20:52:08,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:08,754 INFO:     Epoch: 82
2022-12-05 20:52:09,546 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45036664401943033, 'Total loss': 0.45036664401943033} | train loss {'Reaction outcome loss': 0.12496891102918814, 'Total loss': 0.12496891102918814}
2022-12-05 20:52:09,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:09,546 INFO:     Epoch: 83
2022-12-05 20:52:10,343 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44628758305175736, 'Total loss': 0.44628758305175736} | train loss {'Reaction outcome loss': 0.12121369318300558, 'Total loss': 0.12121369318300558}
2022-12-05 20:52:10,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:10,344 INFO:     Epoch: 84
2022-12-05 20:52:11,140 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45471943440762436, 'Total loss': 0.45471943440762436} | train loss {'Reaction outcome loss': 0.12312918965659675, 'Total loss': 0.12312918965659675}
2022-12-05 20:52:11,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:11,141 INFO:     Epoch: 85
2022-12-05 20:52:11,936 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4631641005927866, 'Total loss': 0.4631641005927866} | train loss {'Reaction outcome loss': 0.12664861469379357, 'Total loss': 0.12664861469379357}
2022-12-05 20:52:11,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:11,937 INFO:     Epoch: 86
2022-12-05 20:52:12,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4509883753278039, 'Total loss': 0.4509883753278039} | train loss {'Reaction outcome loss': 0.1209726225840108, 'Total loss': 0.1209726225840108}
2022-12-05 20:52:12,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:12,727 INFO:     Epoch: 87
2022-12-05 20:52:13,516 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4780699922279878, 'Total loss': 0.4780699922279878} | train loss {'Reaction outcome loss': 0.12065691024350424, 'Total loss': 0.12065691024350424}
2022-12-05 20:52:13,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:13,516 INFO:     Epoch: 88
2022-12-05 20:52:14,309 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4657728097994219, 'Total loss': 0.4657728097994219} | train loss {'Reaction outcome loss': 0.12073965513733245, 'Total loss': 0.12073965513733245}
2022-12-05 20:52:14,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:14,309 INFO:     Epoch: 89
2022-12-05 20:52:15,102 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4576424809003418, 'Total loss': 0.4576424809003418} | train loss {'Reaction outcome loss': 0.1212280503767092, 'Total loss': 0.1212280503767092}
2022-12-05 20:52:15,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:15,102 INFO:     Epoch: 90
2022-12-05 20:52:15,892 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45495672862638126, 'Total loss': 0.45495672862638126} | train loss {'Reaction outcome loss': 0.1201234757674918, 'Total loss': 0.1201234757674918}
2022-12-05 20:52:15,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:15,892 INFO:     Epoch: 91
2022-12-05 20:52:16,685 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.451365780423988, 'Total loss': 0.451365780423988} | train loss {'Reaction outcome loss': 0.12213471392545128, 'Total loss': 0.12213471392545128}
2022-12-05 20:52:16,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:16,686 INFO:     Epoch: 92
2022-12-05 20:52:17,479 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4415748386897824, 'Total loss': 0.4415748386897824} | train loss {'Reaction outcome loss': 0.12011625457577588, 'Total loss': 0.12011625457577588}
2022-12-05 20:52:17,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:17,479 INFO:     Epoch: 93
2022-12-05 20:52:18,268 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45345003428784286, 'Total loss': 0.45345003428784286} | train loss {'Reaction outcome loss': 0.12032735191150418, 'Total loss': 0.12032735191150418}
2022-12-05 20:52:18,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:18,268 INFO:     Epoch: 94
2022-12-05 20:52:19,062 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44524257901039993, 'Total loss': 0.44524257901039993} | train loss {'Reaction outcome loss': 0.11882753944730447, 'Total loss': 0.11882753944730447}
2022-12-05 20:52:19,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:19,062 INFO:     Epoch: 95
2022-12-05 20:52:19,856 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4494807488200339, 'Total loss': 0.4494807488200339} | train loss {'Reaction outcome loss': 0.11708732368800068, 'Total loss': 0.11708732368800068}
2022-12-05 20:52:19,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:19,857 INFO:     Epoch: 96
2022-12-05 20:52:20,653 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4398367828266187, 'Total loss': 0.4398367828266187} | train loss {'Reaction outcome loss': 0.1171232990473659, 'Total loss': 0.1171232990473659}
2022-12-05 20:52:20,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:20,653 INFO:     Epoch: 97
2022-12-05 20:52:21,446 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4572459466078065, 'Total loss': 0.4572459466078065} | train loss {'Reaction outcome loss': 0.11749307261103945, 'Total loss': 0.11749307261103945}
2022-12-05 20:52:21,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:21,446 INFO:     Epoch: 98
2022-12-05 20:52:22,242 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.451145046136596, 'Total loss': 0.451145046136596} | train loss {'Reaction outcome loss': 0.11953548383673714, 'Total loss': 0.11953548383673714}
2022-12-05 20:52:22,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:22,242 INFO:     Epoch: 99
2022-12-05 20:52:23,043 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.445608640936288, 'Total loss': 0.445608640936288} | train loss {'Reaction outcome loss': 0.12051700276037257, 'Total loss': 0.12051700276037257}
2022-12-05 20:52:23,043 INFO:     Best model found after epoch 10 of 100.
2022-12-05 20:52:23,043 INFO:   Done with stage: TRAINING
2022-12-05 20:52:23,043 INFO:   Starting stage: EVALUATION
2022-12-05 20:52:23,162 INFO:   Done with stage: EVALUATION
2022-12-05 20:52:23,162 INFO:   Leaving out SEQ value Fold_9
2022-12-05 20:52:23,175 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:52:23,175 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:52:23,814 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:52:23,814 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:52:23,882 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:52:23,882 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:52:23,882 INFO:     No hyperparam tuning for this model
2022-12-05 20:52:23,882 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:52:23,882 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:52:23,883 INFO:     None feature selector for col prot
2022-12-05 20:52:23,883 INFO:     None feature selector for col prot
2022-12-05 20:52:23,883 INFO:     None feature selector for col prot
2022-12-05 20:52:23,884 INFO:     None feature selector for col chem
2022-12-05 20:52:23,884 INFO:     None feature selector for col chem
2022-12-05 20:52:23,884 INFO:     None feature selector for col chem
2022-12-05 20:52:23,884 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:52:23,884 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:52:23,886 INFO:     Number of params in model 215821
2022-12-05 20:52:23,889 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:52:23,889 INFO:   Starting stage: TRAINING
2022-12-05 20:52:23,949 INFO:     Val loss before train {'Reaction outcome loss': 1.04120143299753, 'Total loss': 1.04120143299753}
2022-12-05 20:52:23,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:23,949 INFO:     Epoch: 0
2022-12-05 20:52:24,735 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.657961727204648, 'Total loss': 0.657961727204648} | train loss {'Reaction outcome loss': 0.7952353340022418, 'Total loss': 0.7952353340022418}
2022-12-05 20:52:24,735 INFO:     Found new best model at epoch 0
2022-12-05 20:52:24,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:24,736 INFO:     Epoch: 1
2022-12-05 20:52:25,525 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5519588247618892, 'Total loss': 0.5519588247618892} | train loss {'Reaction outcome loss': 0.5462366518317436, 'Total loss': 0.5462366518317436}
2022-12-05 20:52:25,525 INFO:     Found new best model at epoch 1
2022-12-05 20:52:25,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:25,526 INFO:     Epoch: 2
2022-12-05 20:52:26,309 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5090412517840212, 'Total loss': 0.5090412517840212} | train loss {'Reaction outcome loss': 0.47148432755956843, 'Total loss': 0.47148432755956843}
2022-12-05 20:52:26,309 INFO:     Found new best model at epoch 2
2022-12-05 20:52:26,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:26,310 INFO:     Epoch: 3
2022-12-05 20:52:27,092 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49717906760898506, 'Total loss': 0.49717906760898506} | train loss {'Reaction outcome loss': 0.43088684252330234, 'Total loss': 0.43088684252330234}
2022-12-05 20:52:27,092 INFO:     Found new best model at epoch 3
2022-12-05 20:52:27,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:27,093 INFO:     Epoch: 4
2022-12-05 20:52:27,883 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.470613485540856, 'Total loss': 0.470613485540856} | train loss {'Reaction outcome loss': 0.3986615783097793, 'Total loss': 0.3986615783097793}
2022-12-05 20:52:27,884 INFO:     Found new best model at epoch 4
2022-12-05 20:52:27,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:27,885 INFO:     Epoch: 5
2022-12-05 20:52:28,669 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4485543491318822, 'Total loss': 0.4485543491318822} | train loss {'Reaction outcome loss': 0.37347395277144957, 'Total loss': 0.37347395277144957}
2022-12-05 20:52:28,670 INFO:     Found new best model at epoch 5
2022-12-05 20:52:28,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:28,671 INFO:     Epoch: 6
2022-12-05 20:52:29,454 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4594871452586217, 'Total loss': 0.4594871452586217} | train loss {'Reaction outcome loss': 0.3576944183634252, 'Total loss': 0.3576944183634252}
2022-12-05 20:52:29,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:29,454 INFO:     Epoch: 7
2022-12-05 20:52:30,234 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44002908739176666, 'Total loss': 0.44002908739176666} | train loss {'Reaction outcome loss': 0.33588167933785185, 'Total loss': 0.33588167933785185}
2022-12-05 20:52:30,234 INFO:     Found new best model at epoch 7
2022-12-05 20:52:30,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:30,235 INFO:     Epoch: 8
2022-12-05 20:52:31,019 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43393795420839026, 'Total loss': 0.43393795420839026} | train loss {'Reaction outcome loss': 0.3213821273981308, 'Total loss': 0.3213821273981308}
2022-12-05 20:52:31,019 INFO:     Found new best model at epoch 8
2022-12-05 20:52:31,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:31,020 INFO:     Epoch: 9
2022-12-05 20:52:31,800 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4418824017047882, 'Total loss': 0.4418824017047882} | train loss {'Reaction outcome loss': 0.30787070253673865, 'Total loss': 0.30787070253673865}
2022-12-05 20:52:31,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:31,800 INFO:     Epoch: 10
2022-12-05 20:52:32,581 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46280431611971423, 'Total loss': 0.46280431611971423} | train loss {'Reaction outcome loss': 0.29913852734833346, 'Total loss': 0.29913852734833346}
2022-12-05 20:52:32,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:32,581 INFO:     Epoch: 11
2022-12-05 20:52:33,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44140837620943785, 'Total loss': 0.44140837620943785} | train loss {'Reaction outcome loss': 0.28743182147035795, 'Total loss': 0.28743182147035795}
2022-12-05 20:52:33,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:33,373 INFO:     Epoch: 12
2022-12-05 20:52:34,155 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4415655732154846, 'Total loss': 0.4415655732154846} | train loss {'Reaction outcome loss': 0.2792368407152137, 'Total loss': 0.2792368407152137}
2022-12-05 20:52:34,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:34,155 INFO:     Epoch: 13
2022-12-05 20:52:34,936 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4329687279056419, 'Total loss': 0.4329687279056419} | train loss {'Reaction outcome loss': 0.26761903650298413, 'Total loss': 0.26761903650298413}
2022-12-05 20:52:34,936 INFO:     Found new best model at epoch 13
2022-12-05 20:52:34,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:34,937 INFO:     Epoch: 14
2022-12-05 20:52:35,721 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43789631297642534, 'Total loss': 0.43789631297642534} | train loss {'Reaction outcome loss': 0.2562371666030008, 'Total loss': 0.2562371666030008}
2022-12-05 20:52:35,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:35,721 INFO:     Epoch: 15
2022-12-05 20:52:36,501 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4266119430010969, 'Total loss': 0.4266119430010969} | train loss {'Reaction outcome loss': 0.24952151541199002, 'Total loss': 0.24952151541199002}
2022-12-05 20:52:36,501 INFO:     Found new best model at epoch 15
2022-12-05 20:52:36,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:36,502 INFO:     Epoch: 16
2022-12-05 20:52:37,283 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4367998686026443, 'Total loss': 0.4367998686026443} | train loss {'Reaction outcome loss': 0.2425771438953828, 'Total loss': 0.2425771438953828}
2022-12-05 20:52:37,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:37,283 INFO:     Epoch: 17
2022-12-05 20:52:38,064 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43824013525789435, 'Total loss': 0.43824013525789435} | train loss {'Reaction outcome loss': 0.23688427624957903, 'Total loss': 0.23688427624957903}
2022-12-05 20:52:38,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:38,064 INFO:     Epoch: 18
2022-12-05 20:52:38,849 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4388647086241029, 'Total loss': 0.4388647086241029} | train loss {'Reaction outcome loss': 0.22917511802242727, 'Total loss': 0.22917511802242727}
2022-12-05 20:52:38,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:38,849 INFO:     Epoch: 19
2022-12-05 20:52:39,630 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4420659684322097, 'Total loss': 0.4420659684322097} | train loss {'Reaction outcome loss': 0.22403831863585782, 'Total loss': 0.22403831863585782}
2022-12-05 20:52:39,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:39,630 INFO:     Epoch: 20
2022-12-05 20:52:40,415 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4447244138202884, 'Total loss': 0.4447244138202884} | train loss {'Reaction outcome loss': 0.21837783049868079, 'Total loss': 0.21837783049868079}
2022-12-05 20:52:40,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:40,415 INFO:     Epoch: 21
2022-12-05 20:52:41,195 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43231048942966893, 'Total loss': 0.43231048942966893} | train loss {'Reaction outcome loss': 0.21164233657170314, 'Total loss': 0.21164233657170314}
2022-12-05 20:52:41,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:41,195 INFO:     Epoch: 22
2022-12-05 20:52:41,978 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4338584864004092, 'Total loss': 0.4338584864004092} | train loss {'Reaction outcome loss': 0.20950826591983132, 'Total loss': 0.20950826591983132}
2022-12-05 20:52:41,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:41,978 INFO:     Epoch: 23
2022-12-05 20:52:42,759 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4475916420871561, 'Total loss': 0.4475916420871561} | train loss {'Reaction outcome loss': 0.20413747972675733, 'Total loss': 0.20413747972675733}
2022-12-05 20:52:42,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:42,759 INFO:     Epoch: 24
2022-12-05 20:52:43,539 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46762157434766943, 'Total loss': 0.46762157434766943} | train loss {'Reaction outcome loss': 0.19766311961777355, 'Total loss': 0.19766311961777355}
2022-12-05 20:52:43,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:43,540 INFO:     Epoch: 25
2022-12-05 20:52:44,319 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43877226927063684, 'Total loss': 0.43877226927063684} | train loss {'Reaction outcome loss': 0.19440919181370006, 'Total loss': 0.19440919181370006}
2022-12-05 20:52:44,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:44,319 INFO:     Epoch: 26
2022-12-05 20:52:45,099 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41508525499904697, 'Total loss': 0.41508525499904697} | train loss {'Reaction outcome loss': 0.19244749263233069, 'Total loss': 0.19244749263233069}
2022-12-05 20:52:45,099 INFO:     Found new best model at epoch 26
2022-12-05 20:52:45,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:45,100 INFO:     Epoch: 27
2022-12-05 20:52:45,887 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4379844624887813, 'Total loss': 0.4379844624887813} | train loss {'Reaction outcome loss': 0.18449267512377426, 'Total loss': 0.18449267512377426}
2022-12-05 20:52:45,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:45,888 INFO:     Epoch: 28
2022-12-05 20:52:46,667 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42466128566725686, 'Total loss': 0.42466128566725686} | train loss {'Reaction outcome loss': 0.1849260973078864, 'Total loss': 0.1849260973078864}
2022-12-05 20:52:46,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:46,668 INFO:     Epoch: 29
2022-12-05 20:52:47,449 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42319234121929517, 'Total loss': 0.42319234121929517} | train loss {'Reaction outcome loss': 0.18231597126898716, 'Total loss': 0.18231597126898716}
2022-12-05 20:52:47,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:47,450 INFO:     Epoch: 30
2022-12-05 20:52:48,237 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45696060020815243, 'Total loss': 0.45696060020815243} | train loss {'Reaction outcome loss': 0.176629232873722, 'Total loss': 0.176629232873722}
2022-12-05 20:52:48,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:48,238 INFO:     Epoch: 31
2022-12-05 20:52:49,024 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42356908541511407, 'Total loss': 0.42356908541511407} | train loss {'Reaction outcome loss': 0.17208984754219347, 'Total loss': 0.17208984754219347}
2022-12-05 20:52:49,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:49,024 INFO:     Epoch: 32
2022-12-05 20:52:49,805 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.424333167347041, 'Total loss': 0.424333167347041} | train loss {'Reaction outcome loss': 0.1735152332530338, 'Total loss': 0.1735152332530338}
2022-12-05 20:52:49,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:49,805 INFO:     Epoch: 33
2022-12-05 20:52:50,589 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43149755150079727, 'Total loss': 0.43149755150079727} | train loss {'Reaction outcome loss': 0.16938191805110903, 'Total loss': 0.16938191805110903}
2022-12-05 20:52:50,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:50,589 INFO:     Epoch: 34
2022-12-05 20:52:51,375 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4377847110683268, 'Total loss': 0.4377847110683268} | train loss {'Reaction outcome loss': 0.16570717628513063, 'Total loss': 0.16570717628513063}
2022-12-05 20:52:51,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:51,375 INFO:     Epoch: 35
2022-12-05 20:52:52,163 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42957568913698196, 'Total loss': 0.42957568913698196} | train loss {'Reaction outcome loss': 0.16297075029234498, 'Total loss': 0.16297075029234498}
2022-12-05 20:52:52,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:52,163 INFO:     Epoch: 36
2022-12-05 20:52:52,945 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4452836618504741, 'Total loss': 0.4452836618504741} | train loss {'Reaction outcome loss': 0.16121766425060982, 'Total loss': 0.16121766425060982}
2022-12-05 20:52:52,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:52,945 INFO:     Epoch: 37
2022-12-05 20:52:53,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4433378485793417, 'Total loss': 0.4433378485793417} | train loss {'Reaction outcome loss': 0.1601608115343415, 'Total loss': 0.1601608115343415}
2022-12-05 20:52:53,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:53,727 INFO:     Epoch: 38
2022-12-05 20:52:54,510 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4334920260377906, 'Total loss': 0.4334920260377906} | train loss {'Reaction outcome loss': 0.15855655020901135, 'Total loss': 0.15855655020901135}
2022-12-05 20:52:54,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:54,510 INFO:     Epoch: 39
2022-12-05 20:52:55,296 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.427046894942495, 'Total loss': 0.427046894942495} | train loss {'Reaction outcome loss': 0.15813726754669025, 'Total loss': 0.15813726754669025}
2022-12-05 20:52:55,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:55,296 INFO:     Epoch: 40
2022-12-05 20:52:56,083 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4487978308038278, 'Total loss': 0.4487978308038278} | train loss {'Reaction outcome loss': 0.15413909757091682, 'Total loss': 0.15413909757091682}
2022-12-05 20:52:56,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:56,083 INFO:     Epoch: 41
2022-12-05 20:52:56,877 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43722478029402817, 'Total loss': 0.43722478029402817} | train loss {'Reaction outcome loss': 0.15286239615964647, 'Total loss': 0.15286239615964647}
2022-12-05 20:52:56,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:56,877 INFO:     Epoch: 42
2022-12-05 20:52:57,676 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44041719423098996, 'Total loss': 0.44041719423098996} | train loss {'Reaction outcome loss': 0.15298533470807027, 'Total loss': 0.15298533470807027}
2022-12-05 20:52:57,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:57,676 INFO:     Epoch: 43
2022-12-05 20:52:58,469 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45237709243189206, 'Total loss': 0.45237709243189206} | train loss {'Reaction outcome loss': 0.1485363005223323, 'Total loss': 0.1485363005223323}
2022-12-05 20:52:58,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:58,469 INFO:     Epoch: 44
2022-12-05 20:52:59,265 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44694672558795323, 'Total loss': 0.44694672558795323} | train loss {'Reaction outcome loss': 0.14973483272657104, 'Total loss': 0.14973483272657104}
2022-12-05 20:52:59,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:52:59,266 INFO:     Epoch: 45
2022-12-05 20:53:00,061 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4368780283151533, 'Total loss': 0.4368780283151533} | train loss {'Reaction outcome loss': 0.1485580091573754, 'Total loss': 0.1485580091573754}
2022-12-05 20:53:00,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:00,062 INFO:     Epoch: 46
2022-12-05 20:53:00,853 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4315030410547148, 'Total loss': 0.4315030410547148} | train loss {'Reaction outcome loss': 0.14540927885670443, 'Total loss': 0.14540927885670443}
2022-12-05 20:53:00,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:00,853 INFO:     Epoch: 47
2022-12-05 20:53:01,645 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4377791170369495, 'Total loss': 0.4377791170369495} | train loss {'Reaction outcome loss': 0.14354841401990578, 'Total loss': 0.14354841401990578}
2022-12-05 20:53:01,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:01,645 INFO:     Epoch: 48
2022-12-05 20:53:02,438 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44464628330685874, 'Total loss': 0.44464628330685874} | train loss {'Reaction outcome loss': 0.14136611969799412, 'Total loss': 0.14136611969799412}
2022-12-05 20:53:02,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:02,439 INFO:     Epoch: 49
2022-12-05 20:53:03,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4430821619250558, 'Total loss': 0.4430821619250558} | train loss {'Reaction outcome loss': 0.14200615880972878, 'Total loss': 0.14200615880972878}
2022-12-05 20:53:03,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:03,233 INFO:     Epoch: 50
2022-12-05 20:53:04,026 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4457218768921765, 'Total loss': 0.4457218768921765} | train loss {'Reaction outcome loss': 0.1408119322085867, 'Total loss': 0.1408119322085867}
2022-12-05 20:53:04,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:04,027 INFO:     Epoch: 51
2022-12-05 20:53:04,820 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4429282888516106, 'Total loss': 0.4429282888516106} | train loss {'Reaction outcome loss': 0.142276552395553, 'Total loss': 0.142276552395553}
2022-12-05 20:53:04,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:04,820 INFO:     Epoch: 52
2022-12-05 20:53:05,622 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4485568487170068, 'Total loss': 0.4485568487170068} | train loss {'Reaction outcome loss': 0.13898315083387555, 'Total loss': 0.13898315083387555}
2022-12-05 20:53:05,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:05,623 INFO:     Epoch: 53
2022-12-05 20:53:06,417 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44537408175793564, 'Total loss': 0.44537408175793564} | train loss {'Reaction outcome loss': 0.13845675277466676, 'Total loss': 0.13845675277466676}
2022-12-05 20:53:06,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:06,417 INFO:     Epoch: 54
2022-12-05 20:53:07,208 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45954314179041167, 'Total loss': 0.45954314179041167} | train loss {'Reaction outcome loss': 0.1369565609158302, 'Total loss': 0.1369565609158302}
2022-12-05 20:53:07,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:07,209 INFO:     Epoch: 55
2022-12-05 20:53:07,998 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4379848207939755, 'Total loss': 0.4379848207939755} | train loss {'Reaction outcome loss': 0.13615554485241976, 'Total loss': 0.13615554485241976}
2022-12-05 20:53:07,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:07,998 INFO:     Epoch: 56
2022-12-05 20:53:08,790 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.445451793345538, 'Total loss': 0.445451793345538} | train loss {'Reaction outcome loss': 0.13511190509461626, 'Total loss': 0.13511190509461626}
2022-12-05 20:53:08,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:08,790 INFO:     Epoch: 57
2022-12-05 20:53:09,582 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.433936900713227, 'Total loss': 0.433936900713227} | train loss {'Reaction outcome loss': 0.13600448542179502, 'Total loss': 0.13600448542179502}
2022-12-05 20:53:09,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:09,582 INFO:     Epoch: 58
2022-12-05 20:53:10,376 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43731722980737686, 'Total loss': 0.43731722980737686} | train loss {'Reaction outcome loss': 0.13415751049523147, 'Total loss': 0.13415751049523147}
2022-12-05 20:53:10,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:10,376 INFO:     Epoch: 59
2022-12-05 20:53:11,171 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43799423934383824, 'Total loss': 0.43799423934383824} | train loss {'Reaction outcome loss': 0.13628534239773848, 'Total loss': 0.13628534239773848}
2022-12-05 20:53:11,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:11,171 INFO:     Epoch: 60
2022-12-05 20:53:11,961 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4493734557181597, 'Total loss': 0.4493734557181597} | train loss {'Reaction outcome loss': 0.13251751989734417, 'Total loss': 0.13251751989734417}
2022-12-05 20:53:11,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:11,962 INFO:     Epoch: 61
2022-12-05 20:53:12,755 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4387750420719385, 'Total loss': 0.4387750420719385} | train loss {'Reaction outcome loss': 0.1293053900784984, 'Total loss': 0.1293053900784984}
2022-12-05 20:53:12,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:12,756 INFO:     Epoch: 62
2022-12-05 20:53:13,547 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4447163629599593, 'Total loss': 0.4447163629599593} | train loss {'Reaction outcome loss': 0.13066528399227834, 'Total loss': 0.13066528399227834}
2022-12-05 20:53:13,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:13,547 INFO:     Epoch: 63
2022-12-05 20:53:14,345 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4560044231739911, 'Total loss': 0.4560044231739911} | train loss {'Reaction outcome loss': 0.13175961271460568, 'Total loss': 0.13175961271460568}
2022-12-05 20:53:14,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:14,345 INFO:     Epoch: 64
2022-12-05 20:53:15,138 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4503885250199925, 'Total loss': 0.4503885250199925} | train loss {'Reaction outcome loss': 0.12730494424776764, 'Total loss': 0.12730494424776764}
2022-12-05 20:53:15,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:15,138 INFO:     Epoch: 65
2022-12-05 20:53:15,929 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4407655288549987, 'Total loss': 0.4407655288549987} | train loss {'Reaction outcome loss': 0.12938832283704257, 'Total loss': 0.12938832283704257}
2022-12-05 20:53:15,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:15,929 INFO:     Epoch: 66
2022-12-05 20:53:16,719 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4687645757062869, 'Total loss': 0.4687645757062869} | train loss {'Reaction outcome loss': 0.12839403611664868, 'Total loss': 0.12839403611664868}
2022-12-05 20:53:16,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:16,719 INFO:     Epoch: 67
2022-12-05 20:53:17,509 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4433264715427702, 'Total loss': 0.4433264715427702} | train loss {'Reaction outcome loss': 0.12821916911979112, 'Total loss': 0.12821916911979112}
2022-12-05 20:53:17,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:17,509 INFO:     Epoch: 68
2022-12-05 20:53:18,299 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45071073418313806, 'Total loss': 0.45071073418313806} | train loss {'Reaction outcome loss': 0.1258286837754505, 'Total loss': 0.1258286837754505}
2022-12-05 20:53:18,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:18,300 INFO:     Epoch: 69
2022-12-05 20:53:19,094 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4601946286857128, 'Total loss': 0.4601946286857128} | train loss {'Reaction outcome loss': 0.12549954896830784, 'Total loss': 0.12549954896830784}
2022-12-05 20:53:19,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:19,094 INFO:     Epoch: 70
2022-12-05 20:53:19,887 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4722035862505436, 'Total loss': 0.4722035862505436} | train loss {'Reaction outcome loss': 0.12687562596509044, 'Total loss': 0.12687562596509044}
2022-12-05 20:53:19,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:19,888 INFO:     Epoch: 71
2022-12-05 20:53:20,683 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42899303849447856, 'Total loss': 0.42899303849447856} | train loss {'Reaction outcome loss': 0.12358628172731521, 'Total loss': 0.12358628172731521}
2022-12-05 20:53:20,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:20,683 INFO:     Epoch: 72
2022-12-05 20:53:21,475 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43967515899037773, 'Total loss': 0.43967515899037773} | train loss {'Reaction outcome loss': 0.12346820045946812, 'Total loss': 0.12346820045946812}
2022-12-05 20:53:21,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:21,476 INFO:     Epoch: 73
2022-12-05 20:53:22,273 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44024707038294186, 'Total loss': 0.44024707038294186} | train loss {'Reaction outcome loss': 0.1230354343293881, 'Total loss': 0.1230354343293881}
2022-12-05 20:53:22,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:22,273 INFO:     Epoch: 74
2022-12-05 20:53:23,073 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44438867406411603, 'Total loss': 0.44438867406411603} | train loss {'Reaction outcome loss': 0.1231266623628991, 'Total loss': 0.1231266623628991}
2022-12-05 20:53:23,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:23,073 INFO:     Epoch: 75
2022-12-05 20:53:23,871 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4390808235515248, 'Total loss': 0.4390808235515248} | train loss {'Reaction outcome loss': 0.12180146279041561, 'Total loss': 0.12180146279041561}
2022-12-05 20:53:23,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:23,871 INFO:     Epoch: 76
2022-12-05 20:53:24,662 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4433061179112304, 'Total loss': 0.4433061179112304} | train loss {'Reaction outcome loss': 0.12270133333394723, 'Total loss': 0.12270133333394723}
2022-12-05 20:53:24,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:24,662 INFO:     Epoch: 77
2022-12-05 20:53:25,455 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45086084396197373, 'Total loss': 0.45086084396197373} | train loss {'Reaction outcome loss': 0.12178052277969463, 'Total loss': 0.12178052277969463}
2022-12-05 20:53:25,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:25,455 INFO:     Epoch: 78
2022-12-05 20:53:26,248 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47165249745276844, 'Total loss': 0.47165249745276844} | train loss {'Reaction outcome loss': 0.12144286187783795, 'Total loss': 0.12144286187783795}
2022-12-05 20:53:26,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:26,249 INFO:     Epoch: 79
2022-12-05 20:53:27,038 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4322891574014317, 'Total loss': 0.4322891574014317} | train loss {'Reaction outcome loss': 0.12082309947178071, 'Total loss': 0.12082309947178071}
2022-12-05 20:53:27,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:27,038 INFO:     Epoch: 80
2022-12-05 20:53:27,830 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45496450432322244, 'Total loss': 0.45496450432322244} | train loss {'Reaction outcome loss': 0.1197768183691161, 'Total loss': 0.1197768183691161}
2022-12-05 20:53:27,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:27,830 INFO:     Epoch: 81
2022-12-05 20:53:28,625 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43633659319444135, 'Total loss': 0.43633659319444135} | train loss {'Reaction outcome loss': 0.12096048208827875, 'Total loss': 0.12096048208827875}
2022-12-05 20:53:28,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:28,625 INFO:     Epoch: 82
2022-12-05 20:53:29,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43314482119273057, 'Total loss': 0.43314482119273057} | train loss {'Reaction outcome loss': 0.11906975960473017, 'Total loss': 0.11906975960473017}
2022-12-05 20:53:29,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:29,417 INFO:     Epoch: 83
2022-12-05 20:53:30,214 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44005368260497396, 'Total loss': 0.44005368260497396} | train loss {'Reaction outcome loss': 0.11842388655154072, 'Total loss': 0.11842388655154072}
2022-12-05 20:53:30,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:30,214 INFO:     Epoch: 84
2022-12-05 20:53:31,013 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43932911855253304, 'Total loss': 0.43932911855253304} | train loss {'Reaction outcome loss': 0.11632305569566634, 'Total loss': 0.11632305569566634}
2022-12-05 20:53:31,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:31,014 INFO:     Epoch: 85
2022-12-05 20:53:31,810 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45684862915765156, 'Total loss': 0.45684862915765156} | train loss {'Reaction outcome loss': 0.1176851274445653, 'Total loss': 0.1176851274445653}
2022-12-05 20:53:31,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:31,810 INFO:     Epoch: 86
2022-12-05 20:53:32,601 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43497529287229886, 'Total loss': 0.43497529287229886} | train loss {'Reaction outcome loss': 0.1180068489620272, 'Total loss': 0.1180068489620272}
2022-12-05 20:53:32,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:32,602 INFO:     Epoch: 87
2022-12-05 20:53:33,392 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4437839084050872, 'Total loss': 0.4437839084050872} | train loss {'Reaction outcome loss': 0.11853729740013273, 'Total loss': 0.11853729740013273}
2022-12-05 20:53:33,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:33,392 INFO:     Epoch: 88
2022-12-05 20:53:34,185 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44518729637969623, 'Total loss': 0.44518729637969623} | train loss {'Reaction outcome loss': 0.11727093465778292, 'Total loss': 0.11727093465778292}
2022-12-05 20:53:34,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:34,185 INFO:     Epoch: 89
2022-12-05 20:53:34,978 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43859269249845634, 'Total loss': 0.43859269249845634} | train loss {'Reaction outcome loss': 0.11658902942221992, 'Total loss': 0.11658902942221992}
2022-12-05 20:53:34,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:34,979 INFO:     Epoch: 90
2022-12-05 20:53:35,768 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4271310432390733, 'Total loss': 0.4271310432390733} | train loss {'Reaction outcome loss': 0.11468861693782466, 'Total loss': 0.11468861693782466}
2022-12-05 20:53:35,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:35,768 INFO:     Epoch: 91
2022-12-05 20:53:36,563 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45301272195171227, 'Total loss': 0.45301272195171227} | train loss {'Reaction outcome loss': 0.11612051066239269, 'Total loss': 0.11612051066239269}
2022-12-05 20:53:36,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:36,563 INFO:     Epoch: 92
2022-12-05 20:53:37,349 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.427561475133354, 'Total loss': 0.427561475133354} | train loss {'Reaction outcome loss': 0.1174948769944663, 'Total loss': 0.1174948769944663}
2022-12-05 20:53:37,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:37,350 INFO:     Epoch: 93
2022-12-05 20:53:38,142 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4346175031228499, 'Total loss': 0.4346175031228499} | train loss {'Reaction outcome loss': 0.11613535028787292, 'Total loss': 0.11613535028787292}
2022-12-05 20:53:38,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:38,142 INFO:     Epoch: 94
2022-12-05 20:53:38,935 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.421613123267889, 'Total loss': 0.421613123267889} | train loss {'Reaction outcome loss': 0.11454103468176054, 'Total loss': 0.11454103468176054}
2022-12-05 20:53:38,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:38,935 INFO:     Epoch: 95
2022-12-05 20:53:39,726 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4293899233029647, 'Total loss': 0.4293899233029647} | train loss {'Reaction outcome loss': 0.11277700536029071, 'Total loss': 0.11277700536029071}
2022-12-05 20:53:39,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:39,726 INFO:     Epoch: 96
2022-12-05 20:53:40,519 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4482593387365341, 'Total loss': 0.4482593387365341} | train loss {'Reaction outcome loss': 0.11290091418338065, 'Total loss': 0.11290091418338065}
2022-12-05 20:53:40,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:40,519 INFO:     Epoch: 97
2022-12-05 20:53:41,308 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43687115812843497, 'Total loss': 0.43687115812843497} | train loss {'Reaction outcome loss': 0.11203006725682288, 'Total loss': 0.11203006725682288}
2022-12-05 20:53:41,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:41,308 INFO:     Epoch: 98
2022-12-05 20:53:42,099 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43316458174112166, 'Total loss': 0.43316458174112166} | train loss {'Reaction outcome loss': 0.11278555322514505, 'Total loss': 0.11278555322514505}
2022-12-05 20:53:42,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:42,099 INFO:     Epoch: 99
2022-12-05 20:53:42,887 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4432272284545682, 'Total loss': 0.4432272284545682} | train loss {'Reaction outcome loss': 0.11225709025843107, 'Total loss': 0.11225709025843107}
2022-12-05 20:53:42,887 INFO:     Best model found after epoch 27 of 100.
2022-12-05 20:53:42,887 INFO:   Done with stage: TRAINING
2022-12-05 20:53:42,887 INFO:   Starting stage: EVALUATION
2022-12-05 20:53:43,017 INFO:   Done with stage: EVALUATION
2022-12-05 20:53:43,026 INFO:   Leaving out SEQ value Fold_0
2022-12-05 20:53:43,038 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:53:43,038 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:53:43,671 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:53:43,672 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:53:43,741 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:53:43,742 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:53:43,742 INFO:     No hyperparam tuning for this model
2022-12-05 20:53:43,742 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:53:43,742 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:53:43,743 INFO:     None feature selector for col prot
2022-12-05 20:53:43,743 INFO:     None feature selector for col prot
2022-12-05 20:53:43,743 INFO:     None feature selector for col prot
2022-12-05 20:53:43,743 INFO:     None feature selector for col chem
2022-12-05 20:53:43,743 INFO:     None feature selector for col chem
2022-12-05 20:53:43,743 INFO:     None feature selector for col chem
2022-12-05 20:53:43,744 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:53:43,744 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:53:43,745 INFO:     Number of params in model 215821
2022-12-05 20:53:43,748 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:53:43,748 INFO:   Starting stage: TRAINING
2022-12-05 20:53:43,808 INFO:     Val loss before train {'Reaction outcome loss': 1.0161459348922552, 'Total loss': 1.0161459348922552}
2022-12-05 20:53:43,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:43,808 INFO:     Epoch: 0
2022-12-05 20:53:44,594 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6240358782369037, 'Total loss': 0.6240358782369037} | train loss {'Reaction outcome loss': 0.7884966788477585, 'Total loss': 0.7884966788477585}
2022-12-05 20:53:44,594 INFO:     Found new best model at epoch 0
2022-12-05 20:53:44,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:44,595 INFO:     Epoch: 1
2022-12-05 20:53:45,376 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5335115232439929, 'Total loss': 0.5335115232439929} | train loss {'Reaction outcome loss': 0.5368348804042965, 'Total loss': 0.5368348804042965}
2022-12-05 20:53:45,377 INFO:     Found new best model at epoch 1
2022-12-05 20:53:45,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:45,377 INFO:     Epoch: 2
2022-12-05 20:53:46,168 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5027088755091955, 'Total loss': 0.5027088755091955} | train loss {'Reaction outcome loss': 0.47702744200092845, 'Total loss': 0.47702744200092845}
2022-12-05 20:53:46,168 INFO:     Found new best model at epoch 2
2022-12-05 20:53:46,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:46,169 INFO:     Epoch: 3
2022-12-05 20:53:46,953 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48233717679977417, 'Total loss': 0.48233717679977417} | train loss {'Reaction outcome loss': 0.44042519553274406, 'Total loss': 0.44042519553274406}
2022-12-05 20:53:46,953 INFO:     Found new best model at epoch 3
2022-12-05 20:53:46,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:46,954 INFO:     Epoch: 4
2022-12-05 20:53:47,742 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45592467105665874, 'Total loss': 0.45592467105665874} | train loss {'Reaction outcome loss': 0.4112459518259666, 'Total loss': 0.4112459518259666}
2022-12-05 20:53:47,743 INFO:     Found new best model at epoch 4
2022-12-05 20:53:47,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:47,743 INFO:     Epoch: 5
2022-12-05 20:53:48,532 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45837537112624144, 'Total loss': 0.45837537112624144} | train loss {'Reaction outcome loss': 0.39091278105729915, 'Total loss': 0.39091278105729915}
2022-12-05 20:53:48,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:48,532 INFO:     Epoch: 6
2022-12-05 20:53:49,324 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43574849810711175, 'Total loss': 0.43574849810711175} | train loss {'Reaction outcome loss': 0.3731514288448408, 'Total loss': 0.3731514288448408}
2022-12-05 20:53:49,324 INFO:     Found new best model at epoch 6
2022-12-05 20:53:49,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:49,325 INFO:     Epoch: 7
2022-12-05 20:53:50,110 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4353172491456187, 'Total loss': 0.4353172491456187} | train loss {'Reaction outcome loss': 0.35497207457169155, 'Total loss': 0.35497207457169155}
2022-12-05 20:53:50,111 INFO:     Found new best model at epoch 7
2022-12-05 20:53:50,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:50,112 INFO:     Epoch: 8
2022-12-05 20:53:50,897 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4198251907215562, 'Total loss': 0.4198251907215562} | train loss {'Reaction outcome loss': 0.3426482789829129, 'Total loss': 0.3426482789829129}
2022-12-05 20:53:50,897 INFO:     Found new best model at epoch 8
2022-12-05 20:53:50,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:50,898 INFO:     Epoch: 9
2022-12-05 20:53:51,681 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4218370703070663, 'Total loss': 0.4218370703070663} | train loss {'Reaction outcome loss': 0.32701746004893156, 'Total loss': 0.32701746004893156}
2022-12-05 20:53:51,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:51,682 INFO:     Epoch: 10
2022-12-05 20:53:52,464 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4244218967681707, 'Total loss': 0.4244218967681707} | train loss {'Reaction outcome loss': 0.3150359439800997, 'Total loss': 0.3150359439800997}
2022-12-05 20:53:52,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:52,464 INFO:     Epoch: 11
2022-12-05 20:53:53,246 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41490091626034226, 'Total loss': 0.41490091626034226} | train loss {'Reaction outcome loss': 0.3023496818285985, 'Total loss': 0.3023496818285985}
2022-12-05 20:53:53,247 INFO:     Found new best model at epoch 11
2022-12-05 20:53:53,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:53,247 INFO:     Epoch: 12
2022-12-05 20:53:54,036 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41227462298648304, 'Total loss': 0.41227462298648304} | train loss {'Reaction outcome loss': 0.29126423609549884, 'Total loss': 0.29126423609549884}
2022-12-05 20:53:54,036 INFO:     Found new best model at epoch 12
2022-12-05 20:53:54,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:54,037 INFO:     Epoch: 13
2022-12-05 20:53:54,823 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4143308967698452, 'Total loss': 0.4143308967698452} | train loss {'Reaction outcome loss': 0.2844260259546706, 'Total loss': 0.2844260259546706}
2022-12-05 20:53:54,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:54,823 INFO:     Epoch: 14
2022-12-05 20:53:55,609 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4050613011038581, 'Total loss': 0.4050613011038581} | train loss {'Reaction outcome loss': 0.2743999088854819, 'Total loss': 0.2743999088854819}
2022-12-05 20:53:55,609 INFO:     Found new best model at epoch 14
2022-12-05 20:53:55,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:55,610 INFO:     Epoch: 15
2022-12-05 20:53:56,392 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41319634609444195, 'Total loss': 0.41319634609444195} | train loss {'Reaction outcome loss': 0.26412633006445696, 'Total loss': 0.26412633006445696}
2022-12-05 20:53:56,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:56,392 INFO:     Epoch: 16
2022-12-05 20:53:57,179 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.412613021079884, 'Total loss': 0.412613021079884} | train loss {'Reaction outcome loss': 0.25791442679760396, 'Total loss': 0.25791442679760396}
2022-12-05 20:53:57,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:57,179 INFO:     Epoch: 17
2022-12-05 20:53:57,965 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4118204234644424, 'Total loss': 0.4118204234644424} | train loss {'Reaction outcome loss': 0.25025165710048597, 'Total loss': 0.25025165710048597}
2022-12-05 20:53:57,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:57,965 INFO:     Epoch: 18
2022-12-05 20:53:58,751 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40957250671331275, 'Total loss': 0.40957250671331275} | train loss {'Reaction outcome loss': 0.24306335013176575, 'Total loss': 0.24306335013176575}
2022-12-05 20:53:58,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:58,751 INFO:     Epoch: 19
2022-12-05 20:53:59,535 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4061302090453547, 'Total loss': 0.4061302090453547} | train loss {'Reaction outcome loss': 0.2388112613717552, 'Total loss': 0.2388112613717552}
2022-12-05 20:53:59,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:53:59,536 INFO:     Epoch: 20
2022-12-05 20:54:00,319 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4061463232650313, 'Total loss': 0.4061463232650313} | train loss {'Reaction outcome loss': 0.2311292815587071, 'Total loss': 0.2311292815587071}
2022-12-05 20:54:00,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:00,320 INFO:     Epoch: 21
2022-12-05 20:54:01,107 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41186361326727755, 'Total loss': 0.41186361326727755} | train loss {'Reaction outcome loss': 0.22343493801098865, 'Total loss': 0.22343493801098865}
2022-12-05 20:54:01,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:01,107 INFO:     Epoch: 22
2022-12-05 20:54:01,890 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4122107075743897, 'Total loss': 0.4122107075743897} | train loss {'Reaction outcome loss': 0.2170853772673939, 'Total loss': 0.2170853772673939}
2022-12-05 20:54:01,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:01,892 INFO:     Epoch: 23
2022-12-05 20:54:02,675 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41151075169097545, 'Total loss': 0.41151075169097545} | train loss {'Reaction outcome loss': 0.21381390865006653, 'Total loss': 0.21381390865006653}
2022-12-05 20:54:02,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:02,675 INFO:     Epoch: 24
2022-12-05 20:54:03,457 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4151736740456071, 'Total loss': 0.4151736740456071} | train loss {'Reaction outcome loss': 0.2082741055484922, 'Total loss': 0.2082741055484922}
2022-12-05 20:54:03,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:03,457 INFO:     Epoch: 25
2022-12-05 20:54:04,241 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4160570640896642, 'Total loss': 0.4160570640896642} | train loss {'Reaction outcome loss': 0.20211463232265145, 'Total loss': 0.20211463232265145}
2022-12-05 20:54:04,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:04,241 INFO:     Epoch: 26
2022-12-05 20:54:05,025 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4158575008081835, 'Total loss': 0.4158575008081835} | train loss {'Reaction outcome loss': 0.2028418534939162, 'Total loss': 0.2028418534939162}
2022-12-05 20:54:05,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:05,025 INFO:     Epoch: 27
2022-12-05 20:54:05,811 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41611332255740496, 'Total loss': 0.41611332255740496} | train loss {'Reaction outcome loss': 0.19625935033269104, 'Total loss': 0.19625935033269104}
2022-12-05 20:54:05,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:05,811 INFO:     Epoch: 28
2022-12-05 20:54:06,596 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43427942675906556, 'Total loss': 0.43427942675906556} | train loss {'Reaction outcome loss': 0.19394914747872313, 'Total loss': 0.19394914747872313}
2022-12-05 20:54:06,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:06,596 INFO:     Epoch: 29
2022-12-05 20:54:07,382 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4132012619182121, 'Total loss': 0.4132012619182121} | train loss {'Reaction outcome loss': 0.1909428509104936, 'Total loss': 0.1909428509104936}
2022-12-05 20:54:07,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:07,382 INFO:     Epoch: 30
2022-12-05 20:54:08,168 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41287250019783195, 'Total loss': 0.41287250019783195} | train loss {'Reaction outcome loss': 0.1848366711380296, 'Total loss': 0.1848366711380296}
2022-12-05 20:54:08,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:08,169 INFO:     Epoch: 31
2022-12-05 20:54:08,952 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42094227151815283, 'Total loss': 0.42094227151815283} | train loss {'Reaction outcome loss': 0.1862825202129659, 'Total loss': 0.1862825202129659}
2022-12-05 20:54:08,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:08,952 INFO:     Epoch: 32
2022-12-05 20:54:09,735 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43702808230422263, 'Total loss': 0.43702808230422263} | train loss {'Reaction outcome loss': 0.18067629772742264, 'Total loss': 0.18067629772742264}
2022-12-05 20:54:09,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:09,736 INFO:     Epoch: 33
2022-12-05 20:54:10,519 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41801426819590637, 'Total loss': 0.41801426819590637} | train loss {'Reaction outcome loss': 0.17707837844786586, 'Total loss': 0.17707837844786586}
2022-12-05 20:54:10,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:10,520 INFO:     Epoch: 34
2022-12-05 20:54:11,306 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4241069939940475, 'Total loss': 0.4241069939940475} | train loss {'Reaction outcome loss': 0.1747032565515122, 'Total loss': 0.1747032565515122}
2022-12-05 20:54:11,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:11,306 INFO:     Epoch: 35
2022-12-05 20:54:12,098 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.422990259043006, 'Total loss': 0.422990259043006} | train loss {'Reaction outcome loss': 0.17472952903538455, 'Total loss': 0.17472952903538455}
2022-12-05 20:54:12,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:12,098 INFO:     Epoch: 36
2022-12-05 20:54:12,890 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42890538309895715, 'Total loss': 0.42890538309895715} | train loss {'Reaction outcome loss': 0.1693900235485835, 'Total loss': 0.1693900235485835}
2022-12-05 20:54:12,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:12,890 INFO:     Epoch: 37
2022-12-05 20:54:13,675 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44269335477851157, 'Total loss': 0.44269335477851157} | train loss {'Reaction outcome loss': 0.1675734601716404, 'Total loss': 0.1675734601716404}
2022-12-05 20:54:13,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:13,676 INFO:     Epoch: 38
2022-12-05 20:54:14,460 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4352553961581962, 'Total loss': 0.4352553961581962} | train loss {'Reaction outcome loss': 0.16552881539997752, 'Total loss': 0.16552881539997752}
2022-12-05 20:54:14,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:14,461 INFO:     Epoch: 39
2022-12-05 20:54:15,247 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.423999092606611, 'Total loss': 0.423999092606611} | train loss {'Reaction outcome loss': 0.16556747800472085, 'Total loss': 0.16556747800472085}
2022-12-05 20:54:15,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:15,248 INFO:     Epoch: 40
2022-12-05 20:54:16,032 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4367429276191911, 'Total loss': 0.4367429276191911} | train loss {'Reaction outcome loss': 0.1601200328651266, 'Total loss': 0.1601200328651266}
2022-12-05 20:54:16,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:16,032 INFO:     Epoch: 41
2022-12-05 20:54:16,815 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4235029709200526, 'Total loss': 0.4235029709200526} | train loss {'Reaction outcome loss': 0.1631358533822855, 'Total loss': 0.1631358533822855}
2022-12-05 20:54:16,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:16,816 INFO:     Epoch: 42
2022-12-05 20:54:17,598 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4308692151030829, 'Total loss': 0.4308692151030829} | train loss {'Reaction outcome loss': 0.15909159588093152, 'Total loss': 0.15909159588093152}
2022-12-05 20:54:17,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:17,599 INFO:     Epoch: 43
2022-12-05 20:54:18,384 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43970229909863584, 'Total loss': 0.43970229909863584} | train loss {'Reaction outcome loss': 0.15774835772873436, 'Total loss': 0.15774835772873436}
2022-12-05 20:54:18,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:18,384 INFO:     Epoch: 44
2022-12-05 20:54:19,174 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4395053501045981, 'Total loss': 0.4395053501045981} | train loss {'Reaction outcome loss': 0.1559865270191651, 'Total loss': 0.1559865270191651}
2022-12-05 20:54:19,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:19,174 INFO:     Epoch: 45
2022-12-05 20:54:19,957 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43515934344641, 'Total loss': 0.43515934344641} | train loss {'Reaction outcome loss': 0.15503208591129447, 'Total loss': 0.15503208591129447}
2022-12-05 20:54:19,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:19,958 INFO:     Epoch: 46
2022-12-05 20:54:20,744 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46594788809848386, 'Total loss': 0.46594788809848386} | train loss {'Reaction outcome loss': 0.15606137507091292, 'Total loss': 0.15606137507091292}
2022-12-05 20:54:20,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:20,745 INFO:     Epoch: 47
2022-12-05 20:54:21,538 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44135063886642456, 'Total loss': 0.44135063886642456} | train loss {'Reaction outcome loss': 0.15213925489148156, 'Total loss': 0.15213925489148156}
2022-12-05 20:54:21,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:21,538 INFO:     Epoch: 48
2022-12-05 20:54:22,324 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4360048195650411, 'Total loss': 0.4360048195650411} | train loss {'Reaction outcome loss': 0.15118997229538003, 'Total loss': 0.15118997229538003}
2022-12-05 20:54:22,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:22,324 INFO:     Epoch: 49
2022-12-05 20:54:23,109 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42920101485973183, 'Total loss': 0.42920101485973183} | train loss {'Reaction outcome loss': 0.14973362810054763, 'Total loss': 0.14973362810054763}
2022-12-05 20:54:23,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:23,109 INFO:     Epoch: 50
2022-12-05 20:54:23,895 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44836623377578205, 'Total loss': 0.44836623377578205} | train loss {'Reaction outcome loss': 0.14891695285780873, 'Total loss': 0.14891695285780873}
2022-12-05 20:54:23,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:23,896 INFO:     Epoch: 51
2022-12-05 20:54:24,679 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4427421792995098, 'Total loss': 0.4427421792995098} | train loss {'Reaction outcome loss': 0.14817841244922553, 'Total loss': 0.14817841244922553}
2022-12-05 20:54:24,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:24,679 INFO:     Epoch: 52
2022-12-05 20:54:25,465 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43395927305831467, 'Total loss': 0.43395927305831467} | train loss {'Reaction outcome loss': 0.14861928840305227, 'Total loss': 0.14861928840305227}
2022-12-05 20:54:25,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:25,466 INFO:     Epoch: 53
2022-12-05 20:54:26,259 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43736077914404314, 'Total loss': 0.43736077914404314} | train loss {'Reaction outcome loss': 0.14721337145530297, 'Total loss': 0.14721337145530297}
2022-12-05 20:54:26,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:26,259 INFO:     Epoch: 54
2022-12-05 20:54:27,044 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43883117756178214, 'Total loss': 0.43883117756178214} | train loss {'Reaction outcome loss': 0.14648941127186427, 'Total loss': 0.14648941127186427}
2022-12-05 20:54:27,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:27,045 INFO:     Epoch: 55
2022-12-05 20:54:27,833 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.433869301926258, 'Total loss': 0.433869301926258} | train loss {'Reaction outcome loss': 0.14162610155209654, 'Total loss': 0.14162610155209654}
2022-12-05 20:54:27,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:27,833 INFO:     Epoch: 56
2022-12-05 20:54:28,617 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42863678654959037, 'Total loss': 0.42863678654959037} | train loss {'Reaction outcome loss': 0.14018134331162713, 'Total loss': 0.14018134331162713}
2022-12-05 20:54:28,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:28,618 INFO:     Epoch: 57
2022-12-05 20:54:29,404 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4395628744779631, 'Total loss': 0.4395628744779631} | train loss {'Reaction outcome loss': 0.1402302485028068, 'Total loss': 0.1402302485028068}
2022-12-05 20:54:29,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:29,405 INFO:     Epoch: 58
2022-12-05 20:54:30,187 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4387091904185539, 'Total loss': 0.4387091904185539} | train loss {'Reaction outcome loss': 0.1397026974600969, 'Total loss': 0.1397026974600969}
2022-12-05 20:54:30,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:30,188 INFO:     Epoch: 59
2022-12-05 20:54:30,975 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44620271113722826, 'Total loss': 0.44620271113722826} | train loss {'Reaction outcome loss': 0.1431853311350111, 'Total loss': 0.1431853311350111}
2022-12-05 20:54:30,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:30,975 INFO:     Epoch: 60
2022-12-05 20:54:31,763 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44111082893471387, 'Total loss': 0.44111082893471387} | train loss {'Reaction outcome loss': 0.1388307569823304, 'Total loss': 0.1388307569823304}
2022-12-05 20:54:31,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:31,763 INFO:     Epoch: 61
2022-12-05 20:54:32,549 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43708065152168274, 'Total loss': 0.43708065152168274} | train loss {'Reaction outcome loss': 0.13805565887634627, 'Total loss': 0.13805565887634627}
2022-12-05 20:54:32,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:32,550 INFO:     Epoch: 62
2022-12-05 20:54:33,334 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43818125475284664, 'Total loss': 0.43818125475284664} | train loss {'Reaction outcome loss': 0.1357554113187018, 'Total loss': 0.1357554113187018}
2022-12-05 20:54:33,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:33,334 INFO:     Epoch: 63
2022-12-05 20:54:34,120 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43296437901119855, 'Total loss': 0.43296437901119855} | train loss {'Reaction outcome loss': 0.1339765735062175, 'Total loss': 0.1339765735062175}
2022-12-05 20:54:34,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:34,120 INFO:     Epoch: 64
2022-12-05 20:54:34,903 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.432779005793638, 'Total loss': 0.432779005793638} | train loss {'Reaction outcome loss': 0.13697582616882978, 'Total loss': 0.13697582616882978}
2022-12-05 20:54:34,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:34,903 INFO:     Epoch: 65
2022-12-05 20:54:35,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4379242450691933, 'Total loss': 0.4379242450691933} | train loss {'Reaction outcome loss': 0.1359261898934597, 'Total loss': 0.1359261898934597}
2022-12-05 20:54:35,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:35,690 INFO:     Epoch: 66
2022-12-05 20:54:36,476 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4279862676942071, 'Total loss': 0.4279862676942071} | train loss {'Reaction outcome loss': 0.1360471366721465, 'Total loss': 0.1360471366721465}
2022-12-05 20:54:36,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:36,477 INFO:     Epoch: 67
2022-12-05 20:54:37,259 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44746571605981783, 'Total loss': 0.44746571605981783} | train loss {'Reaction outcome loss': 0.1311665824843479, 'Total loss': 0.1311665824843479}
2022-12-05 20:54:37,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:37,259 INFO:     Epoch: 68
2022-12-05 20:54:38,041 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4287249134030453, 'Total loss': 0.4287249134030453} | train loss {'Reaction outcome loss': 0.1351863572709873, 'Total loss': 0.1351863572709873}
2022-12-05 20:54:38,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:38,041 INFO:     Epoch: 69
2022-12-05 20:54:38,826 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43076280695061353, 'Total loss': 0.43076280695061353} | train loss {'Reaction outcome loss': 0.13285982838953983, 'Total loss': 0.13285982838953983}
2022-12-05 20:54:38,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:38,827 INFO:     Epoch: 70
2022-12-05 20:54:39,611 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44469494667164117, 'Total loss': 0.44469494667164117} | train loss {'Reaction outcome loss': 0.13017865969631515, 'Total loss': 0.13017865969631515}
2022-12-05 20:54:39,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:39,611 INFO:     Epoch: 71
2022-12-05 20:54:40,393 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43617324357809023, 'Total loss': 0.43617324357809023} | train loss {'Reaction outcome loss': 0.12929863571265682, 'Total loss': 0.12929863571265682}
2022-12-05 20:54:40,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:40,393 INFO:     Epoch: 72
2022-12-05 20:54:41,177 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4401758230009744, 'Total loss': 0.4401758230009744} | train loss {'Reaction outcome loss': 0.1341293003738354, 'Total loss': 0.1341293003738354}
2022-12-05 20:54:41,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:41,178 INFO:     Epoch: 73
2022-12-05 20:54:41,966 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43148057769204295, 'Total loss': 0.43148057769204295} | train loss {'Reaction outcome loss': 0.1310703706942865, 'Total loss': 0.1310703706942865}
2022-12-05 20:54:41,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:41,966 INFO:     Epoch: 74
2022-12-05 20:54:42,749 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4464575131965238, 'Total loss': 0.4464575131965238} | train loss {'Reaction outcome loss': 0.12755075745956332, 'Total loss': 0.12755075745956332}
2022-12-05 20:54:42,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:42,749 INFO:     Epoch: 75
2022-12-05 20:54:43,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45152300821487296, 'Total loss': 0.45152300821487296} | train loss {'Reaction outcome loss': 0.12729813900898349, 'Total loss': 0.12729813900898349}
2022-12-05 20:54:43,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:43,531 INFO:     Epoch: 76
2022-12-05 20:54:44,314 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4504902442527372, 'Total loss': 0.4504902442527372} | train loss {'Reaction outcome loss': 0.12794088784101434, 'Total loss': 0.12794088784101434}
2022-12-05 20:54:44,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:44,314 INFO:     Epoch: 77
2022-12-05 20:54:45,091 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4297936725061993, 'Total loss': 0.4297936725061993} | train loss {'Reaction outcome loss': 0.13050897404948464, 'Total loss': 0.13050897404948464}
2022-12-05 20:54:45,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:45,091 INFO:     Epoch: 78
2022-12-05 20:54:45,874 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4315922852865485, 'Total loss': 0.4315922852865485} | train loss {'Reaction outcome loss': 0.12854810458317886, 'Total loss': 0.12854810458317886}
2022-12-05 20:54:45,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:45,874 INFO:     Epoch: 79
2022-12-05 20:54:46,659 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4349478594092436, 'Total loss': 0.4349478594092436} | train loss {'Reaction outcome loss': 0.12727961944011573, 'Total loss': 0.12727961944011573}
2022-12-05 20:54:46,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:46,659 INFO:     Epoch: 80
2022-12-05 20:54:47,436 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4323008264913115, 'Total loss': 0.4323008264913115} | train loss {'Reaction outcome loss': 0.1249518215343295, 'Total loss': 0.1249518215343295}
2022-12-05 20:54:47,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:47,436 INFO:     Epoch: 81
2022-12-05 20:54:48,212 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4437786202098048, 'Total loss': 0.4437786202098048} | train loss {'Reaction outcome loss': 0.12851347694494075, 'Total loss': 0.12851347694494075}
2022-12-05 20:54:48,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:48,213 INFO:     Epoch: 82
2022-12-05 20:54:48,990 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4435130503288535, 'Total loss': 0.4435130503288535} | train loss {'Reaction outcome loss': 0.12583748782511617, 'Total loss': 0.12583748782511617}
2022-12-05 20:54:48,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:48,990 INFO:     Epoch: 83
2022-12-05 20:54:49,767 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43910717028518054, 'Total loss': 0.43910717028518054} | train loss {'Reaction outcome loss': 0.12509536950803193, 'Total loss': 0.12509536950803193}
2022-12-05 20:54:49,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:49,767 INFO:     Epoch: 84
2022-12-05 20:54:50,548 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4447658876346987, 'Total loss': 0.4447658876346987} | train loss {'Reaction outcome loss': 0.1255816465213162, 'Total loss': 0.1255816465213162}
2022-12-05 20:54:50,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:50,548 INFO:     Epoch: 85
2022-12-05 20:54:51,330 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4435990632966507, 'Total loss': 0.4435990632966507} | train loss {'Reaction outcome loss': 0.12109197462817319, 'Total loss': 0.12109197462817319}
2022-12-05 20:54:51,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:51,331 INFO:     Epoch: 86
2022-12-05 20:54:52,110 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4360188250971395, 'Total loss': 0.4360188250971395} | train loss {'Reaction outcome loss': 0.12432314798648118, 'Total loss': 0.12432314798648118}
2022-12-05 20:54:52,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:52,110 INFO:     Epoch: 87
2022-12-05 20:54:52,894 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4442910662917204, 'Total loss': 0.4442910662917204} | train loss {'Reaction outcome loss': 0.12434409488160468, 'Total loss': 0.12434409488160468}
2022-12-05 20:54:52,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:52,894 INFO:     Epoch: 88
2022-12-05 20:54:53,670 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4388287420882735, 'Total loss': 0.4388287420882735} | train loss {'Reaction outcome loss': 0.12494348079637914, 'Total loss': 0.12494348079637914}
2022-12-05 20:54:53,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:53,670 INFO:     Epoch: 89
2022-12-05 20:54:54,446 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4350603694139525, 'Total loss': 0.4350603694139525} | train loss {'Reaction outcome loss': 0.12297689012198358, 'Total loss': 0.12297689012198358}
2022-12-05 20:54:54,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:54,447 INFO:     Epoch: 90
2022-12-05 20:54:55,223 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44189672691877496, 'Total loss': 0.44189672691877496} | train loss {'Reaction outcome loss': 0.12094013060855328, 'Total loss': 0.12094013060855328}
2022-12-05 20:54:55,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:55,223 INFO:     Epoch: 91
2022-12-05 20:54:56,008 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44712924194890397, 'Total loss': 0.44712924194890397} | train loss {'Reaction outcome loss': 0.12235359392571644, 'Total loss': 0.12235359392571644}
2022-12-05 20:54:56,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:56,008 INFO:     Epoch: 92
2022-12-05 20:54:56,789 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43555625857308855, 'Total loss': 0.43555625857308855} | train loss {'Reaction outcome loss': 0.12375326878314868, 'Total loss': 0.12375326878314868}
2022-12-05 20:54:56,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:56,789 INFO:     Epoch: 93
2022-12-05 20:54:57,571 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43280243249826655, 'Total loss': 0.43280243249826655} | train loss {'Reaction outcome loss': 0.12102044852771109, 'Total loss': 0.12102044852771109}
2022-12-05 20:54:57,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:57,572 INFO:     Epoch: 94
2022-12-05 20:54:58,357 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45909773298474243, 'Total loss': 0.45909773298474243} | train loss {'Reaction outcome loss': 0.1219064247733379, 'Total loss': 0.1219064247733379}
2022-12-05 20:54:58,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:58,357 INFO:     Epoch: 95
2022-12-05 20:54:59,137 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42941446948883144, 'Total loss': 0.42941446948883144} | train loss {'Reaction outcome loss': 0.11834750300441242, 'Total loss': 0.11834750300441242}
2022-12-05 20:54:59,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:59,137 INFO:     Epoch: 96
2022-12-05 20:54:59,920 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44164820743161576, 'Total loss': 0.44164820743161576} | train loss {'Reaction outcome loss': 0.12101441513953089, 'Total loss': 0.12101441513953089}
2022-12-05 20:54:59,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:54:59,920 INFO:     Epoch: 97
2022-12-05 20:55:00,699 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4430096819996834, 'Total loss': 0.4430096819996834} | train loss {'Reaction outcome loss': 0.11993514146793206, 'Total loss': 0.11993514146793206}
2022-12-05 20:55:00,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:00,700 INFO:     Epoch: 98
2022-12-05 20:55:01,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4379155677418376, 'Total loss': 0.4379155677418376} | train loss {'Reaction outcome loss': 0.11980648347955258, 'Total loss': 0.11980648347955258}
2022-12-05 20:55:01,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:01,480 INFO:     Epoch: 99
2022-12-05 20:55:02,263 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43289551312147184, 'Total loss': 0.43289551312147184} | train loss {'Reaction outcome loss': 0.11945989400102588, 'Total loss': 0.11945989400102588}
2022-12-05 20:55:02,263 INFO:     Best model found after epoch 15 of 100.
2022-12-05 20:55:02,263 INFO:   Done with stage: TRAINING
2022-12-05 20:55:02,263 INFO:   Starting stage: EVALUATION
2022-12-05 20:55:02,400 INFO:   Done with stage: EVALUATION
2022-12-05 20:55:02,400 INFO:   Leaving out SEQ value Fold_1
2022-12-05 20:55:02,413 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:55:02,413 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:55:03,045 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:55:03,045 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:55:03,114 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:55:03,114 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:55:03,114 INFO:     No hyperparam tuning for this model
2022-12-05 20:55:03,114 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:55:03,114 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:55:03,115 INFO:     None feature selector for col prot
2022-12-05 20:55:03,115 INFO:     None feature selector for col prot
2022-12-05 20:55:03,115 INFO:     None feature selector for col prot
2022-12-05 20:55:03,116 INFO:     None feature selector for col chem
2022-12-05 20:55:03,116 INFO:     None feature selector for col chem
2022-12-05 20:55:03,116 INFO:     None feature selector for col chem
2022-12-05 20:55:03,116 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:55:03,116 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:55:03,118 INFO:     Number of params in model 215821
2022-12-05 20:55:03,121 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:55:03,121 INFO:   Starting stage: TRAINING
2022-12-05 20:55:03,180 INFO:     Val loss before train {'Reaction outcome loss': 0.9772748070007021, 'Total loss': 0.9772748070007021}
2022-12-05 20:55:03,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:03,180 INFO:     Epoch: 0
2022-12-05 20:55:03,961 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.611141555688598, 'Total loss': 0.611141555688598} | train loss {'Reaction outcome loss': 0.8072031607433241, 'Total loss': 0.8072031607433241}
2022-12-05 20:55:03,962 INFO:     Found new best model at epoch 0
2022-12-05 20:55:03,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:03,963 INFO:     Epoch: 1
2022-12-05 20:55:04,743 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5211418809538538, 'Total loss': 0.5211418809538538} | train loss {'Reaction outcome loss': 0.5507515240688713, 'Total loss': 0.5507515240688713}
2022-12-05 20:55:04,743 INFO:     Found new best model at epoch 1
2022-12-05 20:55:04,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:04,744 INFO:     Epoch: 2
2022-12-05 20:55:05,528 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4886730428446423, 'Total loss': 0.4886730428446423} | train loss {'Reaction outcome loss': 0.4795583662938099, 'Total loss': 0.4795583662938099}
2022-12-05 20:55:05,528 INFO:     Found new best model at epoch 2
2022-12-05 20:55:05,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:05,529 INFO:     Epoch: 3
2022-12-05 20:55:06,313 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46507443860173225, 'Total loss': 0.46507443860173225} | train loss {'Reaction outcome loss': 0.4380086946244143, 'Total loss': 0.4380086946244143}
2022-12-05 20:55:06,314 INFO:     Found new best model at epoch 3
2022-12-05 20:55:06,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:06,315 INFO:     Epoch: 4
2022-12-05 20:55:07,099 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4579306346448985, 'Total loss': 0.4579306346448985} | train loss {'Reaction outcome loss': 0.4111747992282011, 'Total loss': 0.4111747992282011}
2022-12-05 20:55:07,100 INFO:     Found new best model at epoch 4
2022-12-05 20:55:07,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:07,100 INFO:     Epoch: 5
2022-12-05 20:55:07,886 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44281989403746347, 'Total loss': 0.44281989403746347} | train loss {'Reaction outcome loss': 0.38450565015783117, 'Total loss': 0.38450565015783117}
2022-12-05 20:55:07,886 INFO:     Found new best model at epoch 5
2022-12-05 20:55:07,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:07,887 INFO:     Epoch: 6
2022-12-05 20:55:08,670 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42677622965791007, 'Total loss': 0.42677622965791007} | train loss {'Reaction outcome loss': 0.3657189022065425, 'Total loss': 0.3657189022065425}
2022-12-05 20:55:08,670 INFO:     Found new best model at epoch 6
2022-12-05 20:55:08,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:08,671 INFO:     Epoch: 7
2022-12-05 20:55:09,459 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4329375926066529, 'Total loss': 0.4329375926066529} | train loss {'Reaction outcome loss': 0.34471021480098063, 'Total loss': 0.34471021480098063}
2022-12-05 20:55:09,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:09,459 INFO:     Epoch: 8
2022-12-05 20:55:10,241 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43247143348509615, 'Total loss': 0.43247143348509615} | train loss {'Reaction outcome loss': 0.3291971509858054, 'Total loss': 0.3291971509858054}
2022-12-05 20:55:10,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:10,242 INFO:     Epoch: 9
2022-12-05 20:55:11,033 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4214338318190791, 'Total loss': 0.4214338318190791} | train loss {'Reaction outcome loss': 0.311751029062636, 'Total loss': 0.311751029062636}
2022-12-05 20:55:11,033 INFO:     Found new best model at epoch 9
2022-12-05 20:55:11,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:11,034 INFO:     Epoch: 10
2022-12-05 20:55:11,815 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41419838639822876, 'Total loss': 0.41419838639822876} | train loss {'Reaction outcome loss': 0.2983510633512419, 'Total loss': 0.2983510633512419}
2022-12-05 20:55:11,815 INFO:     Found new best model at epoch 10
2022-12-05 20:55:11,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:11,816 INFO:     Epoch: 11
2022-12-05 20:55:12,598 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40981920809082856, 'Total loss': 0.40981920809082856} | train loss {'Reaction outcome loss': 0.2872450207265056, 'Total loss': 0.2872450207265056}
2022-12-05 20:55:12,598 INFO:     Found new best model at epoch 11
2022-12-05 20:55:12,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:12,599 INFO:     Epoch: 12
2022-12-05 20:55:13,389 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40904428132555704, 'Total loss': 0.40904428132555704} | train loss {'Reaction outcome loss': 0.2771369669510394, 'Total loss': 0.2771369669510394}
2022-12-05 20:55:13,389 INFO:     Found new best model at epoch 12
2022-12-05 20:55:13,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:13,390 INFO:     Epoch: 13
2022-12-05 20:55:14,173 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4089528491551226, 'Total loss': 0.4089528491551226} | train loss {'Reaction outcome loss': 0.26621816342278404, 'Total loss': 0.26621816342278404}
2022-12-05 20:55:14,173 INFO:     Found new best model at epoch 13
2022-12-05 20:55:14,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:14,174 INFO:     Epoch: 14
2022-12-05 20:55:14,965 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40769908644936304, 'Total loss': 0.40769908644936304} | train loss {'Reaction outcome loss': 0.2576978090618338, 'Total loss': 0.2576978090618338}
2022-12-05 20:55:14,965 INFO:     Found new best model at epoch 14
2022-12-05 20:55:14,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:14,966 INFO:     Epoch: 15
2022-12-05 20:55:15,751 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4268195701932365, 'Total loss': 0.4268195701932365} | train loss {'Reaction outcome loss': 0.24960316786048364, 'Total loss': 0.24960316786048364}
2022-12-05 20:55:15,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:15,751 INFO:     Epoch: 16
2022-12-05 20:55:16,531 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39858992330052634, 'Total loss': 0.39858992330052634} | train loss {'Reaction outcome loss': 0.2408813829932894, 'Total loss': 0.2408813829932894}
2022-12-05 20:55:16,531 INFO:     Found new best model at epoch 16
2022-12-05 20:55:16,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:16,532 INFO:     Epoch: 17
2022-12-05 20:55:17,313 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4271034547551112, 'Total loss': 0.4271034547551112} | train loss {'Reaction outcome loss': 0.237053268980615, 'Total loss': 0.237053268980615}
2022-12-05 20:55:17,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:17,313 INFO:     Epoch: 18
2022-12-05 20:55:18,098 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4149373893372037, 'Total loss': 0.4149373893372037} | train loss {'Reaction outcome loss': 0.23115382078959018, 'Total loss': 0.23115382078959018}
2022-12-05 20:55:18,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:18,098 INFO:     Epoch: 19
2022-12-05 20:55:18,881 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4225058186460625, 'Total loss': 0.4225058186460625} | train loss {'Reaction outcome loss': 0.22562619523734462, 'Total loss': 0.22562619523734462}
2022-12-05 20:55:18,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:18,881 INFO:     Epoch: 20
2022-12-05 20:55:19,671 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4099049131301316, 'Total loss': 0.4099049131301316} | train loss {'Reaction outcome loss': 0.22178064720058926, 'Total loss': 0.22178064720058926}
2022-12-05 20:55:19,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:19,671 INFO:     Epoch: 21
2022-12-05 20:55:20,458 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41054351010825485, 'Total loss': 0.41054351010825485} | train loss {'Reaction outcome loss': 0.21282376993675622, 'Total loss': 0.21282376993675622}
2022-12-05 20:55:20,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:20,458 INFO:     Epoch: 22
2022-12-05 20:55:21,246 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42660244181752205, 'Total loss': 0.42660244181752205} | train loss {'Reaction outcome loss': 0.20994701186309056, 'Total loss': 0.20994701186309056}
2022-12-05 20:55:21,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:21,246 INFO:     Epoch: 23
2022-12-05 20:55:22,035 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4282420165836811, 'Total loss': 0.4282420165836811} | train loss {'Reaction outcome loss': 0.2033727615159385, 'Total loss': 0.2033727615159385}
2022-12-05 20:55:22,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:22,035 INFO:     Epoch: 24
2022-12-05 20:55:22,818 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4206056628714908, 'Total loss': 0.4206056628714908} | train loss {'Reaction outcome loss': 0.2034270592033863, 'Total loss': 0.2034270592033863}
2022-12-05 20:55:22,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:22,819 INFO:     Epoch: 25
2022-12-05 20:55:23,600 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42091572318564763, 'Total loss': 0.42091572318564763} | train loss {'Reaction outcome loss': 0.19678639269300868, 'Total loss': 0.19678639269300868}
2022-12-05 20:55:23,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:23,601 INFO:     Epoch: 26
2022-12-05 20:55:24,385 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42015998539599503, 'Total loss': 0.42015998539599503} | train loss {'Reaction outcome loss': 0.19115290547512015, 'Total loss': 0.19115290547512015}
2022-12-05 20:55:24,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:24,385 INFO:     Epoch: 27
2022-12-05 20:55:25,170 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43996829370206053, 'Total loss': 0.43996829370206053} | train loss {'Reaction outcome loss': 0.19047347167316747, 'Total loss': 0.19047347167316747}
2022-12-05 20:55:25,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:25,171 INFO:     Epoch: 28
2022-12-05 20:55:25,952 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4343001019548286, 'Total loss': 0.4343001019548286} | train loss {'Reaction outcome loss': 0.185262783517947, 'Total loss': 0.185262783517947}
2022-12-05 20:55:25,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:25,953 INFO:     Epoch: 29
2022-12-05 20:55:26,737 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4476384998045184, 'Total loss': 0.4476384998045184} | train loss {'Reaction outcome loss': 0.18360398147179155, 'Total loss': 0.18360398147179155}
2022-12-05 20:55:26,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:26,738 INFO:     Epoch: 30
2022-12-05 20:55:27,522 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4234026406298984, 'Total loss': 0.4234026406298984} | train loss {'Reaction outcome loss': 0.18205490739521932, 'Total loss': 0.18205490739521932}
2022-12-05 20:55:27,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:27,522 INFO:     Epoch: 31
2022-12-05 20:55:28,308 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.420120418579741, 'Total loss': 0.420120418579741} | train loss {'Reaction outcome loss': 0.17654386144511552, 'Total loss': 0.17654386144511552}
2022-12-05 20:55:28,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:28,308 INFO:     Epoch: 32
2022-12-05 20:55:29,093 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42526193064722145, 'Total loss': 0.42526193064722145} | train loss {'Reaction outcome loss': 0.1760123741908037, 'Total loss': 0.1760123741908037}
2022-12-05 20:55:29,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:29,093 INFO:     Epoch: 33
2022-12-05 20:55:29,882 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4293855804611336, 'Total loss': 0.4293855804611336} | train loss {'Reaction outcome loss': 0.17286208418711108, 'Total loss': 0.17286208418711108}
2022-12-05 20:55:29,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:29,882 INFO:     Epoch: 34
2022-12-05 20:55:30,667 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4172191812910817, 'Total loss': 0.4172191812910817} | train loss {'Reaction outcome loss': 0.169352946673729, 'Total loss': 0.169352946673729}
2022-12-05 20:55:30,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:30,667 INFO:     Epoch: 35
2022-12-05 20:55:31,452 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4194095488637686, 'Total loss': 0.4194095488637686} | train loss {'Reaction outcome loss': 0.16724259600955613, 'Total loss': 0.16724259600955613}
2022-12-05 20:55:31,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:31,452 INFO:     Epoch: 36
2022-12-05 20:55:32,238 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4077946148304777, 'Total loss': 0.4077946148304777} | train loss {'Reaction outcome loss': 0.16793165420543174, 'Total loss': 0.16793165420543174}
2022-12-05 20:55:32,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:32,238 INFO:     Epoch: 37
2022-12-05 20:55:33,019 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4670396755364808, 'Total loss': 0.4670396755364808} | train loss {'Reaction outcome loss': 0.168136430721806, 'Total loss': 0.168136430721806}
2022-12-05 20:55:33,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:33,019 INFO:     Epoch: 38
2022-12-05 20:55:33,803 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43633489073677495, 'Total loss': 0.43633489073677495} | train loss {'Reaction outcome loss': 0.1612414409083371, 'Total loss': 0.1612414409083371}
2022-12-05 20:55:33,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:33,803 INFO:     Epoch: 39
2022-12-05 20:55:34,589 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4179718890650706, 'Total loss': 0.4179718890650706} | train loss {'Reaction outcome loss': 0.16101955180721625, 'Total loss': 0.16101955180721625}
2022-12-05 20:55:34,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:34,590 INFO:     Epoch: 40
2022-12-05 20:55:35,375 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40083820914680307, 'Total loss': 0.40083820914680307} | train loss {'Reaction outcome loss': 0.15990767180159385, 'Total loss': 0.15990767180159385}
2022-12-05 20:55:35,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:35,376 INFO:     Epoch: 41
2022-12-05 20:55:36,161 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4239571483975107, 'Total loss': 0.4239571483975107} | train loss {'Reaction outcome loss': 0.15686184660512573, 'Total loss': 0.15686184660512573}
2022-12-05 20:55:36,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:36,162 INFO:     Epoch: 42
2022-12-05 20:55:36,955 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43159770288250665, 'Total loss': 0.43159770288250665} | train loss {'Reaction outcome loss': 0.15460193833830405, 'Total loss': 0.15460193833830405}
2022-12-05 20:55:36,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:36,955 INFO:     Epoch: 43
2022-12-05 20:55:37,750 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42823055826804857, 'Total loss': 0.42823055826804857} | train loss {'Reaction outcome loss': 0.1539099675736257, 'Total loss': 0.1539099675736257}
2022-12-05 20:55:37,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:37,750 INFO:     Epoch: 44
2022-12-05 20:55:38,541 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4137270083989609, 'Total loss': 0.4137270083989609} | train loss {'Reaction outcome loss': 0.15228782885384803, 'Total loss': 0.15228782885384803}
2022-12-05 20:55:38,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:38,541 INFO:     Epoch: 45
2022-12-05 20:55:39,338 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.406690022400157, 'Total loss': 0.406690022400157} | train loss {'Reaction outcome loss': 0.15347108130096174, 'Total loss': 0.15347108130096174}
2022-12-05 20:55:39,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:39,339 INFO:     Epoch: 46
2022-12-05 20:55:40,130 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.412646577947519, 'Total loss': 0.412646577947519} | train loss {'Reaction outcome loss': 0.14895203600884702, 'Total loss': 0.14895203600884702}
2022-12-05 20:55:40,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:40,130 INFO:     Epoch: 47
2022-12-05 20:55:40,922 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40072014030407777, 'Total loss': 0.40072014030407777} | train loss {'Reaction outcome loss': 0.14725534814048785, 'Total loss': 0.14725534814048785}
2022-12-05 20:55:40,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:40,923 INFO:     Epoch: 48
2022-12-05 20:55:41,720 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42392194880680606, 'Total loss': 0.42392194880680606} | train loss {'Reaction outcome loss': 0.14745268992775556, 'Total loss': 0.14745268992775556}
2022-12-05 20:55:41,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:41,721 INFO:     Epoch: 49
2022-12-05 20:55:42,521 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4190238077532161, 'Total loss': 0.4190238077532161} | train loss {'Reaction outcome loss': 0.1474484479092822, 'Total loss': 0.1474484479092822}
2022-12-05 20:55:42,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:42,521 INFO:     Epoch: 50
2022-12-05 20:55:43,314 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4173515069891106, 'Total loss': 0.4173515069891106} | train loss {'Reaction outcome loss': 0.14314038804827295, 'Total loss': 0.14314038804827295}
2022-12-05 20:55:43,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:43,315 INFO:     Epoch: 51
2022-12-05 20:55:44,108 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42008950730616396, 'Total loss': 0.42008950730616396} | train loss {'Reaction outcome loss': 0.14301555683950382, 'Total loss': 0.14301555683950382}
2022-12-05 20:55:44,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:44,108 INFO:     Epoch: 52
2022-12-05 20:55:44,899 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4235976272347299, 'Total loss': 0.4235976272347299} | train loss {'Reaction outcome loss': 0.1423441289296868, 'Total loss': 0.1423441289296868}
2022-12-05 20:55:44,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:44,899 INFO:     Epoch: 53
2022-12-05 20:55:45,690 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41071068072183564, 'Total loss': 0.41071068072183564} | train loss {'Reaction outcome loss': 0.14435007662645408, 'Total loss': 0.14435007662645408}
2022-12-05 20:55:45,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:45,690 INFO:     Epoch: 54
2022-12-05 20:55:46,486 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4338325018232519, 'Total loss': 0.4338325018232519} | train loss {'Reaction outcome loss': 0.13887121227702925, 'Total loss': 0.13887121227702925}
2022-12-05 20:55:46,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:46,486 INFO:     Epoch: 55
2022-12-05 20:55:47,278 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42573134431784804, 'Total loss': 0.42573134431784804} | train loss {'Reaction outcome loss': 0.13977412535827988, 'Total loss': 0.13977412535827988}
2022-12-05 20:55:47,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:47,278 INFO:     Epoch: 56
2022-12-05 20:55:48,071 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43974155170673673, 'Total loss': 0.43974155170673673} | train loss {'Reaction outcome loss': 0.1390197493135929, 'Total loss': 0.1390197493135929}
2022-12-05 20:55:48,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:48,071 INFO:     Epoch: 57
2022-12-05 20:55:48,862 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41375280802392145, 'Total loss': 0.41375280802392145} | train loss {'Reaction outcome loss': 0.13773021126280025, 'Total loss': 0.13773021126280025}
2022-12-05 20:55:48,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:48,862 INFO:     Epoch: 58
2022-12-05 20:55:49,649 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43177687512202695, 'Total loss': 0.43177687512202695} | train loss {'Reaction outcome loss': 0.1333057372697762, 'Total loss': 0.1333057372697762}
2022-12-05 20:55:49,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:49,649 INFO:     Epoch: 59
2022-12-05 20:55:50,440 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4116127585822886, 'Total loss': 0.4116127585822886} | train loss {'Reaction outcome loss': 0.13917562167863456, 'Total loss': 0.13917562167863456}
2022-12-05 20:55:50,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:50,440 INFO:     Epoch: 60
2022-12-05 20:55:51,232 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.424988885156133, 'Total loss': 0.424988885156133} | train loss {'Reaction outcome loss': 0.13446169318821358, 'Total loss': 0.13446169318821358}
2022-12-05 20:55:51,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:51,233 INFO:     Epoch: 61
2022-12-05 20:55:52,020 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42299742895093834, 'Total loss': 0.42299742895093834} | train loss {'Reaction outcome loss': 0.13330820173557315, 'Total loss': 0.13330820173557315}
2022-12-05 20:55:52,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:52,021 INFO:     Epoch: 62
2022-12-05 20:55:52,811 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4165360928428444, 'Total loss': 0.4165360928428444} | train loss {'Reaction outcome loss': 0.133047337305485, 'Total loss': 0.133047337305485}
2022-12-05 20:55:52,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:52,811 INFO:     Epoch: 63
2022-12-05 20:55:53,605 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42913657596165483, 'Total loss': 0.42913657596165483} | train loss {'Reaction outcome loss': 0.13406542405790212, 'Total loss': 0.13406542405790212}
2022-12-05 20:55:53,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:53,605 INFO:     Epoch: 64
2022-12-05 20:55:54,402 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42646601355888625, 'Total loss': 0.42646601355888625} | train loss {'Reaction outcome loss': 0.1333257630277349, 'Total loss': 0.1333257630277349}
2022-12-05 20:55:54,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:54,403 INFO:     Epoch: 65
2022-12-05 20:55:55,200 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42278720675544307, 'Total loss': 0.42278720675544307} | train loss {'Reaction outcome loss': 0.13125591315329074, 'Total loss': 0.13125591315329074}
2022-12-05 20:55:55,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:55,200 INFO:     Epoch: 66
2022-12-05 20:55:55,997 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4372757344760678, 'Total loss': 0.4372757344760678} | train loss {'Reaction outcome loss': 0.13151024096474356, 'Total loss': 0.13151024096474356}
2022-12-05 20:55:55,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:55,998 INFO:     Epoch: 67
2022-12-05 20:55:56,790 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47162139043211937, 'Total loss': 0.47162139043211937} | train loss {'Reaction outcome loss': 0.12822154835626787, 'Total loss': 0.12822154835626787}
2022-12-05 20:55:56,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:56,791 INFO:     Epoch: 68
2022-12-05 20:55:57,588 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.434309376234358, 'Total loss': 0.434309376234358} | train loss {'Reaction outcome loss': 0.13160833922043746, 'Total loss': 0.13160833922043746}
2022-12-05 20:55:57,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:57,588 INFO:     Epoch: 69
2022-12-05 20:55:58,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42540238526734436, 'Total loss': 0.42540238526734436} | train loss {'Reaction outcome loss': 0.12828045508691244, 'Total loss': 0.12828045508691244}
2022-12-05 20:55:58,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:58,383 INFO:     Epoch: 70
2022-12-05 20:55:59,179 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4352374110709537, 'Total loss': 0.4352374110709537} | train loss {'Reaction outcome loss': 0.12896351980007426, 'Total loss': 0.12896351980007426}
2022-12-05 20:55:59,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:59,179 INFO:     Epoch: 71
2022-12-05 20:55:59,980 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4180958851833235, 'Total loss': 0.4180958851833235} | train loss {'Reaction outcome loss': 0.12911502218672208, 'Total loss': 0.12911502218672208}
2022-12-05 20:55:59,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:55:59,980 INFO:     Epoch: 72
2022-12-05 20:56:00,774 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43313581361012027, 'Total loss': 0.43313581361012027} | train loss {'Reaction outcome loss': 0.12878693866410426, 'Total loss': 0.12878693866410426}
2022-12-05 20:56:00,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:00,774 INFO:     Epoch: 73
2022-12-05 20:56:01,578 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41722479852085764, 'Total loss': 0.41722479852085764} | train loss {'Reaction outcome loss': 0.12615423251931765, 'Total loss': 0.12615423251931765}
2022-12-05 20:56:01,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:01,578 INFO:     Epoch: 74
2022-12-05 20:56:02,374 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40832439928569575, 'Total loss': 0.40832439928569575} | train loss {'Reaction outcome loss': 0.12640148874904428, 'Total loss': 0.12640148874904428}
2022-12-05 20:56:02,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:02,375 INFO:     Epoch: 75
2022-12-05 20:56:03,171 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43181435425173154, 'Total loss': 0.43181435425173154} | train loss {'Reaction outcome loss': 0.12748881376975654, 'Total loss': 0.12748881376975654}
2022-12-05 20:56:03,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:03,171 INFO:     Epoch: 76
2022-12-05 20:56:03,968 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4197052912786603, 'Total loss': 0.4197052912786603} | train loss {'Reaction outcome loss': 0.12576758400822172, 'Total loss': 0.12576758400822172}
2022-12-05 20:56:03,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:03,968 INFO:     Epoch: 77
2022-12-05 20:56:04,769 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42873480230231176, 'Total loss': 0.42873480230231176} | train loss {'Reaction outcome loss': 0.12495357023970205, 'Total loss': 0.12495357023970205}
2022-12-05 20:56:04,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:04,769 INFO:     Epoch: 78
2022-12-05 20:56:05,565 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4270454572344368, 'Total loss': 0.4270454572344368} | train loss {'Reaction outcome loss': 0.12752376228799017, 'Total loss': 0.12752376228799017}
2022-12-05 20:56:05,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:05,565 INFO:     Epoch: 79
2022-12-05 20:56:06,361 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4351367682895877, 'Total loss': 0.4351367682895877} | train loss {'Reaction outcome loss': 0.12592860212055396, 'Total loss': 0.12592860212055396}
2022-12-05 20:56:06,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:06,362 INFO:     Epoch: 80
2022-12-05 20:56:07,164 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4435544667596167, 'Total loss': 0.4435544667596167} | train loss {'Reaction outcome loss': 0.1231541247088082, 'Total loss': 0.1231541247088082}
2022-12-05 20:56:07,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:07,164 INFO:     Epoch: 81
2022-12-05 20:56:07,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44888991422273894, 'Total loss': 0.44888991422273894} | train loss {'Reaction outcome loss': 0.12110636700324866, 'Total loss': 0.12110636700324866}
2022-12-05 20:56:07,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:07,961 INFO:     Epoch: 82
2022-12-05 20:56:08,760 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42185148190368305, 'Total loss': 0.42185148190368305} | train loss {'Reaction outcome loss': 0.12262177022592145, 'Total loss': 0.12262177022592145}
2022-12-05 20:56:08,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:08,760 INFO:     Epoch: 83
2022-12-05 20:56:09,559 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4378366343338381, 'Total loss': 0.4378366343338381} | train loss {'Reaction outcome loss': 0.1219336279116723, 'Total loss': 0.1219336279116723}
2022-12-05 20:56:09,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:09,559 INFO:     Epoch: 84
2022-12-05 20:56:10,359 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44026492959396407, 'Total loss': 0.44026492959396407} | train loss {'Reaction outcome loss': 0.12040173009950288, 'Total loss': 0.12040173009950288}
2022-12-05 20:56:10,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:10,359 INFO:     Epoch: 85
2022-12-05 20:56:11,157 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.437950759480538, 'Total loss': 0.437950759480538} | train loss {'Reaction outcome loss': 0.12205137312792394, 'Total loss': 0.12205137312792394}
2022-12-05 20:56:11,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:11,157 INFO:     Epoch: 86
2022-12-05 20:56:11,958 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4393370082093911, 'Total loss': 0.4393370082093911} | train loss {'Reaction outcome loss': 0.1206809597165913, 'Total loss': 0.1206809597165913}
2022-12-05 20:56:11,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:11,959 INFO:     Epoch: 87
2022-12-05 20:56:12,761 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43576012314720586, 'Total loss': 0.43576012314720586} | train loss {'Reaction outcome loss': 0.12289913285675706, 'Total loss': 0.12289913285675706}
2022-12-05 20:56:12,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:12,762 INFO:     Epoch: 88
2022-12-05 20:56:13,561 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4504824362017892, 'Total loss': 0.4504824362017892} | train loss {'Reaction outcome loss': 0.11994379010735726, 'Total loss': 0.11994379010735726}
2022-12-05 20:56:13,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:13,561 INFO:     Epoch: 89
2022-12-05 20:56:14,358 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43552867526357825, 'Total loss': 0.43552867526357825} | train loss {'Reaction outcome loss': 0.12051997443242948, 'Total loss': 0.12051997443242948}
2022-12-05 20:56:14,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:14,358 INFO:     Epoch: 90
2022-12-05 20:56:15,158 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4396602250635624, 'Total loss': 0.4396602250635624} | train loss {'Reaction outcome loss': 0.11968907416627116, 'Total loss': 0.11968907416627116}
2022-12-05 20:56:15,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:15,158 INFO:     Epoch: 91
2022-12-05 20:56:15,956 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4247772893445058, 'Total loss': 0.4247772893445058} | train loss {'Reaction outcome loss': 0.12317362875126454, 'Total loss': 0.12317362875126454}
2022-12-05 20:56:15,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:15,956 INFO:     Epoch: 92
2022-12-05 20:56:16,758 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4231451905745251, 'Total loss': 0.4231451905745251} | train loss {'Reaction outcome loss': 0.11932596971413918, 'Total loss': 0.11932596971413918}
2022-12-05 20:56:16,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:16,758 INFO:     Epoch: 93
2022-12-05 20:56:17,559 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4237709963186221, 'Total loss': 0.4237709963186221} | train loss {'Reaction outcome loss': 0.12176238274847975, 'Total loss': 0.12176238274847975}
2022-12-05 20:56:17,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:17,559 INFO:     Epoch: 94
2022-12-05 20:56:18,363 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42793300529857253, 'Total loss': 0.42793300529857253} | train loss {'Reaction outcome loss': 0.11887133175089043, 'Total loss': 0.11887133175089043}
2022-12-05 20:56:18,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:18,363 INFO:     Epoch: 95
2022-12-05 20:56:19,165 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44175501946698537, 'Total loss': 0.44175501946698537} | train loss {'Reaction outcome loss': 0.1156912215244101, 'Total loss': 0.1156912215244101}
2022-12-05 20:56:19,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:19,165 INFO:     Epoch: 96
2022-12-05 20:56:19,964 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43140060208018194, 'Total loss': 0.43140060208018194} | train loss {'Reaction outcome loss': 0.11852220771644188, 'Total loss': 0.11852220771644188}
2022-12-05 20:56:19,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:19,965 INFO:     Epoch: 97
2022-12-05 20:56:20,754 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47078189931132575, 'Total loss': 0.47078189931132575} | train loss {'Reaction outcome loss': 0.11933789505642288, 'Total loss': 0.11933789505642288}
2022-12-05 20:56:20,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:20,754 INFO:     Epoch: 98
2022-12-05 20:56:21,539 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42119962569664826, 'Total loss': 0.42119962569664826} | train loss {'Reaction outcome loss': 0.11887886732132459, 'Total loss': 0.11887886732132459}
2022-12-05 20:56:21,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:21,539 INFO:     Epoch: 99
2022-12-05 20:56:22,325 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4693398015065627, 'Total loss': 0.4693398015065627} | train loss {'Reaction outcome loss': 0.1160979501408886, 'Total loss': 0.1160979501408886}
2022-12-05 20:56:22,325 INFO:     Best model found after epoch 17 of 100.
2022-12-05 20:56:22,326 INFO:   Done with stage: TRAINING
2022-12-05 20:56:22,326 INFO:   Starting stage: EVALUATION
2022-12-05 20:56:22,456 INFO:   Done with stage: EVALUATION
2022-12-05 20:56:22,456 INFO:   Leaving out SEQ value Fold_2
2022-12-05 20:56:22,469 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 20:56:22,469 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:56:23,107 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:56:23,107 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:56:23,177 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:56:23,177 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:56:23,177 INFO:     No hyperparam tuning for this model
2022-12-05 20:56:23,177 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:56:23,177 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:56:23,178 INFO:     None feature selector for col prot
2022-12-05 20:56:23,178 INFO:     None feature selector for col prot
2022-12-05 20:56:23,178 INFO:     None feature selector for col prot
2022-12-05 20:56:23,178 INFO:     None feature selector for col chem
2022-12-05 20:56:23,178 INFO:     None feature selector for col chem
2022-12-05 20:56:23,179 INFO:     None feature selector for col chem
2022-12-05 20:56:23,179 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:56:23,179 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:56:23,180 INFO:     Number of params in model 215821
2022-12-05 20:56:23,184 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:56:23,184 INFO:   Starting stage: TRAINING
2022-12-05 20:56:23,243 INFO:     Val loss before train {'Reaction outcome loss': 0.965336516846058, 'Total loss': 0.965336516846058}
2022-12-05 20:56:23,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:23,243 INFO:     Epoch: 0
2022-12-05 20:56:24,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5816892988460008, 'Total loss': 0.5816892988460008} | train loss {'Reaction outcome loss': 0.7980876744526332, 'Total loss': 0.7980876744526332}
2022-12-05 20:56:24,023 INFO:     Found new best model at epoch 0
2022-12-05 20:56:24,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:24,024 INFO:     Epoch: 1
2022-12-05 20:56:24,801 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4982332718926807, 'Total loss': 0.4982332718926807} | train loss {'Reaction outcome loss': 0.5405487497566176, 'Total loss': 0.5405487497566176}
2022-12-05 20:56:24,801 INFO:     Found new best model at epoch 1
2022-12-05 20:56:24,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:24,802 INFO:     Epoch: 2
2022-12-05 20:56:25,579 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4783508517714434, 'Total loss': 0.4783508517714434} | train loss {'Reaction outcome loss': 0.4703510418289997, 'Total loss': 0.4703510418289997}
2022-12-05 20:56:25,579 INFO:     Found new best model at epoch 2
2022-12-05 20:56:25,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:25,580 INFO:     Epoch: 3
2022-12-05 20:56:26,367 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4475372554950936, 'Total loss': 0.4475372554950936} | train loss {'Reaction outcome loss': 0.4326018685566597, 'Total loss': 0.4326018685566597}
2022-12-05 20:56:26,367 INFO:     Found new best model at epoch 3
2022-12-05 20:56:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:26,368 INFO:     Epoch: 4
2022-12-05 20:56:27,154 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4392865670974864, 'Total loss': 0.4392865670974864} | train loss {'Reaction outcome loss': 0.40090252923183756, 'Total loss': 0.40090252923183756}
2022-12-05 20:56:27,154 INFO:     Found new best model at epoch 4
2022-12-05 20:56:27,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:27,155 INFO:     Epoch: 5
2022-12-05 20:56:27,938 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4302808649318163, 'Total loss': 0.4302808649318163} | train loss {'Reaction outcome loss': 0.37992419045968134, 'Total loss': 0.37992419045968134}
2022-12-05 20:56:27,938 INFO:     Found new best model at epoch 5
2022-12-05 20:56:27,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:27,939 INFO:     Epoch: 6
2022-12-05 20:56:28,719 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42170300282711204, 'Total loss': 0.42170300282711204} | train loss {'Reaction outcome loss': 0.3599917724362162, 'Total loss': 0.3599917724362162}
2022-12-05 20:56:28,720 INFO:     Found new best model at epoch 6
2022-12-05 20:56:28,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:28,720 INFO:     Epoch: 7
2022-12-05 20:56:29,505 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43049835257751995, 'Total loss': 0.43049835257751995} | train loss {'Reaction outcome loss': 0.34465269594773895, 'Total loss': 0.34465269594773895}
2022-12-05 20:56:29,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:29,505 INFO:     Epoch: 8
2022-12-05 20:56:30,286 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.426028907992119, 'Total loss': 0.426028907992119} | train loss {'Reaction outcome loss': 0.33026612589715937, 'Total loss': 0.33026612589715937}
2022-12-05 20:56:30,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:30,286 INFO:     Epoch: 9
2022-12-05 20:56:31,069 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.421903578347938, 'Total loss': 0.421903578347938} | train loss {'Reaction outcome loss': 0.31626253309430646, 'Total loss': 0.31626253309430646}
2022-12-05 20:56:31,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:31,069 INFO:     Epoch: 10
2022-12-05 20:56:31,846 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42055608020272367, 'Total loss': 0.42055608020272367} | train loss {'Reaction outcome loss': 0.3007585002017803, 'Total loss': 0.3007585002017803}
2022-12-05 20:56:31,846 INFO:     Found new best model at epoch 10
2022-12-05 20:56:31,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:31,847 INFO:     Epoch: 11
2022-12-05 20:56:32,624 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4324035024227098, 'Total loss': 0.4324035024227098} | train loss {'Reaction outcome loss': 0.2908917771285919, 'Total loss': 0.2908917771285919}
2022-12-05 20:56:32,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:32,624 INFO:     Epoch: 12
2022-12-05 20:56:33,404 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42118499306745305, 'Total loss': 0.42118499306745305} | train loss {'Reaction outcome loss': 0.28263002612673843, 'Total loss': 0.28263002612673843}
2022-12-05 20:56:33,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:33,405 INFO:     Epoch: 13
2022-12-05 20:56:34,183 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4110527426697487, 'Total loss': 0.4110527426697487} | train loss {'Reaction outcome loss': 0.2709273829079065, 'Total loss': 0.2709273829079065}
2022-12-05 20:56:34,183 INFO:     Found new best model at epoch 13
2022-12-05 20:56:34,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:34,184 INFO:     Epoch: 14
2022-12-05 20:56:34,968 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4177269554415414, 'Total loss': 0.4177269554415414} | train loss {'Reaction outcome loss': 0.26186459804656076, 'Total loss': 0.26186459804656076}
2022-12-05 20:56:34,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:34,968 INFO:     Epoch: 15
2022-12-05 20:56:35,749 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4289852931748989, 'Total loss': 0.4289852931748989} | train loss {'Reaction outcome loss': 0.25531179677756105, 'Total loss': 0.25531179677756105}
2022-12-05 20:56:35,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:35,749 INFO:     Epoch: 16
2022-12-05 20:56:36,530 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4311557387889818, 'Total loss': 0.4311557387889818} | train loss {'Reaction outcome loss': 0.24869820635887932, 'Total loss': 0.24869820635887932}
2022-12-05 20:56:36,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:36,530 INFO:     Epoch: 17
2022-12-05 20:56:37,310 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4265845404114834, 'Total loss': 0.4265845404114834} | train loss {'Reaction outcome loss': 0.23676505770351067, 'Total loss': 0.23676505770351067}
2022-12-05 20:56:37,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:37,311 INFO:     Epoch: 18
2022-12-05 20:56:38,087 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41334712401378987, 'Total loss': 0.41334712401378987} | train loss {'Reaction outcome loss': 0.23571799698545307, 'Total loss': 0.23571799698545307}
2022-12-05 20:56:38,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:38,087 INFO:     Epoch: 19
2022-12-05 20:56:38,867 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4130607524583506, 'Total loss': 0.4130607524583506} | train loss {'Reaction outcome loss': 0.2289794688036696, 'Total loss': 0.2289794688036696}
2022-12-05 20:56:38,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:38,867 INFO:     Epoch: 20
2022-12-05 20:56:39,644 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41788659781910653, 'Total loss': 0.41788659781910653} | train loss {'Reaction outcome loss': 0.22508991743270002, 'Total loss': 0.22508991743270002}
2022-12-05 20:56:39,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:39,645 INFO:     Epoch: 21
2022-12-05 20:56:40,425 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.422571852110153, 'Total loss': 0.422571852110153} | train loss {'Reaction outcome loss': 0.21839099839238113, 'Total loss': 0.21839099839238113}
2022-12-05 20:56:40,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:40,425 INFO:     Epoch: 22
2022-12-05 20:56:41,204 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4120405482691388, 'Total loss': 0.4120405482691388} | train loss {'Reaction outcome loss': 0.21473503931135426, 'Total loss': 0.21473503931135426}
2022-12-05 20:56:41,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:41,204 INFO:     Epoch: 23
2022-12-05 20:56:41,981 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4205243431551512, 'Total loss': 0.4205243431551512} | train loss {'Reaction outcome loss': 0.20868243103785838, 'Total loss': 0.20868243103785838}
2022-12-05 20:56:41,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:41,981 INFO:     Epoch: 24
2022-12-05 20:56:42,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41879378917605375, 'Total loss': 0.41879378917605375} | train loss {'Reaction outcome loss': 0.20481484545181033, 'Total loss': 0.20481484545181033}
2022-12-05 20:56:42,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:42,762 INFO:     Epoch: 25
2022-12-05 20:56:43,540 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42595572631026424, 'Total loss': 0.42595572631026424} | train loss {'Reaction outcome loss': 0.19885932362531542, 'Total loss': 0.19885932362531542}
2022-12-05 20:56:43,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:43,541 INFO:     Epoch: 26
2022-12-05 20:56:44,321 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4091720071642898, 'Total loss': 0.4091720071642898} | train loss {'Reaction outcome loss': 0.19591601103635842, 'Total loss': 0.19591601103635842}
2022-12-05 20:56:44,321 INFO:     Found new best model at epoch 26
2022-12-05 20:56:44,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:44,322 INFO:     Epoch: 27
2022-12-05 20:56:45,103 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43133099065270536, 'Total loss': 0.43133099065270536} | train loss {'Reaction outcome loss': 0.1917537501020754, 'Total loss': 0.1917537501020754}
2022-12-05 20:56:45,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:45,104 INFO:     Epoch: 28
2022-12-05 20:56:45,886 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42590936741163565, 'Total loss': 0.42590936741163565} | train loss {'Reaction outcome loss': 0.19189641997218132, 'Total loss': 0.19189641997218132}
2022-12-05 20:56:45,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:45,886 INFO:     Epoch: 29
2022-12-05 20:56:46,668 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43041924439197365, 'Total loss': 0.43041924439197365} | train loss {'Reaction outcome loss': 0.18867023863264773, 'Total loss': 0.18867023863264773}
2022-12-05 20:56:46,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:46,668 INFO:     Epoch: 30
2022-12-05 20:56:47,451 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41878152344115943, 'Total loss': 0.41878152344115943} | train loss {'Reaction outcome loss': 0.1842018065470286, 'Total loss': 0.1842018065470286}
2022-12-05 20:56:47,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:47,451 INFO:     Epoch: 31
2022-12-05 20:56:48,235 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4276855605286221, 'Total loss': 0.4276855605286221} | train loss {'Reaction outcome loss': 0.18359050936386234, 'Total loss': 0.18359050936386234}
2022-12-05 20:56:48,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:48,235 INFO:     Epoch: 32
2022-12-05 20:56:49,019 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4239942549273025, 'Total loss': 0.4239942549273025} | train loss {'Reaction outcome loss': 0.17854555390133967, 'Total loss': 0.17854555390133967}
2022-12-05 20:56:49,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:49,019 INFO:     Epoch: 33
2022-12-05 20:56:49,800 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42949876015962557, 'Total loss': 0.42949876015962557} | train loss {'Reaction outcome loss': 0.17616258326490394, 'Total loss': 0.17616258326490394}
2022-12-05 20:56:49,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:49,800 INFO:     Epoch: 34
2022-12-05 20:56:50,580 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44019229536832766, 'Total loss': 0.44019229536832766} | train loss {'Reaction outcome loss': 0.1741287871645611, 'Total loss': 0.1741287871645611}
2022-12-05 20:56:50,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:50,580 INFO:     Epoch: 35
2022-12-05 20:56:51,364 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4386832859627036, 'Total loss': 0.4386832859627036} | train loss {'Reaction outcome loss': 0.17018181832934745, 'Total loss': 0.17018181832934745}
2022-12-05 20:56:51,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:51,365 INFO:     Epoch: 36
2022-12-05 20:56:52,145 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4582763052610464, 'Total loss': 0.4582763052610464} | train loss {'Reaction outcome loss': 0.1712423337043309, 'Total loss': 0.1712423337043309}
2022-12-05 20:56:52,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:52,146 INFO:     Epoch: 37
2022-12-05 20:56:52,926 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43960716800634253, 'Total loss': 0.43960716800634253} | train loss {'Reaction outcome loss': 0.16772565708236128, 'Total loss': 0.16772565708236128}
2022-12-05 20:56:52,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:52,926 INFO:     Epoch: 38
2022-12-05 20:56:53,706 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43799599277418716, 'Total loss': 0.43799599277418716} | train loss {'Reaction outcome loss': 0.16583071148297826, 'Total loss': 0.16583071148297826}
2022-12-05 20:56:53,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:53,706 INFO:     Epoch: 39
2022-12-05 20:56:54,489 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44596000015735626, 'Total loss': 0.44596000015735626} | train loss {'Reaction outcome loss': 0.16067663497734266, 'Total loss': 0.16067663497734266}
2022-12-05 20:56:54,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:54,489 INFO:     Epoch: 40
2022-12-05 20:56:55,273 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44080861848454145, 'Total loss': 0.44080861848454145} | train loss {'Reaction outcome loss': 0.16559929406026103, 'Total loss': 0.16559929406026103}
2022-12-05 20:56:55,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:55,274 INFO:     Epoch: 41
2022-12-05 20:56:56,053 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44496572086977404, 'Total loss': 0.44496572086977404} | train loss {'Reaction outcome loss': 0.15994043365792662, 'Total loss': 0.15994043365792662}
2022-12-05 20:56:56,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:56,054 INFO:     Epoch: 42
2022-12-05 20:56:56,840 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4507102796504664, 'Total loss': 0.4507102796504664} | train loss {'Reaction outcome loss': 0.15623866603328068, 'Total loss': 0.15623866603328068}
2022-12-05 20:56:56,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:56,840 INFO:     Epoch: 43
2022-12-05 20:56:57,622 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4436910100454508, 'Total loss': 0.4436910100454508} | train loss {'Reaction outcome loss': 0.15837242084814876, 'Total loss': 0.15837242084814876}
2022-12-05 20:56:57,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:57,622 INFO:     Epoch: 44
2022-12-05 20:56:58,401 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43801137770331183, 'Total loss': 0.43801137770331183} | train loss {'Reaction outcome loss': 0.153229574665244, 'Total loss': 0.153229574665244}
2022-12-05 20:56:58,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:58,402 INFO:     Epoch: 45
2022-12-05 20:56:59,184 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4299039345147998, 'Total loss': 0.4299039345147998} | train loss {'Reaction outcome loss': 0.15610747538568054, 'Total loss': 0.15610747538568054}
2022-12-05 20:56:59,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:59,184 INFO:     Epoch: 46
2022-12-05 20:56:59,967 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43669274484002313, 'Total loss': 0.43669274484002313} | train loss {'Reaction outcome loss': 0.15168463590661765, 'Total loss': 0.15168463590661765}
2022-12-05 20:56:59,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:56:59,968 INFO:     Epoch: 47
2022-12-05 20:57:00,748 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4485818166718927, 'Total loss': 0.4485818166718927} | train loss {'Reaction outcome loss': 0.14898045320582928, 'Total loss': 0.14898045320582928}
2022-12-05 20:57:00,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:00,748 INFO:     Epoch: 48
2022-12-05 20:57:01,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44223808410555815, 'Total loss': 0.44223808410555815} | train loss {'Reaction outcome loss': 0.15099879922955983, 'Total loss': 0.15099879922955983}
2022-12-05 20:57:01,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:01,530 INFO:     Epoch: 49
2022-12-05 20:57:02,316 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4422693023847979, 'Total loss': 0.4422693023847979} | train loss {'Reaction outcome loss': 0.14622803895016673, 'Total loss': 0.14622803895016673}
2022-12-05 20:57:02,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:02,316 INFO:     Epoch: 50
2022-12-05 20:57:03,103 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44031145856824033, 'Total loss': 0.44031145856824033} | train loss {'Reaction outcome loss': 0.14926244558949694, 'Total loss': 0.14926244558949694}
2022-12-05 20:57:03,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:03,103 INFO:     Epoch: 51
2022-12-05 20:57:03,886 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44175426887218344, 'Total loss': 0.44175426887218344} | train loss {'Reaction outcome loss': 0.14857165881844817, 'Total loss': 0.14857165881844817}
2022-12-05 20:57:03,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:03,886 INFO:     Epoch: 52
2022-12-05 20:57:04,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4310880812794663, 'Total loss': 0.4310880812794663} | train loss {'Reaction outcome loss': 0.14543412523496835, 'Total loss': 0.14543412523496835}
2022-12-05 20:57:04,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:04,672 INFO:     Epoch: 53
2022-12-05 20:57:05,455 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43307916265587476, 'Total loss': 0.43307916265587476} | train loss {'Reaction outcome loss': 0.14635618192861316, 'Total loss': 0.14635618192861316}
2022-12-05 20:57:05,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:05,455 INFO:     Epoch: 54
2022-12-05 20:57:06,240 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46512599601302035, 'Total loss': 0.46512599601302035} | train loss {'Reaction outcome loss': 0.14417355109891686, 'Total loss': 0.14417355109891686}
2022-12-05 20:57:06,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:06,240 INFO:     Epoch: 55
2022-12-05 20:57:07,022 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4395249749338904, 'Total loss': 0.4395249749338904} | train loss {'Reaction outcome loss': 0.1442269682273513, 'Total loss': 0.1442269682273513}
2022-12-05 20:57:07,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:07,022 INFO:     Epoch: 56
2022-12-05 20:57:07,805 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45079752768194953, 'Total loss': 0.45079752768194953} | train loss {'Reaction outcome loss': 0.1417299107587362, 'Total loss': 0.1417299107587362}
2022-12-05 20:57:07,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:07,806 INFO:     Epoch: 57
2022-12-05 20:57:08,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4466492492099141, 'Total loss': 0.4466492492099141} | train loss {'Reaction outcome loss': 0.14087435015339833, 'Total loss': 0.14087435015339833}
2022-12-05 20:57:08,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:08,592 INFO:     Epoch: 58
2022-12-05 20:57:09,376 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4540326737387236, 'Total loss': 0.4540326737387236} | train loss {'Reaction outcome loss': 0.13913968185604106, 'Total loss': 0.13913968185604106}
2022-12-05 20:57:09,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:09,376 INFO:     Epoch: 59
2022-12-05 20:57:10,161 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44348078099794164, 'Total loss': 0.44348078099794164} | train loss {'Reaction outcome loss': 0.137930555017207, 'Total loss': 0.137930555017207}
2022-12-05 20:57:10,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:10,161 INFO:     Epoch: 60
2022-12-05 20:57:10,949 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44146658757398294, 'Total loss': 0.44146658757398294} | train loss {'Reaction outcome loss': 0.1404767753480033, 'Total loss': 0.1404767753480033}
2022-12-05 20:57:10,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:10,950 INFO:     Epoch: 61
2022-12-05 20:57:11,738 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4444867725982222, 'Total loss': 0.4444867725982222} | train loss {'Reaction outcome loss': 0.13800038750756716, 'Total loss': 0.13800038750756716}
2022-12-05 20:57:11,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:11,738 INFO:     Epoch: 62
2022-12-05 20:57:12,530 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45045345519171204, 'Total loss': 0.45045345519171204} | train loss {'Reaction outcome loss': 0.13771360558381335, 'Total loss': 0.13771360558381335}
2022-12-05 20:57:12,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:12,531 INFO:     Epoch: 63
2022-12-05 20:57:13,315 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43381876654403156, 'Total loss': 0.43381876654403156} | train loss {'Reaction outcome loss': 0.1391468851246917, 'Total loss': 0.1391468851246917}
2022-12-05 20:57:13,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:13,315 INFO:     Epoch: 64
2022-12-05 20:57:14,099 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45144463832988296, 'Total loss': 0.45144463832988296} | train loss {'Reaction outcome loss': 0.13645858003864766, 'Total loss': 0.13645858003864766}
2022-12-05 20:57:14,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:14,099 INFO:     Epoch: 65
2022-12-05 20:57:14,889 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4403097210235374, 'Total loss': 0.4403097210235374} | train loss {'Reaction outcome loss': 0.1349556400234521, 'Total loss': 0.1349556400234521}
2022-12-05 20:57:14,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:14,890 INFO:     Epoch: 66
2022-12-05 20:57:15,674 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4602430542541105, 'Total loss': 0.4602430542541105} | train loss {'Reaction outcome loss': 0.13612632922156423, 'Total loss': 0.13612632922156423}
2022-12-05 20:57:15,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:15,674 INFO:     Epoch: 67
2022-12-05 20:57:16,461 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45722369052642997, 'Total loss': 0.45722369052642997} | train loss {'Reaction outcome loss': 0.13388617215372745, 'Total loss': 0.13388617215372745}
2022-12-05 20:57:16,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:16,461 INFO:     Epoch: 68
2022-12-05 20:57:17,253 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4538379498692446, 'Total loss': 0.4538379498692446} | train loss {'Reaction outcome loss': 0.13271464874632047, 'Total loss': 0.13271464874632047}
2022-12-05 20:57:17,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:17,254 INFO:     Epoch: 69
2022-12-05 20:57:18,039 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44877820288719134, 'Total loss': 0.44877820288719134} | train loss {'Reaction outcome loss': 0.13430498298410265, 'Total loss': 0.13430498298410265}
2022-12-05 20:57:18,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:18,039 INFO:     Epoch: 70
2022-12-05 20:57:18,823 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4384342667668365, 'Total loss': 0.4384342667668365} | train loss {'Reaction outcome loss': 0.13224596805015548, 'Total loss': 0.13224596805015548}
2022-12-05 20:57:18,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:18,823 INFO:     Epoch: 71
2022-12-05 20:57:19,607 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44268683950568355, 'Total loss': 0.44268683950568355} | train loss {'Reaction outcome loss': 0.13223575036514734, 'Total loss': 0.13223575036514734}
2022-12-05 20:57:19,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:19,607 INFO:     Epoch: 72
2022-12-05 20:57:20,391 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44831337069356164, 'Total loss': 0.44831337069356164} | train loss {'Reaction outcome loss': 0.13252277086397296, 'Total loss': 0.13252277086397296}
2022-12-05 20:57:20,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:20,391 INFO:     Epoch: 73
2022-12-05 20:57:21,174 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45819489449955697, 'Total loss': 0.45819489449955697} | train loss {'Reaction outcome loss': 0.13073306312387595, 'Total loss': 0.13073306312387595}
2022-12-05 20:57:21,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:21,175 INFO:     Epoch: 74
2022-12-05 20:57:21,962 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4459988419399705, 'Total loss': 0.4459988419399705} | train loss {'Reaction outcome loss': 0.12999447431323713, 'Total loss': 0.12999447431323713}
2022-12-05 20:57:21,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:21,962 INFO:     Epoch: 75
2022-12-05 20:57:22,747 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4589074330274449, 'Total loss': 0.4589074330274449} | train loss {'Reaction outcome loss': 0.12655595947270754, 'Total loss': 0.12655595947270754}
2022-12-05 20:57:22,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:22,747 INFO:     Epoch: 76
2022-12-05 20:57:23,537 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44871695408987444, 'Total loss': 0.44871695408987444} | train loss {'Reaction outcome loss': 0.13291319253564368, 'Total loss': 0.13291319253564368}
2022-12-05 20:57:23,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:23,537 INFO:     Epoch: 77
2022-12-05 20:57:24,321 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4652279845850412, 'Total loss': 0.4652279845850412} | train loss {'Reaction outcome loss': 0.1296955282937308, 'Total loss': 0.1296955282937308}
2022-12-05 20:57:24,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:24,321 INFO:     Epoch: 78
2022-12-05 20:57:25,105 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44731391134650206, 'Total loss': 0.44731391134650206} | train loss {'Reaction outcome loss': 0.12937039369144707, 'Total loss': 0.12937039369144707}
2022-12-05 20:57:25,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:25,105 INFO:     Epoch: 79
2022-12-05 20:57:25,889 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44734112745107607, 'Total loss': 0.44734112745107607} | train loss {'Reaction outcome loss': 0.1289292158765077, 'Total loss': 0.1289292158765077}
2022-12-05 20:57:25,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:25,889 INFO:     Epoch: 80
2022-12-05 20:57:26,675 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4445560477500738, 'Total loss': 0.4445560477500738} | train loss {'Reaction outcome loss': 0.1273563673746482, 'Total loss': 0.1273563673746482}
2022-12-05 20:57:26,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:26,675 INFO:     Epoch: 81
2022-12-05 20:57:27,462 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4432593067718107, 'Total loss': 0.4432593067718107} | train loss {'Reaction outcome loss': 0.1257671905933406, 'Total loss': 0.1257671905933406}
2022-12-05 20:57:27,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:27,463 INFO:     Epoch: 82
2022-12-05 20:57:28,250 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44056485454703487, 'Total loss': 0.44056485454703487} | train loss {'Reaction outcome loss': 0.12691640890524036, 'Total loss': 0.12691640890524036}
2022-12-05 20:57:28,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:28,250 INFO:     Epoch: 83
2022-12-05 20:57:29,038 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45358506962656975, 'Total loss': 0.45358506962656975} | train loss {'Reaction outcome loss': 0.12775237324502564, 'Total loss': 0.12775237324502564}
2022-12-05 20:57:29,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:29,038 INFO:     Epoch: 84
2022-12-05 20:57:29,827 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4433663002280302, 'Total loss': 0.4433663002280302} | train loss {'Reaction outcome loss': 0.1246402000619068, 'Total loss': 0.1246402000619068}
2022-12-05 20:57:29,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:29,828 INFO:     Epoch: 85
2022-12-05 20:57:30,615 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4611897537874621, 'Total loss': 0.4611897537874621} | train loss {'Reaction outcome loss': 0.12447405887431785, 'Total loss': 0.12447405887431785}
2022-12-05 20:57:30,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:30,616 INFO:     Epoch: 86
2022-12-05 20:57:31,403 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.454457106285317, 'Total loss': 0.454457106285317} | train loss {'Reaction outcome loss': 0.12561134188664985, 'Total loss': 0.12561134188664985}
2022-12-05 20:57:31,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:31,403 INFO:     Epoch: 87
2022-12-05 20:57:32,190 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4613668468109397, 'Total loss': 0.4613668468109397} | train loss {'Reaction outcome loss': 0.12490782427570982, 'Total loss': 0.12490782427570982}
2022-12-05 20:57:32,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:32,190 INFO:     Epoch: 88
2022-12-05 20:57:32,973 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46773078275281327, 'Total loss': 0.46773078275281327} | train loss {'Reaction outcome loss': 0.12400023352362399, 'Total loss': 0.12400023352362399}
2022-12-05 20:57:32,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:32,974 INFO:     Epoch: 89
2022-12-05 20:57:33,756 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4429429672485174, 'Total loss': 0.4429429672485174} | train loss {'Reaction outcome loss': 0.12455051549191236, 'Total loss': 0.12455051549191236}
2022-12-05 20:57:33,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:33,756 INFO:     Epoch: 90
2022-12-05 20:57:34,540 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4529036110223726, 'Total loss': 0.4529036110223726} | train loss {'Reaction outcome loss': 0.124530905976006, 'Total loss': 0.124530905976006}
2022-12-05 20:57:34,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:34,541 INFO:     Epoch: 91
2022-12-05 20:57:35,325 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4362360734579175, 'Total loss': 0.4362360734579175} | train loss {'Reaction outcome loss': 0.12202257214144605, 'Total loss': 0.12202257214144605}
2022-12-05 20:57:35,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:35,325 INFO:     Epoch: 92
2022-12-05 20:57:36,114 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4702093559642171, 'Total loss': 0.4702093559642171} | train loss {'Reaction outcome loss': 0.12396711657266514, 'Total loss': 0.12396711657266514}
2022-12-05 20:57:36,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:36,114 INFO:     Epoch: 93
2022-12-05 20:57:36,899 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4384931294723999, 'Total loss': 0.4384931294723999} | train loss {'Reaction outcome loss': 0.12291534902283648, 'Total loss': 0.12291534902283648}
2022-12-05 20:57:36,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:36,899 INFO:     Epoch: 94
2022-12-05 20:57:37,689 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44296511470578437, 'Total loss': 0.44296511470578437} | train loss {'Reaction outcome loss': 0.12351965246966383, 'Total loss': 0.12351965246966383}
2022-12-05 20:57:37,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:37,690 INFO:     Epoch: 95
2022-12-05 20:57:38,483 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4469465252964996, 'Total loss': 0.4469465252964996} | train loss {'Reaction outcome loss': 0.12478808123145069, 'Total loss': 0.12478808123145069}
2022-12-05 20:57:38,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:38,484 INFO:     Epoch: 96
2022-12-05 20:57:39,268 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45929784691611003, 'Total loss': 0.45929784691611003} | train loss {'Reaction outcome loss': 0.12414965107578968, 'Total loss': 0.12414965107578968}
2022-12-05 20:57:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:39,268 INFO:     Epoch: 97
2022-12-05 20:57:40,062 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4368795662425285, 'Total loss': 0.4368795662425285} | train loss {'Reaction outcome loss': 0.1216223528303328, 'Total loss': 0.1216223528303328}
2022-12-05 20:57:40,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:40,063 INFO:     Epoch: 98
2022-12-05 20:57:40,854 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44835677916227384, 'Total loss': 0.44835677916227384} | train loss {'Reaction outcome loss': 0.12200445356229167, 'Total loss': 0.12200445356229167}
2022-12-05 20:57:40,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:40,855 INFO:     Epoch: 99
2022-12-05 20:57:41,647 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4552570162124412, 'Total loss': 0.4552570162124412} | train loss {'Reaction outcome loss': 0.1226339000506235, 'Total loss': 0.1226339000506235}
2022-12-05 20:57:41,647 INFO:     Best model found after epoch 27 of 100.
2022-12-05 20:57:41,647 INFO:   Done with stage: TRAINING
2022-12-05 20:57:41,647 INFO:   Starting stage: EVALUATION
2022-12-05 20:57:41,784 INFO:   Done with stage: EVALUATION
2022-12-05 20:57:41,784 INFO:   Leaving out SEQ value Fold_3
2022-12-05 20:57:41,797 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 20:57:41,797 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:57:42,433 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:57:42,433 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:57:42,502 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:57:42,502 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:57:42,502 INFO:     No hyperparam tuning for this model
2022-12-05 20:57:42,502 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:57:42,502 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:57:42,503 INFO:     None feature selector for col prot
2022-12-05 20:57:42,503 INFO:     None feature selector for col prot
2022-12-05 20:57:42,503 INFO:     None feature selector for col prot
2022-12-05 20:57:42,504 INFO:     None feature selector for col chem
2022-12-05 20:57:42,504 INFO:     None feature selector for col chem
2022-12-05 20:57:42,504 INFO:     None feature selector for col chem
2022-12-05 20:57:42,504 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:57:42,504 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:57:42,506 INFO:     Number of params in model 215821
2022-12-05 20:57:42,509 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:57:42,509 INFO:   Starting stage: TRAINING
2022-12-05 20:57:42,569 INFO:     Val loss before train {'Reaction outcome loss': 0.9912756478244608, 'Total loss': 0.9912756478244608}
2022-12-05 20:57:42,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:42,569 INFO:     Epoch: 0
2022-12-05 20:57:43,358 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5963478122245182, 'Total loss': 0.5963478122245182} | train loss {'Reaction outcome loss': 0.7953626180181698, 'Total loss': 0.7953626180181698}
2022-12-05 20:57:43,358 INFO:     Found new best model at epoch 0
2022-12-05 20:57:43,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:43,359 INFO:     Epoch: 1
2022-12-05 20:57:44,153 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.511448351497, 'Total loss': 0.511448351497} | train loss {'Reaction outcome loss': 0.5509403288364411, 'Total loss': 0.5509403288364411}
2022-12-05 20:57:44,153 INFO:     Found new best model at epoch 1
2022-12-05 20:57:44,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:44,154 INFO:     Epoch: 2
2022-12-05 20:57:44,944 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4744262397289276, 'Total loss': 0.4744262397289276} | train loss {'Reaction outcome loss': 0.4765976923460863, 'Total loss': 0.4765976923460863}
2022-12-05 20:57:44,944 INFO:     Found new best model at epoch 2
2022-12-05 20:57:44,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:44,945 INFO:     Epoch: 3
2022-12-05 20:57:45,736 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4591820046982982, 'Total loss': 0.4591820046982982} | train loss {'Reaction outcome loss': 0.4370482573095633, 'Total loss': 0.4370482573095633}
2022-12-05 20:57:45,737 INFO:     Found new best model at epoch 3
2022-12-05 20:57:45,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:45,737 INFO:     Epoch: 4
2022-12-05 20:57:46,527 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.438334140249274, 'Total loss': 0.438334140249274} | train loss {'Reaction outcome loss': 0.4079086937466446, 'Total loss': 0.4079086937466446}
2022-12-05 20:57:46,528 INFO:     Found new best model at epoch 4
2022-12-05 20:57:46,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:46,529 INFO:     Epoch: 5
2022-12-05 20:57:47,317 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42883514206517825, 'Total loss': 0.42883514206517825} | train loss {'Reaction outcome loss': 0.3854817111881412, 'Total loss': 0.3854817111881412}
2022-12-05 20:57:47,318 INFO:     Found new best model at epoch 5
2022-12-05 20:57:47,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:47,318 INFO:     Epoch: 6
2022-12-05 20:57:48,106 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4335067624395544, 'Total loss': 0.4335067624395544} | train loss {'Reaction outcome loss': 0.36566648644452193, 'Total loss': 0.36566648644452193}
2022-12-05 20:57:48,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:48,107 INFO:     Epoch: 7
2022-12-05 20:57:48,897 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4322183518247171, 'Total loss': 0.4322183518247171} | train loss {'Reaction outcome loss': 0.34564223186093934, 'Total loss': 0.34564223186093934}
2022-12-05 20:57:48,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:48,897 INFO:     Epoch: 8
2022-12-05 20:57:49,685 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.429827171293172, 'Total loss': 0.429827171293172} | train loss {'Reaction outcome loss': 0.32762196994557674, 'Total loss': 0.32762196994557674}
2022-12-05 20:57:49,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:49,685 INFO:     Epoch: 9
2022-12-05 20:57:50,483 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.430904667485844, 'Total loss': 0.430904667485844} | train loss {'Reaction outcome loss': 0.31406270651792995, 'Total loss': 0.31406270651792995}
2022-12-05 20:57:50,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:50,483 INFO:     Epoch: 10
2022-12-05 20:57:51,271 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4302849874577739, 'Total loss': 0.4302849874577739} | train loss {'Reaction outcome loss': 0.2999564430695407, 'Total loss': 0.2999564430695407}
2022-12-05 20:57:51,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:51,271 INFO:     Epoch: 11
2022-12-05 20:57:52,065 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43035967817360704, 'Total loss': 0.43035967817360704} | train loss {'Reaction outcome loss': 0.28972689600623386, 'Total loss': 0.28972689600623386}
2022-12-05 20:57:52,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:52,065 INFO:     Epoch: 12
2022-12-05 20:57:52,856 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44492110440676863, 'Total loss': 0.44492110440676863} | train loss {'Reaction outcome loss': 0.27730974922983015, 'Total loss': 0.27730974922983015}
2022-12-05 20:57:52,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:52,856 INFO:     Epoch: 13
2022-12-05 20:57:53,643 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.422593460672281, 'Total loss': 0.422593460672281} | train loss {'Reaction outcome loss': 0.26646148195984415, 'Total loss': 0.26646148195984415}
2022-12-05 20:57:53,643 INFO:     Found new best model at epoch 13
2022-12-05 20:57:53,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:53,644 INFO:     Epoch: 14
2022-12-05 20:57:54,436 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42478052725676785, 'Total loss': 0.42478052725676785} | train loss {'Reaction outcome loss': 0.2581659784274442, 'Total loss': 0.2581659784274442}
2022-12-05 20:57:54,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:54,436 INFO:     Epoch: 15
2022-12-05 20:57:55,227 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44224688986485655, 'Total loss': 0.44224688986485655} | train loss {'Reaction outcome loss': 0.25096041368586675, 'Total loss': 0.25096041368586675}
2022-12-05 20:57:55,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:55,227 INFO:     Epoch: 16
2022-12-05 20:57:56,015 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4433805984868245, 'Total loss': 0.4433805984868245} | train loss {'Reaction outcome loss': 0.24468317132215112, 'Total loss': 0.24468317132215112}
2022-12-05 20:57:56,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:56,015 INFO:     Epoch: 17
2022-12-05 20:57:56,808 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4383009939708493, 'Total loss': 0.4383009939708493} | train loss {'Reaction outcome loss': 0.23694199667293198, 'Total loss': 0.23694199667293198}
2022-12-05 20:57:56,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:56,809 INFO:     Epoch: 18
2022-12-05 20:57:57,599 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4379948360676115, 'Total loss': 0.4379948360676115} | train loss {'Reaction outcome loss': 0.23144664273274188, 'Total loss': 0.23144664273274188}
2022-12-05 20:57:57,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:57,599 INFO:     Epoch: 19
2022-12-05 20:57:58,391 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.426537609743801, 'Total loss': 0.426537609743801} | train loss {'Reaction outcome loss': 0.2266393984610937, 'Total loss': 0.2266393984610937}
2022-12-05 20:57:58,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:58,392 INFO:     Epoch: 20
2022-12-05 20:57:59,184 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43081380663947627, 'Total loss': 0.43081380663947627} | train loss {'Reaction outcome loss': 0.2241191997515912, 'Total loss': 0.2241191997515912}
2022-12-05 20:57:59,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:59,184 INFO:     Epoch: 21
2022-12-05 20:57:59,973 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44421795450828294, 'Total loss': 0.44421795450828294} | train loss {'Reaction outcome loss': 0.2152364503212121, 'Total loss': 0.2152364503212121}
2022-12-05 20:57:59,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:57:59,974 INFO:     Epoch: 22
2022-12-05 20:58:00,763 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43889468671246007, 'Total loss': 0.43889468671246007} | train loss {'Reaction outcome loss': 0.21044625186798524, 'Total loss': 0.21044625186798524}
2022-12-05 20:58:00,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:00,763 INFO:     Epoch: 23
2022-12-05 20:58:01,551 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43440689154985274, 'Total loss': 0.43440689154985274} | train loss {'Reaction outcome loss': 0.20729582844948283, 'Total loss': 0.20729582844948283}
2022-12-05 20:58:01,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:01,552 INFO:     Epoch: 24
2022-12-05 20:58:02,346 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.463255010756918, 'Total loss': 0.463255010756918} | train loss {'Reaction outcome loss': 0.19864557714638661, 'Total loss': 0.19864557714638661}
2022-12-05 20:58:02,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:02,346 INFO:     Epoch: 25
2022-12-05 20:58:03,137 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4601767845451832, 'Total loss': 0.4601767845451832} | train loss {'Reaction outcome loss': 0.19943405438442618, 'Total loss': 0.19943405438442618}
2022-12-05 20:58:03,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:03,137 INFO:     Epoch: 26
2022-12-05 20:58:03,926 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.459087252701548, 'Total loss': 0.459087252701548} | train loss {'Reaction outcome loss': 0.19401883954296306, 'Total loss': 0.19401883954296306}
2022-12-05 20:58:03,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:03,926 INFO:     Epoch: 27
2022-12-05 20:58:04,716 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4543211936781352, 'Total loss': 0.4543211936781352} | train loss {'Reaction outcome loss': 0.19018666076720978, 'Total loss': 0.19018666076720978}
2022-12-05 20:58:04,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:04,716 INFO:     Epoch: 28
2022-12-05 20:58:05,508 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44771903854879463, 'Total loss': 0.44771903854879463} | train loss {'Reaction outcome loss': 0.18742797958607577, 'Total loss': 0.18742797958607577}
2022-12-05 20:58:05,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:05,508 INFO:     Epoch: 29
2022-12-05 20:58:06,301 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4482693760232492, 'Total loss': 0.4482693760232492} | train loss {'Reaction outcome loss': 0.18275549241474698, 'Total loss': 0.18275549241474698}
2022-12-05 20:58:06,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:06,302 INFO:     Epoch: 30
2022-12-05 20:58:07,099 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4468653892928904, 'Total loss': 0.4468653892928904} | train loss {'Reaction outcome loss': 0.18154908311458268, 'Total loss': 0.18154908311458268}
2022-12-05 20:58:07,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:07,099 INFO:     Epoch: 31
2022-12-05 20:58:07,888 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4681419364430688, 'Total loss': 0.4681419364430688} | train loss {'Reaction outcome loss': 0.17602363345878466, 'Total loss': 0.17602363345878466}
2022-12-05 20:58:07,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:07,889 INFO:     Epoch: 32
2022-12-05 20:58:08,681 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44363306200301106, 'Total loss': 0.44363306200301106} | train loss {'Reaction outcome loss': 0.17492500776234937, 'Total loss': 0.17492500776234937}
2022-12-05 20:58:08,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:08,681 INFO:     Epoch: 33
2022-12-05 20:58:09,471 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4597709189084443, 'Total loss': 0.4597709189084443} | train loss {'Reaction outcome loss': 0.17129182968364687, 'Total loss': 0.17129182968364687}
2022-12-05 20:58:09,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:09,471 INFO:     Epoch: 34
2022-12-05 20:58:10,270 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44255245316096326, 'Total loss': 0.44255245316096326} | train loss {'Reaction outcome loss': 0.1700399157192026, 'Total loss': 0.1700399157192026}
2022-12-05 20:58:10,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:10,270 INFO:     Epoch: 35
2022-12-05 20:58:11,060 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4473756870085543, 'Total loss': 0.4473756870085543} | train loss {'Reaction outcome loss': 0.16782182747003985, 'Total loss': 0.16782182747003985}
2022-12-05 20:58:11,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:11,061 INFO:     Epoch: 36
2022-12-05 20:58:11,849 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47117194025353953, 'Total loss': 0.47117194025353953} | train loss {'Reaction outcome loss': 0.16560140469548654, 'Total loss': 0.16560140469548654}
2022-12-05 20:58:11,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:11,849 INFO:     Epoch: 37
2022-12-05 20:58:12,644 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47168881649320776, 'Total loss': 0.47168881649320776} | train loss {'Reaction outcome loss': 0.16543627094705493, 'Total loss': 0.16543627094705493}
2022-12-05 20:58:12,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:12,644 INFO:     Epoch: 38
2022-12-05 20:58:13,439 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46061266941780393, 'Total loss': 0.46061266941780393} | train loss {'Reaction outcome loss': 0.16305369603998807, 'Total loss': 0.16305369603998807}
2022-12-05 20:58:13,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:13,440 INFO:     Epoch: 39
2022-12-05 20:58:14,235 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4731157516891306, 'Total loss': 0.4731157516891306} | train loss {'Reaction outcome loss': 0.16340081657910224, 'Total loss': 0.16340081657910224}
2022-12-05 20:58:14,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:14,235 INFO:     Epoch: 40
2022-12-05 20:58:15,025 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4486523216420954, 'Total loss': 0.4486523216420954} | train loss {'Reaction outcome loss': 0.15685588644855486, 'Total loss': 0.15685588644855486}
2022-12-05 20:58:15,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:15,025 INFO:     Epoch: 41
2022-12-05 20:58:15,811 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45081268691203813, 'Total loss': 0.45081268691203813} | train loss {'Reaction outcome loss': 0.1548890644722447, 'Total loss': 0.1548890644722447}
2022-12-05 20:58:15,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:15,811 INFO:     Epoch: 42
2022-12-05 20:58:16,603 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47562316817824135, 'Total loss': 0.47562316817824135} | train loss {'Reaction outcome loss': 0.1513323214589333, 'Total loss': 0.1513323214589333}
2022-12-05 20:58:16,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:16,603 INFO:     Epoch: 43
2022-12-05 20:58:17,395 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46645587682724, 'Total loss': 0.46645587682724} | train loss {'Reaction outcome loss': 0.15093440727463792, 'Total loss': 0.15093440727463792}
2022-12-05 20:58:17,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:17,396 INFO:     Epoch: 44
2022-12-05 20:58:18,191 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4681419591334733, 'Total loss': 0.4681419591334733} | train loss {'Reaction outcome loss': 0.15194854924113166, 'Total loss': 0.15194854924113166}
2022-12-05 20:58:18,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:18,192 INFO:     Epoch: 45
2022-12-05 20:58:18,989 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4691475487568162, 'Total loss': 0.4691475487568162} | train loss {'Reaction outcome loss': 0.15039628982087788, 'Total loss': 0.15039628982087788}
2022-12-05 20:58:18,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:18,989 INFO:     Epoch: 46
2022-12-05 20:58:19,780 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4671754701571031, 'Total loss': 0.4671754701571031} | train loss {'Reaction outcome loss': 0.14935090186796626, 'Total loss': 0.14935090186796626}
2022-12-05 20:58:19,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:19,781 INFO:     Epoch: 47
2022-12-05 20:58:20,573 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47117499905553734, 'Total loss': 0.47117499905553734} | train loss {'Reaction outcome loss': 0.1459149866155824, 'Total loss': 0.1459149866155824}
2022-12-05 20:58:20,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:20,573 INFO:     Epoch: 48
2022-12-05 20:58:21,364 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4546183747324077, 'Total loss': 0.4546183747324077} | train loss {'Reaction outcome loss': 0.14756898459199133, 'Total loss': 0.14756898459199133}
2022-12-05 20:58:21,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:21,364 INFO:     Epoch: 49
2022-12-05 20:58:22,155 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4612174323675307, 'Total loss': 0.4612174323675307} | train loss {'Reaction outcome loss': 0.14440353491476604, 'Total loss': 0.14440353491476604}
2022-12-05 20:58:22,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:22,155 INFO:     Epoch: 50
2022-12-05 20:58:22,943 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4844734919342128, 'Total loss': 0.4844734919342128} | train loss {'Reaction outcome loss': 0.14464989424664146, 'Total loss': 0.14464989424664146}
2022-12-05 20:58:22,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:22,943 INFO:     Epoch: 51
2022-12-05 20:58:23,730 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4538393946872516, 'Total loss': 0.4538393946872516} | train loss {'Reaction outcome loss': 0.14425677456417862, 'Total loss': 0.14425677456417862}
2022-12-05 20:58:23,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:23,730 INFO:     Epoch: 52
2022-12-05 20:58:24,518 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4646297811572863, 'Total loss': 0.4646297811572863} | train loss {'Reaction outcome loss': 0.14073767732372697, 'Total loss': 0.14073767732372697}
2022-12-05 20:58:24,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:24,518 INFO:     Epoch: 53
2022-12-05 20:58:25,313 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4589923159642653, 'Total loss': 0.4589923159642653} | train loss {'Reaction outcome loss': 0.1440293710070605, 'Total loss': 0.1440293710070605}
2022-12-05 20:58:25,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:25,313 INFO:     Epoch: 54
2022-12-05 20:58:26,106 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46590761721811513, 'Total loss': 0.46590761721811513} | train loss {'Reaction outcome loss': 0.14358662122062274, 'Total loss': 0.14358662122062274}
2022-12-05 20:58:26,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:26,106 INFO:     Epoch: 55
2022-12-05 20:58:26,904 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48549855703657324, 'Total loss': 0.48549855703657324} | train loss {'Reaction outcome loss': 0.14248351032788656, 'Total loss': 0.14248351032788656}
2022-12-05 20:58:26,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:26,904 INFO:     Epoch: 56
2022-12-05 20:58:27,695 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4573596223172816, 'Total loss': 0.4573596223172816} | train loss {'Reaction outcome loss': 0.1397273597820681, 'Total loss': 0.1397273597820681}
2022-12-05 20:58:27,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:27,695 INFO:     Epoch: 57
2022-12-05 20:58:28,485 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47887617552822287, 'Total loss': 0.47887617552822287} | train loss {'Reaction outcome loss': 0.13736316144314348, 'Total loss': 0.13736316144314348}
2022-12-05 20:58:28,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:28,485 INFO:     Epoch: 58
2022-12-05 20:58:29,278 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45106627317992126, 'Total loss': 0.45106627317992126} | train loss {'Reaction outcome loss': 0.1365295638463327, 'Total loss': 0.1365295638463327}
2022-12-05 20:58:29,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:29,279 INFO:     Epoch: 59
2022-12-05 20:58:30,068 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4587030390446836, 'Total loss': 0.4587030390446836} | train loss {'Reaction outcome loss': 0.13668394754545726, 'Total loss': 0.13668394754545726}
2022-12-05 20:58:30,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:30,069 INFO:     Epoch: 60
2022-12-05 20:58:30,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4717760114845904, 'Total loss': 0.4717760114845904} | train loss {'Reaction outcome loss': 0.1388416379157986, 'Total loss': 0.1388416379157986}
2022-12-05 20:58:30,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:30,859 INFO:     Epoch: 61
2022-12-05 20:58:31,649 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4669639856808565, 'Total loss': 0.4669639856808565} | train loss {'Reaction outcome loss': 0.13323305255296278, 'Total loss': 0.13323305255296278}
2022-12-05 20:58:31,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:31,649 INFO:     Epoch: 62
2022-12-05 20:58:32,438 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.448701932687651, 'Total loss': 0.448701932687651} | train loss {'Reaction outcome loss': 0.13444989907498262, 'Total loss': 0.13444989907498262}
2022-12-05 20:58:32,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:32,438 INFO:     Epoch: 63
2022-12-05 20:58:33,228 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4618078944357959, 'Total loss': 0.4618078944357959} | train loss {'Reaction outcome loss': 0.13554075936577759, 'Total loss': 0.13554075936577759}
2022-12-05 20:58:33,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:33,229 INFO:     Epoch: 64
2022-12-05 20:58:34,023 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46149839189919556, 'Total loss': 0.46149839189919556} | train loss {'Reaction outcome loss': 0.13209233388912922, 'Total loss': 0.13209233388912922}
2022-12-05 20:58:34,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:34,023 INFO:     Epoch: 65
2022-12-05 20:58:34,819 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4698587026108395, 'Total loss': 0.4698587026108395} | train loss {'Reaction outcome loss': 0.1331026463408251, 'Total loss': 0.1331026463408251}
2022-12-05 20:58:34,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:34,820 INFO:     Epoch: 66
2022-12-05 20:58:35,616 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4734127050773664, 'Total loss': 0.4734127050773664} | train loss {'Reaction outcome loss': 0.1308892185818784, 'Total loss': 0.1308892185818784}
2022-12-05 20:58:35,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:35,616 INFO:     Epoch: 67
2022-12-05 20:58:36,404 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4623857292939316, 'Total loss': 0.4623857292939316} | train loss {'Reaction outcome loss': 0.13355141855700284, 'Total loss': 0.13355141855700284}
2022-12-05 20:58:36,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:36,405 INFO:     Epoch: 68
2022-12-05 20:58:37,196 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.471895865757357, 'Total loss': 0.471895865757357} | train loss {'Reaction outcome loss': 0.1302762270505939, 'Total loss': 0.1302762270505939}
2022-12-05 20:58:37,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:37,196 INFO:     Epoch: 69
2022-12-05 20:58:37,985 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46368683624843304, 'Total loss': 0.46368683624843304} | train loss {'Reaction outcome loss': 0.12877879844104148, 'Total loss': 0.12877879844104148}
2022-12-05 20:58:37,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:37,985 INFO:     Epoch: 70
2022-12-05 20:58:38,774 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4659720554270528, 'Total loss': 0.4659720554270528} | train loss {'Reaction outcome loss': 0.13166244133204527, 'Total loss': 0.13166244133204527}
2022-12-05 20:58:38,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:38,775 INFO:     Epoch: 71
2022-12-05 20:58:39,568 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4912647134201093, 'Total loss': 0.4912647134201093} | train loss {'Reaction outcome loss': 0.12935076758113442, 'Total loss': 0.12935076758113442}
2022-12-05 20:58:39,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:39,568 INFO:     Epoch: 72
2022-12-05 20:58:40,360 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4976639293811538, 'Total loss': 0.4976639293811538} | train loss {'Reaction outcome loss': 0.12864656682715428, 'Total loss': 0.12864656682715428}
2022-12-05 20:58:40,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:40,360 INFO:     Epoch: 73
2022-12-05 20:58:41,148 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4616233218799938, 'Total loss': 0.4616233218799938} | train loss {'Reaction outcome loss': 0.13152062462224645, 'Total loss': 0.13152062462224645}
2022-12-05 20:58:41,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:41,149 INFO:     Epoch: 74
2022-12-05 20:58:41,948 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47570950571786275, 'Total loss': 0.47570950571786275} | train loss {'Reaction outcome loss': 0.12827725778428875, 'Total loss': 0.12827725778428875}
2022-12-05 20:58:41,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:41,949 INFO:     Epoch: 75
2022-12-05 20:58:42,744 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47255123338916083, 'Total loss': 0.47255123338916083} | train loss {'Reaction outcome loss': 0.12665876324421593, 'Total loss': 0.12665876324421593}
2022-12-05 20:58:42,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:42,744 INFO:     Epoch: 76
2022-12-05 20:58:43,532 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4876999431713061, 'Total loss': 0.4876999431713061} | train loss {'Reaction outcome loss': 0.12730469051368382, 'Total loss': 0.12730469051368382}
2022-12-05 20:58:43,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:43,533 INFO:     Epoch: 77
2022-12-05 20:58:44,323 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4698342288082296, 'Total loss': 0.4698342288082296} | train loss {'Reaction outcome loss': 0.12626358196139337, 'Total loss': 0.12626358196139337}
2022-12-05 20:58:44,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:44,323 INFO:     Epoch: 78
2022-12-05 20:58:45,115 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45837833325971256, 'Total loss': 0.45837833325971256} | train loss {'Reaction outcome loss': 0.1260116697003951, 'Total loss': 0.1260116697003951}
2022-12-05 20:58:45,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:45,116 INFO:     Epoch: 79
2022-12-05 20:58:45,909 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.455845725976608, 'Total loss': 0.455845725976608} | train loss {'Reaction outcome loss': 0.12588619791275385, 'Total loss': 0.12588619791275385}
2022-12-05 20:58:45,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:45,909 INFO:     Epoch: 80
2022-12-05 20:58:46,701 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4692598008974032, 'Total loss': 0.4692598008974032} | train loss {'Reaction outcome loss': 0.12588614756051375, 'Total loss': 0.12588614756051375}
2022-12-05 20:58:46,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:46,701 INFO:     Epoch: 81
2022-12-05 20:58:47,496 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4574815063652667, 'Total loss': 0.4574815063652667} | train loss {'Reaction outcome loss': 0.12713224526722822, 'Total loss': 0.12713224526722822}
2022-12-05 20:58:47,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:47,497 INFO:     Epoch: 82
2022-12-05 20:58:48,287 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4669520055705851, 'Total loss': 0.4669520055705851} | train loss {'Reaction outcome loss': 0.12448049602383862, 'Total loss': 0.12448049602383862}
2022-12-05 20:58:48,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:48,288 INFO:     Epoch: 83
2022-12-05 20:58:49,084 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.440338114107197, 'Total loss': 0.440338114107197} | train loss {'Reaction outcome loss': 0.12247558385513875, 'Total loss': 0.12247558385513875}
2022-12-05 20:58:49,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:49,084 INFO:     Epoch: 84
2022-12-05 20:58:49,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4537081691986797, 'Total loss': 0.4537081691986797} | train loss {'Reaction outcome loss': 0.12327882942496514, 'Total loss': 0.12327882942496514}
2022-12-05 20:58:49,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:49,877 INFO:     Epoch: 85
2022-12-05 20:58:50,665 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4623648627999831, 'Total loss': 0.4623648627999831} | train loss {'Reaction outcome loss': 0.12233553773590497, 'Total loss': 0.12233553773590497}
2022-12-05 20:58:50,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:50,665 INFO:     Epoch: 86
2022-12-05 20:58:51,453 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4630653632974083, 'Total loss': 0.4630653632974083} | train loss {'Reaction outcome loss': 0.12362490807640918, 'Total loss': 0.12362490807640918}
2022-12-05 20:58:51,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:51,453 INFO:     Epoch: 87
2022-12-05 20:58:52,245 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4586943445557898, 'Total loss': 0.4586943445557898} | train loss {'Reaction outcome loss': 0.1257025997097395, 'Total loss': 0.1257025997097395}
2022-12-05 20:58:52,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:52,246 INFO:     Epoch: 88
2022-12-05 20:58:53,039 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4781893589957194, 'Total loss': 0.4781893589957194} | train loss {'Reaction outcome loss': 0.12151882121795599, 'Total loss': 0.12151882121795599}
2022-12-05 20:58:53,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:53,039 INFO:     Epoch: 89
2022-12-05 20:58:53,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47007514570247044, 'Total loss': 0.47007514570247044} | train loss {'Reaction outcome loss': 0.12340740825296664, 'Total loss': 0.12340740825296664}
2022-12-05 20:58:53,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:53,831 INFO:     Epoch: 90
2022-12-05 20:58:54,628 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49397353353825485, 'Total loss': 0.49397353353825485} | train loss {'Reaction outcome loss': 0.12289198513085745, 'Total loss': 0.12289198513085745}
2022-12-05 20:58:54,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:54,628 INFO:     Epoch: 91
2022-12-05 20:58:55,428 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4628027699866586, 'Total loss': 0.4628027699866586} | train loss {'Reaction outcome loss': 0.12175338262578055, 'Total loss': 0.12175338262578055}
2022-12-05 20:58:55,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:55,428 INFO:     Epoch: 92
2022-12-05 20:58:56,224 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4640134241093289, 'Total loss': 0.4640134241093289} | train loss {'Reaction outcome loss': 0.12441645129298677, 'Total loss': 0.12441645129298677}
2022-12-05 20:58:56,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:56,224 INFO:     Epoch: 93
2022-12-05 20:58:57,013 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45247420901432633, 'Total loss': 0.45247420901432633} | train loss {'Reaction outcome loss': 0.12117016962064164, 'Total loss': 0.12117016962064164}
2022-12-05 20:58:57,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:57,013 INFO:     Epoch: 94
2022-12-05 20:58:57,802 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4700860340486873, 'Total loss': 0.4700860340486873} | train loss {'Reaction outcome loss': 0.12051788917837702, 'Total loss': 0.12051788917837702}
2022-12-05 20:58:57,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:57,802 INFO:     Epoch: 95
2022-12-05 20:58:58,590 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47112453424117784, 'Total loss': 0.47112453424117784} | train loss {'Reaction outcome loss': 0.11957331937262598, 'Total loss': 0.11957331937262598}
2022-12-05 20:58:58,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:58,590 INFO:     Epoch: 96
2022-12-05 20:58:59,379 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45812311666932976, 'Total loss': 0.45812311666932976} | train loss {'Reaction outcome loss': 0.11931045139778633, 'Total loss': 0.11931045139778633}
2022-12-05 20:58:59,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:58:59,379 INFO:     Epoch: 97
2022-12-05 20:59:00,167 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.451794697818431, 'Total loss': 0.451794697818431} | train loss {'Reaction outcome loss': 0.11887732928200644, 'Total loss': 0.11887732928200644}
2022-12-05 20:59:00,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:00,168 INFO:     Epoch: 98
2022-12-05 20:59:00,955 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45023393410850654, 'Total loss': 0.45023393410850654} | train loss {'Reaction outcome loss': 0.11974655103926755, 'Total loss': 0.11974655103926755}
2022-12-05 20:59:00,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:00,956 INFO:     Epoch: 99
2022-12-05 20:59:01,744 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4349117817526514, 'Total loss': 0.4349117817526514} | train loss {'Reaction outcome loss': 0.11820606954813916, 'Total loss': 0.11820606954813916}
2022-12-05 20:59:01,744 INFO:     Best model found after epoch 14 of 100.
2022-12-05 20:59:01,744 INFO:   Done with stage: TRAINING
2022-12-05 20:59:01,745 INFO:   Starting stage: EVALUATION
2022-12-05 20:59:01,875 INFO:   Done with stage: EVALUATION
2022-12-05 20:59:01,875 INFO:   Leaving out SEQ value Fold_4
2022-12-05 20:59:01,888 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 20:59:01,888 INFO:   Starting stage: FEATURE SCALING
2022-12-05 20:59:02,532 INFO:   Done with stage: FEATURE SCALING
2022-12-05 20:59:02,532 INFO:   Starting stage: SCALING TARGETS
2022-12-05 20:59:02,601 INFO:   Done with stage: SCALING TARGETS
2022-12-05 20:59:02,601 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:59:02,601 INFO:     No hyperparam tuning for this model
2022-12-05 20:59:02,601 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 20:59:02,601 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 20:59:02,602 INFO:     None feature selector for col prot
2022-12-05 20:59:02,602 INFO:     None feature selector for col prot
2022-12-05 20:59:02,602 INFO:     None feature selector for col prot
2022-12-05 20:59:02,603 INFO:     None feature selector for col chem
2022-12-05 20:59:02,603 INFO:     None feature selector for col chem
2022-12-05 20:59:02,603 INFO:     None feature selector for col chem
2022-12-05 20:59:02,603 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 20:59:02,603 INFO:   Starting stage: BUILD MODEL
2022-12-05 20:59:02,605 INFO:     Number of params in model 215821
2022-12-05 20:59:02,608 INFO:   Done with stage: BUILD MODEL
2022-12-05 20:59:02,608 INFO:   Starting stage: TRAINING
2022-12-05 20:59:02,669 INFO:     Val loss before train {'Reaction outcome loss': 0.9791173528541218, 'Total loss': 0.9791173528541218}
2022-12-05 20:59:02,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:02,669 INFO:     Epoch: 0
2022-12-05 20:59:03,469 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.63716240294955, 'Total loss': 0.63716240294955} | train loss {'Reaction outcome loss': 0.8143357543523616, 'Total loss': 0.8143357543523616}
2022-12-05 20:59:03,469 INFO:     Found new best model at epoch 0
2022-12-05 20:59:03,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:03,470 INFO:     Epoch: 1
2022-12-05 20:59:04,268 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.527464706112038, 'Total loss': 0.527464706112038} | train loss {'Reaction outcome loss': 0.5699521325498458, 'Total loss': 0.5699521325498458}
2022-12-05 20:59:04,268 INFO:     Found new best model at epoch 1
2022-12-05 20:59:04,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:04,269 INFO:     Epoch: 2
2022-12-05 20:59:05,061 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49344522980126465, 'Total loss': 0.49344522980126465} | train loss {'Reaction outcome loss': 0.4859923359594847, 'Total loss': 0.4859923359594847}
2022-12-05 20:59:05,061 INFO:     Found new best model at epoch 2
2022-12-05 20:59:05,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:05,062 INFO:     Epoch: 3
2022-12-05 20:59:05,857 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46559951318935916, 'Total loss': 0.46559951318935916} | train loss {'Reaction outcome loss': 0.4442630329957375, 'Total loss': 0.4442630329957375}
2022-12-05 20:59:05,857 INFO:     Found new best model at epoch 3
2022-12-05 20:59:05,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:05,858 INFO:     Epoch: 4
2022-12-05 20:59:06,652 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46320869197899645, 'Total loss': 0.46320869197899645} | train loss {'Reaction outcome loss': 0.41045282636335506, 'Total loss': 0.41045282636335506}
2022-12-05 20:59:06,653 INFO:     Found new best model at epoch 4
2022-12-05 20:59:06,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:06,653 INFO:     Epoch: 5
2022-12-05 20:59:07,448 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4462162845514037, 'Total loss': 0.4462162845514037} | train loss {'Reaction outcome loss': 0.38393755079160335, 'Total loss': 0.38393755079160335}
2022-12-05 20:59:07,448 INFO:     Found new best model at epoch 5
2022-12-05 20:59:07,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:07,449 INFO:     Epoch: 6
2022-12-05 20:59:08,240 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43428891456939955, 'Total loss': 0.43428891456939955} | train loss {'Reaction outcome loss': 0.3624109043042187, 'Total loss': 0.3624109043042187}
2022-12-05 20:59:08,241 INFO:     Found new best model at epoch 6
2022-12-05 20:59:08,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:08,242 INFO:     Epoch: 7
2022-12-05 20:59:09,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4357687678526748, 'Total loss': 0.4357687678526748} | train loss {'Reaction outcome loss': 0.3480123799701451, 'Total loss': 0.3480123799701451}
2022-12-05 20:59:09,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:09,034 INFO:     Epoch: 8
2022-12-05 20:59:09,827 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42920685339380393, 'Total loss': 0.42920685339380393} | train loss {'Reaction outcome loss': 0.3335368247619766, 'Total loss': 0.3335368247619766}
2022-12-05 20:59:09,827 INFO:     Found new best model at epoch 8
2022-12-05 20:59:09,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:09,828 INFO:     Epoch: 9
2022-12-05 20:59:10,625 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4413540485230359, 'Total loss': 0.4413540485230359} | train loss {'Reaction outcome loss': 0.31703948866017917, 'Total loss': 0.31703948866017917}
2022-12-05 20:59:10,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:10,625 INFO:     Epoch: 10
2022-12-05 20:59:11,422 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4342623417350379, 'Total loss': 0.4342623417350379} | train loss {'Reaction outcome loss': 0.31549182856975777, 'Total loss': 0.31549182856975777}
2022-12-05 20:59:11,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:11,423 INFO:     Epoch: 11
2022-12-05 20:59:12,218 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43264930017969827, 'Total loss': 0.43264930017969827} | train loss {'Reaction outcome loss': 0.3066975998914676, 'Total loss': 0.3066975998914676}
2022-12-05 20:59:12,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:12,218 INFO:     Epoch: 12
2022-12-05 20:59:13,015 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42597445574673737, 'Total loss': 0.42597445574673737} | train loss {'Reaction outcome loss': 0.2933407949683396, 'Total loss': 0.2933407949683396}
2022-12-05 20:59:13,016 INFO:     Found new best model at epoch 12
2022-12-05 20:59:13,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:13,016 INFO:     Epoch: 13
2022-12-05 20:59:13,813 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41401379250667314, 'Total loss': 0.41401379250667314} | train loss {'Reaction outcome loss': 0.2800724694905011, 'Total loss': 0.2800724694905011}
2022-12-05 20:59:13,813 INFO:     Found new best model at epoch 13
2022-12-05 20:59:13,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:13,814 INFO:     Epoch: 14
2022-12-05 20:59:14,613 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4284208057956262, 'Total loss': 0.4284208057956262} | train loss {'Reaction outcome loss': 0.26987758411569635, 'Total loss': 0.26987758411569635}
2022-12-05 20:59:14,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:14,613 INFO:     Epoch: 15
2022-12-05 20:59:15,408 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4178125529804013, 'Total loss': 0.4178125529804013} | train loss {'Reaction outcome loss': 0.2631016609519117, 'Total loss': 0.2631016609519117}
2022-12-05 20:59:15,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:15,408 INFO:     Epoch: 16
2022-12-05 20:59:16,201 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4214402718300169, 'Total loss': 0.4214402718300169} | train loss {'Reaction outcome loss': 0.2538149073146857, 'Total loss': 0.2538149073146857}
2022-12-05 20:59:16,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:16,202 INFO:     Epoch: 17
2022-12-05 20:59:16,997 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4179544377733361, 'Total loss': 0.4179544377733361} | train loss {'Reaction outcome loss': 0.24548073584281724, 'Total loss': 0.24548073584281724}
2022-12-05 20:59:16,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:16,997 INFO:     Epoch: 18
2022-12-05 20:59:17,789 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4359223629263314, 'Total loss': 0.4359223629263314} | train loss {'Reaction outcome loss': 0.24116131894079298, 'Total loss': 0.24116131894079298}
2022-12-05 20:59:17,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:17,789 INFO:     Epoch: 19
2022-12-05 20:59:18,583 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.426190953024409, 'Total loss': 0.426190953024409} | train loss {'Reaction outcome loss': 0.23641014215347889, 'Total loss': 0.23641014215347889}
2022-12-05 20:59:18,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:18,583 INFO:     Epoch: 20
2022-12-05 20:59:19,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43865067630328913, 'Total loss': 0.43865067630328913} | train loss {'Reaction outcome loss': 0.23073084537799543, 'Total loss': 0.23073084537799543}
2022-12-05 20:59:19,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:19,384 INFO:     Epoch: 21
2022-12-05 20:59:20,187 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43190053376284515, 'Total loss': 0.43190053376284515} | train loss {'Reaction outcome loss': 0.22359457776433062, 'Total loss': 0.22359457776433062}
2022-12-05 20:59:20,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:20,187 INFO:     Epoch: 22
2022-12-05 20:59:20,987 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4290269332175905, 'Total loss': 0.4290269332175905} | train loss {'Reaction outcome loss': 0.21754732483673675, 'Total loss': 0.21754732483673675}
2022-12-05 20:59:20,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:20,987 INFO:     Epoch: 23
2022-12-05 20:59:21,782 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4237433573739095, 'Total loss': 0.4237433573739095} | train loss {'Reaction outcome loss': 0.21580601877227487, 'Total loss': 0.21580601877227487}
2022-12-05 20:59:21,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:21,782 INFO:     Epoch: 24
2022-12-05 20:59:22,575 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43234526670791884, 'Total loss': 0.43234526670791884} | train loss {'Reaction outcome loss': 0.20959793459548642, 'Total loss': 0.20959793459548642}
2022-12-05 20:59:22,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:22,575 INFO:     Epoch: 25
2022-12-05 20:59:23,367 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4278115298260342, 'Total loss': 0.4278115298260342} | train loss {'Reaction outcome loss': 0.20147141428505963, 'Total loss': 0.20147141428505963}
2022-12-05 20:59:23,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:23,368 INFO:     Epoch: 26
2022-12-05 20:59:24,164 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4182327156039802, 'Total loss': 0.4182327156039802} | train loss {'Reaction outcome loss': 0.20279242356236166, 'Total loss': 0.20279242356236166}
2022-12-05 20:59:24,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:24,164 INFO:     Epoch: 27
2022-12-05 20:59:24,959 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4317099844867533, 'Total loss': 0.4317099844867533} | train loss {'Reaction outcome loss': 0.19830489876540566, 'Total loss': 0.19830489876540566}
2022-12-05 20:59:24,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:24,959 INFO:     Epoch: 28
2022-12-05 20:59:25,757 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42017438262701035, 'Total loss': 0.42017438262701035} | train loss {'Reaction outcome loss': 0.19380062248422067, 'Total loss': 0.19380062248422067}
2022-12-05 20:59:25,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:25,757 INFO:     Epoch: 29
2022-12-05 20:59:26,550 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4318388348275965, 'Total loss': 0.4318388348275965} | train loss {'Reaction outcome loss': 0.19022510205546342, 'Total loss': 0.19022510205546342}
2022-12-05 20:59:26,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:26,550 INFO:     Epoch: 30
2022-12-05 20:59:27,346 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4276789575815201, 'Total loss': 0.4276789575815201} | train loss {'Reaction outcome loss': 0.1849686409373153, 'Total loss': 0.1849686409373153}
2022-12-05 20:59:27,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:27,346 INFO:     Epoch: 31
2022-12-05 20:59:28,140 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4386952495710416, 'Total loss': 0.4386952495710416} | train loss {'Reaction outcome loss': 0.18389762889005637, 'Total loss': 0.18389762889005637}
2022-12-05 20:59:28,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:28,140 INFO:     Epoch: 32
2022-12-05 20:59:28,941 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44395388527349994, 'Total loss': 0.44395388527349994} | train loss {'Reaction outcome loss': 0.18063631423028856, 'Total loss': 0.18063631423028856}
2022-12-05 20:59:28,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:28,941 INFO:     Epoch: 33
2022-12-05 20:59:29,734 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45755290578712116, 'Total loss': 0.45755290578712116} | train loss {'Reaction outcome loss': 0.17765898446115072, 'Total loss': 0.17765898446115072}
2022-12-05 20:59:29,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:29,734 INFO:     Epoch: 34
2022-12-05 20:59:30,526 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44821344722401013, 'Total loss': 0.44821344722401013} | train loss {'Reaction outcome loss': 0.175046833701477, 'Total loss': 0.175046833701477}
2022-12-05 20:59:30,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:30,526 INFO:     Epoch: 35
2022-12-05 20:59:31,318 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44690351763909514, 'Total loss': 0.44690351763909514} | train loss {'Reaction outcome loss': 0.17020541960411226, 'Total loss': 0.17020541960411226}
2022-12-05 20:59:31,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:31,319 INFO:     Epoch: 36
2022-12-05 20:59:32,114 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4293001267043027, 'Total loss': 0.4293001267043027} | train loss {'Reaction outcome loss': 0.17176099244867138, 'Total loss': 0.17176099244867138}
2022-12-05 20:59:32,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:32,115 INFO:     Epoch: 37
2022-12-05 20:59:32,908 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43755156614563684, 'Total loss': 0.43755156614563684} | train loss {'Reaction outcome loss': 0.16521160419170672, 'Total loss': 0.16521160419170672}
2022-12-05 20:59:32,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:32,909 INFO:     Epoch: 38
2022-12-05 20:59:33,702 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4489381950009953, 'Total loss': 0.4489381950009953} | train loss {'Reaction outcome loss': 0.1669100585284262, 'Total loss': 0.1669100585284262}
2022-12-05 20:59:33,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:33,703 INFO:     Epoch: 39
2022-12-05 20:59:34,501 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4318283654072068, 'Total loss': 0.4318283654072068} | train loss {'Reaction outcome loss': 0.16300822686600058, 'Total loss': 0.16300822686600058}
2022-12-05 20:59:34,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:34,501 INFO:     Epoch: 40
2022-12-05 20:59:35,298 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4364945715801282, 'Total loss': 0.4364945715801282} | train loss {'Reaction outcome loss': 0.16839632722982753, 'Total loss': 0.16839632722982753}
2022-12-05 20:59:35,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:35,298 INFO:     Epoch: 41
2022-12-05 20:59:36,090 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4458828036758033, 'Total loss': 0.4458828036758033} | train loss {'Reaction outcome loss': 0.1654171090919962, 'Total loss': 0.1654171090919962}
2022-12-05 20:59:36,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:36,090 INFO:     Epoch: 42
2022-12-05 20:59:36,886 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43254439820620144, 'Total loss': 0.43254439820620144} | train loss {'Reaction outcome loss': 0.16022199707535598, 'Total loss': 0.16022199707535598}
2022-12-05 20:59:36,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:36,887 INFO:     Epoch: 43
2022-12-05 20:59:37,685 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4415504371916706, 'Total loss': 0.4415504371916706} | train loss {'Reaction outcome loss': 0.15886451913654684, 'Total loss': 0.15886451913654684}
2022-12-05 20:59:37,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:37,685 INFO:     Epoch: 44
2022-12-05 20:59:38,485 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42783757993443444, 'Total loss': 0.42783757993443444} | train loss {'Reaction outcome loss': 0.15424574208389288, 'Total loss': 0.15424574208389288}
2022-12-05 20:59:38,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:38,485 INFO:     Epoch: 45
2022-12-05 20:59:39,285 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43779183754866774, 'Total loss': 0.43779183754866774} | train loss {'Reaction outcome loss': 0.15379781498449294, 'Total loss': 0.15379781498449294}
2022-12-05 20:59:39,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:39,285 INFO:     Epoch: 46
2022-12-05 20:59:40,085 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43201089243997226, 'Total loss': 0.43201089243997226} | train loss {'Reaction outcome loss': 0.15450948785221288, 'Total loss': 0.15450948785221288}
2022-12-05 20:59:40,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:40,085 INFO:     Epoch: 47
2022-12-05 20:59:40,880 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4435434988276525, 'Total loss': 0.4435434988276525} | train loss {'Reaction outcome loss': 0.150950199781129, 'Total loss': 0.150950199781129}
2022-12-05 20:59:40,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:40,880 INFO:     Epoch: 48
2022-12-05 20:59:41,679 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4454956884411248, 'Total loss': 0.4454956884411248} | train loss {'Reaction outcome loss': 0.14991042404793775, 'Total loss': 0.14991042404793775}
2022-12-05 20:59:41,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:41,679 INFO:     Epoch: 49
2022-12-05 20:59:42,476 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4381713657216592, 'Total loss': 0.4381713657216592} | train loss {'Reaction outcome loss': 0.149409669563589, 'Total loss': 0.149409669563589}
2022-12-05 20:59:42,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:42,476 INFO:     Epoch: 50
2022-12-05 20:59:43,268 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4570421969348734, 'Total loss': 0.4570421969348734} | train loss {'Reaction outcome loss': 0.147601392359552, 'Total loss': 0.147601392359552}
2022-12-05 20:59:43,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:43,268 INFO:     Epoch: 51
2022-12-05 20:59:44,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4481347816234285, 'Total loss': 0.4481347816234285} | train loss {'Reaction outcome loss': 0.14646526976669516, 'Total loss': 0.14646526976669516}
2022-12-05 20:59:44,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:44,064 INFO:     Epoch: 52
2022-12-05 20:59:44,860 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43526514077728445, 'Total loss': 0.43526514077728445} | train loss {'Reaction outcome loss': 0.14775405287259985, 'Total loss': 0.14775405287259985}
2022-12-05 20:59:44,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:44,860 INFO:     Epoch: 53
2022-12-05 20:59:45,665 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43601047721776093, 'Total loss': 0.43601047721776093} | train loss {'Reaction outcome loss': 0.14528912605966635, 'Total loss': 0.14528912605966635}
2022-12-05 20:59:45,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:45,665 INFO:     Epoch: 54
2022-12-05 20:59:46,461 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43392166563055734, 'Total loss': 0.43392166563055734} | train loss {'Reaction outcome loss': 0.14295905205583284, 'Total loss': 0.14295905205583284}
2022-12-05 20:59:46,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:46,461 INFO:     Epoch: 55
2022-12-05 20:59:47,256 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45377266305414116, 'Total loss': 0.45377266305414116} | train loss {'Reaction outcome loss': 0.1446509364057287, 'Total loss': 0.1446509364057287}
2022-12-05 20:59:47,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:47,256 INFO:     Epoch: 56
2022-12-05 20:59:48,054 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4364575831727548, 'Total loss': 0.4364575831727548} | train loss {'Reaction outcome loss': 0.14595110612631085, 'Total loss': 0.14595110612631085}
2022-12-05 20:59:48,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:48,054 INFO:     Epoch: 57
2022-12-05 20:59:48,851 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4492689232257279, 'Total loss': 0.4492689232257279} | train loss {'Reaction outcome loss': 0.14191100918518207, 'Total loss': 0.14191100918518207}
2022-12-05 20:59:48,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:48,851 INFO:     Epoch: 58
2022-12-05 20:59:49,646 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4426306347278031, 'Total loss': 0.4426306347278031} | train loss {'Reaction outcome loss': 0.14225019486658727, 'Total loss': 0.14225019486658727}
2022-12-05 20:59:49,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:49,646 INFO:     Epoch: 59
2022-12-05 20:59:50,440 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4493253860961307, 'Total loss': 0.4493253860961307} | train loss {'Reaction outcome loss': 0.14010517075016854, 'Total loss': 0.14010517075016854}
2022-12-05 20:59:50,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:50,441 INFO:     Epoch: 60
2022-12-05 20:59:51,237 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4265873530371623, 'Total loss': 0.4265873530371623} | train loss {'Reaction outcome loss': 0.138181316455155, 'Total loss': 0.138181316455155}
2022-12-05 20:59:51,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:51,237 INFO:     Epoch: 61
2022-12-05 20:59:52,038 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43679382448846643, 'Total loss': 0.43679382448846643} | train loss {'Reaction outcome loss': 0.13684532493503712, 'Total loss': 0.13684532493503712}
2022-12-05 20:59:52,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:52,038 INFO:     Epoch: 62
2022-12-05 20:59:52,829 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.441409610550512, 'Total loss': 0.441409610550512} | train loss {'Reaction outcome loss': 0.137160118160249, 'Total loss': 0.137160118160249}
2022-12-05 20:59:52,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:52,829 INFO:     Epoch: 63
2022-12-05 20:59:53,619 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43760907819325273, 'Total loss': 0.43760907819325273} | train loss {'Reaction outcome loss': 0.13755075188885305, 'Total loss': 0.13755075188885305}
2022-12-05 20:59:53,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:53,619 INFO:     Epoch: 64
2022-12-05 20:59:54,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4359025006944483, 'Total loss': 0.4359025006944483} | train loss {'Reaction outcome loss': 0.1338409368431399, 'Total loss': 0.1338409368431399}
2022-12-05 20:59:54,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:54,409 INFO:     Epoch: 65
2022-12-05 20:59:55,206 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4406039955263788, 'Total loss': 0.4406039955263788} | train loss {'Reaction outcome loss': 0.1328852373469425, 'Total loss': 0.1328852373469425}
2022-12-05 20:59:55,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:55,206 INFO:     Epoch: 66
2022-12-05 20:59:55,999 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4539111381904645, 'Total loss': 0.4539111381904645} | train loss {'Reaction outcome loss': 0.12991395357219496, 'Total loss': 0.12991395357219496}
2022-12-05 20:59:56,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:56,000 INFO:     Epoch: 67
2022-12-05 20:59:56,790 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4660926813429052, 'Total loss': 0.4660926813429052} | train loss {'Reaction outcome loss': 0.13232653146903767, 'Total loss': 0.13232653146903767}
2022-12-05 20:59:56,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:56,790 INFO:     Epoch: 68
2022-12-05 20:59:57,587 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4541156640784307, 'Total loss': 0.4541156640784307} | train loss {'Reaction outcome loss': 0.13402816106618085, 'Total loss': 0.13402816106618085}
2022-12-05 20:59:57,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:57,587 INFO:     Epoch: 69
2022-12-05 20:59:58,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44316824576394126, 'Total loss': 0.44316824576394126} | train loss {'Reaction outcome loss': 0.13032931514340734, 'Total loss': 0.13032931514340734}
2022-12-05 20:59:58,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:58,383 INFO:     Epoch: 70
2022-12-05 20:59:59,181 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45159142870794644, 'Total loss': 0.45159142870794644} | train loss {'Reaction outcome loss': 0.1305223526946846, 'Total loss': 0.1305223526946846}
2022-12-05 20:59:59,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:59,182 INFO:     Epoch: 71
2022-12-05 20:59:59,972 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4340242963622917, 'Total loss': 0.4340242963622917} | train loss {'Reaction outcome loss': 0.12929167259715005, 'Total loss': 0.12929167259715005}
2022-12-05 20:59:59,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 20:59:59,972 INFO:     Epoch: 72
2022-12-05 21:00:00,762 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44622527435421944, 'Total loss': 0.44622527435421944} | train loss {'Reaction outcome loss': 0.13412781673208302, 'Total loss': 0.13412781673208302}
2022-12-05 21:00:00,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:00,762 INFO:     Epoch: 73
2022-12-05 21:00:01,557 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45574065670371056, 'Total loss': 0.45574065670371056} | train loss {'Reaction outcome loss': 0.1314311424997986, 'Total loss': 0.1314311424997986}
2022-12-05 21:00:01,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:01,558 INFO:     Epoch: 74
2022-12-05 21:00:02,347 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4579331238161434, 'Total loss': 0.4579331238161434} | train loss {'Reaction outcome loss': 0.12947689569442106, 'Total loss': 0.12947689569442106}
2022-12-05 21:00:02,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:02,347 INFO:     Epoch: 75
2022-12-05 21:00:03,136 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44364987686276436, 'Total loss': 0.44364987686276436} | train loss {'Reaction outcome loss': 0.12701393849110826, 'Total loss': 0.12701393849110826}
2022-12-05 21:00:03,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:03,137 INFO:     Epoch: 76
2022-12-05 21:00:03,925 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46123087338425894, 'Total loss': 0.46123087338425894} | train loss {'Reaction outcome loss': 0.13155074043930903, 'Total loss': 0.13155074043930903}
2022-12-05 21:00:03,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:03,926 INFO:     Epoch: 77
2022-12-05 21:00:04,714 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4601627556099133, 'Total loss': 0.4601627556099133} | train loss {'Reaction outcome loss': 0.13062838550943595, 'Total loss': 0.13062838550943595}
2022-12-05 21:00:04,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:04,714 INFO:     Epoch: 78
2022-12-05 21:00:05,503 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46723679622465913, 'Total loss': 0.46723679622465913} | train loss {'Reaction outcome loss': 0.13193419536854695, 'Total loss': 0.13193419536854695}
2022-12-05 21:00:05,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:05,504 INFO:     Epoch: 79
2022-12-05 21:00:06,293 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4485245079479434, 'Total loss': 0.4485245079479434} | train loss {'Reaction outcome loss': 0.1272027457853108, 'Total loss': 0.1272027457853108}
2022-12-05 21:00:06,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:06,293 INFO:     Epoch: 80
2022-12-05 21:00:07,081 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45863227563148196, 'Total loss': 0.45863227563148196} | train loss {'Reaction outcome loss': 0.12388839582094417, 'Total loss': 0.12388839582094417}
2022-12-05 21:00:07,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:07,081 INFO:     Epoch: 81
2022-12-05 21:00:07,872 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4545661803673614, 'Total loss': 0.4545661803673614} | train loss {'Reaction outcome loss': 0.12610993298290954, 'Total loss': 0.12610993298290954}
2022-12-05 21:00:07,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:07,872 INFO:     Epoch: 82
2022-12-05 21:00:08,665 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44623933935707266, 'Total loss': 0.44623933935707266} | train loss {'Reaction outcome loss': 0.12534046705589755, 'Total loss': 0.12534046705589755}
2022-12-05 21:00:08,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:08,665 INFO:     Epoch: 83
2022-12-05 21:00:09,460 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4527399573813785, 'Total loss': 0.4527399573813785} | train loss {'Reaction outcome loss': 0.12490493002788801, 'Total loss': 0.12490493002788801}
2022-12-05 21:00:09,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:09,460 INFO:     Epoch: 84
2022-12-05 21:00:10,252 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43707621470093727, 'Total loss': 0.43707621470093727} | train loss {'Reaction outcome loss': 0.12504987884689922, 'Total loss': 0.12504987884689922}
2022-12-05 21:00:10,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:10,252 INFO:     Epoch: 85
2022-12-05 21:00:11,049 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.442066027359529, 'Total loss': 0.442066027359529} | train loss {'Reaction outcome loss': 0.12671690887813022, 'Total loss': 0.12671690887813022}
2022-12-05 21:00:11,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:11,049 INFO:     Epoch: 86
2022-12-05 21:00:11,844 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4449539692564444, 'Total loss': 0.4449539692564444} | train loss {'Reaction outcome loss': 0.1277414013043438, 'Total loss': 0.1277414013043438}
2022-12-05 21:00:11,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:11,844 INFO:     Epoch: 87
2022-12-05 21:00:12,641 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44139389994300227, 'Total loss': 0.44139389994300227} | train loss {'Reaction outcome loss': 0.12377162579353239, 'Total loss': 0.12377162579353239}
2022-12-05 21:00:12,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:12,641 INFO:     Epoch: 88
2022-12-05 21:00:13,435 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4351314519616691, 'Total loss': 0.4351314519616691} | train loss {'Reaction outcome loss': 0.12122109636234549, 'Total loss': 0.12122109636234549}
2022-12-05 21:00:13,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:13,435 INFO:     Epoch: 89
2022-12-05 21:00:14,225 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4623223580420017, 'Total loss': 0.4623223580420017} | train loss {'Reaction outcome loss': 0.1224014148764644, 'Total loss': 0.1224014148764644}
2022-12-05 21:00:14,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:14,225 INFO:     Epoch: 90
2022-12-05 21:00:15,015 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44076643426987255, 'Total loss': 0.44076643426987255} | train loss {'Reaction outcome loss': 0.12407132987732347, 'Total loss': 0.12407132987732347}
2022-12-05 21:00:15,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:15,017 INFO:     Epoch: 91
2022-12-05 21:00:15,807 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44505616412921384, 'Total loss': 0.44505616412921384} | train loss {'Reaction outcome loss': 0.12337976953095799, 'Total loss': 0.12337976953095799}
2022-12-05 21:00:15,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:15,807 INFO:     Epoch: 92
2022-12-05 21:00:16,607 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45699815011837264, 'Total loss': 0.45699815011837264} | train loss {'Reaction outcome loss': 0.11970033644423311, 'Total loss': 0.11970033644423311}
2022-12-05 21:00:16,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:16,608 INFO:     Epoch: 93
2022-12-05 21:00:17,402 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43146514012054965, 'Total loss': 0.43146514012054965} | train loss {'Reaction outcome loss': 0.12635681668658427, 'Total loss': 0.12635681668658427}
2022-12-05 21:00:17,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:17,402 INFO:     Epoch: 94
2022-12-05 21:00:18,203 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4694239189001647, 'Total loss': 0.4694239189001647} | train loss {'Reaction outcome loss': 0.12275008565222144, 'Total loss': 0.12275008565222144}
2022-12-05 21:00:18,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:18,203 INFO:     Epoch: 95
2022-12-05 21:00:19,002 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4614600024440072, 'Total loss': 0.4614600024440072} | train loss {'Reaction outcome loss': 0.1221846072267183, 'Total loss': 0.1221846072267183}
2022-12-05 21:00:19,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:19,002 INFO:     Epoch: 96
2022-12-05 21:00:19,800 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4622106731615283, 'Total loss': 0.4622106731615283} | train loss {'Reaction outcome loss': 0.12130595069107136, 'Total loss': 0.12130595069107136}
2022-12-05 21:00:19,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:19,800 INFO:     Epoch: 97
2022-12-05 21:00:20,594 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4460639152675867, 'Total loss': 0.4460639152675867} | train loss {'Reaction outcome loss': 0.12203068355558372, 'Total loss': 0.12203068355558372}
2022-12-05 21:00:20,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:20,594 INFO:     Epoch: 98
2022-12-05 21:00:21,384 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4472087039188905, 'Total loss': 0.4472087039188905} | train loss {'Reaction outcome loss': 0.11911820547715553, 'Total loss': 0.11911820547715553}
2022-12-05 21:00:21,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:21,385 INFO:     Epoch: 99
2022-12-05 21:00:22,179 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44933621991764416, 'Total loss': 0.44933621991764416} | train loss {'Reaction outcome loss': 0.12131493005464193, 'Total loss': 0.12131493005464193}
2022-12-05 21:00:22,179 INFO:     Best model found after epoch 14 of 100.
2022-12-05 21:00:22,180 INFO:   Done with stage: TRAINING
2022-12-05 21:00:22,180 INFO:   Starting stage: EVALUATION
2022-12-05 21:00:22,304 INFO:   Done with stage: EVALUATION
2022-12-05 21:00:22,304 INFO:   Leaving out SEQ value Fold_5
2022-12-05 21:00:22,317 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:00:22,317 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:00:22,959 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:00:22,959 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:00:23,028 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:00:23,028 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:00:23,028 INFO:     No hyperparam tuning for this model
2022-12-05 21:00:23,028 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:00:23,028 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:00:23,029 INFO:     None feature selector for col prot
2022-12-05 21:00:23,029 INFO:     None feature selector for col prot
2022-12-05 21:00:23,029 INFO:     None feature selector for col prot
2022-12-05 21:00:23,029 INFO:     None feature selector for col chem
2022-12-05 21:00:23,030 INFO:     None feature selector for col chem
2022-12-05 21:00:23,030 INFO:     None feature selector for col chem
2022-12-05 21:00:23,030 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:00:23,030 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:00:23,031 INFO:     Number of params in model 215821
2022-12-05 21:00:23,035 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:00:23,035 INFO:   Starting stage: TRAINING
2022-12-05 21:00:23,095 INFO:     Val loss before train {'Reaction outcome loss': 1.0010092041709207, 'Total loss': 1.0010092041709207}
2022-12-05 21:00:23,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:23,096 INFO:     Epoch: 0
2022-12-05 21:00:23,887 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5781835717233744, 'Total loss': 0.5781835717233744} | train loss {'Reaction outcome loss': 0.7718217516476326, 'Total loss': 0.7718217516476326}
2022-12-05 21:00:23,887 INFO:     Found new best model at epoch 0
2022-12-05 21:00:23,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:23,888 INFO:     Epoch: 1
2022-12-05 21:00:24,682 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48526482995260845, 'Total loss': 0.48526482995260845} | train loss {'Reaction outcome loss': 0.5289866330652584, 'Total loss': 0.5289866330652584}
2022-12-05 21:00:24,682 INFO:     Found new best model at epoch 1
2022-12-05 21:00:24,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:24,683 INFO:     Epoch: 2
2022-12-05 21:00:25,477 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4628531790592454, 'Total loss': 0.4628531790592454} | train loss {'Reaction outcome loss': 0.4605533872780047, 'Total loss': 0.4605533872780047}
2022-12-05 21:00:25,477 INFO:     Found new best model at epoch 2
2022-12-05 21:00:25,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:25,478 INFO:     Epoch: 3
2022-12-05 21:00:26,274 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4332657148214904, 'Total loss': 0.4332657148214904} | train loss {'Reaction outcome loss': 0.419753827727758, 'Total loss': 0.419753827727758}
2022-12-05 21:00:26,274 INFO:     Found new best model at epoch 3
2022-12-05 21:00:26,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:26,275 INFO:     Epoch: 4
2022-12-05 21:00:27,071 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4283246746794744, 'Total loss': 0.4283246746794744} | train loss {'Reaction outcome loss': 0.39616114591900636, 'Total loss': 0.39616114591900636}
2022-12-05 21:00:27,071 INFO:     Found new best model at epoch 4
2022-12-05 21:00:27,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:27,072 INFO:     Epoch: 5
2022-12-05 21:00:27,864 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.422449049285867, 'Total loss': 0.422449049285867} | train loss {'Reaction outcome loss': 0.37549020859755966, 'Total loss': 0.37549020859755966}
2022-12-05 21:00:27,864 INFO:     Found new best model at epoch 5
2022-12-05 21:00:27,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:27,865 INFO:     Epoch: 6
2022-12-05 21:00:28,663 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4138964223252101, 'Total loss': 0.4138964223252101} | train loss {'Reaction outcome loss': 0.3531303945400937, 'Total loss': 0.3531303945400937}
2022-12-05 21:00:28,664 INFO:     Found new best model at epoch 6
2022-12-05 21:00:28,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:28,664 INFO:     Epoch: 7
2022-12-05 21:00:29,461 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3988213799893856, 'Total loss': 0.3988213799893856} | train loss {'Reaction outcome loss': 0.33720575420841997, 'Total loss': 0.33720575420841997}
2022-12-05 21:00:29,462 INFO:     Found new best model at epoch 7
2022-12-05 21:00:29,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:29,462 INFO:     Epoch: 8
2022-12-05 21:00:30,257 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3829055377705531, 'Total loss': 0.3829055377705531} | train loss {'Reaction outcome loss': 0.32185257360459824, 'Total loss': 0.32185257360459824}
2022-12-05 21:00:30,257 INFO:     Found new best model at epoch 8
2022-12-05 21:00:30,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:30,258 INFO:     Epoch: 9
2022-12-05 21:00:31,048 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4099294969981367, 'Total loss': 0.4099294969981367} | train loss {'Reaction outcome loss': 0.3078600310301974, 'Total loss': 0.3078600310301974}
2022-12-05 21:00:31,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:31,049 INFO:     Epoch: 10
2022-12-05 21:00:31,839 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3974215510216626, 'Total loss': 0.3974215510216626} | train loss {'Reaction outcome loss': 0.2955291869744719, 'Total loss': 0.2955291869744719}
2022-12-05 21:00:31,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:31,840 INFO:     Epoch: 11
2022-12-05 21:00:32,634 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4060346783900803, 'Total loss': 0.4060346783900803} | train loss {'Reaction outcome loss': 0.28433838498737163, 'Total loss': 0.28433838498737163}
2022-12-05 21:00:32,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:32,634 INFO:     Epoch: 12
2022-12-05 21:00:33,424 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39430668171156535, 'Total loss': 0.39430668171156535} | train loss {'Reaction outcome loss': 0.27052730816578574, 'Total loss': 0.27052730816578574}
2022-12-05 21:00:33,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:33,425 INFO:     Epoch: 13
2022-12-05 21:00:34,216 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39829536188732495, 'Total loss': 0.39829536188732495} | train loss {'Reaction outcome loss': 0.26420209654097854, 'Total loss': 0.26420209654097854}
2022-12-05 21:00:34,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:34,216 INFO:     Epoch: 14
2022-12-05 21:00:35,013 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40091427584940736, 'Total loss': 0.40091427584940736} | train loss {'Reaction outcome loss': 0.25555256306220164, 'Total loss': 0.25555256306220164}
2022-12-05 21:00:35,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:35,014 INFO:     Epoch: 15
2022-12-05 21:00:35,809 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4016917808489366, 'Total loss': 0.4016917808489366} | train loss {'Reaction outcome loss': 0.2448820623791652, 'Total loss': 0.2448820623791652}
2022-12-05 21:00:35,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:35,809 INFO:     Epoch: 16
2022-12-05 21:00:36,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4029430113732815, 'Total loss': 0.4029430113732815} | train loss {'Reaction outcome loss': 0.24028923171327302, 'Total loss': 0.24028923171327302}
2022-12-05 21:00:36,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:36,611 INFO:     Epoch: 17
2022-12-05 21:00:37,406 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4018419645726681, 'Total loss': 0.4018419645726681} | train loss {'Reaction outcome loss': 0.2308400647096366, 'Total loss': 0.2308400647096366}
2022-12-05 21:00:37,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:37,406 INFO:     Epoch: 18
2022-12-05 21:00:38,197 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4103326245465062, 'Total loss': 0.4103326245465062} | train loss {'Reaction outcome loss': 0.22651576872176005, 'Total loss': 0.22651576872176005}
2022-12-05 21:00:38,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:38,197 INFO:     Epoch: 19
2022-12-05 21:00:38,988 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4152705533937974, 'Total loss': 0.4152705533937974} | train loss {'Reaction outcome loss': 0.2192046266192427, 'Total loss': 0.2192046266192427}
2022-12-05 21:00:38,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:38,988 INFO:     Epoch: 20
2022-12-05 21:00:39,781 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41683380983092566, 'Total loss': 0.41683380983092566} | train loss {'Reaction outcome loss': 0.2121268361354405, 'Total loss': 0.2121268361354405}
2022-12-05 21:00:39,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:39,781 INFO:     Epoch: 21
2022-12-05 21:00:40,576 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4174657927995378, 'Total loss': 0.4174657927995378} | train loss {'Reaction outcome loss': 0.20844601020820228, 'Total loss': 0.20844601020820228}
2022-12-05 21:00:40,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:40,576 INFO:     Epoch: 22
2022-12-05 21:00:41,369 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4044636037539352, 'Total loss': 0.4044636037539352} | train loss {'Reaction outcome loss': 0.206646855181528, 'Total loss': 0.206646855181528}
2022-12-05 21:00:41,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:41,369 INFO:     Epoch: 23
2022-12-05 21:00:42,165 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41090365973385895, 'Total loss': 0.41090365973385895} | train loss {'Reaction outcome loss': 0.20233240782430298, 'Total loss': 0.20233240782430298}
2022-12-05 21:00:42,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:42,165 INFO:     Epoch: 24
2022-12-05 21:00:42,963 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4195216568186879, 'Total loss': 0.4195216568186879} | train loss {'Reaction outcome loss': 0.19659401148912092, 'Total loss': 0.19659401148912092}
2022-12-05 21:00:42,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:42,964 INFO:     Epoch: 25
2022-12-05 21:00:43,759 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4114755774763497, 'Total loss': 0.4114755774763497} | train loss {'Reaction outcome loss': 0.18976578149691917, 'Total loss': 0.18976578149691917}
2022-12-05 21:00:43,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:43,759 INFO:     Epoch: 26
2022-12-05 21:00:44,551 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4283801464533264, 'Total loss': 0.4283801464533264} | train loss {'Reaction outcome loss': 0.1902081623582946, 'Total loss': 0.1902081623582946}
2022-12-05 21:00:44,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:44,551 INFO:     Epoch: 27
2022-12-05 21:00:45,347 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42285946367139166, 'Total loss': 0.42285946367139166} | train loss {'Reaction outcome loss': 0.18987976350945981, 'Total loss': 0.18987976350945981}
2022-12-05 21:00:45,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:45,348 INFO:     Epoch: 28
2022-12-05 21:00:46,143 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41412947089834645, 'Total loss': 0.41412947089834645} | train loss {'Reaction outcome loss': 0.18293792458990144, 'Total loss': 0.18293792458990144}
2022-12-05 21:00:46,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:46,144 INFO:     Epoch: 29
2022-12-05 21:00:46,937 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4289487935602665, 'Total loss': 0.4289487935602665} | train loss {'Reaction outcome loss': 0.1786263607864679, 'Total loss': 0.1786263607864679}
2022-12-05 21:00:46,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:46,937 INFO:     Epoch: 30
2022-12-05 21:00:47,731 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4162307217378508, 'Total loss': 0.4162307217378508} | train loss {'Reaction outcome loss': 0.1805746948124034, 'Total loss': 0.1805746948124034}
2022-12-05 21:00:47,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:47,731 INFO:     Epoch: 31
2022-12-05 21:00:48,522 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4281815520741723, 'Total loss': 0.4281815520741723} | train loss {'Reaction outcome loss': 0.17324272674406588, 'Total loss': 0.17324272674406588}
2022-12-05 21:00:48,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:48,522 INFO:     Epoch: 32
2022-12-05 21:00:49,314 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4303501739420674, 'Total loss': 0.4303501739420674} | train loss {'Reaction outcome loss': 0.16972098231545615, 'Total loss': 0.16972098231545615}
2022-12-05 21:00:49,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:49,314 INFO:     Epoch: 33
2022-12-05 21:00:50,107 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42591319673440675, 'Total loss': 0.42591319673440675} | train loss {'Reaction outcome loss': 0.1675432226243561, 'Total loss': 0.1675432226243561}
2022-12-05 21:00:50,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:50,107 INFO:     Epoch: 34
2022-12-05 21:00:50,899 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42390078848058527, 'Total loss': 0.42390078848058527} | train loss {'Reaction outcome loss': 0.16962891669287855, 'Total loss': 0.16962891669287855}
2022-12-05 21:00:50,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:50,900 INFO:     Epoch: 35
2022-12-05 21:00:51,694 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4350280724465847, 'Total loss': 0.4350280724465847} | train loss {'Reaction outcome loss': 0.17139597271799076, 'Total loss': 0.17139597271799076}
2022-12-05 21:00:51,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:51,695 INFO:     Epoch: 36
2022-12-05 21:00:52,487 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42190610050139105, 'Total loss': 0.42190610050139105} | train loss {'Reaction outcome loss': 0.16414340274777972, 'Total loss': 0.16414340274777972}
2022-12-05 21:00:52,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:52,487 INFO:     Epoch: 37
2022-12-05 21:00:53,283 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41974436017599975, 'Total loss': 0.41974436017599975} | train loss {'Reaction outcome loss': 0.1598431605031254, 'Total loss': 0.1598431605031254}
2022-12-05 21:00:53,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:53,283 INFO:     Epoch: 38
2022-12-05 21:00:54,074 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.432815011929382, 'Total loss': 0.432815011929382} | train loss {'Reaction outcome loss': 0.16270812561637477, 'Total loss': 0.16270812561637477}
2022-12-05 21:00:54,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:54,075 INFO:     Epoch: 39
2022-12-05 21:00:54,870 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44555084881457413, 'Total loss': 0.44555084881457413} | train loss {'Reaction outcome loss': 0.15422470918159012, 'Total loss': 0.15422470918159012}
2022-12-05 21:00:54,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:54,871 INFO:     Epoch: 40
2022-12-05 21:00:55,665 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43745995279062877, 'Total loss': 0.43745995279062877} | train loss {'Reaction outcome loss': 0.1583770522282191, 'Total loss': 0.1583770522282191}
2022-12-05 21:00:55,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:55,665 INFO:     Epoch: 41
2022-12-05 21:00:56,462 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4347935820167715, 'Total loss': 0.4347935820167715} | train loss {'Reaction outcome loss': 0.15403968326347742, 'Total loss': 0.15403968326347742}
2022-12-05 21:00:56,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:56,462 INFO:     Epoch: 42
2022-12-05 21:00:57,255 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44143391942436044, 'Total loss': 0.44143391942436044} | train loss {'Reaction outcome loss': 0.1506311882830221, 'Total loss': 0.1506311882830221}
2022-12-05 21:00:57,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:57,256 INFO:     Epoch: 43
2022-12-05 21:00:58,049 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4355429123071107, 'Total loss': 0.4355429123071107} | train loss {'Reaction outcome loss': 0.1517729209170409, 'Total loss': 0.1517729209170409}
2022-12-05 21:00:58,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:58,049 INFO:     Epoch: 44
2022-12-05 21:00:58,844 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44617482207038184, 'Total loss': 0.44617482207038184} | train loss {'Reaction outcome loss': 0.14949283945498618, 'Total loss': 0.14949283945498618}
2022-12-05 21:00:58,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:58,844 INFO:     Epoch: 45
2022-12-05 21:00:59,637 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4494510789147832, 'Total loss': 0.4494510789147832} | train loss {'Reaction outcome loss': 0.14752257903491106, 'Total loss': 0.14752257903491106}
2022-12-05 21:00:59,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:00:59,637 INFO:     Epoch: 46
2022-12-05 21:01:00,430 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43234707635234704, 'Total loss': 0.43234707635234704} | train loss {'Reaction outcome loss': 0.14889914589191255, 'Total loss': 0.14889914589191255}
2022-12-05 21:01:00,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:00,430 INFO:     Epoch: 47
2022-12-05 21:01:01,230 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42043060466477816, 'Total loss': 0.42043060466477816} | train loss {'Reaction outcome loss': 0.14971167292928528, 'Total loss': 0.14971167292928528}
2022-12-05 21:01:01,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:01,230 INFO:     Epoch: 48
2022-12-05 21:01:02,026 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45076766508546745, 'Total loss': 0.45076766508546745} | train loss {'Reaction outcome loss': 0.1468076544779877, 'Total loss': 0.1468076544779877}
2022-12-05 21:01:02,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:02,026 INFO:     Epoch: 49
2022-12-05 21:01:02,825 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4407842731611295, 'Total loss': 0.4407842731611295} | train loss {'Reaction outcome loss': 0.145816724864306, 'Total loss': 0.145816724864306}
2022-12-05 21:01:02,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:02,825 INFO:     Epoch: 50
2022-12-05 21:01:03,617 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4407690590755506, 'Total loss': 0.4407690590755506} | train loss {'Reaction outcome loss': 0.14449761855427312, 'Total loss': 0.14449761855427312}
2022-12-05 21:01:03,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:03,617 INFO:     Epoch: 51
2022-12-05 21:01:04,413 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4379729843613776, 'Total loss': 0.4379729843613776} | train loss {'Reaction outcome loss': 0.1392041521094106, 'Total loss': 0.1392041521094106}
2022-12-05 21:01:04,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:04,413 INFO:     Epoch: 52
2022-12-05 21:01:05,204 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42975379154086113, 'Total loss': 0.42975379154086113} | train loss {'Reaction outcome loss': 0.1423058467521238, 'Total loss': 0.1423058467521238}
2022-12-05 21:01:05,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:05,205 INFO:     Epoch: 53
2022-12-05 21:01:06,001 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44318853555755183, 'Total loss': 0.44318853555755183} | train loss {'Reaction outcome loss': 0.14158018151305707, 'Total loss': 0.14158018151305707}
2022-12-05 21:01:06,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:06,002 INFO:     Epoch: 54
2022-12-05 21:01:06,794 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4510322528129274, 'Total loss': 0.4510322528129274} | train loss {'Reaction outcome loss': 0.14021163983534463, 'Total loss': 0.14021163983534463}
2022-12-05 21:01:06,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:06,794 INFO:     Epoch: 55
2022-12-05 21:01:07,593 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4460790084505623, 'Total loss': 0.4460790084505623} | train loss {'Reaction outcome loss': 0.13981316876050975, 'Total loss': 0.13981316876050975}
2022-12-05 21:01:07,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:07,593 INFO:     Epoch: 56
2022-12-05 21:01:08,387 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45734426988796756, 'Total loss': 0.45734426988796756} | train loss {'Reaction outcome loss': 0.13748633458577417, 'Total loss': 0.13748633458577417}
2022-12-05 21:01:08,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:08,387 INFO:     Epoch: 57
2022-12-05 21:01:09,181 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45037610456347466, 'Total loss': 0.45037610456347466} | train loss {'Reaction outcome loss': 0.13567260070986714, 'Total loss': 0.13567260070986714}
2022-12-05 21:01:09,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:09,182 INFO:     Epoch: 58
2022-12-05 21:01:09,974 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44525228576226666, 'Total loss': 0.44525228576226666} | train loss {'Reaction outcome loss': 0.14243982269274078, 'Total loss': 0.14243982269274078}
2022-12-05 21:01:09,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:09,974 INFO:     Epoch: 59
2022-12-05 21:01:10,766 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4353998073122718, 'Total loss': 0.4353998073122718} | train loss {'Reaction outcome loss': 0.13580471546830317, 'Total loss': 0.13580471546830317}
2022-12-05 21:01:10,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:10,766 INFO:     Epoch: 60
2022-12-05 21:01:11,558 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4504108957268975, 'Total loss': 0.4504108957268975} | train loss {'Reaction outcome loss': 0.13539990939356403, 'Total loss': 0.13539990939356403}
2022-12-05 21:01:11,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:11,559 INFO:     Epoch: 61
2022-12-05 21:01:12,357 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4469781250438907, 'Total loss': 0.4469781250438907} | train loss {'Reaction outcome loss': 0.13511819382450782, 'Total loss': 0.13511819382450782}
2022-12-05 21:01:12,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:12,357 INFO:     Epoch: 62
2022-12-05 21:01:13,154 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4459196308797056, 'Total loss': 0.4459196308797056} | train loss {'Reaction outcome loss': 0.13479351006289905, 'Total loss': 0.13479351006289905}
2022-12-05 21:01:13,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:13,154 INFO:     Epoch: 63
2022-12-05 21:01:13,947 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43996318023313175, 'Total loss': 0.43996318023313175} | train loss {'Reaction outcome loss': 0.13156493404608688, 'Total loss': 0.13156493404608688}
2022-12-05 21:01:13,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:13,947 INFO:     Epoch: 64
2022-12-05 21:01:14,744 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44646505334160547, 'Total loss': 0.44646505334160547} | train loss {'Reaction outcome loss': 0.1355163914336246, 'Total loss': 0.1355163914336246}
2022-12-05 21:01:14,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:14,744 INFO:     Epoch: 65
2022-12-05 21:01:15,544 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4492872729897499, 'Total loss': 0.4492872729897499} | train loss {'Reaction outcome loss': 0.13743238142024167, 'Total loss': 0.13743238142024167}
2022-12-05 21:01:15,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:15,544 INFO:     Epoch: 66
2022-12-05 21:01:16,347 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45613296634771605, 'Total loss': 0.45613296634771605} | train loss {'Reaction outcome loss': 0.13584394192677518, 'Total loss': 0.13584394192677518}
2022-12-05 21:01:16,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:16,347 INFO:     Epoch: 67
2022-12-05 21:01:17,146 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4565724767744541, 'Total loss': 0.4565724767744541} | train loss {'Reaction outcome loss': 0.13604304122056074, 'Total loss': 0.13604304122056074}
2022-12-05 21:01:17,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:17,147 INFO:     Epoch: 68
2022-12-05 21:01:17,942 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4457483186640523, 'Total loss': 0.4457483186640523} | train loss {'Reaction outcome loss': 0.1309776556591394, 'Total loss': 0.1309776556591394}
2022-12-05 21:01:17,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:17,942 INFO:     Epoch: 69
2022-12-05 21:01:18,739 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4599920653484084, 'Total loss': 0.4599920653484084} | train loss {'Reaction outcome loss': 0.13151992803537532, 'Total loss': 0.13151992803537532}
2022-12-05 21:01:18,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:18,740 INFO:     Epoch: 70
2022-12-05 21:01:19,535 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4629878906363791, 'Total loss': 0.4629878906363791} | train loss {'Reaction outcome loss': 0.1389088922591224, 'Total loss': 0.1389088922591224}
2022-12-05 21:01:19,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:19,535 INFO:     Epoch: 71
2022-12-05 21:01:20,329 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4510149440982125, 'Total loss': 0.4510149440982125} | train loss {'Reaction outcome loss': 0.13204028823899355, 'Total loss': 0.13204028823899355}
2022-12-05 21:01:20,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:20,330 INFO:     Epoch: 72
2022-12-05 21:01:21,125 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47090587070719764, 'Total loss': 0.47090587070719764} | train loss {'Reaction outcome loss': 0.12881683864110424, 'Total loss': 0.12881683864110424}
2022-12-05 21:01:21,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:21,125 INFO:     Epoch: 73
2022-12-05 21:01:21,920 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4452363516796719, 'Total loss': 0.4452363516796719} | train loss {'Reaction outcome loss': 0.12687637374890962, 'Total loss': 0.12687637374890962}
2022-12-05 21:01:21,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:21,920 INFO:     Epoch: 74
2022-12-05 21:01:22,717 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.471460128033703, 'Total loss': 0.471460128033703} | train loss {'Reaction outcome loss': 0.1286824936431791, 'Total loss': 0.1286824936431791}
2022-12-05 21:01:22,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:22,717 INFO:     Epoch: 75
2022-12-05 21:01:23,509 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45465629480101843, 'Total loss': 0.45465629480101843} | train loss {'Reaction outcome loss': 0.13424660636466523, 'Total loss': 0.13424660636466523}
2022-12-05 21:01:23,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:23,509 INFO:     Epoch: 76
2022-12-05 21:01:24,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44396540183912625, 'Total loss': 0.44396540183912625} | train loss {'Reaction outcome loss': 0.1277773183306702, 'Total loss': 0.1277773183306702}
2022-12-05 21:01:24,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:24,299 INFO:     Epoch: 77
2022-12-05 21:01:25,095 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.453974744474346, 'Total loss': 0.453974744474346} | train loss {'Reaction outcome loss': 0.12856416017013161, 'Total loss': 0.12856416017013161}
2022-12-05 21:01:25,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:25,095 INFO:     Epoch: 78
2022-12-05 21:01:25,893 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4457255971025337, 'Total loss': 0.4457255971025337} | train loss {'Reaction outcome loss': 0.12776084452007824, 'Total loss': 0.12776084452007824}
2022-12-05 21:01:25,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:25,894 INFO:     Epoch: 79
2022-12-05 21:01:26,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46454823829910974, 'Total loss': 0.46454823829910974} | train loss {'Reaction outcome loss': 0.12698027725342798, 'Total loss': 0.12698027725342798}
2022-12-05 21:01:26,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:26,695 INFO:     Epoch: 80
2022-12-05 21:01:27,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.449723887511275, 'Total loss': 0.449723887511275} | train loss {'Reaction outcome loss': 0.12827160454125178, 'Total loss': 0.12827160454125178}
2022-12-05 21:01:27,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:27,490 INFO:     Epoch: 81
2022-12-05 21:01:28,281 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4343969434161078, 'Total loss': 0.4343969434161078} | train loss {'Reaction outcome loss': 0.12470734830538512, 'Total loss': 0.12470734830538512}
2022-12-05 21:01:28,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:28,281 INFO:     Epoch: 82
2022-12-05 21:01:29,072 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46130920946598053, 'Total loss': 0.46130920946598053} | train loss {'Reaction outcome loss': 0.12359925391631359, 'Total loss': 0.12359925391631359}
2022-12-05 21:01:29,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:29,072 INFO:     Epoch: 83
2022-12-05 21:01:29,863 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46524410965767776, 'Total loss': 0.46524410965767776} | train loss {'Reaction outcome loss': 0.12365515497305736, 'Total loss': 0.12365515497305736}
2022-12-05 21:01:29,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:29,863 INFO:     Epoch: 84
2022-12-05 21:01:30,654 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44885863922536373, 'Total loss': 0.44885863922536373} | train loss {'Reaction outcome loss': 0.12411739202480206, 'Total loss': 0.12411739202480206}
2022-12-05 21:01:30,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:30,654 INFO:     Epoch: 85
2022-12-05 21:01:31,445 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4620056446980346, 'Total loss': 0.4620056446980346} | train loss {'Reaction outcome loss': 0.12217867775605275, 'Total loss': 0.12217867775605275}
2022-12-05 21:01:31,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:31,445 INFO:     Epoch: 86
2022-12-05 21:01:32,235 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44975369017232547, 'Total loss': 0.44975369017232547} | train loss {'Reaction outcome loss': 0.12380196151760998, 'Total loss': 0.12380196151760998}
2022-12-05 21:01:32,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:32,235 INFO:     Epoch: 87
2022-12-05 21:01:33,032 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45504839989272033, 'Total loss': 0.45504839989272033} | train loss {'Reaction outcome loss': 0.1236654375019947, 'Total loss': 0.1236654375019947}
2022-12-05 21:01:33,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:33,033 INFO:     Epoch: 88
2022-12-05 21:01:33,827 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4657688371159814, 'Total loss': 0.4657688371159814} | train loss {'Reaction outcome loss': 0.1217542374845941, 'Total loss': 0.1217542374845941}
2022-12-05 21:01:33,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:33,828 INFO:     Epoch: 89
2022-12-05 21:01:34,623 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4767523028633811, 'Total loss': 0.4767523028633811} | train loss {'Reaction outcome loss': 0.13100143379497867, 'Total loss': 0.13100143379497867}
2022-12-05 21:01:34,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:34,623 INFO:     Epoch: 90
2022-12-05 21:01:35,418 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4617409418252381, 'Total loss': 0.4617409418252381} | train loss {'Reaction outcome loss': 0.13071199909968656, 'Total loss': 0.13071199909968656}
2022-12-05 21:01:35,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:35,418 INFO:     Epoch: 91
2022-12-05 21:01:36,209 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4530497315255078, 'Total loss': 0.4530497315255078} | train loss {'Reaction outcome loss': 0.1212444447983916, 'Total loss': 0.1212444447983916}
2022-12-05 21:01:36,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:36,210 INFO:     Epoch: 92
2022-12-05 21:01:37,005 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45576940883289685, 'Total loss': 0.45576940883289685} | train loss {'Reaction outcome loss': 0.12051217518626667, 'Total loss': 0.12051217518626667}
2022-12-05 21:01:37,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:37,005 INFO:     Epoch: 93
2022-12-05 21:01:37,799 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4644604531878775, 'Total loss': 0.4644604531878775} | train loss {'Reaction outcome loss': 0.12355519136895146, 'Total loss': 0.12355519136895146}
2022-12-05 21:01:37,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:37,800 INFO:     Epoch: 94
2022-12-05 21:01:38,593 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4613242068073966, 'Total loss': 0.4613242068073966} | train loss {'Reaction outcome loss': 0.11656657834857823, 'Total loss': 0.11656657834857823}
2022-12-05 21:01:38,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:38,593 INFO:     Epoch: 95
2022-12-05 21:01:39,385 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46935647759925236, 'Total loss': 0.46935647759925236} | train loss {'Reaction outcome loss': 0.1198823070040478, 'Total loss': 0.1198823070040478}
2022-12-05 21:01:39,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:39,386 INFO:     Epoch: 96
2022-12-05 21:01:40,177 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4603585929355838, 'Total loss': 0.4603585929355838} | train loss {'Reaction outcome loss': 0.12342957412420587, 'Total loss': 0.12342957412420587}
2022-12-05 21:01:40,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:40,178 INFO:     Epoch: 97
2022-12-05 21:01:40,968 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.460401596670801, 'Total loss': 0.460401596670801} | train loss {'Reaction outcome loss': 0.11799124411122519, 'Total loss': 0.11799124411122519}
2022-12-05 21:01:40,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:40,968 INFO:     Epoch: 98
2022-12-05 21:01:41,762 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46075850928371603, 'Total loss': 0.46075850928371603} | train loss {'Reaction outcome loss': 0.12062586194869539, 'Total loss': 0.12062586194869539}
2022-12-05 21:01:41,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:41,762 INFO:     Epoch: 99
2022-12-05 21:01:42,562 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4653069556436755, 'Total loss': 0.4653069556436755} | train loss {'Reaction outcome loss': 0.11964855049001544, 'Total loss': 0.11964855049001544}
2022-12-05 21:01:42,562 INFO:     Best model found after epoch 9 of 100.
2022-12-05 21:01:42,562 INFO:   Done with stage: TRAINING
2022-12-05 21:01:42,562 INFO:   Starting stage: EVALUATION
2022-12-05 21:01:42,688 INFO:   Done with stage: EVALUATION
2022-12-05 21:01:42,688 INFO:   Leaving out SEQ value Fold_6
2022-12-05 21:01:42,700 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:01:42,701 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:01:43,361 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:01:43,361 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:01:43,432 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:01:43,432 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:01:43,432 INFO:     No hyperparam tuning for this model
2022-12-05 21:01:43,432 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:01:43,432 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:01:43,433 INFO:     None feature selector for col prot
2022-12-05 21:01:43,433 INFO:     None feature selector for col prot
2022-12-05 21:01:43,433 INFO:     None feature selector for col prot
2022-12-05 21:01:43,434 INFO:     None feature selector for col chem
2022-12-05 21:01:43,434 INFO:     None feature selector for col chem
2022-12-05 21:01:43,434 INFO:     None feature selector for col chem
2022-12-05 21:01:43,434 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:01:43,434 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:01:43,436 INFO:     Number of params in model 215821
2022-12-05 21:01:43,439 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:01:43,439 INFO:   Starting stage: TRAINING
2022-12-05 21:01:43,500 INFO:     Val loss before train {'Reaction outcome loss': 0.9862932942130349, 'Total loss': 0.9862932942130349}
2022-12-05 21:01:43,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:43,500 INFO:     Epoch: 0
2022-12-05 21:01:44,294 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6089433208107948, 'Total loss': 0.6089433208107948} | train loss {'Reaction outcome loss': 0.7853991116487211, 'Total loss': 0.7853991116487211}
2022-12-05 21:01:44,295 INFO:     Found new best model at epoch 0
2022-12-05 21:01:44,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:44,296 INFO:     Epoch: 1
2022-12-05 21:01:45,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.529488356275992, 'Total loss': 0.529488356275992} | train loss {'Reaction outcome loss': 0.5383807683904325, 'Total loss': 0.5383807683904325}
2022-12-05 21:01:45,093 INFO:     Found new best model at epoch 1
2022-12-05 21:01:45,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:45,094 INFO:     Epoch: 2
2022-12-05 21:01:45,890 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49467805806886067, 'Total loss': 0.49467805806886067} | train loss {'Reaction outcome loss': 0.47228878279847486, 'Total loss': 0.47228878279847486}
2022-12-05 21:01:45,890 INFO:     Found new best model at epoch 2
2022-12-05 21:01:45,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:45,891 INFO:     Epoch: 3
2022-12-05 21:01:46,687 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4741487205028534, 'Total loss': 0.4741487205028534} | train loss {'Reaction outcome loss': 0.43401494135539376, 'Total loss': 0.43401494135539376}
2022-12-05 21:01:46,687 INFO:     Found new best model at epoch 3
2022-12-05 21:01:46,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:46,688 INFO:     Epoch: 4
2022-12-05 21:01:47,481 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4595090387897058, 'Total loss': 0.4595090387897058} | train loss {'Reaction outcome loss': 0.40632404311890563, 'Total loss': 0.40632404311890563}
2022-12-05 21:01:47,481 INFO:     Found new best model at epoch 4
2022-12-05 21:01:47,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:47,482 INFO:     Epoch: 5
2022-12-05 21:01:48,275 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4460008814930916, 'Total loss': 0.4460008814930916} | train loss {'Reaction outcome loss': 0.3815284554035433, 'Total loss': 0.3815284554035433}
2022-12-05 21:01:48,276 INFO:     Found new best model at epoch 5
2022-12-05 21:01:48,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:48,277 INFO:     Epoch: 6
2022-12-05 21:01:49,074 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45045719465071504, 'Total loss': 0.45045719465071504} | train loss {'Reaction outcome loss': 0.3604046821353897, 'Total loss': 0.3604046821353897}
2022-12-05 21:01:49,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:49,075 INFO:     Epoch: 7
2022-12-05 21:01:49,871 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44012271240353584, 'Total loss': 0.44012271240353584} | train loss {'Reaction outcome loss': 0.34456394321375317, 'Total loss': 0.34456394321375317}
2022-12-05 21:01:49,872 INFO:     Found new best model at epoch 7
2022-12-05 21:01:49,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:49,872 INFO:     Epoch: 8
2022-12-05 21:01:50,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4371857185932723, 'Total loss': 0.4371857185932723} | train loss {'Reaction outcome loss': 0.3273873595641025, 'Total loss': 0.3273873595641025}
2022-12-05 21:01:50,664 INFO:     Found new best model at epoch 8
2022-12-05 21:01:50,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:50,664 INFO:     Epoch: 9
2022-12-05 21:01:51,461 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4424096735363657, 'Total loss': 0.4424096735363657} | train loss {'Reaction outcome loss': 0.3122457872715689, 'Total loss': 0.3122457872715689}
2022-12-05 21:01:51,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:51,462 INFO:     Epoch: 10
2022-12-05 21:01:52,260 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4285766871815378, 'Total loss': 0.4285766871815378} | train loss {'Reaction outcome loss': 0.3006725094972118, 'Total loss': 0.3006725094972118}
2022-12-05 21:01:52,260 INFO:     Found new best model at epoch 10
2022-12-05 21:01:52,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:52,261 INFO:     Epoch: 11
2022-12-05 21:01:53,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44251611320809886, 'Total loss': 0.44251611320809886} | train loss {'Reaction outcome loss': 0.28704631286523036, 'Total loss': 0.28704631286523036}
2022-12-05 21:01:53,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:53,055 INFO:     Epoch: 12
2022-12-05 21:01:53,849 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4369602704590017, 'Total loss': 0.4369602704590017} | train loss {'Reaction outcome loss': 0.2780702810794596, 'Total loss': 0.2780702810794596}
2022-12-05 21:01:53,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:53,849 INFO:     Epoch: 13
2022-12-05 21:01:54,646 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4354954404248433, 'Total loss': 0.4354954404248433} | train loss {'Reaction outcome loss': 0.266080645874383, 'Total loss': 0.266080645874383}
2022-12-05 21:01:54,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:54,647 INFO:     Epoch: 14
2022-12-05 21:01:55,447 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4378943722695112, 'Total loss': 0.4378943722695112} | train loss {'Reaction outcome loss': 0.2573772669739781, 'Total loss': 0.2573772669739781}
2022-12-05 21:01:55,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:55,448 INFO:     Epoch: 15
2022-12-05 21:01:56,239 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4291921090334654, 'Total loss': 0.4291921090334654} | train loss {'Reaction outcome loss': 0.24987514226907684, 'Total loss': 0.24987514226907684}
2022-12-05 21:01:56,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:56,240 INFO:     Epoch: 16
2022-12-05 21:01:57,030 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43868025324561377, 'Total loss': 0.43868025324561377} | train loss {'Reaction outcome loss': 0.23977792620538704, 'Total loss': 0.23977792620538704}
2022-12-05 21:01:57,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:57,031 INFO:     Epoch: 17
2022-12-05 21:01:57,825 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4260551543398337, 'Total loss': 0.4260551543398337} | train loss {'Reaction outcome loss': 0.23690877572423027, 'Total loss': 0.23690877572423027}
2022-12-05 21:01:57,825 INFO:     Found new best model at epoch 17
2022-12-05 21:01:57,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:57,826 INFO:     Epoch: 18
2022-12-05 21:01:58,622 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.431923070075837, 'Total loss': 0.431923070075837} | train loss {'Reaction outcome loss': 0.2279339873442246, 'Total loss': 0.2279339873442246}
2022-12-05 21:01:58,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:58,622 INFO:     Epoch: 19
2022-12-05 21:01:59,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4592820063910701, 'Total loss': 0.4592820063910701} | train loss {'Reaction outcome loss': 0.22309789599310006, 'Total loss': 0.22309789599310006}
2022-12-05 21:01:59,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:01:59,415 INFO:     Epoch: 20
2022-12-05 21:02:00,209 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43473952094262297, 'Total loss': 0.43473952094262297} | train loss {'Reaction outcome loss': 0.2177374799089927, 'Total loss': 0.2177374799089927}
2022-12-05 21:02:00,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:00,209 INFO:     Epoch: 21
2022-12-05 21:02:01,002 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4388929768042131, 'Total loss': 0.4388929768042131} | train loss {'Reaction outcome loss': 0.20969641273240408, 'Total loss': 0.20969641273240408}
2022-12-05 21:02:01,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:01,002 INFO:     Epoch: 22
2022-12-05 21:02:01,792 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44640050117265095, 'Total loss': 0.44640050117265095} | train loss {'Reaction outcome loss': 0.20433446924172102, 'Total loss': 0.20433446924172102}
2022-12-05 21:02:01,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:01,793 INFO:     Epoch: 23
2022-12-05 21:02:02,584 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4425597211176699, 'Total loss': 0.4425597211176699} | train loss {'Reaction outcome loss': 0.20362786428942795, 'Total loss': 0.20362786428942795}
2022-12-05 21:02:02,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:02,584 INFO:     Epoch: 24
2022-12-05 21:02:03,374 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45050009221515874, 'Total loss': 0.45050009221515874} | train loss {'Reaction outcome loss': 0.19925384194169554, 'Total loss': 0.19925384194169554}
2022-12-05 21:02:03,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:03,374 INFO:     Epoch: 25
2022-12-05 21:02:04,174 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45812784575603227, 'Total loss': 0.45812784575603227} | train loss {'Reaction outcome loss': 0.194101249919303, 'Total loss': 0.194101249919303}
2022-12-05 21:02:04,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:04,174 INFO:     Epoch: 26
2022-12-05 21:02:04,976 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4580014952543107, 'Total loss': 0.4580014952543107} | train loss {'Reaction outcome loss': 0.1921010107222584, 'Total loss': 0.1921010107222584}
2022-12-05 21:02:04,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:04,976 INFO:     Epoch: 27
2022-12-05 21:02:05,776 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4563257582485676, 'Total loss': 0.4563257582485676} | train loss {'Reaction outcome loss': 0.18845153049445681, 'Total loss': 0.18845153049445681}
2022-12-05 21:02:05,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:05,776 INFO:     Epoch: 28
2022-12-05 21:02:06,568 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44693562252955005, 'Total loss': 0.44693562252955005} | train loss {'Reaction outcome loss': 0.1844724375442902, 'Total loss': 0.1844724375442902}
2022-12-05 21:02:06,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:06,568 INFO:     Epoch: 29
2022-12-05 21:02:07,366 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46599527956409886, 'Total loss': 0.46599527956409886} | train loss {'Reaction outcome loss': 0.17941504779962764, 'Total loss': 0.17941504779962764}
2022-12-05 21:02:07,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:07,367 INFO:     Epoch: 30
2022-12-05 21:02:08,158 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47205005484548485, 'Total loss': 0.47205005484548485} | train loss {'Reaction outcome loss': 0.1787397307794421, 'Total loss': 0.1787397307794421}
2022-12-05 21:02:08,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:08,158 INFO:     Epoch: 31
2022-12-05 21:02:08,951 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45744259282946587, 'Total loss': 0.45744259282946587} | train loss {'Reaction outcome loss': 0.17913462290720594, 'Total loss': 0.17913462290720594}
2022-12-05 21:02:08,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:08,952 INFO:     Epoch: 32
2022-12-05 21:02:09,742 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46611041541803966, 'Total loss': 0.46611041541803966} | train loss {'Reaction outcome loss': 0.17371868620806885, 'Total loss': 0.17371868620806885}
2022-12-05 21:02:09,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:09,742 INFO:     Epoch: 33
2022-12-05 21:02:10,533 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44798401692374185, 'Total loss': 0.44798401692374185} | train loss {'Reaction outcome loss': 0.17281320053453167, 'Total loss': 0.17281320053453167}
2022-12-05 21:02:10,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:10,533 INFO:     Epoch: 34
2022-12-05 21:02:11,324 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.458410824903033, 'Total loss': 0.458410824903033} | train loss {'Reaction outcome loss': 0.1714670159178035, 'Total loss': 0.1714670159178035}
2022-12-05 21:02:11,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:11,324 INFO:     Epoch: 35
2022-12-05 21:02:12,115 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44644195620309224, 'Total loss': 0.44644195620309224} | train loss {'Reaction outcome loss': 0.16855064843360695, 'Total loss': 0.16855064843360695}
2022-12-05 21:02:12,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:12,115 INFO:     Epoch: 36
2022-12-05 21:02:12,906 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4412716894664548, 'Total loss': 0.4412716894664548} | train loss {'Reaction outcome loss': 0.16437065267124243, 'Total loss': 0.16437065267124243}
2022-12-05 21:02:12,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:12,907 INFO:     Epoch: 37
2022-12-05 21:02:13,696 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4455665873194283, 'Total loss': 0.4455665873194283} | train loss {'Reaction outcome loss': 0.1669667766789996, 'Total loss': 0.1669667766789996}
2022-12-05 21:02:13,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:13,697 INFO:     Epoch: 38
2022-12-05 21:02:14,489 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4463024078445001, 'Total loss': 0.4463024078445001} | train loss {'Reaction outcome loss': 0.16266974558182543, 'Total loss': 0.16266974558182543}
2022-12-05 21:02:14,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:14,489 INFO:     Epoch: 39
2022-12-05 21:02:15,283 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4607065570625392, 'Total loss': 0.4607065570625392} | train loss {'Reaction outcome loss': 0.15956313077044942, 'Total loss': 0.15956313077044942}
2022-12-05 21:02:15,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:15,284 INFO:     Epoch: 40
2022-12-05 21:02:16,076 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45008430494503543, 'Total loss': 0.45008430494503543} | train loss {'Reaction outcome loss': 0.1584172478741816, 'Total loss': 0.1584172478741816}
2022-12-05 21:02:16,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:16,076 INFO:     Epoch: 41
2022-12-05 21:02:16,873 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45724407312544907, 'Total loss': 0.45724407312544907} | train loss {'Reaction outcome loss': 0.15607878272872297, 'Total loss': 0.15607878272872297}
2022-12-05 21:02:16,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:16,873 INFO:     Epoch: 42
2022-12-05 21:02:17,667 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4616598490286957, 'Total loss': 0.4616598490286957} | train loss {'Reaction outcome loss': 0.1545234548844277, 'Total loss': 0.1545234548844277}
2022-12-05 21:02:17,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:17,667 INFO:     Epoch: 43
2022-12-05 21:02:18,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4581990990449082, 'Total loss': 0.4581990990449082} | train loss {'Reaction outcome loss': 0.15400308612433652, 'Total loss': 0.15400308612433652}
2022-12-05 21:02:18,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:18,462 INFO:     Epoch: 44
2022-12-05 21:02:19,256 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46611048958518286, 'Total loss': 0.46611048958518286} | train loss {'Reaction outcome loss': 0.15290334976969228, 'Total loss': 0.15290334976969228}
2022-12-05 21:02:19,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:19,257 INFO:     Epoch: 45
2022-12-05 21:02:20,051 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4649081294509498, 'Total loss': 0.4649081294509498} | train loss {'Reaction outcome loss': 0.14963317355291256, 'Total loss': 0.14963317355291256}
2022-12-05 21:02:20,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:20,052 INFO:     Epoch: 46
2022-12-05 21:02:20,848 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46436397528106516, 'Total loss': 0.46436397528106516} | train loss {'Reaction outcome loss': 0.1469958010054524, 'Total loss': 0.1469958010054524}
2022-12-05 21:02:20,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:20,848 INFO:     Epoch: 47
2022-12-05 21:02:21,639 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47086605869910936, 'Total loss': 0.47086605869910936} | train loss {'Reaction outcome loss': 0.14833316128821142, 'Total loss': 0.14833316128821142}
2022-12-05 21:02:21,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:21,639 INFO:     Epoch: 48
2022-12-05 21:02:22,434 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44348702105608856, 'Total loss': 0.44348702105608856} | train loss {'Reaction outcome loss': 0.14989948703817302, 'Total loss': 0.14989948703817302}
2022-12-05 21:02:22,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:22,435 INFO:     Epoch: 49
2022-12-05 21:02:23,228 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.468780461021445, 'Total loss': 0.468780461021445} | train loss {'Reaction outcome loss': 0.14633569738737517, 'Total loss': 0.14633569738737517}
2022-12-05 21:02:23,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:23,229 INFO:     Epoch: 50
2022-12-05 21:02:24,018 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47369072857228195, 'Total loss': 0.47369072857228195} | train loss {'Reaction outcome loss': 0.14817662429695408, 'Total loss': 0.14817662429695408}
2022-12-05 21:02:24,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:24,018 INFO:     Epoch: 51
2022-12-05 21:02:24,809 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4574144431813197, 'Total loss': 0.4574144431813197} | train loss {'Reaction outcome loss': 0.1435445010541908, 'Total loss': 0.1435445010541908}
2022-12-05 21:02:24,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:24,809 INFO:     Epoch: 52
2022-12-05 21:02:25,603 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45564682951027696, 'Total loss': 0.45564682951027696} | train loss {'Reaction outcome loss': 0.14624666110161813, 'Total loss': 0.14624666110161813}
2022-12-05 21:02:25,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:25,604 INFO:     Epoch: 53
2022-12-05 21:02:26,395 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4736472876234488, 'Total loss': 0.4736472876234488} | train loss {'Reaction outcome loss': 0.14248475011047576, 'Total loss': 0.14248475011047576}
2022-12-05 21:02:26,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:26,395 INFO:     Epoch: 54
2022-12-05 21:02:27,189 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4643110785294663, 'Total loss': 0.4643110785294663} | train loss {'Reaction outcome loss': 0.14139184961095452, 'Total loss': 0.14139184961095452}
2022-12-05 21:02:27,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:27,189 INFO:     Epoch: 55
2022-12-05 21:02:27,980 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4536056568507444, 'Total loss': 0.4536056568507444} | train loss {'Reaction outcome loss': 0.14282129792075965, 'Total loss': 0.14282129792075965}
2022-12-05 21:02:27,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:27,980 INFO:     Epoch: 56
2022-12-05 21:02:28,771 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45631715858524496, 'Total loss': 0.45631715858524496} | train loss {'Reaction outcome loss': 0.13975365227088332, 'Total loss': 0.13975365227088332}
2022-12-05 21:02:28,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:28,772 INFO:     Epoch: 57
2022-12-05 21:02:29,563 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46768064627593214, 'Total loss': 0.46768064627593214} | train loss {'Reaction outcome loss': 0.13948787555789516, 'Total loss': 0.13948787555789516}
2022-12-05 21:02:29,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:29,563 INFO:     Epoch: 58
2022-12-05 21:02:30,360 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4704573164609345, 'Total loss': 0.4704573164609345} | train loss {'Reaction outcome loss': 0.1358009787734538, 'Total loss': 0.1358009787734538}
2022-12-05 21:02:30,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:30,360 INFO:     Epoch: 59
2022-12-05 21:02:31,157 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46640876172618434, 'Total loss': 0.46640876172618434} | train loss {'Reaction outcome loss': 0.13920529504426785, 'Total loss': 0.13920529504426785}
2022-12-05 21:02:31,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:31,157 INFO:     Epoch: 60
2022-12-05 21:02:31,951 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45473734763535584, 'Total loss': 0.45473734763535584} | train loss {'Reaction outcome loss': 0.1383969496575094, 'Total loss': 0.1383969496575094}
2022-12-05 21:02:31,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:31,951 INFO:     Epoch: 61
2022-12-05 21:02:32,743 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4709546041082252, 'Total loss': 0.4709546041082252} | train loss {'Reaction outcome loss': 0.13732397840208105, 'Total loss': 0.13732397840208105}
2022-12-05 21:02:32,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:32,743 INFO:     Epoch: 62
2022-12-05 21:02:33,540 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4747146906500513, 'Total loss': 0.4747146906500513} | train loss {'Reaction outcome loss': 0.13575597805902362, 'Total loss': 0.13575597805902362}
2022-12-05 21:02:33,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:33,540 INFO:     Epoch: 63
2022-12-05 21:02:34,334 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49945334751497616, 'Total loss': 0.49945334751497616} | train loss {'Reaction outcome loss': 0.13538580877526152, 'Total loss': 0.13538580877526152}
2022-12-05 21:02:34,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:34,335 INFO:     Epoch: 64
2022-12-05 21:02:35,127 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4650469816882502, 'Total loss': 0.4650469816882502} | train loss {'Reaction outcome loss': 0.13602051711002847, 'Total loss': 0.13602051711002847}
2022-12-05 21:02:35,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:35,127 INFO:     Epoch: 65
2022-12-05 21:02:35,918 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45748273249376903, 'Total loss': 0.45748273249376903} | train loss {'Reaction outcome loss': 0.13402001142892386, 'Total loss': 0.13402001142892386}
2022-12-05 21:02:35,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:35,918 INFO:     Epoch: 66
2022-12-05 21:02:36,714 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4783035037531094, 'Total loss': 0.4783035037531094} | train loss {'Reaction outcome loss': 0.13215389439175207, 'Total loss': 0.13215389439175207}
2022-12-05 21:02:36,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:36,714 INFO:     Epoch: 67
2022-12-05 21:02:37,510 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47930294851010496, 'Total loss': 0.47930294851010496} | train loss {'Reaction outcome loss': 0.1345956780827574, 'Total loss': 0.1345956780827574}
2022-12-05 21:02:37,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:37,510 INFO:     Epoch: 68
2022-12-05 21:02:38,307 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4518423920327967, 'Total loss': 0.4518423920327967} | train loss {'Reaction outcome loss': 0.13415400375191483, 'Total loss': 0.13415400375191483}
2022-12-05 21:02:38,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:38,308 INFO:     Epoch: 69
2022-12-05 21:02:39,113 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4614083817736669, 'Total loss': 0.4614083817736669} | train loss {'Reaction outcome loss': 0.133766696093634, 'Total loss': 0.133766696093634}
2022-12-05 21:02:39,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:39,113 INFO:     Epoch: 70
2022-12-05 21:02:39,913 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4963540908965198, 'Total loss': 0.4963540908965198} | train loss {'Reaction outcome loss': 0.13307981917469372, 'Total loss': 0.13307981917469372}
2022-12-05 21:02:39,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:39,913 INFO:     Epoch: 71
2022-12-05 21:02:40,709 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4649783152748238, 'Total loss': 0.4649783152748238} | train loss {'Reaction outcome loss': 0.13226412760183937, 'Total loss': 0.13226412760183937}
2022-12-05 21:02:40,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:40,709 INFO:     Epoch: 72
2022-12-05 21:02:41,506 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4842243120074272, 'Total loss': 0.4842243120074272} | train loss {'Reaction outcome loss': 0.12853133119642735, 'Total loss': 0.12853133119642735}
2022-12-05 21:02:41,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:41,506 INFO:     Epoch: 73
2022-12-05 21:02:42,303 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4562012661587108, 'Total loss': 0.4562012661587108} | train loss {'Reaction outcome loss': 0.13240647728314564, 'Total loss': 0.13240647728314564}
2022-12-05 21:02:42,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:42,303 INFO:     Epoch: 74
2022-12-05 21:02:43,105 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4778669114139947, 'Total loss': 0.4778669114139947} | train loss {'Reaction outcome loss': 0.13132649971052043, 'Total loss': 0.13132649971052043}
2022-12-05 21:02:43,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:43,105 INFO:     Epoch: 75
2022-12-05 21:02:43,900 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4655971500006589, 'Total loss': 0.4655971500006589} | train loss {'Reaction outcome loss': 0.1326722146777977, 'Total loss': 0.1326722146777977}
2022-12-05 21:02:43,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:43,900 INFO:     Epoch: 76
2022-12-05 21:02:44,693 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46138087152080104, 'Total loss': 0.46138087152080104} | train loss {'Reaction outcome loss': 0.1310371585873767, 'Total loss': 0.1310371585873767}
2022-12-05 21:02:44,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:44,694 INFO:     Epoch: 77
2022-12-05 21:02:45,494 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47651231390508736, 'Total loss': 0.47651231390508736} | train loss {'Reaction outcome loss': 0.12961128395193466, 'Total loss': 0.12961128395193466}
2022-12-05 21:02:45,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:45,494 INFO:     Epoch: 78
2022-12-05 21:02:46,288 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4824813631447879, 'Total loss': 0.4824813631447879} | train loss {'Reaction outcome loss': 0.1294716787993938, 'Total loss': 0.1294716787993938}
2022-12-05 21:02:46,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:46,288 INFO:     Epoch: 79
2022-12-05 21:02:47,084 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47153218259865587, 'Total loss': 0.47153218259865587} | train loss {'Reaction outcome loss': 0.12722550530827814, 'Total loss': 0.12722550530827814}
2022-12-05 21:02:47,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:47,084 INFO:     Epoch: 80
2022-12-05 21:02:47,884 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4700597094541246, 'Total loss': 0.4700597094541246} | train loss {'Reaction outcome loss': 0.12691169751868134, 'Total loss': 0.12691169751868134}
2022-12-05 21:02:47,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:47,884 INFO:     Epoch: 81
2022-12-05 21:02:48,683 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46322027695449913, 'Total loss': 0.46322027695449913} | train loss {'Reaction outcome loss': 0.1263447716989885, 'Total loss': 0.1263447716989885}
2022-12-05 21:02:48,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:48,683 INFO:     Epoch: 82
2022-12-05 21:02:49,480 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46887992102314124, 'Total loss': 0.46887992102314124} | train loss {'Reaction outcome loss': 0.12838577926384226, 'Total loss': 0.12838577926384226}
2022-12-05 21:02:49,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:49,480 INFO:     Epoch: 83
2022-12-05 21:02:50,278 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4766449057920413, 'Total loss': 0.4766449057920413} | train loss {'Reaction outcome loss': 0.12675081414636225, 'Total loss': 0.12675081414636225}
2022-12-05 21:02:50,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:50,279 INFO:     Epoch: 84
2022-12-05 21:02:51,073 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48092586343938654, 'Total loss': 0.48092586343938654} | train loss {'Reaction outcome loss': 0.12508526162785147, 'Total loss': 0.12508526162785147}
2022-12-05 21:02:51,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:51,073 INFO:     Epoch: 85
2022-12-05 21:02:51,868 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.463626563210379, 'Total loss': 0.463626563210379} | train loss {'Reaction outcome loss': 0.1248808219360428, 'Total loss': 0.1248808219360428}
2022-12-05 21:02:51,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:51,868 INFO:     Epoch: 86
2022-12-05 21:02:52,664 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4741499202156609, 'Total loss': 0.4741499202156609} | train loss {'Reaction outcome loss': 0.125782459478585, 'Total loss': 0.125782459478585}
2022-12-05 21:02:52,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:52,664 INFO:     Epoch: 87
2022-12-05 21:02:53,457 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4681443690576337, 'Total loss': 0.4681443690576337} | train loss {'Reaction outcome loss': 0.12589070429619884, 'Total loss': 0.12589070429619884}
2022-12-05 21:02:53,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:53,457 INFO:     Epoch: 88
2022-12-05 21:02:54,252 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4682480220428922, 'Total loss': 0.4682480220428922} | train loss {'Reaction outcome loss': 0.12743315147987055, 'Total loss': 0.12743315147987055}
2022-12-05 21:02:54,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:54,253 INFO:     Epoch: 89
2022-12-05 21:02:55,047 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47189347683028743, 'Total loss': 0.47189347683028743} | train loss {'Reaction outcome loss': 0.1251885401490595, 'Total loss': 0.1251885401490595}
2022-12-05 21:02:55,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:55,048 INFO:     Epoch: 90
2022-12-05 21:02:55,842 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4627166183834726, 'Total loss': 0.4627166183834726} | train loss {'Reaction outcome loss': 0.12557061854186619, 'Total loss': 0.12557061854186619}
2022-12-05 21:02:55,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:55,843 INFO:     Epoch: 91
2022-12-05 21:02:56,635 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4801512159068476, 'Total loss': 0.4801512159068476} | train loss {'Reaction outcome loss': 0.12448148238622854, 'Total loss': 0.12448148238622854}
2022-12-05 21:02:56,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:56,636 INFO:     Epoch: 92
2022-12-05 21:02:57,431 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4734143146991052, 'Total loss': 0.4734143146991052} | train loss {'Reaction outcome loss': 0.12248645148300115, 'Total loss': 0.12248645148300115}
2022-12-05 21:02:57,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:57,431 INFO:     Epoch: 93
2022-12-05 21:02:58,225 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5005518926138227, 'Total loss': 0.5005518926138227} | train loss {'Reaction outcome loss': 0.12077428987099519, 'Total loss': 0.12077428987099519}
2022-12-05 21:02:58,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:58,226 INFO:     Epoch: 94
2022-12-05 21:02:59,023 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46390958841551433, 'Total loss': 0.46390958841551433} | train loss {'Reaction outcome loss': 0.12301775718468332, 'Total loss': 0.12301775718468332}
2022-12-05 21:02:59,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:59,024 INFO:     Epoch: 95
2022-12-05 21:02:59,819 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48360453139651904, 'Total loss': 0.48360453139651904} | train loss {'Reaction outcome loss': 0.12315946045301614, 'Total loss': 0.12315946045301614}
2022-12-05 21:02:59,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:02:59,819 INFO:     Epoch: 96
2022-12-05 21:03:00,617 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4762653147971088, 'Total loss': 0.4762653147971088} | train loss {'Reaction outcome loss': 0.12157015402936527, 'Total loss': 0.12157015402936527}
2022-12-05 21:03:00,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:00,617 INFO:     Epoch: 97
2022-12-05 21:03:01,413 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4761980531567877, 'Total loss': 0.4761980531567877} | train loss {'Reaction outcome loss': 0.12142971402875358, 'Total loss': 0.12142971402875358}
2022-12-05 21:03:01,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:01,413 INFO:     Epoch: 98
2022-12-05 21:03:02,208 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47352608462626283, 'Total loss': 0.47352608462626283} | train loss {'Reaction outcome loss': 0.12076856369047516, 'Total loss': 0.12076856369047516}
2022-12-05 21:03:02,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:02,208 INFO:     Epoch: 99
2022-12-05 21:03:03,001 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46783035553314467, 'Total loss': 0.46783035553314467} | train loss {'Reaction outcome loss': 0.12145515800183339, 'Total loss': 0.12145515800183339}
2022-12-05 21:03:03,002 INFO:     Best model found after epoch 18 of 100.
2022-12-05 21:03:03,002 INFO:   Done with stage: TRAINING
2022-12-05 21:03:03,002 INFO:   Starting stage: EVALUATION
2022-12-05 21:03:03,121 INFO:   Done with stage: EVALUATION
2022-12-05 21:03:03,121 INFO:   Leaving out SEQ value Fold_7
2022-12-05 21:03:03,133 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:03:03,133 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:03:03,780 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:03:03,780 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:03:03,850 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:03:03,850 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:03:03,850 INFO:     No hyperparam tuning for this model
2022-12-05 21:03:03,850 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:03:03,850 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:03:03,851 INFO:     None feature selector for col prot
2022-12-05 21:03:03,851 INFO:     None feature selector for col prot
2022-12-05 21:03:03,851 INFO:     None feature selector for col prot
2022-12-05 21:03:03,852 INFO:     None feature selector for col chem
2022-12-05 21:03:03,852 INFO:     None feature selector for col chem
2022-12-05 21:03:03,852 INFO:     None feature selector for col chem
2022-12-05 21:03:03,852 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:03:03,852 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:03:03,854 INFO:     Number of params in model 215821
2022-12-05 21:03:03,857 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:03:03,857 INFO:   Starting stage: TRAINING
2022-12-05 21:03:03,917 INFO:     Val loss before train {'Reaction outcome loss': 1.008660148490559, 'Total loss': 1.008660148490559}
2022-12-05 21:03:03,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:03,917 INFO:     Epoch: 0
2022-12-05 21:03:04,714 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6301888586445288, 'Total loss': 0.6301888586445288} | train loss {'Reaction outcome loss': 0.8037201537480277, 'Total loss': 0.8037201537480277}
2022-12-05 21:03:04,714 INFO:     Found new best model at epoch 0
2022-12-05 21:03:04,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:04,715 INFO:     Epoch: 1
2022-12-05 21:03:05,512 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5249076878482645, 'Total loss': 0.5249076878482645} | train loss {'Reaction outcome loss': 0.5432872616595799, 'Total loss': 0.5432872616595799}
2022-12-05 21:03:05,512 INFO:     Found new best model at epoch 1
2022-12-05 21:03:05,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:05,513 INFO:     Epoch: 2
2022-12-05 21:03:06,309 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49418976801362907, 'Total loss': 0.49418976801362907} | train loss {'Reaction outcome loss': 0.46816150363414516, 'Total loss': 0.46816150363414516}
2022-12-05 21:03:06,309 INFO:     Found new best model at epoch 2
2022-12-05 21:03:06,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:06,310 INFO:     Epoch: 3
2022-12-05 21:03:07,107 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47449801049449225, 'Total loss': 0.47449801049449225} | train loss {'Reaction outcome loss': 0.4260872842804078, 'Total loss': 0.4260872842804078}
2022-12-05 21:03:07,107 INFO:     Found new best model at epoch 3
2022-12-05 21:03:07,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:07,108 INFO:     Epoch: 4
2022-12-05 21:03:07,904 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44695390185171907, 'Total loss': 0.44695390185171907} | train loss {'Reaction outcome loss': 0.3962734443165602, 'Total loss': 0.3962734443165602}
2022-12-05 21:03:07,904 INFO:     Found new best model at epoch 4
2022-12-05 21:03:07,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:07,905 INFO:     Epoch: 5
2022-12-05 21:03:08,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44607581062750384, 'Total loss': 0.44607581062750384} | train loss {'Reaction outcome loss': 0.36990950130406886, 'Total loss': 0.36990950130406886}
2022-12-05 21:03:08,699 INFO:     Found new best model at epoch 5
2022-12-05 21:03:08,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:08,700 INFO:     Epoch: 6
2022-12-05 21:03:09,493 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4329281872646375, 'Total loss': 0.4329281872646375} | train loss {'Reaction outcome loss': 0.3505865637393248, 'Total loss': 0.3505865637393248}
2022-12-05 21:03:09,494 INFO:     Found new best model at epoch 6
2022-12-05 21:03:09,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:09,494 INFO:     Epoch: 7
2022-12-05 21:03:10,288 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4266289310021834, 'Total loss': 0.4266289310021834} | train loss {'Reaction outcome loss': 0.33549139261125555, 'Total loss': 0.33549139261125555}
2022-12-05 21:03:10,288 INFO:     Found new best model at epoch 7
2022-12-05 21:03:10,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:10,289 INFO:     Epoch: 8
2022-12-05 21:03:11,083 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4324332136999477, 'Total loss': 0.4324332136999477} | train loss {'Reaction outcome loss': 0.3190645589343002, 'Total loss': 0.3190645589343002}
2022-12-05 21:03:11,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:11,084 INFO:     Epoch: 9
2022-12-05 21:03:11,877 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42440315894782543, 'Total loss': 0.42440315894782543} | train loss {'Reaction outcome loss': 0.3066311338916421, 'Total loss': 0.3066311338916421}
2022-12-05 21:03:11,877 INFO:     Found new best model at epoch 9
2022-12-05 21:03:11,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:11,878 INFO:     Epoch: 10
2022-12-05 21:03:12,674 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4247791425070979, 'Total loss': 0.4247791425070979} | train loss {'Reaction outcome loss': 0.29481133692447214, 'Total loss': 0.29481133692447214}
2022-12-05 21:03:12,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:12,674 INFO:     Epoch: 11
2022-12-05 21:03:13,471 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4156898459927602, 'Total loss': 0.4156898459927602} | train loss {'Reaction outcome loss': 0.2867302781932296, 'Total loss': 0.2867302781932296}
2022-12-05 21:03:13,471 INFO:     Found new best model at epoch 11
2022-12-05 21:03:13,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:13,472 INFO:     Epoch: 12
2022-12-05 21:03:14,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4151855167001486, 'Total loss': 0.4151855167001486} | train loss {'Reaction outcome loss': 0.2754114280124345, 'Total loss': 0.2754114280124345}
2022-12-05 21:03:14,268 INFO:     Found new best model at epoch 12
2022-12-05 21:03:14,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:14,269 INFO:     Epoch: 13
2022-12-05 21:03:15,062 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4201912185685201, 'Total loss': 0.4201912185685201} | train loss {'Reaction outcome loss': 0.26479163832001146, 'Total loss': 0.26479163832001146}
2022-12-05 21:03:15,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:15,062 INFO:     Epoch: 14
2022-12-05 21:03:15,856 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.419745803556659, 'Total loss': 0.419745803556659} | train loss {'Reaction outcome loss': 0.2559611780809299, 'Total loss': 0.2559611780809299}
2022-12-05 21:03:15,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:15,856 INFO:     Epoch: 15
2022-12-05 21:03:16,653 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4386353093114766, 'Total loss': 0.4386353093114766} | train loss {'Reaction outcome loss': 0.2482333257193527, 'Total loss': 0.2482333257193527}
2022-12-05 21:03:16,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:16,653 INFO:     Epoch: 16
2022-12-05 21:03:17,448 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41733160377903417, 'Total loss': 0.41733160377903417} | train loss {'Reaction outcome loss': 0.2428167154411635, 'Total loss': 0.2428167154411635}
2022-12-05 21:03:17,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:17,449 INFO:     Epoch: 17
2022-12-05 21:03:18,241 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4312976249916987, 'Total loss': 0.4312976249916987} | train loss {'Reaction outcome loss': 0.23377721612491914, 'Total loss': 0.23377721612491914}
2022-12-05 21:03:18,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:18,242 INFO:     Epoch: 18
2022-12-05 21:03:19,036 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41738014397296036, 'Total loss': 0.41738014397296036} | train loss {'Reaction outcome loss': 0.2279881955004267, 'Total loss': 0.2279881955004267}
2022-12-05 21:03:19,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:19,037 INFO:     Epoch: 19
2022-12-05 21:03:19,830 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4296919730576602, 'Total loss': 0.4296919730576602} | train loss {'Reaction outcome loss': 0.22420158387432176, 'Total loss': 0.22420158387432176}
2022-12-05 21:03:19,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:19,830 INFO:     Epoch: 20
2022-12-05 21:03:20,628 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4176418280059641, 'Total loss': 0.4176418280059641} | train loss {'Reaction outcome loss': 0.21520097876688646, 'Total loss': 0.21520097876688646}
2022-12-05 21:03:20,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:20,628 INFO:     Epoch: 21
2022-12-05 21:03:21,421 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4233311697502028, 'Total loss': 0.4233311697502028} | train loss {'Reaction outcome loss': 0.21050152908860437, 'Total loss': 0.21050152908860437}
2022-12-05 21:03:21,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:21,422 INFO:     Epoch: 22
2022-12-05 21:03:22,215 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43506183102726936, 'Total loss': 0.43506183102726936} | train loss {'Reaction outcome loss': 0.20692738059968238, 'Total loss': 0.20692738059968238}
2022-12-05 21:03:22,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:22,215 INFO:     Epoch: 23
2022-12-05 21:03:23,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42842514609748666, 'Total loss': 0.42842514609748666} | train loss {'Reaction outcome loss': 0.20068972517976597, 'Total loss': 0.20068972517976597}
2022-12-05 21:03:23,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:23,016 INFO:     Epoch: 24
2022-12-05 21:03:23,815 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4356245283376087, 'Total loss': 0.4356245283376087} | train loss {'Reaction outcome loss': 0.19668110593732807, 'Total loss': 0.19668110593732807}
2022-12-05 21:03:23,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:23,815 INFO:     Epoch: 25
2022-12-05 21:03:24,609 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43608087368986825, 'Total loss': 0.43608087368986825} | train loss {'Reaction outcome loss': 0.19560087469947193, 'Total loss': 0.19560087469947193}
2022-12-05 21:03:24,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:24,610 INFO:     Epoch: 26
2022-12-05 21:03:25,410 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42939862541177054, 'Total loss': 0.42939862541177054} | train loss {'Reaction outcome loss': 0.19161741794537632, 'Total loss': 0.19161741794537632}
2022-12-05 21:03:25,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:25,410 INFO:     Epoch: 27
2022-12-05 21:03:26,203 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4411648632111875, 'Total loss': 0.4411648632111875} | train loss {'Reaction outcome loss': 0.18832967018768673, 'Total loss': 0.18832967018768673}
2022-12-05 21:03:26,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:26,203 INFO:     Epoch: 28
2022-12-05 21:03:27,001 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44521284712986514, 'Total loss': 0.44521284712986514} | train loss {'Reaction outcome loss': 0.1842462993527372, 'Total loss': 0.1842462993527372}
2022-12-05 21:03:27,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:27,001 INFO:     Epoch: 29
2022-12-05 21:03:27,797 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44169488684697583, 'Total loss': 0.44169488684697583} | train loss {'Reaction outcome loss': 0.18309732645209278, 'Total loss': 0.18309732645209278}
2022-12-05 21:03:27,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:27,798 INFO:     Epoch: 30
2022-12-05 21:03:28,592 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45363977483727713, 'Total loss': 0.45363977483727713} | train loss {'Reaction outcome loss': 0.17766593019628235, 'Total loss': 0.17766593019628235}
2022-12-05 21:03:28,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:28,592 INFO:     Epoch: 31
2022-12-05 21:03:29,391 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4393396457149224, 'Total loss': 0.4393396457149224} | train loss {'Reaction outcome loss': 0.17573078553522786, 'Total loss': 0.17573078553522786}
2022-12-05 21:03:29,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:29,392 INFO:     Epoch: 32
2022-12-05 21:03:30,186 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4436801566996358, 'Total loss': 0.4436801566996358} | train loss {'Reaction outcome loss': 0.17326698407170274, 'Total loss': 0.17326698407170274}
2022-12-05 21:03:30,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:30,186 INFO:     Epoch: 33
2022-12-05 21:03:30,980 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44957994906739757, 'Total loss': 0.44957994906739757} | train loss {'Reaction outcome loss': 0.16976622477053635, 'Total loss': 0.16976622477053635}
2022-12-05 21:03:30,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:30,980 INFO:     Epoch: 34
2022-12-05 21:03:31,777 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.451540908691558, 'Total loss': 0.451540908691558} | train loss {'Reaction outcome loss': 0.16747119312264747, 'Total loss': 0.16747119312264747}
2022-12-05 21:03:31,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:31,777 INFO:     Epoch: 35
2022-12-05 21:03:32,572 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4505895691161806, 'Total loss': 0.4505895691161806} | train loss {'Reaction outcome loss': 0.1644863995776001, 'Total loss': 0.1644863995776001}
2022-12-05 21:03:32,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:32,572 INFO:     Epoch: 36
2022-12-05 21:03:33,372 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44257119348780677, 'Total loss': 0.44257119348780677} | train loss {'Reaction outcome loss': 0.16559544403196103, 'Total loss': 0.16559544403196103}
2022-12-05 21:03:33,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:33,372 INFO:     Epoch: 37
2022-12-05 21:03:34,169 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43051449073986575, 'Total loss': 0.43051449073986575} | train loss {'Reaction outcome loss': 0.1642358205731838, 'Total loss': 0.1642358205731838}
2022-12-05 21:03:34,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:34,169 INFO:     Epoch: 38
2022-12-05 21:03:34,964 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4418053278191523, 'Total loss': 0.4418053278191523} | train loss {'Reaction outcome loss': 0.15902799295051204, 'Total loss': 0.15902799295051204}
2022-12-05 21:03:34,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:34,964 INFO:     Epoch: 39
2022-12-05 21:03:35,763 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43751062926920975, 'Total loss': 0.43751062926920975} | train loss {'Reaction outcome loss': 0.15780074919964518, 'Total loss': 0.15780074919964518}
2022-12-05 21:03:35,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:35,763 INFO:     Epoch: 40
2022-12-05 21:03:36,560 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.455861802466891, 'Total loss': 0.455861802466891} | train loss {'Reaction outcome loss': 0.15796766447414073, 'Total loss': 0.15796766447414073}
2022-12-05 21:03:36,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:36,560 INFO:     Epoch: 41
2022-12-05 21:03:37,359 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4502263909036463, 'Total loss': 0.4502263909036463} | train loss {'Reaction outcome loss': 0.15493465338893717, 'Total loss': 0.15493465338893717}
2022-12-05 21:03:37,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:37,359 INFO:     Epoch: 42
2022-12-05 21:03:38,154 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45418547347865323, 'Total loss': 0.45418547347865323} | train loss {'Reaction outcome loss': 0.1540645332556338, 'Total loss': 0.1540645332556338}
2022-12-05 21:03:38,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:38,155 INFO:     Epoch: 43
2022-12-05 21:03:38,950 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4640795039859685, 'Total loss': 0.4640795039859685} | train loss {'Reaction outcome loss': 0.1527577440419625, 'Total loss': 0.1527577440419625}
2022-12-05 21:03:38,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:38,951 INFO:     Epoch: 44
2022-12-05 21:03:39,748 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.454911623488773, 'Total loss': 0.454911623488773} | train loss {'Reaction outcome loss': 0.15087467247259714, 'Total loss': 0.15087467247259714}
2022-12-05 21:03:39,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:39,749 INFO:     Epoch: 45
2022-12-05 21:03:40,545 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4534907215698199, 'Total loss': 0.4534907215698199} | train loss {'Reaction outcome loss': 0.1501902432158409, 'Total loss': 0.1501902432158409}
2022-12-05 21:03:40,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:40,546 INFO:     Epoch: 46
2022-12-05 21:03:41,343 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.452291936698285, 'Total loss': 0.452291936698285} | train loss {'Reaction outcome loss': 0.14659462670885748, 'Total loss': 0.14659462670885748}
2022-12-05 21:03:41,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:41,343 INFO:     Epoch: 47
2022-12-05 21:03:42,141 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4512610061263496, 'Total loss': 0.4512610061263496} | train loss {'Reaction outcome loss': 0.1475671563342574, 'Total loss': 0.1475671563342574}
2022-12-05 21:03:42,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:42,141 INFO:     Epoch: 48
2022-12-05 21:03:42,941 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4498464824123816, 'Total loss': 0.4498464824123816} | train loss {'Reaction outcome loss': 0.1441885375327641, 'Total loss': 0.1441885375327641}
2022-12-05 21:03:42,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:42,941 INFO:     Epoch: 49
2022-12-05 21:03:43,741 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4702588196166537, 'Total loss': 0.4702588196166537} | train loss {'Reaction outcome loss': 0.1459956661189696, 'Total loss': 0.1459956661189696}
2022-12-05 21:03:43,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:43,741 INFO:     Epoch: 50
2022-12-05 21:03:44,537 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4747176901860671, 'Total loss': 0.4747176901860671} | train loss {'Reaction outcome loss': 0.14398190072707592, 'Total loss': 0.14398190072707592}
2022-12-05 21:03:44,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:44,537 INFO:     Epoch: 51
2022-12-05 21:03:45,330 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4754865389655937, 'Total loss': 0.4754865389655937} | train loss {'Reaction outcome loss': 0.14111028414880555, 'Total loss': 0.14111028414880555}
2022-12-05 21:03:45,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:45,331 INFO:     Epoch: 52
2022-12-05 21:03:46,131 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44556143202564935, 'Total loss': 0.44556143202564935} | train loss {'Reaction outcome loss': 0.1396914559619261, 'Total loss': 0.1396914559619261}
2022-12-05 21:03:46,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:46,131 INFO:     Epoch: 53
2022-12-05 21:03:46,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4556329216469418, 'Total loss': 0.4556329216469418} | train loss {'Reaction outcome loss': 0.1436413538814973, 'Total loss': 0.1436413538814973}
2022-12-05 21:03:46,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:46,924 INFO:     Epoch: 54
2022-12-05 21:03:47,718 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46176430210471153, 'Total loss': 0.46176430210471153} | train loss {'Reaction outcome loss': 0.13947147963899037, 'Total loss': 0.13947147963899037}
2022-12-05 21:03:47,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:47,718 INFO:     Epoch: 55
2022-12-05 21:03:48,514 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46855071119286795, 'Total loss': 0.46855071119286795} | train loss {'Reaction outcome loss': 0.14052424541929917, 'Total loss': 0.14052424541929917}
2022-12-05 21:03:48,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:48,514 INFO:     Epoch: 56
2022-12-05 21:03:49,311 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4547626813026992, 'Total loss': 0.4547626813026992} | train loss {'Reaction outcome loss': 0.13626637905385466, 'Total loss': 0.13626637905385466}
2022-12-05 21:03:49,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:49,311 INFO:     Epoch: 57
2022-12-05 21:03:50,106 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4643532576208765, 'Total loss': 0.4643532576208765} | train loss {'Reaction outcome loss': 0.13688274080895127, 'Total loss': 0.13688274080895127}
2022-12-05 21:03:50,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:50,106 INFO:     Epoch: 58
2022-12-05 21:03:50,899 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4589857906103134, 'Total loss': 0.4589857906103134} | train loss {'Reaction outcome loss': 0.13690796096418653, 'Total loss': 0.13690796096418653}
2022-12-05 21:03:50,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:50,900 INFO:     Epoch: 59
2022-12-05 21:03:51,693 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4650478464635936, 'Total loss': 0.4650478464635936} | train loss {'Reaction outcome loss': 0.13645985910308459, 'Total loss': 0.13645985910308459}
2022-12-05 21:03:51,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:51,694 INFO:     Epoch: 60
2022-12-05 21:03:52,488 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4664884250272404, 'Total loss': 0.4664884250272404} | train loss {'Reaction outcome loss': 0.13367691035232238, 'Total loss': 0.13367691035232238}
2022-12-05 21:03:52,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:52,489 INFO:     Epoch: 61
2022-12-05 21:03:53,283 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4632502116940238, 'Total loss': 0.4632502116940238} | train loss {'Reaction outcome loss': 0.13287561572337103, 'Total loss': 0.13287561572337103}
2022-12-05 21:03:53,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:53,283 INFO:     Epoch: 62
2022-12-05 21:03:54,078 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46741551702672784, 'Total loss': 0.46741551702672784} | train loss {'Reaction outcome loss': 0.1334700516346211, 'Total loss': 0.1334700516346211}
2022-12-05 21:03:54,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:54,078 INFO:     Epoch: 63
2022-12-05 21:03:54,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45852831209247763, 'Total loss': 0.45852831209247763} | train loss {'Reaction outcome loss': 0.13201160086018424, 'Total loss': 0.13201160086018424}
2022-12-05 21:03:54,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:54,871 INFO:     Epoch: 64
2022-12-05 21:03:55,673 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.462252082133835, 'Total loss': 0.462252082133835} | train loss {'Reaction outcome loss': 0.1319188423109271, 'Total loss': 0.1319188423109271}
2022-12-05 21:03:55,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:55,673 INFO:     Epoch: 65
2022-12-05 21:03:56,467 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4587071876634251, 'Total loss': 0.4587071876634251} | train loss {'Reaction outcome loss': 0.1311179841718366, 'Total loss': 0.1311179841718366}
2022-12-05 21:03:56,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:56,468 INFO:     Epoch: 66
2022-12-05 21:03:57,261 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4628090174360709, 'Total loss': 0.4628090174360709} | train loss {'Reaction outcome loss': 0.12958267565831663, 'Total loss': 0.12958267565831663}
2022-12-05 21:03:57,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:57,262 INFO:     Epoch: 67
2022-12-05 21:03:58,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46347605606371706, 'Total loss': 0.46347605606371706} | train loss {'Reaction outcome loss': 0.13004293281870383, 'Total loss': 0.13004293281870383}
2022-12-05 21:03:58,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:58,055 INFO:     Epoch: 68
2022-12-05 21:03:58,847 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45518070831894875, 'Total loss': 0.45518070831894875} | train loss {'Reaction outcome loss': 0.12887360105260967, 'Total loss': 0.12887360105260967}
2022-12-05 21:03:58,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:58,848 INFO:     Epoch: 69
2022-12-05 21:03:59,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4621595916422931, 'Total loss': 0.4621595916422931} | train loss {'Reaction outcome loss': 0.12675812147227267, 'Total loss': 0.12675812147227267}
2022-12-05 21:03:59,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:03:59,647 INFO:     Epoch: 70
2022-12-05 21:04:00,442 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45572480085221206, 'Total loss': 0.45572480085221206} | train loss {'Reaction outcome loss': 0.1273531503487198, 'Total loss': 0.1273531503487198}
2022-12-05 21:04:00,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:00,442 INFO:     Epoch: 71
2022-12-05 21:04:01,237 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4531797224825079, 'Total loss': 0.4531797224825079} | train loss {'Reaction outcome loss': 0.1284574458202828, 'Total loss': 0.1284574458202828}
2022-12-05 21:04:01,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:01,237 INFO:     Epoch: 72
2022-12-05 21:04:02,034 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45478473806923086, 'Total loss': 0.45478473806923086} | train loss {'Reaction outcome loss': 0.12610420754044166, 'Total loss': 0.12610420754044166}
2022-12-05 21:04:02,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:02,035 INFO:     Epoch: 73
2022-12-05 21:04:02,831 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4584562768313018, 'Total loss': 0.4584562768313018} | train loss {'Reaction outcome loss': 0.12356403712633877, 'Total loss': 0.12356403712633877}
2022-12-05 21:04:02,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:02,831 INFO:     Epoch: 74
2022-12-05 21:04:03,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4734690809114413, 'Total loss': 0.4734690809114413} | train loss {'Reaction outcome loss': 0.125822875209363, 'Total loss': 0.125822875209363}
2022-12-05 21:04:03,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:03,631 INFO:     Epoch: 75
2022-12-05 21:04:04,427 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4584684321148829, 'Total loss': 0.4584684321148829} | train loss {'Reaction outcome loss': 0.12748967681545764, 'Total loss': 0.12748967681545764}
2022-12-05 21:04:04,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:04,427 INFO:     Epoch: 76
2022-12-05 21:04:05,220 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4576799292117357, 'Total loss': 0.4576799292117357} | train loss {'Reaction outcome loss': 0.12404543281187333, 'Total loss': 0.12404543281187333}
2022-12-05 21:04:05,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:05,220 INFO:     Epoch: 77
2022-12-05 21:04:06,015 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46588180264966056, 'Total loss': 0.46588180264966056} | train loss {'Reaction outcome loss': 0.12540392293369457, 'Total loss': 0.12540392293369457}
2022-12-05 21:04:06,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:06,015 INFO:     Epoch: 78
2022-12-05 21:04:06,809 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4499058970673518, 'Total loss': 0.4499058970673518} | train loss {'Reaction outcome loss': 0.12341476111267242, 'Total loss': 0.12341476111267242}
2022-12-05 21:04:06,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:06,810 INFO:     Epoch: 79
2022-12-05 21:04:07,601 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4562046830965714, 'Total loss': 0.4562046830965714} | train loss {'Reaction outcome loss': 0.12062960261509063, 'Total loss': 0.12062960261509063}
2022-12-05 21:04:07,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:07,601 INFO:     Epoch: 80
2022-12-05 21:04:08,396 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.462135258723389, 'Total loss': 0.462135258723389} | train loss {'Reaction outcome loss': 0.12258995919969053, 'Total loss': 0.12258995919969053}
2022-12-05 21:04:08,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:08,396 INFO:     Epoch: 81
2022-12-05 21:04:09,187 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4738819912414659, 'Total loss': 0.4738819912414659} | train loss {'Reaction outcome loss': 0.1222047864594647, 'Total loss': 0.1222047864594647}
2022-12-05 21:04:09,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:09,188 INFO:     Epoch: 82
2022-12-05 21:04:09,980 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45966316387057304, 'Total loss': 0.45966316387057304} | train loss {'Reaction outcome loss': 0.12161545422784384, 'Total loss': 0.12161545422784384}
2022-12-05 21:04:09,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:09,980 INFO:     Epoch: 83
2022-12-05 21:04:10,775 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46963074193759397, 'Total loss': 0.46963074193759397} | train loss {'Reaction outcome loss': 0.1197767834434466, 'Total loss': 0.1197767834434466}
2022-12-05 21:04:10,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:10,775 INFO:     Epoch: 84
2022-12-05 21:04:11,568 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47564142095771705, 'Total loss': 0.47564142095771705} | train loss {'Reaction outcome loss': 0.12022684217475715, 'Total loss': 0.12022684217475715}
2022-12-05 21:04:11,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:11,569 INFO:     Epoch: 85
2022-12-05 21:04:12,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45364090766419063, 'Total loss': 0.45364090766419063} | train loss {'Reaction outcome loss': 0.12019475993715346, 'Total loss': 0.12019475993715346}
2022-12-05 21:04:12,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:12,361 INFO:     Epoch: 86
2022-12-05 21:04:13,157 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44786847856911743, 'Total loss': 0.44786847856911743} | train loss {'Reaction outcome loss': 0.11935571171230666, 'Total loss': 0.11935571171230666}
2022-12-05 21:04:13,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:13,157 INFO:     Epoch: 87
2022-12-05 21:04:13,956 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4694860933179205, 'Total loss': 0.4694860933179205} | train loss {'Reaction outcome loss': 0.11990283212939938, 'Total loss': 0.11990283212939938}
2022-12-05 21:04:13,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:13,956 INFO:     Epoch: 88
2022-12-05 21:04:14,751 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4869604930281639, 'Total loss': 0.4869604930281639} | train loss {'Reaction outcome loss': 0.11967173133481053, 'Total loss': 0.11967173133481053}
2022-12-05 21:04:14,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:14,751 INFO:     Epoch: 89
2022-12-05 21:04:15,544 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4568148126656359, 'Total loss': 0.4568148126656359} | train loss {'Reaction outcome loss': 0.11974187545298089, 'Total loss': 0.11974187545298089}
2022-12-05 21:04:15,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:15,545 INFO:     Epoch: 90
2022-12-05 21:04:16,346 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4627288888123902, 'Total loss': 0.4627288888123902} | train loss {'Reaction outcome loss': 0.11916306146585773, 'Total loss': 0.11916306146585773}
2022-12-05 21:04:16,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:16,346 INFO:     Epoch: 91
2022-12-05 21:04:17,146 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47557217289100995, 'Total loss': 0.47557217289100995} | train loss {'Reaction outcome loss': 0.11735309193083536, 'Total loss': 0.11735309193083536}
2022-12-05 21:04:17,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:17,146 INFO:     Epoch: 92
2022-12-05 21:04:17,942 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46638561480424623, 'Total loss': 0.46638561480424623} | train loss {'Reaction outcome loss': 0.11656179323777437, 'Total loss': 0.11656179323777437}
2022-12-05 21:04:17,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:17,942 INFO:     Epoch: 93
2022-12-05 21:04:18,737 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4640326878394593, 'Total loss': 0.4640326878394593} | train loss {'Reaction outcome loss': 0.11904534306978026, 'Total loss': 0.11904534306978026}
2022-12-05 21:04:18,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:18,737 INFO:     Epoch: 94
2022-12-05 21:04:19,530 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46205042573538696, 'Total loss': 0.46205042573538696} | train loss {'Reaction outcome loss': 0.11896429347219847, 'Total loss': 0.11896429347219847}
2022-12-05 21:04:19,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:19,530 INFO:     Epoch: 95
2022-12-05 21:04:20,325 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4672077416696332, 'Total loss': 0.4672077416696332} | train loss {'Reaction outcome loss': 0.11742811416456055, 'Total loss': 0.11742811416456055}
2022-12-05 21:04:20,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:20,325 INFO:     Epoch: 96
2022-12-05 21:04:21,121 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4596758853982795, 'Total loss': 0.4596758853982795} | train loss {'Reaction outcome loss': 0.11622783266037943, 'Total loss': 0.11622783266037943}
2022-12-05 21:04:21,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:21,121 INFO:     Epoch: 97
2022-12-05 21:04:21,918 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4592183479531245, 'Total loss': 0.4592183479531245} | train loss {'Reaction outcome loss': 0.11448507304979308, 'Total loss': 0.11448507304979308}
2022-12-05 21:04:21,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:21,919 INFO:     Epoch: 98
2022-12-05 21:04:22,714 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4562539979815483, 'Total loss': 0.4562539979815483} | train loss {'Reaction outcome loss': 0.11744397539540284, 'Total loss': 0.11744397539540284}
2022-12-05 21:04:22,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:22,714 INFO:     Epoch: 99
2022-12-05 21:04:23,513 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48814084651795303, 'Total loss': 0.48814084651795303} | train loss {'Reaction outcome loss': 0.11601074571691213, 'Total loss': 0.11601074571691213}
2022-12-05 21:04:23,515 INFO:     Best model found after epoch 13 of 100.
2022-12-05 21:04:23,515 INFO:   Done with stage: TRAINING
2022-12-05 21:04:23,515 INFO:   Starting stage: EVALUATION
2022-12-05 21:04:23,634 INFO:   Done with stage: EVALUATION
2022-12-05 21:04:23,634 INFO:   Leaving out SEQ value Fold_8
2022-12-05 21:04:23,647 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:04:23,647 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:04:24,290 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:04:24,290 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:04:24,359 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:04:24,359 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:04:24,359 INFO:     No hyperparam tuning for this model
2022-12-05 21:04:24,359 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:04:24,359 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:04:24,360 INFO:     None feature selector for col prot
2022-12-05 21:04:24,360 INFO:     None feature selector for col prot
2022-12-05 21:04:24,360 INFO:     None feature selector for col prot
2022-12-05 21:04:24,361 INFO:     None feature selector for col chem
2022-12-05 21:04:24,361 INFO:     None feature selector for col chem
2022-12-05 21:04:24,361 INFO:     None feature selector for col chem
2022-12-05 21:04:24,361 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:04:24,361 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:04:24,363 INFO:     Number of params in model 215821
2022-12-05 21:04:24,366 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:04:24,366 INFO:   Starting stage: TRAINING
2022-12-05 21:04:24,426 INFO:     Val loss before train {'Reaction outcome loss': 0.975013177503239, 'Total loss': 0.975013177503239}
2022-12-05 21:04:24,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:24,426 INFO:     Epoch: 0
2022-12-05 21:04:25,222 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6081614555283026, 'Total loss': 0.6081614555283026} | train loss {'Reaction outcome loss': 0.8036607995388969, 'Total loss': 0.8036607995388969}
2022-12-05 21:04:25,222 INFO:     Found new best model at epoch 0
2022-12-05 21:04:25,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:25,223 INFO:     Epoch: 1
2022-12-05 21:04:26,018 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5327781682664697, 'Total loss': 0.5327781682664697} | train loss {'Reaction outcome loss': 0.5510678466169103, 'Total loss': 0.5510678466169103}
2022-12-05 21:04:26,018 INFO:     Found new best model at epoch 1
2022-12-05 21:04:26,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:26,019 INFO:     Epoch: 2
2022-12-05 21:04:26,816 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49393006278709933, 'Total loss': 0.49393006278709933} | train loss {'Reaction outcome loss': 0.4821696518770149, 'Total loss': 0.4821696518770149}
2022-12-05 21:04:26,816 INFO:     Found new best model at epoch 2
2022-12-05 21:04:26,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:26,817 INFO:     Epoch: 3
2022-12-05 21:04:27,616 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4701582125642083, 'Total loss': 0.4701582125642083} | train loss {'Reaction outcome loss': 0.4419216486595331, 'Total loss': 0.4419216486595331}
2022-12-05 21:04:27,616 INFO:     Found new best model at epoch 3
2022-12-05 21:04:27,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:27,617 INFO:     Epoch: 4
2022-12-05 21:04:28,412 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45605489205230365, 'Total loss': 0.45605489205230365} | train loss {'Reaction outcome loss': 0.4111393055307769, 'Total loss': 0.4111393055307769}
2022-12-05 21:04:28,412 INFO:     Found new best model at epoch 4
2022-12-05 21:04:28,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:28,413 INFO:     Epoch: 5
2022-12-05 21:04:29,204 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4569706469774246, 'Total loss': 0.4569706469774246} | train loss {'Reaction outcome loss': 0.3907150851502534, 'Total loss': 0.3907150851502534}
2022-12-05 21:04:29,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:29,204 INFO:     Epoch: 6
2022-12-05 21:04:29,996 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4360564811663194, 'Total loss': 0.4360564811663194} | train loss {'Reaction outcome loss': 0.37112062529570633, 'Total loss': 0.37112062529570633}
2022-12-05 21:04:29,997 INFO:     Found new best model at epoch 6
2022-12-05 21:04:29,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:29,998 INFO:     Epoch: 7
2022-12-05 21:04:30,790 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4357492056759921, 'Total loss': 0.4357492056759921} | train loss {'Reaction outcome loss': 0.35493416450316867, 'Total loss': 0.35493416450316867}
2022-12-05 21:04:30,791 INFO:     Found new best model at epoch 7
2022-12-05 21:04:30,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:30,791 INFO:     Epoch: 8
2022-12-05 21:04:31,583 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4235775728117336, 'Total loss': 0.4235775728117336} | train loss {'Reaction outcome loss': 0.3388273511983214, 'Total loss': 0.3388273511983214}
2022-12-05 21:04:31,583 INFO:     Found new best model at epoch 8
2022-12-05 21:04:31,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:31,584 INFO:     Epoch: 9
2022-12-05 21:04:32,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4317691688510505, 'Total loss': 0.4317691688510505} | train loss {'Reaction outcome loss': 0.3224609909999755, 'Total loss': 0.3224609909999755}
2022-12-05 21:04:32,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:32,379 INFO:     Epoch: 10
2022-12-05 21:04:33,173 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4155017506669868, 'Total loss': 0.4155017506669868} | train loss {'Reaction outcome loss': 0.3111338571254765, 'Total loss': 0.3111338571254765}
2022-12-05 21:04:33,173 INFO:     Found new best model at epoch 10
2022-12-05 21:04:33,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:33,174 INFO:     Epoch: 11
2022-12-05 21:04:33,966 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.421280270611698, 'Total loss': 0.421280270611698} | train loss {'Reaction outcome loss': 0.2975397993389878, 'Total loss': 0.2975397993389878}
2022-12-05 21:04:33,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:33,966 INFO:     Epoch: 12
2022-12-05 21:04:34,758 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41724016348069365, 'Total loss': 0.41724016348069365} | train loss {'Reaction outcome loss': 0.28763637208049336, 'Total loss': 0.28763637208049336}
2022-12-05 21:04:34,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:34,758 INFO:     Epoch: 13
2022-12-05 21:04:35,553 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4157279066064141, 'Total loss': 0.4157279066064141} | train loss {'Reaction outcome loss': 0.2774601961155572, 'Total loss': 0.2774601961155572}
2022-12-05 21:04:35,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:35,553 INFO:     Epoch: 14
2022-12-05 21:04:36,352 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40884737026962364, 'Total loss': 0.40884737026962364} | train loss {'Reaction outcome loss': 0.27246525399987737, 'Total loss': 0.27246525399987737}
2022-12-05 21:04:36,352 INFO:     Found new best model at epoch 14
2022-12-05 21:04:36,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:36,353 INFO:     Epoch: 15
2022-12-05 21:04:37,147 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42520792850039224, 'Total loss': 0.42520792850039224} | train loss {'Reaction outcome loss': 0.26140263790805496, 'Total loss': 0.26140263790805496}
2022-12-05 21:04:37,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:37,147 INFO:     Epoch: 16
2022-12-05 21:04:37,938 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41156248206442053, 'Total loss': 0.41156248206442053} | train loss {'Reaction outcome loss': 0.2561623117315673, 'Total loss': 0.2561623117315673}
2022-12-05 21:04:37,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:37,939 INFO:     Epoch: 17
2022-12-05 21:04:38,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41939288784157147, 'Total loss': 0.41939288784157147} | train loss {'Reaction outcome loss': 0.24603071440792373, 'Total loss': 0.24603071440792373}
2022-12-05 21:04:38,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:38,734 INFO:     Epoch: 18
2022-12-05 21:04:39,529 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4174754429947246, 'Total loss': 0.4174754429947246} | train loss {'Reaction outcome loss': 0.24075624504457077, 'Total loss': 0.24075624504457077}
2022-12-05 21:04:39,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:39,529 INFO:     Epoch: 19
2022-12-05 21:04:40,322 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4078023455698382, 'Total loss': 0.4078023455698382} | train loss {'Reaction outcome loss': 0.2358215764134882, 'Total loss': 0.2358215764134882}
2022-12-05 21:04:40,322 INFO:     Found new best model at epoch 19
2022-12-05 21:04:40,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:40,323 INFO:     Epoch: 20
2022-12-05 21:04:41,115 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42163154550574045, 'Total loss': 0.42163154550574045} | train loss {'Reaction outcome loss': 0.22777358757992905, 'Total loss': 0.22777358757992905}
2022-12-05 21:04:41,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:41,115 INFO:     Epoch: 21
2022-12-05 21:04:41,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.410157555883581, 'Total loss': 0.410157555883581} | train loss {'Reaction outcome loss': 0.22507485125454202, 'Total loss': 0.22507485125454202}
2022-12-05 21:04:41,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:41,911 INFO:     Epoch: 22
2022-12-05 21:04:42,706 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4154169444333423, 'Total loss': 0.4154169444333423} | train loss {'Reaction outcome loss': 0.2189309882420686, 'Total loss': 0.2189309882420686}
2022-12-05 21:04:42,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:42,706 INFO:     Epoch: 23
2022-12-05 21:04:43,498 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4130203547802838, 'Total loss': 0.4130203547802838} | train loss {'Reaction outcome loss': 0.2159028526155218, 'Total loss': 0.2159028526155218}
2022-12-05 21:04:43,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:43,498 INFO:     Epoch: 24
2022-12-05 21:04:44,290 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4179693602702834, 'Total loss': 0.4179693602702834} | train loss {'Reaction outcome loss': 0.21189893914326544, 'Total loss': 0.21189893914326544}
2022-12-05 21:04:44,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:44,290 INFO:     Epoch: 25
2022-12-05 21:04:45,082 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4198598037050529, 'Total loss': 0.4198598037050529} | train loss {'Reaction outcome loss': 0.20746961734708277, 'Total loss': 0.20746961734708277}
2022-12-05 21:04:45,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:45,082 INFO:     Epoch: 26
2022-12-05 21:04:45,876 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4102537462657148, 'Total loss': 0.4102537462657148} | train loss {'Reaction outcome loss': 0.20152458315715194, 'Total loss': 0.20152458315715194}
2022-12-05 21:04:45,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:45,876 INFO:     Epoch: 27
2022-12-05 21:04:46,673 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4180480041964488, 'Total loss': 0.4180480041964488} | train loss {'Reaction outcome loss': 0.1973916590814629, 'Total loss': 0.1973916590814629}
2022-12-05 21:04:46,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:46,673 INFO:     Epoch: 28
2022-12-05 21:04:47,473 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43119662695310335, 'Total loss': 0.43119662695310335} | train loss {'Reaction outcome loss': 0.19544267257855785, 'Total loss': 0.19544267257855785}
2022-12-05 21:04:47,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:47,473 INFO:     Epoch: 29
2022-12-05 21:04:48,268 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42608744684945454, 'Total loss': 0.42608744684945454} | train loss {'Reaction outcome loss': 0.194910051766783, 'Total loss': 0.194910051766783}
2022-12-05 21:04:48,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:48,269 INFO:     Epoch: 30
2022-12-05 21:04:49,061 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4258545098656958, 'Total loss': 0.4258545098656958} | train loss {'Reaction outcome loss': 0.18991421245699447, 'Total loss': 0.18991421245699447}
2022-12-05 21:04:49,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:49,061 INFO:     Epoch: 31
2022-12-05 21:04:49,859 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4278871694749052, 'Total loss': 0.4278871694749052} | train loss {'Reaction outcome loss': 0.18673349736678985, 'Total loss': 0.18673349736678985}
2022-12-05 21:04:49,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:49,859 INFO:     Epoch: 32
2022-12-05 21:04:50,655 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43164251947944815, 'Total loss': 0.43164251947944815} | train loss {'Reaction outcome loss': 0.18463801870483063, 'Total loss': 0.18463801870483063}
2022-12-05 21:04:50,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:50,656 INFO:     Epoch: 33
2022-12-05 21:04:51,453 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42985343289646233, 'Total loss': 0.42985343289646233} | train loss {'Reaction outcome loss': 0.1815635515226712, 'Total loss': 0.1815635515226712}
2022-12-05 21:04:51,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:51,453 INFO:     Epoch: 34
2022-12-05 21:04:52,247 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4415991458703171, 'Total loss': 0.4415991458703171} | train loss {'Reaction outcome loss': 0.1785056472365414, 'Total loss': 0.1785056472365414}
2022-12-05 21:04:52,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:52,248 INFO:     Epoch: 35
2022-12-05 21:04:53,046 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41743558137254283, 'Total loss': 0.41743558137254283} | train loss {'Reaction outcome loss': 0.17625059161875997, 'Total loss': 0.17625059161875997}
2022-12-05 21:04:53,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:53,047 INFO:     Epoch: 36
2022-12-05 21:04:53,842 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4410163705999201, 'Total loss': 0.4410163705999201} | train loss {'Reaction outcome loss': 0.17331075424989384, 'Total loss': 0.17331075424989384}
2022-12-05 21:04:53,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:53,842 INFO:     Epoch: 37
2022-12-05 21:04:54,634 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45044851963492955, 'Total loss': 0.45044851963492955} | train loss {'Reaction outcome loss': 0.17337662148319424, 'Total loss': 0.17337662148319424}
2022-12-05 21:04:54,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:54,635 INFO:     Epoch: 38
2022-12-05 21:04:55,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4297933578491211, 'Total loss': 0.4297933578491211} | train loss {'Reaction outcome loss': 0.16815664931651084, 'Total loss': 0.16815664931651084}
2022-12-05 21:04:55,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:55,435 INFO:     Epoch: 39
2022-12-05 21:04:56,232 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42623850398442964, 'Total loss': 0.42623850398442964} | train loss {'Reaction outcome loss': 0.16913896286109042, 'Total loss': 0.16913896286109042}
2022-12-05 21:04:56,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:56,232 INFO:     Epoch: 40
2022-12-05 21:04:57,029 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44975967874581163, 'Total loss': 0.44975967874581163} | train loss {'Reaction outcome loss': 0.16765976787334488, 'Total loss': 0.16765976787334488}
2022-12-05 21:04:57,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:57,030 INFO:     Epoch: 41
2022-12-05 21:04:57,825 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4411156499250369, 'Total loss': 0.4411156499250369} | train loss {'Reaction outcome loss': 0.1641536742268551, 'Total loss': 0.1641536742268551}
2022-12-05 21:04:57,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:57,825 INFO:     Epoch: 42
2022-12-05 21:04:58,618 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.434404832734303, 'Total loss': 0.434404832734303} | train loss {'Reaction outcome loss': 0.1630066904434634, 'Total loss': 0.1630066904434634}
2022-12-05 21:04:58,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:58,618 INFO:     Epoch: 43
2022-12-05 21:04:59,413 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.434829041023146, 'Total loss': 0.434829041023146} | train loss {'Reaction outcome loss': 0.16053391386184, 'Total loss': 0.16053391386184}
2022-12-05 21:04:59,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:04:59,414 INFO:     Epoch: 44
2022-12-05 21:05:00,208 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44550918211991136, 'Total loss': 0.44550918211991136} | train loss {'Reaction outcome loss': 0.16039037196371222, 'Total loss': 0.16039037196371222}
2022-12-05 21:05:00,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:00,208 INFO:     Epoch: 45
2022-12-05 21:05:01,010 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4434047808701342, 'Total loss': 0.4434047808701342} | train loss {'Reaction outcome loss': 0.15835963312776818, 'Total loss': 0.15835963312776818}
2022-12-05 21:05:01,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:01,011 INFO:     Epoch: 46
2022-12-05 21:05:01,806 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4314700270240957, 'Total loss': 0.4314700270240957} | train loss {'Reaction outcome loss': 0.15554059016698552, 'Total loss': 0.15554059016698552}
2022-12-05 21:05:01,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:01,807 INFO:     Epoch: 47
2022-12-05 21:05:02,602 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4436460103500973, 'Total loss': 0.4436460103500973} | train loss {'Reaction outcome loss': 0.1543843657334125, 'Total loss': 0.1543843657334125}
2022-12-05 21:05:02,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:02,602 INFO:     Epoch: 48
2022-12-05 21:05:03,395 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4385124788704244, 'Total loss': 0.4385124788704244} | train loss {'Reaction outcome loss': 0.1526550293239134, 'Total loss': 0.1526550293239134}
2022-12-05 21:05:03,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:03,395 INFO:     Epoch: 49
2022-12-05 21:05:04,193 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4343829967758872, 'Total loss': 0.4343829967758872} | train loss {'Reaction outcome loss': 0.1527993361420569, 'Total loss': 0.1527993361420569}
2022-12-05 21:05:04,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:04,193 INFO:     Epoch: 50
2022-12-05 21:05:04,992 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.445361407304352, 'Total loss': 0.445361407304352} | train loss {'Reaction outcome loss': 0.1513441894503851, 'Total loss': 0.1513441894503851}
2022-12-05 21:05:04,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:04,992 INFO:     Epoch: 51
2022-12-05 21:05:05,787 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44886865686963906, 'Total loss': 0.44886865686963906} | train loss {'Reaction outcome loss': 0.15080269785117237, 'Total loss': 0.15080269785117237}
2022-12-05 21:05:05,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:05,788 INFO:     Epoch: 52
2022-12-05 21:05:06,585 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4396467191929167, 'Total loss': 0.4396467191929167} | train loss {'Reaction outcome loss': 0.14812042908893236, 'Total loss': 0.14812042908893236}
2022-12-05 21:05:06,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:06,585 INFO:     Epoch: 53
2022-12-05 21:05:07,380 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4433418298986825, 'Total loss': 0.4433418298986825} | train loss {'Reaction outcome loss': 0.1459496159467005, 'Total loss': 0.1459496159467005}
2022-12-05 21:05:07,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:07,381 INFO:     Epoch: 54
2022-12-05 21:05:08,172 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4492806815965609, 'Total loss': 0.4492806815965609} | train loss {'Reaction outcome loss': 0.1438433555961256, 'Total loss': 0.1438433555961256}
2022-12-05 21:05:08,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:08,173 INFO:     Epoch: 55
2022-12-05 21:05:08,967 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44876583326946606, 'Total loss': 0.44876583326946606} | train loss {'Reaction outcome loss': 0.1449075281477323, 'Total loss': 0.1449075281477323}
2022-12-05 21:05:08,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:08,967 INFO:     Epoch: 56
2022-12-05 21:05:09,760 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4484380016272718, 'Total loss': 0.4484380016272718} | train loss {'Reaction outcome loss': 0.1442479679488667, 'Total loss': 0.1442479679488667}
2022-12-05 21:05:09,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:09,760 INFO:     Epoch: 57
2022-12-05 21:05:10,553 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44468236883932893, 'Total loss': 0.44468236883932893} | train loss {'Reaction outcome loss': 0.145868114916788, 'Total loss': 0.145868114916788}
2022-12-05 21:05:10,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:10,553 INFO:     Epoch: 58
2022-12-05 21:05:11,348 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45296403545547614, 'Total loss': 0.45296403545547614} | train loss {'Reaction outcome loss': 0.14259313458516712, 'Total loss': 0.14259313458516712}
2022-12-05 21:05:11,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:11,348 INFO:     Epoch: 59
2022-12-05 21:05:12,140 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4467307556081902, 'Total loss': 0.4467307556081902} | train loss {'Reaction outcome loss': 0.14290583350004687, 'Total loss': 0.14290583350004687}
2022-12-05 21:05:12,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:12,140 INFO:     Epoch: 60
2022-12-05 21:05:12,930 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4434260522777384, 'Total loss': 0.4434260522777384} | train loss {'Reaction outcome loss': 0.14212265978717514, 'Total loss': 0.14212265978717514}
2022-12-05 21:05:12,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:12,931 INFO:     Epoch: 61
2022-12-05 21:05:13,723 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.469560964202339, 'Total loss': 0.469560964202339} | train loss {'Reaction outcome loss': 0.13867079881545638, 'Total loss': 0.13867079881545638}
2022-12-05 21:05:13,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:13,723 INFO:     Epoch: 62
2022-12-05 21:05:14,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45005608519369905, 'Total loss': 0.45005608519369905} | train loss {'Reaction outcome loss': 0.13956295351888384, 'Total loss': 0.13956295351888384}
2022-12-05 21:05:14,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:14,513 INFO:     Epoch: 63
2022-12-05 21:05:15,301 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4633519109338522, 'Total loss': 0.4633519109338522} | train loss {'Reaction outcome loss': 0.1375127582089795, 'Total loss': 0.1375127582089795}
2022-12-05 21:05:15,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:15,301 INFO:     Epoch: 64
2022-12-05 21:05:16,089 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46277752857316623, 'Total loss': 0.46277752857316623} | train loss {'Reaction outcome loss': 0.13653185078123165, 'Total loss': 0.13653185078123165}
2022-12-05 21:05:16,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:16,090 INFO:     Epoch: 65
2022-12-05 21:05:16,878 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46750713004307315, 'Total loss': 0.46750713004307315} | train loss {'Reaction outcome loss': 0.1334429022465502, 'Total loss': 0.1334429022465502}
2022-12-05 21:05:16,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:16,878 INFO:     Epoch: 66
2022-12-05 21:05:17,667 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45265254378318787, 'Total loss': 0.45265254378318787} | train loss {'Reaction outcome loss': 0.1357363335855846, 'Total loss': 0.1357363335855846}
2022-12-05 21:05:17,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:17,667 INFO:     Epoch: 67
2022-12-05 21:05:18,456 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45892102135853335, 'Total loss': 0.45892102135853335} | train loss {'Reaction outcome loss': 0.13440913930084677, 'Total loss': 0.13440913930084677}
2022-12-05 21:05:18,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:18,456 INFO:     Epoch: 68
2022-12-05 21:05:19,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45647637376731093, 'Total loss': 0.45647637376731093} | train loss {'Reaction outcome loss': 0.1348503744530101, 'Total loss': 0.1348503744530101}
2022-12-05 21:05:19,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:19,249 INFO:     Epoch: 69
2022-12-05 21:05:20,040 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46415631947192276, 'Total loss': 0.46415631947192276} | train loss {'Reaction outcome loss': 0.1372980724779829, 'Total loss': 0.1372980724779829}
2022-12-05 21:05:20,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:20,040 INFO:     Epoch: 70
2022-12-05 21:05:20,832 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45356089452450926, 'Total loss': 0.45356089452450926} | train loss {'Reaction outcome loss': 0.13385410778855364, 'Total loss': 0.13385410778855364}
2022-12-05 21:05:20,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:20,833 INFO:     Epoch: 71
2022-12-05 21:05:21,625 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45313385941765527, 'Total loss': 0.45313385941765527} | train loss {'Reaction outcome loss': 0.13251548290117493, 'Total loss': 0.13251548290117493}
2022-12-05 21:05:21,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:21,625 INFO:     Epoch: 72
2022-12-05 21:05:22,419 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4661137629300356, 'Total loss': 0.4661137629300356} | train loss {'Reaction outcome loss': 0.1321580281496168, 'Total loss': 0.1321580281496168}
2022-12-05 21:05:22,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:22,419 INFO:     Epoch: 73
2022-12-05 21:05:23,210 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45611687207763846, 'Total loss': 0.45611687207763846} | train loss {'Reaction outcome loss': 0.13375906075816602, 'Total loss': 0.13375906075816602}
2022-12-05 21:05:23,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:23,210 INFO:     Epoch: 74
2022-12-05 21:05:23,998 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45564222979274666, 'Total loss': 0.45564222979274666} | train loss {'Reaction outcome loss': 0.13145282727125432, 'Total loss': 0.13145282727125432}
2022-12-05 21:05:23,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:23,998 INFO:     Epoch: 75
2022-12-05 21:05:24,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4535640552639961, 'Total loss': 0.4535640552639961} | train loss {'Reaction outcome loss': 0.13297295665758993, 'Total loss': 0.13297295665758993}
2022-12-05 21:05:24,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:24,789 INFO:     Epoch: 76
2022-12-05 21:05:25,578 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4551615799692544, 'Total loss': 0.4551615799692544} | train loss {'Reaction outcome loss': 0.1335790150333196, 'Total loss': 0.1335790150333196}
2022-12-05 21:05:25,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:25,579 INFO:     Epoch: 77
2022-12-05 21:05:26,373 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4520152009684931, 'Total loss': 0.4520152009684931} | train loss {'Reaction outcome loss': 0.13149275777921562, 'Total loss': 0.13149275777921562}
2022-12-05 21:05:26,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:26,373 INFO:     Epoch: 78
2022-12-05 21:05:27,169 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44821204854683444, 'Total loss': 0.44821204854683444} | train loss {'Reaction outcome loss': 0.1291069270321919, 'Total loss': 0.1291069270321919}
2022-12-05 21:05:27,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:27,169 INFO:     Epoch: 79
2022-12-05 21:05:27,965 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4595933085815473, 'Total loss': 0.4595933085815473} | train loss {'Reaction outcome loss': 0.12742958502513507, 'Total loss': 0.12742958502513507}
2022-12-05 21:05:27,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:27,965 INFO:     Epoch: 80
2022-12-05 21:05:28,753 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45600477809255774, 'Total loss': 0.45600477809255774} | train loss {'Reaction outcome loss': 0.12972331800377898, 'Total loss': 0.12972331800377898}
2022-12-05 21:05:28,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:28,753 INFO:     Epoch: 81
2022-12-05 21:05:29,545 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45450779964978044, 'Total loss': 0.45450779964978044} | train loss {'Reaction outcome loss': 0.1300557031626663, 'Total loss': 0.1300557031626663}
2022-12-05 21:05:29,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:29,545 INFO:     Epoch: 82
2022-12-05 21:05:30,339 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45564656603065407, 'Total loss': 0.45564656603065407} | train loss {'Reaction outcome loss': 0.12718864750011913, 'Total loss': 0.12718864750011913}
2022-12-05 21:05:30,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:30,339 INFO:     Epoch: 83
2022-12-05 21:05:31,133 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46244165707718243, 'Total loss': 0.46244165707718243} | train loss {'Reaction outcome loss': 0.1265584509256446, 'Total loss': 0.1265584509256446}
2022-12-05 21:05:31,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:31,133 INFO:     Epoch: 84
2022-12-05 21:05:31,923 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46122976527972653, 'Total loss': 0.46122976527972653} | train loss {'Reaction outcome loss': 0.12782495995352586, 'Total loss': 0.12782495995352586}
2022-12-05 21:05:31,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:31,924 INFO:     Epoch: 85
2022-12-05 21:05:32,712 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4603155824271115, 'Total loss': 0.4603155824271115} | train loss {'Reaction outcome loss': 0.1269397011680168, 'Total loss': 0.1269397011680168}
2022-12-05 21:05:32,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:32,712 INFO:     Epoch: 86
2022-12-05 21:05:33,502 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4523010416464372, 'Total loss': 0.4523010416464372} | train loss {'Reaction outcome loss': 0.12546973269913467, 'Total loss': 0.12546973269913467}
2022-12-05 21:05:33,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:33,502 INFO:     Epoch: 87
2022-12-05 21:05:34,291 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4652527811175043, 'Total loss': 0.4652527811175043} | train loss {'Reaction outcome loss': 0.12512250542790898, 'Total loss': 0.12512250542790898}
2022-12-05 21:05:34,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:34,291 INFO:     Epoch: 88
2022-12-05 21:05:35,079 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4727234501730312, 'Total loss': 0.4727234501730312} | train loss {'Reaction outcome loss': 0.1239809195826491, 'Total loss': 0.1239809195826491}
2022-12-05 21:05:35,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:35,079 INFO:     Epoch: 89
2022-12-05 21:05:35,867 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4535420760512352, 'Total loss': 0.4535420760512352} | train loss {'Reaction outcome loss': 0.12733961514107162, 'Total loss': 0.12733961514107162}
2022-12-05 21:05:35,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:35,868 INFO:     Epoch: 90
2022-12-05 21:05:36,660 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47600966539572587, 'Total loss': 0.47600966539572587} | train loss {'Reaction outcome loss': 0.12197339594093783, 'Total loss': 0.12197339594093783}
2022-12-05 21:05:36,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:36,660 INFO:     Epoch: 91
2022-12-05 21:05:37,449 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4598680666901849, 'Total loss': 0.4598680666901849} | train loss {'Reaction outcome loss': 0.1263902689435429, 'Total loss': 0.1263902689435429}
2022-12-05 21:05:37,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:37,449 INFO:     Epoch: 92
2022-12-05 21:05:38,236 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47154532406817784, 'Total loss': 0.47154532406817784} | train loss {'Reaction outcome loss': 0.12258240287267272, 'Total loss': 0.12258240287267272}
2022-12-05 21:05:38,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:38,236 INFO:     Epoch: 93
2022-12-05 21:05:39,029 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4617941633544185, 'Total loss': 0.4617941633544185} | train loss {'Reaction outcome loss': 0.1229340796839566, 'Total loss': 0.1229340796839566}
2022-12-05 21:05:39,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:39,029 INFO:     Epoch: 94
2022-12-05 21:05:39,817 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46808515692299063, 'Total loss': 0.46808515692299063} | train loss {'Reaction outcome loss': 0.12440201330689653, 'Total loss': 0.12440201330689653}
2022-12-05 21:05:39,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:39,817 INFO:     Epoch: 95
2022-12-05 21:05:40,609 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45537921820174565, 'Total loss': 0.45537921820174565} | train loss {'Reaction outcome loss': 0.12321662812891807, 'Total loss': 0.12321662812891807}
2022-12-05 21:05:40,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:40,609 INFO:     Epoch: 96
2022-12-05 21:05:41,401 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4625872459939935, 'Total loss': 0.4625872459939935} | train loss {'Reaction outcome loss': 0.12213495616132634, 'Total loss': 0.12213495616132634}
2022-12-05 21:05:41,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:41,401 INFO:     Epoch: 97
2022-12-05 21:05:42,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4703313088552518, 'Total loss': 0.4703313088552518} | train loss {'Reaction outcome loss': 0.12325279186329534, 'Total loss': 0.12325279186329534}
2022-12-05 21:05:42,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:42,193 INFO:     Epoch: 98
2022-12-05 21:05:42,980 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45363490181890403, 'Total loss': 0.45363490181890403} | train loss {'Reaction outcome loss': 0.12097245326355821, 'Total loss': 0.12097245326355821}
2022-12-05 21:05:42,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:42,980 INFO:     Epoch: 99
2022-12-05 21:05:43,776 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4606475572694432, 'Total loss': 0.4606475572694432} | train loss {'Reaction outcome loss': 0.1234229029148757, 'Total loss': 0.1234229029148757}
2022-12-05 21:05:43,776 INFO:     Best model found after epoch 20 of 100.
2022-12-05 21:05:43,776 INFO:   Done with stage: TRAINING
2022-12-05 21:05:43,776 INFO:   Starting stage: EVALUATION
2022-12-05 21:05:43,895 INFO:   Done with stage: EVALUATION
2022-12-05 21:05:43,895 INFO:   Leaving out SEQ value Fold_9
2022-12-05 21:05:43,908 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:05:43,908 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:05:44,542 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:05:44,542 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:05:44,612 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:05:44,612 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:05:44,612 INFO:     No hyperparam tuning for this model
2022-12-05 21:05:44,612 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:05:44,612 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:05:44,612 INFO:     None feature selector for col prot
2022-12-05 21:05:44,613 INFO:     None feature selector for col prot
2022-12-05 21:05:44,613 INFO:     None feature selector for col prot
2022-12-05 21:05:44,613 INFO:     None feature selector for col chem
2022-12-05 21:05:44,613 INFO:     None feature selector for col chem
2022-12-05 21:05:44,613 INFO:     None feature selector for col chem
2022-12-05 21:05:44,613 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:05:44,613 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:05:44,615 INFO:     Number of params in model 215821
2022-12-05 21:05:44,618 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:05:44,618 INFO:   Starting stage: TRAINING
2022-12-05 21:05:44,678 INFO:     Val loss before train {'Reaction outcome loss': 1.0555799440904097, 'Total loss': 1.0555799440904097}
2022-12-05 21:05:44,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:44,678 INFO:     Epoch: 0
2022-12-05 21:05:45,465 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6205718314105814, 'Total loss': 0.6205718314105814} | train loss {'Reaction outcome loss': 0.8051952602303758, 'Total loss': 0.8051952602303758}
2022-12-05 21:05:45,466 INFO:     Found new best model at epoch 0
2022-12-05 21:05:45,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:45,466 INFO:     Epoch: 1
2022-12-05 21:05:46,246 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5257421203634955, 'Total loss': 0.5257421203634955} | train loss {'Reaction outcome loss': 0.5329168418232275, 'Total loss': 0.5329168418232275}
2022-12-05 21:05:46,246 INFO:     Found new best model at epoch 1
2022-12-05 21:05:46,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:46,247 INFO:     Epoch: 2
2022-12-05 21:05:47,024 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49314862388101494, 'Total loss': 0.49314862388101494} | train loss {'Reaction outcome loss': 0.45756478644147214, 'Total loss': 0.45756478644147214}
2022-12-05 21:05:47,024 INFO:     Found new best model at epoch 2
2022-12-05 21:05:47,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:47,025 INFO:     Epoch: 3
2022-12-05 21:05:47,805 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4619032757526094, 'Total loss': 0.4619032757526094} | train loss {'Reaction outcome loss': 0.4175326609489869, 'Total loss': 0.4175326609489869}
2022-12-05 21:05:47,806 INFO:     Found new best model at epoch 3
2022-12-05 21:05:47,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:47,806 INFO:     Epoch: 4
2022-12-05 21:05:48,588 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4508666470646858, 'Total loss': 0.4508666470646858} | train loss {'Reaction outcome loss': 0.39086243236551477, 'Total loss': 0.39086243236551477}
2022-12-05 21:05:48,588 INFO:     Found new best model at epoch 4
2022-12-05 21:05:48,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:48,589 INFO:     Epoch: 5
2022-12-05 21:05:49,371 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45583821629936044, 'Total loss': 0.45583821629936044} | train loss {'Reaction outcome loss': 0.36746070403225567, 'Total loss': 0.36746070403225567}
2022-12-05 21:05:49,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:49,371 INFO:     Epoch: 6
2022-12-05 21:05:50,153 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45075230029496277, 'Total loss': 0.45075230029496277} | train loss {'Reaction outcome loss': 0.3497595691559266, 'Total loss': 0.3497595691559266}
2022-12-05 21:05:50,153 INFO:     Found new best model at epoch 6
2022-12-05 21:05:50,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:50,154 INFO:     Epoch: 7
2022-12-05 21:05:50,937 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4553955773060972, 'Total loss': 0.4553955773060972} | train loss {'Reaction outcome loss': 0.33112238973987346, 'Total loss': 0.33112238973987346}
2022-12-05 21:05:50,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:50,937 INFO:     Epoch: 8
2022-12-05 21:05:51,720 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42978193441575224, 'Total loss': 0.42978193441575224} | train loss {'Reaction outcome loss': 0.32193515890715074, 'Total loss': 0.32193515890715074}
2022-12-05 21:05:51,721 INFO:     Found new best model at epoch 8
2022-12-05 21:05:51,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:51,721 INFO:     Epoch: 9
2022-12-05 21:05:52,500 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4253341346471147, 'Total loss': 0.4253341346471147} | train loss {'Reaction outcome loss': 0.30518667860602844, 'Total loss': 0.30518667860602844}
2022-12-05 21:05:52,500 INFO:     Found new best model at epoch 9
2022-12-05 21:05:52,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:52,501 INFO:     Epoch: 10
2022-12-05 21:05:53,283 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4292160469022664, 'Total loss': 0.4292160469022664} | train loss {'Reaction outcome loss': 0.2923906612761167, 'Total loss': 0.2923906612761167}
2022-12-05 21:05:53,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:53,284 INFO:     Epoch: 11
2022-12-05 21:05:54,065 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43647159534421837, 'Total loss': 0.43647159534421837} | train loss {'Reaction outcome loss': 0.28149750232696535, 'Total loss': 0.28149750232696535}
2022-12-05 21:05:54,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:54,065 INFO:     Epoch: 12
2022-12-05 21:05:54,843 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4351463798772205, 'Total loss': 0.4351463798772205} | train loss {'Reaction outcome loss': 0.26863823219829674, 'Total loss': 0.26863823219829674}
2022-12-05 21:05:54,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:54,844 INFO:     Epoch: 13
2022-12-05 21:05:55,622 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42654908990318124, 'Total loss': 0.42654908990318124} | train loss {'Reaction outcome loss': 0.26502283557641265, 'Total loss': 0.26502283557641265}
2022-12-05 21:05:55,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:55,623 INFO:     Epoch: 14
2022-12-05 21:05:56,403 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44261706925251265, 'Total loss': 0.44261706925251265} | train loss {'Reaction outcome loss': 0.2533570561786087, 'Total loss': 0.2533570561786087}
2022-12-05 21:05:56,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:56,404 INFO:     Epoch: 15
2022-12-05 21:05:57,182 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4426837150346149, 'Total loss': 0.4426837150346149} | train loss {'Reaction outcome loss': 0.24595053420991314, 'Total loss': 0.24595053420991314}
2022-12-05 21:05:57,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:57,182 INFO:     Epoch: 16
2022-12-05 21:05:57,960 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4341302019628612, 'Total loss': 0.4341302019628612} | train loss {'Reaction outcome loss': 0.23706821116561794, 'Total loss': 0.23706821116561794}
2022-12-05 21:05:57,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:57,960 INFO:     Epoch: 17
2022-12-05 21:05:58,737 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44115490771152754, 'Total loss': 0.44115490771152754} | train loss {'Reaction outcome loss': 0.2316149452511145, 'Total loss': 0.2316149452511145}
2022-12-05 21:05:58,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:58,738 INFO:     Epoch: 18
2022-12-05 21:05:59,515 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.440159042111852, 'Total loss': 0.440159042111852} | train loss {'Reaction outcome loss': 0.22659693661392952, 'Total loss': 0.22659693661392952}
2022-12-05 21:05:59,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:05:59,516 INFO:     Epoch: 19
2022-12-05 21:06:00,294 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45060158825733443, 'Total loss': 0.45060158825733443} | train loss {'Reaction outcome loss': 0.21934273329620457, 'Total loss': 0.21934273329620457}
2022-12-05 21:06:00,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:00,294 INFO:     Epoch: 20
2022-12-05 21:06:01,076 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.440067129378969, 'Total loss': 0.440067129378969} | train loss {'Reaction outcome loss': 0.21180015172885389, 'Total loss': 0.21180015172885389}
2022-12-05 21:06:01,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:01,077 INFO:     Epoch: 21
2022-12-05 21:06:01,860 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4220160814848813, 'Total loss': 0.4220160814848813} | train loss {'Reaction outcome loss': 0.20991004110903155, 'Total loss': 0.20991004110903155}
2022-12-05 21:06:01,860 INFO:     Found new best model at epoch 21
2022-12-05 21:06:01,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:01,861 INFO:     Epoch: 22
2022-12-05 21:06:02,640 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44338003478266974, 'Total loss': 0.44338003478266974} | train loss {'Reaction outcome loss': 0.20477564010997207, 'Total loss': 0.20477564010997207}
2022-12-05 21:06:02,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:02,641 INFO:     Epoch: 23
2022-12-05 21:06:03,423 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42989568412303925, 'Total loss': 0.42989568412303925} | train loss {'Reaction outcome loss': 0.20051331764505226, 'Total loss': 0.20051331764505226}
2022-12-05 21:06:03,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:03,424 INFO:     Epoch: 24
2022-12-05 21:06:04,204 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42955834858796815, 'Total loss': 0.42955834858796815} | train loss {'Reaction outcome loss': 0.19480210066753992, 'Total loss': 0.19480210066753992}
2022-12-05 21:06:04,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:04,204 INFO:     Epoch: 25
2022-12-05 21:06:04,985 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44234410707246175, 'Total loss': 0.44234410707246175} | train loss {'Reaction outcome loss': 0.18943617532447893, 'Total loss': 0.18943617532447893}
2022-12-05 21:06:04,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:04,985 INFO:     Epoch: 26
2022-12-05 21:06:05,763 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4466337710618973, 'Total loss': 0.4466337710618973} | train loss {'Reaction outcome loss': 0.18684502255399615, 'Total loss': 0.18684502255399615}
2022-12-05 21:06:05,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:05,763 INFO:     Epoch: 27
2022-12-05 21:06:06,541 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43796924116428604, 'Total loss': 0.43796924116428604} | train loss {'Reaction outcome loss': 0.18463760012266586, 'Total loss': 0.18463760012266586}
2022-12-05 21:06:06,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:06,542 INFO:     Epoch: 28
2022-12-05 21:06:07,323 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.443684764883735, 'Total loss': 0.443684764883735} | train loss {'Reaction outcome loss': 0.1819297003198643, 'Total loss': 0.1819297003198643}
2022-12-05 21:06:07,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:07,323 INFO:     Epoch: 29
2022-12-05 21:06:08,106 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4602140321988951, 'Total loss': 0.4602140321988951} | train loss {'Reaction outcome loss': 0.17766183876261418, 'Total loss': 0.17766183876261418}
2022-12-05 21:06:08,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:08,106 INFO:     Epoch: 30
2022-12-05 21:06:08,889 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44911339675838297, 'Total loss': 0.44911339675838297} | train loss {'Reaction outcome loss': 0.17498983074815905, 'Total loss': 0.17498983074815905}
2022-12-05 21:06:08,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:08,889 INFO:     Epoch: 31
2022-12-05 21:06:09,668 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44427046992562036, 'Total loss': 0.44427046992562036} | train loss {'Reaction outcome loss': 0.16986704579725556, 'Total loss': 0.16986704579725556}
2022-12-05 21:06:09,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:09,668 INFO:     Epoch: 32
2022-12-05 21:06:10,449 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4644228822805665, 'Total loss': 0.4644228822805665} | train loss {'Reaction outcome loss': 0.1686974795801299, 'Total loss': 0.1686974795801299}
2022-12-05 21:06:10,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:10,450 INFO:     Epoch: 33
2022-12-05 21:06:11,231 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44163958728313446, 'Total loss': 0.44163958728313446} | train loss {'Reaction outcome loss': 0.16586683128713345, 'Total loss': 0.16586683128713345}
2022-12-05 21:06:11,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:11,231 INFO:     Epoch: 34
2022-12-05 21:06:12,014 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4222744774412025, 'Total loss': 0.4222744774412025} | train loss {'Reaction outcome loss': 0.1644902184073414, 'Total loss': 0.1644902184073414}
2022-12-05 21:06:12,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:12,014 INFO:     Epoch: 35
2022-12-05 21:06:12,798 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44576591930606146, 'Total loss': 0.44576591930606146} | train loss {'Reaction outcome loss': 0.16393166310629065, 'Total loss': 0.16393166310629065}
2022-12-05 21:06:12,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:12,799 INFO:     Epoch: 36
2022-12-05 21:06:13,580 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4488273271444169, 'Total loss': 0.4488273271444169} | train loss {'Reaction outcome loss': 0.16001964301935265, 'Total loss': 0.16001964301935265}
2022-12-05 21:06:13,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:13,580 INFO:     Epoch: 37
2022-12-05 21:06:14,358 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4440670856697993, 'Total loss': 0.4440670856697993} | train loss {'Reaction outcome loss': 0.15845329735656175, 'Total loss': 0.15845329735656175}
2022-12-05 21:06:14,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:14,359 INFO:     Epoch: 38
2022-12-05 21:06:15,139 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46523450992324134, 'Total loss': 0.46523450992324134} | train loss {'Reaction outcome loss': 0.15633648883703413, 'Total loss': 0.15633648883703413}
2022-12-05 21:06:15,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:15,140 INFO:     Epoch: 39
2022-12-05 21:06:15,921 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45607326755469496, 'Total loss': 0.45607326755469496} | train loss {'Reaction outcome loss': 0.15387523370433825, 'Total loss': 0.15387523370433825}
2022-12-05 21:06:15,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:15,922 INFO:     Epoch: 40
2022-12-05 21:06:16,702 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43739873949777, 'Total loss': 0.43739873949777} | train loss {'Reaction outcome loss': 0.1517599448485642, 'Total loss': 0.1517599448485642}
2022-12-05 21:06:16,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:16,703 INFO:     Epoch: 41
2022-12-05 21:06:17,484 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4430931583046913, 'Total loss': 0.4430931583046913} | train loss {'Reaction outcome loss': 0.14951567566972607, 'Total loss': 0.14951567566972607}
2022-12-05 21:06:17,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:17,484 INFO:     Epoch: 42
2022-12-05 21:06:18,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4449035737832839, 'Total loss': 0.4449035737832839} | train loss {'Reaction outcome loss': 0.1511109779455832, 'Total loss': 0.1511109779455832}
2022-12-05 21:06:18,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:18,269 INFO:     Epoch: 43
2022-12-05 21:06:19,047 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43694103191691364, 'Total loss': 0.43694103191691364} | train loss {'Reaction outcome loss': 0.14717557363364162, 'Total loss': 0.14717557363364162}
2022-12-05 21:06:19,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:19,048 INFO:     Epoch: 44
2022-12-05 21:06:19,829 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4584369053217498, 'Total loss': 0.4584369053217498} | train loss {'Reaction outcome loss': 0.14938389322511395, 'Total loss': 0.14938389322511395}
2022-12-05 21:06:19,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:19,829 INFO:     Epoch: 45
2022-12-05 21:06:20,608 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4507416700097648, 'Total loss': 0.4507416700097648} | train loss {'Reaction outcome loss': 0.14593232199549674, 'Total loss': 0.14593232199549674}
2022-12-05 21:06:20,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:20,609 INFO:     Epoch: 46
2022-12-05 21:06:21,389 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4566059866496785, 'Total loss': 0.4566059866496785} | train loss {'Reaction outcome loss': 0.14031758186768511, 'Total loss': 0.14031758186768511}
2022-12-05 21:06:21,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:21,390 INFO:     Epoch: 47
2022-12-05 21:06:22,169 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45699131895195355, 'Total loss': 0.45699131895195355} | train loss {'Reaction outcome loss': 0.14196631559836012, 'Total loss': 0.14196631559836012}
2022-12-05 21:06:22,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:22,169 INFO:     Epoch: 48
2022-12-05 21:06:22,948 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4555476067418402, 'Total loss': 0.4555476067418402} | train loss {'Reaction outcome loss': 0.14141971738818956, 'Total loss': 0.14141971738818956}
2022-12-05 21:06:22,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:22,948 INFO:     Epoch: 49
2022-12-05 21:06:23,727 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4445438676259734, 'Total loss': 0.4445438676259734} | train loss {'Reaction outcome loss': 0.13928460220293123, 'Total loss': 0.13928460220293123}
2022-12-05 21:06:23,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:23,727 INFO:     Epoch: 50
2022-12-05 21:06:24,508 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4522021087733182, 'Total loss': 0.4522021087733182} | train loss {'Reaction outcome loss': 0.13787814506462642, 'Total loss': 0.13787814506462642}
2022-12-05 21:06:24,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:24,509 INFO:     Epoch: 51
2022-12-05 21:06:25,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48114742067727173, 'Total loss': 0.48114742067727173} | train loss {'Reaction outcome loss': 0.13693696263113192, 'Total loss': 0.13693696263113192}
2022-12-05 21:06:25,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:25,292 INFO:     Epoch: 52
2022-12-05 21:06:26,080 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4644694606011564, 'Total loss': 0.4644694606011564} | train loss {'Reaction outcome loss': 0.13590471152292222, 'Total loss': 0.13590471152292222}
2022-12-05 21:06:26,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:26,080 INFO:     Epoch: 53
2022-12-05 21:06:26,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4530488195067102, 'Total loss': 0.4530488195067102} | train loss {'Reaction outcome loss': 0.13609420953660595, 'Total loss': 0.13609420953660595}
2022-12-05 21:06:26,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:26,866 INFO:     Epoch: 54
2022-12-05 21:06:27,648 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45077816532416776, 'Total loss': 0.45077816532416776} | train loss {'Reaction outcome loss': 0.13265152781897663, 'Total loss': 0.13265152781897663}
2022-12-05 21:06:27,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:27,649 INFO:     Epoch: 55
2022-12-05 21:06:28,429 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4614087739451365, 'Total loss': 0.4614087739451365} | train loss {'Reaction outcome loss': 0.13633734034944553, 'Total loss': 0.13633734034944553}
2022-12-05 21:06:28,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:28,429 INFO:     Epoch: 56
2022-12-05 21:06:29,207 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4520675995471803, 'Total loss': 0.4520675995471803} | train loss {'Reaction outcome loss': 0.13190536272464967, 'Total loss': 0.13190536272464967}
2022-12-05 21:06:29,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:29,207 INFO:     Epoch: 57
2022-12-05 21:06:29,989 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4524947652085261, 'Total loss': 0.4524947652085261} | train loss {'Reaction outcome loss': 0.13120525800147836, 'Total loss': 0.13120525800147836}
2022-12-05 21:06:29,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:29,990 INFO:     Epoch: 58
2022-12-05 21:06:30,775 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47236907041885634, 'Total loss': 0.47236907041885634} | train loss {'Reaction outcome loss': 0.13160710865821765, 'Total loss': 0.13160710865821765}
2022-12-05 21:06:30,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:30,775 INFO:     Epoch: 59
2022-12-05 21:06:31,558 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4658399789848111, 'Total loss': 0.4658399789848111} | train loss {'Reaction outcome loss': 0.13045324259152521, 'Total loss': 0.13045324259152521}
2022-12-05 21:06:31,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:31,558 INFO:     Epoch: 60
2022-12-05 21:06:32,343 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4586309783838012, 'Total loss': 0.4586309783838012} | train loss {'Reaction outcome loss': 0.13183836104842472, 'Total loss': 0.13183836104842472}
2022-12-05 21:06:32,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:32,343 INFO:     Epoch: 61
2022-12-05 21:06:33,127 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4590013513172215, 'Total loss': 0.4590013513172215} | train loss {'Reaction outcome loss': 0.12932724559641615, 'Total loss': 0.12932724559641615}
2022-12-05 21:06:33,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:33,127 INFO:     Epoch: 62
2022-12-05 21:06:33,907 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4365396507465365, 'Total loss': 0.4365396507465365} | train loss {'Reaction outcome loss': 0.12709495800034123, 'Total loss': 0.12709495800034123}
2022-12-05 21:06:33,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:33,908 INFO:     Epoch: 63
2022-12-05 21:06:34,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4627349159934304, 'Total loss': 0.4627349159934304} | train loss {'Reaction outcome loss': 0.1281146444988494, 'Total loss': 0.1281146444988494}
2022-12-05 21:06:34,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:34,688 INFO:     Epoch: 64
2022-12-05 21:06:35,468 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45124961334196007, 'Total loss': 0.45124961334196007} | train loss {'Reaction outcome loss': 0.12629599602398825, 'Total loss': 0.12629599602398825}
2022-12-05 21:06:35,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:35,468 INFO:     Epoch: 65
2022-12-05 21:06:36,255 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47017715325240383, 'Total loss': 0.47017715325240383} | train loss {'Reaction outcome loss': 0.1250123664128537, 'Total loss': 0.1250123664128537}
2022-12-05 21:06:36,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:36,256 INFO:     Epoch: 66
2022-12-05 21:06:37,036 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47672896832227707, 'Total loss': 0.47672896832227707} | train loss {'Reaction outcome loss': 0.12446112834601378, 'Total loss': 0.12446112834601378}
2022-12-05 21:06:37,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:37,037 INFO:     Epoch: 67
2022-12-05 21:06:37,816 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47267402640797873, 'Total loss': 0.47267402640797873} | train loss {'Reaction outcome loss': 0.12583811326826713, 'Total loss': 0.12583811326826713}
2022-12-05 21:06:37,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:37,817 INFO:     Epoch: 68
2022-12-05 21:06:38,599 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46935687078671023, 'Total loss': 0.46935687078671023} | train loss {'Reaction outcome loss': 0.12668855126795112, 'Total loss': 0.12668855126795112}
2022-12-05 21:06:38,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:38,599 INFO:     Epoch: 69
2022-12-05 21:06:39,378 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44286637393419037, 'Total loss': 0.44286637393419037} | train loss {'Reaction outcome loss': 0.12246156006063126, 'Total loss': 0.12246156006063126}
2022-12-05 21:06:39,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:39,379 INFO:     Epoch: 70
2022-12-05 21:06:40,161 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4744569750672037, 'Total loss': 0.4744569750672037} | train loss {'Reaction outcome loss': 0.12163511078272547, 'Total loss': 0.12163511078272547}
2022-12-05 21:06:40,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:40,161 INFO:     Epoch: 71
2022-12-05 21:06:40,945 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47403020106933336, 'Total loss': 0.47403020106933336} | train loss {'Reaction outcome loss': 0.12093577828182249, 'Total loss': 0.12093577828182249}
2022-12-05 21:06:40,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:40,945 INFO:     Epoch: 72
2022-12-05 21:06:41,729 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4449587678748437, 'Total loss': 0.4449587678748437} | train loss {'Reaction outcome loss': 0.12109155218896209, 'Total loss': 0.12109155218896209}
2022-12-05 21:06:41,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:41,729 INFO:     Epoch: 73
2022-12-05 21:06:42,509 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4736833419989456, 'Total loss': 0.4736833419989456} | train loss {'Reaction outcome loss': 0.11954644404503764, 'Total loss': 0.11954644404503764}
2022-12-05 21:06:42,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:42,510 INFO:     Epoch: 74
2022-12-05 21:06:43,288 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4564577904953198, 'Total loss': 0.4564577904953198} | train loss {'Reaction outcome loss': 0.1230572519405764, 'Total loss': 0.1230572519405764}
2022-12-05 21:06:43,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:43,288 INFO:     Epoch: 75
2022-12-05 21:06:44,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46990375830368564, 'Total loss': 0.46990375830368564} | train loss {'Reaction outcome loss': 0.12091805894992182, 'Total loss': 0.12091805894992182}
2022-12-05 21:06:44,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:44,071 INFO:     Epoch: 76
2022-12-05 21:06:44,855 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4684263782745058, 'Total loss': 0.4684263782745058} | train loss {'Reaction outcome loss': 0.11831771979982755, 'Total loss': 0.11831771979982755}
2022-12-05 21:06:44,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:44,856 INFO:     Epoch: 77
2022-12-05 21:06:45,638 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44900096919048915, 'Total loss': 0.44900096919048915} | train loss {'Reaction outcome loss': 0.11803544103643115, 'Total loss': 0.11803544103643115}
2022-12-05 21:06:45,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:45,638 INFO:     Epoch: 78
2022-12-05 21:06:46,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44508257101882587, 'Total loss': 0.44508257101882587} | train loss {'Reaction outcome loss': 0.11765029366527285, 'Total loss': 0.11765029366527285}
2022-12-05 21:06:46,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:46,424 INFO:     Epoch: 79
2022-12-05 21:06:47,204 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4588094750757922, 'Total loss': 0.4588094750757922} | train loss {'Reaction outcome loss': 0.11803894750013644, 'Total loss': 0.11803894750013644}
2022-12-05 21:06:47,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:47,204 INFO:     Epoch: 80
2022-12-05 21:06:47,986 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47412005778063426, 'Total loss': 0.47412005778063426} | train loss {'Reaction outcome loss': 0.11939926663299605, 'Total loss': 0.11939926663299605}
2022-12-05 21:06:47,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:47,986 INFO:     Epoch: 81
2022-12-05 21:06:48,767 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47088229757818306, 'Total loss': 0.47088229757818306} | train loss {'Reaction outcome loss': 0.11620763168119046, 'Total loss': 0.11620763168119046}
2022-12-05 21:06:48,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:48,767 INFO:     Epoch: 82
2022-12-05 21:06:49,546 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45597145266153594, 'Total loss': 0.45597145266153594} | train loss {'Reaction outcome loss': 0.11660575475923869, 'Total loss': 0.11660575475923869}
2022-12-05 21:06:49,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:49,546 INFO:     Epoch: 83
2022-12-05 21:06:50,330 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4505410695617849, 'Total loss': 0.4505410695617849} | train loss {'Reaction outcome loss': 0.1155205223975437, 'Total loss': 0.1155205223975437}
2022-12-05 21:06:50,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:50,330 INFO:     Epoch: 84
2022-12-05 21:06:51,117 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4694634669206359, 'Total loss': 0.4694634669206359} | train loss {'Reaction outcome loss': 0.11646522675849953, 'Total loss': 0.11646522675849953}
2022-12-05 21:06:51,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:51,117 INFO:     Epoch: 85
2022-12-05 21:06:51,897 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4629440585320646, 'Total loss': 0.4629440585320646} | train loss {'Reaction outcome loss': 0.11486928169520534, 'Total loss': 0.11486928169520534}
2022-12-05 21:06:51,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:51,898 INFO:     Epoch: 86
2022-12-05 21:06:52,683 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4509048827669837, 'Total loss': 0.4509048827669837} | train loss {'Reaction outcome loss': 0.11457019868325823, 'Total loss': 0.11457019868325823}
2022-12-05 21:06:52,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:52,683 INFO:     Epoch: 87
2022-12-05 21:06:53,463 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46060383489186113, 'Total loss': 0.46060383489186113} | train loss {'Reaction outcome loss': 0.11742060544463445, 'Total loss': 0.11742060544463445}
2022-12-05 21:06:53,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:53,463 INFO:     Epoch: 88
2022-12-05 21:06:54,246 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4764187481593002, 'Total loss': 0.4764187481593002} | train loss {'Reaction outcome loss': 0.11303362412074086, 'Total loss': 0.11303362412074086}
2022-12-05 21:06:54,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:54,246 INFO:     Epoch: 89
2022-12-05 21:06:55,036 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4532169032503258, 'Total loss': 0.4532169032503258} | train loss {'Reaction outcome loss': 0.11340497112357799, 'Total loss': 0.11340497112357799}
2022-12-05 21:06:55,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:55,037 INFO:     Epoch: 90
2022-12-05 21:06:55,819 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45502354560250585, 'Total loss': 0.45502354560250585} | train loss {'Reaction outcome loss': 0.1134254193123506, 'Total loss': 0.1134254193123506}
2022-12-05 21:06:55,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:55,820 INFO:     Epoch: 91
2022-12-05 21:06:56,606 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44876670160076837, 'Total loss': 0.44876670160076837} | train loss {'Reaction outcome loss': 0.11412676328184958, 'Total loss': 0.11412676328184958}
2022-12-05 21:06:56,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:56,606 INFO:     Epoch: 92
2022-12-05 21:06:57,387 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4615796946666457, 'Total loss': 0.4615796946666457} | train loss {'Reaction outcome loss': 0.11407358343427887, 'Total loss': 0.11407358343427887}
2022-12-05 21:06:57,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:57,388 INFO:     Epoch: 93
2022-12-05 21:06:58,169 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46171244233846664, 'Total loss': 0.46171244233846664} | train loss {'Reaction outcome loss': 0.11328368291486891, 'Total loss': 0.11328368291486891}
2022-12-05 21:06:58,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:58,171 INFO:     Epoch: 94
2022-12-05 21:06:58,953 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.463083282451738, 'Total loss': 0.463083282451738} | train loss {'Reaction outcome loss': 0.11319505576310414, 'Total loss': 0.11319505576310414}
2022-12-05 21:06:58,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:58,954 INFO:     Epoch: 95
2022-12-05 21:06:59,733 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46117264879020775, 'Total loss': 0.46117264879020775} | train loss {'Reaction outcome loss': 0.11175960536133878, 'Total loss': 0.11175960536133878}
2022-12-05 21:06:59,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:06:59,734 INFO:     Epoch: 96
2022-12-05 21:07:00,519 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48227368938651954, 'Total loss': 0.48227368938651954} | train loss {'Reaction outcome loss': 0.11318706437679274, 'Total loss': 0.11318706437679274}
2022-12-05 21:07:00,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:00,519 INFO:     Epoch: 97
2022-12-05 21:07:01,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47404793243516574, 'Total loss': 0.47404793243516574} | train loss {'Reaction outcome loss': 0.11177267538649695, 'Total loss': 0.11177267538649695}
2022-12-05 21:07:01,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:01,302 INFO:     Epoch: 98
2022-12-05 21:07:02,085 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45914048328995705, 'Total loss': 0.45914048328995705} | train loss {'Reaction outcome loss': 0.11008247010105726, 'Total loss': 0.11008247010105726}
2022-12-05 21:07:02,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:02,085 INFO:     Epoch: 99
2022-12-05 21:07:02,869 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44430886454541574, 'Total loss': 0.44430886454541574} | train loss {'Reaction outcome loss': 0.10975974765511191, 'Total loss': 0.10975974765511191}
2022-12-05 21:07:02,869 INFO:     Best model found after epoch 22 of 100.
2022-12-05 21:07:02,869 INFO:   Done with stage: TRAINING
2022-12-05 21:07:02,869 INFO:   Starting stage: EVALUATION
2022-12-05 21:07:02,999 INFO:   Done with stage: EVALUATION
2022-12-05 21:07:03,008 INFO:   Leaving out SEQ value Fold_0
2022-12-05 21:07:03,021 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:07:03,021 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:07:03,655 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:07:03,655 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:07:03,725 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:07:03,725 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:07:03,725 INFO:     No hyperparam tuning for this model
2022-12-05 21:07:03,725 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:07:03,725 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:07:03,726 INFO:     None feature selector for col prot
2022-12-05 21:07:03,726 INFO:     None feature selector for col prot
2022-12-05 21:07:03,726 INFO:     None feature selector for col prot
2022-12-05 21:07:03,726 INFO:     None feature selector for col chem
2022-12-05 21:07:03,727 INFO:     None feature selector for col chem
2022-12-05 21:07:03,727 INFO:     None feature selector for col chem
2022-12-05 21:07:03,727 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:07:03,727 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:07:03,728 INFO:     Number of params in model 215821
2022-12-05 21:07:03,731 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:07:03,732 INFO:   Starting stage: TRAINING
2022-12-05 21:07:03,792 INFO:     Val loss before train {'Reaction outcome loss': 0.9672571501948617, 'Total loss': 0.9672571501948617}
2022-12-05 21:07:03,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:03,792 INFO:     Epoch: 0
2022-12-05 21:07:04,579 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6032047495245934, 'Total loss': 0.6032047495245934} | train loss {'Reaction outcome loss': 0.7878845726957127, 'Total loss': 0.7878845726957127}
2022-12-05 21:07:04,580 INFO:     Found new best model at epoch 0
2022-12-05 21:07:04,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:04,581 INFO:     Epoch: 1
2022-12-05 21:07:05,363 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5307274200022221, 'Total loss': 0.5307274200022221} | train loss {'Reaction outcome loss': 0.5313355161219228, 'Total loss': 0.5313355161219228}
2022-12-05 21:07:05,363 INFO:     Found new best model at epoch 1
2022-12-05 21:07:05,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:05,364 INFO:     Epoch: 2
2022-12-05 21:07:06,148 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5032575948333199, 'Total loss': 0.5032575948333199} | train loss {'Reaction outcome loss': 0.46033586081193417, 'Total loss': 0.46033586081193417}
2022-12-05 21:07:06,148 INFO:     Found new best model at epoch 2
2022-12-05 21:07:06,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:06,149 INFO:     Epoch: 3
2022-12-05 21:07:06,927 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4846638866107572, 'Total loss': 0.4846638866107572} | train loss {'Reaction outcome loss': 0.41667818305443743, 'Total loss': 0.41667818305443743}
2022-12-05 21:07:06,927 INFO:     Found new best model at epoch 3
2022-12-05 21:07:06,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:06,928 INFO:     Epoch: 4
2022-12-05 21:07:07,711 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4933136220682751, 'Total loss': 0.4933136220682751} | train loss {'Reaction outcome loss': 0.3884687166432945, 'Total loss': 0.3884687166432945}
2022-12-05 21:07:07,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:07,711 INFO:     Epoch: 5
2022-12-05 21:07:08,492 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4699360653758049, 'Total loss': 0.4699360653758049} | train loss {'Reaction outcome loss': 0.3653972064353982, 'Total loss': 0.3653972064353982}
2022-12-05 21:07:08,492 INFO:     Found new best model at epoch 5
2022-12-05 21:07:08,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:08,493 INFO:     Epoch: 6
2022-12-05 21:07:09,279 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46151326258074155, 'Total loss': 0.46151326258074155} | train loss {'Reaction outcome loss': 0.3495030159244732, 'Total loss': 0.3495030159244732}
2022-12-05 21:07:09,279 INFO:     Found new best model at epoch 6
2022-12-05 21:07:09,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:09,280 INFO:     Epoch: 7
2022-12-05 21:07:10,061 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46497811715711246, 'Total loss': 0.46497811715711246} | train loss {'Reaction outcome loss': 0.33160703915114303, 'Total loss': 0.33160703915114303}
2022-12-05 21:07:10,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:10,061 INFO:     Epoch: 8
2022-12-05 21:07:10,841 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4417006996544925, 'Total loss': 0.4417006996544925} | train loss {'Reaction outcome loss': 0.3175046185449678, 'Total loss': 0.3175046185449678}
2022-12-05 21:07:10,841 INFO:     Found new best model at epoch 8
2022-12-05 21:07:10,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:10,842 INFO:     Epoch: 9
2022-12-05 21:07:11,620 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4519414129582318, 'Total loss': 0.4519414129582318} | train loss {'Reaction outcome loss': 0.3027236739287571, 'Total loss': 0.3027236739287571}
2022-12-05 21:07:11,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:11,620 INFO:     Epoch: 10
2022-12-05 21:07:12,401 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4482746029442007, 'Total loss': 0.4482746029442007} | train loss {'Reaction outcome loss': 0.28910112520869896, 'Total loss': 0.28910112520869896}
2022-12-05 21:07:12,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:12,402 INFO:     Epoch: 11
2022-12-05 21:07:13,186 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4613954716108062, 'Total loss': 0.4613954716108062} | train loss {'Reaction outcome loss': 0.2809151671066576, 'Total loss': 0.2809151671066576}
2022-12-05 21:07:13,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:13,186 INFO:     Epoch: 12
2022-12-05 21:07:13,965 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4445608254860748, 'Total loss': 0.4445608254860748} | train loss {'Reaction outcome loss': 0.26918979040822205, 'Total loss': 0.26918979040822205}
2022-12-05 21:07:13,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:13,965 INFO:     Epoch: 13
2022-12-05 21:07:14,744 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43732163415883074, 'Total loss': 0.43732163415883074} | train loss {'Reaction outcome loss': 0.2598118733082499, 'Total loss': 0.2598118733082499}
2022-12-05 21:07:14,744 INFO:     Found new best model at epoch 13
2022-12-05 21:07:14,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:14,745 INFO:     Epoch: 14
2022-12-05 21:07:15,525 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44272373616695404, 'Total loss': 0.44272373616695404} | train loss {'Reaction outcome loss': 0.25350124215593145, 'Total loss': 0.25350124215593145}
2022-12-05 21:07:15,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:15,525 INFO:     Epoch: 15
2022-12-05 21:07:16,308 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4439250472933054, 'Total loss': 0.4439250472933054} | train loss {'Reaction outcome loss': 0.24411206403557134, 'Total loss': 0.24411206403557134}
2022-12-05 21:07:16,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:16,308 INFO:     Epoch: 16
2022-12-05 21:07:17,087 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45376764542677184, 'Total loss': 0.45376764542677184} | train loss {'Reaction outcome loss': 0.23785786872767672, 'Total loss': 0.23785786872767672}
2022-12-05 21:07:17,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:17,087 INFO:     Epoch: 17
2022-12-05 21:07:17,868 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44791056317361916, 'Total loss': 0.44791056317361916} | train loss {'Reaction outcome loss': 0.23195540897396147, 'Total loss': 0.23195540897396147}
2022-12-05 21:07:17,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:17,868 INFO:     Epoch: 18
2022-12-05 21:07:18,650 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48882202770222316, 'Total loss': 0.48882202770222316} | train loss {'Reaction outcome loss': 0.22496461670617668, 'Total loss': 0.22496461670617668}
2022-12-05 21:07:18,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:18,651 INFO:     Epoch: 19
2022-12-05 21:07:19,431 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46462723409587686, 'Total loss': 0.46462723409587686} | train loss {'Reaction outcome loss': 0.22052867772931956, 'Total loss': 0.22052867772931956}
2022-12-05 21:07:19,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:19,431 INFO:     Epoch: 20
2022-12-05 21:07:20,211 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4782132943245498, 'Total loss': 0.4782132943245498} | train loss {'Reaction outcome loss': 0.2129385471800152, 'Total loss': 0.2129385471800152}
2022-12-05 21:07:20,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:20,211 INFO:     Epoch: 21
2022-12-05 21:07:20,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45715842666951095, 'Total loss': 0.45715842666951095} | train loss {'Reaction outcome loss': 0.2109481709648152, 'Total loss': 0.2109481709648152}
2022-12-05 21:07:20,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:20,988 INFO:     Epoch: 22
2022-12-05 21:07:21,770 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4892093143002553, 'Total loss': 0.4892093143002553} | train loss {'Reaction outcome loss': 0.20320679852548912, 'Total loss': 0.20320679852548912}
2022-12-05 21:07:21,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:21,770 INFO:     Epoch: 23
2022-12-05 21:07:22,554 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4572283713655038, 'Total loss': 0.4572283713655038} | train loss {'Reaction outcome loss': 0.20264844378950644, 'Total loss': 0.20264844378950644}
2022-12-05 21:07:22,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:22,554 INFO:     Epoch: 24
2022-12-05 21:07:23,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4701595065945929, 'Total loss': 0.4701595065945929} | train loss {'Reaction outcome loss': 0.19910526879283846, 'Total loss': 0.19910526879283846}
2022-12-05 21:07:23,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:23,333 INFO:     Epoch: 25
2022-12-05 21:07:24,112 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4789527173746716, 'Total loss': 0.4789527173746716} | train loss {'Reaction outcome loss': 0.19457517876004687, 'Total loss': 0.19457517876004687}
2022-12-05 21:07:24,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:24,112 INFO:     Epoch: 26
2022-12-05 21:07:24,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48763956485146825, 'Total loss': 0.48763956485146825} | train loss {'Reaction outcome loss': 0.18640360391261626, 'Total loss': 0.18640360391261626}
2022-12-05 21:07:24,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:24,898 INFO:     Epoch: 27
2022-12-05 21:07:25,679 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4718905971808867, 'Total loss': 0.4718905971808867} | train loss {'Reaction outcome loss': 0.18466346306460243, 'Total loss': 0.18466346306460243}
2022-12-05 21:07:25,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:25,680 INFO:     Epoch: 28
2022-12-05 21:07:26,457 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47167123888026585, 'Total loss': 0.47167123888026585} | train loss {'Reaction outcome loss': 0.18237716726654646, 'Total loss': 0.18237716726654646}
2022-12-05 21:07:26,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:26,458 INFO:     Epoch: 29
2022-12-05 21:07:27,242 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4694659215482799, 'Total loss': 0.4694659215482799} | train loss {'Reaction outcome loss': 0.18102418678451557, 'Total loss': 0.18102418678451557}
2022-12-05 21:07:27,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:27,243 INFO:     Epoch: 30
2022-12-05 21:07:28,021 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4780506898056377, 'Total loss': 0.4780506898056377} | train loss {'Reaction outcome loss': 0.17725353517702647, 'Total loss': 0.17725353517702647}
2022-12-05 21:07:28,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:28,021 INFO:     Epoch: 31
2022-12-05 21:07:28,801 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46711263384416024, 'Total loss': 0.46711263384416024} | train loss {'Reaction outcome loss': 0.17564189865881083, 'Total loss': 0.17564189865881083}
2022-12-05 21:07:28,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:28,802 INFO:     Epoch: 32
2022-12-05 21:07:29,582 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4776079441336068, 'Total loss': 0.4776079441336068} | train loss {'Reaction outcome loss': 0.17310140877962113, 'Total loss': 0.17310140877962113}
2022-12-05 21:07:29,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:29,582 INFO:     Epoch: 33
2022-12-05 21:07:30,364 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.468141010877761, 'Total loss': 0.468141010877761} | train loss {'Reaction outcome loss': 0.1712495240021725, 'Total loss': 0.1712495240021725}
2022-12-05 21:07:30,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:30,365 INFO:     Epoch: 34
2022-12-05 21:07:31,147 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.482082894241268, 'Total loss': 0.482082894241268} | train loss {'Reaction outcome loss': 0.16456453696805604, 'Total loss': 0.16456453696805604}
2022-12-05 21:07:31,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:31,147 INFO:     Epoch: 35
2022-12-05 21:07:31,926 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4815551990812475, 'Total loss': 0.4815551990812475} | train loss {'Reaction outcome loss': 0.16750043740077894, 'Total loss': 0.16750043740077894}
2022-12-05 21:07:31,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:31,926 INFO:     Epoch: 36
2022-12-05 21:07:32,711 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46271447058428417, 'Total loss': 0.46271447058428417} | train loss {'Reaction outcome loss': 0.16607177623984765, 'Total loss': 0.16607177623984765}
2022-12-05 21:07:32,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:32,712 INFO:     Epoch: 37
2022-12-05 21:07:33,492 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4943749637088992, 'Total loss': 0.4943749637088992} | train loss {'Reaction outcome loss': 0.16064342359955214, 'Total loss': 0.16064342359955214}
2022-12-05 21:07:33,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:33,492 INFO:     Epoch: 38
2022-12-05 21:07:34,270 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4843415987085212, 'Total loss': 0.4843415987085212} | train loss {'Reaction outcome loss': 0.15873209274545008, 'Total loss': 0.15873209274545008}
2022-12-05 21:07:34,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:34,270 INFO:     Epoch: 39
2022-12-05 21:07:35,052 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4855169765651226, 'Total loss': 0.4855169765651226} | train loss {'Reaction outcome loss': 0.15677893260607914, 'Total loss': 0.15677893260607914}
2022-12-05 21:07:35,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:35,052 INFO:     Epoch: 40
2022-12-05 21:07:35,833 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48839457269588654, 'Total loss': 0.48839457269588654} | train loss {'Reaction outcome loss': 0.1561881280827279, 'Total loss': 0.1561881280827279}
2022-12-05 21:07:35,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:35,833 INFO:     Epoch: 41
2022-12-05 21:07:36,616 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49167676185342396, 'Total loss': 0.49167676185342396} | train loss {'Reaction outcome loss': 0.15474075500150117, 'Total loss': 0.15474075500150117}
2022-12-05 21:07:36,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:36,616 INFO:     Epoch: 42
2022-12-05 21:07:37,396 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4751854318786751, 'Total loss': 0.4751854318786751} | train loss {'Reaction outcome loss': 0.15398619491606952, 'Total loss': 0.15398619491606952}
2022-12-05 21:07:37,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:37,396 INFO:     Epoch: 43
2022-12-05 21:07:38,181 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4884249513799494, 'Total loss': 0.4884249513799494} | train loss {'Reaction outcome loss': 0.15344918831726725, 'Total loss': 0.15344918831726725}
2022-12-05 21:07:38,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:38,181 INFO:     Epoch: 44
2022-12-05 21:07:38,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49476323141293094, 'Total loss': 0.49476323141293094} | train loss {'Reaction outcome loss': 0.15093775577082927, 'Total loss': 0.15093775577082927}
2022-12-05 21:07:38,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:38,965 INFO:     Epoch: 45
2022-12-05 21:07:39,743 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5233125295913355, 'Total loss': 0.5233125295913355} | train loss {'Reaction outcome loss': 0.1481319755163728, 'Total loss': 0.1481319755163728}
2022-12-05 21:07:39,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:39,744 INFO:     Epoch: 46
2022-12-05 21:07:40,524 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4761015241118995, 'Total loss': 0.4761015241118995} | train loss {'Reaction outcome loss': 0.15023902336097494, 'Total loss': 0.15023902336097494}
2022-12-05 21:07:40,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:40,524 INFO:     Epoch: 47
2022-12-05 21:07:41,307 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4950800162147392, 'Total loss': 0.4950800162147392} | train loss {'Reaction outcome loss': 0.1502917316723235, 'Total loss': 0.1502917316723235}
2022-12-05 21:07:41,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:41,307 INFO:     Epoch: 48
2022-12-05 21:07:42,087 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4981748272072185, 'Total loss': 0.4981748272072185} | train loss {'Reaction outcome loss': 0.14753398465714893, 'Total loss': 0.14753398465714893}
2022-12-05 21:07:42,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:42,087 INFO:     Epoch: 49
2022-12-05 21:07:42,868 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49276224930178036, 'Total loss': 0.49276224930178036} | train loss {'Reaction outcome loss': 0.1472114729790055, 'Total loss': 0.1472114729790055}
2022-12-05 21:07:42,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:42,868 INFO:     Epoch: 50
2022-12-05 21:07:43,652 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48258227719502017, 'Total loss': 0.48258227719502017} | train loss {'Reaction outcome loss': 0.1451377338900858, 'Total loss': 0.1451377338900858}
2022-12-05 21:07:43,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:43,653 INFO:     Epoch: 51
2022-12-05 21:07:44,433 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4921553802083839, 'Total loss': 0.4921553802083839} | train loss {'Reaction outcome loss': 0.14444536619192483, 'Total loss': 0.14444536619192483}
2022-12-05 21:07:44,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:44,433 INFO:     Epoch: 52
2022-12-05 21:07:45,216 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.510866792364554, 'Total loss': 0.510866792364554} | train loss {'Reaction outcome loss': 0.14324432746792326, 'Total loss': 0.14324432746792326}
2022-12-05 21:07:45,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:45,216 INFO:     Epoch: 53
2022-12-05 21:07:45,997 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4759309647435492, 'Total loss': 0.4759309647435492} | train loss {'Reaction outcome loss': 0.1399752759735803, 'Total loss': 0.1399752759735803}
2022-12-05 21:07:45,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:45,997 INFO:     Epoch: 54
2022-12-05 21:07:46,779 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5260349573059515, 'Total loss': 0.5260349573059515} | train loss {'Reaction outcome loss': 0.14006465264805118, 'Total loss': 0.14006465264805118}
2022-12-05 21:07:46,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:46,779 INFO:     Epoch: 55
2022-12-05 21:07:47,563 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4900348802859133, 'Total loss': 0.4900348802859133} | train loss {'Reaction outcome loss': 0.14063757351618641, 'Total loss': 0.14063757351618641}
2022-12-05 21:07:47,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:47,564 INFO:     Epoch: 56
2022-12-05 21:07:48,345 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5064691007137299, 'Total loss': 0.5064691007137299} | train loss {'Reaction outcome loss': 0.13918335381515173, 'Total loss': 0.13918335381515173}
2022-12-05 21:07:48,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:48,346 INFO:     Epoch: 57
2022-12-05 21:07:49,133 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.491735658862374, 'Total loss': 0.491735658862374} | train loss {'Reaction outcome loss': 0.13970057570508548, 'Total loss': 0.13970057570508548}
2022-12-05 21:07:49,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:49,134 INFO:     Epoch: 58
2022-12-05 21:07:49,915 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5054345740513368, 'Total loss': 0.5054345740513368} | train loss {'Reaction outcome loss': 0.1388835606906487, 'Total loss': 0.1388835606906487}
2022-12-05 21:07:49,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:49,915 INFO:     Epoch: 59
2022-12-05 21:07:50,695 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5285166901620951, 'Total loss': 0.5285166901620951} | train loss {'Reaction outcome loss': 0.13485128169461172, 'Total loss': 0.13485128169461172}
2022-12-05 21:07:50,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:50,695 INFO:     Epoch: 60
2022-12-05 21:07:51,477 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48745720088481903, 'Total loss': 0.48745720088481903} | train loss {'Reaction outcome loss': 0.13880235407577485, 'Total loss': 0.13880235407577485}
2022-12-05 21:07:51,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:51,478 INFO:     Epoch: 61
2022-12-05 21:07:52,261 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49591508033600723, 'Total loss': 0.49591508033600723} | train loss {'Reaction outcome loss': 0.138232274315491, 'Total loss': 0.138232274315491}
2022-12-05 21:07:52,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:52,262 INFO:     Epoch: 62
2022-12-05 21:07:53,043 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49841534244743263, 'Total loss': 0.49841534244743263} | train loss {'Reaction outcome loss': 0.13365692541915544, 'Total loss': 0.13365692541915544}
2022-12-05 21:07:53,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:53,044 INFO:     Epoch: 63
2022-12-05 21:07:53,830 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.498830548402938, 'Total loss': 0.498830548402938} | train loss {'Reaction outcome loss': 0.13524916711434418, 'Total loss': 0.13524916711434418}
2022-12-05 21:07:53,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:53,830 INFO:     Epoch: 64
2022-12-05 21:07:54,618 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5051630288362503, 'Total loss': 0.5051630288362503} | train loss {'Reaction outcome loss': 0.1326074009723201, 'Total loss': 0.1326074009723201}
2022-12-05 21:07:54,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:54,619 INFO:     Epoch: 65
2022-12-05 21:07:55,400 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4894015831364827, 'Total loss': 0.4894015831364827} | train loss {'Reaction outcome loss': 0.13459198046095516, 'Total loss': 0.13459198046095516}
2022-12-05 21:07:55,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:55,401 INFO:     Epoch: 66
2022-12-05 21:07:56,184 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48092484461482277, 'Total loss': 0.48092484461482277} | train loss {'Reaction outcome loss': 0.13505532060350692, 'Total loss': 0.13505532060350692}
2022-12-05 21:07:56,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:56,184 INFO:     Epoch: 67
2022-12-05 21:07:56,963 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.505651072006334, 'Total loss': 0.505651072006334} | train loss {'Reaction outcome loss': 0.13361260843064104, 'Total loss': 0.13361260843064104}
2022-12-05 21:07:56,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:56,964 INFO:     Epoch: 68
2022-12-05 21:07:57,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49213968454436824, 'Total loss': 0.49213968454436824} | train loss {'Reaction outcome loss': 0.13234488250193546, 'Total loss': 0.13234488250193546}
2022-12-05 21:07:57,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:57,749 INFO:     Epoch: 69
2022-12-05 21:07:58,532 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5050652755255048, 'Total loss': 0.5050652755255048} | train loss {'Reaction outcome loss': 0.13182771489480322, 'Total loss': 0.13182771489480322}
2022-12-05 21:07:58,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:58,532 INFO:     Epoch: 70
2022-12-05 21:07:59,315 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5134524432095614, 'Total loss': 0.5134524432095614} | train loss {'Reaction outcome loss': 0.13081711149793498, 'Total loss': 0.13081711149793498}
2022-12-05 21:07:59,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:07:59,315 INFO:     Epoch: 71
2022-12-05 21:08:00,100 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5142858096144416, 'Total loss': 0.5142858096144416} | train loss {'Reaction outcome loss': 0.13019845151931655, 'Total loss': 0.13019845151931655}
2022-12-05 21:08:00,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:00,100 INFO:     Epoch: 72
2022-12-05 21:08:00,881 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.512537654150616, 'Total loss': 0.512537654150616} | train loss {'Reaction outcome loss': 0.13053181159253024, 'Total loss': 0.13053181159253024}
2022-12-05 21:08:00,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:00,883 INFO:     Epoch: 73
2022-12-05 21:08:01,666 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5103592601689425, 'Total loss': 0.5103592601689425} | train loss {'Reaction outcome loss': 0.127530278466946, 'Total loss': 0.127530278466946}
2022-12-05 21:08:01,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:01,666 INFO:     Epoch: 74
2022-12-05 21:08:02,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5246755843135443, 'Total loss': 0.5246755843135443} | train loss {'Reaction outcome loss': 0.1287876420673363, 'Total loss': 0.1287876420673363}
2022-12-05 21:08:02,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:02,446 INFO:     Epoch: 75
2022-12-05 21:08:03,228 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49854616905477916, 'Total loss': 0.49854616905477916} | train loss {'Reaction outcome loss': 0.1311184882053307, 'Total loss': 0.1311184882053307}
2022-12-05 21:08:03,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:03,228 INFO:     Epoch: 76
2022-12-05 21:08:04,008 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4961692557077516, 'Total loss': 0.4961692557077516} | train loss {'Reaction outcome loss': 0.12625761861931914, 'Total loss': 0.12625761861931914}
2022-12-05 21:08:04,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:04,008 INFO:     Epoch: 77
2022-12-05 21:08:04,787 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5095559619367123, 'Total loss': 0.5095559619367123} | train loss {'Reaction outcome loss': 0.12821549986089978, 'Total loss': 0.12821549986089978}
2022-12-05 21:08:04,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:04,787 INFO:     Epoch: 78
2022-12-05 21:08:05,567 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5111973024904728, 'Total loss': 0.5111973024904728} | train loss {'Reaction outcome loss': 0.12766026814221118, 'Total loss': 0.12766026814221118}
2022-12-05 21:08:05,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:05,567 INFO:     Epoch: 79
2022-12-05 21:08:06,352 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48962846940213983, 'Total loss': 0.48962846940213983} | train loss {'Reaction outcome loss': 0.1263763190912349, 'Total loss': 0.1263763190912349}
2022-12-05 21:08:06,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:06,352 INFO:     Epoch: 80
2022-12-05 21:08:07,132 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49764619090340356, 'Total loss': 0.49764619090340356} | train loss {'Reaction outcome loss': 0.1270522071162657, 'Total loss': 0.1270522071162657}
2022-12-05 21:08:07,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:07,133 INFO:     Epoch: 81
2022-12-05 21:08:07,912 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5034966103055261, 'Total loss': 0.5034966103055261} | train loss {'Reaction outcome loss': 0.12372841622908505, 'Total loss': 0.12372841622908505}
2022-12-05 21:08:07,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:07,912 INFO:     Epoch: 82
2022-12-05 21:08:08,692 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5092232877557928, 'Total loss': 0.5092232877557928} | train loss {'Reaction outcome loss': 0.12537496118445177, 'Total loss': 0.12537496118445177}
2022-12-05 21:08:08,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:08,692 INFO:     Epoch: 83
2022-12-05 21:08:09,473 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5131021172485568, 'Total loss': 0.5131021172485568} | train loss {'Reaction outcome loss': 0.12509717097391887, 'Total loss': 0.12509717097391887}
2022-12-05 21:08:09,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:09,473 INFO:     Epoch: 84
2022-12-05 21:08:10,251 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48087751221927727, 'Total loss': 0.48087751221927727} | train loss {'Reaction outcome loss': 0.12879401017360542, 'Total loss': 0.12879401017360542}
2022-12-05 21:08:10,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:10,251 INFO:     Epoch: 85
2022-12-05 21:08:11,029 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4965624238618396, 'Total loss': 0.4965624238618396} | train loss {'Reaction outcome loss': 0.12425007799602285, 'Total loss': 0.12425007799602285}
2022-12-05 21:08:11,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:11,029 INFO:     Epoch: 86
2022-12-05 21:08:11,808 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4836042599583214, 'Total loss': 0.4836042599583214} | train loss {'Reaction outcome loss': 0.12383650413581303, 'Total loss': 0.12383650413581303}
2022-12-05 21:08:11,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:11,808 INFO:     Epoch: 87
2022-12-05 21:08:12,589 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48972576043822547, 'Total loss': 0.48972576043822547} | train loss {'Reaction outcome loss': 0.12378980012952673, 'Total loss': 0.12378980012952673}
2022-12-05 21:08:12,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:12,589 INFO:     Epoch: 88
2022-12-05 21:08:13,370 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5031640455126762, 'Total loss': 0.5031640455126762} | train loss {'Reaction outcome loss': 0.12424057224119196, 'Total loss': 0.12424057224119196}
2022-12-05 21:08:13,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:13,370 INFO:     Epoch: 89
2022-12-05 21:08:14,151 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5033284088766034, 'Total loss': 0.5033284088766034} | train loss {'Reaction outcome loss': 0.12217171096756142, 'Total loss': 0.12217171096756142}
2022-12-05 21:08:14,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:14,152 INFO:     Epoch: 90
2022-12-05 21:08:14,934 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4942243092439391, 'Total loss': 0.4942243092439391} | train loss {'Reaction outcome loss': 0.12425052683648406, 'Total loss': 0.12425052683648406}
2022-12-05 21:08:14,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:14,934 INFO:     Epoch: 91
2022-12-05 21:08:15,718 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.484296070443551, 'Total loss': 0.484296070443551} | train loss {'Reaction outcome loss': 0.12283965828923546, 'Total loss': 0.12283965828923546}
2022-12-05 21:08:15,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:15,718 INFO:     Epoch: 92
2022-12-05 21:08:16,501 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5151422362435948, 'Total loss': 0.5151422362435948} | train loss {'Reaction outcome loss': 0.12054298242782148, 'Total loss': 0.12054298242782148}
2022-12-05 21:08:16,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:16,502 INFO:     Epoch: 93
2022-12-05 21:08:17,284 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49484427832067013, 'Total loss': 0.49484427832067013} | train loss {'Reaction outcome loss': 0.12286838343633073, 'Total loss': 0.12286838343633073}
2022-12-05 21:08:17,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:17,284 INFO:     Epoch: 94
2022-12-05 21:08:18,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4928502917967059, 'Total loss': 0.4928502917967059} | train loss {'Reaction outcome loss': 0.1204884397322122, 'Total loss': 0.1204884397322122}
2022-12-05 21:08:18,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:18,071 INFO:     Epoch: 95
2022-12-05 21:08:18,856 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49654035744341934, 'Total loss': 0.49654035744341934} | train loss {'Reaction outcome loss': 0.12264551578887871, 'Total loss': 0.12264551578887871}
2022-12-05 21:08:18,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:18,856 INFO:     Epoch: 96
2022-12-05 21:08:19,634 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4915665659778328, 'Total loss': 0.4915665659778328} | train loss {'Reaction outcome loss': 0.120485752885591, 'Total loss': 0.120485752885591}
2022-12-05 21:08:19,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:19,635 INFO:     Epoch: 97
2022-12-05 21:08:20,417 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5017650156197223, 'Total loss': 0.5017650156197223} | train loss {'Reaction outcome loss': 0.12022279095740951, 'Total loss': 0.12022279095740951}
2022-12-05 21:08:20,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:20,417 INFO:     Epoch: 98
2022-12-05 21:08:21,201 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4913762669840997, 'Total loss': 0.4913762669840997} | train loss {'Reaction outcome loss': 0.11921889772448613, 'Total loss': 0.11921889772448613}
2022-12-05 21:08:21,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:21,201 INFO:     Epoch: 99
2022-12-05 21:08:21,982 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5128743475811048, 'Total loss': 0.5128743475811048} | train loss {'Reaction outcome loss': 0.12027711815827963, 'Total loss': 0.12027711815827963}
2022-12-05 21:08:21,983 INFO:     Best model found after epoch 14 of 100.
2022-12-05 21:08:21,983 INFO:   Done with stage: TRAINING
2022-12-05 21:08:21,983 INFO:   Starting stage: EVALUATION
2022-12-05 21:08:22,114 INFO:   Done with stage: EVALUATION
2022-12-05 21:08:22,114 INFO:   Leaving out SEQ value Fold_1
2022-12-05 21:08:22,126 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:08:22,127 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:08:22,766 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:08:22,766 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:08:22,835 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:08:22,835 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:08:22,835 INFO:     No hyperparam tuning for this model
2022-12-05 21:08:22,835 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:08:22,835 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:08:22,836 INFO:     None feature selector for col prot
2022-12-05 21:08:22,836 INFO:     None feature selector for col prot
2022-12-05 21:08:22,836 INFO:     None feature selector for col prot
2022-12-05 21:08:22,837 INFO:     None feature selector for col chem
2022-12-05 21:08:22,837 INFO:     None feature selector for col chem
2022-12-05 21:08:22,837 INFO:     None feature selector for col chem
2022-12-05 21:08:22,837 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:08:22,837 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:08:22,839 INFO:     Number of params in model 215821
2022-12-05 21:08:22,842 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:08:22,842 INFO:   Starting stage: TRAINING
2022-12-05 21:08:22,902 INFO:     Val loss before train {'Reaction outcome loss': 1.0075080381198362, 'Total loss': 1.0075080381198362}
2022-12-05 21:08:22,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:22,902 INFO:     Epoch: 0
2022-12-05 21:08:23,693 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6340466283939101, 'Total loss': 0.6340466283939101} | train loss {'Reaction outcome loss': 0.8224649073985907, 'Total loss': 0.8224649073985907}
2022-12-05 21:08:23,693 INFO:     Found new best model at epoch 0
2022-12-05 21:08:23,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:23,694 INFO:     Epoch: 1
2022-12-05 21:08:24,479 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5147822292690928, 'Total loss': 0.5147822292690928} | train loss {'Reaction outcome loss': 0.55929298192142, 'Total loss': 0.55929298192142}
2022-12-05 21:08:24,479 INFO:     Found new best model at epoch 1
2022-12-05 21:08:24,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:24,480 INFO:     Epoch: 2
2022-12-05 21:08:25,264 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47617257047783246, 'Total loss': 0.47617257047783246} | train loss {'Reaction outcome loss': 0.47870161369261954, 'Total loss': 0.47870161369261954}
2022-12-05 21:08:25,264 INFO:     Found new best model at epoch 2
2022-12-05 21:08:25,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:25,265 INFO:     Epoch: 3
2022-12-05 21:08:26,055 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46352763948115433, 'Total loss': 0.46352763948115433} | train loss {'Reaction outcome loss': 0.4358109385227626, 'Total loss': 0.4358109385227626}
2022-12-05 21:08:26,055 INFO:     Found new best model at epoch 3
2022-12-05 21:08:26,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:26,056 INFO:     Epoch: 4
2022-12-05 21:08:26,840 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4435380453413183, 'Total loss': 0.4435380453413183} | train loss {'Reaction outcome loss': 0.4037058110903149, 'Total loss': 0.4037058110903149}
2022-12-05 21:08:26,840 INFO:     Found new best model at epoch 4
2022-12-05 21:08:26,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:26,841 INFO:     Epoch: 5
2022-12-05 21:08:27,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4386803219941529, 'Total loss': 0.4386803219941529} | train loss {'Reaction outcome loss': 0.3795171706571511, 'Total loss': 0.3795171706571511}
2022-12-05 21:08:27,627 INFO:     Found new best model at epoch 5
2022-12-05 21:08:27,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:27,628 INFO:     Epoch: 6
2022-12-05 21:08:28,414 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42899580570784485, 'Total loss': 0.42899580570784485} | train loss {'Reaction outcome loss': 0.35875503387045765, 'Total loss': 0.35875503387045765}
2022-12-05 21:08:28,414 INFO:     Found new best model at epoch 6
2022-12-05 21:08:28,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:28,415 INFO:     Epoch: 7
2022-12-05 21:08:29,199 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44424850764599716, 'Total loss': 0.44424850764599716} | train loss {'Reaction outcome loss': 0.3432383431114166, 'Total loss': 0.3432383431114166}
2022-12-05 21:08:29,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:29,199 INFO:     Epoch: 8
2022-12-05 21:08:29,987 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44313997301188385, 'Total loss': 0.44313997301188385} | train loss {'Reaction outcome loss': 0.3296582985382814, 'Total loss': 0.3296582985382814}
2022-12-05 21:08:29,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:29,988 INFO:     Epoch: 9
2022-12-05 21:08:30,776 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42564718289808795, 'Total loss': 0.42564718289808795} | train loss {'Reaction outcome loss': 0.31593401790389164, 'Total loss': 0.31593401790389164}
2022-12-05 21:08:30,777 INFO:     Found new best model at epoch 9
2022-12-05 21:08:30,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:30,777 INFO:     Epoch: 10
2022-12-05 21:08:31,562 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4151603579521179, 'Total loss': 0.4151603579521179} | train loss {'Reaction outcome loss': 0.30087946988793035, 'Total loss': 0.30087946988793035}
2022-12-05 21:08:31,562 INFO:     Found new best model at epoch 10
2022-12-05 21:08:31,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:31,563 INFO:     Epoch: 11
2022-12-05 21:08:32,354 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4348333069885319, 'Total loss': 0.4348333069885319} | train loss {'Reaction outcome loss': 0.2862869108827249, 'Total loss': 0.2862869108827249}
2022-12-05 21:08:32,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:32,355 INFO:     Epoch: 12
2022-12-05 21:08:33,147 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41640550744804466, 'Total loss': 0.41640550744804466} | train loss {'Reaction outcome loss': 0.27575580348913004, 'Total loss': 0.27575580348913004}
2022-12-05 21:08:33,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:33,147 INFO:     Epoch: 13
2022-12-05 21:08:33,935 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4120547913692214, 'Total loss': 0.4120547913692214} | train loss {'Reaction outcome loss': 0.26841591781208873, 'Total loss': 0.26841591781208873}
2022-12-05 21:08:33,935 INFO:     Found new best model at epoch 13
2022-12-05 21:08:33,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:33,936 INFO:     Epoch: 14
2022-12-05 21:08:34,725 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43184130875901744, 'Total loss': 0.43184130875901744} | train loss {'Reaction outcome loss': 0.2615221558734473, 'Total loss': 0.2615221558734473}
2022-12-05 21:08:34,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:34,725 INFO:     Epoch: 15
2022-12-05 21:08:35,516 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43431926874274557, 'Total loss': 0.43431926874274557} | train loss {'Reaction outcome loss': 0.2543989174399781, 'Total loss': 0.2543989174399781}
2022-12-05 21:08:35,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:35,516 INFO:     Epoch: 16
2022-12-05 21:08:36,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4241389616985213, 'Total loss': 0.4241389616985213} | train loss {'Reaction outcome loss': 0.2415890321135521, 'Total loss': 0.2415890321135521}
2022-12-05 21:08:36,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:36,306 INFO:     Epoch: 17
2022-12-05 21:08:37,093 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42058880999684334, 'Total loss': 0.42058880999684334} | train loss {'Reaction outcome loss': 0.2340317277260396, 'Total loss': 0.2340317277260396}
2022-12-05 21:08:37,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:37,093 INFO:     Epoch: 18
2022-12-05 21:08:37,879 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4148295125500722, 'Total loss': 0.4148295125500722} | train loss {'Reaction outcome loss': 0.2334796510983696, 'Total loss': 0.2334796510983696}
2022-12-05 21:08:37,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:37,879 INFO:     Epoch: 19
2022-12-05 21:08:38,667 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41040762615474785, 'Total loss': 0.41040762615474785} | train loss {'Reaction outcome loss': 0.23129717866901445, 'Total loss': 0.23129717866901445}
2022-12-05 21:08:38,668 INFO:     Found new best model at epoch 19
2022-12-05 21:08:38,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:38,669 INFO:     Epoch: 20
2022-12-05 21:08:39,457 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4362839433279904, 'Total loss': 0.4362839433279904} | train loss {'Reaction outcome loss': 0.2160147498512588, 'Total loss': 0.2160147498512588}
2022-12-05 21:08:39,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:39,458 INFO:     Epoch: 21
2022-12-05 21:08:40,243 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4481345211917704, 'Total loss': 0.4481345211917704} | train loss {'Reaction outcome loss': 0.21097661233563655, 'Total loss': 0.21097661233563655}
2022-12-05 21:08:40,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:40,243 INFO:     Epoch: 22
2022-12-05 21:08:41,027 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4322906072166833, 'Total loss': 0.4322906072166833} | train loss {'Reaction outcome loss': 0.20522674928732246, 'Total loss': 0.20522674928732246}
2022-12-05 21:08:41,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:41,027 INFO:     Epoch: 23
2022-12-05 21:08:41,815 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42983895066109573, 'Total loss': 0.42983895066109573} | train loss {'Reaction outcome loss': 0.20227318641028333, 'Total loss': 0.20227318641028333}
2022-12-05 21:08:41,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:41,815 INFO:     Epoch: 24
2022-12-05 21:08:42,600 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42454157769680023, 'Total loss': 0.42454157769680023} | train loss {'Reaction outcome loss': 0.19624819126176207, 'Total loss': 0.19624819126176207}
2022-12-05 21:08:42,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:42,600 INFO:     Epoch: 25
2022-12-05 21:08:43,383 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4458640126342123, 'Total loss': 0.4458640126342123} | train loss {'Reaction outcome loss': 0.19643066140261256, 'Total loss': 0.19643066140261256}
2022-12-05 21:08:43,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:43,384 INFO:     Epoch: 26
2022-12-05 21:08:44,169 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4309573115950281, 'Total loss': 0.4309573115950281} | train loss {'Reaction outcome loss': 0.19074106609320593, 'Total loss': 0.19074106609320593}
2022-12-05 21:08:44,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:44,170 INFO:     Epoch: 27
2022-12-05 21:08:44,955 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.415995717048645, 'Total loss': 0.415995717048645} | train loss {'Reaction outcome loss': 0.1855119691203963, 'Total loss': 0.1855119691203963}
2022-12-05 21:08:44,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:44,955 INFO:     Epoch: 28
2022-12-05 21:08:45,743 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4417649270458655, 'Total loss': 0.4417649270458655} | train loss {'Reaction outcome loss': 0.18284871996293667, 'Total loss': 0.18284871996293667}
2022-12-05 21:08:45,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:45,744 INFO:     Epoch: 29
2022-12-05 21:08:46,531 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4616613316942345, 'Total loss': 0.4616613316942345} | train loss {'Reaction outcome loss': 0.18238748324967105, 'Total loss': 0.18238748324967105}
2022-12-05 21:08:46,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:46,531 INFO:     Epoch: 30
2022-12-05 21:08:47,316 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4273884398016063, 'Total loss': 0.4273884398016063} | train loss {'Reaction outcome loss': 0.18357906271873214, 'Total loss': 0.18357906271873214}
2022-12-05 21:08:47,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:47,316 INFO:     Epoch: 31
2022-12-05 21:08:48,106 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4258089495653456, 'Total loss': 0.4258089495653456} | train loss {'Reaction outcome loss': 0.17341198916980613, 'Total loss': 0.17341198916980613}
2022-12-05 21:08:48,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:48,106 INFO:     Epoch: 32
2022-12-05 21:08:48,898 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4336920553310351, 'Total loss': 0.4336920553310351} | train loss {'Reaction outcome loss': 0.17449040636269428, 'Total loss': 0.17449040636269428}
2022-12-05 21:08:48,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:48,898 INFO:     Epoch: 33
2022-12-05 21:08:49,695 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.423418805595826, 'Total loss': 0.423418805595826} | train loss {'Reaction outcome loss': 0.16866168399390422, 'Total loss': 0.16866168399390422}
2022-12-05 21:08:49,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:49,695 INFO:     Epoch: 34
2022-12-05 21:08:50,491 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4319412423805757, 'Total loss': 0.4319412423805757} | train loss {'Reaction outcome loss': 0.16704266207662188, 'Total loss': 0.16704266207662188}
2022-12-05 21:08:50,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:50,491 INFO:     Epoch: 35
2022-12-05 21:08:51,285 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42424972727894783, 'Total loss': 0.42424972727894783} | train loss {'Reaction outcome loss': 0.16609207482684238, 'Total loss': 0.16609207482684238}
2022-12-05 21:08:51,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:51,285 INFO:     Epoch: 36
2022-12-05 21:08:52,078 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4432498331774365, 'Total loss': 0.4432498331774365} | train loss {'Reaction outcome loss': 0.1683845526655676, 'Total loss': 0.1683845526655676}
2022-12-05 21:08:52,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:52,079 INFO:     Epoch: 37
2022-12-05 21:08:52,872 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43019127744165336, 'Total loss': 0.43019127744165336} | train loss {'Reaction outcome loss': 0.16284056556852242, 'Total loss': 0.16284056556852242}
2022-12-05 21:08:52,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:52,873 INFO:     Epoch: 38
2022-12-05 21:08:53,662 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44519958399574866, 'Total loss': 0.44519958399574866} | train loss {'Reaction outcome loss': 0.16716789875013627, 'Total loss': 0.16716789875013627}
2022-12-05 21:08:53,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:53,662 INFO:     Epoch: 39
2022-12-05 21:08:54,450 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44750332087278366, 'Total loss': 0.44750332087278366} | train loss {'Reaction outcome loss': 0.15914895197353984, 'Total loss': 0.15914895197353984}
2022-12-05 21:08:54,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:54,450 INFO:     Epoch: 40
2022-12-05 21:08:55,238 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.438901043751023, 'Total loss': 0.438901043751023} | train loss {'Reaction outcome loss': 0.15762767578034023, 'Total loss': 0.15762767578034023}
2022-12-05 21:08:55,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:55,238 INFO:     Epoch: 41
2022-12-05 21:08:56,028 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43623593415726314, 'Total loss': 0.43623593415726314} | train loss {'Reaction outcome loss': 0.15610870514687167, 'Total loss': 0.15610870514687167}
2022-12-05 21:08:56,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:56,028 INFO:     Epoch: 42
2022-12-05 21:08:56,821 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4438482651656324, 'Total loss': 0.4438482651656324} | train loss {'Reaction outcome loss': 0.14817526644691523, 'Total loss': 0.14817526644691523}
2022-12-05 21:08:56,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:56,821 INFO:     Epoch: 43
2022-12-05 21:08:57,610 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4487112940035083, 'Total loss': 0.4487112940035083} | train loss {'Reaction outcome loss': 0.15112262556088055, 'Total loss': 0.15112262556088055}
2022-12-05 21:08:57,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:57,610 INFO:     Epoch: 44
2022-12-05 21:08:58,397 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4683758287944577, 'Total loss': 0.4683758287944577} | train loss {'Reaction outcome loss': 0.1493257944611644, 'Total loss': 0.1493257944611644}
2022-12-05 21:08:58,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:58,397 INFO:     Epoch: 45
2022-12-05 21:08:59,188 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4427063451571898, 'Total loss': 0.4427063451571898} | train loss {'Reaction outcome loss': 0.14834439394399826, 'Total loss': 0.14834439394399826}
2022-12-05 21:08:59,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:59,188 INFO:     Epoch: 46
2022-12-05 21:08:59,984 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4453939502550797, 'Total loss': 0.4453939502550797} | train loss {'Reaction outcome loss': 0.14783860583552103, 'Total loss': 0.14783860583552103}
2022-12-05 21:08:59,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:08:59,984 INFO:     Epoch: 47
2022-12-05 21:09:00,771 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4481898349794475, 'Total loss': 0.4481898349794475} | train loss {'Reaction outcome loss': 0.14423419486897193, 'Total loss': 0.14423419486897193}
2022-12-05 21:09:00,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:00,772 INFO:     Epoch: 48
2022-12-05 21:09:01,564 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4418709288266572, 'Total loss': 0.4418709288266572} | train loss {'Reaction outcome loss': 0.14710971523785157, 'Total loss': 0.14710971523785157}
2022-12-05 21:09:01,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:01,564 INFO:     Epoch: 49
2022-12-05 21:09:02,363 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4578320763327859, 'Total loss': 0.4578320763327859} | train loss {'Reaction outcome loss': 0.146976543699772, 'Total loss': 0.146976543699772}
2022-12-05 21:09:02,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:02,363 INFO:     Epoch: 50
2022-12-05 21:09:03,152 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.453096752139655, 'Total loss': 0.453096752139655} | train loss {'Reaction outcome loss': 0.14091825857758522, 'Total loss': 0.14091825857758522}
2022-12-05 21:09:03,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:03,153 INFO:     Epoch: 51
2022-12-05 21:09:03,941 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48393839733167127, 'Total loss': 0.48393839733167127} | train loss {'Reaction outcome loss': 0.14797516606808434, 'Total loss': 0.14797516606808434}
2022-12-05 21:09:03,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:03,942 INFO:     Epoch: 52
2022-12-05 21:09:04,735 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4537327387793498, 'Total loss': 0.4537327387793498} | train loss {'Reaction outcome loss': 0.1384215978424815, 'Total loss': 0.1384215978424815}
2022-12-05 21:09:04,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:04,735 INFO:     Epoch: 53
2022-12-05 21:09:05,527 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42817324200983753, 'Total loss': 0.42817324200983753} | train loss {'Reaction outcome loss': 0.14147020363614626, 'Total loss': 0.14147020363614626}
2022-12-05 21:09:05,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:05,527 INFO:     Epoch: 54
2022-12-05 21:09:06,319 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4465030570599166, 'Total loss': 0.4465030570599166} | train loss {'Reaction outcome loss': 0.1403370749936835, 'Total loss': 0.1403370749936835}
2022-12-05 21:09:06,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:06,319 INFO:     Epoch: 55
2022-12-05 21:09:07,116 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4567409240725366, 'Total loss': 0.4567409240725366} | train loss {'Reaction outcome loss': 0.136123307516821, 'Total loss': 0.136123307516821}
2022-12-05 21:09:07,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:07,116 INFO:     Epoch: 56
2022-12-05 21:09:07,913 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4580455849116499, 'Total loss': 0.4580455849116499} | train loss {'Reaction outcome loss': 0.13712049424572875, 'Total loss': 0.13712049424572875}
2022-12-05 21:09:07,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:07,913 INFO:     Epoch: 57
2022-12-05 21:09:08,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.468075114894997, 'Total loss': 0.468075114894997} | train loss {'Reaction outcome loss': 0.14083867964263147, 'Total loss': 0.14083867964263147}
2022-12-05 21:09:08,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:08,710 INFO:     Epoch: 58
2022-12-05 21:09:09,507 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47138857435096393, 'Total loss': 0.47138857435096393} | train loss {'Reaction outcome loss': 0.1345867629724777, 'Total loss': 0.1345867629724777}
2022-12-05 21:09:09,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:09,507 INFO:     Epoch: 59
2022-12-05 21:09:10,310 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.447564533488317, 'Total loss': 0.447564533488317} | train loss {'Reaction outcome loss': 0.13722701112999908, 'Total loss': 0.13722701112999908}
2022-12-05 21:09:10,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:10,311 INFO:     Epoch: 60
2022-12-05 21:09:11,119 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46299248933792114, 'Total loss': 0.46299248933792114} | train loss {'Reaction outcome loss': 0.13070117098350936, 'Total loss': 0.13070117098350936}
2022-12-05 21:09:11,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:11,120 INFO:     Epoch: 61
2022-12-05 21:09:11,926 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45015743442557077, 'Total loss': 0.45015743442557077} | train loss {'Reaction outcome loss': 0.12998478750647366, 'Total loss': 0.12998478750647366}
2022-12-05 21:09:11,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:11,926 INFO:     Epoch: 62
2022-12-05 21:09:12,725 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4746016240255399, 'Total loss': 0.4746016240255399} | train loss {'Reaction outcome loss': 0.1325252902908967, 'Total loss': 0.1325252902908967}
2022-12-05 21:09:12,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:12,726 INFO:     Epoch: 63
2022-12-05 21:09:13,528 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4462881823155013, 'Total loss': 0.4462881823155013} | train loss {'Reaction outcome loss': 0.13416465490996113, 'Total loss': 0.13416465490996113}
2022-12-05 21:09:13,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:13,528 INFO:     Epoch: 64
2022-12-05 21:09:14,324 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4669620157642798, 'Total loss': 0.4669620157642798} | train loss {'Reaction outcome loss': 0.1304293920687562, 'Total loss': 0.1304293920687562}
2022-12-05 21:09:14,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:14,324 INFO:     Epoch: 65
2022-12-05 21:09:15,119 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46471757407892833, 'Total loss': 0.46471757407892833} | train loss {'Reaction outcome loss': 0.12889793827782878, 'Total loss': 0.12889793827782878}
2022-12-05 21:09:15,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:15,120 INFO:     Epoch: 66
2022-12-05 21:09:15,916 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4588968371125785, 'Total loss': 0.4588968371125785} | train loss {'Reaction outcome loss': 0.13380583833435528, 'Total loss': 0.13380583833435528}
2022-12-05 21:09:15,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:15,916 INFO:     Epoch: 67
2022-12-05 21:09:16,715 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43993514725430444, 'Total loss': 0.43993514725430444} | train loss {'Reaction outcome loss': 0.13219451634844892, 'Total loss': 0.13219451634844892}
2022-12-05 21:09:16,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:16,715 INFO:     Epoch: 68
2022-12-05 21:09:17,511 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4651765212077986, 'Total loss': 0.4651765212077986} | train loss {'Reaction outcome loss': 0.12721384763868473, 'Total loss': 0.12721384763868473}
2022-12-05 21:09:17,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:17,511 INFO:     Epoch: 69
2022-12-05 21:09:18,308 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4603925804522904, 'Total loss': 0.4603925804522904} | train loss {'Reaction outcome loss': 0.125814750839613, 'Total loss': 0.125814750839613}
2022-12-05 21:09:18,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:18,309 INFO:     Epoch: 70
2022-12-05 21:09:19,106 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4513862525874918, 'Total loss': 0.4513862525874918} | train loss {'Reaction outcome loss': 0.1279147840953368, 'Total loss': 0.1279147840953368}
2022-12-05 21:09:19,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:19,106 INFO:     Epoch: 71
2022-12-05 21:09:19,901 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4597228816287084, 'Total loss': 0.4597228816287084} | train loss {'Reaction outcome loss': 0.12798773251504067, 'Total loss': 0.12798773251504067}
2022-12-05 21:09:19,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:19,901 INFO:     Epoch: 72
2022-12-05 21:09:20,695 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4606286663223397, 'Total loss': 0.4606286663223397} | train loss {'Reaction outcome loss': 0.12553569018041436, 'Total loss': 0.12553569018041436}
2022-12-05 21:09:20,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:20,695 INFO:     Epoch: 73
2022-12-05 21:09:21,493 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44522934119132435, 'Total loss': 0.44522934119132435} | train loss {'Reaction outcome loss': 0.12580921122736413, 'Total loss': 0.12580921122736413}
2022-12-05 21:09:21,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:21,493 INFO:     Epoch: 74
2022-12-05 21:09:22,287 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47006831250407477, 'Total loss': 0.47006831250407477} | train loss {'Reaction outcome loss': 0.12953700248891042, 'Total loss': 0.12953700248891042}
2022-12-05 21:09:22,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:22,288 INFO:     Epoch: 75
2022-12-05 21:09:23,085 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.480800474062562, 'Total loss': 0.480800474062562} | train loss {'Reaction outcome loss': 0.12733655716462233, 'Total loss': 0.12733655716462233}
2022-12-05 21:09:23,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:23,086 INFO:     Epoch: 76
2022-12-05 21:09:23,889 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4629441970451312, 'Total loss': 0.4629441970451312} | train loss {'Reaction outcome loss': 0.12611300213948676, 'Total loss': 0.12611300213948676}
2022-12-05 21:09:23,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:23,889 INFO:     Epoch: 77
2022-12-05 21:09:24,689 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45487084053456783, 'Total loss': 0.45487084053456783} | train loss {'Reaction outcome loss': 0.12476276945669641, 'Total loss': 0.12476276945669641}
2022-12-05 21:09:24,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:24,689 INFO:     Epoch: 78
2022-12-05 21:09:25,489 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4483395723562518, 'Total loss': 0.4483395723562518} | train loss {'Reaction outcome loss': 0.12662305764718215, 'Total loss': 0.12662305764718215}
2022-12-05 21:09:25,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:25,489 INFO:     Epoch: 79
2022-12-05 21:09:26,291 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4691825048490004, 'Total loss': 0.4691825048490004} | train loss {'Reaction outcome loss': 0.12329299946274111, 'Total loss': 0.12329299946274111}
2022-12-05 21:09:26,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:26,291 INFO:     Epoch: 80
2022-12-05 21:09:27,091 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4709142934192311, 'Total loss': 0.4709142934192311} | train loss {'Reaction outcome loss': 0.12328721674890654, 'Total loss': 0.12328721674890654}
2022-12-05 21:09:27,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:27,091 INFO:     Epoch: 81
2022-12-05 21:09:27,889 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4316589541902596, 'Total loss': 0.4316589541902596} | train loss {'Reaction outcome loss': 0.127957752645619, 'Total loss': 0.127957752645619}
2022-12-05 21:09:27,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:27,889 INFO:     Epoch: 82
2022-12-05 21:09:28,686 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4725893427702514, 'Total loss': 0.4725893427702514} | train loss {'Reaction outcome loss': 0.1240028139837237, 'Total loss': 0.1240028139837237}
2022-12-05 21:09:28,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:28,686 INFO:     Epoch: 83
2022-12-05 21:09:29,487 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45030972293832083, 'Total loss': 0.45030972293832083} | train loss {'Reaction outcome loss': 0.1226519362238398, 'Total loss': 0.1226519362238398}
2022-12-05 21:09:29,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:29,488 INFO:     Epoch: 84
2022-12-05 21:09:30,293 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46480112455107947, 'Total loss': 0.46480112455107947} | train loss {'Reaction outcome loss': 0.12416585142675199, 'Total loss': 0.12416585142675199}
2022-12-05 21:09:30,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:30,294 INFO:     Epoch: 85
2022-12-05 21:09:31,092 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46356687728654256, 'Total loss': 0.46356687728654256} | train loss {'Reaction outcome loss': 0.132473990283454, 'Total loss': 0.132473990283454}
2022-12-05 21:09:31,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:31,093 INFO:     Epoch: 86
2022-12-05 21:09:31,892 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4581083726476539, 'Total loss': 0.4581083726476539} | train loss {'Reaction outcome loss': 0.12245712607348647, 'Total loss': 0.12245712607348647}
2022-12-05 21:09:31,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:31,892 INFO:     Epoch: 87
2022-12-05 21:09:32,688 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46847993237051094, 'Total loss': 0.46847993237051094} | train loss {'Reaction outcome loss': 0.12127465773600074, 'Total loss': 0.12127465773600074}
2022-12-05 21:09:32,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:32,689 INFO:     Epoch: 88
2022-12-05 21:09:33,489 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4672204733572223, 'Total loss': 0.4672204733572223} | train loss {'Reaction outcome loss': 0.12085096806175592, 'Total loss': 0.12085096806175592}
2022-12-05 21:09:33,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:33,489 INFO:     Epoch: 89
2022-12-05 21:09:34,285 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48164084113456984, 'Total loss': 0.48164084113456984} | train loss {'Reaction outcome loss': 0.1270697514568022, 'Total loss': 0.1270697514568022}
2022-12-05 21:09:34,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:34,285 INFO:     Epoch: 90
2022-12-05 21:09:35,083 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4613920050588521, 'Total loss': 0.4613920050588521} | train loss {'Reaction outcome loss': 0.12524169351272135, 'Total loss': 0.12524169351272135}
2022-12-05 21:09:35,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:35,083 INFO:     Epoch: 91
2022-12-05 21:09:35,877 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45626278526403685, 'Total loss': 0.45626278526403685} | train loss {'Reaction outcome loss': 0.12267071976060583, 'Total loss': 0.12267071976060583}
2022-12-05 21:09:35,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:35,878 INFO:     Epoch: 92
2022-12-05 21:09:36,680 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4760955758392811, 'Total loss': 0.4760955758392811} | train loss {'Reaction outcome loss': 0.1205571070652802, 'Total loss': 0.1205571070652802}
2022-12-05 21:09:36,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:36,680 INFO:     Epoch: 93
2022-12-05 21:09:37,476 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46111218563534995, 'Total loss': 0.46111218563534995} | train loss {'Reaction outcome loss': 0.1256073489521257, 'Total loss': 0.1256073489521257}
2022-12-05 21:09:37,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:37,476 INFO:     Epoch: 94
2022-12-05 21:09:38,274 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.475335624746301, 'Total loss': 0.475335624746301} | train loss {'Reaction outcome loss': 0.1180637096005835, 'Total loss': 0.1180637096005835}
2022-12-05 21:09:38,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:38,275 INFO:     Epoch: 95
2022-12-05 21:09:39,071 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4494938189163804, 'Total loss': 0.4494938189163804} | train loss {'Reaction outcome loss': 0.1175297300636708, 'Total loss': 0.1175297300636708}
2022-12-05 21:09:39,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:39,072 INFO:     Epoch: 96
2022-12-05 21:09:39,872 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4819141843102195, 'Total loss': 0.4819141843102195} | train loss {'Reaction outcome loss': 0.1195236424187779, 'Total loss': 0.1195236424187779}
2022-12-05 21:09:39,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:39,873 INFO:     Epoch: 97
2022-12-05 21:09:40,669 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4503528851677071, 'Total loss': 0.4503528851677071} | train loss {'Reaction outcome loss': 0.11707968633576685, 'Total loss': 0.11707968633576685}
2022-12-05 21:09:40,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:40,669 INFO:     Epoch: 98
2022-12-05 21:09:41,469 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4721875251694159, 'Total loss': 0.4721875251694159} | train loss {'Reaction outcome loss': 0.11836627945454739, 'Total loss': 0.11836627945454739}
2022-12-05 21:09:41,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:41,469 INFO:     Epoch: 99
2022-12-05 21:09:42,263 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4561877106739716, 'Total loss': 0.4561877106739716} | train loss {'Reaction outcome loss': 0.11874273457462609, 'Total loss': 0.11874273457462609}
2022-12-05 21:09:42,263 INFO:     Best model found after epoch 20 of 100.
2022-12-05 21:09:42,264 INFO:   Done with stage: TRAINING
2022-12-05 21:09:42,264 INFO:   Starting stage: EVALUATION
2022-12-05 21:09:42,389 INFO:   Done with stage: EVALUATION
2022-12-05 21:09:42,389 INFO:   Leaving out SEQ value Fold_2
2022-12-05 21:09:42,402 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:09:42,402 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:09:43,039 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:09:43,039 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:09:43,109 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:09:43,109 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:09:43,109 INFO:     No hyperparam tuning for this model
2022-12-05 21:09:43,109 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:09:43,110 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:09:43,110 INFO:     None feature selector for col prot
2022-12-05 21:09:43,110 INFO:     None feature selector for col prot
2022-12-05 21:09:43,111 INFO:     None feature selector for col prot
2022-12-05 21:09:43,111 INFO:     None feature selector for col chem
2022-12-05 21:09:43,111 INFO:     None feature selector for col chem
2022-12-05 21:09:43,111 INFO:     None feature selector for col chem
2022-12-05 21:09:43,111 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:09:43,111 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:09:43,113 INFO:     Number of params in model 215821
2022-12-05 21:09:43,116 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:09:43,116 INFO:   Starting stage: TRAINING
2022-12-05 21:09:43,178 INFO:     Val loss before train {'Reaction outcome loss': 0.9711544784632596, 'Total loss': 0.9711544784632596}
2022-12-05 21:09:43,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:43,178 INFO:     Epoch: 0
2022-12-05 21:09:43,966 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5963388207283887, 'Total loss': 0.5963388207283887} | train loss {'Reaction outcome loss': 0.7865557661470102, 'Total loss': 0.7865557661470102}
2022-12-05 21:09:43,966 INFO:     Found new best model at epoch 0
2022-12-05 21:09:43,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:43,967 INFO:     Epoch: 1
2022-12-05 21:09:44,762 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5137444111433896, 'Total loss': 0.5137444111433896} | train loss {'Reaction outcome loss': 0.5430465169707123, 'Total loss': 0.5430465169707123}
2022-12-05 21:09:44,762 INFO:     Found new best model at epoch 1
2022-12-05 21:09:44,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:44,763 INFO:     Epoch: 2
2022-12-05 21:09:45,554 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4546410881660201, 'Total loss': 0.4546410881660201} | train loss {'Reaction outcome loss': 0.47480312026276883, 'Total loss': 0.47480312026276883}
2022-12-05 21:09:45,554 INFO:     Found new best model at epoch 2
2022-12-05 21:09:45,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:45,555 INFO:     Epoch: 3
2022-12-05 21:09:46,343 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4370786984535781, 'Total loss': 0.4370786984535781} | train loss {'Reaction outcome loss': 0.4346688406808036, 'Total loss': 0.4346688406808036}
2022-12-05 21:09:46,344 INFO:     Found new best model at epoch 3
2022-12-05 21:09:46,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:46,344 INFO:     Epoch: 4
2022-12-05 21:09:47,140 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4190313382582231, 'Total loss': 0.4190313382582231} | train loss {'Reaction outcome loss': 0.39928303701536993, 'Total loss': 0.39928303701536993}
2022-12-05 21:09:47,140 INFO:     Found new best model at epoch 4
2022-12-05 21:09:47,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:47,141 INFO:     Epoch: 5
2022-12-05 21:09:47,931 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40970410440455785, 'Total loss': 0.40970410440455785} | train loss {'Reaction outcome loss': 0.3774802495326315, 'Total loss': 0.3774802495326315}
2022-12-05 21:09:47,931 INFO:     Found new best model at epoch 5
2022-12-05 21:09:47,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:47,932 INFO:     Epoch: 6
2022-12-05 21:09:48,721 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3914232255721634, 'Total loss': 0.3914232255721634} | train loss {'Reaction outcome loss': 0.35601072004254986, 'Total loss': 0.35601072004254986}
2022-12-05 21:09:48,721 INFO:     Found new best model at epoch 6
2022-12-05 21:09:48,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:48,722 INFO:     Epoch: 7
2022-12-05 21:09:49,518 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38259163160215726, 'Total loss': 0.38259163160215726} | train loss {'Reaction outcome loss': 0.3385686224212452, 'Total loss': 0.3385686224212452}
2022-12-05 21:09:49,519 INFO:     Found new best model at epoch 7
2022-12-05 21:09:49,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:49,519 INFO:     Epoch: 8
2022-12-05 21:09:50,310 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3855911227451129, 'Total loss': 0.3855911227451129} | train loss {'Reaction outcome loss': 0.3217008658513731, 'Total loss': 0.3217008658513731}
2022-12-05 21:09:50,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:50,310 INFO:     Epoch: 9
2022-12-05 21:09:51,099 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.375772338360548, 'Total loss': 0.375772338360548} | train loss {'Reaction outcome loss': 0.307321151330763, 'Total loss': 0.307321151330763}
2022-12-05 21:09:51,099 INFO:     Found new best model at epoch 9
2022-12-05 21:09:51,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:51,100 INFO:     Epoch: 10
2022-12-05 21:09:51,891 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40277661179954355, 'Total loss': 0.40277661179954355} | train loss {'Reaction outcome loss': 0.29533489471187396, 'Total loss': 0.29533489471187396}
2022-12-05 21:09:51,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:51,892 INFO:     Epoch: 11
2022-12-05 21:09:52,684 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3820365640250119, 'Total loss': 0.3820365640250119} | train loss {'Reaction outcome loss': 0.28495255897239763, 'Total loss': 0.28495255897239763}
2022-12-05 21:09:52,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:52,684 INFO:     Epoch: 12
2022-12-05 21:09:53,475 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3872494778849862, 'Total loss': 0.3872494778849862} | train loss {'Reaction outcome loss': 0.27400015255018156, 'Total loss': 0.27400015255018156}
2022-12-05 21:09:53,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:53,475 INFO:     Epoch: 13
2022-12-05 21:09:54,263 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38053225285627623, 'Total loss': 0.38053225285627623} | train loss {'Reaction outcome loss': 0.26359303201339684, 'Total loss': 0.26359303201339684}
2022-12-05 21:09:54,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:54,264 INFO:     Epoch: 14
2022-12-05 21:09:55,060 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3817907693711194, 'Total loss': 0.3817907693711194} | train loss {'Reaction outcome loss': 0.25743190643130515, 'Total loss': 0.25743190643130515}
2022-12-05 21:09:55,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:55,061 INFO:     Epoch: 15
2022-12-05 21:09:55,849 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37571514093063096, 'Total loss': 0.37571514093063096} | train loss {'Reaction outcome loss': 0.24838850256435724, 'Total loss': 0.24838850256435724}
2022-12-05 21:09:55,850 INFO:     Found new best model at epoch 15
2022-12-05 21:09:55,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:55,851 INFO:     Epoch: 16
2022-12-05 21:09:56,648 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3880300938405774, 'Total loss': 0.3880300938405774} | train loss {'Reaction outcome loss': 0.24098651574886576, 'Total loss': 0.24098651574886576}
2022-12-05 21:09:56,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:56,648 INFO:     Epoch: 17
2022-12-05 21:09:57,439 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37637859963896597, 'Total loss': 0.37637859963896597} | train loss {'Reaction outcome loss': 0.2359678681407656, 'Total loss': 0.2359678681407656}
2022-12-05 21:09:57,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:57,439 INFO:     Epoch: 18
2022-12-05 21:09:58,228 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36915860508187587, 'Total loss': 0.36915860508187587} | train loss {'Reaction outcome loss': 0.23042094525025816, 'Total loss': 0.23042094525025816}
2022-12-05 21:09:58,228 INFO:     Found new best model at epoch 18
2022-12-05 21:09:58,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:58,229 INFO:     Epoch: 19
2022-12-05 21:09:59,018 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37777872857722367, 'Total loss': 0.37777872857722367} | train loss {'Reaction outcome loss': 0.2248136531333534, 'Total loss': 0.2248136531333534}
2022-12-05 21:09:59,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:59,019 INFO:     Epoch: 20
2022-12-05 21:09:59,811 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3796452751213854, 'Total loss': 0.3796452751213854} | train loss {'Reaction outcome loss': 0.21765621620781567, 'Total loss': 0.21765621620781567}
2022-12-05 21:09:59,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:09:59,811 INFO:     Epoch: 21
2022-12-05 21:10:00,602 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4031654179773547, 'Total loss': 0.4031654179773547} | train loss {'Reaction outcome loss': 0.21775073795294275, 'Total loss': 0.21775073795294275}
2022-12-05 21:10:00,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:00,603 INFO:     Epoch: 22
2022-12-05 21:10:01,396 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37050963239215146, 'Total loss': 0.37050963239215146} | train loss {'Reaction outcome loss': 0.21135762837164257, 'Total loss': 0.21135762837164257}
2022-12-05 21:10:01,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:01,397 INFO:     Epoch: 23
2022-12-05 21:10:02,190 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38036317412148823, 'Total loss': 0.38036317412148823} | train loss {'Reaction outcome loss': 0.20467343309095928, 'Total loss': 0.20467343309095928}
2022-12-05 21:10:02,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:02,190 INFO:     Epoch: 24
2022-12-05 21:10:02,977 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39412635073743085, 'Total loss': 0.39412635073743085} | train loss {'Reaction outcome loss': 0.20122526665123142, 'Total loss': 0.20122526665123142}
2022-12-05 21:10:02,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:02,978 INFO:     Epoch: 25
2022-12-05 21:10:03,768 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3807651905173605, 'Total loss': 0.3807651905173605} | train loss {'Reaction outcome loss': 0.1987024021848124, 'Total loss': 0.1987024021848124}
2022-12-05 21:10:03,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:03,768 INFO:     Epoch: 26
2022-12-05 21:10:04,558 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3845207145945592, 'Total loss': 0.3845207145945592} | train loss {'Reaction outcome loss': 0.19500488430565718, 'Total loss': 0.19500488430565718}
2022-12-05 21:10:04,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:04,559 INFO:     Epoch: 27
2022-12-05 21:10:05,352 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3842661404474215, 'Total loss': 0.3842661404474215} | train loss {'Reaction outcome loss': 0.19163991624907573, 'Total loss': 0.19163991624907573}
2022-12-05 21:10:05,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:05,352 INFO:     Epoch: 28
2022-12-05 21:10:06,137 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38645381277257745, 'Total loss': 0.38645381277257745} | train loss {'Reaction outcome loss': 0.1899780160310317, 'Total loss': 0.1899780160310317}
2022-12-05 21:10:06,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:06,137 INFO:     Epoch: 29
2022-12-05 21:10:06,926 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37971008636734704, 'Total loss': 0.37971008636734704} | train loss {'Reaction outcome loss': 0.1850633353299024, 'Total loss': 0.1850633353299024}
2022-12-05 21:10:06,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:06,927 INFO:     Epoch: 30
2022-12-05 21:10:07,717 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3994019136510112, 'Total loss': 0.3994019136510112} | train loss {'Reaction outcome loss': 0.18274682027344802, 'Total loss': 0.18274682027344802}
2022-12-05 21:10:07,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:07,717 INFO:     Epoch: 31
2022-12-05 21:10:08,506 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3793876428495754, 'Total loss': 0.3793876428495754} | train loss {'Reaction outcome loss': 0.1822795008518258, 'Total loss': 0.1822795008518258}
2022-12-05 21:10:08,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:08,506 INFO:     Epoch: 32
2022-12-05 21:10:09,291 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3900683701715686, 'Total loss': 0.3900683701715686} | train loss {'Reaction outcome loss': 0.1772862933119949, 'Total loss': 0.1772862933119949}
2022-12-05 21:10:09,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:09,291 INFO:     Epoch: 33
2022-12-05 21:10:10,074 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3884702135216106, 'Total loss': 0.3884702135216106} | train loss {'Reaction outcome loss': 0.17414452182699222, 'Total loss': 0.17414452182699222}
2022-12-05 21:10:10,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:10,075 INFO:     Epoch: 34
2022-12-05 21:10:10,857 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.381078362126242, 'Total loss': 0.381078362126242} | train loss {'Reaction outcome loss': 0.17518127265633368, 'Total loss': 0.17518127265633368}
2022-12-05 21:10:10,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:10,858 INFO:     Epoch: 35
2022-12-05 21:10:11,643 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3856815675442869, 'Total loss': 0.3856815675442869} | train loss {'Reaction outcome loss': 0.1708709649589597, 'Total loss': 0.1708709649589597}
2022-12-05 21:10:11,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:11,644 INFO:     Epoch: 36
2022-12-05 21:10:12,427 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38593472904441034, 'Total loss': 0.38593472904441034} | train loss {'Reaction outcome loss': 0.1695237181928693, 'Total loss': 0.1695237181928693}
2022-12-05 21:10:12,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:12,427 INFO:     Epoch: 37
2022-12-05 21:10:13,215 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38869334147735074, 'Total loss': 0.38869334147735074} | train loss {'Reaction outcome loss': 0.16743087450764618, 'Total loss': 0.16743087450764618}
2022-12-05 21:10:13,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:13,216 INFO:     Epoch: 38
2022-12-05 21:10:14,008 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40171919542957435, 'Total loss': 0.40171919542957435} | train loss {'Reaction outcome loss': 0.16511471124023808, 'Total loss': 0.16511471124023808}
2022-12-05 21:10:14,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:14,008 INFO:     Epoch: 39
2022-12-05 21:10:14,797 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4037795488468625, 'Total loss': 0.4037795488468625} | train loss {'Reaction outcome loss': 0.16629445911670218, 'Total loss': 0.16629445911670218}
2022-12-05 21:10:14,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:14,798 INFO:     Epoch: 40
2022-12-05 21:10:15,587 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3944535008208318, 'Total loss': 0.3944535008208318} | train loss {'Reaction outcome loss': 0.16339238293621006, 'Total loss': 0.16339238293621006}
2022-12-05 21:10:15,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:15,588 INFO:     Epoch: 41
2022-12-05 21:10:16,373 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3901604576544328, 'Total loss': 0.3901604576544328} | train loss {'Reaction outcome loss': 0.15897523354814977, 'Total loss': 0.15897523354814977}
2022-12-05 21:10:16,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:16,373 INFO:     Epoch: 42
2022-12-05 21:10:17,165 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40289289165626874, 'Total loss': 0.40289289165626874} | train loss {'Reaction outcome loss': 0.15954179924209508, 'Total loss': 0.15954179924209508}
2022-12-05 21:10:17,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:17,165 INFO:     Epoch: 43
2022-12-05 21:10:17,950 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38546898385340517, 'Total loss': 0.38546898385340517} | train loss {'Reaction outcome loss': 0.161623792852066, 'Total loss': 0.161623792852066}
2022-12-05 21:10:17,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:17,950 INFO:     Epoch: 44
2022-12-05 21:10:18,739 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38158727691254835, 'Total loss': 0.38158727691254835} | train loss {'Reaction outcome loss': 0.1548320202727099, 'Total loss': 0.1548320202727099}
2022-12-05 21:10:18,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:18,739 INFO:     Epoch: 45
2022-12-05 21:10:19,524 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40880495005033235, 'Total loss': 0.40880495005033235} | train loss {'Reaction outcome loss': 0.15659044290683707, 'Total loss': 0.15659044290683707}
2022-12-05 21:10:19,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:19,524 INFO:     Epoch: 46
2022-12-05 21:10:20,310 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39941176772117615, 'Total loss': 0.39941176772117615} | train loss {'Reaction outcome loss': 0.1578151887244716, 'Total loss': 0.1578151887244716}
2022-12-05 21:10:20,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:20,310 INFO:     Epoch: 47
2022-12-05 21:10:21,093 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3952458448369395, 'Total loss': 0.3952458448369395} | train loss {'Reaction outcome loss': 0.15324460851142602, 'Total loss': 0.15324460851142602}
2022-12-05 21:10:21,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:21,094 INFO:     Epoch: 48
2022-12-05 21:10:21,882 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39417526142841036, 'Total loss': 0.39417526142841036} | train loss {'Reaction outcome loss': 0.15181285087019206, 'Total loss': 0.15181285087019206}
2022-12-05 21:10:21,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:21,882 INFO:     Epoch: 49
2022-12-05 21:10:22,675 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4176998626102101, 'Total loss': 0.4176998626102101} | train loss {'Reaction outcome loss': 0.14828213764240547, 'Total loss': 0.14828213764240547}
2022-12-05 21:10:22,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:22,676 INFO:     Epoch: 50
2022-12-05 21:10:23,462 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3989460844207894, 'Total loss': 0.3989460844207894} | train loss {'Reaction outcome loss': 0.1522907388909739, 'Total loss': 0.1522907388909739}
2022-12-05 21:10:23,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:23,462 INFO:     Epoch: 51
2022-12-05 21:10:24,248 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3987363642928275, 'Total loss': 0.3987363642928275} | train loss {'Reaction outcome loss': 0.1468063587740976, 'Total loss': 0.1468063587740976}
2022-12-05 21:10:24,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:24,249 INFO:     Epoch: 52
2022-12-05 21:10:25,040 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39510218223387544, 'Total loss': 0.39510218223387544} | train loss {'Reaction outcome loss': 0.14637842208755258, 'Total loss': 0.14637842208755258}
2022-12-05 21:10:25,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:25,040 INFO:     Epoch: 53
2022-12-05 21:10:25,834 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39762699798765505, 'Total loss': 0.39762699798765505} | train loss {'Reaction outcome loss': 0.1471314855300042, 'Total loss': 0.1471314855300042}
2022-12-05 21:10:25,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:25,835 INFO:     Epoch: 54
2022-12-05 21:10:26,629 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3996035463430665, 'Total loss': 0.3996035463430665} | train loss {'Reaction outcome loss': 0.14822790792249904, 'Total loss': 0.14822790792249904}
2022-12-05 21:10:26,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:26,630 INFO:     Epoch: 55
2022-12-05 21:10:27,414 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4077318656173619, 'Total loss': 0.4077318656173619} | train loss {'Reaction outcome loss': 0.14502584737326418, 'Total loss': 0.14502584737326418}
2022-12-05 21:10:27,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:27,414 INFO:     Epoch: 56
2022-12-05 21:10:28,199 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3950124081562866, 'Total loss': 0.3950124081562866} | train loss {'Reaction outcome loss': 0.14294914595630703, 'Total loss': 0.14294914595630703}
2022-12-05 21:10:28,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:28,199 INFO:     Epoch: 57
2022-12-05 21:10:28,989 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4135371300984513, 'Total loss': 0.4135371300984513} | train loss {'Reaction outcome loss': 0.14168280077223874, 'Total loss': 0.14168280077223874}
2022-12-05 21:10:28,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:28,989 INFO:     Epoch: 58
2022-12-05 21:10:29,774 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40976671569726686, 'Total loss': 0.40976671569726686} | train loss {'Reaction outcome loss': 0.1405495608035399, 'Total loss': 0.1405495608035399}
2022-12-05 21:10:29,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:29,774 INFO:     Epoch: 59
2022-12-05 21:10:30,565 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40327318757772446, 'Total loss': 0.40327318757772446} | train loss {'Reaction outcome loss': 0.1444529044384859, 'Total loss': 0.1444529044384859}
2022-12-05 21:10:30,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:30,565 INFO:     Epoch: 60
2022-12-05 21:10:31,353 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39290348402309144, 'Total loss': 0.39290348402309144} | train loss {'Reaction outcome loss': 0.1425862649341627, 'Total loss': 0.1425862649341627}
2022-12-05 21:10:31,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:31,354 INFO:     Epoch: 61
2022-12-05 21:10:32,143 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4059698033061894, 'Total loss': 0.4059698033061894} | train loss {'Reaction outcome loss': 0.13995272744523019, 'Total loss': 0.13995272744523019}
2022-12-05 21:10:32,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:32,143 INFO:     Epoch: 62
2022-12-05 21:10:32,934 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39889843490990723, 'Total loss': 0.39889843490990723} | train loss {'Reaction outcome loss': 0.1431838899318661, 'Total loss': 0.1431838899318661}
2022-12-05 21:10:32,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:32,934 INFO:     Epoch: 63
2022-12-05 21:10:33,720 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4058675183491273, 'Total loss': 0.4058675183491273} | train loss {'Reaction outcome loss': 0.13644242745120916, 'Total loss': 0.13644242745120916}
2022-12-05 21:10:33,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:33,720 INFO:     Epoch: 64
2022-12-05 21:10:34,507 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4036294404755939, 'Total loss': 0.4036294404755939} | train loss {'Reaction outcome loss': 0.139629571014369, 'Total loss': 0.139629571014369}
2022-12-05 21:10:34,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:34,507 INFO:     Epoch: 65
2022-12-05 21:10:35,292 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41463269310241396, 'Total loss': 0.41463269310241396} | train loss {'Reaction outcome loss': 0.1360319441982678, 'Total loss': 0.1360319441982678}
2022-12-05 21:10:35,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:35,292 INFO:     Epoch: 66
2022-12-05 21:10:36,083 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41738352687521413, 'Total loss': 0.41738352687521413} | train loss {'Reaction outcome loss': 0.13824055585249953, 'Total loss': 0.13824055585249953}
2022-12-05 21:10:36,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:36,083 INFO:     Epoch: 67
2022-12-05 21:10:36,872 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3915516476739537, 'Total loss': 0.3915516476739537} | train loss {'Reaction outcome loss': 0.13707665205762096, 'Total loss': 0.13707665205762096}
2022-12-05 21:10:36,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:36,872 INFO:     Epoch: 68
2022-12-05 21:10:37,659 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42413180423053826, 'Total loss': 0.42413180423053826} | train loss {'Reaction outcome loss': 0.1353560474834272, 'Total loss': 0.1353560474834272}
2022-12-05 21:10:37,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:37,660 INFO:     Epoch: 69
2022-12-05 21:10:38,448 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40637879175218666, 'Total loss': 0.40637879175218666} | train loss {'Reaction outcome loss': 0.1349190692398317, 'Total loss': 0.1349190692398317}
2022-12-05 21:10:38,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:38,448 INFO:     Epoch: 70
2022-12-05 21:10:39,235 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39049134026837157, 'Total loss': 0.39049134026837157} | train loss {'Reaction outcome loss': 0.13726542220279878, 'Total loss': 0.13726542220279878}
2022-12-05 21:10:39,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:39,236 INFO:     Epoch: 71
2022-12-05 21:10:40,024 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41274535029449244, 'Total loss': 0.41274535029449244} | train loss {'Reaction outcome loss': 0.13652738895343275, 'Total loss': 0.13652738895343275}
2022-12-05 21:10:40,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:40,024 INFO:     Epoch: 72
2022-12-05 21:10:40,811 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4037322655997493, 'Total loss': 0.4037322655997493} | train loss {'Reaction outcome loss': 0.13474451957308517, 'Total loss': 0.13474451957308517}
2022-12-05 21:10:40,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:40,811 INFO:     Epoch: 73
2022-12-05 21:10:41,597 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4257301451130347, 'Total loss': 0.4257301451130347} | train loss {'Reaction outcome loss': 0.13352901436084388, 'Total loss': 0.13352901436084388}
2022-12-05 21:10:41,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:41,597 INFO:     Epoch: 74
2022-12-05 21:10:42,382 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40325141113928775, 'Total loss': 0.40325141113928775} | train loss {'Reaction outcome loss': 0.13367647315774644, 'Total loss': 0.13367647315774644}
2022-12-05 21:10:42,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:42,382 INFO:     Epoch: 75
2022-12-05 21:10:43,167 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40600829165090213, 'Total loss': 0.40600829165090213} | train loss {'Reaction outcome loss': 0.13252373072793897, 'Total loss': 0.13252373072793897}
2022-12-05 21:10:43,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:43,168 INFO:     Epoch: 76
2022-12-05 21:10:43,955 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4192899577319622, 'Total loss': 0.4192899577319622} | train loss {'Reaction outcome loss': 0.13304778161857808, 'Total loss': 0.13304778161857808}
2022-12-05 21:10:43,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:43,956 INFO:     Epoch: 77
2022-12-05 21:10:44,742 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4205946180630814, 'Total loss': 0.4205946180630814} | train loss {'Reaction outcome loss': 0.13291929423504947, 'Total loss': 0.13291929423504947}
2022-12-05 21:10:44,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:44,742 INFO:     Epoch: 78
2022-12-05 21:10:45,530 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39887265649370174, 'Total loss': 0.39887265649370174} | train loss {'Reaction outcome loss': 0.1289899625682405, 'Total loss': 0.1289899625682405}
2022-12-05 21:10:45,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:45,530 INFO:     Epoch: 79
2022-12-05 21:10:46,321 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4071062251248143, 'Total loss': 0.4071062251248143} | train loss {'Reaction outcome loss': 0.13026641221070775, 'Total loss': 0.13026641221070775}
2022-12-05 21:10:46,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:46,321 INFO:     Epoch: 80
2022-12-05 21:10:47,107 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4027980202808976, 'Total loss': 0.4027980202808976} | train loss {'Reaction outcome loss': 0.1320506024041346, 'Total loss': 0.1320506024041346}
2022-12-05 21:10:47,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:47,107 INFO:     Epoch: 81
2022-12-05 21:10:47,892 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4109299953349612, 'Total loss': 0.4109299953349612} | train loss {'Reaction outcome loss': 0.13049645005744331, 'Total loss': 0.13049645005744331}
2022-12-05 21:10:47,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:47,892 INFO:     Epoch: 82
2022-12-05 21:10:48,677 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3879659803827632, 'Total loss': 0.3879659803827632} | train loss {'Reaction outcome loss': 0.13238045277492125, 'Total loss': 0.13238045277492125}
2022-12-05 21:10:48,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:48,677 INFO:     Epoch: 83
2022-12-05 21:10:49,464 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4103971538557248, 'Total loss': 0.4103971538557248} | train loss {'Reaction outcome loss': 0.12935447956302337, 'Total loss': 0.12935447956302337}
2022-12-05 21:10:49,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:49,464 INFO:     Epoch: 84
2022-12-05 21:10:50,251 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39585737917910924, 'Total loss': 0.39585737917910924} | train loss {'Reaction outcome loss': 0.12734260443902137, 'Total loss': 0.12734260443902137}
2022-12-05 21:10:50,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:50,251 INFO:     Epoch: 85
2022-12-05 21:10:51,043 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4020115573128516, 'Total loss': 0.4020115573128516} | train loss {'Reaction outcome loss': 0.12827651561903103, 'Total loss': 0.12827651561903103}
2022-12-05 21:10:51,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:51,043 INFO:     Epoch: 86
2022-12-05 21:10:51,832 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4096630183471875, 'Total loss': 0.4096630183471875} | train loss {'Reaction outcome loss': 0.12867437081069363, 'Total loss': 0.12867437081069363}
2022-12-05 21:10:51,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:51,833 INFO:     Epoch: 87
2022-12-05 21:10:52,620 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40369506036354735, 'Total loss': 0.40369506036354735} | train loss {'Reaction outcome loss': 0.12650780495712344, 'Total loss': 0.12650780495712344}
2022-12-05 21:10:52,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:52,621 INFO:     Epoch: 88
2022-12-05 21:10:53,409 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41919712485237554, 'Total loss': 0.41919712485237554} | train loss {'Reaction outcome loss': 0.12742869140846388, 'Total loss': 0.12742869140846388}
2022-12-05 21:10:53,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:53,409 INFO:     Epoch: 89
2022-12-05 21:10:54,200 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41261162236332893, 'Total loss': 0.41261162236332893} | train loss {'Reaction outcome loss': 0.12682245125880046, 'Total loss': 0.12682245125880046}
2022-12-05 21:10:54,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:54,200 INFO:     Epoch: 90
2022-12-05 21:10:54,991 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40582451495257293, 'Total loss': 0.40582451495257293} | train loss {'Reaction outcome loss': 0.12863561205413876, 'Total loss': 0.12863561205413876}
2022-12-05 21:10:54,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:54,991 INFO:     Epoch: 91
2022-12-05 21:10:55,780 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4032971713353287, 'Total loss': 0.4032971713353287} | train loss {'Reaction outcome loss': 0.12716004665636896, 'Total loss': 0.12716004665636896}
2022-12-05 21:10:55,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:55,781 INFO:     Epoch: 92
2022-12-05 21:10:56,571 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4149616262452169, 'Total loss': 0.4149616262452169} | train loss {'Reaction outcome loss': 0.12642224408610134, 'Total loss': 0.12642224408610134}
2022-12-05 21:10:56,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:56,572 INFO:     Epoch: 93
2022-12-05 21:10:57,356 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41479446095499123, 'Total loss': 0.41479446095499123} | train loss {'Reaction outcome loss': 0.12578051788162212, 'Total loss': 0.12578051788162212}
2022-12-05 21:10:57,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:57,356 INFO:     Epoch: 94
2022-12-05 21:10:58,141 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40164686807177286, 'Total loss': 0.40164686807177286} | train loss {'Reaction outcome loss': 0.12391949441968178, 'Total loss': 0.12391949441968178}
2022-12-05 21:10:58,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:58,141 INFO:     Epoch: 95
2022-12-05 21:10:58,928 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41002999449318106, 'Total loss': 0.41002999449318106} | train loss {'Reaction outcome loss': 0.12686117322621296, 'Total loss': 0.12686117322621296}
2022-12-05 21:10:58,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:58,928 INFO:     Epoch: 96
2022-12-05 21:10:59,711 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41336388572711835, 'Total loss': 0.41336388572711835} | train loss {'Reaction outcome loss': 0.12212780056787388, 'Total loss': 0.12212780056787388}
2022-12-05 21:10:59,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:10:59,712 INFO:     Epoch: 97
2022-12-05 21:11:00,496 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41969466573474085, 'Total loss': 0.41969466573474085} | train loss {'Reaction outcome loss': 0.1241820751347256, 'Total loss': 0.1241820751347256}
2022-12-05 21:11:00,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:00,496 INFO:     Epoch: 98
2022-12-05 21:11:01,286 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41488363102755765, 'Total loss': 0.41488363102755765} | train loss {'Reaction outcome loss': 0.12565918210703803, 'Total loss': 0.12565918210703803}
2022-12-05 21:11:01,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:01,286 INFO:     Epoch: 99
2022-12-05 21:11:02,072 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41285027483139525, 'Total loss': 0.41285027483139525} | train loss {'Reaction outcome loss': 0.12348513017047424, 'Total loss': 0.12348513017047424}
2022-12-05 21:11:02,072 INFO:     Best model found after epoch 19 of 100.
2022-12-05 21:11:02,072 INFO:   Done with stage: TRAINING
2022-12-05 21:11:02,072 INFO:   Starting stage: EVALUATION
2022-12-05 21:11:02,203 INFO:   Done with stage: EVALUATION
2022-12-05 21:11:02,203 INFO:   Leaving out SEQ value Fold_3
2022-12-05 21:11:02,216 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:11:02,216 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:11:02,847 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:11:02,847 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:11:02,916 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:11:02,916 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:11:02,916 INFO:     No hyperparam tuning for this model
2022-12-05 21:11:02,916 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:11:02,916 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:11:02,917 INFO:     None feature selector for col prot
2022-12-05 21:11:02,917 INFO:     None feature selector for col prot
2022-12-05 21:11:02,917 INFO:     None feature selector for col prot
2022-12-05 21:11:02,917 INFO:     None feature selector for col chem
2022-12-05 21:11:02,918 INFO:     None feature selector for col chem
2022-12-05 21:11:02,918 INFO:     None feature selector for col chem
2022-12-05 21:11:02,918 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:11:02,918 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:11:02,919 INFO:     Number of params in model 215821
2022-12-05 21:11:02,922 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:11:02,922 INFO:   Starting stage: TRAINING
2022-12-05 21:11:02,982 INFO:     Val loss before train {'Reaction outcome loss': 0.9984325634878736, 'Total loss': 0.9984325634878736}
2022-12-05 21:11:02,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:02,982 INFO:     Epoch: 0
2022-12-05 21:11:03,765 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6530180989309798, 'Total loss': 0.6530180989309798} | train loss {'Reaction outcome loss': 0.7875981967224449, 'Total loss': 0.7875981967224449}
2022-12-05 21:11:03,765 INFO:     Found new best model at epoch 0
2022-12-05 21:11:03,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:03,766 INFO:     Epoch: 1
2022-12-05 21:11:04,545 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.558043708634931, 'Total loss': 0.558043708634931} | train loss {'Reaction outcome loss': 0.545411533813496, 'Total loss': 0.545411533813496}
2022-12-05 21:11:04,545 INFO:     Found new best model at epoch 1
2022-12-05 21:11:04,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:04,546 INFO:     Epoch: 2
2022-12-05 21:11:05,331 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5139812723148701, 'Total loss': 0.5139812723148701} | train loss {'Reaction outcome loss': 0.47357525285638746, 'Total loss': 0.47357525285638746}
2022-12-05 21:11:05,331 INFO:     Found new best model at epoch 2
2022-12-05 21:11:05,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:05,332 INFO:     Epoch: 3
2022-12-05 21:11:06,113 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4854128728079241, 'Total loss': 0.4854128728079241} | train loss {'Reaction outcome loss': 0.4296366955901756, 'Total loss': 0.4296366955901756}
2022-12-05 21:11:06,113 INFO:     Found new best model at epoch 3
2022-12-05 21:11:06,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:06,114 INFO:     Epoch: 4
2022-12-05 21:11:06,899 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48174630348072495, 'Total loss': 0.48174630348072495} | train loss {'Reaction outcome loss': 0.3993041268320846, 'Total loss': 0.3993041268320846}
2022-12-05 21:11:06,899 INFO:     Found new best model at epoch 4
2022-12-05 21:11:06,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:06,900 INFO:     Epoch: 5
2022-12-05 21:11:07,682 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46683464459208557, 'Total loss': 0.46683464459208557} | train loss {'Reaction outcome loss': 0.38183980221386815, 'Total loss': 0.38183980221386815}
2022-12-05 21:11:07,682 INFO:     Found new best model at epoch 5
2022-12-05 21:11:07,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:07,683 INFO:     Epoch: 6
2022-12-05 21:11:08,462 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45463445193545765, 'Total loss': 0.45463445193545765} | train loss {'Reaction outcome loss': 0.3563342681612636, 'Total loss': 0.3563342681612636}
2022-12-05 21:11:08,462 INFO:     Found new best model at epoch 6
2022-12-05 21:11:08,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:08,463 INFO:     Epoch: 7
2022-12-05 21:11:09,249 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46132587554842924, 'Total loss': 0.46132587554842924} | train loss {'Reaction outcome loss': 0.3421361394776184, 'Total loss': 0.3421361394776184}
2022-12-05 21:11:09,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:09,250 INFO:     Epoch: 8
2022-12-05 21:11:10,032 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4457632039868554, 'Total loss': 0.4457632039868554} | train loss {'Reaction outcome loss': 0.3263969170387651, 'Total loss': 0.3263969170387651}
2022-12-05 21:11:10,032 INFO:     Found new best model at epoch 8
2022-12-05 21:11:10,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:10,033 INFO:     Epoch: 9
2022-12-05 21:11:10,817 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4621544903100923, 'Total loss': 0.4621544903100923} | train loss {'Reaction outcome loss': 0.31083128294434215, 'Total loss': 0.31083128294434215}
2022-12-05 21:11:10,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:10,817 INFO:     Epoch: 10
2022-12-05 21:11:11,598 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43876191939032355, 'Total loss': 0.43876191939032355} | train loss {'Reaction outcome loss': 0.2999245944875674, 'Total loss': 0.2999245944875674}
2022-12-05 21:11:11,598 INFO:     Found new best model at epoch 10
2022-12-05 21:11:11,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:11,599 INFO:     Epoch: 11
2022-12-05 21:11:12,384 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43360469472962754, 'Total loss': 0.43360469472962754} | train loss {'Reaction outcome loss': 0.28917347306965807, 'Total loss': 0.28917347306965807}
2022-12-05 21:11:12,384 INFO:     Found new best model at epoch 11
2022-12-05 21:11:12,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:12,385 INFO:     Epoch: 12
2022-12-05 21:11:13,169 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4294392158125722, 'Total loss': 0.4294392158125722} | train loss {'Reaction outcome loss': 0.2778840427149515, 'Total loss': 0.2778840427149515}
2022-12-05 21:11:13,169 INFO:     Found new best model at epoch 12
2022-12-05 21:11:13,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:13,170 INFO:     Epoch: 13
2022-12-05 21:11:13,951 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43793656590373015, 'Total loss': 0.43793656590373015} | train loss {'Reaction outcome loss': 0.2669090724199033, 'Total loss': 0.2669090724199033}
2022-12-05 21:11:13,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:13,951 INFO:     Epoch: 14
2022-12-05 21:11:14,731 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4368314344522565, 'Total loss': 0.4368314344522565} | train loss {'Reaction outcome loss': 0.26111664946694846, 'Total loss': 0.26111664946694846}
2022-12-05 21:11:14,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:14,731 INFO:     Epoch: 15
2022-12-05 21:11:15,514 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4348329212083373, 'Total loss': 0.4348329212083373} | train loss {'Reaction outcome loss': 0.2508461469265281, 'Total loss': 0.2508461469265281}
2022-12-05 21:11:15,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:15,515 INFO:     Epoch: 16
2022-12-05 21:11:16,299 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4225767909787422, 'Total loss': 0.4225767909787422} | train loss {'Reaction outcome loss': 0.2466062252089137, 'Total loss': 0.2466062252089137}
2022-12-05 21:11:16,299 INFO:     Found new best model at epoch 16
2022-12-05 21:11:16,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:16,300 INFO:     Epoch: 17
2022-12-05 21:11:17,080 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4310001107149346, 'Total loss': 0.4310001107149346} | train loss {'Reaction outcome loss': 0.2385713521116337, 'Total loss': 0.2385713521116337}
2022-12-05 21:11:17,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:17,080 INFO:     Epoch: 18
2022-12-05 21:11:17,859 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4290136590946552, 'Total loss': 0.4290136590946552} | train loss {'Reaction outcome loss': 0.22909969688377907, 'Total loss': 0.22909969688377907}
2022-12-05 21:11:17,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:17,859 INFO:     Epoch: 19
2022-12-05 21:11:18,638 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4308939011291016, 'Total loss': 0.4308939011291016} | train loss {'Reaction outcome loss': 0.2250141021566557, 'Total loss': 0.2250141021566557}
2022-12-05 21:11:18,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:18,638 INFO:     Epoch: 20
2022-12-05 21:11:19,419 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4259655382051024, 'Total loss': 0.4259655382051024} | train loss {'Reaction outcome loss': 0.2168789254348786, 'Total loss': 0.2168789254348786}
2022-12-05 21:11:19,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:19,419 INFO:     Epoch: 21
2022-12-05 21:11:20,200 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4388464623412421, 'Total loss': 0.4388464623412421} | train loss {'Reaction outcome loss': 0.21498155396920246, 'Total loss': 0.21498155396920246}
2022-12-05 21:11:20,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:20,200 INFO:     Epoch: 22
2022-12-05 21:11:20,980 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42497061712797296, 'Total loss': 0.42497061712797296} | train loss {'Reaction outcome loss': 0.2079873667022244, 'Total loss': 0.2079873667022244}
2022-12-05 21:11:20,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:20,981 INFO:     Epoch: 23
2022-12-05 21:11:21,760 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4286983692368796, 'Total loss': 0.4286983692368796} | train loss {'Reaction outcome loss': 0.20475562342793727, 'Total loss': 0.20475562342793727}
2022-12-05 21:11:21,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:21,760 INFO:     Epoch: 24
2022-12-05 21:11:22,543 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4305693975021673, 'Total loss': 0.4305693975021673} | train loss {'Reaction outcome loss': 0.20076897519747497, 'Total loss': 0.20076897519747497}
2022-12-05 21:11:22,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:22,543 INFO:     Epoch: 25
2022-12-05 21:11:23,326 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44698812431374263, 'Total loss': 0.44698812431374263} | train loss {'Reaction outcome loss': 0.1965226663246018, 'Total loss': 0.1965226663246018}
2022-12-05 21:11:23,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:23,326 INFO:     Epoch: 26
2022-12-05 21:11:24,108 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44037144544512724, 'Total loss': 0.44037144544512724} | train loss {'Reaction outcome loss': 0.19246344580544067, 'Total loss': 0.19246344580544067}
2022-12-05 21:11:24,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:24,108 INFO:     Epoch: 27
2022-12-05 21:11:24,892 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4323322180398675, 'Total loss': 0.4323322180398675} | train loss {'Reaction outcome loss': 0.1896357836171252, 'Total loss': 0.1896357836171252}
2022-12-05 21:11:24,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:24,892 INFO:     Epoch: 28
2022-12-05 21:11:25,682 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45002102747906086, 'Total loss': 0.45002102747906086} | train loss {'Reaction outcome loss': 0.18572779841049283, 'Total loss': 0.18572779841049283}
2022-12-05 21:11:25,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:25,682 INFO:     Epoch: 29
2022-12-05 21:11:26,472 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4473565099544303, 'Total loss': 0.4473565099544303} | train loss {'Reaction outcome loss': 0.18119023676167745, 'Total loss': 0.18119023676167745}
2022-12-05 21:11:26,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:26,472 INFO:     Epoch: 30
2022-12-05 21:11:27,254 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44697591939637826, 'Total loss': 0.44697591939637826} | train loss {'Reaction outcome loss': 0.17818934748285128, 'Total loss': 0.17818934748285128}
2022-12-05 21:11:27,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:27,255 INFO:     Epoch: 31
2022-12-05 21:11:28,038 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44108009061148, 'Total loss': 0.44108009061148} | train loss {'Reaction outcome loss': 0.17722710942635772, 'Total loss': 0.17722710942635772}
2022-12-05 21:11:28,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:28,039 INFO:     Epoch: 32
2022-12-05 21:11:28,824 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4343876034714455, 'Total loss': 0.4343876034714455} | train loss {'Reaction outcome loss': 0.17309550207383076, 'Total loss': 0.17309550207383076}
2022-12-05 21:11:28,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:28,824 INFO:     Epoch: 33
2022-12-05 21:11:29,608 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4417276243830836, 'Total loss': 0.4417276243830836} | train loss {'Reaction outcome loss': 0.17056361882809978, 'Total loss': 0.17056361882809978}
2022-12-05 21:11:29,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:29,608 INFO:     Epoch: 34
2022-12-05 21:11:30,392 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.435843076816825, 'Total loss': 0.435843076816825} | train loss {'Reaction outcome loss': 0.16913173911085383, 'Total loss': 0.16913173911085383}
2022-12-05 21:11:30,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:30,392 INFO:     Epoch: 35
2022-12-05 21:11:31,175 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44977186464293056, 'Total loss': 0.44977186464293056} | train loss {'Reaction outcome loss': 0.16432985889374233, 'Total loss': 0.16432985889374233}
2022-12-05 21:11:31,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:31,175 INFO:     Epoch: 36
2022-12-05 21:11:31,962 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4506216745736987, 'Total loss': 0.4506216745736987} | train loss {'Reaction outcome loss': 0.16246712074966216, 'Total loss': 0.16246712074966216}
2022-12-05 21:11:31,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:31,963 INFO:     Epoch: 37
2022-12-05 21:11:32,743 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44898810185665305, 'Total loss': 0.44898810185665305} | train loss {'Reaction outcome loss': 0.1607385282939086, 'Total loss': 0.1607385282939086}
2022-12-05 21:11:32,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:32,743 INFO:     Epoch: 38
2022-12-05 21:11:33,529 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4670592795970828, 'Total loss': 0.4670592795970828} | train loss {'Reaction outcome loss': 0.1607799169179968, 'Total loss': 0.1607799169179968}
2022-12-05 21:11:33,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:33,529 INFO:     Epoch: 39
2022-12-05 21:11:34,319 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44913678806881574, 'Total loss': 0.44913678806881574} | train loss {'Reaction outcome loss': 0.16029778421001478, 'Total loss': 0.16029778421001478}
2022-12-05 21:11:34,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:34,319 INFO:     Epoch: 40
2022-12-05 21:11:35,105 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44201386910538343, 'Total loss': 0.44201386910538343} | train loss {'Reaction outcome loss': 0.15493090564888887, 'Total loss': 0.15493090564888887}
2022-12-05 21:11:35,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:35,106 INFO:     Epoch: 41
2022-12-05 21:11:35,888 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45089563034301583, 'Total loss': 0.45089563034301583} | train loss {'Reaction outcome loss': 0.15369288372944612, 'Total loss': 0.15369288372944612}
2022-12-05 21:11:35,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:35,888 INFO:     Epoch: 42
2022-12-05 21:11:36,670 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4593599199555641, 'Total loss': 0.4593599199555641} | train loss {'Reaction outcome loss': 0.15386697604534688, 'Total loss': 0.15386697604534688}
2022-12-05 21:11:36,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:36,670 INFO:     Epoch: 43
2022-12-05 21:11:37,453 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4557206124760384, 'Total loss': 0.4557206124760384} | train loss {'Reaction outcome loss': 0.14881430860211858, 'Total loss': 0.14881430860211858}
2022-12-05 21:11:37,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:37,453 INFO:     Epoch: 44
2022-12-05 21:11:38,237 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4614685389191605, 'Total loss': 0.4614685389191605} | train loss {'Reaction outcome loss': 0.15011825393427347, 'Total loss': 0.15011825393427347}
2022-12-05 21:11:38,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:38,238 INFO:     Epoch: 45
2022-12-05 21:11:39,023 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4504951890124831, 'Total loss': 0.4504951890124831} | train loss {'Reaction outcome loss': 0.14993596599498366, 'Total loss': 0.14993596599498366}
2022-12-05 21:11:39,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:39,023 INFO:     Epoch: 46
2022-12-05 21:11:39,804 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45528094513818274, 'Total loss': 0.45528094513818274} | train loss {'Reaction outcome loss': 0.14860656097928276, 'Total loss': 0.14860656097928276}
2022-12-05 21:11:39,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:39,805 INFO:     Epoch: 47
2022-12-05 21:11:40,592 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46484874188899994, 'Total loss': 0.46484874188899994} | train loss {'Reaction outcome loss': 0.14389255312347754, 'Total loss': 0.14389255312347754}
2022-12-05 21:11:40,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:40,593 INFO:     Epoch: 48
2022-12-05 21:11:41,383 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4466914756353511, 'Total loss': 0.4466914756353511} | train loss {'Reaction outcome loss': 0.14262608559344148, 'Total loss': 0.14262608559344148}
2022-12-05 21:11:41,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:41,383 INFO:     Epoch: 49
2022-12-05 21:11:42,170 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46398855607176936, 'Total loss': 0.46398855607176936} | train loss {'Reaction outcome loss': 0.14331903022744494, 'Total loss': 0.14331903022744494}
2022-12-05 21:11:42,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:42,170 INFO:     Epoch: 50
2022-12-05 21:11:42,950 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4523826969224353, 'Total loss': 0.4523826969224353} | train loss {'Reaction outcome loss': 0.14336034800231334, 'Total loss': 0.14336034800231334}
2022-12-05 21:11:42,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:42,950 INFO:     Epoch: 51
2022-12-05 21:11:43,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4651714147523392, 'Total loss': 0.4651714147523392} | train loss {'Reaction outcome loss': 0.13806289799328222, 'Total loss': 0.13806289799328222}
2022-12-05 21:11:43,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:43,732 INFO:     Epoch: 52
2022-12-05 21:11:44,514 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4639318571534268, 'Total loss': 0.4639318571534268} | train loss {'Reaction outcome loss': 0.14139092934592704, 'Total loss': 0.14139092934592704}
2022-12-05 21:11:44,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:44,515 INFO:     Epoch: 53
2022-12-05 21:11:45,296 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47940233280492384, 'Total loss': 0.47940233280492384} | train loss {'Reaction outcome loss': 0.14123014388911304, 'Total loss': 0.14123014388911304}
2022-12-05 21:11:45,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:45,296 INFO:     Epoch: 54
2022-12-05 21:11:46,080 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4447693613379501, 'Total loss': 0.4447693613379501} | train loss {'Reaction outcome loss': 0.13713578811892477, 'Total loss': 0.13713578811892477}
2022-12-05 21:11:46,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:46,081 INFO:     Epoch: 55
2022-12-05 21:11:46,865 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45840713416421136, 'Total loss': 0.45840713416421136} | train loss {'Reaction outcome loss': 0.1364446132306437, 'Total loss': 0.1364446132306437}
2022-12-05 21:11:46,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:46,865 INFO:     Epoch: 56
2022-12-05 21:11:47,647 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4755184411309486, 'Total loss': 0.4755184411309486} | train loss {'Reaction outcome loss': 0.13725121120052014, 'Total loss': 0.13725121120052014}
2022-12-05 21:11:47,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:47,648 INFO:     Epoch: 57
2022-12-05 21:11:48,427 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44505260728819424, 'Total loss': 0.44505260728819424} | train loss {'Reaction outcome loss': 0.13813752157338818, 'Total loss': 0.13813752157338818}
2022-12-05 21:11:48,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:48,428 INFO:     Epoch: 58
2022-12-05 21:11:49,208 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45527537478957064, 'Total loss': 0.45527537478957064} | train loss {'Reaction outcome loss': 0.13489320715812997, 'Total loss': 0.13489320715812997}
2022-12-05 21:11:49,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:49,208 INFO:     Epoch: 59
2022-12-05 21:11:49,992 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4675620340330656, 'Total loss': 0.4675620340330656} | train loss {'Reaction outcome loss': 0.13519845406723316, 'Total loss': 0.13519845406723316}
2022-12-05 21:11:49,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:49,992 INFO:     Epoch: 60
2022-12-05 21:11:50,772 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4602164511763772, 'Total loss': 0.4602164511763772} | train loss {'Reaction outcome loss': 0.1310144362925384, 'Total loss': 0.1310144362925384}
2022-12-05 21:11:50,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:50,773 INFO:     Epoch: 61
2022-12-05 21:11:51,560 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45821247960245887, 'Total loss': 0.45821247960245887} | train loss {'Reaction outcome loss': 0.13490547622233384, 'Total loss': 0.13490547622233384}
2022-12-05 21:11:51,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:51,560 INFO:     Epoch: 62
2022-12-05 21:11:52,345 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46063438508399696, 'Total loss': 0.46063438508399696} | train loss {'Reaction outcome loss': 0.12957253030379165, 'Total loss': 0.12957253030379165}
2022-12-05 21:11:52,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:52,345 INFO:     Epoch: 63
2022-12-05 21:11:53,128 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4618201903825582, 'Total loss': 0.4618201903825582} | train loss {'Reaction outcome loss': 0.13045553183259412, 'Total loss': 0.13045553183259412}
2022-12-05 21:11:53,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:53,129 INFO:     Epoch: 64
2022-12-05 21:11:53,914 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4612091072770052, 'Total loss': 0.4612091072770052} | train loss {'Reaction outcome loss': 0.13071390820980133, 'Total loss': 0.13071390820980133}
2022-12-05 21:11:53,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:53,914 INFO:     Epoch: 65
2022-12-05 21:11:54,694 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44379993372185284, 'Total loss': 0.44379993372185284} | train loss {'Reaction outcome loss': 0.1278790686065789, 'Total loss': 0.1278790686065789}
2022-12-05 21:11:54,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:54,694 INFO:     Epoch: 66
2022-12-05 21:11:55,475 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4540446539257848, 'Total loss': 0.4540446539257848} | train loss {'Reaction outcome loss': 0.1282987314215327, 'Total loss': 0.1282987314215327}
2022-12-05 21:11:55,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:55,475 INFO:     Epoch: 67
2022-12-05 21:11:56,257 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47165457072646116, 'Total loss': 0.47165457072646116} | train loss {'Reaction outcome loss': 0.12659139386530904, 'Total loss': 0.12659139386530904}
2022-12-05 21:11:56,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:56,258 INFO:     Epoch: 68
2022-12-05 21:11:57,037 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46205991263999496, 'Total loss': 0.46205991263999496} | train loss {'Reaction outcome loss': 0.12962982529148337, 'Total loss': 0.12962982529148337}
2022-12-05 21:11:57,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:57,037 INFO:     Epoch: 69
2022-12-05 21:11:57,818 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4558936634729075, 'Total loss': 0.4558936634729075} | train loss {'Reaction outcome loss': 0.12628823393368024, 'Total loss': 0.12628823393368024}
2022-12-05 21:11:57,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:57,818 INFO:     Epoch: 70
2022-12-05 21:11:58,605 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4583201266305391, 'Total loss': 0.4583201266305391} | train loss {'Reaction outcome loss': 0.12516282853807825, 'Total loss': 0.12516282853807825}
2022-12-05 21:11:58,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:58,606 INFO:     Epoch: 71
2022-12-05 21:11:59,385 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4519243642341259, 'Total loss': 0.4519243642341259} | train loss {'Reaction outcome loss': 0.12473330363921332, 'Total loss': 0.12473330363921332}
2022-12-05 21:11:59,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:11:59,386 INFO:     Epoch: 72
2022-12-05 21:12:00,166 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46036646393842473, 'Total loss': 0.46036646393842473} | train loss {'Reaction outcome loss': 0.12488376627462443, 'Total loss': 0.12488376627462443}
2022-12-05 21:12:00,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:00,166 INFO:     Epoch: 73
2022-12-05 21:12:00,951 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44982261089391484, 'Total loss': 0.44982261089391484} | train loss {'Reaction outcome loss': 0.12261931349324887, 'Total loss': 0.12261931349324887}
2022-12-05 21:12:00,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:00,952 INFO:     Epoch: 74
2022-12-05 21:12:01,733 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45727335609668907, 'Total loss': 0.45727335609668907} | train loss {'Reaction outcome loss': 0.12413446434208604, 'Total loss': 0.12413446434208604}
2022-12-05 21:12:01,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:01,733 INFO:     Epoch: 75
2022-12-05 21:12:02,514 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45397366202154826, 'Total loss': 0.45397366202154826} | train loss {'Reaction outcome loss': 0.12347855223113763, 'Total loss': 0.12347855223113763}
2022-12-05 21:12:02,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:02,514 INFO:     Epoch: 76
2022-12-05 21:12:03,298 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4583607270967129, 'Total loss': 0.4583607270967129} | train loss {'Reaction outcome loss': 0.12120201872646442, 'Total loss': 0.12120201872646442}
2022-12-05 21:12:03,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:03,299 INFO:     Epoch: 77
2022-12-05 21:12:04,081 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4594215891042421, 'Total loss': 0.4594215891042421} | train loss {'Reaction outcome loss': 0.12509870509517793, 'Total loss': 0.12509870509517793}
2022-12-05 21:12:04,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:04,082 INFO:     Epoch: 78
2022-12-05 21:12:04,864 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45972083994122437, 'Total loss': 0.45972083994122437} | train loss {'Reaction outcome loss': 0.12107864891743807, 'Total loss': 0.12107864891743807}
2022-12-05 21:12:04,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:04,864 INFO:     Epoch: 79
2022-12-05 21:12:05,650 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45984102161817775, 'Total loss': 0.45984102161817775} | train loss {'Reaction outcome loss': 0.119067745321415, 'Total loss': 0.119067745321415}
2022-12-05 21:12:05,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:05,651 INFO:     Epoch: 80
2022-12-05 21:12:06,434 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4622011912423511, 'Total loss': 0.4622011912423511} | train loss {'Reaction outcome loss': 0.12108302338155688, 'Total loss': 0.12108302338155688}
2022-12-05 21:12:06,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:06,434 INFO:     Epoch: 81
2022-12-05 21:12:07,217 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4558696195829746, 'Total loss': 0.4558696195829746} | train loss {'Reaction outcome loss': 0.11976862787345394, 'Total loss': 0.11976862787345394}
2022-12-05 21:12:07,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:07,217 INFO:     Epoch: 82
2022-12-05 21:12:08,003 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46829064190387726, 'Total loss': 0.46829064190387726} | train loss {'Reaction outcome loss': 0.1194346898701042, 'Total loss': 0.1194346898701042}
2022-12-05 21:12:08,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:08,003 INFO:     Epoch: 83
2022-12-05 21:12:08,785 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46196411480737287, 'Total loss': 0.46196411480737287} | train loss {'Reaction outcome loss': 0.11952532364101318, 'Total loss': 0.11952532364101318}
2022-12-05 21:12:08,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:08,785 INFO:     Epoch: 84
2022-12-05 21:12:09,569 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45334943158682, 'Total loss': 0.45334943158682} | train loss {'Reaction outcome loss': 0.12129165263480095, 'Total loss': 0.12129165263480095}
2022-12-05 21:12:09,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:09,569 INFO:     Epoch: 85
2022-12-05 21:12:10,352 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44254009339005446, 'Total loss': 0.44254009339005446} | train loss {'Reaction outcome loss': 0.11735950493192697, 'Total loss': 0.11735950493192697}
2022-12-05 21:12:10,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:10,353 INFO:     Epoch: 86
2022-12-05 21:12:11,134 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4591671483114708, 'Total loss': 0.4591671483114708} | train loss {'Reaction outcome loss': 0.11723294908364044, 'Total loss': 0.11723294908364044}
2022-12-05 21:12:11,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:11,134 INFO:     Epoch: 87
2022-12-05 21:12:11,919 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4546276469563329, 'Total loss': 0.4546276469563329} | train loss {'Reaction outcome loss': 0.116703502219323, 'Total loss': 0.116703502219323}
2022-12-05 21:12:11,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:11,921 INFO:     Epoch: 88
2022-12-05 21:12:12,701 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46727484326029933, 'Total loss': 0.46727484326029933} | train loss {'Reaction outcome loss': 0.11630741407957355, 'Total loss': 0.11630741407957355}
2022-12-05 21:12:12,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:12,701 INFO:     Epoch: 89
2022-12-05 21:12:13,483 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45007590672304465, 'Total loss': 0.45007590672304465} | train loss {'Reaction outcome loss': 0.11677524605460587, 'Total loss': 0.11677524605460587}
2022-12-05 21:12:13,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:13,483 INFO:     Epoch: 90
2022-12-05 21:12:14,264 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45063919764618543, 'Total loss': 0.45063919764618543} | train loss {'Reaction outcome loss': 0.11622801550557135, 'Total loss': 0.11622801550557135}
2022-12-05 21:12:14,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:14,264 INFO:     Epoch: 91
2022-12-05 21:12:15,044 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46248552549717037, 'Total loss': 0.46248552549717037} | train loss {'Reaction outcome loss': 0.11357621912325382, 'Total loss': 0.11357621912325382}
2022-12-05 21:12:15,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:15,044 INFO:     Epoch: 92
2022-12-05 21:12:15,827 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44694031047266586, 'Total loss': 0.44694031047266586} | train loss {'Reaction outcome loss': 0.1146553262197947, 'Total loss': 0.1146553262197947}
2022-12-05 21:12:15,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:15,827 INFO:     Epoch: 93
2022-12-05 21:12:16,610 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4532343325919883, 'Total loss': 0.4532343325919883} | train loss {'Reaction outcome loss': 0.11381675938495481, 'Total loss': 0.11381675938495481}
2022-12-05 21:12:16,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:16,611 INFO:     Epoch: 94
2022-12-05 21:12:17,393 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4594275435042936, 'Total loss': 0.4594275435042936} | train loss {'Reaction outcome loss': 0.11472872567561562, 'Total loss': 0.11472872567561562}
2022-12-05 21:12:17,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:17,393 INFO:     Epoch: 95
2022-12-05 21:12:18,176 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45152613312699075, 'Total loss': 0.45152613312699075} | train loss {'Reaction outcome loss': 0.11412743606116073, 'Total loss': 0.11412743606116073}
2022-12-05 21:12:18,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:18,177 INFO:     Epoch: 96
2022-12-05 21:12:18,957 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4549363325241693, 'Total loss': 0.4549363325241693} | train loss {'Reaction outcome loss': 0.11337254325034798, 'Total loss': 0.11337254325034798}
2022-12-05 21:12:18,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:18,957 INFO:     Epoch: 97
2022-12-05 21:12:19,742 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45162983377312504, 'Total loss': 0.45162983377312504} | train loss {'Reaction outcome loss': 0.11291495289989427, 'Total loss': 0.11291495289989427}
2022-12-05 21:12:19,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:19,743 INFO:     Epoch: 98
2022-12-05 21:12:20,532 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46628324098365254, 'Total loss': 0.46628324098365254} | train loss {'Reaction outcome loss': 0.11434645679794618, 'Total loss': 0.11434645679794618}
2022-12-05 21:12:20,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:20,533 INFO:     Epoch: 99
2022-12-05 21:12:21,318 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4539530724287033, 'Total loss': 0.4539530724287033} | train loss {'Reaction outcome loss': 0.11389871390505893, 'Total loss': 0.11389871390505893}
2022-12-05 21:12:21,318 INFO:     Best model found after epoch 17 of 100.
2022-12-05 21:12:21,318 INFO:   Done with stage: TRAINING
2022-12-05 21:12:21,318 INFO:   Starting stage: EVALUATION
2022-12-05 21:12:21,455 INFO:   Done with stage: EVALUATION
2022-12-05 21:12:21,455 INFO:   Leaving out SEQ value Fold_4
2022-12-05 21:12:21,467 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:12:21,468 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:12:22,112 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:12:22,112 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:12:22,181 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:12:22,181 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:12:22,181 INFO:     No hyperparam tuning for this model
2022-12-05 21:12:22,181 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:12:22,181 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:12:22,182 INFO:     None feature selector for col prot
2022-12-05 21:12:22,182 INFO:     None feature selector for col prot
2022-12-05 21:12:22,182 INFO:     None feature selector for col prot
2022-12-05 21:12:22,183 INFO:     None feature selector for col chem
2022-12-05 21:12:22,183 INFO:     None feature selector for col chem
2022-12-05 21:12:22,183 INFO:     None feature selector for col chem
2022-12-05 21:12:22,183 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:12:22,183 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:12:22,185 INFO:     Number of params in model 215821
2022-12-05 21:12:22,188 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:12:22,188 INFO:   Starting stage: TRAINING
2022-12-05 21:12:22,248 INFO:     Val loss before train {'Reaction outcome loss': 1.074170390313322, 'Total loss': 1.074170390313322}
2022-12-05 21:12:22,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:22,248 INFO:     Epoch: 0
2022-12-05 21:12:23,042 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6647742932493036, 'Total loss': 0.6647742932493036} | train loss {'Reaction outcome loss': 0.7789456625940346, 'Total loss': 0.7789456625940346}
2022-12-05 21:12:23,043 INFO:     Found new best model at epoch 0
2022-12-05 21:12:23,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:23,043 INFO:     Epoch: 1
2022-12-05 21:12:23,834 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5785488255999305, 'Total loss': 0.5785488255999305} | train loss {'Reaction outcome loss': 0.5246769561534107, 'Total loss': 0.5246769561534107}
2022-12-05 21:12:23,834 INFO:     Found new best model at epoch 1
2022-12-05 21:12:23,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:23,835 INFO:     Epoch: 2
2022-12-05 21:12:24,628 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5423212031071837, 'Total loss': 0.5423212031071837} | train loss {'Reaction outcome loss': 0.4589462779492502, 'Total loss': 0.4589462779492502}
2022-12-05 21:12:24,628 INFO:     Found new best model at epoch 2
2022-12-05 21:12:24,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:24,629 INFO:     Epoch: 3
2022-12-05 21:12:25,426 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5136826763098891, 'Total loss': 0.5136826763098891} | train loss {'Reaction outcome loss': 0.422376952205713, 'Total loss': 0.422376952205713}
2022-12-05 21:12:25,426 INFO:     Found new best model at epoch 3
2022-12-05 21:12:25,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:25,427 INFO:     Epoch: 4
2022-12-05 21:12:26,220 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49895852228457277, 'Total loss': 0.49895852228457277} | train loss {'Reaction outcome loss': 0.3949980029896626, 'Total loss': 0.3949980029896626}
2022-12-05 21:12:26,220 INFO:     Found new best model at epoch 4
2022-12-05 21:12:26,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:26,221 INFO:     Epoch: 5
2022-12-05 21:12:27,013 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4922675144943324, 'Total loss': 0.4922675144943324} | train loss {'Reaction outcome loss': 0.3685862977540324, 'Total loss': 0.3685862977540324}
2022-12-05 21:12:27,013 INFO:     Found new best model at epoch 5
2022-12-05 21:12:27,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:27,014 INFO:     Epoch: 6
2022-12-05 21:12:27,804 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4887054484676231, 'Total loss': 0.4887054484676231} | train loss {'Reaction outcome loss': 0.3520655720400424, 'Total loss': 0.3520655720400424}
2022-12-05 21:12:27,804 INFO:     Found new best model at epoch 6
2022-12-05 21:12:27,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:27,805 INFO:     Epoch: 7
2022-12-05 21:12:28,595 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4887430742383003, 'Total loss': 0.4887430742383003} | train loss {'Reaction outcome loss': 0.33263328716701823, 'Total loss': 0.33263328716701823}
2022-12-05 21:12:28,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:28,595 INFO:     Epoch: 8
2022-12-05 21:12:29,384 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4799383661963723, 'Total loss': 0.4799383661963723} | train loss {'Reaction outcome loss': 0.318934515997134, 'Total loss': 0.318934515997134}
2022-12-05 21:12:29,385 INFO:     Found new best model at epoch 8
2022-12-05 21:12:29,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:29,385 INFO:     Epoch: 9
2022-12-05 21:12:30,178 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4761758731170134, 'Total loss': 0.4761758731170134} | train loss {'Reaction outcome loss': 0.3100753289605924, 'Total loss': 0.3100753289605924}
2022-12-05 21:12:30,179 INFO:     Found new best model at epoch 9
2022-12-05 21:12:30,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:30,180 INFO:     Epoch: 10
2022-12-05 21:12:30,972 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48366462777961383, 'Total loss': 0.48366462777961383} | train loss {'Reaction outcome loss': 0.2929409528490503, 'Total loss': 0.2929409528490503}
2022-12-05 21:12:30,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:30,972 INFO:     Epoch: 11
2022-12-05 21:12:31,762 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4770738753405484, 'Total loss': 0.4770738753405484} | train loss {'Reaction outcome loss': 0.27923231551740396, 'Total loss': 0.27923231551740396}
2022-12-05 21:12:31,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:31,762 INFO:     Epoch: 12
2022-12-05 21:12:32,552 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49216459081931546, 'Total loss': 0.49216459081931546} | train loss {'Reaction outcome loss': 0.2720775693232714, 'Total loss': 0.2720775693232714}
2022-12-05 21:12:32,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:32,552 INFO:     Epoch: 13
2022-12-05 21:12:33,342 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47797996720129793, 'Total loss': 0.47797996720129793} | train loss {'Reaction outcome loss': 0.26567067473048445, 'Total loss': 0.26567067473048445}
2022-12-05 21:12:33,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:33,342 INFO:     Epoch: 14
2022-12-05 21:12:34,136 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.477397948842157, 'Total loss': 0.477397948842157} | train loss {'Reaction outcome loss': 0.24995215716752928, 'Total loss': 0.24995215716752928}
2022-12-05 21:12:34,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:34,136 INFO:     Epoch: 15
2022-12-05 21:12:34,931 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48043507879430597, 'Total loss': 0.48043507879430597} | train loss {'Reaction outcome loss': 0.2434630253114681, 'Total loss': 0.2434630253114681}
2022-12-05 21:12:34,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:34,931 INFO:     Epoch: 16
2022-12-05 21:12:35,724 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.483571917834607, 'Total loss': 0.483571917834607} | train loss {'Reaction outcome loss': 0.23596757274452854, 'Total loss': 0.23596757274452854}
2022-12-05 21:12:35,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:35,725 INFO:     Epoch: 17
2022-12-05 21:12:36,517 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4812649691646749, 'Total loss': 0.4812649691646749} | train loss {'Reaction outcome loss': 0.2287537574990528, 'Total loss': 0.2287537574990528}
2022-12-05 21:12:36,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:36,517 INFO:     Epoch: 18
2022-12-05 21:12:37,308 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48434948988936166, 'Total loss': 0.48434948988936166} | train loss {'Reaction outcome loss': 0.22148607591325456, 'Total loss': 0.22148607591325456}
2022-12-05 21:12:37,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:37,309 INFO:     Epoch: 19
2022-12-05 21:12:38,101 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4866066144948656, 'Total loss': 0.4866066144948656} | train loss {'Reaction outcome loss': 0.21687954939856582, 'Total loss': 0.21687954939856582}
2022-12-05 21:12:38,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:38,101 INFO:     Epoch: 20
2022-12-05 21:12:38,892 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49110793288458476, 'Total loss': 0.49110793288458476} | train loss {'Reaction outcome loss': 0.21020565785256476, 'Total loss': 0.21020565785256476}
2022-12-05 21:12:38,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:38,893 INFO:     Epoch: 21
2022-12-05 21:12:39,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4981089234352112, 'Total loss': 0.4981089234352112} | train loss {'Reaction outcome loss': 0.20684986033661645, 'Total loss': 0.20684986033661645}
2022-12-05 21:12:39,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:39,685 INFO:     Epoch: 22
2022-12-05 21:12:40,476 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4929957091808319, 'Total loss': 0.4929957091808319} | train loss {'Reaction outcome loss': 0.2041487610731123, 'Total loss': 0.2041487610731123}
2022-12-05 21:12:40,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:40,476 INFO:     Epoch: 23
2022-12-05 21:12:41,267 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4922979118471796, 'Total loss': 0.4922979118471796} | train loss {'Reaction outcome loss': 0.19963416193238637, 'Total loss': 0.19963416193238637}
2022-12-05 21:12:41,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:41,268 INFO:     Epoch: 24
2022-12-05 21:12:42,059 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4931352104653012, 'Total loss': 0.4931352104653012} | train loss {'Reaction outcome loss': 0.19901344491364925, 'Total loss': 0.19901344491364925}
2022-12-05 21:12:42,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:42,059 INFO:     Epoch: 25
2022-12-05 21:12:42,849 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49474370581182564, 'Total loss': 0.49474370581182564} | train loss {'Reaction outcome loss': 0.1883970622344674, 'Total loss': 0.1883970622344674}
2022-12-05 21:12:42,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:42,850 INFO:     Epoch: 26
2022-12-05 21:12:43,640 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48680856823921204, 'Total loss': 0.48680856823921204} | train loss {'Reaction outcome loss': 0.18439283371367585, 'Total loss': 0.18439283371367585}
2022-12-05 21:12:43,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:43,640 INFO:     Epoch: 27
2022-12-05 21:12:44,433 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48924932832067664, 'Total loss': 0.48924932832067664} | train loss {'Reaction outcome loss': 0.1812751263131195, 'Total loss': 0.1812751263131195}
2022-12-05 21:12:44,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:44,433 INFO:     Epoch: 28
2022-12-05 21:12:45,228 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4863865642215718, 'Total loss': 0.4863865642215718} | train loss {'Reaction outcome loss': 0.17822824406101997, 'Total loss': 0.17822824406101997}
2022-12-05 21:12:45,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:45,229 INFO:     Epoch: 29
2022-12-05 21:12:46,019 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4943900846622207, 'Total loss': 0.4943900846622207} | train loss {'Reaction outcome loss': 0.17348233511603553, 'Total loss': 0.17348233511603553}
2022-12-05 21:12:46,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:46,019 INFO:     Epoch: 30
2022-12-05 21:12:46,811 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5090480917556719, 'Total loss': 0.5090480917556719} | train loss {'Reaction outcome loss': 0.17132575028700384, 'Total loss': 0.17132575028700384}
2022-12-05 21:12:46,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:46,812 INFO:     Epoch: 31
2022-12-05 21:12:47,604 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4847498207607053, 'Total loss': 0.4847498207607053} | train loss {'Reaction outcome loss': 0.17116749371865742, 'Total loss': 0.17116749371865742}
2022-12-05 21:12:47,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:47,605 INFO:     Epoch: 32
2022-12-05 21:12:48,394 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.490927516059442, 'Total loss': 0.490927516059442} | train loss {'Reaction outcome loss': 0.16836380977032758, 'Total loss': 0.16836380977032758}
2022-12-05 21:12:48,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:48,394 INFO:     Epoch: 33
2022-12-05 21:12:49,186 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49419031850993633, 'Total loss': 0.49419031850993633} | train loss {'Reaction outcome loss': 0.16888386708672953, 'Total loss': 0.16888386708672953}
2022-12-05 21:12:49,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:49,187 INFO:     Epoch: 34
2022-12-05 21:12:49,977 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49608893049034203, 'Total loss': 0.49608893049034203} | train loss {'Reaction outcome loss': 0.16534517744654104, 'Total loss': 0.16534517744654104}
2022-12-05 21:12:49,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:49,977 INFO:     Epoch: 35
2022-12-05 21:12:50,772 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.500599817796187, 'Total loss': 0.500599817796187} | train loss {'Reaction outcome loss': 0.16301714880052606, 'Total loss': 0.16301714880052606}
2022-12-05 21:12:50,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:50,773 INFO:     Epoch: 36
2022-12-05 21:12:51,562 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4968011484227397, 'Total loss': 0.4968011484227397} | train loss {'Reaction outcome loss': 0.1652192831160086, 'Total loss': 0.1652192831160086}
2022-12-05 21:12:51,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:51,562 INFO:     Epoch: 37
2022-12-05 21:12:52,352 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5010530173101209, 'Total loss': 0.5010530173101209} | train loss {'Reaction outcome loss': 0.16072865257318686, 'Total loss': 0.16072865257318686}
2022-12-05 21:12:52,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:52,352 INFO:     Epoch: 38
2022-12-05 21:12:53,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5162722102620385, 'Total loss': 0.5162722102620385} | train loss {'Reaction outcome loss': 0.15567613065220143, 'Total loss': 0.15567613065220143}
2022-12-05 21:12:53,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:53,144 INFO:     Epoch: 39
2022-12-05 21:12:53,933 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5164022838527506, 'Total loss': 0.5164022838527506} | train loss {'Reaction outcome loss': 0.1525991121014799, 'Total loss': 0.1525991121014799}
2022-12-05 21:12:53,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:53,934 INFO:     Epoch: 40
2022-12-05 21:12:54,724 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5247228020294146, 'Total loss': 0.5247228020294146} | train loss {'Reaction outcome loss': 0.1564578137922323, 'Total loss': 0.1564578137922323}
2022-12-05 21:12:54,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:54,724 INFO:     Epoch: 41
2022-12-05 21:12:55,522 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5138751139694994, 'Total loss': 0.5138751139694994} | train loss {'Reaction outcome loss': 0.1576531440479613, 'Total loss': 0.1576531440479613}
2022-12-05 21:12:55,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:55,522 INFO:     Epoch: 42
2022-12-05 21:12:56,317 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4997065013105219, 'Total loss': 0.4997065013105219} | train loss {'Reaction outcome loss': 0.15192056705549298, 'Total loss': 0.15192056705549298}
2022-12-05 21:12:56,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:56,317 INFO:     Epoch: 43
2022-12-05 21:12:57,107 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5048078227449547, 'Total loss': 0.5048078227449547} | train loss {'Reaction outcome loss': 0.14927304987814505, 'Total loss': 0.14927304987814505}
2022-12-05 21:12:57,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:57,107 INFO:     Epoch: 44
2022-12-05 21:12:57,906 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5027470307593996, 'Total loss': 0.5027470307593996} | train loss {'Reaction outcome loss': 0.14788835073787313, 'Total loss': 0.14788835073787313}
2022-12-05 21:12:57,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:57,906 INFO:     Epoch: 45
2022-12-05 21:12:58,699 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5005285722965543, 'Total loss': 0.5005285722965543} | train loss {'Reaction outcome loss': 0.1468853291184434, 'Total loss': 0.1468853291184434}
2022-12-05 21:12:58,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:58,699 INFO:     Epoch: 46
2022-12-05 21:12:59,491 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5132386115464297, 'Total loss': 0.5132386115464297} | train loss {'Reaction outcome loss': 0.14821073769587978, 'Total loss': 0.14821073769587978}
2022-12-05 21:12:59,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:12:59,492 INFO:     Epoch: 47
2022-12-05 21:13:00,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5064440750601616, 'Total loss': 0.5064440750601616} | train loss {'Reaction outcome loss': 0.14327373342053126, 'Total loss': 0.14327373342053126}
2022-12-05 21:13:00,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:00,287 INFO:     Epoch: 48
2022-12-05 21:13:01,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5323534377596595, 'Total loss': 0.5323534377596595} | train loss {'Reaction outcome loss': 0.1414091204894473, 'Total loss': 0.1414091204894473}
2022-12-05 21:13:01,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:01,077 INFO:     Epoch: 49
2022-12-05 21:13:01,869 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5116500532762571, 'Total loss': 0.5116500532762571} | train loss {'Reaction outcome loss': 0.14941872427096733, 'Total loss': 0.14941872427096733}
2022-12-05 21:13:01,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:01,870 INFO:     Epoch: 50
2022-12-05 21:13:02,667 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5086197795515711, 'Total loss': 0.5086197795515711} | train loss {'Reaction outcome loss': 0.14088454805934322, 'Total loss': 0.14088454805934322}
2022-12-05 21:13:02,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:02,667 INFO:     Epoch: 51
2022-12-05 21:13:03,460 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5201379341835325, 'Total loss': 0.5201379341835325} | train loss {'Reaction outcome loss': 0.13836315040842362, 'Total loss': 0.13836315040842362}
2022-12-05 21:13:03,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:03,460 INFO:     Epoch: 52
2022-12-05 21:13:04,252 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5023740110072222, 'Total loss': 0.5023740110072222} | train loss {'Reaction outcome loss': 0.13645402872595588, 'Total loss': 0.13645402872595588}
2022-12-05 21:13:04,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:04,252 INFO:     Epoch: 53
2022-12-05 21:13:05,047 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5258766676891934, 'Total loss': 0.5258766676891934} | train loss {'Reaction outcome loss': 0.13812585549828735, 'Total loss': 0.13812585549828735}
2022-12-05 21:13:05,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:05,047 INFO:     Epoch: 54
2022-12-05 21:13:05,846 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5345973450351845, 'Total loss': 0.5345973450351845} | train loss {'Reaction outcome loss': 0.1391230825719382, 'Total loss': 0.1391230825719382}
2022-12-05 21:13:05,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:05,847 INFO:     Epoch: 55
2022-12-05 21:13:06,640 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5099664384668524, 'Total loss': 0.5099664384668524} | train loss {'Reaction outcome loss': 0.13980046722958778, 'Total loss': 0.13980046722958778}
2022-12-05 21:13:06,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:06,640 INFO:     Epoch: 56
2022-12-05 21:13:07,433 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.508304008028724, 'Total loss': 0.508304008028724} | train loss {'Reaction outcome loss': 0.13599021020175717, 'Total loss': 0.13599021020175717}
2022-12-05 21:13:07,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:07,434 INFO:     Epoch: 57
2022-12-05 21:13:08,232 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5010790811343626, 'Total loss': 0.5010790811343626} | train loss {'Reaction outcome loss': 0.13354650974228435, 'Total loss': 0.13354650974228435}
2022-12-05 21:13:08,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:08,232 INFO:     Epoch: 58
2022-12-05 21:13:09,025 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5003805238414895, 'Total loss': 0.5003805238414895} | train loss {'Reaction outcome loss': 0.1335821079744426, 'Total loss': 0.1335821079744426}
2022-12-05 21:13:09,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:09,026 INFO:     Epoch: 59
2022-12-05 21:13:09,821 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5153310041535984, 'Total loss': 0.5153310041535984} | train loss {'Reaction outcome loss': 0.13335082609100862, 'Total loss': 0.13335082609100862}
2022-12-05 21:13:09,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:09,821 INFO:     Epoch: 60
2022-12-05 21:13:10,613 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5117922570895065, 'Total loss': 0.5117922570895065} | train loss {'Reaction outcome loss': 0.13382061412920873, 'Total loss': 0.13382061412920873}
2022-12-05 21:13:10,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:10,614 INFO:     Epoch: 61
2022-12-05 21:13:11,408 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5144073197787459, 'Total loss': 0.5144073197787459} | train loss {'Reaction outcome loss': 0.13184035886649367, 'Total loss': 0.13184035886649367}
2022-12-05 21:13:11,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:11,408 INFO:     Epoch: 62
2022-12-05 21:13:12,206 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5259630097584291, 'Total loss': 0.5259630097584291} | train loss {'Reaction outcome loss': 0.13008488143081606, 'Total loss': 0.13008488143081606}
2022-12-05 21:13:12,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:12,206 INFO:     Epoch: 63
2022-12-05 21:13:13,005 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5159980571744117, 'Total loss': 0.5159980571744117} | train loss {'Reaction outcome loss': 0.13040591651189182, 'Total loss': 0.13040591651189182}
2022-12-05 21:13:13,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:13,005 INFO:     Epoch: 64
2022-12-05 21:13:13,799 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5074993520975113, 'Total loss': 0.5074993520975113} | train loss {'Reaction outcome loss': 0.133996840006472, 'Total loss': 0.133996840006472}
2022-12-05 21:13:13,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:13,800 INFO:     Epoch: 65
2022-12-05 21:13:14,592 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5290645421905951, 'Total loss': 0.5290645421905951} | train loss {'Reaction outcome loss': 0.12967988267599376, 'Total loss': 0.12967988267599376}
2022-12-05 21:13:14,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:14,593 INFO:     Epoch: 66
2022-12-05 21:13:15,383 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5140970349311829, 'Total loss': 0.5140970349311829} | train loss {'Reaction outcome loss': 0.1306663559003156, 'Total loss': 0.1306663559003156}
2022-12-05 21:13:15,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:15,383 INFO:     Epoch: 67
2022-12-05 21:13:16,179 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4971238151192665, 'Total loss': 0.4971238151192665} | train loss {'Reaction outcome loss': 0.12941076513379812, 'Total loss': 0.12941076513379812}
2022-12-05 21:13:16,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:16,179 INFO:     Epoch: 68
2022-12-05 21:13:16,969 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5080507695674896, 'Total loss': 0.5080507695674896} | train loss {'Reaction outcome loss': 0.12866301247133657, 'Total loss': 0.12866301247133657}
2022-12-05 21:13:16,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:16,969 INFO:     Epoch: 69
2022-12-05 21:13:17,760 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5123919649896297, 'Total loss': 0.5123919649896297} | train loss {'Reaction outcome loss': 0.12769641354279443, 'Total loss': 0.12769641354279443}
2022-12-05 21:13:17,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:17,761 INFO:     Epoch: 70
2022-12-05 21:13:18,554 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5104390768842264, 'Total loss': 0.5104390768842264} | train loss {'Reaction outcome loss': 0.13084587950998472, 'Total loss': 0.13084587950998472}
2022-12-05 21:13:18,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:18,554 INFO:     Epoch: 71
2022-12-05 21:13:19,347 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5256735756993294, 'Total loss': 0.5256735756993294} | train loss {'Reaction outcome loss': 0.13236547151376843, 'Total loss': 0.13236547151376843}
2022-12-05 21:13:19,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:19,347 INFO:     Epoch: 72
2022-12-05 21:13:20,142 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5128142723644321, 'Total loss': 0.5128142723644321} | train loss {'Reaction outcome loss': 0.12907421687308715, 'Total loss': 0.12907421687308715}
2022-12-05 21:13:20,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:20,143 INFO:     Epoch: 73
2022-12-05 21:13:20,936 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.515328062698245, 'Total loss': 0.515328062698245} | train loss {'Reaction outcome loss': 0.12664137523327218, 'Total loss': 0.12664137523327218}
2022-12-05 21:13:20,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:20,936 INFO:     Epoch: 74
2022-12-05 21:13:21,727 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5109224353324283, 'Total loss': 0.5109224353324283} | train loss {'Reaction outcome loss': 0.12454245136183524, 'Total loss': 0.12454245136183524}
2022-12-05 21:13:21,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:21,728 INFO:     Epoch: 75
2022-12-05 21:13:22,519 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5092438137666746, 'Total loss': 0.5092438137666746} | train loss {'Reaction outcome loss': 0.12659599078509973, 'Total loss': 0.12659599078509973}
2022-12-05 21:13:22,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:22,519 INFO:     Epoch: 76
2022-12-05 21:13:23,309 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5146812403743918, 'Total loss': 0.5146812403743918} | train loss {'Reaction outcome loss': 0.1270983762104019, 'Total loss': 0.1270983762104019}
2022-12-05 21:13:23,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:23,309 INFO:     Epoch: 77
2022-12-05 21:13:24,102 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5308755182407119, 'Total loss': 0.5308755182407119} | train loss {'Reaction outcome loss': 0.12704654416231523, 'Total loss': 0.12704654416231523}
2022-12-05 21:13:24,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:24,102 INFO:     Epoch: 78
2022-12-05 21:13:24,892 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5250502504747022, 'Total loss': 0.5250502504747022} | train loss {'Reaction outcome loss': 0.12468325227559336, 'Total loss': 0.12468325227559336}
2022-12-05 21:13:24,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:24,893 INFO:     Epoch: 79
2022-12-05 21:13:25,683 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5145770287649198, 'Total loss': 0.5145770287649198} | train loss {'Reaction outcome loss': 0.12556725201693736, 'Total loss': 0.12556725201693736}
2022-12-05 21:13:25,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:25,683 INFO:     Epoch: 80
2022-12-05 21:13:26,479 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5341125306758013, 'Total loss': 0.5341125306758013} | train loss {'Reaction outcome loss': 0.12258582791645337, 'Total loss': 0.12258582791645337}
2022-12-05 21:13:26,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:26,479 INFO:     Epoch: 81
2022-12-05 21:13:27,272 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5112842504273761, 'Total loss': 0.5112842504273761} | train loss {'Reaction outcome loss': 0.12151032944656683, 'Total loss': 0.12151032944656683}
2022-12-05 21:13:27,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:27,272 INFO:     Epoch: 82
2022-12-05 21:13:28,062 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5082397701388056, 'Total loss': 0.5082397701388056} | train loss {'Reaction outcome loss': 0.1210579207451705, 'Total loss': 0.1210579207451705}
2022-12-05 21:13:28,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:28,062 INFO:     Epoch: 83
2022-12-05 21:13:28,854 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5073126967657696, 'Total loss': 0.5073126967657696} | train loss {'Reaction outcome loss': 0.1202894759454919, 'Total loss': 0.1202894759454919}
2022-12-05 21:13:28,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:28,854 INFO:     Epoch: 84
2022-12-05 21:13:29,644 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5128469399430535, 'Total loss': 0.5128469399430535} | train loss {'Reaction outcome loss': 0.12280780319803157, 'Total loss': 0.12280780319803157}
2022-12-05 21:13:29,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:29,644 INFO:     Epoch: 85
2022-12-05 21:13:30,434 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5307544442740354, 'Total loss': 0.5307544442740354} | train loss {'Reaction outcome loss': 0.12408928153470822, 'Total loss': 0.12408928153470822}
2022-12-05 21:13:30,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:30,435 INFO:     Epoch: 86
2022-12-05 21:13:31,227 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5241719596087933, 'Total loss': 0.5241719596087933} | train loss {'Reaction outcome loss': 0.1221629510546925, 'Total loss': 0.1221629510546925}
2022-12-05 21:13:31,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:31,228 INFO:     Epoch: 87
2022-12-05 21:13:32,021 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5168369510634379, 'Total loss': 0.5168369510634379} | train loss {'Reaction outcome loss': 0.12138693354720333, 'Total loss': 0.12138693354720333}
2022-12-05 21:13:32,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:32,021 INFO:     Epoch: 88
2022-12-05 21:13:32,813 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5121634345162999, 'Total loss': 0.5121634345162999} | train loss {'Reaction outcome loss': 0.11873526698890847, 'Total loss': 0.11873526698890847}
2022-12-05 21:13:32,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:32,814 INFO:     Epoch: 89
2022-12-05 21:13:33,605 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5176725726235997, 'Total loss': 0.5176725726235997} | train loss {'Reaction outcome loss': 0.12076934441350974, 'Total loss': 0.12076934441350974}
2022-12-05 21:13:33,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:33,605 INFO:     Epoch: 90
2022-12-05 21:13:34,397 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.533846814439378, 'Total loss': 0.533846814439378} | train loss {'Reaction outcome loss': 0.12161426763860923, 'Total loss': 0.12161426763860923}
2022-12-05 21:13:34,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:34,397 INFO:     Epoch: 91
2022-12-05 21:13:35,189 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5105804032222792, 'Total loss': 0.5105804032222792} | train loss {'Reaction outcome loss': 0.12117931667184137, 'Total loss': 0.12117931667184137}
2022-12-05 21:13:35,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:35,189 INFO:     Epoch: 92
2022-12-05 21:13:35,981 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5144453167238019, 'Total loss': 0.5144453167238019} | train loss {'Reaction outcome loss': 0.11839301657376562, 'Total loss': 0.11839301657376562}
2022-12-05 21:13:35,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:35,981 INFO:     Epoch: 93
2022-12-05 21:13:36,778 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5114892457019199, 'Total loss': 0.5114892457019199} | train loss {'Reaction outcome loss': 0.11979297508841695, 'Total loss': 0.11979297508841695}
2022-12-05 21:13:36,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:36,778 INFO:     Epoch: 94
2022-12-05 21:13:37,573 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5198145292022012, 'Total loss': 0.5198145292022012} | train loss {'Reaction outcome loss': 0.11969240643988978, 'Total loss': 0.11969240643988978}
2022-12-05 21:13:37,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:37,573 INFO:     Epoch: 95
2022-12-05 21:13:38,366 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5057777955450795, 'Total loss': 0.5057777955450795} | train loss {'Reaction outcome loss': 0.11987775521963714, 'Total loss': 0.11987775521963714}
2022-12-05 21:13:38,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:38,366 INFO:     Epoch: 96
2022-12-05 21:13:39,164 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5305851677601988, 'Total loss': 0.5305851677601988} | train loss {'Reaction outcome loss': 0.11691982274863733, 'Total loss': 0.11691982274863733}
2022-12-05 21:13:39,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:39,165 INFO:     Epoch: 97
2022-12-05 21:13:39,960 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5088269964537837, 'Total loss': 0.5088269964537837} | train loss {'Reaction outcome loss': 0.11617094559759007, 'Total loss': 0.11617094559759007}
2022-12-05 21:13:39,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:39,961 INFO:     Epoch: 98
2022-12-05 21:13:40,758 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5266544297337532, 'Total loss': 0.5266544297337532} | train loss {'Reaction outcome loss': 0.11854946449859, 'Total loss': 0.11854946449859}
2022-12-05 21:13:40,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:40,758 INFO:     Epoch: 99
2022-12-05 21:13:41,549 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5044326843185858, 'Total loss': 0.5044326843185858} | train loss {'Reaction outcome loss': 0.11688259377395017, 'Total loss': 0.11688259377395017}
2022-12-05 21:13:41,549 INFO:     Best model found after epoch 10 of 100.
2022-12-05 21:13:41,549 INFO:   Done with stage: TRAINING
2022-12-05 21:13:41,550 INFO:   Starting stage: EVALUATION
2022-12-05 21:13:41,675 INFO:   Done with stage: EVALUATION
2022-12-05 21:13:41,675 INFO:   Leaving out SEQ value Fold_5
2022-12-05 21:13:41,688 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:13:41,688 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:13:42,327 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:13:42,328 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:13:42,397 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:13:42,397 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:13:42,397 INFO:     No hyperparam tuning for this model
2022-12-05 21:13:42,397 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:13:42,398 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:13:42,398 INFO:     None feature selector for col prot
2022-12-05 21:13:42,398 INFO:     None feature selector for col prot
2022-12-05 21:13:42,399 INFO:     None feature selector for col prot
2022-12-05 21:13:42,399 INFO:     None feature selector for col chem
2022-12-05 21:13:42,399 INFO:     None feature selector for col chem
2022-12-05 21:13:42,399 INFO:     None feature selector for col chem
2022-12-05 21:13:42,399 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:13:42,399 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:13:42,401 INFO:     Number of params in model 215821
2022-12-05 21:13:42,404 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:13:42,404 INFO:   Starting stage: TRAINING
2022-12-05 21:13:42,465 INFO:     Val loss before train {'Reaction outcome loss': 1.0006607283245434, 'Total loss': 1.0006607283245434}
2022-12-05 21:13:42,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:42,465 INFO:     Epoch: 0
2022-12-05 21:13:43,261 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5693735771558501, 'Total loss': 0.5693735771558501} | train loss {'Reaction outcome loss': 0.8039011849686202, 'Total loss': 0.8039011849686202}
2022-12-05 21:13:43,261 INFO:     Found new best model at epoch 0
2022-12-05 21:13:43,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:43,262 INFO:     Epoch: 1
2022-12-05 21:13:44,052 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4790818745439703, 'Total loss': 0.4790818745439703} | train loss {'Reaction outcome loss': 0.5534574982487721, 'Total loss': 0.5534574982487721}
2022-12-05 21:13:44,052 INFO:     Found new best model at epoch 1
2022-12-05 21:13:44,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:44,053 INFO:     Epoch: 2
2022-12-05 21:13:44,846 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45114274661649356, 'Total loss': 0.45114274661649356} | train loss {'Reaction outcome loss': 0.4831610556073517, 'Total loss': 0.4831610556073517}
2022-12-05 21:13:44,847 INFO:     Found new best model at epoch 2
2022-12-05 21:13:44,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:44,848 INFO:     Epoch: 3
2022-12-05 21:13:45,645 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42398584058338945, 'Total loss': 0.42398584058338945} | train loss {'Reaction outcome loss': 0.4481456373867236, 'Total loss': 0.4481456373867236}
2022-12-05 21:13:45,646 INFO:     Found new best model at epoch 3
2022-12-05 21:13:45,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:45,646 INFO:     Epoch: 4
2022-12-05 21:13:46,449 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4073472520844503, 'Total loss': 0.4073472520844503} | train loss {'Reaction outcome loss': 0.41329941189723457, 'Total loss': 0.41329941189723457}
2022-12-05 21:13:46,449 INFO:     Found new best model at epoch 4
2022-12-05 21:13:46,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:46,450 INFO:     Epoch: 5
2022-12-05 21:13:47,247 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40838588841936807, 'Total loss': 0.40838588841936807} | train loss {'Reaction outcome loss': 0.38865817944530534, 'Total loss': 0.38865817944530534}
2022-12-05 21:13:47,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:47,247 INFO:     Epoch: 6
2022-12-05 21:13:48,039 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39725950157100504, 'Total loss': 0.39725950157100504} | train loss {'Reaction outcome loss': 0.3678614734426925, 'Total loss': 0.3678614734426925}
2022-12-05 21:13:48,039 INFO:     Found new best model at epoch 6
2022-12-05 21:13:48,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:48,040 INFO:     Epoch: 7
2022-12-05 21:13:48,835 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39090917936780234, 'Total loss': 0.39090917936780234} | train loss {'Reaction outcome loss': 0.3470175474399497, 'Total loss': 0.3470175474399497}
2022-12-05 21:13:48,835 INFO:     Found new best model at epoch 7
2022-12-05 21:13:48,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:48,836 INFO:     Epoch: 8
2022-12-05 21:13:49,630 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38885886018926447, 'Total loss': 0.38885886018926447} | train loss {'Reaction outcome loss': 0.33234571020763654, 'Total loss': 0.33234571020763654}
2022-12-05 21:13:49,630 INFO:     Found new best model at epoch 8
2022-12-05 21:13:49,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:49,631 INFO:     Epoch: 9
2022-12-05 21:13:50,423 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3916859481145035, 'Total loss': 0.3916859481145035} | train loss {'Reaction outcome loss': 0.31972489638729135, 'Total loss': 0.31972489638729135}
2022-12-05 21:13:50,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:50,423 INFO:     Epoch: 10
2022-12-05 21:13:51,214 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38117223436182196, 'Total loss': 0.38117223436182196} | train loss {'Reaction outcome loss': 0.310661108116148, 'Total loss': 0.310661108116148}
2022-12-05 21:13:51,215 INFO:     Found new best model at epoch 10
2022-12-05 21:13:51,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:51,216 INFO:     Epoch: 11
2022-12-05 21:13:52,010 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37738768688657065, 'Total loss': 0.37738768688657065} | train loss {'Reaction outcome loss': 0.2964363061947379, 'Total loss': 0.2964363061947379}
2022-12-05 21:13:52,010 INFO:     Found new best model at epoch 11
2022-12-05 21:13:52,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:52,011 INFO:     Epoch: 12
2022-12-05 21:13:52,804 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3832637566057118, 'Total loss': 0.3832637566057118} | train loss {'Reaction outcome loss': 0.28562657133891034, 'Total loss': 0.28562657133891034}
2022-12-05 21:13:52,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:52,805 INFO:     Epoch: 13
2022-12-05 21:13:53,596 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37912253493612463, 'Total loss': 0.37912253493612463} | train loss {'Reaction outcome loss': 0.2758501709593452, 'Total loss': 0.2758501709593452}
2022-12-05 21:13:53,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:53,597 INFO:     Epoch: 14
2022-12-05 21:13:54,390 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37097007544203237, 'Total loss': 0.37097007544203237} | train loss {'Reaction outcome loss': 0.264199403073141, 'Total loss': 0.264199403073141}
2022-12-05 21:13:54,391 INFO:     Found new best model at epoch 14
2022-12-05 21:13:54,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:54,392 INFO:     Epoch: 15
2022-12-05 21:13:55,188 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37301310016350314, 'Total loss': 0.37301310016350314} | train loss {'Reaction outcome loss': 0.2570263617615468, 'Total loss': 0.2570263617615468}
2022-12-05 21:13:55,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:55,188 INFO:     Epoch: 16
2022-12-05 21:13:55,982 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3665422400967641, 'Total loss': 0.3665422400967641} | train loss {'Reaction outcome loss': 0.2511526867747307, 'Total loss': 0.2511526867747307}
2022-12-05 21:13:55,982 INFO:     Found new best model at epoch 16
2022-12-05 21:13:55,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:55,983 INFO:     Epoch: 17
2022-12-05 21:13:56,775 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3596748509867625, 'Total loss': 0.3596748509867625} | train loss {'Reaction outcome loss': 0.23911710207912362, 'Total loss': 0.23911710207912362}
2022-12-05 21:13:56,775 INFO:     Found new best model at epoch 17
2022-12-05 21:13:56,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:56,776 INFO:     Epoch: 18
2022-12-05 21:13:57,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3943627124482935, 'Total loss': 0.3943627124482935} | train loss {'Reaction outcome loss': 0.2337667752690764, 'Total loss': 0.2337667752690764}
2022-12-05 21:13:57,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:57,568 INFO:     Epoch: 19
2022-12-05 21:13:58,358 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37533233585682785, 'Total loss': 0.37533233585682785} | train loss {'Reaction outcome loss': 0.2257967508082921, 'Total loss': 0.2257967508082921}
2022-12-05 21:13:58,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:58,359 INFO:     Epoch: 20
2022-12-05 21:13:59,151 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38397718813608994, 'Total loss': 0.38397718813608994} | train loss {'Reaction outcome loss': 0.22477861373168737, 'Total loss': 0.22477861373168737}
2022-12-05 21:13:59,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:59,152 INFO:     Epoch: 21
2022-12-05 21:13:59,951 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3996901417320425, 'Total loss': 0.3996901417320425} | train loss {'Reaction outcome loss': 0.22136594895235742, 'Total loss': 0.22136594895235742}
2022-12-05 21:13:59,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:13:59,951 INFO:     Epoch: 22
2022-12-05 21:14:00,744 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38202933831648395, 'Total loss': 0.38202933831648395} | train loss {'Reaction outcome loss': 0.21242663478818138, 'Total loss': 0.21242663478818138}
2022-12-05 21:14:00,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:00,744 INFO:     Epoch: 23
2022-12-05 21:14:01,535 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3855850867588412, 'Total loss': 0.3855850867588412} | train loss {'Reaction outcome loss': 0.20495835034108836, 'Total loss': 0.20495835034108836}
2022-12-05 21:14:01,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:01,536 INFO:     Epoch: 24
2022-12-05 21:14:02,328 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38299865732816135, 'Total loss': 0.38299865732816135} | train loss {'Reaction outcome loss': 0.2072841503962814, 'Total loss': 0.2072841503962814}
2022-12-05 21:14:02,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:02,328 INFO:     Epoch: 25
2022-12-05 21:14:03,120 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39161171120676125, 'Total loss': 0.39161171120676125} | train loss {'Reaction outcome loss': 0.20105456155046128, 'Total loss': 0.20105456155046128}
2022-12-05 21:14:03,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:03,120 INFO:     Epoch: 26
2022-12-05 21:14:03,912 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3922031918032603, 'Total loss': 0.3922031918032603} | train loss {'Reaction outcome loss': 0.19499768700586398, 'Total loss': 0.19499768700586398}
2022-12-05 21:14:03,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:03,913 INFO:     Epoch: 27
2022-12-05 21:14:04,705 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3796686237169938, 'Total loss': 0.3796686237169938} | train loss {'Reaction outcome loss': 0.19118222468702295, 'Total loss': 0.19118222468702295}
2022-12-05 21:14:04,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:04,705 INFO:     Epoch: 28
2022-12-05 21:14:05,498 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38068140839988535, 'Total loss': 0.38068140839988535} | train loss {'Reaction outcome loss': 0.18635830502233164, 'Total loss': 0.18635830502233164}
2022-12-05 21:14:05,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:05,498 INFO:     Epoch: 29
2022-12-05 21:14:06,289 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3918201218951832, 'Total loss': 0.3918201218951832} | train loss {'Reaction outcome loss': 0.18048593799794763, 'Total loss': 0.18048593799794763}
2022-12-05 21:14:06,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:06,289 INFO:     Epoch: 30
2022-12-05 21:14:07,083 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3859357060017911, 'Total loss': 0.3859357060017911} | train loss {'Reaction outcome loss': 0.17907536160276244, 'Total loss': 0.17907536160276244}
2022-12-05 21:14:07,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:07,083 INFO:     Epoch: 31
2022-12-05 21:14:07,876 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3871826089241288, 'Total loss': 0.3871826089241288} | train loss {'Reaction outcome loss': 0.17680769368840255, 'Total loss': 0.17680769368840255}
2022-12-05 21:14:07,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:07,877 INFO:     Epoch: 32
2022-12-05 21:14:08,667 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38890680196610367, 'Total loss': 0.38890680196610367} | train loss {'Reaction outcome loss': 0.17427860677755072, 'Total loss': 0.17427860677755072}
2022-12-05 21:14:08,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:08,667 INFO:     Epoch: 33
2022-12-05 21:14:09,463 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4085716408762065, 'Total loss': 0.4085716408762065} | train loss {'Reaction outcome loss': 0.17140966587462406, 'Total loss': 0.17140966587462406}
2022-12-05 21:14:09,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:09,463 INFO:     Epoch: 34
2022-12-05 21:14:10,254 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3811406831849705, 'Total loss': 0.3811406831849705} | train loss {'Reaction outcome loss': 0.17272510294150184, 'Total loss': 0.17272510294150184}
2022-12-05 21:14:10,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:10,255 INFO:     Epoch: 35
2022-12-05 21:14:11,048 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3898291476070881, 'Total loss': 0.3898291476070881} | train loss {'Reaction outcome loss': 0.16687830566213682, 'Total loss': 0.16687830566213682}
2022-12-05 21:14:11,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:11,048 INFO:     Epoch: 36
2022-12-05 21:14:11,841 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4010734166103331, 'Total loss': 0.4010734166103331} | train loss {'Reaction outcome loss': 0.16842109640977282, 'Total loss': 0.16842109640977282}
2022-12-05 21:14:11,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:11,842 INFO:     Epoch: 37
2022-12-05 21:14:12,641 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39319284294139256, 'Total loss': 0.39319284294139256} | train loss {'Reaction outcome loss': 0.16160903094140322, 'Total loss': 0.16160903094140322}
2022-12-05 21:14:12,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:12,641 INFO:     Epoch: 38
2022-12-05 21:14:13,433 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40338475528088485, 'Total loss': 0.40338475528088485} | train loss {'Reaction outcome loss': 0.1618749570357896, 'Total loss': 0.1618749570357896}
2022-12-05 21:14:13,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:13,433 INFO:     Epoch: 39
2022-12-05 21:14:14,223 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4053490590304136, 'Total loss': 0.4053490590304136} | train loss {'Reaction outcome loss': 0.15754123860102917, 'Total loss': 0.15754123860102917}
2022-12-05 21:14:14,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:14,223 INFO:     Epoch: 40
2022-12-05 21:14:15,016 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38820373199202796, 'Total loss': 0.38820373199202796} | train loss {'Reaction outcome loss': 0.15851834781377422, 'Total loss': 0.15851834781377422}
2022-12-05 21:14:15,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:15,017 INFO:     Epoch: 41
2022-12-05 21:14:15,808 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3942370858382095, 'Total loss': 0.3942370858382095} | train loss {'Reaction outcome loss': 0.15677887228928386, 'Total loss': 0.15677887228928386}
2022-12-05 21:14:15,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:15,809 INFO:     Epoch: 42
2022-12-05 21:14:16,603 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39550950208848173, 'Total loss': 0.39550950208848173} | train loss {'Reaction outcome loss': 0.15471156433918457, 'Total loss': 0.15471156433918457}
2022-12-05 21:14:16,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:16,603 INFO:     Epoch: 43
2022-12-05 21:14:17,401 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3942719901149923, 'Total loss': 0.3942719901149923} | train loss {'Reaction outcome loss': 0.1501002957260138, 'Total loss': 0.1501002957260138}
2022-12-05 21:14:17,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:17,401 INFO:     Epoch: 44
2022-12-05 21:14:18,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4029978004030206, 'Total loss': 0.4029978004030206} | train loss {'Reaction outcome loss': 0.15009922393397823, 'Total loss': 0.15009922393397823}
2022-12-05 21:14:18,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:18,202 INFO:     Epoch: 45
2022-12-05 21:14:18,999 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3977789074521173, 'Total loss': 0.3977789074521173} | train loss {'Reaction outcome loss': 0.1471607319497869, 'Total loss': 0.1471607319497869}
2022-12-05 21:14:18,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:18,999 INFO:     Epoch: 46
2022-12-05 21:14:19,801 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3881334093695676, 'Total loss': 0.3881334093695676} | train loss {'Reaction outcome loss': 0.14865960420565566, 'Total loss': 0.14865960420565566}
2022-12-05 21:14:19,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:19,801 INFO:     Epoch: 47
2022-12-05 21:14:20,597 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4128857348114252, 'Total loss': 0.4128857348114252} | train loss {'Reaction outcome loss': 0.14501492061882246, 'Total loss': 0.14501492061882246}
2022-12-05 21:14:20,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:20,597 INFO:     Epoch: 48
2022-12-05 21:14:21,399 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3974717090075666, 'Total loss': 0.3974717090075666} | train loss {'Reaction outcome loss': 0.1451342264906718, 'Total loss': 0.1451342264906718}
2022-12-05 21:14:21,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:21,399 INFO:     Epoch: 49
2022-12-05 21:14:22,201 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3995545455677943, 'Total loss': 0.3995545455677943} | train loss {'Reaction outcome loss': 0.14643560963690372, 'Total loss': 0.14643560963690372}
2022-12-05 21:14:22,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:22,202 INFO:     Epoch: 50
2022-12-05 21:14:22,996 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39165209064429457, 'Total loss': 0.39165209064429457} | train loss {'Reaction outcome loss': 0.14312371265082827, 'Total loss': 0.14312371265082827}
2022-12-05 21:14:22,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:22,996 INFO:     Epoch: 51
2022-12-05 21:14:23,788 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39443782615390693, 'Total loss': 0.39443782615390693} | train loss {'Reaction outcome loss': 0.14429667136567806, 'Total loss': 0.14429667136567806}
2022-12-05 21:14:23,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:23,788 INFO:     Epoch: 52
2022-12-05 21:14:24,579 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4029850885272026, 'Total loss': 0.4029850885272026} | train loss {'Reaction outcome loss': 0.14329688711778113, 'Total loss': 0.14329688711778113}
2022-12-05 21:14:24,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:24,579 INFO:     Epoch: 53
2022-12-05 21:14:25,373 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39534543437713926, 'Total loss': 0.39534543437713926} | train loss {'Reaction outcome loss': 0.14456196988250322, 'Total loss': 0.14456196988250322}
2022-12-05 21:14:25,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:25,373 INFO:     Epoch: 54
2022-12-05 21:14:26,165 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4045884981751442, 'Total loss': 0.4045884981751442} | train loss {'Reaction outcome loss': 0.13989323419792132, 'Total loss': 0.13989323419792132}
2022-12-05 21:14:26,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:26,165 INFO:     Epoch: 55
2022-12-05 21:14:26,958 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3928598812357946, 'Total loss': 0.3928598812357946} | train loss {'Reaction outcome loss': 0.13701769530109548, 'Total loss': 0.13701769530109548}
2022-12-05 21:14:26,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:26,958 INFO:     Epoch: 56
2022-12-05 21:14:27,753 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37771873379295523, 'Total loss': 0.37771873379295523} | train loss {'Reaction outcome loss': 0.13488629182823275, 'Total loss': 0.13488629182823275}
2022-12-05 21:14:27,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:27,753 INFO:     Epoch: 57
2022-12-05 21:14:28,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39433869086629286, 'Total loss': 0.39433869086629286} | train loss {'Reaction outcome loss': 0.1340197567311436, 'Total loss': 0.1340197567311436}
2022-12-05 21:14:28,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:28,544 INFO:     Epoch: 58
2022-12-05 21:14:29,336 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4048252993009307, 'Total loss': 0.4048252993009307} | train loss {'Reaction outcome loss': 0.13242410506811822, 'Total loss': 0.13242410506811822}
2022-12-05 21:14:29,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:29,336 INFO:     Epoch: 59
2022-12-05 21:14:30,130 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4035722274671901, 'Total loss': 0.4035722274671901} | train loss {'Reaction outcome loss': 0.1321803403260405, 'Total loss': 0.1321803403260405}
2022-12-05 21:14:30,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:30,131 INFO:     Epoch: 60
2022-12-05 21:14:30,923 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39705679108473385, 'Total loss': 0.39705679108473385} | train loss {'Reaction outcome loss': 0.13758696847301172, 'Total loss': 0.13758696847301172}
2022-12-05 21:14:30,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:30,923 INFO:     Epoch: 61
2022-12-05 21:14:31,714 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4094505393030969, 'Total loss': 0.4094505393030969} | train loss {'Reaction outcome loss': 0.1332378750893208, 'Total loss': 0.1332378750893208}
2022-12-05 21:14:31,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:31,714 INFO:     Epoch: 62
2022-12-05 21:14:32,508 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41854575885967776, 'Total loss': 0.41854575885967776} | train loss {'Reaction outcome loss': 0.13497290460143976, 'Total loss': 0.13497290460143976}
2022-12-05 21:14:32,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:32,508 INFO:     Epoch: 63
2022-12-05 21:14:33,300 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39999531412666495, 'Total loss': 0.39999531412666495} | train loss {'Reaction outcome loss': 0.13015004494020088, 'Total loss': 0.13015004494020088}
2022-12-05 21:14:33,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:33,301 INFO:     Epoch: 64
2022-12-05 21:14:34,090 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4081193699755452, 'Total loss': 0.4081193699755452} | train loss {'Reaction outcome loss': 0.1317259224606791, 'Total loss': 0.1317259224606791}
2022-12-05 21:14:34,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:34,091 INFO:     Epoch: 65
2022-12-05 21:14:34,884 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4043064002286304, 'Total loss': 0.4043064002286304} | train loss {'Reaction outcome loss': 0.12570593404481828, 'Total loss': 0.12570593404481828}
2022-12-05 21:14:34,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:34,885 INFO:     Epoch: 66
2022-12-05 21:14:35,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4305722156370228, 'Total loss': 0.4305722156370228} | train loss {'Reaction outcome loss': 0.12528565602927555, 'Total loss': 0.12528565602927555}
2022-12-05 21:14:35,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:35,677 INFO:     Epoch: 67
2022-12-05 21:14:36,470 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.404140926558863, 'Total loss': 0.404140926558863} | train loss {'Reaction outcome loss': 0.12809099953787528, 'Total loss': 0.12809099953787528}
2022-12-05 21:14:36,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:36,470 INFO:     Epoch: 68
2022-12-05 21:14:37,260 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4191875396804376, 'Total loss': 0.4191875396804376} | train loss {'Reaction outcome loss': 0.13717084101246677, 'Total loss': 0.13717084101246677}
2022-12-05 21:14:37,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:37,260 INFO:     Epoch: 69
2022-12-05 21:14:38,053 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4149624292146076, 'Total loss': 0.4149624292146076} | train loss {'Reaction outcome loss': 0.12649318163739404, 'Total loss': 0.12649318163739404}
2022-12-05 21:14:38,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:38,053 INFO:     Epoch: 70
2022-12-05 21:14:38,848 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40585228241980076, 'Total loss': 0.40585228241980076} | train loss {'Reaction outcome loss': 0.12686228938212218, 'Total loss': 0.12686228938212218}
2022-12-05 21:14:38,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:38,848 INFO:     Epoch: 71
2022-12-05 21:14:39,639 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41683559492230415, 'Total loss': 0.41683559492230415} | train loss {'Reaction outcome loss': 0.1277589882773004, 'Total loss': 0.1277589882773004}
2022-12-05 21:14:39,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:39,640 INFO:     Epoch: 72
2022-12-05 21:14:40,431 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4090440669520335, 'Total loss': 0.4090440669520335} | train loss {'Reaction outcome loss': 0.12588398923592167, 'Total loss': 0.12588398923592167}
2022-12-05 21:14:40,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:40,431 INFO:     Epoch: 73
2022-12-05 21:14:41,222 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4126607227054509, 'Total loss': 0.4126607227054509} | train loss {'Reaction outcome loss': 0.12642879731319695, 'Total loss': 0.12642879731319695}
2022-12-05 21:14:41,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:41,223 INFO:     Epoch: 74
2022-12-05 21:14:42,013 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41987302188168873, 'Total loss': 0.41987302188168873} | train loss {'Reaction outcome loss': 0.12582749553846745, 'Total loss': 0.12582749553846745}
2022-12-05 21:14:42,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:42,014 INFO:     Epoch: 75
2022-12-05 21:14:42,806 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4034890908409249, 'Total loss': 0.4034890908409249} | train loss {'Reaction outcome loss': 0.13306949284259487, 'Total loss': 0.13306949284259487}
2022-12-05 21:14:42,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:42,806 INFO:     Epoch: 76
2022-12-05 21:14:43,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4197115989571268, 'Total loss': 0.4197115989571268} | train loss {'Reaction outcome loss': 0.12260067642021638, 'Total loss': 0.12260067642021638}
2022-12-05 21:14:43,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:43,599 INFO:     Epoch: 77
2022-12-05 21:14:44,390 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40823889523744583, 'Total loss': 0.40823889523744583} | train loss {'Reaction outcome loss': 0.12264755038687816, 'Total loss': 0.12264755038687816}
2022-12-05 21:14:44,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:44,390 INFO:     Epoch: 78
2022-12-05 21:14:45,184 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4120016321539879, 'Total loss': 0.4120016321539879} | train loss {'Reaction outcome loss': 0.12388132256172929, 'Total loss': 0.12388132256172929}
2022-12-05 21:14:45,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:45,184 INFO:     Epoch: 79
2022-12-05 21:14:45,977 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42108050462874497, 'Total loss': 0.42108050462874497} | train loss {'Reaction outcome loss': 0.12146002049124253, 'Total loss': 0.12146002049124253}
2022-12-05 21:14:45,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:45,977 INFO:     Epoch: 80
2022-12-05 21:14:46,772 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3969936682419343, 'Total loss': 0.3969936682419343} | train loss {'Reaction outcome loss': 0.1186562732563388, 'Total loss': 0.1186562732563388}
2022-12-05 21:14:46,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:46,773 INFO:     Epoch: 81
2022-12-05 21:14:47,564 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3976209722459316, 'Total loss': 0.3976209722459316} | train loss {'Reaction outcome loss': 0.13787348976788613, 'Total loss': 0.13787348976788613}
2022-12-05 21:14:47,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:47,564 INFO:     Epoch: 82
2022-12-05 21:14:48,357 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4229517186229879, 'Total loss': 0.4229517186229879} | train loss {'Reaction outcome loss': 0.13048959014039893, 'Total loss': 0.13048959014039893}
2022-12-05 21:14:48,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:48,357 INFO:     Epoch: 83
2022-12-05 21:14:49,153 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4167974703013897, 'Total loss': 0.4167974703013897} | train loss {'Reaction outcome loss': 0.13110870003760586, 'Total loss': 0.13110870003760586}
2022-12-05 21:14:49,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:49,154 INFO:     Epoch: 84
2022-12-05 21:14:49,944 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40501044487411325, 'Total loss': 0.40501044487411325} | train loss {'Reaction outcome loss': 0.12284179022045512, 'Total loss': 0.12284179022045512}
2022-12-05 21:14:49,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:49,945 INFO:     Epoch: 85
2022-12-05 21:14:50,737 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4062363298779184, 'Total loss': 0.4062363298779184} | train loss {'Reaction outcome loss': 0.1197421755867931, 'Total loss': 0.1197421755867931}
2022-12-05 21:14:50,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:50,737 INFO:     Epoch: 86
2022-12-05 21:14:51,533 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4135338599708947, 'Total loss': 0.4135338599708947} | train loss {'Reaction outcome loss': 0.12146820903563427, 'Total loss': 0.12146820903563427}
2022-12-05 21:14:51,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:51,533 INFO:     Epoch: 87
2022-12-05 21:14:52,327 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3927599188279022, 'Total loss': 0.3927599188279022} | train loss {'Reaction outcome loss': 0.11734006331426654, 'Total loss': 0.11734006331426654}
2022-12-05 21:14:52,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:52,327 INFO:     Epoch: 88
2022-12-05 21:14:53,121 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3943249678069895, 'Total loss': 0.3943249678069895} | train loss {'Reaction outcome loss': 0.12116415649727892, 'Total loss': 0.12116415649727892}
2022-12-05 21:14:53,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:53,122 INFO:     Epoch: 89
2022-12-05 21:14:53,912 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4153704575516961, 'Total loss': 0.4153704575516961} | train loss {'Reaction outcome loss': 0.12272745556752329, 'Total loss': 0.12272745556752329}
2022-12-05 21:14:53,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:53,912 INFO:     Epoch: 90
2022-12-05 21:14:54,702 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39521029058166524, 'Total loss': 0.39521029058166524} | train loss {'Reaction outcome loss': 0.11963119711877726, 'Total loss': 0.11963119711877726}
2022-12-05 21:14:54,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:54,703 INFO:     Epoch: 91
2022-12-05 21:14:55,497 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4178091077642007, 'Total loss': 0.4178091077642007} | train loss {'Reaction outcome loss': 0.124271838786269, 'Total loss': 0.124271838786269}
2022-12-05 21:14:55,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:55,497 INFO:     Epoch: 92
2022-12-05 21:14:56,288 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41735610213469376, 'Total loss': 0.41735610213469376} | train loss {'Reaction outcome loss': 0.11736101370968437, 'Total loss': 0.11736101370968437}
2022-12-05 21:14:56,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:56,288 INFO:     Epoch: 93
2022-12-05 21:14:57,078 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42755474692041223, 'Total loss': 0.42755474692041223} | train loss {'Reaction outcome loss': 0.11612858431722954, 'Total loss': 0.11612858431722954}
2022-12-05 21:14:57,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:57,078 INFO:     Epoch: 94
2022-12-05 21:14:57,872 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4150263826278123, 'Total loss': 0.4150263826278123} | train loss {'Reaction outcome loss': 0.11481989705972825, 'Total loss': 0.11481989705972825}
2022-12-05 21:14:57,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:57,872 INFO:     Epoch: 95
2022-12-05 21:14:58,664 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41755103184418246, 'Total loss': 0.41755103184418246} | train loss {'Reaction outcome loss': 0.11543337086796278, 'Total loss': 0.11543337086796278}
2022-12-05 21:14:58,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:58,664 INFO:     Epoch: 96
2022-12-05 21:14:59,455 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4065931427546523, 'Total loss': 0.4065931427546523} | train loss {'Reaction outcome loss': 0.11626160009820694, 'Total loss': 0.11626160009820694}
2022-12-05 21:14:59,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:14:59,455 INFO:     Epoch: 97
2022-12-05 21:15:00,245 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3945572767406702, 'Total loss': 0.3945572767406702} | train loss {'Reaction outcome loss': 0.11600243082168221, 'Total loss': 0.11600243082168221}
2022-12-05 21:15:00,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:00,245 INFO:     Epoch: 98
2022-12-05 21:15:01,035 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4035211285914887, 'Total loss': 0.4035211285914887} | train loss {'Reaction outcome loss': 0.11465774290640707, 'Total loss': 0.11465774290640707}
2022-12-05 21:15:01,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:01,035 INFO:     Epoch: 99
2022-12-05 21:15:01,825 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4184979921714826, 'Total loss': 0.4184979921714826} | train loss {'Reaction outcome loss': 0.11837271678634742, 'Total loss': 0.11837271678634742}
2022-12-05 21:15:01,825 INFO:     Best model found after epoch 18 of 100.
2022-12-05 21:15:01,825 INFO:   Done with stage: TRAINING
2022-12-05 21:15:01,825 INFO:   Starting stage: EVALUATION
2022-12-05 21:15:01,950 INFO:   Done with stage: EVALUATION
2022-12-05 21:15:01,950 INFO:   Leaving out SEQ value Fold_6
2022-12-05 21:15:01,962 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:15:01,963 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:15:02,605 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:15:02,605 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:15:02,674 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:15:02,675 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:15:02,675 INFO:     No hyperparam tuning for this model
2022-12-05 21:15:02,675 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:15:02,675 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:15:02,675 INFO:     None feature selector for col prot
2022-12-05 21:15:02,676 INFO:     None feature selector for col prot
2022-12-05 21:15:02,676 INFO:     None feature selector for col prot
2022-12-05 21:15:02,676 INFO:     None feature selector for col chem
2022-12-05 21:15:02,676 INFO:     None feature selector for col chem
2022-12-05 21:15:02,676 INFO:     None feature selector for col chem
2022-12-05 21:15:02,676 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:15:02,676 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:15:02,678 INFO:     Number of params in model 215821
2022-12-05 21:15:02,681 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:15:02,681 INFO:   Starting stage: TRAINING
2022-12-05 21:15:02,742 INFO:     Val loss before train {'Reaction outcome loss': 1.0121255733750083, 'Total loss': 1.0121255733750083}
2022-12-05 21:15:02,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:02,742 INFO:     Epoch: 0
2022-12-05 21:15:03,537 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6103128160942685, 'Total loss': 0.6103128160942685} | train loss {'Reaction outcome loss': 0.7814601002193173, 'Total loss': 0.7814601002193173}
2022-12-05 21:15:03,537 INFO:     Found new best model at epoch 0
2022-12-05 21:15:03,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:03,538 INFO:     Epoch: 1
2022-12-05 21:15:04,329 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5157612552019682, 'Total loss': 0.5157612552019682} | train loss {'Reaction outcome loss': 0.5422465334295744, 'Total loss': 0.5422465334295744}
2022-12-05 21:15:04,330 INFO:     Found new best model at epoch 1
2022-12-05 21:15:04,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:04,330 INFO:     Epoch: 2
2022-12-05 21:15:05,121 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48731710287657654, 'Total loss': 0.48731710287657654} | train loss {'Reaction outcome loss': 0.4708501326923187, 'Total loss': 0.4708501326923187}
2022-12-05 21:15:05,122 INFO:     Found new best model at epoch 2
2022-12-05 21:15:05,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:05,123 INFO:     Epoch: 3
2022-12-05 21:15:05,917 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4828043742613359, 'Total loss': 0.4828043742613359} | train loss {'Reaction outcome loss': 0.43228482798888135, 'Total loss': 0.43228482798888135}
2022-12-05 21:15:05,917 INFO:     Found new best model at epoch 3
2022-12-05 21:15:05,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:05,918 INFO:     Epoch: 4
2022-12-05 21:15:06,712 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45984526351094246, 'Total loss': 0.45984526351094246} | train loss {'Reaction outcome loss': 0.40435484657252607, 'Total loss': 0.40435484657252607}
2022-12-05 21:15:06,712 INFO:     Found new best model at epoch 4
2022-12-05 21:15:06,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:06,713 INFO:     Epoch: 5
2022-12-05 21:15:07,510 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4557651362635873, 'Total loss': 0.4557651362635873} | train loss {'Reaction outcome loss': 0.38455705981143573, 'Total loss': 0.38455705981143573}
2022-12-05 21:15:07,510 INFO:     Found new best model at epoch 5
2022-12-05 21:15:07,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:07,511 INFO:     Epoch: 6
2022-12-05 21:15:08,300 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45904891937971115, 'Total loss': 0.45904891937971115} | train loss {'Reaction outcome loss': 0.3633104830919972, 'Total loss': 0.3633104830919972}
2022-12-05 21:15:08,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:08,301 INFO:     Epoch: 7
2022-12-05 21:15:09,089 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45537487688389694, 'Total loss': 0.45537487688389694} | train loss {'Reaction outcome loss': 0.349853379644363, 'Total loss': 0.349853379644363}
2022-12-05 21:15:09,089 INFO:     Found new best model at epoch 7
2022-12-05 21:15:09,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:09,090 INFO:     Epoch: 8
2022-12-05 21:15:09,875 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4428398930890994, 'Total loss': 0.4428398930890994} | train loss {'Reaction outcome loss': 0.3358892952563309, 'Total loss': 0.3358892952563309}
2022-12-05 21:15:09,875 INFO:     Found new best model at epoch 8
2022-12-05 21:15:09,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:09,876 INFO:     Epoch: 9
2022-12-05 21:15:10,661 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45751376348462974, 'Total loss': 0.45751376348462974} | train loss {'Reaction outcome loss': 0.3164458806939453, 'Total loss': 0.3164458806939453}
2022-12-05 21:15:10,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:10,661 INFO:     Epoch: 10
2022-12-05 21:15:11,448 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46404358643022453, 'Total loss': 0.46404358643022453} | train loss {'Reaction outcome loss': 0.3074313778173827, 'Total loss': 0.3074313778173827}
2022-12-05 21:15:11,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:11,448 INFO:     Epoch: 11
2022-12-05 21:15:12,235 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4456623819741336, 'Total loss': 0.4456623819741336} | train loss {'Reaction outcome loss': 0.29291893454336443, 'Total loss': 0.29291893454336443}
2022-12-05 21:15:12,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:12,236 INFO:     Epoch: 12
2022-12-05 21:15:13,025 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4473909000781449, 'Total loss': 0.4473909000781449} | train loss {'Reaction outcome loss': 0.28562178025361495, 'Total loss': 0.28562178025361495}
2022-12-05 21:15:13,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:13,026 INFO:     Epoch: 13
2022-12-05 21:15:13,821 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44191461403600196, 'Total loss': 0.44191461403600196} | train loss {'Reaction outcome loss': 0.2788172224899452, 'Total loss': 0.2788172224899452}
2022-12-05 21:15:13,821 INFO:     Found new best model at epoch 13
2022-12-05 21:15:13,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:13,822 INFO:     Epoch: 14
2022-12-05 21:15:14,617 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4441998587413268, 'Total loss': 0.4441998587413268} | train loss {'Reaction outcome loss': 0.2656959976080941, 'Total loss': 0.2656959976080941}
2022-12-05 21:15:14,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:14,618 INFO:     Epoch: 15
2022-12-05 21:15:15,407 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45028337091207504, 'Total loss': 0.45028337091207504} | train loss {'Reaction outcome loss': 0.25679397056688014, 'Total loss': 0.25679397056688014}
2022-12-05 21:15:15,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:15,407 INFO:     Epoch: 16
2022-12-05 21:15:16,195 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45218162780458276, 'Total loss': 0.45218162780458276} | train loss {'Reaction outcome loss': 0.24954711013899641, 'Total loss': 0.24954711013899641}
2022-12-05 21:15:16,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:16,195 INFO:     Epoch: 17
2022-12-05 21:15:16,981 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45035425234924664, 'Total loss': 0.45035425234924664} | train loss {'Reaction outcome loss': 0.24329190550424792, 'Total loss': 0.24329190550424792}
2022-12-05 21:15:16,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:16,981 INFO:     Epoch: 18
2022-12-05 21:15:17,771 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4514847000722181, 'Total loss': 0.4514847000722181} | train loss {'Reaction outcome loss': 0.23603570618127523, 'Total loss': 0.23603570618127523}
2022-12-05 21:15:17,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:17,772 INFO:     Epoch: 19
2022-12-05 21:15:18,565 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4616407372734763, 'Total loss': 0.4616407372734763} | train loss {'Reaction outcome loss': 0.2279922581062867, 'Total loss': 0.2279922581062867}
2022-12-05 21:15:18,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:18,565 INFO:     Epoch: 20
2022-12-05 21:15:19,360 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46251886371861806, 'Total loss': 0.46251886371861806} | train loss {'Reaction outcome loss': 0.22250395215414315, 'Total loss': 0.22250395215414315}
2022-12-05 21:15:19,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:19,361 INFO:     Epoch: 21
2022-12-05 21:15:20,155 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46773212030529976, 'Total loss': 0.46773212030529976} | train loss {'Reaction outcome loss': 0.21576707835991674, 'Total loss': 0.21576707835991674}
2022-12-05 21:15:20,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:20,155 INFO:     Epoch: 22
2022-12-05 21:15:20,956 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4708587760952386, 'Total loss': 0.4708587760952386} | train loss {'Reaction outcome loss': 0.2126209761943623, 'Total loss': 0.2126209761943623}
2022-12-05 21:15:20,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:20,956 INFO:     Epoch: 23
2022-12-05 21:15:21,752 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4560146792368455, 'Total loss': 0.4560146792368455} | train loss {'Reaction outcome loss': 0.20709178203845072, 'Total loss': 0.20709178203845072}
2022-12-05 21:15:21,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:21,752 INFO:     Epoch: 24
2022-12-05 21:15:22,549 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.460698432543061, 'Total loss': 0.460698432543061} | train loss {'Reaction outcome loss': 0.2030726341372318, 'Total loss': 0.2030726341372318}
2022-12-05 21:15:22,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:22,549 INFO:     Epoch: 25
2022-12-05 21:15:23,342 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44940993223677983, 'Total loss': 0.44940993223677983} | train loss {'Reaction outcome loss': 0.2015936154163318, 'Total loss': 0.2015936154163318}
2022-12-05 21:15:23,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:23,343 INFO:     Epoch: 26
2022-12-05 21:15:24,136 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4700362204828046, 'Total loss': 0.4700362204828046} | train loss {'Reaction outcome loss': 0.19525865736881248, 'Total loss': 0.19525865736881248}
2022-12-05 21:15:24,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:24,137 INFO:     Epoch: 27
2022-12-05 21:15:24,933 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44994493370706384, 'Total loss': 0.44994493370706384} | train loss {'Reaction outcome loss': 0.19596650155811657, 'Total loss': 0.19596650155811657}
2022-12-05 21:15:24,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:24,933 INFO:     Epoch: 28
2022-12-05 21:15:25,729 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4652854454788295, 'Total loss': 0.4652854454788295} | train loss {'Reaction outcome loss': 0.1879546319243879, 'Total loss': 0.1879546319243879}
2022-12-05 21:15:25,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:25,730 INFO:     Epoch: 29
2022-12-05 21:15:26,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.462952429598028, 'Total loss': 0.462952429598028} | train loss {'Reaction outcome loss': 0.1902082077404748, 'Total loss': 0.1902082077404748}
2022-12-05 21:15:26,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:26,530 INFO:     Epoch: 30
2022-12-05 21:15:27,334 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46039769324389374, 'Total loss': 0.46039769324389374} | train loss {'Reaction outcome loss': 0.18193329326376725, 'Total loss': 0.18193329326376725}
2022-12-05 21:15:27,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:27,334 INFO:     Epoch: 31
2022-12-05 21:15:28,134 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4694798636165532, 'Total loss': 0.4694798636165532} | train loss {'Reaction outcome loss': 0.17872022773772628, 'Total loss': 0.17872022773772628}
2022-12-05 21:15:28,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:28,134 INFO:     Epoch: 32
2022-12-05 21:15:28,935 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4834370728243481, 'Total loss': 0.4834370728243481} | train loss {'Reaction outcome loss': 0.17845405550741475, 'Total loss': 0.17845405550741475}
2022-12-05 21:15:28,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:28,936 INFO:     Epoch: 33
2022-12-05 21:15:29,734 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4674119267782027, 'Total loss': 0.4674119267782027} | train loss {'Reaction outcome loss': 0.1771689784309642, 'Total loss': 0.1771689784309642}
2022-12-05 21:15:29,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:29,734 INFO:     Epoch: 34
2022-12-05 21:15:30,534 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46258017454635014, 'Total loss': 0.46258017454635014} | train loss {'Reaction outcome loss': 0.1746859080818018, 'Total loss': 0.1746859080818018}
2022-12-05 21:15:30,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:30,534 INFO:     Epoch: 35
2022-12-05 21:15:31,336 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47184989956969564, 'Total loss': 0.47184989956969564} | train loss {'Reaction outcome loss': 0.17256315520055865, 'Total loss': 0.17256315520055865}
2022-12-05 21:15:31,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:31,336 INFO:     Epoch: 36
2022-12-05 21:15:32,141 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4689299108629877, 'Total loss': 0.4689299108629877} | train loss {'Reaction outcome loss': 0.16479206447930714, 'Total loss': 0.16479206447930714}
2022-12-05 21:15:32,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:32,141 INFO:     Epoch: 37
2022-12-05 21:15:32,943 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.474236979403279, 'Total loss': 0.474236979403279} | train loss {'Reaction outcome loss': 0.16604438961034845, 'Total loss': 0.16604438961034845}
2022-12-05 21:15:32,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:32,944 INFO:     Epoch: 38
2022-12-05 21:15:33,743 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4659670435569503, 'Total loss': 0.4659670435569503} | train loss {'Reaction outcome loss': 0.1617016800969598, 'Total loss': 0.1617016800969598}
2022-12-05 21:15:33,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:33,743 INFO:     Epoch: 39
2022-12-05 21:15:34,544 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4753388464450836, 'Total loss': 0.4753388464450836} | train loss {'Reaction outcome loss': 0.16028143326386146, 'Total loss': 0.16028143326386146}
2022-12-05 21:15:34,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:34,544 INFO:     Epoch: 40
2022-12-05 21:15:35,352 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47534647990356793, 'Total loss': 0.47534647990356793} | train loss {'Reaction outcome loss': 0.158045801888352, 'Total loss': 0.158045801888352}
2022-12-05 21:15:35,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:35,352 INFO:     Epoch: 41
2022-12-05 21:15:36,146 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4712548371065747, 'Total loss': 0.4712548371065747} | train loss {'Reaction outcome loss': 0.16134883320102325, 'Total loss': 0.16134883320102325}
2022-12-05 21:15:36,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:36,147 INFO:     Epoch: 42
2022-12-05 21:15:36,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46199291571974754, 'Total loss': 0.46199291571974754} | train loss {'Reaction outcome loss': 0.15829775232052515, 'Total loss': 0.15829775232052515}
2022-12-05 21:15:36,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:36,940 INFO:     Epoch: 43
2022-12-05 21:15:37,731 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48728353733366186, 'Total loss': 0.48728353733366186} | train loss {'Reaction outcome loss': 0.15422979852388263, 'Total loss': 0.15422979852388263}
2022-12-05 21:15:37,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:37,732 INFO:     Epoch: 44
2022-12-05 21:15:38,525 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4776005917652087, 'Total loss': 0.4776005917652087} | train loss {'Reaction outcome loss': 0.15361825937427853, 'Total loss': 0.15361825937427853}
2022-12-05 21:15:38,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:38,525 INFO:     Epoch: 45
2022-12-05 21:15:39,315 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46685659580610017, 'Total loss': 0.46685659580610017} | train loss {'Reaction outcome loss': 0.15626253014588767, 'Total loss': 0.15626253014588767}
2022-12-05 21:15:39,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:39,315 INFO:     Epoch: 46
2022-12-05 21:15:40,108 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47587811354209075, 'Total loss': 0.47587811354209075} | train loss {'Reaction outcome loss': 0.14978266387484093, 'Total loss': 0.14978266387484093}
2022-12-05 21:15:40,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:40,109 INFO:     Epoch: 47
2022-12-05 21:15:40,905 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48098807206208055, 'Total loss': 0.48098807206208055} | train loss {'Reaction outcome loss': 0.1488204356660003, 'Total loss': 0.1488204356660003}
2022-12-05 21:15:40,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:40,905 INFO:     Epoch: 48
2022-12-05 21:15:41,701 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4711883559145711, 'Total loss': 0.4711883559145711} | train loss {'Reaction outcome loss': 0.14843329326730403, 'Total loss': 0.14843329326730403}
2022-12-05 21:15:41,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:41,701 INFO:     Epoch: 49
2022-12-05 21:15:42,500 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4809578609737483, 'Total loss': 0.4809578609737483} | train loss {'Reaction outcome loss': 0.1437415221200781, 'Total loss': 0.1437415221200781}
2022-12-05 21:15:42,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:42,500 INFO:     Epoch: 50
2022-12-05 21:15:43,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4761006954041394, 'Total loss': 0.4761006954041394} | train loss {'Reaction outcome loss': 0.14800809312099025, 'Total loss': 0.14800809312099025}
2022-12-05 21:15:43,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:43,294 INFO:     Epoch: 51
2022-12-05 21:15:44,088 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4701036424799399, 'Total loss': 0.4701036424799399} | train loss {'Reaction outcome loss': 0.14394841355230162, 'Total loss': 0.14394841355230162}
2022-12-05 21:15:44,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:44,088 INFO:     Epoch: 52
2022-12-05 21:15:44,881 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47182862291281874, 'Total loss': 0.47182862291281874} | train loss {'Reaction outcome loss': 0.14515013452845546, 'Total loss': 0.14515013452845546}
2022-12-05 21:15:44,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:44,881 INFO:     Epoch: 53
2022-12-05 21:15:45,675 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4743809554387223, 'Total loss': 0.4743809554387223} | train loss {'Reaction outcome loss': 0.1429014318124938, 'Total loss': 0.1429014318124938}
2022-12-05 21:15:45,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:45,675 INFO:     Epoch: 54
2022-12-05 21:15:46,470 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46891663494435226, 'Total loss': 0.46891663494435226} | train loss {'Reaction outcome loss': 0.13901285102651248, 'Total loss': 0.13901285102651248}
2022-12-05 21:15:46,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:46,471 INFO:     Epoch: 55
2022-12-05 21:15:47,262 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48726021633906796, 'Total loss': 0.48726021633906796} | train loss {'Reaction outcome loss': 0.13874769578819815, 'Total loss': 0.13874769578819815}
2022-12-05 21:15:47,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:47,262 INFO:     Epoch: 56
2022-12-05 21:15:48,052 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4722002578729933, 'Total loss': 0.4722002578729933} | train loss {'Reaction outcome loss': 0.14064899242298323, 'Total loss': 0.14064899242298323}
2022-12-05 21:15:48,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:48,052 INFO:     Epoch: 57
2022-12-05 21:15:48,846 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4736679616299542, 'Total loss': 0.4736679616299542} | train loss {'Reaction outcome loss': 0.13671312865005572, 'Total loss': 0.13671312865005572}
2022-12-05 21:15:48,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:48,847 INFO:     Epoch: 58
2022-12-05 21:15:49,643 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4591814719817855, 'Total loss': 0.4591814719817855} | train loss {'Reaction outcome loss': 0.14015886550279041, 'Total loss': 0.14015886550279041}
2022-12-05 21:15:49,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:49,643 INFO:     Epoch: 59
2022-12-05 21:15:50,442 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49288375269282947, 'Total loss': 0.49288375269282947} | train loss {'Reaction outcome loss': 0.14267192057028474, 'Total loss': 0.14267192057028474}
2022-12-05 21:15:50,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:50,442 INFO:     Epoch: 60
2022-12-05 21:15:51,237 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46576788733628666, 'Total loss': 0.46576788733628666} | train loss {'Reaction outcome loss': 0.13779742989937968, 'Total loss': 0.13779742989937968}
2022-12-05 21:15:51,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:51,237 INFO:     Epoch: 61
2022-12-05 21:15:52,032 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4656804119321433, 'Total loss': 0.4656804119321433} | train loss {'Reaction outcome loss': 0.1331424174890646, 'Total loss': 0.1331424174890646}
2022-12-05 21:15:52,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:52,032 INFO:     Epoch: 62
2022-12-05 21:15:52,826 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47889643331820314, 'Total loss': 0.47889643331820314} | train loss {'Reaction outcome loss': 0.12948626809591343, 'Total loss': 0.12948626809591343}
2022-12-05 21:15:52,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:52,826 INFO:     Epoch: 63
2022-12-05 21:15:53,617 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4659398966892199, 'Total loss': 0.4659398966892199} | train loss {'Reaction outcome loss': 0.13067008988924234, 'Total loss': 0.13067008988924234}
2022-12-05 21:15:53,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:53,618 INFO:     Epoch: 64
2022-12-05 21:15:54,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49024305187843065, 'Total loss': 0.49024305187843065} | train loss {'Reaction outcome loss': 0.1329718994180321, 'Total loss': 0.1329718994180321}
2022-12-05 21:15:54,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:54,409 INFO:     Epoch: 65
2022-12-05 21:15:55,202 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48455351862040436, 'Total loss': 0.48455351862040436} | train loss {'Reaction outcome loss': 0.12837307823648458, 'Total loss': 0.12837307823648458}
2022-12-05 21:15:55,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:55,203 INFO:     Epoch: 66
2022-12-05 21:15:55,996 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4835869012908502, 'Total loss': 0.4835869012908502} | train loss {'Reaction outcome loss': 0.12935081496080647, 'Total loss': 0.12935081496080647}
2022-12-05 21:15:55,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:55,996 INFO:     Epoch: 67
2022-12-05 21:15:56,790 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4757079238241369, 'Total loss': 0.4757079238241369} | train loss {'Reaction outcome loss': 0.12618878165161923, 'Total loss': 0.12618878165161923}
2022-12-05 21:15:56,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:56,791 INFO:     Epoch: 68
2022-12-05 21:15:57,587 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4679541513323784, 'Total loss': 0.4679541513323784} | train loss {'Reaction outcome loss': 0.13404166230909254, 'Total loss': 0.13404166230909254}
2022-12-05 21:15:57,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:57,587 INFO:     Epoch: 69
2022-12-05 21:15:58,387 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4751757837154649, 'Total loss': 0.4751757837154649} | train loss {'Reaction outcome loss': 0.13498304427605168, 'Total loss': 0.13498304427605168}
2022-12-05 21:15:58,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:58,387 INFO:     Epoch: 70
2022-12-05 21:15:59,182 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4643449848094447, 'Total loss': 0.4643449848094447} | train loss {'Reaction outcome loss': 0.12426098465338832, 'Total loss': 0.12426098465338832}
2022-12-05 21:15:59,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:59,182 INFO:     Epoch: 71
2022-12-05 21:15:59,976 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46594837036999787, 'Total loss': 0.46594837036999787} | train loss {'Reaction outcome loss': 0.12590286756492397, 'Total loss': 0.12590286756492397}
2022-12-05 21:15:59,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:15:59,976 INFO:     Epoch: 72
2022-12-05 21:16:00,769 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4621253281154416, 'Total loss': 0.4621253281154416} | train loss {'Reaction outcome loss': 0.12341457198521025, 'Total loss': 0.12341457198521025}
2022-12-05 21:16:00,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:00,769 INFO:     Epoch: 73
2022-12-05 21:16:01,564 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.484954989769242, 'Total loss': 0.484954989769242} | train loss {'Reaction outcome loss': 0.1263482711157245, 'Total loss': 0.1263482711157245}
2022-12-05 21:16:01,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:01,564 INFO:     Epoch: 74
2022-12-05 21:16:02,360 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4570372294295918, 'Total loss': 0.4570372294295918} | train loss {'Reaction outcome loss': 0.12907077878834264, 'Total loss': 0.12907077878834264}
2022-12-05 21:16:02,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:02,360 INFO:     Epoch: 75
2022-12-05 21:16:03,153 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48658206567845563, 'Total loss': 0.48658206567845563} | train loss {'Reaction outcome loss': 0.12570847944933394, 'Total loss': 0.12570847944933394}
2022-12-05 21:16:03,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:03,153 INFO:     Epoch: 76
2022-12-05 21:16:03,946 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4773565165021203, 'Total loss': 0.4773565165021203} | train loss {'Reaction outcome loss': 0.12132887279547408, 'Total loss': 0.12132887279547408}
2022-12-05 21:16:03,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:03,946 INFO:     Epoch: 77
2022-12-05 21:16:04,741 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4701518663628535, 'Total loss': 0.4701518663628535} | train loss {'Reaction outcome loss': 0.12275478965508552, 'Total loss': 0.12275478965508552}
2022-12-05 21:16:04,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:04,741 INFO:     Epoch: 78
2022-12-05 21:16:05,536 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4675210734659975, 'Total loss': 0.4675210734659975} | train loss {'Reaction outcome loss': 0.1230048516063917, 'Total loss': 0.1230048516063917}
2022-12-05 21:16:05,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:05,536 INFO:     Epoch: 79
2022-12-05 21:16:06,328 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4560534537515857, 'Total loss': 0.4560534537515857} | train loss {'Reaction outcome loss': 0.12526377387767137, 'Total loss': 0.12526377387767137}
2022-12-05 21:16:06,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:06,328 INFO:     Epoch: 80
2022-12-05 21:16:07,121 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4782917746766047, 'Total loss': 0.4782917746766047} | train loss {'Reaction outcome loss': 0.13021478596848515, 'Total loss': 0.13021478596848515}
2022-12-05 21:16:07,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:07,121 INFO:     Epoch: 81
2022-12-05 21:16:07,912 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45337473262440076, 'Total loss': 0.45337473262440076} | train loss {'Reaction outcome loss': 0.12074051824537849, 'Total loss': 0.12074051824537849}
2022-12-05 21:16:07,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:07,913 INFO:     Epoch: 82
2022-12-05 21:16:08,709 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4669786027886651, 'Total loss': 0.4669786027886651} | train loss {'Reaction outcome loss': 0.12489528174564876, 'Total loss': 0.12489528174564876}
2022-12-05 21:16:08,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:08,709 INFO:     Epoch: 83
2022-12-05 21:16:09,505 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45953724499453197, 'Total loss': 0.45953724499453197} | train loss {'Reaction outcome loss': 0.11889324475245679, 'Total loss': 0.11889324475245679}
2022-12-05 21:16:09,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:09,505 INFO:     Epoch: 84
2022-12-05 21:16:10,301 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46100802516395395, 'Total loss': 0.46100802516395395} | train loss {'Reaction outcome loss': 0.12091672247811126, 'Total loss': 0.12091672247811126}
2022-12-05 21:16:10,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:10,301 INFO:     Epoch: 85
2022-12-05 21:16:11,095 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4615659639239311, 'Total loss': 0.4615659639239311} | train loss {'Reaction outcome loss': 0.11949302005083846, 'Total loss': 0.11949302005083846}
2022-12-05 21:16:11,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:11,095 INFO:     Epoch: 86
2022-12-05 21:16:11,889 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45961436358365143, 'Total loss': 0.45961436358365143} | train loss {'Reaction outcome loss': 0.11661974638926717, 'Total loss': 0.11661974638926717}
2022-12-05 21:16:11,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:11,889 INFO:     Epoch: 87
2022-12-05 21:16:12,682 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48109634999524464, 'Total loss': 0.48109634999524464} | train loss {'Reaction outcome loss': 0.11759384109971853, 'Total loss': 0.11759384109971853}
2022-12-05 21:16:12,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:12,682 INFO:     Epoch: 88
2022-12-05 21:16:13,473 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46227978533980524, 'Total loss': 0.46227978533980524} | train loss {'Reaction outcome loss': 0.1161566148003043, 'Total loss': 0.1161566148003043}
2022-12-05 21:16:13,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:13,473 INFO:     Epoch: 89
2022-12-05 21:16:14,267 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4631989064033736, 'Total loss': 0.4631989064033736} | train loss {'Reaction outcome loss': 0.11615268978820963, 'Total loss': 0.11615268978820963}
2022-12-05 21:16:14,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:14,267 INFO:     Epoch: 90
2022-12-05 21:16:15,065 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47864087679508055, 'Total loss': 0.47864087679508055} | train loss {'Reaction outcome loss': 0.11749126223719072, 'Total loss': 0.11749126223719072}
2022-12-05 21:16:15,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:15,065 INFO:     Epoch: 91
2022-12-05 21:16:15,857 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47272663800553844, 'Total loss': 0.47272663800553844} | train loss {'Reaction outcome loss': 0.11974472990297233, 'Total loss': 0.11974472990297233}
2022-12-05 21:16:15,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:15,857 INFO:     Epoch: 92
2022-12-05 21:16:16,649 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4731728465042331, 'Total loss': 0.4731728465042331} | train loss {'Reaction outcome loss': 0.11637602717076477, 'Total loss': 0.11637602717076477}
2022-12-05 21:16:16,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:16,649 INFO:     Epoch: 93
2022-12-05 21:16:17,441 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46068124676292593, 'Total loss': 0.46068124676292593} | train loss {'Reaction outcome loss': 0.11536303720425678, 'Total loss': 0.11536303720425678}
2022-12-05 21:16:17,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:17,442 INFO:     Epoch: 94
2022-12-05 21:16:18,234 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46142839606512676, 'Total loss': 0.46142839606512676} | train loss {'Reaction outcome loss': 0.11747326062396471, 'Total loss': 0.11747326062396471}
2022-12-05 21:16:18,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:18,234 INFO:     Epoch: 95
2022-12-05 21:16:19,025 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4831552430987358, 'Total loss': 0.4831552430987358} | train loss {'Reaction outcome loss': 0.12168924103826587, 'Total loss': 0.12168924103826587}
2022-12-05 21:16:19,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:19,025 INFO:     Epoch: 96
2022-12-05 21:16:19,822 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45763609710742126, 'Total loss': 0.45763609710742126} | train loss {'Reaction outcome loss': 0.11491340753218905, 'Total loss': 0.11491340753218905}
2022-12-05 21:16:19,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:19,823 INFO:     Epoch: 97
2022-12-05 21:16:20,615 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4530671262605624, 'Total loss': 0.4530671262605624} | train loss {'Reaction outcome loss': 0.11974933740083385, 'Total loss': 0.11974933740083385}
2022-12-05 21:16:20,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:20,615 INFO:     Epoch: 98
2022-12-05 21:16:21,410 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45995091274380684, 'Total loss': 0.45995091274380684} | train loss {'Reaction outcome loss': 0.11548549444358117, 'Total loss': 0.11548549444358117}
2022-12-05 21:16:21,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:21,411 INFO:     Epoch: 99
2022-12-05 21:16:22,208 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4639889586039565, 'Total loss': 0.4639889586039565} | train loss {'Reaction outcome loss': 0.11447038442869237, 'Total loss': 0.11447038442869237}
2022-12-05 21:16:22,208 INFO:     Best model found after epoch 14 of 100.
2022-12-05 21:16:22,208 INFO:   Done with stage: TRAINING
2022-12-05 21:16:22,208 INFO:   Starting stage: EVALUATION
2022-12-05 21:16:22,333 INFO:   Done with stage: EVALUATION
2022-12-05 21:16:22,333 INFO:   Leaving out SEQ value Fold_7
2022-12-05 21:16:22,346 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:16:22,346 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:16:22,988 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:16:22,988 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:16:23,058 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:16:23,058 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:16:23,058 INFO:     No hyperparam tuning for this model
2022-12-05 21:16:23,058 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:16:23,058 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:16:23,059 INFO:     None feature selector for col prot
2022-12-05 21:16:23,059 INFO:     None feature selector for col prot
2022-12-05 21:16:23,059 INFO:     None feature selector for col prot
2022-12-05 21:16:23,059 INFO:     None feature selector for col chem
2022-12-05 21:16:23,060 INFO:     None feature selector for col chem
2022-12-05 21:16:23,060 INFO:     None feature selector for col chem
2022-12-05 21:16:23,060 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:16:23,060 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:16:23,061 INFO:     Number of params in model 215821
2022-12-05 21:16:23,064 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:16:23,064 INFO:   Starting stage: TRAINING
2022-12-05 21:16:23,125 INFO:     Val loss before train {'Reaction outcome loss': 1.0067657151005485, 'Total loss': 1.0067657151005485}
2022-12-05 21:16:23,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:23,125 INFO:     Epoch: 0
2022-12-05 21:16:23,924 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6060477075251666, 'Total loss': 0.6060477075251666} | train loss {'Reaction outcome loss': 0.7945224228164842, 'Total loss': 0.7945224228164842}
2022-12-05 21:16:23,924 INFO:     Found new best model at epoch 0
2022-12-05 21:16:23,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:23,925 INFO:     Epoch: 1
2022-12-05 21:16:24,724 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5159678967161612, 'Total loss': 0.5159678967161612} | train loss {'Reaction outcome loss': 0.5489093874010348, 'Total loss': 0.5489093874010348}
2022-12-05 21:16:24,724 INFO:     Found new best model at epoch 1
2022-12-05 21:16:24,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:24,725 INFO:     Epoch: 2
2022-12-05 21:16:25,518 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49299679459495976, 'Total loss': 0.49299679459495976} | train loss {'Reaction outcome loss': 0.4693387908440444, 'Total loss': 0.4693387908440444}
2022-12-05 21:16:25,519 INFO:     Found new best model at epoch 2
2022-12-05 21:16:25,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:25,519 INFO:     Epoch: 3
2022-12-05 21:16:26,320 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4620270034806295, 'Total loss': 0.4620270034806295} | train loss {'Reaction outcome loss': 0.4274429266130732, 'Total loss': 0.4274429266130732}
2022-12-05 21:16:26,321 INFO:     Found new best model at epoch 3
2022-12-05 21:16:26,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:26,321 INFO:     Epoch: 4
2022-12-05 21:16:27,119 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4569751864129847, 'Total loss': 0.4569751864129847} | train loss {'Reaction outcome loss': 0.3970942413434386, 'Total loss': 0.3970942413434386}
2022-12-05 21:16:27,119 INFO:     Found new best model at epoch 4
2022-12-05 21:16:27,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:27,120 INFO:     Epoch: 5
2022-12-05 21:16:27,920 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4515783336352218, 'Total loss': 0.4515783336352218} | train loss {'Reaction outcome loss': 0.3690805751229486, 'Total loss': 0.3690805751229486}
2022-12-05 21:16:27,920 INFO:     Found new best model at epoch 5
2022-12-05 21:16:27,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:27,922 INFO:     Epoch: 6
2022-12-05 21:16:28,719 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4500691426748579, 'Total loss': 0.4500691426748579} | train loss {'Reaction outcome loss': 0.35295616931492285, 'Total loss': 0.35295616931492285}
2022-12-05 21:16:28,719 INFO:     Found new best model at epoch 6
2022-12-05 21:16:28,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:28,720 INFO:     Epoch: 7
2022-12-05 21:16:29,523 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45335976068269124, 'Total loss': 0.45335976068269124} | train loss {'Reaction outcome loss': 0.33112677391017636, 'Total loss': 0.33112677391017636}
2022-12-05 21:16:29,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:29,524 INFO:     Epoch: 8
2022-12-05 21:16:30,322 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4354549300941554, 'Total loss': 0.4354549300941554} | train loss {'Reaction outcome loss': 0.31720439807301565, 'Total loss': 0.31720439807301565}
2022-12-05 21:16:30,322 INFO:     Found new best model at epoch 8
2022-12-05 21:16:30,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:30,323 INFO:     Epoch: 9
2022-12-05 21:16:31,123 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4400535103949634, 'Total loss': 0.4400535103949634} | train loss {'Reaction outcome loss': 0.304494327820477, 'Total loss': 0.304494327820477}
2022-12-05 21:16:31,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:31,123 INFO:     Epoch: 10
2022-12-05 21:16:31,919 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4458971121771769, 'Total loss': 0.4458971121771769} | train loss {'Reaction outcome loss': 0.29151893503242926, 'Total loss': 0.29151893503242926}
2022-12-05 21:16:31,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:31,919 INFO:     Epoch: 11
2022-12-05 21:16:32,720 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44246831062165176, 'Total loss': 0.44246831062165176} | train loss {'Reaction outcome loss': 0.2793649691307256, 'Total loss': 0.2793649691307256}
2022-12-05 21:16:32,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:32,720 INFO:     Epoch: 12
2022-12-05 21:16:33,517 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42783545228567993, 'Total loss': 0.42783545228567993} | train loss {'Reaction outcome loss': 0.2707858907749816, 'Total loss': 0.2707858907749816}
2022-12-05 21:16:33,517 INFO:     Found new best model at epoch 12
2022-12-05 21:16:33,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:33,518 INFO:     Epoch: 13
2022-12-05 21:16:34,321 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44769395379857585, 'Total loss': 0.44769395379857585} | train loss {'Reaction outcome loss': 0.2614716587047423, 'Total loss': 0.2614716587047423}
2022-12-05 21:16:34,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:34,321 INFO:     Epoch: 14
2022-12-05 21:16:35,121 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4436671303754503, 'Total loss': 0.4436671303754503} | train loss {'Reaction outcome loss': 0.24885340288822208, 'Total loss': 0.24885340288822208}
2022-12-05 21:16:35,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:35,121 INFO:     Epoch: 15
2022-12-05 21:16:35,918 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4358517950908704, 'Total loss': 0.4358517950908704} | train loss {'Reaction outcome loss': 0.24392166403272458, 'Total loss': 0.24392166403272458}
2022-12-05 21:16:35,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:35,919 INFO:     Epoch: 16
2022-12-05 21:16:36,715 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43731423298066313, 'Total loss': 0.43731423298066313} | train loss {'Reaction outcome loss': 0.2392865210741518, 'Total loss': 0.2392865210741518}
2022-12-05 21:16:36,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:36,716 INFO:     Epoch: 17
2022-12-05 21:16:37,515 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4274870333346454, 'Total loss': 0.4274870333346454} | train loss {'Reaction outcome loss': 0.23272601216130198, 'Total loss': 0.23272601216130198}
2022-12-05 21:16:37,515 INFO:     Found new best model at epoch 17
2022-12-05 21:16:37,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:37,517 INFO:     Epoch: 18
2022-12-05 21:16:38,311 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44619048488411034, 'Total loss': 0.44619048488411034} | train loss {'Reaction outcome loss': 0.2257854184736648, 'Total loss': 0.2257854184736648}
2022-12-05 21:16:38,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:38,311 INFO:     Epoch: 19
2022-12-05 21:16:39,108 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4449587952006947, 'Total loss': 0.4449587952006947} | train loss {'Reaction outcome loss': 0.22080944158557442, 'Total loss': 0.22080944158557442}
2022-12-05 21:16:39,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:39,109 INFO:     Epoch: 20
2022-12-05 21:16:39,908 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44076184928417206, 'Total loss': 0.44076184928417206} | train loss {'Reaction outcome loss': 0.21651981107049412, 'Total loss': 0.21651981107049412}
2022-12-05 21:16:39,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:39,909 INFO:     Epoch: 21
2022-12-05 21:16:40,710 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43344898081638594, 'Total loss': 0.43344898081638594} | train loss {'Reaction outcome loss': 0.21266908930133907, 'Total loss': 0.21266908930133907}
2022-12-05 21:16:40,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:40,710 INFO:     Epoch: 22
2022-12-05 21:16:41,513 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44208611480214377, 'Total loss': 0.44208611480214377} | train loss {'Reaction outcome loss': 0.20276016902719293, 'Total loss': 0.20276016902719293}
2022-12-05 21:16:41,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:41,513 INFO:     Epoch: 23
2022-12-05 21:16:42,311 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44925281168384984, 'Total loss': 0.44925281168384984} | train loss {'Reaction outcome loss': 0.20044685210732202, 'Total loss': 0.20044685210732202}
2022-12-05 21:16:42,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:42,311 INFO:     Epoch: 24
2022-12-05 21:16:43,109 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4476557309654626, 'Total loss': 0.4476557309654626} | train loss {'Reaction outcome loss': 0.19820260552449093, 'Total loss': 0.19820260552449093}
2022-12-05 21:16:43,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:43,109 INFO:     Epoch: 25
2022-12-05 21:16:43,906 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45839283700016414, 'Total loss': 0.45839283700016414} | train loss {'Reaction outcome loss': 0.1927801588279826, 'Total loss': 0.1927801588279826}
2022-12-05 21:16:43,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:43,906 INFO:     Epoch: 26
2022-12-05 21:16:44,703 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4613207114691084, 'Total loss': 0.4613207114691084} | train loss {'Reaction outcome loss': 0.1894260446931566, 'Total loss': 0.1894260446931566}
2022-12-05 21:16:44,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:44,703 INFO:     Epoch: 27
2022-12-05 21:16:45,501 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4615996696732261, 'Total loss': 0.4615996696732261} | train loss {'Reaction outcome loss': 0.18552652325841687, 'Total loss': 0.18552652325841687}
2022-12-05 21:16:45,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:45,501 INFO:     Epoch: 28
2022-12-05 21:16:46,306 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45431623980402946, 'Total loss': 0.45431623980402946} | train loss {'Reaction outcome loss': 0.18285347540832816, 'Total loss': 0.18285347540832816}
2022-12-05 21:16:46,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:46,306 INFO:     Epoch: 29
2022-12-05 21:16:47,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45121047273278236, 'Total loss': 0.45121047273278236} | train loss {'Reaction outcome loss': 0.18253416094868893, 'Total loss': 0.18253416094868893}
2022-12-05 21:16:47,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:47,105 INFO:     Epoch: 30
2022-12-05 21:16:47,901 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.451232006942684, 'Total loss': 0.451232006942684} | train loss {'Reaction outcome loss': 0.17755138270196416, 'Total loss': 0.17755138270196416}
2022-12-05 21:16:47,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:47,901 INFO:     Epoch: 31
2022-12-05 21:16:48,701 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46199755878611043, 'Total loss': 0.46199755878611043} | train loss {'Reaction outcome loss': 0.17600608433807088, 'Total loss': 0.17600608433807088}
2022-12-05 21:16:48,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:48,701 INFO:     Epoch: 32
2022-12-05 21:16:49,499 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45245425403118134, 'Total loss': 0.45245425403118134} | train loss {'Reaction outcome loss': 0.17232313891872764, 'Total loss': 0.17232313891872764}
2022-12-05 21:16:49,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:49,500 INFO:     Epoch: 33
2022-12-05 21:16:50,309 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4564429917796092, 'Total loss': 0.4564429917796092} | train loss {'Reaction outcome loss': 0.17222649530477582, 'Total loss': 0.17222649530477582}
2022-12-05 21:16:50,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:50,310 INFO:     Epoch: 34
2022-12-05 21:16:51,117 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4609067233448679, 'Total loss': 0.4609067233448679} | train loss {'Reaction outcome loss': 0.17035987408411118, 'Total loss': 0.17035987408411118}
2022-12-05 21:16:51,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:51,117 INFO:     Epoch: 35
2022-12-05 21:16:51,918 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4627899317578836, 'Total loss': 0.4627899317578836} | train loss {'Reaction outcome loss': 0.16781848424204415, 'Total loss': 0.16781848424204415}
2022-12-05 21:16:51,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:51,918 INFO:     Epoch: 36
2022-12-05 21:16:52,720 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.471766303547404, 'Total loss': 0.471766303547404} | train loss {'Reaction outcome loss': 0.16194085936783062, 'Total loss': 0.16194085936783062}
2022-12-05 21:16:52,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:52,720 INFO:     Epoch: 37
2022-12-05 21:16:53,521 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4828024645420638, 'Total loss': 0.4828024645420638} | train loss {'Reaction outcome loss': 0.1628453289233749, 'Total loss': 0.1628453289233749}
2022-12-05 21:16:53,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:53,521 INFO:     Epoch: 38
2022-12-05 21:16:54,320 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4549240456386046, 'Total loss': 0.4549240456386046} | train loss {'Reaction outcome loss': 0.15955299057907635, 'Total loss': 0.15955299057907635}
2022-12-05 21:16:54,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:54,320 INFO:     Epoch: 39
2022-12-05 21:16:55,122 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46712434613569215, 'Total loss': 0.46712434613569215} | train loss {'Reaction outcome loss': 0.15911637858728006, 'Total loss': 0.15911637858728006}
2022-12-05 21:16:55,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:55,123 INFO:     Epoch: 40
2022-12-05 21:16:55,929 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4735604683783921, 'Total loss': 0.4735604683783921} | train loss {'Reaction outcome loss': 0.16111428777296696, 'Total loss': 0.16111428777296696}
2022-12-05 21:16:55,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:55,930 INFO:     Epoch: 41
2022-12-05 21:16:56,731 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47181382876905525, 'Total loss': 0.47181382876905525} | train loss {'Reaction outcome loss': 0.15481482042870934, 'Total loss': 0.15481482042870934}
2022-12-05 21:16:56,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:56,732 INFO:     Epoch: 42
2022-12-05 21:16:57,529 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4648434565063905, 'Total loss': 0.4648434565063905} | train loss {'Reaction outcome loss': 0.15153177510646562, 'Total loss': 0.15153177510646562}
2022-12-05 21:16:57,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:57,529 INFO:     Epoch: 43
2022-12-05 21:16:58,323 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4838516756214879, 'Total loss': 0.4838516756214879} | train loss {'Reaction outcome loss': 0.15535880694346083, 'Total loss': 0.15535880694346083}
2022-12-05 21:16:58,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:58,323 INFO:     Epoch: 44
2022-12-05 21:16:59,117 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4657627154480327, 'Total loss': 0.4657627154480327} | train loss {'Reaction outcome loss': 0.15012955315215815, 'Total loss': 0.15012955315215815}
2022-12-05 21:16:59,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:59,117 INFO:     Epoch: 45
2022-12-05 21:16:59,912 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46490724046121945, 'Total loss': 0.46490724046121945} | train loss {'Reaction outcome loss': 0.14797629310651833, 'Total loss': 0.14797629310651833}
2022-12-05 21:16:59,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:16:59,912 INFO:     Epoch: 46
2022-12-05 21:17:00,709 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49061213501475076, 'Total loss': 0.49061213501475076} | train loss {'Reaction outcome loss': 0.14895272520070355, 'Total loss': 0.14895272520070355}
2022-12-05 21:17:00,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:00,709 INFO:     Epoch: 47
2022-12-05 21:17:01,504 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47829901494763116, 'Total loss': 0.47829901494763116} | train loss {'Reaction outcome loss': 0.14735291553511015, 'Total loss': 0.14735291553511015}
2022-12-05 21:17:01,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:01,504 INFO:     Epoch: 48
2022-12-05 21:17:02,298 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47907664626836777, 'Total loss': 0.47907664626836777} | train loss {'Reaction outcome loss': 0.14253018432927708, 'Total loss': 0.14253018432927708}
2022-12-05 21:17:02,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:02,298 INFO:     Epoch: 49
2022-12-05 21:17:03,095 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4841317165304314, 'Total loss': 0.4841317165304314} | train loss {'Reaction outcome loss': 0.1437598991643397, 'Total loss': 0.1437598991643397}
2022-12-05 21:17:03,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:03,095 INFO:     Epoch: 50
2022-12-05 21:17:03,894 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4720747875557704, 'Total loss': 0.4720747875557704} | train loss {'Reaction outcome loss': 0.14159625328536476, 'Total loss': 0.14159625328536476}
2022-12-05 21:17:03,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:03,895 INFO:     Epoch: 51
2022-12-05 21:17:04,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4757789745926857, 'Total loss': 0.4757789745926857} | train loss {'Reaction outcome loss': 0.1444553596703636, 'Total loss': 0.1444553596703636}
2022-12-05 21:17:04,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:04,693 INFO:     Epoch: 52
2022-12-05 21:17:05,489 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4755417267707261, 'Total loss': 0.4755417267707261} | train loss {'Reaction outcome loss': 0.14009439001881308, 'Total loss': 0.14009439001881308}
2022-12-05 21:17:05,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:05,490 INFO:     Epoch: 53
2022-12-05 21:17:06,286 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4831373549320481, 'Total loss': 0.4831373549320481} | train loss {'Reaction outcome loss': 0.14112290620593534, 'Total loss': 0.14112290620593534}
2022-12-05 21:17:06,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:06,286 INFO:     Epoch: 54
2022-12-05 21:17:07,082 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48341473056511447, 'Total loss': 0.48341473056511447} | train loss {'Reaction outcome loss': 0.13767970892255224, 'Total loss': 0.13767970892255224}
2022-12-05 21:17:07,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:07,082 INFO:     Epoch: 55
2022-12-05 21:17:07,878 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4891247776421634, 'Total loss': 0.4891247776421634} | train loss {'Reaction outcome loss': 0.13679904664956755, 'Total loss': 0.13679904664956755}
2022-12-05 21:17:07,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:07,878 INFO:     Epoch: 56
2022-12-05 21:17:08,675 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47307282347570767, 'Total loss': 0.47307282347570767} | train loss {'Reaction outcome loss': 0.13955594610512978, 'Total loss': 0.13955594610512978}
2022-12-05 21:17:08,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:08,675 INFO:     Epoch: 57
2022-12-05 21:17:09,474 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4886926439675418, 'Total loss': 0.4886926439675418} | train loss {'Reaction outcome loss': 0.13516223981916423, 'Total loss': 0.13516223981916423}
2022-12-05 21:17:09,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:09,475 INFO:     Epoch: 58
2022-12-05 21:17:10,274 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4837122156538747, 'Total loss': 0.4837122156538747} | train loss {'Reaction outcome loss': 0.13520364420518519, 'Total loss': 0.13520364420518519}
2022-12-05 21:17:10,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:10,274 INFO:     Epoch: 59
2022-12-05 21:17:11,067 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47945202920924535, 'Total loss': 0.47945202920924535} | train loss {'Reaction outcome loss': 0.13249943001315959, 'Total loss': 0.13249943001315959}
2022-12-05 21:17:11,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:11,067 INFO:     Epoch: 60
2022-12-05 21:17:11,863 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4966933158310977, 'Total loss': 0.4966933158310977} | train loss {'Reaction outcome loss': 0.13405557727110723, 'Total loss': 0.13405557727110723}
2022-12-05 21:17:11,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:11,863 INFO:     Epoch: 61
2022-12-05 21:17:12,656 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.480271307582205, 'Total loss': 0.480271307582205} | train loss {'Reaction outcome loss': 0.13258049276567274, 'Total loss': 0.13258049276567274}
2022-12-05 21:17:12,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:12,656 INFO:     Epoch: 62
2022-12-05 21:17:13,453 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4903075298802419, 'Total loss': 0.4903075298802419} | train loss {'Reaction outcome loss': 0.1320449135701863, 'Total loss': 0.1320449135701863}
2022-12-05 21:17:13,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:13,454 INFO:     Epoch: 63
2022-12-05 21:17:14,245 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4908301346004009, 'Total loss': 0.4908301346004009} | train loss {'Reaction outcome loss': 0.13281935442899984, 'Total loss': 0.13281935442899984}
2022-12-05 21:17:14,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:14,246 INFO:     Epoch: 64
2022-12-05 21:17:15,036 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4822642830285159, 'Total loss': 0.4822642830285159} | train loss {'Reaction outcome loss': 0.1315463368420399, 'Total loss': 0.1315463368420399}
2022-12-05 21:17:15,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:15,036 INFO:     Epoch: 65
2022-12-05 21:17:15,828 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5058483671058308, 'Total loss': 0.5058483671058308} | train loss {'Reaction outcome loss': 0.13145161568818073, 'Total loss': 0.13145161568818073}
2022-12-05 21:17:15,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:15,829 INFO:     Epoch: 66
2022-12-05 21:17:16,622 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5008993243629282, 'Total loss': 0.5008993243629282} | train loss {'Reaction outcome loss': 0.12906758608521834, 'Total loss': 0.12906758608521834}
2022-12-05 21:17:16,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:16,622 INFO:     Epoch: 67
2022-12-05 21:17:17,413 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4766750413585793, 'Total loss': 0.4766750413585793} | train loss {'Reaction outcome loss': 0.12853136509206267, 'Total loss': 0.12853136509206267}
2022-12-05 21:17:17,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:17,414 INFO:     Epoch: 68
2022-12-05 21:17:18,210 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4860665186054327, 'Total loss': 0.4860665186054327} | train loss {'Reaction outcome loss': 0.12883126578714338, 'Total loss': 0.12883126578714338}
2022-12-05 21:17:18,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:18,210 INFO:     Epoch: 69
2022-12-05 21:17:19,007 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5036138946359808, 'Total loss': 0.5036138946359808} | train loss {'Reaction outcome loss': 0.12842025511687802, 'Total loss': 0.12842025511687802}
2022-12-05 21:17:19,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:19,007 INFO:     Epoch: 70
2022-12-05 21:17:19,795 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4845596216619015, 'Total loss': 0.4845596216619015} | train loss {'Reaction outcome loss': 0.12627399453683005, 'Total loss': 0.12627399453683005}
2022-12-05 21:17:19,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:19,795 INFO:     Epoch: 71
2022-12-05 21:17:20,586 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49403002028438175, 'Total loss': 0.49403002028438175} | train loss {'Reaction outcome loss': 0.12920605892225379, 'Total loss': 0.12920605892225379}
2022-12-05 21:17:20,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:20,586 INFO:     Epoch: 72
2022-12-05 21:17:21,382 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5036813447421248, 'Total loss': 0.5036813447421248} | train loss {'Reaction outcome loss': 0.1249551544859705, 'Total loss': 0.1249551544859705}
2022-12-05 21:17:21,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:21,383 INFO:     Epoch: 73
2022-12-05 21:17:22,171 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4911215522072532, 'Total loss': 0.4911215522072532} | train loss {'Reaction outcome loss': 0.12555193870643816, 'Total loss': 0.12555193870643816}
2022-12-05 21:17:22,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:22,172 INFO:     Epoch: 74
2022-12-05 21:17:22,964 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49301366609605873, 'Total loss': 0.49301366609605873} | train loss {'Reaction outcome loss': 0.12000648472683444, 'Total loss': 0.12000648472683444}
2022-12-05 21:17:22,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:22,965 INFO:     Epoch: 75
2022-12-05 21:17:23,757 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4943199401552027, 'Total loss': 0.4943199401552027} | train loss {'Reaction outcome loss': 0.1248437617342138, 'Total loss': 0.1248437617342138}
2022-12-05 21:17:23,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:23,757 INFO:     Epoch: 76
2022-12-05 21:17:24,550 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48814762383699417, 'Total loss': 0.48814762383699417} | train loss {'Reaction outcome loss': 0.12400180986526632, 'Total loss': 0.12400180986526632}
2022-12-05 21:17:24,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:24,551 INFO:     Epoch: 77
2022-12-05 21:17:25,344 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4910604178228162, 'Total loss': 0.4910604178228162} | train loss {'Reaction outcome loss': 0.12555114496424194, 'Total loss': 0.12555114496424194}
2022-12-05 21:17:25,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:25,344 INFO:     Epoch: 78
2022-12-05 21:17:26,136 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48601919277147815, 'Total loss': 0.48601919277147815} | train loss {'Reaction outcome loss': 0.12514688192506232, 'Total loss': 0.12514688192506232}
2022-12-05 21:17:26,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:26,136 INFO:     Epoch: 79
2022-12-05 21:17:26,929 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49849435551600024, 'Total loss': 0.49849435551600024} | train loss {'Reaction outcome loss': 0.12074429712318364, 'Total loss': 0.12074429712318364}
2022-12-05 21:17:26,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:26,929 INFO:     Epoch: 80
2022-12-05 21:17:27,723 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5012088519605723, 'Total loss': 0.5012088519605723} | train loss {'Reaction outcome loss': 0.1213089241158037, 'Total loss': 0.1213089241158037}
2022-12-05 21:17:27,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:27,723 INFO:     Epoch: 81
2022-12-05 21:17:28,514 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49714919535273855, 'Total loss': 0.49714919535273855} | train loss {'Reaction outcome loss': 0.12135493744450111, 'Total loss': 0.12135493744450111}
2022-12-05 21:17:28,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:28,515 INFO:     Epoch: 82
2022-12-05 21:17:29,306 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4782544625076381, 'Total loss': 0.4782544625076381} | train loss {'Reaction outcome loss': 0.12248908135769589, 'Total loss': 0.12248908135769589}
2022-12-05 21:17:29,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:29,306 INFO:     Epoch: 83
2022-12-05 21:17:30,095 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49804429709911346, 'Total loss': 0.49804429709911346} | train loss {'Reaction outcome loss': 0.11945750421634124, 'Total loss': 0.11945750421634124}
2022-12-05 21:17:30,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:30,096 INFO:     Epoch: 84
2022-12-05 21:17:30,887 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4851229570128701, 'Total loss': 0.4851229570128701} | train loss {'Reaction outcome loss': 0.11985596488305036, 'Total loss': 0.11985596488305036}
2022-12-05 21:17:30,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:30,887 INFO:     Epoch: 85
2022-12-05 21:17:31,686 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4972259940748865, 'Total loss': 0.4972259940748865} | train loss {'Reaction outcome loss': 0.12039472770336415, 'Total loss': 0.12039472770336415}
2022-12-05 21:17:31,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:31,686 INFO:     Epoch: 86
2022-12-05 21:17:32,475 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5076134916056286, 'Total loss': 0.5076134916056286} | train loss {'Reaction outcome loss': 0.11863511317079106, 'Total loss': 0.11863511317079106}
2022-12-05 21:17:32,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:32,476 INFO:     Epoch: 87
2022-12-05 21:17:33,267 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4937196042050015, 'Total loss': 0.4937196042050015} | train loss {'Reaction outcome loss': 0.11841584350012484, 'Total loss': 0.11841584350012484}
2022-12-05 21:17:33,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:33,267 INFO:     Epoch: 88
2022-12-05 21:17:34,061 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4978153505785899, 'Total loss': 0.4978153505785899} | train loss {'Reaction outcome loss': 0.11830416018699086, 'Total loss': 0.11830416018699086}
2022-12-05 21:17:34,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:34,061 INFO:     Epoch: 89
2022-12-05 21:17:34,856 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49544838680462405, 'Total loss': 0.49544838680462405} | train loss {'Reaction outcome loss': 0.1198090658327865, 'Total loss': 0.1198090658327865}
2022-12-05 21:17:34,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:34,857 INFO:     Epoch: 90
2022-12-05 21:17:35,648 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49252390226518566, 'Total loss': 0.49252390226518566} | train loss {'Reaction outcome loss': 0.1207634205817275, 'Total loss': 0.1207634205817275}
2022-12-05 21:17:35,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:35,648 INFO:     Epoch: 91
2022-12-05 21:17:36,445 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4888830515132709, 'Total loss': 0.4888830515132709} | train loss {'Reaction outcome loss': 0.11882990135270502, 'Total loss': 0.11882990135270502}
2022-12-05 21:17:36,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:36,445 INFO:     Epoch: 92
2022-12-05 21:17:37,236 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4970312917774374, 'Total loss': 0.4970312917774374} | train loss {'Reaction outcome loss': 0.11715258998728748, 'Total loss': 0.11715258998728748}
2022-12-05 21:17:37,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:37,236 INFO:     Epoch: 93
2022-12-05 21:17:38,030 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49562430822036485, 'Total loss': 0.49562430822036485} | train loss {'Reaction outcome loss': 0.11855053429251476, 'Total loss': 0.11855053429251476}
2022-12-05 21:17:38,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:38,030 INFO:     Epoch: 94
2022-12-05 21:17:38,823 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49685311215845024, 'Total loss': 0.49685311215845024} | train loss {'Reaction outcome loss': 0.11837366756592546, 'Total loss': 0.11837366756592546}
2022-12-05 21:17:38,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:38,823 INFO:     Epoch: 95
2022-12-05 21:17:39,611 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49193761396137153, 'Total loss': 0.49193761396137153} | train loss {'Reaction outcome loss': 0.11748619477880458, 'Total loss': 0.11748619477880458}
2022-12-05 21:17:39,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:39,611 INFO:     Epoch: 96
2022-12-05 21:17:40,400 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5022661987353455, 'Total loss': 0.5022661987353455} | train loss {'Reaction outcome loss': 0.11672299131826167, 'Total loss': 0.11672299131826167}
2022-12-05 21:17:40,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:40,400 INFO:     Epoch: 97
2022-12-05 21:17:41,192 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5075887864963575, 'Total loss': 0.5075887864963575} | train loss {'Reaction outcome loss': 0.11663422459405998, 'Total loss': 0.11663422459405998}
2022-12-05 21:17:41,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:41,192 INFO:     Epoch: 98
2022-12-05 21:17:41,985 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5138017989017747, 'Total loss': 0.5138017989017747} | train loss {'Reaction outcome loss': 0.11626307695593324, 'Total loss': 0.11626307695593324}
2022-12-05 21:17:41,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:41,985 INFO:     Epoch: 99
2022-12-05 21:17:42,776 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49501484344628727, 'Total loss': 0.49501484344628727} | train loss {'Reaction outcome loss': 0.11612475954461843, 'Total loss': 0.11612475954461843}
2022-12-05 21:17:42,776 INFO:     Best model found after epoch 18 of 100.
2022-12-05 21:17:42,776 INFO:   Done with stage: TRAINING
2022-12-05 21:17:42,776 INFO:   Starting stage: EVALUATION
2022-12-05 21:17:42,895 INFO:   Done with stage: EVALUATION
2022-12-05 21:17:42,895 INFO:   Leaving out SEQ value Fold_8
2022-12-05 21:17:42,907 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:17:42,908 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:17:43,537 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:17:43,537 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:17:43,606 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:17:43,606 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:17:43,606 INFO:     No hyperparam tuning for this model
2022-12-05 21:17:43,606 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:17:43,606 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:17:43,607 INFO:     None feature selector for col prot
2022-12-05 21:17:43,607 INFO:     None feature selector for col prot
2022-12-05 21:17:43,607 INFO:     None feature selector for col prot
2022-12-05 21:17:43,608 INFO:     None feature selector for col chem
2022-12-05 21:17:43,608 INFO:     None feature selector for col chem
2022-12-05 21:17:43,608 INFO:     None feature selector for col chem
2022-12-05 21:17:43,608 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:17:43,608 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:17:43,610 INFO:     Number of params in model 215821
2022-12-05 21:17:43,613 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:17:43,613 INFO:   Starting stage: TRAINING
2022-12-05 21:17:43,671 INFO:     Val loss before train {'Reaction outcome loss': 0.9733213962510575, 'Total loss': 0.9733213962510575}
2022-12-05 21:17:43,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:43,672 INFO:     Epoch: 0
2022-12-05 21:17:44,446 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5758363507514777, 'Total loss': 0.5758363507514777} | train loss {'Reaction outcome loss': 0.7887272494005375, 'Total loss': 0.7887272494005375}
2022-12-05 21:17:44,447 INFO:     Found new best model at epoch 0
2022-12-05 21:17:44,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:44,447 INFO:     Epoch: 1
2022-12-05 21:17:45,225 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49514549658742063, 'Total loss': 0.49514549658742063} | train loss {'Reaction outcome loss': 0.5339999385178089, 'Total loss': 0.5339999385178089}
2022-12-05 21:17:45,225 INFO:     Found new best model at epoch 1
2022-12-05 21:17:45,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:45,226 INFO:     Epoch: 2
2022-12-05 21:17:46,001 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47109380641648935, 'Total loss': 0.47109380641648935} | train loss {'Reaction outcome loss': 0.46343787765649497, 'Total loss': 0.46343787765649497}
2022-12-05 21:17:46,001 INFO:     Found new best model at epoch 2
2022-12-05 21:17:46,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:46,002 INFO:     Epoch: 3
2022-12-05 21:17:46,783 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44864025157551435, 'Total loss': 0.44864025157551435} | train loss {'Reaction outcome loss': 0.4286783702182965, 'Total loss': 0.4286783702182965}
2022-12-05 21:17:46,783 INFO:     Found new best model at epoch 3
2022-12-05 21:17:46,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:46,784 INFO:     Epoch: 4
2022-12-05 21:17:47,562 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.436156245165093, 'Total loss': 0.436156245165093} | train loss {'Reaction outcome loss': 0.3992245722806356, 'Total loss': 0.3992245722806356}
2022-12-05 21:17:47,562 INFO:     Found new best model at epoch 4
2022-12-05 21:17:47,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:47,563 INFO:     Epoch: 5
2022-12-05 21:17:48,337 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4264405189558517, 'Total loss': 0.4264405189558517} | train loss {'Reaction outcome loss': 0.37940861235876555, 'Total loss': 0.37940861235876555}
2022-12-05 21:17:48,338 INFO:     Found new best model at epoch 5
2022-12-05 21:17:48,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:48,338 INFO:     Epoch: 6
2022-12-05 21:17:49,113 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4397603810526604, 'Total loss': 0.4397603810526604} | train loss {'Reaction outcome loss': 0.35806461924412214, 'Total loss': 0.35806461924412214}
2022-12-05 21:17:49,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:49,113 INFO:     Epoch: 7
2022-12-05 21:17:49,893 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4259624474270399, 'Total loss': 0.4259624474270399} | train loss {'Reaction outcome loss': 0.3434144594996679, 'Total loss': 0.3434144594996679}
2022-12-05 21:17:49,893 INFO:     Found new best model at epoch 7
2022-12-05 21:17:49,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:49,894 INFO:     Epoch: 8
2022-12-05 21:17:50,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4136089337773101, 'Total loss': 0.4136089337773101} | train loss {'Reaction outcome loss': 0.32802646784264533, 'Total loss': 0.32802646784264533}
2022-12-05 21:17:50,673 INFO:     Found new best model at epoch 8
2022-12-05 21:17:50,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:50,673 INFO:     Epoch: 9
2022-12-05 21:17:51,451 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41819155943948166, 'Total loss': 0.41819155943948166} | train loss {'Reaction outcome loss': 0.31587505771122015, 'Total loss': 0.31587505771122015}
2022-12-05 21:17:51,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:51,452 INFO:     Epoch: 10
2022-12-05 21:17:52,227 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41998289040354797, 'Total loss': 0.41998289040354797} | train loss {'Reaction outcome loss': 0.30263739491461733, 'Total loss': 0.30263739491461733}
2022-12-05 21:17:52,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:52,227 INFO:     Epoch: 11
2022-12-05 21:17:53,007 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4141649049381877, 'Total loss': 0.4141649049381877} | train loss {'Reaction outcome loss': 0.28942675708380877, 'Total loss': 0.28942675708380877}
2022-12-05 21:17:53,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:53,009 INFO:     Epoch: 12
2022-12-05 21:17:53,787 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4230745836745861, 'Total loss': 0.4230745836745861} | train loss {'Reaction outcome loss': 0.280965622636627, 'Total loss': 0.280965622636627}
2022-12-05 21:17:53,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:53,787 INFO:     Epoch: 13
2022-12-05 21:17:54,561 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41861634926740515, 'Total loss': 0.41861634926740515} | train loss {'Reaction outcome loss': 0.27297218131725903, 'Total loss': 0.27297218131725903}
2022-12-05 21:17:54,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:54,561 INFO:     Epoch: 14
2022-12-05 21:17:55,340 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40753236551617467, 'Total loss': 0.40753236551617467} | train loss {'Reaction outcome loss': 0.2633110432595503, 'Total loss': 0.2633110432595503}
2022-12-05 21:17:55,340 INFO:     Found new best model at epoch 14
2022-12-05 21:17:55,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:55,341 INFO:     Epoch: 15
2022-12-05 21:17:56,121 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4320701665656511, 'Total loss': 0.4320701665656511} | train loss {'Reaction outcome loss': 0.2549099859888436, 'Total loss': 0.2549099859888436}
2022-12-05 21:17:56,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:56,121 INFO:     Epoch: 16
2022-12-05 21:17:56,895 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4179037686350734, 'Total loss': 0.4179037686350734} | train loss {'Reaction outcome loss': 0.2488571739465487, 'Total loss': 0.2488571739465487}
2022-12-05 21:17:56,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:56,895 INFO:     Epoch: 17
2022-12-05 21:17:57,676 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42479739719352055, 'Total loss': 0.42479739719352055} | train loss {'Reaction outcome loss': 0.24010184825565972, 'Total loss': 0.24010184825565972}
2022-12-05 21:17:57,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:57,677 INFO:     Epoch: 18
2022-12-05 21:17:58,458 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4045859408933063, 'Total loss': 0.4045859408933063} | train loss {'Reaction outcome loss': 0.23509678050692454, 'Total loss': 0.23509678050692454}
2022-12-05 21:17:58,458 INFO:     Found new best model at epoch 18
2022-12-05 21:17:58,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:58,459 INFO:     Epoch: 19
2022-12-05 21:17:59,237 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41201120407082314, 'Total loss': 0.41201120407082314} | train loss {'Reaction outcome loss': 0.23062421218110402, 'Total loss': 0.23062421218110402}
2022-12-05 21:17:59,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:17:59,238 INFO:     Epoch: 20
2022-12-05 21:18:00,015 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42735531544962596, 'Total loss': 0.42735531544962596} | train loss {'Reaction outcome loss': 0.22156415566740956, 'Total loss': 0.22156415566740956}
2022-12-05 21:18:00,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:00,016 INFO:     Epoch: 21
2022-12-05 21:18:00,790 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4134247829747755, 'Total loss': 0.4134247829747755} | train loss {'Reaction outcome loss': 0.2189309808624084, 'Total loss': 0.2189309808624084}
2022-12-05 21:18:00,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:00,790 INFO:     Epoch: 22
2022-12-05 21:18:01,564 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4256685289532639, 'Total loss': 0.4256685289532639} | train loss {'Reaction outcome loss': 0.21357726626342438, 'Total loss': 0.21357726626342438}
2022-12-05 21:18:01,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:01,564 INFO:     Epoch: 23
2022-12-05 21:18:02,341 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42897621940734776, 'Total loss': 0.42897621940734776} | train loss {'Reaction outcome loss': 0.20980987091716685, 'Total loss': 0.20980987091716685}
2022-12-05 21:18:02,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:02,342 INFO:     Epoch: 24
2022-12-05 21:18:03,122 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4233099260302477, 'Total loss': 0.4233099260302477} | train loss {'Reaction outcome loss': 0.20141779399309, 'Total loss': 0.20141779399309}
2022-12-05 21:18:03,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:03,122 INFO:     Epoch: 25
2022-12-05 21:18:03,902 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42275891262431475, 'Total loss': 0.42275891262431475} | train loss {'Reaction outcome loss': 0.2004812026060507, 'Total loss': 0.2004812026060507}
2022-12-05 21:18:03,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:03,902 INFO:     Epoch: 26
2022-12-05 21:18:04,679 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4151574265818263, 'Total loss': 0.4151574265818263} | train loss {'Reaction outcome loss': 0.19610205926306423, 'Total loss': 0.19610205926306423}
2022-12-05 21:18:04,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:04,680 INFO:     Epoch: 27
2022-12-05 21:18:05,455 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4163365459372831, 'Total loss': 0.4163365459372831} | train loss {'Reaction outcome loss': 0.19142715799332152, 'Total loss': 0.19142715799332152}
2022-12-05 21:18:05,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:05,455 INFO:     Epoch: 28
2022-12-05 21:18:06,233 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4292946340039719, 'Total loss': 0.4292946340039719} | train loss {'Reaction outcome loss': 0.19184232514626423, 'Total loss': 0.19184232514626423}
2022-12-05 21:18:06,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:06,233 INFO:     Epoch: 29
2022-12-05 21:18:07,015 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.417204320084217, 'Total loss': 0.417204320084217} | train loss {'Reaction outcome loss': 0.1874004185474554, 'Total loss': 0.1874004185474554}
2022-12-05 21:18:07,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:07,015 INFO:     Epoch: 30
2022-12-05 21:18:07,798 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4227335782245148, 'Total loss': 0.4227335782245148} | train loss {'Reaction outcome loss': 0.1830304952216197, 'Total loss': 0.1830304952216197}
2022-12-05 21:18:07,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:07,798 INFO:     Epoch: 31
2022-12-05 21:18:08,579 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42959355233713636, 'Total loss': 0.42959355233713636} | train loss {'Reaction outcome loss': 0.18090747581550576, 'Total loss': 0.18090747581550576}
2022-12-05 21:18:08,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:08,580 INFO:     Epoch: 32
2022-12-05 21:18:09,360 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43224672869194386, 'Total loss': 0.43224672869194386} | train loss {'Reaction outcome loss': 0.17872333718982877, 'Total loss': 0.17872333718982877}
2022-12-05 21:18:09,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:09,360 INFO:     Epoch: 33
2022-12-05 21:18:10,137 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4164132867441621, 'Total loss': 0.4164132867441621} | train loss {'Reaction outcome loss': 0.17729763863760917, 'Total loss': 0.17729763863760917}
2022-12-05 21:18:10,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:10,137 INFO:     Epoch: 34
2022-12-05 21:18:10,920 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4254548598167508, 'Total loss': 0.4254548598167508} | train loss {'Reaction outcome loss': 0.17334470166595745, 'Total loss': 0.17334470166595745}
2022-12-05 21:18:10,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:10,920 INFO:     Epoch: 35
2022-12-05 21:18:11,709 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42739306667516397, 'Total loss': 0.42739306667516397} | train loss {'Reaction outcome loss': 0.17107507280364145, 'Total loss': 0.17107507280364145}
2022-12-05 21:18:11,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:11,710 INFO:     Epoch: 36
2022-12-05 21:18:12,497 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42448561863843787, 'Total loss': 0.42448561863843787} | train loss {'Reaction outcome loss': 0.16815585479689915, 'Total loss': 0.16815585479689915}
2022-12-05 21:18:12,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:12,497 INFO:     Epoch: 37
2022-12-05 21:18:13,282 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42862496057222055, 'Total loss': 0.42862496057222055} | train loss {'Reaction outcome loss': 0.16800082758924023, 'Total loss': 0.16800082758924023}
2022-12-05 21:18:13,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:13,283 INFO:     Epoch: 38
2022-12-05 21:18:14,073 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44665189468583394, 'Total loss': 0.44665189468583394} | train loss {'Reaction outcome loss': 0.16356914224042024, 'Total loss': 0.16356914224042024}
2022-12-05 21:18:14,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:14,074 INFO:     Epoch: 39
2022-12-05 21:18:14,860 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43406625334606613, 'Total loss': 0.43406625334606613} | train loss {'Reaction outcome loss': 0.1640664446014972, 'Total loss': 0.1640664446014972}
2022-12-05 21:18:14,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:14,860 INFO:     Epoch: 40
2022-12-05 21:18:15,649 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43970784544944763, 'Total loss': 0.43970784544944763} | train loss {'Reaction outcome loss': 0.15969295646292997, 'Total loss': 0.15969295646292997}
2022-12-05 21:18:15,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:15,649 INFO:     Epoch: 41
2022-12-05 21:18:16,440 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43180555278478666, 'Total loss': 0.43180555278478666} | train loss {'Reaction outcome loss': 0.1594286638113563, 'Total loss': 0.1594286638113563}
2022-12-05 21:18:16,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:16,440 INFO:     Epoch: 42
2022-12-05 21:18:17,229 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4459481371003528, 'Total loss': 0.4459481371003528} | train loss {'Reaction outcome loss': 0.15933231639935344, 'Total loss': 0.15933231639935344}
2022-12-05 21:18:17,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:17,229 INFO:     Epoch: 43
2022-12-05 21:18:18,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.434930075046628, 'Total loss': 0.434930075046628} | train loss {'Reaction outcome loss': 0.1564907756802, 'Total loss': 0.1564907756802}
2022-12-05 21:18:18,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:18,016 INFO:     Epoch: 44
2022-12-05 21:18:18,803 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4226844955322354, 'Total loss': 0.4226844955322354} | train loss {'Reaction outcome loss': 0.15429876553902372, 'Total loss': 0.15429876553902372}
2022-12-05 21:18:18,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:18,803 INFO:     Epoch: 45
2022-12-05 21:18:19,592 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4307933564102927, 'Total loss': 0.4307933564102927} | train loss {'Reaction outcome loss': 0.15040875815587942, 'Total loss': 0.15040875815587942}
2022-12-05 21:18:19,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:19,592 INFO:     Epoch: 46
2022-12-05 21:18:20,378 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4366749788439551, 'Total loss': 0.4366749788439551} | train loss {'Reaction outcome loss': 0.14949518618494517, 'Total loss': 0.14949518618494517}
2022-12-05 21:18:20,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:20,378 INFO:     Epoch: 47
2022-12-05 21:18:21,164 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.441105866674767, 'Total loss': 0.441105866674767} | train loss {'Reaction outcome loss': 0.14829787150880352, 'Total loss': 0.14829787150880352}
2022-12-05 21:18:21,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:21,164 INFO:     Epoch: 48
2022-12-05 21:18:21,956 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.432217335631681, 'Total loss': 0.432217335631681} | train loss {'Reaction outcome loss': 0.1489846515621929, 'Total loss': 0.1489846515621929}
2022-12-05 21:18:21,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:21,957 INFO:     Epoch: 49
2022-12-05 21:18:22,748 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4330301468455514, 'Total loss': 0.4330301468455514} | train loss {'Reaction outcome loss': 0.14974734997834827, 'Total loss': 0.14974734997834827}
2022-12-05 21:18:22,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:22,748 INFO:     Epoch: 50
2022-12-05 21:18:23,537 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43477288200411685, 'Total loss': 0.43477288200411685} | train loss {'Reaction outcome loss': 0.14778260955373285, 'Total loss': 0.14778260955373285}
2022-12-05 21:18:23,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:23,537 INFO:     Epoch: 51
2022-12-05 21:18:24,328 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4491314638492673, 'Total loss': 0.4491314638492673} | train loss {'Reaction outcome loss': 0.14485468379542477, 'Total loss': 0.14485468379542477}
2022-12-05 21:18:24,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:24,330 INFO:     Epoch: 52
2022-12-05 21:18:25,123 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4283336487620376, 'Total loss': 0.4283336487620376} | train loss {'Reaction outcome loss': 0.1425422356830391, 'Total loss': 0.1425422356830391}
2022-12-05 21:18:25,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:25,123 INFO:     Epoch: 53
2022-12-05 21:18:25,916 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4237839340470558, 'Total loss': 0.4237839340470558} | train loss {'Reaction outcome loss': 0.13986797212455115, 'Total loss': 0.13986797212455115}
2022-12-05 21:18:25,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:25,916 INFO:     Epoch: 54
2022-12-05 21:18:26,705 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43769541954578356, 'Total loss': 0.43769541954578356} | train loss {'Reaction outcome loss': 0.14080986073316976, 'Total loss': 0.14080986073316976}
2022-12-05 21:18:26,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:26,705 INFO:     Epoch: 55
2022-12-05 21:18:27,499 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43195658870214637, 'Total loss': 0.43195658870214637} | train loss {'Reaction outcome loss': 0.14103287026347194, 'Total loss': 0.14103287026347194}
2022-12-05 21:18:27,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:27,499 INFO:     Epoch: 56
2022-12-05 21:18:28,294 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4358540603587794, 'Total loss': 0.4358540603587794} | train loss {'Reaction outcome loss': 0.139814496269358, 'Total loss': 0.139814496269358}
2022-12-05 21:18:28,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:28,294 INFO:     Epoch: 57
2022-12-05 21:18:29,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.446727606446244, 'Total loss': 0.446727606446244} | train loss {'Reaction outcome loss': 0.13843507658629145, 'Total loss': 0.13843507658629145}
2022-12-05 21:18:29,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:29,080 INFO:     Epoch: 58
2022-12-05 21:18:29,869 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43967896613270735, 'Total loss': 0.43967896613270735} | train loss {'Reaction outcome loss': 0.1405532867037004, 'Total loss': 0.1405532867037004}
2022-12-05 21:18:29,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:29,869 INFO:     Epoch: 59
2022-12-05 21:18:30,656 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4277216492350711, 'Total loss': 0.4277216492350711} | train loss {'Reaction outcome loss': 0.13809659674794214, 'Total loss': 0.13809659674794214}
2022-12-05 21:18:30,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:30,657 INFO:     Epoch: 60
2022-12-05 21:18:31,443 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43127633960441103, 'Total loss': 0.43127633960441103} | train loss {'Reaction outcome loss': 0.13554324473055904, 'Total loss': 0.13554324473055904}
2022-12-05 21:18:31,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:31,443 INFO:     Epoch: 61
2022-12-05 21:18:32,232 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43716118614687477, 'Total loss': 0.43716118614687477} | train loss {'Reaction outcome loss': 0.13420539826429526, 'Total loss': 0.13420539826429526}
2022-12-05 21:18:32,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:32,232 INFO:     Epoch: 62
2022-12-05 21:18:33,021 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45266178354274395, 'Total loss': 0.45266178354274395} | train loss {'Reaction outcome loss': 0.1353616156905401, 'Total loss': 0.1353616156905401}
2022-12-05 21:18:33,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:33,021 INFO:     Epoch: 63
2022-12-05 21:18:33,813 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4388642099707626, 'Total loss': 0.4388642099707626} | train loss {'Reaction outcome loss': 0.13521530613547467, 'Total loss': 0.13521530613547467}
2022-12-05 21:18:33,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:33,814 INFO:     Epoch: 64
2022-12-05 21:18:34,600 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4383500696614731, 'Total loss': 0.4383500696614731} | train loss {'Reaction outcome loss': 0.13471368416288837, 'Total loss': 0.13471368416288837}
2022-12-05 21:18:34,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:34,600 INFO:     Epoch: 65
2022-12-05 21:18:35,385 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4390427969222845, 'Total loss': 0.4390427969222845} | train loss {'Reaction outcome loss': 0.13113024623560735, 'Total loss': 0.13113024623560735}
2022-12-05 21:18:35,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:35,386 INFO:     Epoch: 66
2022-12-05 21:18:36,175 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4502072888751363, 'Total loss': 0.4502072888751363} | train loss {'Reaction outcome loss': 0.13339865806924758, 'Total loss': 0.13339865806924758}
2022-12-05 21:18:36,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:36,175 INFO:     Epoch: 67
2022-12-05 21:18:36,961 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44614961362162303, 'Total loss': 0.44614961362162303} | train loss {'Reaction outcome loss': 0.1303534682030927, 'Total loss': 0.1303534682030927}
2022-12-05 21:18:36,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:36,961 INFO:     Epoch: 68
2022-12-05 21:18:37,747 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43807365242824997, 'Total loss': 0.43807365242824997} | train loss {'Reaction outcome loss': 0.13212655892320832, 'Total loss': 0.13212655892320832}
2022-12-05 21:18:37,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:37,748 INFO:     Epoch: 69
2022-12-05 21:18:38,539 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4413037028077037, 'Total loss': 0.4413037028077037} | train loss {'Reaction outcome loss': 0.13196993466527734, 'Total loss': 0.13196993466527734}
2022-12-05 21:18:38,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:38,540 INFO:     Epoch: 70
2022-12-05 21:18:39,332 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44625279411327007, 'Total loss': 0.44625279411327007} | train loss {'Reaction outcome loss': 0.12995865370040058, 'Total loss': 0.12995865370040058}
2022-12-05 21:18:39,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:39,332 INFO:     Epoch: 71
2022-12-05 21:18:40,127 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4567579313419586, 'Total loss': 0.4567579313419586} | train loss {'Reaction outcome loss': 0.12715221901775384, 'Total loss': 0.12715221901775384}
2022-12-05 21:18:40,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:40,127 INFO:     Epoch: 72
2022-12-05 21:18:40,924 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4246567595143651, 'Total loss': 0.4246567595143651} | train loss {'Reaction outcome loss': 0.12885417422035433, 'Total loss': 0.12885417422035433}
2022-12-05 21:18:40,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:40,924 INFO:     Epoch: 73
2022-12-05 21:18:41,717 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.452508095391961, 'Total loss': 0.452508095391961} | train loss {'Reaction outcome loss': 0.129101428707115, 'Total loss': 0.129101428707115}
2022-12-05 21:18:41,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:41,718 INFO:     Epoch: 74
2022-12-05 21:18:42,515 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4427983150925747, 'Total loss': 0.4427983150925747} | train loss {'Reaction outcome loss': 0.12665987682727273, 'Total loss': 0.12665987682727273}
2022-12-05 21:18:42,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:42,516 INFO:     Epoch: 75
2022-12-05 21:18:43,308 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4301523843476939, 'Total loss': 0.4301523843476939} | train loss {'Reaction outcome loss': 0.12701160852324034, 'Total loss': 0.12701160852324034}
2022-12-05 21:18:43,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:43,309 INFO:     Epoch: 76
2022-12-05 21:18:44,101 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44068932567918023, 'Total loss': 0.44068932567918023} | train loss {'Reaction outcome loss': 0.12435234989589233, 'Total loss': 0.12435234989589233}
2022-12-05 21:18:44,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:44,101 INFO:     Epoch: 77
2022-12-05 21:18:44,891 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45928311555884604, 'Total loss': 0.45928311555884604} | train loss {'Reaction outcome loss': 0.12727738452357712, 'Total loss': 0.12727738452357712}
2022-12-05 21:18:44,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:44,892 INFO:     Epoch: 78
2022-12-05 21:18:45,683 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43842494626377904, 'Total loss': 0.43842494626377904} | train loss {'Reaction outcome loss': 0.1266834744420208, 'Total loss': 0.1266834744420208}
2022-12-05 21:18:45,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:45,683 INFO:     Epoch: 79
2022-12-05 21:18:46,477 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4585429357234822, 'Total loss': 0.4585429357234822} | train loss {'Reaction outcome loss': 0.1258246612383938, 'Total loss': 0.1258246612383938}
2022-12-05 21:18:46,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:46,477 INFO:     Epoch: 80
2022-12-05 21:18:47,273 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4426317031300345, 'Total loss': 0.4426317031300345} | train loss {'Reaction outcome loss': 0.12326877913056095, 'Total loss': 0.12326877913056095}
2022-12-05 21:18:47,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:47,273 INFO:     Epoch: 81
2022-12-05 21:18:48,063 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44560835077319033, 'Total loss': 0.44560835077319033} | train loss {'Reaction outcome loss': 0.12299079348363715, 'Total loss': 0.12299079348363715}
2022-12-05 21:18:48,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:48,063 INFO:     Epoch: 82
2022-12-05 21:18:48,853 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4334553542525269, 'Total loss': 0.4334553542525269} | train loss {'Reaction outcome loss': 0.1259633341430091, 'Total loss': 0.1259633341430091}
2022-12-05 21:18:48,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:48,853 INFO:     Epoch: 83
2022-12-05 21:18:49,643 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4392482787370682, 'Total loss': 0.4392482787370682} | train loss {'Reaction outcome loss': 0.12277055208067425, 'Total loss': 0.12277055208067425}
2022-12-05 21:18:49,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:49,643 INFO:     Epoch: 84
2022-12-05 21:18:50,434 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43676176840482756, 'Total loss': 0.43676176840482756} | train loss {'Reaction outcome loss': 0.12287525640281498, 'Total loss': 0.12287525640281498}
2022-12-05 21:18:50,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:50,434 INFO:     Epoch: 85
2022-12-05 21:18:51,224 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42913266046102655, 'Total loss': 0.42913266046102655} | train loss {'Reaction outcome loss': 0.12337172367671108, 'Total loss': 0.12337172367671108}
2022-12-05 21:18:51,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:51,225 INFO:     Epoch: 86
2022-12-05 21:18:52,019 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45270160429699474, 'Total loss': 0.45270160429699474} | train loss {'Reaction outcome loss': 0.12475860694835543, 'Total loss': 0.12475860694835543}
2022-12-05 21:18:52,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:52,019 INFO:     Epoch: 87
2022-12-05 21:18:52,810 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42710316319798314, 'Total loss': 0.42710316319798314} | train loss {'Reaction outcome loss': 0.12015373367800943, 'Total loss': 0.12015373367800943}
2022-12-05 21:18:52,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:52,811 INFO:     Epoch: 88
2022-12-05 21:18:53,600 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4316528124171634, 'Total loss': 0.4316528124171634} | train loss {'Reaction outcome loss': 0.12242827343288809, 'Total loss': 0.12242827343288809}
2022-12-05 21:18:53,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:53,600 INFO:     Epoch: 89
2022-12-05 21:18:54,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42605651273976924, 'Total loss': 0.42605651273976924} | train loss {'Reaction outcome loss': 0.1226834604386851, 'Total loss': 0.1226834604386851}
2022-12-05 21:18:54,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:54,393 INFO:     Epoch: 90
2022-12-05 21:18:55,183 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4514193361581758, 'Total loss': 0.4514193361581758} | train loss {'Reaction outcome loss': 0.12081100598939495, 'Total loss': 0.12081100598939495}
2022-12-05 21:18:55,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:55,184 INFO:     Epoch: 91
2022-12-05 21:18:55,976 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.453352129736612, 'Total loss': 0.453352129736612} | train loss {'Reaction outcome loss': 0.12225339133254268, 'Total loss': 0.12225339133254268}
2022-12-05 21:18:55,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:55,977 INFO:     Epoch: 92
2022-12-05 21:18:56,770 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45894991103992905, 'Total loss': 0.45894991103992905} | train loss {'Reaction outcome loss': 0.11956855766360694, 'Total loss': 0.11956855766360694}
2022-12-05 21:18:56,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:56,770 INFO:     Epoch: 93
2022-12-05 21:18:57,562 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4490674806888713, 'Total loss': 0.4490674806888713} | train loss {'Reaction outcome loss': 0.12053816503326058, 'Total loss': 0.12053816503326058}
2022-12-05 21:18:57,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:57,563 INFO:     Epoch: 94
2022-12-05 21:18:58,354 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4558269485484722, 'Total loss': 0.4558269485484722} | train loss {'Reaction outcome loss': 0.12030387265210757, 'Total loss': 0.12030387265210757}
2022-12-05 21:18:58,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:58,354 INFO:     Epoch: 95
2022-12-05 21:18:59,142 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4511539121699888, 'Total loss': 0.4511539121699888} | train loss {'Reaction outcome loss': 0.11884046543664376, 'Total loss': 0.11884046543664376}
2022-12-05 21:18:59,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:59,142 INFO:     Epoch: 96
2022-12-05 21:18:59,931 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4312549482078053, 'Total loss': 0.4312549482078053} | train loss {'Reaction outcome loss': 0.11961455950437144, 'Total loss': 0.11961455950437144}
2022-12-05 21:18:59,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:18:59,931 INFO:     Epoch: 97
2022-12-05 21:19:00,720 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4404306858778, 'Total loss': 0.4404306858778} | train loss {'Reaction outcome loss': 0.11758748336588262, 'Total loss': 0.11758748336588262}
2022-12-05 21:19:00,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:00,720 INFO:     Epoch: 98
2022-12-05 21:19:01,517 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4502938005120255, 'Total loss': 0.4502938005120255} | train loss {'Reaction outcome loss': 0.11745891876549261, 'Total loss': 0.11745891876549261}
2022-12-05 21:19:01,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:01,518 INFO:     Epoch: 99
2022-12-05 21:19:02,310 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43804208258556765, 'Total loss': 0.43804208258556765} | train loss {'Reaction outcome loss': 0.1187273704782739, 'Total loss': 0.1187273704782739}
2022-12-05 21:19:02,310 INFO:     Best model found after epoch 19 of 100.
2022-12-05 21:19:02,310 INFO:   Done with stage: TRAINING
2022-12-05 21:19:02,310 INFO:   Starting stage: EVALUATION
2022-12-05 21:19:02,447 INFO:   Done with stage: EVALUATION
2022-12-05 21:19:02,448 INFO:   Leaving out SEQ value Fold_9
2022-12-05 21:19:02,460 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:19:02,460 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:19:03,102 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:19:03,103 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:19:03,173 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:19:03,173 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:19:03,173 INFO:     No hyperparam tuning for this model
2022-12-05 21:19:03,173 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:19:03,173 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:19:03,174 INFO:     None feature selector for col prot
2022-12-05 21:19:03,174 INFO:     None feature selector for col prot
2022-12-05 21:19:03,174 INFO:     None feature selector for col prot
2022-12-05 21:19:03,175 INFO:     None feature selector for col chem
2022-12-05 21:19:03,175 INFO:     None feature selector for col chem
2022-12-05 21:19:03,175 INFO:     None feature selector for col chem
2022-12-05 21:19:03,175 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:19:03,175 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:19:03,177 INFO:     Number of params in model 215821
2022-12-05 21:19:03,180 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:19:03,180 INFO:   Starting stage: TRAINING
2022-12-05 21:19:03,241 INFO:     Val loss before train {'Reaction outcome loss': 1.029214310375127, 'Total loss': 1.029214310375127}
2022-12-05 21:19:03,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:03,241 INFO:     Epoch: 0
2022-12-05 21:19:04,043 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6250948479229753, 'Total loss': 0.6250948479229753} | train loss {'Reaction outcome loss': 0.7826142925168237, 'Total loss': 0.7826142925168237}
2022-12-05 21:19:04,043 INFO:     Found new best model at epoch 0
2022-12-05 21:19:04,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:04,044 INFO:     Epoch: 1
2022-12-05 21:19:04,853 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5374661751768806, 'Total loss': 0.5374661751768806} | train loss {'Reaction outcome loss': 0.5446661951080445, 'Total loss': 0.5446661951080445}
2022-12-05 21:19:04,853 INFO:     Found new best model at epoch 1
2022-12-05 21:19:04,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:04,854 INFO:     Epoch: 2
2022-12-05 21:19:05,661 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4987077211791819, 'Total loss': 0.4987077211791819} | train loss {'Reaction outcome loss': 0.47376023947952256, 'Total loss': 0.47376023947952256}
2022-12-05 21:19:05,661 INFO:     Found new best model at epoch 2
2022-12-05 21:19:05,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:05,662 INFO:     Epoch: 3
2022-12-05 21:19:06,465 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4855038750578057, 'Total loss': 0.4855038750578057} | train loss {'Reaction outcome loss': 0.4366428246120772, 'Total loss': 0.4366428246120772}
2022-12-05 21:19:06,465 INFO:     Found new best model at epoch 3
2022-12-05 21:19:06,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:06,466 INFO:     Epoch: 4
2022-12-05 21:19:07,268 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45747548375617375, 'Total loss': 0.45747548375617375} | train loss {'Reaction outcome loss': 0.4080815762581845, 'Total loss': 0.4080815762581845}
2022-12-05 21:19:07,268 INFO:     Found new best model at epoch 4
2022-12-05 21:19:07,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:07,269 INFO:     Epoch: 5
2022-12-05 21:19:08,071 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4454146440733563, 'Total loss': 0.4454146440733563} | train loss {'Reaction outcome loss': 0.3874558284878731, 'Total loss': 0.3874558284878731}
2022-12-05 21:19:08,071 INFO:     Found new best model at epoch 5
2022-12-05 21:19:08,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:08,072 INFO:     Epoch: 6
2022-12-05 21:19:08,879 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4488276551392945, 'Total loss': 0.4488276551392945} | train loss {'Reaction outcome loss': 0.3718516571266997, 'Total loss': 0.3718516571266997}
2022-12-05 21:19:08,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:08,879 INFO:     Epoch: 7
2022-12-05 21:19:09,675 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42901051112196664, 'Total loss': 0.42901051112196664} | train loss {'Reaction outcome loss': 0.35600138023014993, 'Total loss': 0.35600138023014993}
2022-12-05 21:19:09,676 INFO:     Found new best model at epoch 7
2022-12-05 21:19:09,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:09,676 INFO:     Epoch: 8
2022-12-05 21:19:10,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4211325367743319, 'Total loss': 0.4211325367743319} | train loss {'Reaction outcome loss': 0.33902930345145926, 'Total loss': 0.33902930345145926}
2022-12-05 21:19:10,470 INFO:     Found new best model at epoch 8
2022-12-05 21:19:10,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:10,471 INFO:     Epoch: 9
2022-12-05 21:19:11,263 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42436794157732616, 'Total loss': 0.42436794157732616} | train loss {'Reaction outcome loss': 0.32526864569574115, 'Total loss': 0.32526864569574115}
2022-12-05 21:19:11,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:11,263 INFO:     Epoch: 10
2022-12-05 21:19:12,059 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4233821633864533, 'Total loss': 0.4233821633864533} | train loss {'Reaction outcome loss': 0.3122187948996021, 'Total loss': 0.3122187948996021}
2022-12-05 21:19:12,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:12,059 INFO:     Epoch: 11
2022-12-05 21:19:12,853 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43344777483831753, 'Total loss': 0.43344777483831753} | train loss {'Reaction outcome loss': 0.30176435227716164, 'Total loss': 0.30176435227716164}
2022-12-05 21:19:12,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:12,853 INFO:     Epoch: 12
2022-12-05 21:19:13,649 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4125343402000991, 'Total loss': 0.4125343402000991} | train loss {'Reaction outcome loss': 0.2895285746292962, 'Total loss': 0.2895285746292962}
2022-12-05 21:19:13,650 INFO:     Found new best model at epoch 12
2022-12-05 21:19:13,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:13,651 INFO:     Epoch: 13
2022-12-05 21:19:14,456 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41775883598761127, 'Total loss': 0.41775883598761127} | train loss {'Reaction outcome loss': 0.27912765092426733, 'Total loss': 0.27912765092426733}
2022-12-05 21:19:14,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:14,456 INFO:     Epoch: 14
2022-12-05 21:19:15,263 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41570874743840913, 'Total loss': 0.41570874743840913} | train loss {'Reaction outcome loss': 0.2679481937760307, 'Total loss': 0.2679481937760307}
2022-12-05 21:19:15,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:15,263 INFO:     Epoch: 15
2022-12-05 21:19:16,066 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4224785012616353, 'Total loss': 0.4224785012616353} | train loss {'Reaction outcome loss': 0.26242995398840113, 'Total loss': 0.26242995398840113}
2022-12-05 21:19:16,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:16,066 INFO:     Epoch: 16
2022-12-05 21:19:16,871 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43927825174548407, 'Total loss': 0.43927825174548407} | train loss {'Reaction outcome loss': 0.2527975135092293, 'Total loss': 0.2527975135092293}
2022-12-05 21:19:16,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:16,871 INFO:     Epoch: 17
2022-12-05 21:19:17,676 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41326201300729404, 'Total loss': 0.41326201300729404} | train loss {'Reaction outcome loss': 0.24844863925189262, 'Total loss': 0.24844863925189262}
2022-12-05 21:19:17,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:17,676 INFO:     Epoch: 18
2022-12-05 21:19:18,481 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4134255200624466, 'Total loss': 0.4134255200624466} | train loss {'Reaction outcome loss': 0.2384520030219949, 'Total loss': 0.2384520030219949}
2022-12-05 21:19:18,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:18,481 INFO:     Epoch: 19
2022-12-05 21:19:19,289 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4262027076699517, 'Total loss': 0.4262027076699517} | train loss {'Reaction outcome loss': 0.23275679563202203, 'Total loss': 0.23275679563202203}
2022-12-05 21:19:19,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:19,289 INFO:     Epoch: 20
2022-12-05 21:19:20,093 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4274375553835522, 'Total loss': 0.4274375553835522} | train loss {'Reaction outcome loss': 0.23090374416431353, 'Total loss': 0.23090374416431353}
2022-12-05 21:19:20,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:20,094 INFO:     Epoch: 21
2022-12-05 21:19:20,900 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45449729602445255, 'Total loss': 0.45449729602445255} | train loss {'Reaction outcome loss': 0.2233919538857956, 'Total loss': 0.2233919538857956}
2022-12-05 21:19:20,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:20,901 INFO:     Epoch: 22
2022-12-05 21:19:21,704 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4306596087461168, 'Total loss': 0.4306596087461168} | train loss {'Reaction outcome loss': 0.2181767588481307, 'Total loss': 0.2181767588481307}
2022-12-05 21:19:21,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:21,704 INFO:     Epoch: 23
2022-12-05 21:19:22,508 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42920250682668254, 'Total loss': 0.42920250682668254} | train loss {'Reaction outcome loss': 0.21147268681576656, 'Total loss': 0.21147268681576656}
2022-12-05 21:19:22,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:22,508 INFO:     Epoch: 24
2022-12-05 21:19:23,310 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43021105297587137, 'Total loss': 0.43021105297587137} | train loss {'Reaction outcome loss': 0.20643635591371887, 'Total loss': 0.20643635591371887}
2022-12-05 21:19:23,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:23,311 INFO:     Epoch: 25
2022-12-05 21:19:24,109 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43259502947330475, 'Total loss': 0.43259502947330475} | train loss {'Reaction outcome loss': 0.20313564617367041, 'Total loss': 0.20313564617367041}
2022-12-05 21:19:24,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:24,110 INFO:     Epoch: 26
2022-12-05 21:19:24,909 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4361529651690613, 'Total loss': 0.4361529651690613} | train loss {'Reaction outcome loss': 0.19912218871796805, 'Total loss': 0.19912218871796805}
2022-12-05 21:19:24,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:24,909 INFO:     Epoch: 27
2022-12-05 21:19:25,717 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4447484263642268, 'Total loss': 0.4447484263642268} | train loss {'Reaction outcome loss': 0.19507550338523522, 'Total loss': 0.19507550338523522}
2022-12-05 21:19:25,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:25,719 INFO:     Epoch: 28
2022-12-05 21:19:26,523 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45313282209363853, 'Total loss': 0.45313282209363853} | train loss {'Reaction outcome loss': 0.19452475555120938, 'Total loss': 0.19452475555120938}
2022-12-05 21:19:26,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:26,523 INFO:     Epoch: 29
2022-12-05 21:19:27,325 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44521296498450363, 'Total loss': 0.44521296498450363} | train loss {'Reaction outcome loss': 0.19462581300326892, 'Total loss': 0.19462581300326892}
2022-12-05 21:19:27,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:27,326 INFO:     Epoch: 30
2022-12-05 21:19:28,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43430625105446036, 'Total loss': 0.43430625105446036} | train loss {'Reaction outcome loss': 0.18612474428429718, 'Total loss': 0.18612474428429718}
2022-12-05 21:19:28,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:28,129 INFO:     Epoch: 31
2022-12-05 21:19:28,935 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46445563968948345, 'Total loss': 0.46445563968948345} | train loss {'Reaction outcome loss': 0.18136320231602557, 'Total loss': 0.18136320231602557}
2022-12-05 21:19:28,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:28,935 INFO:     Epoch: 32
2022-12-05 21:19:29,736 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4594116580079902, 'Total loss': 0.4594116580079902} | train loss {'Reaction outcome loss': 0.17828353252562304, 'Total loss': 0.17828353252562304}
2022-12-05 21:19:29,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:29,736 INFO:     Epoch: 33
2022-12-05 21:19:30,537 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46301605383103545, 'Total loss': 0.46301605383103545} | train loss {'Reaction outcome loss': 0.17664878807901854, 'Total loss': 0.17664878807901854}
2022-12-05 21:19:30,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:30,537 INFO:     Epoch: 34
2022-12-05 21:19:31,337 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4536307105286555, 'Total loss': 0.4536307105286555} | train loss {'Reaction outcome loss': 0.1773911357947415, 'Total loss': 0.1773911357947415}
2022-12-05 21:19:31,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:31,337 INFO:     Epoch: 35
2022-12-05 21:19:32,136 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4597595354372805, 'Total loss': 0.4597595354372805} | train loss {'Reaction outcome loss': 0.17214175953619903, 'Total loss': 0.17214175953619903}
2022-12-05 21:19:32,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:32,137 INFO:     Epoch: 36
2022-12-05 21:19:32,936 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45712253519079904, 'Total loss': 0.45712253519079904} | train loss {'Reaction outcome loss': 0.17160632517639426, 'Total loss': 0.17160632517639426}
2022-12-05 21:19:32,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:32,936 INFO:     Epoch: 37
2022-12-05 21:19:33,738 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44405972720547154, 'Total loss': 0.44405972720547154} | train loss {'Reaction outcome loss': 0.16683602939179587, 'Total loss': 0.16683602939179587}
2022-12-05 21:19:33,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:33,738 INFO:     Epoch: 38
2022-12-05 21:19:34,543 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4398834945803339, 'Total loss': 0.4398834945803339} | train loss {'Reaction outcome loss': 0.1658766728810846, 'Total loss': 0.1658766728810846}
2022-12-05 21:19:34,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:34,544 INFO:     Epoch: 39
2022-12-05 21:19:35,345 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4514365594156764, 'Total loss': 0.4514365594156764} | train loss {'Reaction outcome loss': 0.1664870601267584, 'Total loss': 0.1664870601267584}
2022-12-05 21:19:35,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:35,345 INFO:     Epoch: 40
2022-12-05 21:19:36,145 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45156786286018114, 'Total loss': 0.45156786286018114} | train loss {'Reaction outcome loss': 0.1645591309849894, 'Total loss': 0.1645591309849894}
2022-12-05 21:19:36,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:36,145 INFO:     Epoch: 41
2022-12-05 21:19:36,947 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4580714050680399, 'Total loss': 0.4580714050680399} | train loss {'Reaction outcome loss': 0.16050631231478146, 'Total loss': 0.16050631231478146}
2022-12-05 21:19:36,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:36,947 INFO:     Epoch: 42
2022-12-05 21:19:37,746 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.462074839933352, 'Total loss': 0.462074839933352} | train loss {'Reaction outcome loss': 0.15958071502316143, 'Total loss': 0.15958071502316143}
2022-12-05 21:19:37,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:37,746 INFO:     Epoch: 43
2022-12-05 21:19:38,545 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4563010815869678, 'Total loss': 0.4563010815869678} | train loss {'Reaction outcome loss': 0.15921748156899646, 'Total loss': 0.15921748156899646}
2022-12-05 21:19:38,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:38,545 INFO:     Epoch: 44
2022-12-05 21:19:39,340 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46302775564518844, 'Total loss': 0.46302775564518844} | train loss {'Reaction outcome loss': 0.15816048779074224, 'Total loss': 0.15816048779074224}
2022-12-05 21:19:39,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:39,340 INFO:     Epoch: 45
2022-12-05 21:19:40,139 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4788909161632711, 'Total loss': 0.4788909161632711} | train loss {'Reaction outcome loss': 0.15607494598765287, 'Total loss': 0.15607494598765287}
2022-12-05 21:19:40,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:40,140 INFO:     Epoch: 46
2022-12-05 21:19:40,935 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4536361216821454, 'Total loss': 0.4536361216821454} | train loss {'Reaction outcome loss': 0.15606096125162777, 'Total loss': 0.15606096125162777}
2022-12-05 21:19:40,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:40,935 INFO:     Epoch: 47
2022-12-05 21:19:41,731 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45239640873941506, 'Total loss': 0.45239640873941506} | train loss {'Reaction outcome loss': 0.15419498496058007, 'Total loss': 0.15419498496058007}
2022-12-05 21:19:41,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:41,731 INFO:     Epoch: 48
2022-12-05 21:19:42,532 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45961611548608, 'Total loss': 0.45961611548608} | train loss {'Reaction outcome loss': 0.1522822982871965, 'Total loss': 0.1522822982871965}
2022-12-05 21:19:42,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:42,532 INFO:     Epoch: 49
2022-12-05 21:19:43,334 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46336350149729033, 'Total loss': 0.46336350149729033} | train loss {'Reaction outcome loss': 0.1494685392751689, 'Total loss': 0.1494685392751689}
2022-12-05 21:19:43,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:43,334 INFO:     Epoch: 50
2022-12-05 21:19:44,134 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46954314613884146, 'Total loss': 0.46954314613884146} | train loss {'Reaction outcome loss': 0.14937640344648953, 'Total loss': 0.14937640344648953}
2022-12-05 21:19:44,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:44,134 INFO:     Epoch: 51
2022-12-05 21:19:44,928 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4803545835681937, 'Total loss': 0.4803545835681937} | train loss {'Reaction outcome loss': 0.14531316246551973, 'Total loss': 0.14531316246551973}
2022-12-05 21:19:44,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:44,929 INFO:     Epoch: 52
2022-12-05 21:19:45,723 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47509694641286676, 'Total loss': 0.47509694641286676} | train loss {'Reaction outcome loss': 0.1477410359863913, 'Total loss': 0.1477410359863913}
2022-12-05 21:19:45,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:45,723 INFO:     Epoch: 53
2022-12-05 21:19:46,523 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47210102900862694, 'Total loss': 0.47210102900862694} | train loss {'Reaction outcome loss': 0.14627999948307632, 'Total loss': 0.14627999948307632}
2022-12-05 21:19:46,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:46,524 INFO:     Epoch: 54
2022-12-05 21:19:47,320 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4838284115222367, 'Total loss': 0.4838284115222367} | train loss {'Reaction outcome loss': 0.1474383195276342, 'Total loss': 0.1474383195276342}
2022-12-05 21:19:47,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:47,320 INFO:     Epoch: 55
2022-12-05 21:19:48,119 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4600047418339686, 'Total loss': 0.4600047418339686} | train loss {'Reaction outcome loss': 0.14585028043497475, 'Total loss': 0.14585028043497475}
2022-12-05 21:19:48,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:48,119 INFO:     Epoch: 56
2022-12-05 21:19:48,920 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48276887901804666, 'Total loss': 0.48276887901804666} | train loss {'Reaction outcome loss': 0.14487207904758473, 'Total loss': 0.14487207904758473}
2022-12-05 21:19:48,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:48,920 INFO:     Epoch: 57
2022-12-05 21:19:49,719 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4684787710959261, 'Total loss': 0.4684787710959261} | train loss {'Reaction outcome loss': 0.1451991590701284, 'Total loss': 0.1451991590701284}
2022-12-05 21:19:49,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:49,720 INFO:     Epoch: 58
2022-12-05 21:19:50,520 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5024504444815896, 'Total loss': 0.5024504444815896} | train loss {'Reaction outcome loss': 0.1412276026394759, 'Total loss': 0.1412276026394759}
2022-12-05 21:19:50,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:50,520 INFO:     Epoch: 59
2022-12-05 21:19:51,316 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48117377202619205, 'Total loss': 0.48117377202619205} | train loss {'Reaction outcome loss': 0.14221069494998384, 'Total loss': 0.14221069494998384}
2022-12-05 21:19:51,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:51,317 INFO:     Epoch: 60
2022-12-05 21:19:52,116 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47404573959383095, 'Total loss': 0.47404573959383095} | train loss {'Reaction outcome loss': 0.13826415742251782, 'Total loss': 0.13826415742251782}
2022-12-05 21:19:52,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:52,117 INFO:     Epoch: 61
2022-12-05 21:19:52,911 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46657361394979735, 'Total loss': 0.46657361394979735} | train loss {'Reaction outcome loss': 0.13960263845435675, 'Total loss': 0.13960263845435675}
2022-12-05 21:19:52,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:52,911 INFO:     Epoch: 62
2022-12-05 21:19:53,708 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46958253668113187, 'Total loss': 0.46958253668113187} | train loss {'Reaction outcome loss': 0.14422950753191066, 'Total loss': 0.14422950753191066}
2022-12-05 21:19:53,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:53,709 INFO:     Epoch: 63
2022-12-05 21:19:54,503 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47233445959335024, 'Total loss': 0.47233445959335024} | train loss {'Reaction outcome loss': 0.13790539349053776, 'Total loss': 0.13790539349053776}
2022-12-05 21:19:54,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:54,504 INFO:     Epoch: 64
2022-12-05 21:19:55,300 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.478714490478689, 'Total loss': 0.478714490478689} | train loss {'Reaction outcome loss': 0.13485298443570612, 'Total loss': 0.13485298443570612}
2022-12-05 21:19:55,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:55,301 INFO:     Epoch: 65
2022-12-05 21:19:56,094 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4865874895317988, 'Total loss': 0.4865874895317988} | train loss {'Reaction outcome loss': 0.13718813923638193, 'Total loss': 0.13718813923638193}
2022-12-05 21:19:56,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:56,094 INFO:     Epoch: 66
2022-12-05 21:19:56,889 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4725180068476634, 'Total loss': 0.4725180068476634} | train loss {'Reaction outcome loss': 0.13878295774902066, 'Total loss': 0.13878295774902066}
2022-12-05 21:19:56,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:56,889 INFO:     Epoch: 67
2022-12-05 21:19:57,684 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47899810055440123, 'Total loss': 0.47899810055440123} | train loss {'Reaction outcome loss': 0.13605399824295855, 'Total loss': 0.13605399824295855}
2022-12-05 21:19:57,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:57,685 INFO:     Epoch: 68
2022-12-05 21:19:58,479 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4852197210897099, 'Total loss': 0.4852197210897099} | train loss {'Reaction outcome loss': 0.13571097028081217, 'Total loss': 0.13571097028081217}
2022-12-05 21:19:58,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:58,480 INFO:     Epoch: 69
2022-12-05 21:19:59,277 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4733771786771037, 'Total loss': 0.4733771786771037} | train loss {'Reaction outcome loss': 0.13612391084672942, 'Total loss': 0.13612391084672942}
2022-12-05 21:19:59,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:19:59,277 INFO:     Epoch: 70
2022-12-05 21:20:00,072 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4772237722169269, 'Total loss': 0.4772237722169269} | train loss {'Reaction outcome loss': 0.1332989461464627, 'Total loss': 0.1332989461464627}
2022-12-05 21:20:00,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:00,072 INFO:     Epoch: 71
2022-12-05 21:20:00,871 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4962874346158721, 'Total loss': 0.4962874346158721} | train loss {'Reaction outcome loss': 0.1336583361900862, 'Total loss': 0.1336583361900862}
2022-12-05 21:20:00,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:00,871 INFO:     Epoch: 72
2022-12-05 21:20:01,669 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47960980236530304, 'Total loss': 0.47960980236530304} | train loss {'Reaction outcome loss': 0.1324702046713942, 'Total loss': 0.1324702046713942}
2022-12-05 21:20:01,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:01,669 INFO:     Epoch: 73
2022-12-05 21:20:02,470 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4702007499608127, 'Total loss': 0.4702007499608127} | train loss {'Reaction outcome loss': 0.131950712920497, 'Total loss': 0.131950712920497}
2022-12-05 21:20:02,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:02,470 INFO:     Epoch: 74
2022-12-05 21:20:03,264 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4783844162117351, 'Total loss': 0.4783844162117351} | train loss {'Reaction outcome loss': 0.13269438539376302, 'Total loss': 0.13269438539376302}
2022-12-05 21:20:03,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:03,264 INFO:     Epoch: 75
2022-12-05 21:20:04,061 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49150103398344736, 'Total loss': 0.49150103398344736} | train loss {'Reaction outcome loss': 0.131874309477186, 'Total loss': 0.131874309477186}
2022-12-05 21:20:04,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:04,062 INFO:     Epoch: 76
2022-12-05 21:20:04,858 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46651763130318036, 'Total loss': 0.46651763130318036} | train loss {'Reaction outcome loss': 0.13112218696774253, 'Total loss': 0.13112218696774253}
2022-12-05 21:20:04,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:04,858 INFO:     Epoch: 77
2022-12-05 21:20:05,656 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48240437121553853, 'Total loss': 0.48240437121553853} | train loss {'Reaction outcome loss': 0.12906375069231277, 'Total loss': 0.12906375069231277}
2022-12-05 21:20:05,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:05,657 INFO:     Epoch: 78
2022-12-05 21:20:06,458 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46613442355936224, 'Total loss': 0.46613442355936224} | train loss {'Reaction outcome loss': 0.1304378162904252, 'Total loss': 0.1304378162904252}
2022-12-05 21:20:06,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:06,458 INFO:     Epoch: 79
2022-12-05 21:20:07,255 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4724798466671597, 'Total loss': 0.4724798466671597} | train loss {'Reaction outcome loss': 0.1287536905447562, 'Total loss': 0.1287536905447562}
2022-12-05 21:20:07,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:07,256 INFO:     Epoch: 80
2022-12-05 21:20:08,055 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48399157923730934, 'Total loss': 0.48399157923730934} | train loss {'Reaction outcome loss': 0.13045479704610882, 'Total loss': 0.13045479704610882}
2022-12-05 21:20:08,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:08,055 INFO:     Epoch: 81
2022-12-05 21:20:08,849 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4721107533709569, 'Total loss': 0.4721107533709569} | train loss {'Reaction outcome loss': 0.13074258780257114, 'Total loss': 0.13074258780257114}
2022-12-05 21:20:08,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:08,849 INFO:     Epoch: 82
2022-12-05 21:20:09,645 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47676168026571925, 'Total loss': 0.47676168026571925} | train loss {'Reaction outcome loss': 0.12887608461202152, 'Total loss': 0.12887608461202152}
2022-12-05 21:20:09,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:09,645 INFO:     Epoch: 83
2022-12-05 21:20:10,440 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4735295440662991, 'Total loss': 0.4735295440662991} | train loss {'Reaction outcome loss': 0.12938405968804634, 'Total loss': 0.12938405968804634}
2022-12-05 21:20:10,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:10,440 INFO:     Epoch: 84
2022-12-05 21:20:11,234 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4918116263367913, 'Total loss': 0.4918116263367913} | train loss {'Reaction outcome loss': 0.12777450201927773, 'Total loss': 0.12777450201927773}
2022-12-05 21:20:11,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:11,235 INFO:     Epoch: 85
2022-12-05 21:20:12,031 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49538240412419493, 'Total loss': 0.49538240412419493} | train loss {'Reaction outcome loss': 0.1262846023197316, 'Total loss': 0.1262846023197316}
2022-12-05 21:20:12,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:12,031 INFO:     Epoch: 86
2022-12-05 21:20:12,828 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47891011190685356, 'Total loss': 0.47891011190685356} | train loss {'Reaction outcome loss': 0.1275198593615524, 'Total loss': 0.1275198593615524}
2022-12-05 21:20:12,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:12,828 INFO:     Epoch: 87
2022-12-05 21:20:13,633 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48056732389059936, 'Total loss': 0.48056732389059936} | train loss {'Reaction outcome loss': 0.12753494705764518, 'Total loss': 0.12753494705764518}
2022-12-05 21:20:13,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:13,633 INFO:     Epoch: 88
2022-12-05 21:20:14,434 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48060834814201703, 'Total loss': 0.48060834814201703} | train loss {'Reaction outcome loss': 0.12523601890256209, 'Total loss': 0.12523601890256209}
2022-12-05 21:20:14,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:14,434 INFO:     Epoch: 89
2022-12-05 21:20:15,231 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49186220223253424, 'Total loss': 0.49186220223253424} | train loss {'Reaction outcome loss': 0.12723420624576148, 'Total loss': 0.12723420624576148}
2022-12-05 21:20:15,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:15,231 INFO:     Epoch: 90
2022-12-05 21:20:16,026 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4829365192827853, 'Total loss': 0.4829365192827853} | train loss {'Reaction outcome loss': 0.12477804386928197, 'Total loss': 0.12477804386928197}
2022-12-05 21:20:16,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:16,026 INFO:     Epoch: 91
2022-12-05 21:20:16,821 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4804070676592263, 'Total loss': 0.4804070676592263} | train loss {'Reaction outcome loss': 0.12593973581979592, 'Total loss': 0.12593973581979592}
2022-12-05 21:20:16,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:16,822 INFO:     Epoch: 92
2022-12-05 21:20:17,621 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5019586191258647, 'Total loss': 0.5019586191258647} | train loss {'Reaction outcome loss': 0.126019861864587, 'Total loss': 0.126019861864587}
2022-12-05 21:20:17,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:17,621 INFO:     Epoch: 93
2022-12-05 21:20:18,421 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4902253746986389, 'Total loss': 0.4902253746986389} | train loss {'Reaction outcome loss': 0.12360690009870356, 'Total loss': 0.12360690009870356}
2022-12-05 21:20:18,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:18,422 INFO:     Epoch: 94
2022-12-05 21:20:19,218 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5019069764424454, 'Total loss': 0.5019069764424454} | train loss {'Reaction outcome loss': 0.12547699834460452, 'Total loss': 0.12547699834460452}
2022-12-05 21:20:19,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:19,218 INFO:     Epoch: 95
2022-12-05 21:20:20,013 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4938147989186374, 'Total loss': 0.4938147989186374} | train loss {'Reaction outcome loss': 0.12349789695543868, 'Total loss': 0.12349789695543868}
2022-12-05 21:20:20,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:20,013 INFO:     Epoch: 96
2022-12-05 21:20:20,810 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5004751397804781, 'Total loss': 0.5004751397804781} | train loss {'Reaction outcome loss': 0.12411251817379267, 'Total loss': 0.12411251817379267}
2022-12-05 21:20:20,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:20,810 INFO:     Epoch: 97
2022-12-05 21:20:21,608 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4962141571397131, 'Total loss': 0.4962141571397131} | train loss {'Reaction outcome loss': 0.12307277243704565, 'Total loss': 0.12307277243704565}
2022-12-05 21:20:21,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:21,608 INFO:     Epoch: 98
2022-12-05 21:20:22,405 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4878839250992645, 'Total loss': 0.4878839250992645} | train loss {'Reaction outcome loss': 0.12523299471415097, 'Total loss': 0.12523299471415097}
2022-12-05 21:20:22,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:22,405 INFO:     Epoch: 99
2022-12-05 21:20:23,202 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4738120006566698, 'Total loss': 0.4738120006566698} | train loss {'Reaction outcome loss': 0.12432968427592347, 'Total loss': 0.12432968427592347}
2022-12-05 21:20:23,202 INFO:     Best model found after epoch 13 of 100.
2022-12-05 21:20:23,202 INFO:   Done with stage: TRAINING
2022-12-05 21:20:23,202 INFO:   Starting stage: EVALUATION
2022-12-05 21:20:23,322 INFO:   Done with stage: EVALUATION
2022-12-05 21:20:23,330 INFO:   Leaving out SEQ value Fold_0
2022-12-05 21:20:23,342 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:20:23,342 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:20:23,981 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:20:23,981 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:20:24,050 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:20:24,050 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:20:24,050 INFO:     No hyperparam tuning for this model
2022-12-05 21:20:24,050 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:20:24,050 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:20:24,051 INFO:     None feature selector for col prot
2022-12-05 21:20:24,051 INFO:     None feature selector for col prot
2022-12-05 21:20:24,051 INFO:     None feature selector for col prot
2022-12-05 21:20:24,051 INFO:     None feature selector for col chem
2022-12-05 21:20:24,051 INFO:     None feature selector for col chem
2022-12-05 21:20:24,052 INFO:     None feature selector for col chem
2022-12-05 21:20:24,052 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:20:24,052 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:20:24,053 INFO:     Number of params in model 215821
2022-12-05 21:20:24,056 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:20:24,056 INFO:   Starting stage: TRAINING
2022-12-05 21:20:24,116 INFO:     Val loss before train {'Reaction outcome loss': 0.9710347137667916, 'Total loss': 0.9710347137667916}
2022-12-05 21:20:24,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:24,116 INFO:     Epoch: 0
2022-12-05 21:20:24,909 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.602601975879886, 'Total loss': 0.602601975879886} | train loss {'Reaction outcome loss': 0.7993940030514952, 'Total loss': 0.7993940030514952}
2022-12-05 21:20:24,909 INFO:     Found new best model at epoch 0
2022-12-05 21:20:24,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:24,910 INFO:     Epoch: 1
2022-12-05 21:20:25,703 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5150889950719747, 'Total loss': 0.5150889950719747} | train loss {'Reaction outcome loss': 0.536591856269098, 'Total loss': 0.536591856269098}
2022-12-05 21:20:25,703 INFO:     Found new best model at epoch 1
2022-12-05 21:20:25,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:25,704 INFO:     Epoch: 2
2022-12-05 21:20:26,495 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48134716803377325, 'Total loss': 0.48134716803377325} | train loss {'Reaction outcome loss': 0.46644429934893544, 'Total loss': 0.46644429934893544}
2022-12-05 21:20:26,495 INFO:     Found new best model at epoch 2
2022-12-05 21:20:26,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:26,496 INFO:     Epoch: 3
2022-12-05 21:20:27,288 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4565646516328508, 'Total loss': 0.4565646516328508} | train loss {'Reaction outcome loss': 0.4249330654981648, 'Total loss': 0.4249330654981648}
2022-12-05 21:20:27,288 INFO:     Found new best model at epoch 3
2022-12-05 21:20:27,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:27,289 INFO:     Epoch: 4
2022-12-05 21:20:28,081 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4477220953188159, 'Total loss': 0.4477220953188159} | train loss {'Reaction outcome loss': 0.39446475360587785, 'Total loss': 0.39446475360587785}
2022-12-05 21:20:28,082 INFO:     Found new best model at epoch 4
2022-12-05 21:20:28,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:28,082 INFO:     Epoch: 5
2022-12-05 21:20:28,878 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43272959982806986, 'Total loss': 0.43272959982806986} | train loss {'Reaction outcome loss': 0.3705474008553424, 'Total loss': 0.3705474008553424}
2022-12-05 21:20:28,879 INFO:     Found new best model at epoch 5
2022-12-05 21:20:28,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:28,880 INFO:     Epoch: 6
2022-12-05 21:20:29,669 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43743412873961707, 'Total loss': 0.43743412873961707} | train loss {'Reaction outcome loss': 0.3525482715081107, 'Total loss': 0.3525482715081107}
2022-12-05 21:20:29,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:29,669 INFO:     Epoch: 7
2022-12-05 21:20:30,464 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4356016401540149, 'Total loss': 0.4356016401540149} | train loss {'Reaction outcome loss': 0.3350025387066096, 'Total loss': 0.3350025387066096}
2022-12-05 21:20:30,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:30,464 INFO:     Epoch: 8
2022-12-05 21:20:31,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41224884817546065, 'Total loss': 0.41224884817546065} | train loss {'Reaction outcome loss': 0.3175128411712796, 'Total loss': 0.3175128411712796}
2022-12-05 21:20:31,260 INFO:     Found new best model at epoch 8
2022-12-05 21:20:31,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:31,261 INFO:     Epoch: 9
2022-12-05 21:20:32,051 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4367588856680827, 'Total loss': 0.4367588856680827} | train loss {'Reaction outcome loss': 0.3042792882393246, 'Total loss': 0.3042792882393246}
2022-12-05 21:20:32,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:32,051 INFO:     Epoch: 10
2022-12-05 21:20:32,846 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4229836470701478, 'Total loss': 0.4229836470701478} | train loss {'Reaction outcome loss': 0.2919520853532229, 'Total loss': 0.2919520853532229}
2022-12-05 21:20:32,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:32,846 INFO:     Epoch: 11
2022-12-05 21:20:33,637 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4211758024651896, 'Total loss': 0.4211758024651896} | train loss {'Reaction outcome loss': 0.28029097155158816, 'Total loss': 0.28029097155158816}
2022-12-05 21:20:33,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:33,638 INFO:     Epoch: 12
2022-12-05 21:20:34,429 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41710262847217644, 'Total loss': 0.41710262847217644} | train loss {'Reaction outcome loss': 0.27585461049487714, 'Total loss': 0.27585461049487714}
2022-12-05 21:20:34,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:34,429 INFO:     Epoch: 13
2022-12-05 21:20:35,217 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.405195335095579, 'Total loss': 0.405195335095579} | train loss {'Reaction outcome loss': 0.26158601531065123, 'Total loss': 0.26158601531065123}
2022-12-05 21:20:35,218 INFO:     Found new best model at epoch 13
2022-12-05 21:20:35,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:35,219 INFO:     Epoch: 14
2022-12-05 21:20:36,008 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43928023224527185, 'Total loss': 0.43928023224527185} | train loss {'Reaction outcome loss': 0.2576278307388427, 'Total loss': 0.2576278307388427}
2022-12-05 21:20:36,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:36,008 INFO:     Epoch: 15
2022-12-05 21:20:36,797 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4389742033725435, 'Total loss': 0.4389742033725435} | train loss {'Reaction outcome loss': 0.25121499450221235, 'Total loss': 0.25121499450221235}
2022-12-05 21:20:36,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:36,798 INFO:     Epoch: 16
2022-12-05 21:20:37,587 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.420422089709477, 'Total loss': 0.420422089709477} | train loss {'Reaction outcome loss': 0.23693162501838647, 'Total loss': 0.23693162501838647}
2022-12-05 21:20:37,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:37,587 INFO:     Epoch: 17
2022-12-05 21:20:38,385 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42235311764207756, 'Total loss': 0.42235311764207756} | train loss {'Reaction outcome loss': 0.23013193790352177, 'Total loss': 0.23013193790352177}
2022-12-05 21:20:38,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:38,385 INFO:     Epoch: 18
2022-12-05 21:20:39,181 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44888584078712895, 'Total loss': 0.44888584078712895} | train loss {'Reaction outcome loss': 0.22266935168007607, 'Total loss': 0.22266935168007607}
2022-12-05 21:20:39,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:39,182 INFO:     Epoch: 19
2022-12-05 21:20:39,980 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.436116907406937, 'Total loss': 0.436116907406937} | train loss {'Reaction outcome loss': 0.2175765922707826, 'Total loss': 0.2175765922707826}
2022-12-05 21:20:39,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:39,980 INFO:     Epoch: 20
2022-12-05 21:20:40,776 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42409022084691306, 'Total loss': 0.42409022084691306} | train loss {'Reaction outcome loss': 0.214829345448659, 'Total loss': 0.214829345448659}
2022-12-05 21:20:40,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:40,777 INFO:     Epoch: 21
2022-12-05 21:20:41,569 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43988129699772055, 'Total loss': 0.43988129699772055} | train loss {'Reaction outcome loss': 0.20879874107718227, 'Total loss': 0.20879874107718227}
2022-12-05 21:20:41,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:41,569 INFO:     Epoch: 22
2022-12-05 21:20:42,362 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4110267815942114, 'Total loss': 0.4110267815942114} | train loss {'Reaction outcome loss': 0.20581088062783, 'Total loss': 0.20581088062783}
2022-12-05 21:20:42,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:42,363 INFO:     Epoch: 23
2022-12-05 21:20:43,156 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4436267370527441, 'Total loss': 0.4436267370527441} | train loss {'Reaction outcome loss': 0.20286768852819798, 'Total loss': 0.20286768852819798}
2022-12-05 21:20:43,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:43,157 INFO:     Epoch: 24
2022-12-05 21:20:43,950 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4270861663601615, 'Total loss': 0.4270861663601615} | train loss {'Reaction outcome loss': 0.19581301947716276, 'Total loss': 0.19581301947716276}
2022-12-05 21:20:43,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:43,950 INFO:     Epoch: 25
2022-12-05 21:20:44,743 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.438285252248699, 'Total loss': 0.438285252248699} | train loss {'Reaction outcome loss': 0.19073112846469045, 'Total loss': 0.19073112846469045}
2022-12-05 21:20:44,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:44,744 INFO:     Epoch: 26
2022-12-05 21:20:45,531 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44909478012811055, 'Total loss': 0.44909478012811055} | train loss {'Reaction outcome loss': 0.18892253119392916, 'Total loss': 0.18892253119392916}
2022-12-05 21:20:45,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:45,531 INFO:     Epoch: 27
2022-12-05 21:20:46,334 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44147521748461505, 'Total loss': 0.44147521748461505} | train loss {'Reaction outcome loss': 0.18578533549992904, 'Total loss': 0.18578533549992904}
2022-12-05 21:20:46,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:46,334 INFO:     Epoch: 28
2022-12-05 21:20:47,132 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.452017373659394, 'Total loss': 0.452017373659394} | train loss {'Reaction outcome loss': 0.18133256759358804, 'Total loss': 0.18133256759358804}
2022-12-05 21:20:47,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:47,133 INFO:     Epoch: 29
2022-12-05 21:20:47,926 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47436364977197215, 'Total loss': 0.47436364977197215} | train loss {'Reaction outcome loss': 0.1773730599875694, 'Total loss': 0.1773730599875694}
2022-12-05 21:20:47,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:47,927 INFO:     Epoch: 30
2022-12-05 21:20:48,726 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42878593936223874, 'Total loss': 0.42878593936223874} | train loss {'Reaction outcome loss': 0.1764840060611244, 'Total loss': 0.1764840060611244}
2022-12-05 21:20:48,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:48,727 INFO:     Epoch: 31
2022-12-05 21:20:49,519 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46111475879495795, 'Total loss': 0.46111475879495795} | train loss {'Reaction outcome loss': 0.17562576233284918, 'Total loss': 0.17562576233284918}
2022-12-05 21:20:49,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:49,520 INFO:     Epoch: 32
2022-12-05 21:20:50,313 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46514438126574864, 'Total loss': 0.46514438126574864} | train loss {'Reaction outcome loss': 0.17301422067981984, 'Total loss': 0.17301422067981984}
2022-12-05 21:20:50,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:50,313 INFO:     Epoch: 33
2022-12-05 21:20:51,114 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4444779393009164, 'Total loss': 0.4444779393009164} | train loss {'Reaction outcome loss': 0.17041798968335636, 'Total loss': 0.17041798968335636}
2022-12-05 21:20:51,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:51,114 INFO:     Epoch: 34
2022-12-05 21:20:51,912 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45572490990161896, 'Total loss': 0.45572490990161896} | train loss {'Reaction outcome loss': 0.1678629613025227, 'Total loss': 0.1678629613025227}
2022-12-05 21:20:51,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:51,912 INFO:     Epoch: 35
2022-12-05 21:20:52,705 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4760482043705203, 'Total loss': 0.4760482043705203} | train loss {'Reaction outcome loss': 0.16584549011730473, 'Total loss': 0.16584549011730473}
2022-12-05 21:20:52,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:52,705 INFO:     Epoch: 36
2022-12-05 21:20:53,501 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45383481173352763, 'Total loss': 0.45383481173352763} | train loss {'Reaction outcome loss': 0.16235472087989664, 'Total loss': 0.16235472087989664}
2022-12-05 21:20:53,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:53,501 INFO:     Epoch: 37
2022-12-05 21:20:54,297 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4656379632651806, 'Total loss': 0.4656379632651806} | train loss {'Reaction outcome loss': 0.15765196855862432, 'Total loss': 0.15765196855862432}
2022-12-05 21:20:54,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:54,297 INFO:     Epoch: 38
2022-12-05 21:20:55,090 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46212925761938095, 'Total loss': 0.46212925761938095} | train loss {'Reaction outcome loss': 0.15567939753384002, 'Total loss': 0.15567939753384002}
2022-12-05 21:20:55,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:55,091 INFO:     Epoch: 39
2022-12-05 21:20:55,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4528928219594739, 'Total loss': 0.4528928219594739} | train loss {'Reaction outcome loss': 0.15544602360108845, 'Total loss': 0.15544602360108845}
2022-12-05 21:20:55,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:55,883 INFO:     Epoch: 40
2022-12-05 21:20:56,677 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4552402394739064, 'Total loss': 0.4552402394739064} | train loss {'Reaction outcome loss': 0.1512452973296059, 'Total loss': 0.1512452973296059}
2022-12-05 21:20:56,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:56,677 INFO:     Epoch: 41
2022-12-05 21:20:57,473 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45749959451231087, 'Total loss': 0.45749959451231087} | train loss {'Reaction outcome loss': 0.15218918621804006, 'Total loss': 0.15218918621804006}
2022-12-05 21:20:57,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:57,473 INFO:     Epoch: 42
2022-12-05 21:20:58,273 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.449269256808541, 'Total loss': 0.449269256808541} | train loss {'Reaction outcome loss': 0.14928247508129128, 'Total loss': 0.14928247508129128}
2022-12-05 21:20:58,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:58,273 INFO:     Epoch: 43
2022-12-05 21:20:59,073 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45021941140294075, 'Total loss': 0.45021941140294075} | train loss {'Reaction outcome loss': 0.15513073507439995, 'Total loss': 0.15513073507439995}
2022-12-05 21:20:59,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:59,073 INFO:     Epoch: 44
2022-12-05 21:20:59,868 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45908407866954803, 'Total loss': 0.45908407866954803} | train loss {'Reaction outcome loss': 0.14714035016120702, 'Total loss': 0.14714035016120702}
2022-12-05 21:20:59,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:20:59,870 INFO:     Epoch: 45
2022-12-05 21:21:00,666 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47692418369379913, 'Total loss': 0.47692418369379913} | train loss {'Reaction outcome loss': 0.14578258622624357, 'Total loss': 0.14578258622624357}
2022-12-05 21:21:00,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:00,667 INFO:     Epoch: 46
2022-12-05 21:21:01,463 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46813899939033116, 'Total loss': 0.46813899939033116} | train loss {'Reaction outcome loss': 0.14689109631274877, 'Total loss': 0.14689109631274877}
2022-12-05 21:21:01,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:01,464 INFO:     Epoch: 47
2022-12-05 21:21:02,262 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4612984630194577, 'Total loss': 0.4612984630194577} | train loss {'Reaction outcome loss': 0.14959756009702982, 'Total loss': 0.14959756009702982}
2022-12-05 21:21:02,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:02,263 INFO:     Epoch: 48
2022-12-05 21:21:03,056 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47651380334388127, 'Total loss': 0.47651380334388127} | train loss {'Reaction outcome loss': 0.15074629563581848, 'Total loss': 0.15074629563581848}
2022-12-05 21:21:03,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:03,057 INFO:     Epoch: 49
2022-12-05 21:21:03,849 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4835666563700546, 'Total loss': 0.4835666563700546} | train loss {'Reaction outcome loss': 0.14373158221133053, 'Total loss': 0.14373158221133053}
2022-12-05 21:21:03,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:03,850 INFO:     Epoch: 50
2022-12-05 21:21:04,653 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4618790640749715, 'Total loss': 0.4618790640749715} | train loss {'Reaction outcome loss': 0.14190117862482785, 'Total loss': 0.14190117862482785}
2022-12-05 21:21:04,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:04,653 INFO:     Epoch: 51
2022-12-05 21:21:05,454 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4530715383589268, 'Total loss': 0.4530715383589268} | train loss {'Reaction outcome loss': 0.14241643883815783, 'Total loss': 0.14241643883815783}
2022-12-05 21:21:05,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:05,454 INFO:     Epoch: 52
2022-12-05 21:21:06,252 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46942146359519527, 'Total loss': 0.46942146359519527} | train loss {'Reaction outcome loss': 0.14698269930083743, 'Total loss': 0.14698269930083743}
2022-12-05 21:21:06,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:06,253 INFO:     Epoch: 53
2022-12-05 21:21:07,052 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4746484908867966, 'Total loss': 0.4746484908867966} | train loss {'Reaction outcome loss': 0.14020798599294684, 'Total loss': 0.14020798599294684}
2022-12-05 21:21:07,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:07,052 INFO:     Epoch: 54
2022-12-05 21:21:07,850 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46859089928594505, 'Total loss': 0.46859089928594505} | train loss {'Reaction outcome loss': 0.13765979089174676, 'Total loss': 0.13765979089174676}
2022-12-05 21:21:07,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:07,851 INFO:     Epoch: 55
2022-12-05 21:21:08,649 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48352664370428433, 'Total loss': 0.48352664370428433} | train loss {'Reaction outcome loss': 0.13564876858182703, 'Total loss': 0.13564876858182703}
2022-12-05 21:21:08,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:08,649 INFO:     Epoch: 56
2022-12-05 21:21:09,444 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4744990160688758, 'Total loss': 0.4744990160688758} | train loss {'Reaction outcome loss': 0.13405823168393813, 'Total loss': 0.13405823168393813}
2022-12-05 21:21:09,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:09,444 INFO:     Epoch: 57
2022-12-05 21:21:10,243 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46825882521542633, 'Total loss': 0.46825882521542633} | train loss {'Reaction outcome loss': 0.13545348211323563, 'Total loss': 0.13545348211323563}
2022-12-05 21:21:10,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:10,244 INFO:     Epoch: 58
2022-12-05 21:21:11,042 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4753402258184823, 'Total loss': 0.4753402258184823} | train loss {'Reaction outcome loss': 0.13356450346000642, 'Total loss': 0.13356450346000642}
2022-12-05 21:21:11,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:11,043 INFO:     Epoch: 59
2022-12-05 21:21:11,838 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48965991830283945, 'Total loss': 0.48965991830283945} | train loss {'Reaction outcome loss': 0.1361275978714203, 'Total loss': 0.1361275978714203}
2022-12-05 21:21:11,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:11,838 INFO:     Epoch: 60
2022-12-05 21:21:12,639 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4752955020151355, 'Total loss': 0.4752955020151355} | train loss {'Reaction outcome loss': 0.13350556259937132, 'Total loss': 0.13350556259937132}
2022-12-05 21:21:12,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:12,639 INFO:     Epoch: 61
2022-12-05 21:21:13,437 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4755409380251711, 'Total loss': 0.4755409380251711} | train loss {'Reaction outcome loss': 0.13129590319560064, 'Total loss': 0.13129590319560064}
2022-12-05 21:21:13,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:13,437 INFO:     Epoch: 62
2022-12-05 21:21:14,235 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4760008811612021, 'Total loss': 0.4760008811612021} | train loss {'Reaction outcome loss': 0.13380780409614326, 'Total loss': 0.13380780409614326}
2022-12-05 21:21:14,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:14,235 INFO:     Epoch: 63
2022-12-05 21:21:15,033 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48650892688469455, 'Total loss': 0.48650892688469455} | train loss {'Reaction outcome loss': 0.13131837784369224, 'Total loss': 0.13131837784369224}
2022-12-05 21:21:15,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:15,033 INFO:     Epoch: 64
2022-12-05 21:21:15,833 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.467460192062638, 'Total loss': 0.467460192062638} | train loss {'Reaction outcome loss': 0.1325679524586751, 'Total loss': 0.1325679524586751}
2022-12-05 21:21:15,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:15,833 INFO:     Epoch: 65
2022-12-05 21:21:16,631 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4735616431994872, 'Total loss': 0.4735616431994872} | train loss {'Reaction outcome loss': 0.1315931187950165, 'Total loss': 0.1315931187950165}
2022-12-05 21:21:16,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:16,632 INFO:     Epoch: 66
2022-12-05 21:21:17,430 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4799367604269223, 'Total loss': 0.4799367604269223} | train loss {'Reaction outcome loss': 0.13065291441192753, 'Total loss': 0.13065291441192753}
2022-12-05 21:21:17,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:17,431 INFO:     Epoch: 67
2022-12-05 21:21:18,227 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47401297600431874, 'Total loss': 0.47401297600431874} | train loss {'Reaction outcome loss': 0.13179497197194984, 'Total loss': 0.13179497197194984}
2022-12-05 21:21:18,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:18,227 INFO:     Epoch: 68
2022-12-05 21:21:19,025 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4667003893039443, 'Total loss': 0.4667003893039443} | train loss {'Reaction outcome loss': 0.13589493849650328, 'Total loss': 0.13589493849650328}
2022-12-05 21:21:19,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:19,026 INFO:     Epoch: 69
2022-12-05 21:21:19,826 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47906742549755355, 'Total loss': 0.47906742549755355} | train loss {'Reaction outcome loss': 0.1252758326649907, 'Total loss': 0.1252758326649907}
2022-12-05 21:21:19,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:19,827 INFO:     Epoch: 70
2022-12-05 21:21:20,622 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4798828207633712, 'Total loss': 0.4798828207633712} | train loss {'Reaction outcome loss': 0.1294651340979796, 'Total loss': 0.1294651340979796}
2022-12-05 21:21:20,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:20,622 INFO:     Epoch: 71
2022-12-05 21:21:21,419 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4943980947136879, 'Total loss': 0.4943980947136879} | train loss {'Reaction outcome loss': 0.12417179582497248, 'Total loss': 0.12417179582497248}
2022-12-05 21:21:21,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:21,419 INFO:     Epoch: 72
2022-12-05 21:21:22,217 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4831805830313401, 'Total loss': 0.4831805830313401} | train loss {'Reaction outcome loss': 0.12615094806335353, 'Total loss': 0.12615094806335353}
2022-12-05 21:21:22,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:22,217 INFO:     Epoch: 73
2022-12-05 21:21:23,011 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4607285616750067, 'Total loss': 0.4607285616750067} | train loss {'Reaction outcome loss': 0.12904789074920758, 'Total loss': 0.12904789074920758}
2022-12-05 21:21:23,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:23,012 INFO:     Epoch: 74
2022-12-05 21:21:23,808 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4800319094210863, 'Total loss': 0.4800319094210863} | train loss {'Reaction outcome loss': 0.12446039211502684, 'Total loss': 0.12446039211502684}
2022-12-05 21:21:23,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:23,808 INFO:     Epoch: 75
2022-12-05 21:21:24,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49650906873020256, 'Total loss': 0.49650906873020256} | train loss {'Reaction outcome loss': 0.12559373497299336, 'Total loss': 0.12559373497299336}
2022-12-05 21:21:24,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:24,605 INFO:     Epoch: 76
2022-12-05 21:21:25,399 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46623204970224336, 'Total loss': 0.46623204970224336} | train loss {'Reaction outcome loss': 0.1284229800195588, 'Total loss': 0.1284229800195588}
2022-12-05 21:21:25,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:25,400 INFO:     Epoch: 77
2022-12-05 21:21:26,194 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48078166761181573, 'Total loss': 0.48078166761181573} | train loss {'Reaction outcome loss': 0.1277584073657871, 'Total loss': 0.1277584073657871}
2022-12-05 21:21:26,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:26,194 INFO:     Epoch: 78
2022-12-05 21:21:26,992 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47080852362242614, 'Total loss': 0.47080852362242614} | train loss {'Reaction outcome loss': 0.13206915371874084, 'Total loss': 0.13206915371874084}
2022-12-05 21:21:26,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:26,992 INFO:     Epoch: 79
2022-12-05 21:21:27,795 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4813560934906656, 'Total loss': 0.4813560934906656} | train loss {'Reaction outcome loss': 0.12411149628158764, 'Total loss': 0.12411149628158764}
2022-12-05 21:21:27,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:27,795 INFO:     Epoch: 80
2022-12-05 21:21:28,592 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48769211633638904, 'Total loss': 0.48769211633638904} | train loss {'Reaction outcome loss': 0.12282929315914208, 'Total loss': 0.12282929315914208}
2022-12-05 21:21:28,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:28,592 INFO:     Epoch: 81
2022-12-05 21:21:29,385 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5001541098410432, 'Total loss': 0.5001541098410432} | train loss {'Reaction outcome loss': 0.12241779935644254, 'Total loss': 0.12241779935644254}
2022-12-05 21:21:29,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:29,385 INFO:     Epoch: 82
2022-12-05 21:21:30,180 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4819647834043611, 'Total loss': 0.4819647834043611} | train loss {'Reaction outcome loss': 0.12317533602161325, 'Total loss': 0.12317533602161325}
2022-12-05 21:21:30,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:30,181 INFO:     Epoch: 83
2022-12-05 21:21:30,976 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4830825047736818, 'Total loss': 0.4830825047736818} | train loss {'Reaction outcome loss': 0.12574867707364232, 'Total loss': 0.12574867707364232}
2022-12-05 21:21:30,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:30,979 INFO:     Epoch: 84
2022-12-05 21:21:31,779 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49824794043194165, 'Total loss': 0.49824794043194165} | train loss {'Reaction outcome loss': 0.12146999255512739, 'Total loss': 0.12146999255512739}
2022-12-05 21:21:31,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:31,780 INFO:     Epoch: 85
2022-12-05 21:21:32,582 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49579962342977524, 'Total loss': 0.49579962342977524} | train loss {'Reaction outcome loss': 0.11901705758457604, 'Total loss': 0.11901705758457604}
2022-12-05 21:21:32,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:32,582 INFO:     Epoch: 86
2022-12-05 21:21:33,380 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48210950805382297, 'Total loss': 0.48210950805382297} | train loss {'Reaction outcome loss': 0.12155865497042534, 'Total loss': 0.12155865497042534}
2022-12-05 21:21:33,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:33,380 INFO:     Epoch: 87
2022-12-05 21:21:34,175 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4881445975466208, 'Total loss': 0.4881445975466208} | train loss {'Reaction outcome loss': 0.11979947451724546, 'Total loss': 0.11979947451724546}
2022-12-05 21:21:34,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:34,175 INFO:     Epoch: 88
2022-12-05 21:21:34,971 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4799766249277375, 'Total loss': 0.4799766249277375} | train loss {'Reaction outcome loss': 0.1200872669901382, 'Total loss': 0.1200872669901382}
2022-12-05 21:21:34,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:34,971 INFO:     Epoch: 89
2022-12-05 21:21:35,765 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4885991591621529, 'Total loss': 0.4885991591621529} | train loss {'Reaction outcome loss': 0.12002522570386469, 'Total loss': 0.12002522570386469}
2022-12-05 21:21:35,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:35,765 INFO:     Epoch: 90
2022-12-05 21:21:36,562 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48109057105400344, 'Total loss': 0.48109057105400344} | train loss {'Reaction outcome loss': 0.12019348615848342, 'Total loss': 0.12019348615848342}
2022-12-05 21:21:36,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:36,562 INFO:     Epoch: 91
2022-12-05 21:21:37,361 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48242840644988144, 'Total loss': 0.48242840644988144} | train loss {'Reaction outcome loss': 0.11819813674624995, 'Total loss': 0.11819813674624995}
2022-12-05 21:21:37,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:37,363 INFO:     Epoch: 92
2022-12-05 21:21:38,158 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48985184932296927, 'Total loss': 0.48985184932296927} | train loss {'Reaction outcome loss': 0.11995457044165385, 'Total loss': 0.11995457044165385}
2022-12-05 21:21:38,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:38,158 INFO:     Epoch: 93
2022-12-05 21:21:38,956 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47882993637838145, 'Total loss': 0.47882993637838145} | train loss {'Reaction outcome loss': 0.12024683858596, 'Total loss': 0.12024683858596}
2022-12-05 21:21:38,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:38,956 INFO:     Epoch: 94
2022-12-05 21:21:39,758 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4863472408191724, 'Total loss': 0.4863472408191724} | train loss {'Reaction outcome loss': 0.11991836095176003, 'Total loss': 0.11991836095176003}
2022-12-05 21:21:39,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:39,758 INFO:     Epoch: 95
2022-12-05 21:21:40,554 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4813663102686405, 'Total loss': 0.4813663102686405} | train loss {'Reaction outcome loss': 0.12206799332203291, 'Total loss': 0.12206799332203291}
2022-12-05 21:21:40,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:40,554 INFO:     Epoch: 96
2022-12-05 21:21:41,353 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4748315828090364, 'Total loss': 0.4748315828090364} | train loss {'Reaction outcome loss': 0.1211069415357371, 'Total loss': 0.1211069415357371}
2022-12-05 21:21:41,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:41,353 INFO:     Epoch: 97
2022-12-05 21:21:42,151 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4805092005567117, 'Total loss': 0.4805092005567117} | train loss {'Reaction outcome loss': 0.1224961201933699, 'Total loss': 0.1224961201933699}
2022-12-05 21:21:42,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:42,151 INFO:     Epoch: 98
2022-12-05 21:21:42,948 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4750465108928355, 'Total loss': 0.4750465108928355} | train loss {'Reaction outcome loss': 0.11873509274371584, 'Total loss': 0.11873509274371584}
2022-12-05 21:21:42,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:42,948 INFO:     Epoch: 99
2022-12-05 21:21:43,750 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4882456333461133, 'Total loss': 0.4882456333461133} | train loss {'Reaction outcome loss': 0.11747434544980315, 'Total loss': 0.11747434544980315}
2022-12-05 21:21:43,751 INFO:     Best model found after epoch 14 of 100.
2022-12-05 21:21:43,751 INFO:   Done with stage: TRAINING
2022-12-05 21:21:43,751 INFO:   Starting stage: EVALUATION
2022-12-05 21:21:43,876 INFO:   Done with stage: EVALUATION
2022-12-05 21:21:43,877 INFO:   Leaving out SEQ value Fold_1
2022-12-05 21:21:43,889 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 21:21:43,890 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:21:44,530 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:21:44,530 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:21:44,599 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:21:44,599 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:21:44,599 INFO:     No hyperparam tuning for this model
2022-12-05 21:21:44,599 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:21:44,599 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:21:44,600 INFO:     None feature selector for col prot
2022-12-05 21:21:44,600 INFO:     None feature selector for col prot
2022-12-05 21:21:44,600 INFO:     None feature selector for col prot
2022-12-05 21:21:44,600 INFO:     None feature selector for col chem
2022-12-05 21:21:44,600 INFO:     None feature selector for col chem
2022-12-05 21:21:44,601 INFO:     None feature selector for col chem
2022-12-05 21:21:44,601 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:21:44,601 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:21:44,602 INFO:     Number of params in model 215821
2022-12-05 21:21:44,605 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:21:44,606 INFO:   Starting stage: TRAINING
2022-12-05 21:21:44,665 INFO:     Val loss before train {'Reaction outcome loss': 1.0491071800852931, 'Total loss': 1.0491071800852931}
2022-12-05 21:21:44,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:44,665 INFO:     Epoch: 0
2022-12-05 21:21:45,449 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6131393618361894, 'Total loss': 0.6131393618361894} | train loss {'Reaction outcome loss': 0.7940292964256349, 'Total loss': 0.7940292964256349}
2022-12-05 21:21:45,449 INFO:     Found new best model at epoch 0
2022-12-05 21:21:45,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:45,450 INFO:     Epoch: 1
2022-12-05 21:21:46,232 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5181984419739524, 'Total loss': 0.5181984419739524} | train loss {'Reaction outcome loss': 0.5378645965101297, 'Total loss': 0.5378645965101297}
2022-12-05 21:21:46,232 INFO:     Found new best model at epoch 1
2022-12-05 21:21:46,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:46,233 INFO:     Epoch: 2
2022-12-05 21:21:47,017 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4847864272982575, 'Total loss': 0.4847864272982575} | train loss {'Reaction outcome loss': 0.46743599399004454, 'Total loss': 0.46743599399004454}
2022-12-05 21:21:47,018 INFO:     Found new best model at epoch 2
2022-12-05 21:21:47,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:47,018 INFO:     Epoch: 3
2022-12-05 21:21:47,809 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4670315939326619, 'Total loss': 0.4670315939326619} | train loss {'Reaction outcome loss': 0.42683772387082686, 'Total loss': 0.42683772387082686}
2022-12-05 21:21:47,809 INFO:     Found new best model at epoch 3
2022-12-05 21:21:47,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:47,810 INFO:     Epoch: 4
2022-12-05 21:21:48,594 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45786362921082696, 'Total loss': 0.45786362921082696} | train loss {'Reaction outcome loss': 0.3962629933538751, 'Total loss': 0.3962629933538751}
2022-12-05 21:21:48,594 INFO:     Found new best model at epoch 4
2022-12-05 21:21:48,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:48,595 INFO:     Epoch: 5
2022-12-05 21:21:49,378 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4461649607780368, 'Total loss': 0.4461649607780368} | train loss {'Reaction outcome loss': 0.374893191021411, 'Total loss': 0.374893191021411}
2022-12-05 21:21:49,379 INFO:     Found new best model at epoch 5
2022-12-05 21:21:49,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:49,379 INFO:     Epoch: 6
2022-12-05 21:21:50,162 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4488715650730355, 'Total loss': 0.4488715650730355} | train loss {'Reaction outcome loss': 0.3532046781461916, 'Total loss': 0.3532046781461916}
2022-12-05 21:21:50,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:50,163 INFO:     Epoch: 7
2022-12-05 21:21:50,947 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44211024080598077, 'Total loss': 0.44211024080598077} | train loss {'Reaction outcome loss': 0.3357042318876879, 'Total loss': 0.3357042318876879}
2022-12-05 21:21:50,948 INFO:     Found new best model at epoch 7
2022-12-05 21:21:50,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:50,948 INFO:     Epoch: 8
2022-12-05 21:21:51,737 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4339168948489566, 'Total loss': 0.4339168948489566} | train loss {'Reaction outcome loss': 0.32280424960846765, 'Total loss': 0.32280424960846765}
2022-12-05 21:21:51,738 INFO:     Found new best model at epoch 8
2022-12-05 21:21:51,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:51,738 INFO:     Epoch: 9
2022-12-05 21:21:52,522 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44161888437215674, 'Total loss': 0.44161888437215674} | train loss {'Reaction outcome loss': 0.30541278676363665, 'Total loss': 0.30541278676363665}
2022-12-05 21:21:52,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:52,522 INFO:     Epoch: 10
2022-12-05 21:21:53,306 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42729149446931, 'Total loss': 0.42729149446931} | train loss {'Reaction outcome loss': 0.29715677269508317, 'Total loss': 0.29715677269508317}
2022-12-05 21:21:53,306 INFO:     Found new best model at epoch 10
2022-12-05 21:21:53,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:53,307 INFO:     Epoch: 11
2022-12-05 21:21:54,092 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4409830864778785, 'Total loss': 0.4409830864778785} | train loss {'Reaction outcome loss': 0.2857528388990787, 'Total loss': 0.2857528388990787}
2022-12-05 21:21:54,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:54,092 INFO:     Epoch: 12
2022-12-05 21:21:54,876 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43074928016163583, 'Total loss': 0.43074928016163583} | train loss {'Reaction outcome loss': 0.2734396105379234, 'Total loss': 0.2734396105379234}
2022-12-05 21:21:54,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:54,876 INFO:     Epoch: 13
2022-12-05 21:21:55,660 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4333677312662435, 'Total loss': 0.4333677312662435} | train loss {'Reaction outcome loss': 0.2664954539219784, 'Total loss': 0.2664954539219784}
2022-12-05 21:21:55,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:55,660 INFO:     Epoch: 14
2022-12-05 21:21:56,452 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4302419805249503, 'Total loss': 0.4302419805249503} | train loss {'Reaction outcome loss': 0.25910207975671123, 'Total loss': 0.25910207975671123}
2022-12-05 21:21:56,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:56,452 INFO:     Epoch: 15
2022-12-05 21:21:57,238 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43909119520076484, 'Total loss': 0.43909119520076484} | train loss {'Reaction outcome loss': 0.25325919816523423, 'Total loss': 0.25325919816523423}
2022-12-05 21:21:57,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:57,238 INFO:     Epoch: 16
2022-12-05 21:21:58,022 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4276691834593928, 'Total loss': 0.4276691834593928} | train loss {'Reaction outcome loss': 0.24361204948475576, 'Total loss': 0.24361204948475576}
2022-12-05 21:21:58,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:58,022 INFO:     Epoch: 17
2022-12-05 21:21:58,808 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4415516451347706, 'Total loss': 0.4415516451347706} | train loss {'Reaction outcome loss': 0.23759540521497588, 'Total loss': 0.23759540521497588}
2022-12-05 21:21:58,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:58,808 INFO:     Epoch: 18
2022-12-05 21:21:59,590 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4367676623338877, 'Total loss': 0.4367676623338877} | train loss {'Reaction outcome loss': 0.23325708781372864, 'Total loss': 0.23325708781372864}
2022-12-05 21:21:59,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:21:59,590 INFO:     Epoch: 19
2022-12-05 21:22:00,377 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4340734346661457, 'Total loss': 0.4340734346661457} | train loss {'Reaction outcome loss': 0.22529973506682205, 'Total loss': 0.22529973506682205}
2022-12-05 21:22:00,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:00,377 INFO:     Epoch: 20
2022-12-05 21:22:01,163 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4511128161535707, 'Total loss': 0.4511128161535707} | train loss {'Reaction outcome loss': 0.21906335584420727, 'Total loss': 0.21906335584420727}
2022-12-05 21:22:01,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:01,163 INFO:     Epoch: 21
2022-12-05 21:22:01,948 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45375805365484817, 'Total loss': 0.45375805365484817} | train loss {'Reaction outcome loss': 0.21436358266222624, 'Total loss': 0.21436358266222624}
2022-12-05 21:22:01,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:01,949 INFO:     Epoch: 22
2022-12-05 21:22:02,733 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44387432343738026, 'Total loss': 0.44387432343738026} | train loss {'Reaction outcome loss': 0.21420154490588625, 'Total loss': 0.21420154490588625}
2022-12-05 21:22:02,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:02,733 INFO:     Epoch: 23
2022-12-05 21:22:03,517 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4640956084395564, 'Total loss': 0.4640956084395564} | train loss {'Reaction outcome loss': 0.20923673744033638, 'Total loss': 0.20923673744033638}
2022-12-05 21:22:03,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:03,517 INFO:     Epoch: 24
2022-12-05 21:22:04,302 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45583353312902675, 'Total loss': 0.45583353312902675} | train loss {'Reaction outcome loss': 0.20568723234620115, 'Total loss': 0.20568723234620115}
2022-12-05 21:22:04,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:04,302 INFO:     Epoch: 25
2022-12-05 21:22:05,084 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4427967106187066, 'Total loss': 0.4427967106187066} | train loss {'Reaction outcome loss': 0.20276930578696875, 'Total loss': 0.20276930578696875}
2022-12-05 21:22:05,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:05,084 INFO:     Epoch: 26
2022-12-05 21:22:05,869 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45984638465005295, 'Total loss': 0.45984638465005295} | train loss {'Reaction outcome loss': 0.19873640864106362, 'Total loss': 0.19873640864106362}
2022-12-05 21:22:05,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:05,870 INFO:     Epoch: 27
2022-12-05 21:22:06,653 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47008928656578064, 'Total loss': 0.47008928656578064} | train loss {'Reaction outcome loss': 0.19165603883963062, 'Total loss': 0.19165603883963062}
2022-12-05 21:22:06,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:06,653 INFO:     Epoch: 28
2022-12-05 21:22:07,445 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4416819058878477, 'Total loss': 0.4416819058878477} | train loss {'Reaction outcome loss': 0.18886176018435277, 'Total loss': 0.18886176018435277}
2022-12-05 21:22:07,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:07,445 INFO:     Epoch: 29
2022-12-05 21:22:08,232 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4527345438336217, 'Total loss': 0.4527345438336217} | train loss {'Reaction outcome loss': 0.18484743702160233, 'Total loss': 0.18484743702160233}
2022-12-05 21:22:08,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:08,234 INFO:     Epoch: 30
2022-12-05 21:22:09,015 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4597971938377203, 'Total loss': 0.4597971938377203} | train loss {'Reaction outcome loss': 0.18359436586867145, 'Total loss': 0.18359436586867145}
2022-12-05 21:22:09,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:09,015 INFO:     Epoch: 31
2022-12-05 21:22:09,797 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46695897988108703, 'Total loss': 0.46695897988108703} | train loss {'Reaction outcome loss': 0.18223959078759322, 'Total loss': 0.18223959078759322}
2022-12-05 21:22:09,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:09,797 INFO:     Epoch: 32
2022-12-05 21:22:10,583 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45112554122542226, 'Total loss': 0.45112554122542226} | train loss {'Reaction outcome loss': 0.17965809649830003, 'Total loss': 0.17965809649830003}
2022-12-05 21:22:10,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:10,583 INFO:     Epoch: 33
2022-12-05 21:22:11,370 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46882032966891, 'Total loss': 0.46882032966891} | train loss {'Reaction outcome loss': 0.17726131568475026, 'Total loss': 0.17726131568475026}
2022-12-05 21:22:11,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:11,370 INFO:     Epoch: 34
2022-12-05 21:22:12,153 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44835713644360387, 'Total loss': 0.44835713644360387} | train loss {'Reaction outcome loss': 0.17176981813009876, 'Total loss': 0.17176981813009876}
2022-12-05 21:22:12,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:12,153 INFO:     Epoch: 35
2022-12-05 21:22:12,934 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4580808992302695, 'Total loss': 0.4580808992302695} | train loss {'Reaction outcome loss': 0.17093705814408422, 'Total loss': 0.17093705814408422}
2022-12-05 21:22:12,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:12,935 INFO:     Epoch: 36
2022-12-05 21:22:13,716 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4589704853850742, 'Total loss': 0.4589704853850742} | train loss {'Reaction outcome loss': 0.1727407018619555, 'Total loss': 0.1727407018619555}
2022-12-05 21:22:13,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:13,716 INFO:     Epoch: 37
2022-12-05 21:22:14,498 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45486742223418036, 'Total loss': 0.45486742223418036} | train loss {'Reaction outcome loss': 0.16941281238670458, 'Total loss': 0.16941281238670458}
2022-12-05 21:22:14,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:14,499 INFO:     Epoch: 38
2022-12-05 21:22:15,285 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4620495358871859, 'Total loss': 0.4620495358871859} | train loss {'Reaction outcome loss': 0.16378153274947232, 'Total loss': 0.16378153274947232}
2022-12-05 21:22:15,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:15,285 INFO:     Epoch: 39
2022-12-05 21:22:16,073 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45737330684828204, 'Total loss': 0.45737330684828204} | train loss {'Reaction outcome loss': 0.16516220939456802, 'Total loss': 0.16516220939456802}
2022-12-05 21:22:16,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:16,073 INFO:     Epoch: 40
2022-12-05 21:22:16,856 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4631236729233764, 'Total loss': 0.4631236729233764} | train loss {'Reaction outcome loss': 0.16406532947295976, 'Total loss': 0.16406532947295976}
2022-12-05 21:22:16,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:16,857 INFO:     Epoch: 41
2022-12-05 21:22:17,639 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46386575560237087, 'Total loss': 0.46386575560237087} | train loss {'Reaction outcome loss': 0.16072221117193808, 'Total loss': 0.16072221117193808}
2022-12-05 21:22:17,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:17,640 INFO:     Epoch: 42
2022-12-05 21:22:18,425 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4796626086151877, 'Total loss': 0.4796626086151877} | train loss {'Reaction outcome loss': 0.15833412428911575, 'Total loss': 0.15833412428911575}
2022-12-05 21:22:18,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:18,425 INFO:     Epoch: 43
2022-12-05 21:22:19,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45540906142356785, 'Total loss': 0.45540906142356785} | train loss {'Reaction outcome loss': 0.16004905472567052, 'Total loss': 0.16004905472567052}
2022-12-05 21:22:19,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:19,211 INFO:     Epoch: 44
2022-12-05 21:22:19,996 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.471080471609914, 'Total loss': 0.471080471609914} | train loss {'Reaction outcome loss': 0.15502500396850424, 'Total loss': 0.15502500396850424}
2022-12-05 21:22:19,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:19,996 INFO:     Epoch: 45
2022-12-05 21:22:20,780 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4629177213754765, 'Total loss': 0.4629177213754765} | train loss {'Reaction outcome loss': 0.15576675613199978, 'Total loss': 0.15576675613199978}
2022-12-05 21:22:20,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:20,781 INFO:     Epoch: 46
2022-12-05 21:22:21,565 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49403129760609116, 'Total loss': 0.49403129760609116} | train loss {'Reaction outcome loss': 0.15753657591563683, 'Total loss': 0.15753657591563683}
2022-12-05 21:22:21,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:21,566 INFO:     Epoch: 47
2022-12-05 21:22:22,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46503723984540896, 'Total loss': 0.46503723984540896} | train loss {'Reaction outcome loss': 0.15371141079123374, 'Total loss': 0.15371141079123374}
2022-12-05 21:22:22,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:22,350 INFO:     Epoch: 48
2022-12-05 21:22:23,132 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48650957851908927, 'Total loss': 0.48650957851908927} | train loss {'Reaction outcome loss': 0.152347928480295, 'Total loss': 0.152347928480295}
2022-12-05 21:22:23,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:23,132 INFO:     Epoch: 49
2022-12-05 21:22:23,916 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4654591249865155, 'Total loss': 0.4654591249865155} | train loss {'Reaction outcome loss': 0.1488672152713493, 'Total loss': 0.1488672152713493}
2022-12-05 21:22:23,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:23,916 INFO:     Epoch: 50
2022-12-05 21:22:24,703 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4784221177877382, 'Total loss': 0.4784221177877382} | train loss {'Reaction outcome loss': 0.14612185530011915, 'Total loss': 0.14612185530011915}
2022-12-05 21:22:24,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:24,703 INFO:     Epoch: 51
2022-12-05 21:22:25,484 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.464641451662363, 'Total loss': 0.464641451662363} | train loss {'Reaction outcome loss': 0.14850839136222016, 'Total loss': 0.14850839136222016}
2022-12-05 21:22:25,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:25,484 INFO:     Epoch: 52
2022-12-05 21:22:26,266 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46293849584668184, 'Total loss': 0.46293849584668184} | train loss {'Reaction outcome loss': 0.1468727081906771, 'Total loss': 0.1468727081906771}
2022-12-05 21:22:26,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:26,266 INFO:     Epoch: 53
2022-12-05 21:22:27,049 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.456624953552734, 'Total loss': 0.456624953552734} | train loss {'Reaction outcome loss': 0.14629188659811707, 'Total loss': 0.14629188659811707}
2022-12-05 21:22:27,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:27,049 INFO:     Epoch: 54
2022-12-05 21:22:27,836 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46835336089134216, 'Total loss': 0.46835336089134216} | train loss {'Reaction outcome loss': 0.1448123843137006, 'Total loss': 0.1448123843137006}
2022-12-05 21:22:27,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:27,836 INFO:     Epoch: 55
2022-12-05 21:22:28,619 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45295990067859027, 'Total loss': 0.45295990067859027} | train loss {'Reaction outcome loss': 0.14332522731657626, 'Total loss': 0.14332522731657626}
2022-12-05 21:22:28,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:28,620 INFO:     Epoch: 56
2022-12-05 21:22:29,401 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45823319394921147, 'Total loss': 0.45823319394921147} | train loss {'Reaction outcome loss': 0.1402312838414937, 'Total loss': 0.1402312838414937}
2022-12-05 21:22:29,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:29,401 INFO:     Epoch: 57
2022-12-05 21:22:30,191 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.466446777935638, 'Total loss': 0.466446777935638} | train loss {'Reaction outcome loss': 0.14162618631723148, 'Total loss': 0.14162618631723148}
2022-12-05 21:22:30,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:30,191 INFO:     Epoch: 58
2022-12-05 21:22:30,971 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4763448283422825, 'Total loss': 0.4763448283422825} | train loss {'Reaction outcome loss': 0.14227000206954193, 'Total loss': 0.14227000206954193}
2022-12-05 21:22:30,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:30,972 INFO:     Epoch: 59
2022-12-05 21:22:31,756 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45341066478989844, 'Total loss': 0.45341066478989844} | train loss {'Reaction outcome loss': 0.14134872047069633, 'Total loss': 0.14134872047069633}
2022-12-05 21:22:31,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:31,756 INFO:     Epoch: 60
2022-12-05 21:22:32,538 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47805520406989166, 'Total loss': 0.47805520406989166} | train loss {'Reaction outcome loss': 0.13838006155143795, 'Total loss': 0.13838006155143795}
2022-12-05 21:22:32,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:32,539 INFO:     Epoch: 61
2022-12-05 21:22:33,320 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4530972632211308, 'Total loss': 0.4530972632211308} | train loss {'Reaction outcome loss': 0.14002474654971817, 'Total loss': 0.14002474654971817}
2022-12-05 21:22:33,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:33,321 INFO:     Epoch: 62
2022-12-05 21:22:34,108 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4734364914339642, 'Total loss': 0.4734364914339642} | train loss {'Reaction outcome loss': 0.13701931081344315, 'Total loss': 0.13701931081344315}
2022-12-05 21:22:34,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:34,108 INFO:     Epoch: 63
2022-12-05 21:22:34,890 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4568592711936596, 'Total loss': 0.4568592711936596} | train loss {'Reaction outcome loss': 0.13769195149863453, 'Total loss': 0.13769195149863453}
2022-12-05 21:22:34,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:34,890 INFO:     Epoch: 64
2022-12-05 21:22:35,671 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4588932599439177, 'Total loss': 0.4588932599439177} | train loss {'Reaction outcome loss': 0.13657193588008606, 'Total loss': 0.13657193588008606}
2022-12-05 21:22:35,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:35,672 INFO:     Epoch: 65
2022-12-05 21:22:36,455 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46936157865579736, 'Total loss': 0.46936157865579736} | train loss {'Reaction outcome loss': 0.13429333031974702, 'Total loss': 0.13429333031974702}
2022-12-05 21:22:36,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:36,456 INFO:     Epoch: 66
2022-12-05 21:22:37,235 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4734890648098879, 'Total loss': 0.4734890648098879} | train loss {'Reaction outcome loss': 0.13449511596925343, 'Total loss': 0.13449511596925343}
2022-12-05 21:22:37,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:37,235 INFO:     Epoch: 67
2022-12-05 21:22:38,015 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.483351452059524, 'Total loss': 0.483351452059524} | train loss {'Reaction outcome loss': 0.1321817360849047, 'Total loss': 0.1321817360849047}
2022-12-05 21:22:38,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:38,016 INFO:     Epoch: 68
2022-12-05 21:22:38,796 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45483398472153863, 'Total loss': 0.45483398472153863} | train loss {'Reaction outcome loss': 0.13175243575800472, 'Total loss': 0.13175243575800472}
2022-12-05 21:22:38,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:38,797 INFO:     Epoch: 69
2022-12-05 21:22:39,579 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47151637293918186, 'Total loss': 0.47151637293918186} | train loss {'Reaction outcome loss': 0.13037469446919706, 'Total loss': 0.13037469446919706}
2022-12-05 21:22:39,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:39,579 INFO:     Epoch: 70
2022-12-05 21:22:40,361 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48380835354328156, 'Total loss': 0.48380835354328156} | train loss {'Reaction outcome loss': 0.12952292101542032, 'Total loss': 0.12952292101542032}
2022-12-05 21:22:40,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:40,361 INFO:     Epoch: 71
2022-12-05 21:22:41,145 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46339523792266846, 'Total loss': 0.46339523792266846} | train loss {'Reaction outcome loss': 0.13147248343062498, 'Total loss': 0.13147248343062498}
2022-12-05 21:22:41,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:41,145 INFO:     Epoch: 72
2022-12-05 21:22:41,929 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45458323456520255, 'Total loss': 0.45458323456520255} | train loss {'Reaction outcome loss': 0.12995264062144382, 'Total loss': 0.12995264062144382}
2022-12-05 21:22:41,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:41,931 INFO:     Epoch: 73
2022-12-05 21:22:42,712 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48020167648792267, 'Total loss': 0.48020167648792267} | train loss {'Reaction outcome loss': 0.1288699740965548, 'Total loss': 0.1288699740965548}
2022-12-05 21:22:42,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:42,712 INFO:     Epoch: 74
2022-12-05 21:22:43,495 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4491227549868961, 'Total loss': 0.4491227549868961} | train loss {'Reaction outcome loss': 0.13004082572021725, 'Total loss': 0.13004082572021725}
2022-12-05 21:22:43,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:43,496 INFO:     Epoch: 75
2022-12-05 21:22:44,276 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48129670633826144, 'Total loss': 0.48129670633826144} | train loss {'Reaction outcome loss': 0.1289925528613567, 'Total loss': 0.1289925528613567}
2022-12-05 21:22:44,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:44,276 INFO:     Epoch: 76
2022-12-05 21:22:45,062 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4669572347125342, 'Total loss': 0.4669572347125342} | train loss {'Reaction outcome loss': 0.12786140085539086, 'Total loss': 0.12786140085539086}
2022-12-05 21:22:45,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:45,063 INFO:     Epoch: 77
2022-12-05 21:22:45,842 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45098098384779556, 'Total loss': 0.45098098384779556} | train loss {'Reaction outcome loss': 0.12781664273805088, 'Total loss': 0.12781664273805088}
2022-12-05 21:22:45,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:45,842 INFO:     Epoch: 78
2022-12-05 21:22:46,624 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4660900585180105, 'Total loss': 0.4660900585180105} | train loss {'Reaction outcome loss': 0.12910550102254245, 'Total loss': 0.12910550102254245}
2022-12-05 21:22:46,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:46,624 INFO:     Epoch: 79
2022-12-05 21:22:47,417 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4533914838765943, 'Total loss': 0.4533914838765943} | train loss {'Reaction outcome loss': 0.1284982425701103, 'Total loss': 0.1284982425701103}
2022-12-05 21:22:47,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:47,417 INFO:     Epoch: 80
2022-12-05 21:22:48,202 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47703128602615624, 'Total loss': 0.47703128602615624} | train loss {'Reaction outcome loss': 0.12572040025781028, 'Total loss': 0.12572040025781028}
2022-12-05 21:22:48,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:48,202 INFO:     Epoch: 81
2022-12-05 21:22:48,984 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4641672883962476, 'Total loss': 0.4641672883962476} | train loss {'Reaction outcome loss': 0.1292103074199746, 'Total loss': 0.1292103074199746}
2022-12-05 21:22:48,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:48,984 INFO:     Epoch: 82
2022-12-05 21:22:49,765 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47658150313898573, 'Total loss': 0.47658150313898573} | train loss {'Reaction outcome loss': 0.12647125754244778, 'Total loss': 0.12647125754244778}
2022-12-05 21:22:49,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:49,766 INFO:     Epoch: 83
2022-12-05 21:22:50,550 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4692675393334655, 'Total loss': 0.4692675393334655} | train loss {'Reaction outcome loss': 0.12340695859956337, 'Total loss': 0.12340695859956337}
2022-12-05 21:22:50,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:50,551 INFO:     Epoch: 84
2022-12-05 21:22:51,337 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4702860733797384, 'Total loss': 0.4702860733797384} | train loss {'Reaction outcome loss': 0.12585210788289827, 'Total loss': 0.12585210788289827}
2022-12-05 21:22:51,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:51,337 INFO:     Epoch: 85
2022-12-05 21:22:52,121 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4718814079844674, 'Total loss': 0.4718814079844674} | train loss {'Reaction outcome loss': 0.12671036147531659, 'Total loss': 0.12671036147531659}
2022-12-05 21:22:52,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:52,121 INFO:     Epoch: 86
2022-12-05 21:22:52,905 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4612868837145872, 'Total loss': 0.4612868837145872} | train loss {'Reaction outcome loss': 0.12357611097625376, 'Total loss': 0.12357611097625376}
2022-12-05 21:22:52,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:52,905 INFO:     Epoch: 87
2022-12-05 21:22:53,687 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4780490405337755, 'Total loss': 0.4780490405337755} | train loss {'Reaction outcome loss': 0.12244682245094467, 'Total loss': 0.12244682245094467}
2022-12-05 21:22:53,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:53,687 INFO:     Epoch: 88
2022-12-05 21:22:54,473 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4697901644679003, 'Total loss': 0.4697901644679003} | train loss {'Reaction outcome loss': 0.12289978495565217, 'Total loss': 0.12289978495565217}
2022-12-05 21:22:54,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:54,474 INFO:     Epoch: 89
2022-12-05 21:22:55,261 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.470730135087357, 'Total loss': 0.470730135087357} | train loss {'Reaction outcome loss': 0.12310700117391937, 'Total loss': 0.12310700117391937}
2022-12-05 21:22:55,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:55,261 INFO:     Epoch: 90
2022-12-05 21:22:56,049 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47331187822097953, 'Total loss': 0.47331187822097953} | train loss {'Reaction outcome loss': 0.12246122441174072, 'Total loss': 0.12246122441174072}
2022-12-05 21:22:56,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:56,049 INFO:     Epoch: 91
2022-12-05 21:22:56,832 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4608270014787829, 'Total loss': 0.4608270014787829} | train loss {'Reaction outcome loss': 0.12186805101364483, 'Total loss': 0.12186805101364483}
2022-12-05 21:22:56,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:56,832 INFO:     Epoch: 92
2022-12-05 21:22:57,614 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4697669418745263, 'Total loss': 0.4697669418745263} | train loss {'Reaction outcome loss': 0.12108193407670706, 'Total loss': 0.12108193407670706}
2022-12-05 21:22:57,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:57,614 INFO:     Epoch: 93
2022-12-05 21:22:58,399 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4646834658328877, 'Total loss': 0.4646834658328877} | train loss {'Reaction outcome loss': 0.12321856389504401, 'Total loss': 0.12321856389504401}
2022-12-05 21:22:58,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:58,400 INFO:     Epoch: 94
2022-12-05 21:22:59,186 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4820773126774056, 'Total loss': 0.4820773126774056} | train loss {'Reaction outcome loss': 0.12119726175940576, 'Total loss': 0.12119726175940576}
2022-12-05 21:22:59,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:59,186 INFO:     Epoch: 95
2022-12-05 21:22:59,969 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4764993308588516, 'Total loss': 0.4764993308588516} | train loss {'Reaction outcome loss': 0.12094240243941423, 'Total loss': 0.12094240243941423}
2022-12-05 21:22:59,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:22:59,970 INFO:     Epoch: 96
2022-12-05 21:23:00,752 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4787476970705875, 'Total loss': 0.4787476970705875} | train loss {'Reaction outcome loss': 0.12104990782499804, 'Total loss': 0.12104990782499804}
2022-12-05 21:23:00,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:00,753 INFO:     Epoch: 97
2022-12-05 21:23:01,532 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4544104188680649, 'Total loss': 0.4544104188680649} | train loss {'Reaction outcome loss': 0.12106832741939849, 'Total loss': 0.12106832741939849}
2022-12-05 21:23:01,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:01,532 INFO:     Epoch: 98
2022-12-05 21:23:02,314 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4810275470101556, 'Total loss': 0.4810275470101556} | train loss {'Reaction outcome loss': 0.11974902969972832, 'Total loss': 0.11974902969972832}
2022-12-05 21:23:02,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:02,314 INFO:     Epoch: 99
2022-12-05 21:23:03,095 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46548236248105074, 'Total loss': 0.46548236248105074} | train loss {'Reaction outcome loss': 0.11954438804031768, 'Total loss': 0.11954438804031768}
2022-12-05 21:23:03,095 INFO:     Best model found after epoch 11 of 100.
2022-12-05 21:23:03,095 INFO:   Done with stage: TRAINING
2022-12-05 21:23:03,095 INFO:   Starting stage: EVALUATION
2022-12-05 21:23:03,237 INFO:   Done with stage: EVALUATION
2022-12-05 21:23:03,237 INFO:   Leaving out SEQ value Fold_2
2022-12-05 21:23:03,250 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:23:03,250 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:23:03,888 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:23:03,888 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:23:03,958 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:23:03,958 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:23:03,958 INFO:     No hyperparam tuning for this model
2022-12-05 21:23:03,958 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:23:03,958 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:23:03,959 INFO:     None feature selector for col prot
2022-12-05 21:23:03,959 INFO:     None feature selector for col prot
2022-12-05 21:23:03,959 INFO:     None feature selector for col prot
2022-12-05 21:23:03,960 INFO:     None feature selector for col chem
2022-12-05 21:23:03,960 INFO:     None feature selector for col chem
2022-12-05 21:23:03,960 INFO:     None feature selector for col chem
2022-12-05 21:23:03,960 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:23:03,960 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:23:03,962 INFO:     Number of params in model 215821
2022-12-05 21:23:03,965 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:23:03,965 INFO:   Starting stage: TRAINING
2022-12-05 21:23:04,025 INFO:     Val loss before train {'Reaction outcome loss': 0.9485145224766298, 'Total loss': 0.9485145224766298}
2022-12-05 21:23:04,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:04,026 INFO:     Epoch: 0
2022-12-05 21:23:04,812 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5945501530712302, 'Total loss': 0.5945501530712302} | train loss {'Reaction outcome loss': 0.8065026010785784, 'Total loss': 0.8065026010785784}
2022-12-05 21:23:04,812 INFO:     Found new best model at epoch 0
2022-12-05 21:23:04,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:04,813 INFO:     Epoch: 1
2022-12-05 21:23:05,601 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5352985960516062, 'Total loss': 0.5352985960516062} | train loss {'Reaction outcome loss': 0.546616341873091, 'Total loss': 0.546616341873091}
2022-12-05 21:23:05,601 INFO:     Found new best model at epoch 1
2022-12-05 21:23:05,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:05,602 INFO:     Epoch: 2
2022-12-05 21:23:06,387 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47997813536362216, 'Total loss': 0.47997813536362216} | train loss {'Reaction outcome loss': 0.48128164593054323, 'Total loss': 0.48128164593054323}
2022-12-05 21:23:06,387 INFO:     Found new best model at epoch 2
2022-12-05 21:23:06,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:06,388 INFO:     Epoch: 3
2022-12-05 21:23:07,176 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4640016420321031, 'Total loss': 0.4640016420321031} | train loss {'Reaction outcome loss': 0.43778723508727796, 'Total loss': 0.43778723508727796}
2022-12-05 21:23:07,181 INFO:     Found new best model at epoch 3
2022-12-05 21:23:07,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:07,182 INFO:     Epoch: 4
2022-12-05 21:23:07,968 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46083974702791736, 'Total loss': 0.46083974702791736} | train loss {'Reaction outcome loss': 0.4138642459803698, 'Total loss': 0.4138642459803698}
2022-12-05 21:23:07,968 INFO:     Found new best model at epoch 4
2022-12-05 21:23:07,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:07,969 INFO:     Epoch: 5
2022-12-05 21:23:08,755 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4372625740414316, 'Total loss': 0.4372625740414316} | train loss {'Reaction outcome loss': 0.38957388936256876, 'Total loss': 0.38957388936256876}
2022-12-05 21:23:08,755 INFO:     Found new best model at epoch 5
2022-12-05 21:23:08,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:08,756 INFO:     Epoch: 6
2022-12-05 21:23:09,540 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44132081961089914, 'Total loss': 0.44132081961089914} | train loss {'Reaction outcome loss': 0.3701492208911448, 'Total loss': 0.3701492208911448}
2022-12-05 21:23:09,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:09,540 INFO:     Epoch: 7
2022-12-05 21:23:10,329 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4224627837538719, 'Total loss': 0.4224627837538719} | train loss {'Reaction outcome loss': 0.35424227182354245, 'Total loss': 0.35424227182354245}
2022-12-05 21:23:10,330 INFO:     Found new best model at epoch 7
2022-12-05 21:23:10,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:10,330 INFO:     Epoch: 8
2022-12-05 21:23:11,117 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4218276202340018, 'Total loss': 0.4218276202340018} | train loss {'Reaction outcome loss': 0.3382128578059527, 'Total loss': 0.3382128578059527}
2022-12-05 21:23:11,117 INFO:     Found new best model at epoch 8
2022-12-05 21:23:11,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:11,118 INFO:     Epoch: 9
2022-12-05 21:23:11,909 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4300624467432499, 'Total loss': 0.4300624467432499} | train loss {'Reaction outcome loss': 0.32294640915126216, 'Total loss': 0.32294640915126216}
2022-12-05 21:23:11,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:11,909 INFO:     Epoch: 10
2022-12-05 21:23:12,701 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42334522340785374, 'Total loss': 0.42334522340785374} | train loss {'Reaction outcome loss': 0.3101371353682207, 'Total loss': 0.3101371353682207}
2022-12-05 21:23:12,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:12,701 INFO:     Epoch: 11
2022-12-05 21:23:13,491 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43090990287336434, 'Total loss': 0.43090990287336434} | train loss {'Reaction outcome loss': 0.29699410887397065, 'Total loss': 0.29699410887397065}
2022-12-05 21:23:13,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:13,492 INFO:     Epoch: 12
2022-12-05 21:23:14,284 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4369279346005483, 'Total loss': 0.4369279346005483} | train loss {'Reaction outcome loss': 0.28606823232709144, 'Total loss': 0.28606823232709144}
2022-12-05 21:23:14,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:14,285 INFO:     Epoch: 13
2022-12-05 21:23:15,073 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4366148000752384, 'Total loss': 0.4366148000752384} | train loss {'Reaction outcome loss': 0.2802700039379451, 'Total loss': 0.2802700039379451}
2022-12-05 21:23:15,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:15,073 INFO:     Epoch: 14
2022-12-05 21:23:15,861 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4330678575418212, 'Total loss': 0.4330678575418212} | train loss {'Reaction outcome loss': 0.26963478880269187, 'Total loss': 0.26963478880269187}
2022-12-05 21:23:15,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:15,861 INFO:     Epoch: 15
2022-12-05 21:23:16,651 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44036184894767677, 'Total loss': 0.44036184894767677} | train loss {'Reaction outcome loss': 0.2613172158446847, 'Total loss': 0.2613172158446847}
2022-12-05 21:23:16,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:16,651 INFO:     Epoch: 16
2022-12-05 21:23:17,439 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43444402956149797, 'Total loss': 0.43444402956149797} | train loss {'Reaction outcome loss': 0.24959541297688775, 'Total loss': 0.24959541297688775}
2022-12-05 21:23:17,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:17,439 INFO:     Epoch: 17
2022-12-05 21:23:18,226 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42755133692513814, 'Total loss': 0.42755133692513814} | train loss {'Reaction outcome loss': 0.2455212799870238, 'Total loss': 0.2455212799870238}
2022-12-05 21:23:18,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:18,226 INFO:     Epoch: 18
2022-12-05 21:23:19,015 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4217673333531076, 'Total loss': 0.4217673333531076} | train loss {'Reaction outcome loss': 0.23594772555694288, 'Total loss': 0.23594772555694288}
2022-12-05 21:23:19,015 INFO:     Found new best model at epoch 18
2022-12-05 21:23:19,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:19,016 INFO:     Epoch: 19
2022-12-05 21:23:19,805 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4426885369149121, 'Total loss': 0.4426885369149121} | train loss {'Reaction outcome loss': 0.22904989828868788, 'Total loss': 0.22904989828868788}
2022-12-05 21:23:19,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:19,805 INFO:     Epoch: 20
2022-12-05 21:23:20,594 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4282072973860936, 'Total loss': 0.4282072973860936} | train loss {'Reaction outcome loss': 0.2238744182474151, 'Total loss': 0.2238744182474151}
2022-12-05 21:23:20,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:20,594 INFO:     Epoch: 21
2022-12-05 21:23:21,386 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45011329583146353, 'Total loss': 0.45011329583146353} | train loss {'Reaction outcome loss': 0.22092274021433325, 'Total loss': 0.22092274021433325}
2022-12-05 21:23:21,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:21,386 INFO:     Epoch: 22
2022-12-05 21:23:22,182 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4221875190480866, 'Total loss': 0.4221875190480866} | train loss {'Reaction outcome loss': 0.2115797676754241, 'Total loss': 0.2115797676754241}
2022-12-05 21:23:22,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:22,182 INFO:     Epoch: 23
2022-12-05 21:23:22,974 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42417417906902055, 'Total loss': 0.42417417906902055} | train loss {'Reaction outcome loss': 0.2076354699323372, 'Total loss': 0.2076354699323372}
2022-12-05 21:23:22,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:22,975 INFO:     Epoch: 24
2022-12-05 21:23:23,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4279267523776401, 'Total loss': 0.4279267523776401} | train loss {'Reaction outcome loss': 0.20582663331712994, 'Total loss': 0.20582663331712994}
2022-12-05 21:23:23,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:23,762 INFO:     Epoch: 25
2022-12-05 21:23:24,553 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.452497891404412, 'Total loss': 0.452497891404412} | train loss {'Reaction outcome loss': 0.2033037807336267, 'Total loss': 0.2033037807336267}
2022-12-05 21:23:24,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:24,553 INFO:     Epoch: 26
2022-12-05 21:23:25,340 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4462237882173874, 'Total loss': 0.4462237882173874} | train loss {'Reaction outcome loss': 0.19657146554364233, 'Total loss': 0.19657146554364233}
2022-12-05 21:23:25,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:25,340 INFO:     Epoch: 27
2022-12-05 21:23:26,136 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.435028267854994, 'Total loss': 0.435028267854994} | train loss {'Reaction outcome loss': 0.19528203921354548, 'Total loss': 0.19528203921354548}
2022-12-05 21:23:26,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:26,138 INFO:     Epoch: 28
2022-12-05 21:23:26,929 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4481054585088383, 'Total loss': 0.4481054585088383} | train loss {'Reaction outcome loss': 0.19344397643390968, 'Total loss': 0.19344397643390968}
2022-12-05 21:23:26,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:26,929 INFO:     Epoch: 29
2022-12-05 21:23:27,715 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4446536808867346, 'Total loss': 0.4446536808867346} | train loss {'Reaction outcome loss': 0.18821169785699066, 'Total loss': 0.18821169785699066}
2022-12-05 21:23:27,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:27,715 INFO:     Epoch: 30
2022-12-05 21:23:28,506 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4383440780961378, 'Total loss': 0.4383440780961378} | train loss {'Reaction outcome loss': 0.18401350806258163, 'Total loss': 0.18401350806258163}
2022-12-05 21:23:28,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:28,506 INFO:     Epoch: 31
2022-12-05 21:23:29,294 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44693986665118823, 'Total loss': 0.44693986665118823} | train loss {'Reaction outcome loss': 0.18216155291515954, 'Total loss': 0.18216155291515954}
2022-12-05 21:23:29,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:29,294 INFO:     Epoch: 32
2022-12-05 21:23:30,086 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4588942029936747, 'Total loss': 0.4588942029936747} | train loss {'Reaction outcome loss': 0.18011961910797625, 'Total loss': 0.18011961910797625}
2022-12-05 21:23:30,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:30,086 INFO:     Epoch: 33
2022-12-05 21:23:30,875 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4410265253682155, 'Total loss': 0.4410265253682155} | train loss {'Reaction outcome loss': 0.17628444386836217, 'Total loss': 0.17628444386836217}
2022-12-05 21:23:30,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:30,875 INFO:     Epoch: 34
2022-12-05 21:23:31,664 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4403149096125906, 'Total loss': 0.4403149096125906} | train loss {'Reaction outcome loss': 0.1759501748091104, 'Total loss': 0.1759501748091104}
2022-12-05 21:23:31,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:31,664 INFO:     Epoch: 35
2022-12-05 21:23:32,454 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4519864678044211, 'Total loss': 0.4519864678044211} | train loss {'Reaction outcome loss': 0.17149449222322022, 'Total loss': 0.17149449222322022}
2022-12-05 21:23:32,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:32,454 INFO:     Epoch: 36
2022-12-05 21:23:33,244 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46682177585634316, 'Total loss': 0.46682177585634316} | train loss {'Reaction outcome loss': 0.16930415601450569, 'Total loss': 0.16930415601450569}
2022-12-05 21:23:33,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:33,244 INFO:     Epoch: 37
2022-12-05 21:23:34,034 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44666484082964336, 'Total loss': 0.44666484082964336} | train loss {'Reaction outcome loss': 0.16598637092630475, 'Total loss': 0.16598637092630475}
2022-12-05 21:23:34,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:34,034 INFO:     Epoch: 38
2022-12-05 21:23:34,820 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4494258659807118, 'Total loss': 0.4494258659807118} | train loss {'Reaction outcome loss': 0.16714535925765428, 'Total loss': 0.16714535925765428}
2022-12-05 21:23:34,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:34,820 INFO:     Epoch: 39
2022-12-05 21:23:35,610 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45326712050221185, 'Total loss': 0.45326712050221185} | train loss {'Reaction outcome loss': 0.1641901170568807, 'Total loss': 0.1641901170568807}
2022-12-05 21:23:35,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:35,615 INFO:     Epoch: 40
2022-12-05 21:23:36,402 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4526144509965723, 'Total loss': 0.4526144509965723} | train loss {'Reaction outcome loss': 0.1617395739850341, 'Total loss': 0.1617395739850341}
2022-12-05 21:23:36,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:36,402 INFO:     Epoch: 41
2022-12-05 21:23:37,192 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4669128656387329, 'Total loss': 0.4669128656387329} | train loss {'Reaction outcome loss': 0.15973242081853808, 'Total loss': 0.15973242081853808}
2022-12-05 21:23:37,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:37,192 INFO:     Epoch: 42
2022-12-05 21:23:37,978 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.437653623521328, 'Total loss': 0.437653623521328} | train loss {'Reaction outcome loss': 0.158121828293922, 'Total loss': 0.158121828293922}
2022-12-05 21:23:37,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:37,978 INFO:     Epoch: 43
2022-12-05 21:23:38,765 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4513348567892205, 'Total loss': 0.4513348567892205} | train loss {'Reaction outcome loss': 0.15732960854561961, 'Total loss': 0.15732960854561961}
2022-12-05 21:23:38,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:38,765 INFO:     Epoch: 44
2022-12-05 21:23:39,559 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4511271705004302, 'Total loss': 0.4511271705004302} | train loss {'Reaction outcome loss': 0.1552138696937841, 'Total loss': 0.1552138696937841}
2022-12-05 21:23:39,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:39,559 INFO:     Epoch: 45
2022-12-05 21:23:40,346 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44752029939131305, 'Total loss': 0.44752029939131305} | train loss {'Reaction outcome loss': 0.15500593772348092, 'Total loss': 0.15500593772348092}
2022-12-05 21:23:40,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:40,346 INFO:     Epoch: 46
2022-12-05 21:23:41,134 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4671343206004663, 'Total loss': 0.4671343206004663} | train loss {'Reaction outcome loss': 0.15126889656697, 'Total loss': 0.15126889656697}
2022-12-05 21:23:41,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:41,135 INFO:     Epoch: 47
2022-12-05 21:23:41,926 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43885377557440236, 'Total loss': 0.43885377557440236} | train loss {'Reaction outcome loss': 0.14981010908983192, 'Total loss': 0.14981010908983192}
2022-12-05 21:23:41,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:41,926 INFO:     Epoch: 48
2022-12-05 21:23:42,716 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4718272584405812, 'Total loss': 0.4718272584405812} | train loss {'Reaction outcome loss': 0.14978507228043614, 'Total loss': 0.14978507228043614}
2022-12-05 21:23:42,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:42,716 INFO:     Epoch: 49
2022-12-05 21:23:43,503 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4582810594107617, 'Total loss': 0.4582810594107617} | train loss {'Reaction outcome loss': 0.14787846928348347, 'Total loss': 0.14787846928348347}
2022-12-05 21:23:43,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:43,503 INFO:     Epoch: 50
2022-12-05 21:23:44,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46065581166608766, 'Total loss': 0.46065581166608766} | train loss {'Reaction outcome loss': 0.14636622086851572, 'Total loss': 0.14636622086851572}
2022-12-05 21:23:44,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:44,293 INFO:     Epoch: 51
2022-12-05 21:23:45,081 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4757348026402972, 'Total loss': 0.4757348026402972} | train loss {'Reaction outcome loss': 0.1462321335943986, 'Total loss': 0.1462321335943986}
2022-12-05 21:23:45,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:45,081 INFO:     Epoch: 52
2022-12-05 21:23:45,872 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4654713269661773, 'Total loss': 0.4654713269661773} | train loss {'Reaction outcome loss': 0.1472691150800306, 'Total loss': 0.1472691150800306}
2022-12-05 21:23:45,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:45,872 INFO:     Epoch: 53
2022-12-05 21:23:46,660 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4572878693315116, 'Total loss': 0.4572878693315116} | train loss {'Reaction outcome loss': 0.14359524390679232, 'Total loss': 0.14359524390679232}
2022-12-05 21:23:46,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:46,661 INFO:     Epoch: 54
2022-12-05 21:23:47,454 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4426545480435545, 'Total loss': 0.4426545480435545} | train loss {'Reaction outcome loss': 0.14354257755437677, 'Total loss': 0.14354257755437677}
2022-12-05 21:23:47,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:47,454 INFO:     Epoch: 55
2022-12-05 21:23:48,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45569731058044866, 'Total loss': 0.45569731058044866} | train loss {'Reaction outcome loss': 0.142486648428805, 'Total loss': 0.142486648428805}
2022-12-05 21:23:48,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:48,245 INFO:     Epoch: 56
2022-12-05 21:23:49,035 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45437578027221287, 'Total loss': 0.45437578027221287} | train loss {'Reaction outcome loss': 0.14282221730266298, 'Total loss': 0.14282221730266298}
2022-12-05 21:23:49,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:49,035 INFO:     Epoch: 57
2022-12-05 21:23:49,831 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45178598080846394, 'Total loss': 0.45178598080846394} | train loss {'Reaction outcome loss': 0.13940616290332103, 'Total loss': 0.13940616290332103}
2022-12-05 21:23:49,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:49,831 INFO:     Epoch: 58
2022-12-05 21:23:50,624 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45181658694689925, 'Total loss': 0.45181658694689925} | train loss {'Reaction outcome loss': 0.1398160945624113, 'Total loss': 0.1398160945624113}
2022-12-05 21:23:50,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:50,625 INFO:     Epoch: 59
2022-12-05 21:23:51,415 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4537214125421914, 'Total loss': 0.4537214125421914} | train loss {'Reaction outcome loss': 0.14056179319717446, 'Total loss': 0.14056179319717446}
2022-12-05 21:23:51,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:51,415 INFO:     Epoch: 60
2022-12-05 21:23:52,212 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45826928554610774, 'Total loss': 0.45826928554610774} | train loss {'Reaction outcome loss': 0.1379319901825214, 'Total loss': 0.1379319901825214}
2022-12-05 21:23:52,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:52,212 INFO:     Epoch: 61
2022-12-05 21:23:53,010 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44953217086466873, 'Total loss': 0.44953217086466873} | train loss {'Reaction outcome loss': 0.1413961249194583, 'Total loss': 0.1413961249194583}
2022-12-05 21:23:53,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:53,010 INFO:     Epoch: 62
2022-12-05 21:23:53,808 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.464590861377391, 'Total loss': 0.464590861377391} | train loss {'Reaction outcome loss': 0.13747372526143278, 'Total loss': 0.13747372526143278}
2022-12-05 21:23:53,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:53,808 INFO:     Epoch: 63
2022-12-05 21:23:54,601 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4522715007716959, 'Total loss': 0.4522715007716959} | train loss {'Reaction outcome loss': 0.13637387047388724, 'Total loss': 0.13637387047388724}
2022-12-05 21:23:54,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:54,605 INFO:     Epoch: 64
2022-12-05 21:23:55,396 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4698714783245867, 'Total loss': 0.4698714783245867} | train loss {'Reaction outcome loss': 0.13353212787484636, 'Total loss': 0.13353212787484636}
2022-12-05 21:23:55,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:55,396 INFO:     Epoch: 65
2022-12-05 21:23:56,186 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4543706373396245, 'Total loss': 0.4543706373396245} | train loss {'Reaction outcome loss': 0.13569743916848484, 'Total loss': 0.13569743916848484}
2022-12-05 21:23:56,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:56,187 INFO:     Epoch: 66
2022-12-05 21:23:56,978 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4774543202736161, 'Total loss': 0.4774543202736161} | train loss {'Reaction outcome loss': 0.1357486644721761, 'Total loss': 0.1357486644721761}
2022-12-05 21:23:56,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:56,979 INFO:     Epoch: 67
2022-12-05 21:23:57,771 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4787144403566014, 'Total loss': 0.4787144403566014} | train loss {'Reaction outcome loss': 0.13292710227625712, 'Total loss': 0.13292710227625712}
2022-12-05 21:23:57,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:57,772 INFO:     Epoch: 68
2022-12-05 21:23:58,560 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46891033954241057, 'Total loss': 0.46891033954241057} | train loss {'Reaction outcome loss': 0.1323221540382626, 'Total loss': 0.1323221540382626}
2022-12-05 21:23:58,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:58,561 INFO:     Epoch: 69
2022-12-05 21:23:59,352 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46012614938345825, 'Total loss': 0.46012614938345825} | train loss {'Reaction outcome loss': 0.12972215977402365, 'Total loss': 0.12972215977402365}
2022-12-05 21:23:59,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:23:59,353 INFO:     Epoch: 70
2022-12-05 21:24:00,141 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4573363055559722, 'Total loss': 0.4573363055559722} | train loss {'Reaction outcome loss': 0.1308148657408904, 'Total loss': 0.1308148657408904}
2022-12-05 21:24:00,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:00,141 INFO:     Epoch: 71
2022-12-05 21:24:00,932 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45799173503606155, 'Total loss': 0.45799173503606155} | train loss {'Reaction outcome loss': 0.13416871990324283, 'Total loss': 0.13416871990324283}
2022-12-05 21:24:00,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:00,932 INFO:     Epoch: 72
2022-12-05 21:24:01,728 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46593612364747305, 'Total loss': 0.46593612364747305} | train loss {'Reaction outcome loss': 0.13160666363427834, 'Total loss': 0.13160666363427834}
2022-12-05 21:24:01,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:01,729 INFO:     Epoch: 73
2022-12-05 21:24:02,519 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4582767175002532, 'Total loss': 0.4582767175002532} | train loss {'Reaction outcome loss': 0.13129502205292182, 'Total loss': 0.13129502205292182}
2022-12-05 21:24:02,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:02,519 INFO:     Epoch: 74
2022-12-05 21:24:03,309 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46549963392317295, 'Total loss': 0.46549963392317295} | train loss {'Reaction outcome loss': 0.1313767328022086, 'Total loss': 0.1313767328022086}
2022-12-05 21:24:03,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:03,309 INFO:     Epoch: 75
2022-12-05 21:24:04,096 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46502064574848523, 'Total loss': 0.46502064574848523} | train loss {'Reaction outcome loss': 0.12677675880377695, 'Total loss': 0.12677675880377695}
2022-12-05 21:24:04,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:04,096 INFO:     Epoch: 76
2022-12-05 21:24:04,884 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.468931856141849, 'Total loss': 0.468931856141849} | train loss {'Reaction outcome loss': 0.1290887088533871, 'Total loss': 0.1290887088533871}
2022-12-05 21:24:04,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:04,884 INFO:     Epoch: 77
2022-12-05 21:24:05,677 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4603746452961456, 'Total loss': 0.4603746452961456} | train loss {'Reaction outcome loss': 0.1268170320295862, 'Total loss': 0.1268170320295862}
2022-12-05 21:24:05,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:05,677 INFO:     Epoch: 78
2022-12-05 21:24:06,470 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.464368440549482, 'Total loss': 0.464368440549482} | train loss {'Reaction outcome loss': 0.1278939973106798, 'Total loss': 0.1278939973106798}
2022-12-05 21:24:06,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:06,471 INFO:     Epoch: 79
2022-12-05 21:24:07,261 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47035025466572156, 'Total loss': 0.47035025466572156} | train loss {'Reaction outcome loss': 0.12573917782580366, 'Total loss': 0.12573917782580366}
2022-12-05 21:24:07,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:07,261 INFO:     Epoch: 80
2022-12-05 21:24:08,051 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46203728777023073, 'Total loss': 0.46203728777023073} | train loss {'Reaction outcome loss': 0.12702573262991346, 'Total loss': 0.12702573262991346}
2022-12-05 21:24:08,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:08,051 INFO:     Epoch: 81
2022-12-05 21:24:08,843 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4590050002390688, 'Total loss': 0.4590050002390688} | train loss {'Reaction outcome loss': 0.12757635310064164, 'Total loss': 0.12757635310064164}
2022-12-05 21:24:08,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:08,844 INFO:     Epoch: 82
2022-12-05 21:24:09,631 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49183583056384866, 'Total loss': 0.49183583056384866} | train loss {'Reaction outcome loss': 0.12675417979837073, 'Total loss': 0.12675417979837073}
2022-12-05 21:24:09,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:09,631 INFO:     Epoch: 83
2022-12-05 21:24:10,419 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47389063780958, 'Total loss': 0.47389063780958} | train loss {'Reaction outcome loss': 0.12529700663396898, 'Total loss': 0.12529700663396898}
2022-12-05 21:24:10,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:10,419 INFO:     Epoch: 84
2022-12-05 21:24:11,206 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45113771442662587, 'Total loss': 0.45113771442662587} | train loss {'Reaction outcome loss': 0.1256611152799154, 'Total loss': 0.1256611152799154}
2022-12-05 21:24:11,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:11,206 INFO:     Epoch: 85
2022-12-05 21:24:11,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45841360176828777, 'Total loss': 0.45841360176828777} | train loss {'Reaction outcome loss': 0.12486430643392461, 'Total loss': 0.12486430643392461}
2022-12-05 21:24:11,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:11,998 INFO:     Epoch: 86
2022-12-05 21:24:12,788 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5023926394906911, 'Total loss': 0.5023926394906911} | train loss {'Reaction outcome loss': 0.12579789479092068, 'Total loss': 0.12579789479092068}
2022-12-05 21:24:12,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:12,790 INFO:     Epoch: 87
2022-12-05 21:24:13,578 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47836803136901423, 'Total loss': 0.47836803136901423} | train loss {'Reaction outcome loss': 0.1250676606268603, 'Total loss': 0.1250676606268603}
2022-12-05 21:24:13,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:13,579 INFO:     Epoch: 88
2022-12-05 21:24:14,370 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4858913055875085, 'Total loss': 0.4858913055875085} | train loss {'Reaction outcome loss': 0.1256421498916283, 'Total loss': 0.1256421498916283}
2022-12-05 21:24:14,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:14,370 INFO:     Epoch: 89
2022-12-05 21:24:15,162 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4690166884525256, 'Total loss': 0.4690166884525256} | train loss {'Reaction outcome loss': 0.12295539926509468, 'Total loss': 0.12295539926509468}
2022-12-05 21:24:15,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:15,162 INFO:     Epoch: 90
2022-12-05 21:24:15,949 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46305136124349455, 'Total loss': 0.46305136124349455} | train loss {'Reaction outcome loss': 0.12131616855990522, 'Total loss': 0.12131616855990522}
2022-12-05 21:24:15,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:15,950 INFO:     Epoch: 91
2022-12-05 21:24:16,736 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4859822727739811, 'Total loss': 0.4859822727739811} | train loss {'Reaction outcome loss': 0.12177497327555807, 'Total loss': 0.12177497327555807}
2022-12-05 21:24:16,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:16,737 INFO:     Epoch: 92
2022-12-05 21:24:17,526 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46372516394000163, 'Total loss': 0.46372516394000163} | train loss {'Reaction outcome loss': 0.12137637874301599, 'Total loss': 0.12137637874301599}
2022-12-05 21:24:17,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:17,526 INFO:     Epoch: 93
2022-12-05 21:24:18,315 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46758619763634424, 'Total loss': 0.46758619763634424} | train loss {'Reaction outcome loss': 0.12094997145159513, 'Total loss': 0.12094997145159513}
2022-12-05 21:24:18,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:18,315 INFO:     Epoch: 94
2022-12-05 21:24:19,109 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.463697976348075, 'Total loss': 0.463697976348075} | train loss {'Reaction outcome loss': 0.12072615043393203, 'Total loss': 0.12072615043393203}
2022-12-05 21:24:19,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:19,109 INFO:     Epoch: 95
2022-12-05 21:24:19,897 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46407921747727826, 'Total loss': 0.46407921747727826} | train loss {'Reaction outcome loss': 0.12232441274183137, 'Total loss': 0.12232441274183137}
2022-12-05 21:24:19,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:19,897 INFO:     Epoch: 96
2022-12-05 21:24:20,684 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45966818764678796, 'Total loss': 0.45966818764678796} | train loss {'Reaction outcome loss': 0.1198047836748313, 'Total loss': 0.1198047836748313}
2022-12-05 21:24:20,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:20,684 INFO:     Epoch: 97
2022-12-05 21:24:21,472 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47887265241958876, 'Total loss': 0.47887265241958876} | train loss {'Reaction outcome loss': 0.11913414054683276, 'Total loss': 0.11913414054683276}
2022-12-05 21:24:21,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:21,472 INFO:     Epoch: 98
2022-12-05 21:24:22,265 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46435783845795825, 'Total loss': 0.46435783845795825} | train loss {'Reaction outcome loss': 0.11915668554375974, 'Total loss': 0.11915668554375974}
2022-12-05 21:24:22,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:22,266 INFO:     Epoch: 99
2022-12-05 21:24:23,056 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4657387628474019, 'Total loss': 0.4657387628474019} | train loss {'Reaction outcome loss': 0.11940486523873951, 'Total loss': 0.11940486523873951}
2022-12-05 21:24:23,056 INFO:     Best model found after epoch 19 of 100.
2022-12-05 21:24:23,056 INFO:   Done with stage: TRAINING
2022-12-05 21:24:23,056 INFO:   Starting stage: EVALUATION
2022-12-05 21:24:23,186 INFO:   Done with stage: EVALUATION
2022-12-05 21:24:23,186 INFO:   Leaving out SEQ value Fold_3
2022-12-05 21:24:23,199 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:24:23,199 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:24:23,846 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:24:23,847 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:24:23,917 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:24:23,917 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:24:23,917 INFO:     No hyperparam tuning for this model
2022-12-05 21:24:23,917 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:24:23,917 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:24:23,918 INFO:     None feature selector for col prot
2022-12-05 21:24:23,918 INFO:     None feature selector for col prot
2022-12-05 21:24:23,918 INFO:     None feature selector for col prot
2022-12-05 21:24:23,919 INFO:     None feature selector for col chem
2022-12-05 21:24:23,919 INFO:     None feature selector for col chem
2022-12-05 21:24:23,919 INFO:     None feature selector for col chem
2022-12-05 21:24:23,919 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:24:23,919 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:24:23,921 INFO:     Number of params in model 215821
2022-12-05 21:24:23,924 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:24:23,924 INFO:   Starting stage: TRAINING
2022-12-05 21:24:23,985 INFO:     Val loss before train {'Reaction outcome loss': 0.9915474822575395, 'Total loss': 0.9915474822575395}
2022-12-05 21:24:23,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:23,986 INFO:     Epoch: 0
2022-12-05 21:24:24,774 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6089949364011938, 'Total loss': 0.6089949364011938} | train loss {'Reaction outcome loss': 0.7942716358875742, 'Total loss': 0.7942716358875742}
2022-12-05 21:24:24,774 INFO:     Found new best model at epoch 0
2022-12-05 21:24:24,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:24,775 INFO:     Epoch: 1
2022-12-05 21:24:25,565 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5371096472848546, 'Total loss': 0.5371096472848546} | train loss {'Reaction outcome loss': 0.5457260577046141, 'Total loss': 0.5457260577046141}
2022-12-05 21:24:25,566 INFO:     Found new best model at epoch 1
2022-12-05 21:24:25,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:25,567 INFO:     Epoch: 2
2022-12-05 21:24:26,356 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5109409046444026, 'Total loss': 0.5109409046444026} | train loss {'Reaction outcome loss': 0.47654575979223057, 'Total loss': 0.47654575979223057}
2022-12-05 21:24:26,356 INFO:     Found new best model at epoch 2
2022-12-05 21:24:26,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:26,357 INFO:     Epoch: 3
2022-12-05 21:24:27,152 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4892776376483115, 'Total loss': 0.4892776376483115} | train loss {'Reaction outcome loss': 0.43361950811682914, 'Total loss': 0.43361950811682914}
2022-12-05 21:24:27,152 INFO:     Found new best model at epoch 3
2022-12-05 21:24:27,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:27,153 INFO:     Epoch: 4
2022-12-05 21:24:27,953 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46043386378071527, 'Total loss': 0.46043386378071527} | train loss {'Reaction outcome loss': 0.40918022199552884, 'Total loss': 0.40918022199552884}
2022-12-05 21:24:27,953 INFO:     Found new best model at epoch 4
2022-12-05 21:24:27,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:27,954 INFO:     Epoch: 5
2022-12-05 21:24:28,744 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45166535438461736, 'Total loss': 0.45166535438461736} | train loss {'Reaction outcome loss': 0.3850798499523377, 'Total loss': 0.3850798499523377}
2022-12-05 21:24:28,744 INFO:     Found new best model at epoch 5
2022-12-05 21:24:28,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:28,745 INFO:     Epoch: 6
2022-12-05 21:24:29,530 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4588093249635263, 'Total loss': 0.4588093249635263} | train loss {'Reaction outcome loss': 0.3653531927539378, 'Total loss': 0.3653531927539378}
2022-12-05 21:24:29,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:29,530 INFO:     Epoch: 7
2022-12-05 21:24:30,323 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.452657973901792, 'Total loss': 0.452657973901792} | train loss {'Reaction outcome loss': 0.34497198371254667, 'Total loss': 0.34497198371254667}
2022-12-05 21:24:30,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:30,323 INFO:     Epoch: 8
2022-12-05 21:24:31,110 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45739770240404387, 'Total loss': 0.45739770240404387} | train loss {'Reaction outcome loss': 0.33065686006935274, 'Total loss': 0.33065686006935274}
2022-12-05 21:24:31,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:31,110 INFO:     Epoch: 9
2022-12-05 21:24:31,907 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45089069652286445, 'Total loss': 0.45089069652286445} | train loss {'Reaction outcome loss': 0.31852711849674886, 'Total loss': 0.31852711849674886}
2022-12-05 21:24:31,907 INFO:     Found new best model at epoch 9
2022-12-05 21:24:31,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:31,908 INFO:     Epoch: 10
2022-12-05 21:24:32,697 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43350962786511943, 'Total loss': 0.43350962786511943} | train loss {'Reaction outcome loss': 0.30722818867284424, 'Total loss': 0.30722818867284424}
2022-12-05 21:24:32,698 INFO:     Found new best model at epoch 10
2022-12-05 21:24:32,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:32,699 INFO:     Epoch: 11
2022-12-05 21:24:33,488 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43289455805312504, 'Total loss': 0.43289455805312504} | train loss {'Reaction outcome loss': 0.2915173432656697, 'Total loss': 0.2915173432656697}
2022-12-05 21:24:33,488 INFO:     Found new best model at epoch 11
2022-12-05 21:24:33,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:33,489 INFO:     Epoch: 12
2022-12-05 21:24:34,280 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4406050257384777, 'Total loss': 0.4406050257384777} | train loss {'Reaction outcome loss': 0.28239039889707857, 'Total loss': 0.28239039889707857}
2022-12-05 21:24:34,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:34,281 INFO:     Epoch: 13
2022-12-05 21:24:35,071 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4446314668113535, 'Total loss': 0.4446314668113535} | train loss {'Reaction outcome loss': 0.2717641503531106, 'Total loss': 0.2717641503531106}
2022-12-05 21:24:35,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:35,072 INFO:     Epoch: 14
2022-12-05 21:24:35,862 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43508835695683956, 'Total loss': 0.43508835695683956} | train loss {'Reaction outcome loss': 0.26201363440070835, 'Total loss': 0.26201363440070835}
2022-12-05 21:24:35,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:35,862 INFO:     Epoch: 15
2022-12-05 21:24:36,655 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4475279352204366, 'Total loss': 0.4475279352204366} | train loss {'Reaction outcome loss': 0.2540853000112942, 'Total loss': 0.2540853000112942}
2022-12-05 21:24:36,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:36,655 INFO:     Epoch: 16
2022-12-05 21:24:37,448 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4272419786588712, 'Total loss': 0.4272419786588712} | train loss {'Reaction outcome loss': 0.24927115861554536, 'Total loss': 0.24927115861554536}
2022-12-05 21:24:37,449 INFO:     Found new best model at epoch 16
2022-12-05 21:24:37,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:37,450 INFO:     Epoch: 17
2022-12-05 21:24:38,242 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4367910334840417, 'Total loss': 0.4367910334840417} | train loss {'Reaction outcome loss': 0.23910061213739064, 'Total loss': 0.23910061213739064}
2022-12-05 21:24:38,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:38,242 INFO:     Epoch: 18
2022-12-05 21:24:39,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4449369649995457, 'Total loss': 0.4449369649995457} | train loss {'Reaction outcome loss': 0.23244894746006753, 'Total loss': 0.23244894746006753}
2022-12-05 21:24:39,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:39,035 INFO:     Epoch: 19
2022-12-05 21:24:39,825 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4651436084373431, 'Total loss': 0.4651436084373431} | train loss {'Reaction outcome loss': 0.22792228762896694, 'Total loss': 0.22792228762896694}
2022-12-05 21:24:39,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:39,826 INFO:     Epoch: 20
2022-12-05 21:24:40,613 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4454266930168325, 'Total loss': 0.4454266930168325} | train loss {'Reaction outcome loss': 0.22288771524113052, 'Total loss': 0.22288771524113052}
2022-12-05 21:24:40,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:40,614 INFO:     Epoch: 21
2022-12-05 21:24:41,401 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45937181873755023, 'Total loss': 0.45937181873755023} | train loss {'Reaction outcome loss': 0.21879515165881236, 'Total loss': 0.21879515165881236}
2022-12-05 21:24:41,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:41,401 INFO:     Epoch: 22
2022-12-05 21:24:42,189 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45980772884054616, 'Total loss': 0.45980772884054616} | train loss {'Reaction outcome loss': 0.2110612294123489, 'Total loss': 0.2110612294123489}
2022-12-05 21:24:42,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:42,189 INFO:     Epoch: 23
2022-12-05 21:24:42,975 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44538405059244146, 'Total loss': 0.44538405059244146} | train loss {'Reaction outcome loss': 0.20908426640897382, 'Total loss': 0.20908426640897382}
2022-12-05 21:24:42,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:42,975 INFO:     Epoch: 24
2022-12-05 21:24:43,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4572773159227588, 'Total loss': 0.4572773159227588} | train loss {'Reaction outcome loss': 0.20315065906972302, 'Total loss': 0.20315065906972302}
2022-12-05 21:24:43,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:43,763 INFO:     Epoch: 25
2022-12-05 21:24:44,552 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4603977237235416, 'Total loss': 0.4603977237235416} | train loss {'Reaction outcome loss': 0.202432966642842, 'Total loss': 0.202432966642842}
2022-12-05 21:24:44,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:44,552 INFO:     Epoch: 26
2022-12-05 21:24:45,344 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4567660946737636, 'Total loss': 0.4567660946737636} | train loss {'Reaction outcome loss': 0.19918914595428777, 'Total loss': 0.19918914595428777}
2022-12-05 21:24:45,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:45,344 INFO:     Epoch: 27
2022-12-05 21:24:46,130 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46151467107913713, 'Total loss': 0.46151467107913713} | train loss {'Reaction outcome loss': 0.1964908598332989, 'Total loss': 0.1964908598332989}
2022-12-05 21:24:46,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:46,131 INFO:     Epoch: 28
2022-12-05 21:24:46,921 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4596610926091671, 'Total loss': 0.4596610926091671} | train loss {'Reaction outcome loss': 0.18991619695206077, 'Total loss': 0.18991619695206077}
2022-12-05 21:24:46,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:46,921 INFO:     Epoch: 29
2022-12-05 21:24:47,708 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45100528543645685, 'Total loss': 0.45100528543645685} | train loss {'Reaction outcome loss': 0.1886618579376717, 'Total loss': 0.1886618579376717}
2022-12-05 21:24:47,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:47,708 INFO:     Epoch: 30
2022-12-05 21:24:48,498 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46129150028255855, 'Total loss': 0.46129150028255855} | train loss {'Reaction outcome loss': 0.18968101485955471, 'Total loss': 0.18968101485955471}
2022-12-05 21:24:48,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:48,499 INFO:     Epoch: 31
2022-12-05 21:24:49,284 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.458277281712402, 'Total loss': 0.458277281712402} | train loss {'Reaction outcome loss': 0.1853453445191286, 'Total loss': 0.1853453445191286}
2022-12-05 21:24:49,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:49,284 INFO:     Epoch: 32
2022-12-05 21:24:50,070 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46581327373331244, 'Total loss': 0.46581327373331244} | train loss {'Reaction outcome loss': 0.1803502500133247, 'Total loss': 0.1803502500133247}
2022-12-05 21:24:50,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:50,070 INFO:     Epoch: 33
2022-12-05 21:24:50,852 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4648289250379259, 'Total loss': 0.4648289250379259} | train loss {'Reaction outcome loss': 0.1790699122359558, 'Total loss': 0.1790699122359558}
2022-12-05 21:24:50,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:50,853 INFO:     Epoch: 34
2022-12-05 21:24:51,642 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45850276066498324, 'Total loss': 0.45850276066498324} | train loss {'Reaction outcome loss': 0.17439209870537933, 'Total loss': 0.17439209870537933}
2022-12-05 21:24:51,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:51,642 INFO:     Epoch: 35
2022-12-05 21:24:52,428 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4715681848200885, 'Total loss': 0.4715681848200885} | train loss {'Reaction outcome loss': 0.1744536210459714, 'Total loss': 0.1744536210459714}
2022-12-05 21:24:52,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:52,428 INFO:     Epoch: 36
2022-12-05 21:24:53,213 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4592333447865464, 'Total loss': 0.4592333447865464} | train loss {'Reaction outcome loss': 0.17160962917366807, 'Total loss': 0.17160962917366807}
2022-12-05 21:24:53,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:53,214 INFO:     Epoch: 37
2022-12-05 21:24:54,001 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4517917006530545, 'Total loss': 0.4517917006530545} | train loss {'Reaction outcome loss': 0.1703834617016267, 'Total loss': 0.1703834617016267}
2022-12-05 21:24:54,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:54,001 INFO:     Epoch: 38
2022-12-05 21:24:54,786 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4829682091420347, 'Total loss': 0.4829682091420347} | train loss {'Reaction outcome loss': 0.16734569341856606, 'Total loss': 0.16734569341856606}
2022-12-05 21:24:54,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:54,786 INFO:     Epoch: 39
2022-12-05 21:24:55,571 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4771602587266402, 'Total loss': 0.4771602587266402} | train loss {'Reaction outcome loss': 0.16595328473771104, 'Total loss': 0.16595328473771104}
2022-12-05 21:24:55,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:55,571 INFO:     Epoch: 40
2022-12-05 21:24:56,359 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4578859196467833, 'Total loss': 0.4578859196467833} | train loss {'Reaction outcome loss': 0.16471084801822292, 'Total loss': 0.16471084801822292}
2022-12-05 21:24:56,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:56,359 INFO:     Epoch: 41
2022-12-05 21:24:57,141 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4592954770407893, 'Total loss': 0.4592954770407893} | train loss {'Reaction outcome loss': 0.16388961137557517, 'Total loss': 0.16388961137557517}
2022-12-05 21:24:57,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:57,142 INFO:     Epoch: 42
2022-12-05 21:24:57,929 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47281190888448194, 'Total loss': 0.47281190888448194} | train loss {'Reaction outcome loss': 0.1636026113161019, 'Total loss': 0.1636026113161019}
2022-12-05 21:24:57,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:57,929 INFO:     Epoch: 43
2022-12-05 21:24:58,715 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.465929121456363, 'Total loss': 0.465929121456363} | train loss {'Reaction outcome loss': 0.15888274337868302, 'Total loss': 0.15888274337868302}
2022-12-05 21:24:58,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:58,715 INFO:     Epoch: 44
2022-12-05 21:24:59,500 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4932639832523736, 'Total loss': 0.4932639832523736} | train loss {'Reaction outcome loss': 0.15729460568756473, 'Total loss': 0.15729460568756473}
2022-12-05 21:24:59,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:24:59,500 INFO:     Epoch: 45
2022-12-05 21:25:00,283 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4482287215915593, 'Total loss': 0.4482287215915593} | train loss {'Reaction outcome loss': 0.15800808295607566, 'Total loss': 0.15800808295607566}
2022-12-05 21:25:00,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:00,284 INFO:     Epoch: 46
2022-12-05 21:25:01,070 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4785356264222752, 'Total loss': 0.4785356264222752} | train loss {'Reaction outcome loss': 0.15512754490637048, 'Total loss': 0.15512754490637048}
2022-12-05 21:25:01,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:01,070 INFO:     Epoch: 47
2022-12-05 21:25:01,853 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47161509367552673, 'Total loss': 0.47161509367552673} | train loss {'Reaction outcome loss': 0.15464019219638134, 'Total loss': 0.15464019219638134}
2022-12-05 21:25:01,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:01,853 INFO:     Epoch: 48
2022-12-05 21:25:02,637 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5001216845756228, 'Total loss': 0.5001216845756228} | train loss {'Reaction outcome loss': 0.1521540599970185, 'Total loss': 0.1521540599970185}
2022-12-05 21:25:02,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:02,637 INFO:     Epoch: 49
2022-12-05 21:25:03,423 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48178711194883694, 'Total loss': 0.48178711194883694} | train loss {'Reaction outcome loss': 0.14857899104149974, 'Total loss': 0.14857899104149974}
2022-12-05 21:25:03,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:03,423 INFO:     Epoch: 50
2022-12-05 21:25:04,210 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47527371177619154, 'Total loss': 0.47527371177619154} | train loss {'Reaction outcome loss': 0.14976788824614212, 'Total loss': 0.14976788824614212}
2022-12-05 21:25:04,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:04,210 INFO:     Epoch: 51
2022-12-05 21:25:05,005 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45857972727919166, 'Total loss': 0.45857972727919166} | train loss {'Reaction outcome loss': 0.15247819918226832, 'Total loss': 0.15247819918226832}
2022-12-05 21:25:05,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:05,005 INFO:     Epoch: 52
2022-12-05 21:25:05,793 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4733362672003833, 'Total loss': 0.4733362672003833} | train loss {'Reaction outcome loss': 0.14546613176258244, 'Total loss': 0.14546613176258244}
2022-12-05 21:25:05,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:05,793 INFO:     Epoch: 53
2022-12-05 21:25:06,580 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4771866631609472, 'Total loss': 0.4771866631609472} | train loss {'Reaction outcome loss': 0.1451680725858528, 'Total loss': 0.1451680725858528}
2022-12-05 21:25:06,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:06,580 INFO:     Epoch: 54
2022-12-05 21:25:07,364 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4704728035086935, 'Total loss': 0.4704728035086935} | train loss {'Reaction outcome loss': 0.1455618076786703, 'Total loss': 0.1455618076786703}
2022-12-05 21:25:07,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:07,365 INFO:     Epoch: 55
2022-12-05 21:25:08,149 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48520904034376144, 'Total loss': 0.48520904034376144} | train loss {'Reaction outcome loss': 0.1448865502046383, 'Total loss': 0.1448865502046383}
2022-12-05 21:25:08,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:08,150 INFO:     Epoch: 56
2022-12-05 21:25:08,938 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47619920325550164, 'Total loss': 0.47619920325550164} | train loss {'Reaction outcome loss': 0.14285531657538852, 'Total loss': 0.14285531657538852}
2022-12-05 21:25:08,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:08,939 INFO:     Epoch: 57
2022-12-05 21:25:09,726 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4914137504317544, 'Total loss': 0.4914137504317544} | train loss {'Reaction outcome loss': 0.14303888246911217, 'Total loss': 0.14303888246911217}
2022-12-05 21:25:09,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:09,727 INFO:     Epoch: 58
2022-12-05 21:25:10,522 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47202200002290984, 'Total loss': 0.47202200002290984} | train loss {'Reaction outcome loss': 0.14368997029199893, 'Total loss': 0.14368997029199893}
2022-12-05 21:25:10,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:10,522 INFO:     Epoch: 59
2022-12-05 21:25:11,310 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4774932021444494, 'Total loss': 0.4774932021444494} | train loss {'Reaction outcome loss': 0.1414350463343518, 'Total loss': 0.1414350463343518}
2022-12-05 21:25:11,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:11,311 INFO:     Epoch: 60
2022-12-05 21:25:12,101 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49738420749252493, 'Total loss': 0.49738420749252493} | train loss {'Reaction outcome loss': 0.14232934586399673, 'Total loss': 0.14232934586399673}
2022-12-05 21:25:12,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:12,102 INFO:     Epoch: 61
2022-12-05 21:25:12,891 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4870742799883539, 'Total loss': 0.4870742799883539} | train loss {'Reaction outcome loss': 0.14095519729414765, 'Total loss': 0.14095519729414765}
2022-12-05 21:25:12,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:12,892 INFO:     Epoch: 62
2022-12-05 21:25:13,690 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5014027028598569, 'Total loss': 0.5014027028598569} | train loss {'Reaction outcome loss': 0.13910469354263374, 'Total loss': 0.13910469354263374}
2022-12-05 21:25:13,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:13,690 INFO:     Epoch: 63
2022-12-05 21:25:14,483 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47231007528237323, 'Total loss': 0.47231007528237323} | train loss {'Reaction outcome loss': 0.13852049930363286, 'Total loss': 0.13852049930363286}
2022-12-05 21:25:14,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:14,484 INFO:     Epoch: 64
2022-12-05 21:25:15,273 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44463405808941886, 'Total loss': 0.44463405808941886} | train loss {'Reaction outcome loss': 0.13588221257134359, 'Total loss': 0.13588221257134359}
2022-12-05 21:25:15,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:15,273 INFO:     Epoch: 65
2022-12-05 21:25:16,061 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4666090137748556, 'Total loss': 0.4666090137748556} | train loss {'Reaction outcome loss': 0.1384672949128613, 'Total loss': 0.1384672949128613}
2022-12-05 21:25:16,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:16,061 INFO:     Epoch: 66
2022-12-05 21:25:16,853 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46940648403357377, 'Total loss': 0.46940648403357377} | train loss {'Reaction outcome loss': 0.13556373155086623, 'Total loss': 0.13556373155086623}
2022-12-05 21:25:16,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:16,853 INFO:     Epoch: 67
2022-12-05 21:25:17,642 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4939189333130013, 'Total loss': 0.4939189333130013} | train loss {'Reaction outcome loss': 0.13698526919648354, 'Total loss': 0.13698526919648354}
2022-12-05 21:25:17,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:17,643 INFO:     Epoch: 68
2022-12-05 21:25:18,433 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4750312522731044, 'Total loss': 0.4750312522731044} | train loss {'Reaction outcome loss': 0.13501815013587476, 'Total loss': 0.13501815013587476}
2022-12-05 21:25:18,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:18,433 INFO:     Epoch: 69
2022-12-05 21:25:19,226 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47858909280462697, 'Total loss': 0.47858909280462697} | train loss {'Reaction outcome loss': 0.13667488274525624, 'Total loss': 0.13667488274525624}
2022-12-05 21:25:19,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:19,227 INFO:     Epoch: 70
2022-12-05 21:25:20,014 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48178081993352284, 'Total loss': 0.48178081993352284} | train loss {'Reaction outcome loss': 0.13288531617394517, 'Total loss': 0.13288531617394517}
2022-12-05 21:25:20,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:20,014 INFO:     Epoch: 71
2022-12-05 21:25:20,801 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4753247211602601, 'Total loss': 0.4753247211602601} | train loss {'Reaction outcome loss': 0.13318972698203763, 'Total loss': 0.13318972698203763}
2022-12-05 21:25:20,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:20,801 INFO:     Epoch: 72
2022-12-05 21:25:21,590 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4659418055618351, 'Total loss': 0.4659418055618351} | train loss {'Reaction outcome loss': 0.13024050409392435, 'Total loss': 0.13024050409392435}
2022-12-05 21:25:21,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:21,590 INFO:     Epoch: 73
2022-12-05 21:25:22,378 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4763631265271794, 'Total loss': 0.4763631265271794} | train loss {'Reaction outcome loss': 0.1360008832903541, 'Total loss': 0.1360008832903541}
2022-12-05 21:25:22,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:22,378 INFO:     Epoch: 74
2022-12-05 21:25:23,167 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4699846850708127, 'Total loss': 0.4699846850708127} | train loss {'Reaction outcome loss': 0.13239256600108074, 'Total loss': 0.13239256600108074}
2022-12-05 21:25:23,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:23,167 INFO:     Epoch: 75
2022-12-05 21:25:23,954 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4842682524838231, 'Total loss': 0.4842682524838231} | train loss {'Reaction outcome loss': 0.13259189396488424, 'Total loss': 0.13259189396488424}
2022-12-05 21:25:23,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:23,954 INFO:     Epoch: 76
2022-12-05 21:25:24,741 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4617448394948786, 'Total loss': 0.4617448394948786} | train loss {'Reaction outcome loss': 0.13183615517099292, 'Total loss': 0.13183615517099292}
2022-12-05 21:25:24,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:24,741 INFO:     Epoch: 77
2022-12-05 21:25:25,529 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48964985290711577, 'Total loss': 0.48964985290711577} | train loss {'Reaction outcome loss': 0.1317667148475136, 'Total loss': 0.1317667148475136}
2022-12-05 21:25:25,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:25,529 INFO:     Epoch: 78
2022-12-05 21:25:26,317 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.514918946407058, 'Total loss': 0.514918946407058} | train loss {'Reaction outcome loss': 0.12904162525902596, 'Total loss': 0.12904162525902596}
2022-12-05 21:25:26,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:26,317 INFO:     Epoch: 79
2022-12-05 21:25:27,106 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4989510347897356, 'Total loss': 0.4989510347897356} | train loss {'Reaction outcome loss': 0.1285381931811571, 'Total loss': 0.1285381931811571}
2022-12-05 21:25:27,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:27,107 INFO:     Epoch: 80
2022-12-05 21:25:27,897 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47292190891775215, 'Total loss': 0.47292190891775215} | train loss {'Reaction outcome loss': 0.12965526013273973, 'Total loss': 0.12965526013273973}
2022-12-05 21:25:27,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:27,897 INFO:     Epoch: 81
2022-12-05 21:25:28,687 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4907358122820204, 'Total loss': 0.4907358122820204} | train loss {'Reaction outcome loss': 0.12998156295899227, 'Total loss': 0.12998156295899227}
2022-12-05 21:25:28,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:28,687 INFO:     Epoch: 82
2022-12-05 21:25:29,477 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4598261151801456, 'Total loss': 0.4598261151801456} | train loss {'Reaction outcome loss': 0.12924461178481578, 'Total loss': 0.12924461178481578}
2022-12-05 21:25:29,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:29,477 INFO:     Epoch: 83
2022-12-05 21:25:30,263 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4884860979562456, 'Total loss': 0.4884860979562456} | train loss {'Reaction outcome loss': 0.12680516490826801, 'Total loss': 0.12680516490826801}
2022-12-05 21:25:30,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:30,264 INFO:     Epoch: 84
2022-12-05 21:25:31,051 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48599848997863854, 'Total loss': 0.48599848997863854} | train loss {'Reaction outcome loss': 0.12754871599490242, 'Total loss': 0.12754871599490242}
2022-12-05 21:25:31,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:31,051 INFO:     Epoch: 85
2022-12-05 21:25:31,838 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49258095009083097, 'Total loss': 0.49258095009083097} | train loss {'Reaction outcome loss': 0.12868775501087004, 'Total loss': 0.12868775501087004}
2022-12-05 21:25:31,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:31,838 INFO:     Epoch: 86
2022-12-05 21:25:32,628 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5047174656594341, 'Total loss': 0.5047174656594341} | train loss {'Reaction outcome loss': 0.12473844640261056, 'Total loss': 0.12473844640261056}
2022-12-05 21:25:32,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:32,629 INFO:     Epoch: 87
2022-12-05 21:25:33,419 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5034110434353352, 'Total loss': 0.5034110434353352} | train loss {'Reaction outcome loss': 0.12488695791713438, 'Total loss': 0.12488695791713438}
2022-12-05 21:25:33,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:33,419 INFO:     Epoch: 88
2022-12-05 21:25:34,210 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49682046337561175, 'Total loss': 0.49682046337561175} | train loss {'Reaction outcome loss': 0.12677529903166757, 'Total loss': 0.12677529903166757}
2022-12-05 21:25:34,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:34,211 INFO:     Epoch: 89
2022-12-05 21:25:35,002 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5109775950285521, 'Total loss': 0.5109775950285521} | train loss {'Reaction outcome loss': 0.12803887746163778, 'Total loss': 0.12803887746163778}
2022-12-05 21:25:35,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:35,002 INFO:     Epoch: 90
2022-12-05 21:25:35,794 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4920459432019429, 'Total loss': 0.4920459432019429} | train loss {'Reaction outcome loss': 0.12386703713968092, 'Total loss': 0.12386703713968092}
2022-12-05 21:25:35,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:35,794 INFO:     Epoch: 91
2022-12-05 21:25:36,586 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.472568477588621, 'Total loss': 0.472568477588621} | train loss {'Reaction outcome loss': 0.12628614396921226, 'Total loss': 0.12628614396921226}
2022-12-05 21:25:36,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:36,586 INFO:     Epoch: 92
2022-12-05 21:25:37,378 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.509522124108943, 'Total loss': 0.509522124108943} | train loss {'Reaction outcome loss': 0.12642209718041883, 'Total loss': 0.12642209718041883}
2022-12-05 21:25:37,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:37,378 INFO:     Epoch: 93
2022-12-05 21:25:38,165 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47085141559893434, 'Total loss': 0.47085141559893434} | train loss {'Reaction outcome loss': 0.12515768165110933, 'Total loss': 0.12515768165110933}
2022-12-05 21:25:38,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:38,165 INFO:     Epoch: 94
2022-12-05 21:25:38,954 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4751084440133788, 'Total loss': 0.4751084440133788} | train loss {'Reaction outcome loss': 0.12194510455034217, 'Total loss': 0.12194510455034217}
2022-12-05 21:25:38,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:38,955 INFO:     Epoch: 95
2022-12-05 21:25:39,748 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.480904469774528, 'Total loss': 0.480904469774528} | train loss {'Reaction outcome loss': 0.12157133840290564, 'Total loss': 0.12157133840290564}
2022-12-05 21:25:39,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:39,748 INFO:     Epoch: 96
2022-12-05 21:25:40,548 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4904105907136744, 'Total loss': 0.4904105907136744} | train loss {'Reaction outcome loss': 0.1232546562404961, 'Total loss': 0.1232546562404961}
2022-12-05 21:25:40,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:40,548 INFO:     Epoch: 97
2022-12-05 21:25:41,346 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48321381312879647, 'Total loss': 0.48321381312879647} | train loss {'Reaction outcome loss': 0.12298240497784348, 'Total loss': 0.12298240497784348}
2022-12-05 21:25:41,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:41,346 INFO:     Epoch: 98
2022-12-05 21:25:42,144 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4892251356081529, 'Total loss': 0.4892251356081529} | train loss {'Reaction outcome loss': 0.12243290420013422, 'Total loss': 0.12243290420013422}
2022-12-05 21:25:42,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:42,144 INFO:     Epoch: 99
2022-12-05 21:25:42,946 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47217166830192914, 'Total loss': 0.47217166830192914} | train loss {'Reaction outcome loss': 0.12105415227005677, 'Total loss': 0.12105415227005677}
2022-12-05 21:25:42,946 INFO:     Best model found after epoch 17 of 100.
2022-12-05 21:25:42,946 INFO:   Done with stage: TRAINING
2022-12-05 21:25:42,947 INFO:   Starting stage: EVALUATION
2022-12-05 21:25:43,078 INFO:   Done with stage: EVALUATION
2022-12-05 21:25:43,078 INFO:   Leaving out SEQ value Fold_4
2022-12-05 21:25:43,090 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:25:43,090 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:25:43,751 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:25:43,751 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:25:43,821 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:25:43,822 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:25:43,822 INFO:     No hyperparam tuning for this model
2022-12-05 21:25:43,822 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:25:43,822 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:25:43,823 INFO:     None feature selector for col prot
2022-12-05 21:25:43,823 INFO:     None feature selector for col prot
2022-12-05 21:25:43,823 INFO:     None feature selector for col prot
2022-12-05 21:25:43,824 INFO:     None feature selector for col chem
2022-12-05 21:25:43,824 INFO:     None feature selector for col chem
2022-12-05 21:25:43,824 INFO:     None feature selector for col chem
2022-12-05 21:25:43,824 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:25:43,824 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:25:43,826 INFO:     Number of params in model 215821
2022-12-05 21:25:43,829 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:25:43,829 INFO:   Starting stage: TRAINING
2022-12-05 21:25:43,891 INFO:     Val loss before train {'Reaction outcome loss': 0.9595346274701032, 'Total loss': 0.9595346274701032}
2022-12-05 21:25:43,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:43,892 INFO:     Epoch: 0
2022-12-05 21:25:44,692 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5829235288229856, 'Total loss': 0.5829235288229856} | train loss {'Reaction outcome loss': 0.7872296972313391, 'Total loss': 0.7872296972313391}
2022-12-05 21:25:44,692 INFO:     Found new best model at epoch 0
2022-12-05 21:25:44,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:44,693 INFO:     Epoch: 1
2022-12-05 21:25:45,497 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49002664434638893, 'Total loss': 0.49002664434638893} | train loss {'Reaction outcome loss': 0.5314090518574965, 'Total loss': 0.5314090518574965}
2022-12-05 21:25:45,497 INFO:     Found new best model at epoch 1
2022-12-05 21:25:45,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:45,499 INFO:     Epoch: 2
2022-12-05 21:25:46,297 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4727546433833512, 'Total loss': 0.4727546433833512} | train loss {'Reaction outcome loss': 0.46247662344442203, 'Total loss': 0.46247662344442203}
2022-12-05 21:25:46,298 INFO:     Found new best model at epoch 2
2022-12-05 21:25:46,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:46,299 INFO:     Epoch: 3
2022-12-05 21:25:47,100 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45622844486074016, 'Total loss': 0.45622844486074016} | train loss {'Reaction outcome loss': 0.42514347469034464, 'Total loss': 0.42514347469034464}
2022-12-05 21:25:47,101 INFO:     Found new best model at epoch 3
2022-12-05 21:25:47,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:47,101 INFO:     Epoch: 4
2022-12-05 21:25:47,902 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.437697267329151, 'Total loss': 0.437697267329151} | train loss {'Reaction outcome loss': 0.3956495002817046, 'Total loss': 0.3956495002817046}
2022-12-05 21:25:47,902 INFO:     Found new best model at epoch 4
2022-12-05 21:25:47,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:47,903 INFO:     Epoch: 5
2022-12-05 21:25:48,702 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4336230964823203, 'Total loss': 0.4336230964823203} | train loss {'Reaction outcome loss': 0.3772259642962019, 'Total loss': 0.3772259642962019}
2022-12-05 21:25:48,702 INFO:     Found new best model at epoch 5
2022-12-05 21:25:48,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:48,703 INFO:     Epoch: 6
2022-12-05 21:25:49,504 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4171565205536105, 'Total loss': 0.4171565205536105} | train loss {'Reaction outcome loss': 0.3539964005894024, 'Total loss': 0.3539964005894024}
2022-12-05 21:25:49,504 INFO:     Found new best model at epoch 6
2022-12-05 21:25:49,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:49,505 INFO:     Epoch: 7
2022-12-05 21:25:50,304 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41823696429756557, 'Total loss': 0.41823696429756557} | train loss {'Reaction outcome loss': 0.3403607259696794, 'Total loss': 0.3403607259696794}
2022-12-05 21:25:50,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:50,304 INFO:     Epoch: 8
2022-12-05 21:25:51,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4089072407646613, 'Total loss': 0.4089072407646613} | train loss {'Reaction outcome loss': 0.32309116414080746, 'Total loss': 0.32309116414080746}
2022-12-05 21:25:51,105 INFO:     Found new best model at epoch 8
2022-12-05 21:25:51,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:51,105 INFO:     Epoch: 9
2022-12-05 21:25:51,905 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41000146994536574, 'Total loss': 0.41000146994536574} | train loss {'Reaction outcome loss': 0.3070589828527408, 'Total loss': 0.3070589828527408}
2022-12-05 21:25:51,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:51,906 INFO:     Epoch: 10
2022-12-05 21:25:52,709 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41241468624635175, 'Total loss': 0.41241468624635175} | train loss {'Reaction outcome loss': 0.2932374353411227, 'Total loss': 0.2932374353411227}
2022-12-05 21:25:52,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:52,709 INFO:     Epoch: 11
2022-12-05 21:25:53,516 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39655962654135446, 'Total loss': 0.39655962654135446} | train loss {'Reaction outcome loss': 0.2838291685409874, 'Total loss': 0.2838291685409874}
2022-12-05 21:25:53,516 INFO:     Found new best model at epoch 11
2022-12-05 21:25:53,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:53,517 INFO:     Epoch: 12
2022-12-05 21:25:54,314 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4053815488110889, 'Total loss': 0.4053815488110889} | train loss {'Reaction outcome loss': 0.2665350501188021, 'Total loss': 0.2665350501188021}
2022-12-05 21:25:54,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:54,314 INFO:     Epoch: 13
2022-12-05 21:25:55,118 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4053011666983366, 'Total loss': 0.4053011666983366} | train loss {'Reaction outcome loss': 0.2594952622363966, 'Total loss': 0.2594952622363966}
2022-12-05 21:25:55,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:55,118 INFO:     Epoch: 14
2022-12-05 21:25:55,917 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4099731926213611, 'Total loss': 0.4099731926213611} | train loss {'Reaction outcome loss': 0.2517874986838233, 'Total loss': 0.2517874986838233}
2022-12-05 21:25:55,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:55,918 INFO:     Epoch: 15
2022-12-05 21:25:56,714 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4100159945135767, 'Total loss': 0.4100159945135767} | train loss {'Reaction outcome loss': 0.2436084481265381, 'Total loss': 0.2436084481265381}
2022-12-05 21:25:56,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:56,714 INFO:     Epoch: 16
2022-12-05 21:25:57,514 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4124199158766053, 'Total loss': 0.4124199158766053} | train loss {'Reaction outcome loss': 0.23838159784312674, 'Total loss': 0.23838159784312674}
2022-12-05 21:25:57,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:57,515 INFO:     Epoch: 17
2022-12-05 21:25:58,313 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4068676527928222, 'Total loss': 0.4068676527928222} | train loss {'Reaction outcome loss': 0.22657950686268236, 'Total loss': 0.22657950686268236}
2022-12-05 21:25:58,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:58,314 INFO:     Epoch: 18
2022-12-05 21:25:59,108 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41888258572329173, 'Total loss': 0.41888258572329173} | train loss {'Reaction outcome loss': 0.2196002790349939, 'Total loss': 0.2196002790349939}
2022-12-05 21:25:59,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:59,108 INFO:     Epoch: 19
2022-12-05 21:25:59,904 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40450127151879395, 'Total loss': 0.40450127151879395} | train loss {'Reaction outcome loss': 0.2156069622514581, 'Total loss': 0.2156069622514581}
2022-12-05 21:25:59,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:25:59,904 INFO:     Epoch: 20
2022-12-05 21:26:00,696 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4095491346987811, 'Total loss': 0.4095491346987811} | train loss {'Reaction outcome loss': 0.20911474449527997, 'Total loss': 0.20911474449527997}
2022-12-05 21:26:00,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:00,696 INFO:     Epoch: 21
2022-12-05 21:26:01,492 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42974521490660583, 'Total loss': 0.42974521490660583} | train loss {'Reaction outcome loss': 0.20512302132391255, 'Total loss': 0.20512302132391255}
2022-12-05 21:26:01,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:01,493 INFO:     Epoch: 22
2022-12-05 21:26:02,282 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4211134639653293, 'Total loss': 0.4211134639653293} | train loss {'Reaction outcome loss': 0.20277943940237467, 'Total loss': 0.20277943940237467}
2022-12-05 21:26:02,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:02,283 INFO:     Epoch: 23
2022-12-05 21:26:03,073 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41789037361741066, 'Total loss': 0.41789037361741066} | train loss {'Reaction outcome loss': 0.19859287423281535, 'Total loss': 0.19859287423281535}
2022-12-05 21:26:03,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:03,073 INFO:     Epoch: 24
2022-12-05 21:26:03,864 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4420449703254483, 'Total loss': 0.4420449703254483} | train loss {'Reaction outcome loss': 0.19355159565553762, 'Total loss': 0.19355159565553762}
2022-12-05 21:26:03,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:03,865 INFO:     Epoch: 25
2022-12-05 21:26:04,659 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42184300551360304, 'Total loss': 0.42184300551360304} | train loss {'Reaction outcome loss': 0.19070454775487725, 'Total loss': 0.19070454775487725}
2022-12-05 21:26:04,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:04,659 INFO:     Epoch: 26
2022-12-05 21:26:05,450 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.421498449688608, 'Total loss': 0.421498449688608} | train loss {'Reaction outcome loss': 0.1852682805375049, 'Total loss': 0.1852682805375049}
2022-12-05 21:26:05,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:05,450 INFO:     Epoch: 27
2022-12-05 21:26:06,240 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4216578934680332, 'Total loss': 0.4216578934680332} | train loss {'Reaction outcome loss': 0.1822338799987486, 'Total loss': 0.1822338799987486}
2022-12-05 21:26:06,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:06,240 INFO:     Epoch: 28
2022-12-05 21:26:07,033 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4282367639243603, 'Total loss': 0.4282367639243603} | train loss {'Reaction outcome loss': 0.17890954930109051, 'Total loss': 0.17890954930109051}
2022-12-05 21:26:07,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:07,033 INFO:     Epoch: 29
2022-12-05 21:26:07,827 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4162441546266729, 'Total loss': 0.4162441546266729} | train loss {'Reaction outcome loss': 0.1766414655757095, 'Total loss': 0.1766414655757095}
2022-12-05 21:26:07,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:07,827 INFO:     Epoch: 30
2022-12-05 21:26:08,618 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4223484363068234, 'Total loss': 0.4223484363068234} | train loss {'Reaction outcome loss': 0.17688112445024826, 'Total loss': 0.17688112445024826}
2022-12-05 21:26:08,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:08,619 INFO:     Epoch: 31
2022-12-05 21:26:09,409 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4332317726855928, 'Total loss': 0.4332317726855928} | train loss {'Reaction outcome loss': 0.16902855919251739, 'Total loss': 0.16902855919251739}
2022-12-05 21:26:09,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:09,409 INFO:     Epoch: 32
2022-12-05 21:26:10,200 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43113037723709235, 'Total loss': 0.43113037723709235} | train loss {'Reaction outcome loss': 0.1693378630422267, 'Total loss': 0.1693378630422267}
2022-12-05 21:26:10,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:10,201 INFO:     Epoch: 33
2022-12-05 21:26:10,995 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4375262257050384, 'Total loss': 0.4375262257050384} | train loss {'Reaction outcome loss': 0.16773528492206383, 'Total loss': 0.16773528492206383}
2022-12-05 21:26:10,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:10,995 INFO:     Epoch: 34
2022-12-05 21:26:11,789 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44337507405064325, 'Total loss': 0.44337507405064325} | train loss {'Reaction outcome loss': 0.16852818203237857, 'Total loss': 0.16852818203237857}
2022-12-05 21:26:11,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:11,789 INFO:     Epoch: 35
2022-12-05 21:26:12,588 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4300547211684964, 'Total loss': 0.4300547211684964} | train loss {'Reaction outcome loss': 0.1668053618990458, 'Total loss': 0.1668053618990458}
2022-12-05 21:26:12,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:12,588 INFO:     Epoch: 36
2022-12-05 21:26:13,397 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42012524672529916, 'Total loss': 0.42012524672529916} | train loss {'Reaction outcome loss': 0.16053695932995934, 'Total loss': 0.16053695932995934}
2022-12-05 21:26:13,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:13,397 INFO:     Epoch: 37
2022-12-05 21:26:14,202 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4263606748797677, 'Total loss': 0.4263606748797677} | train loss {'Reaction outcome loss': 0.1553037358482787, 'Total loss': 0.1553037358482787}
2022-12-05 21:26:14,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:14,202 INFO:     Epoch: 38
2022-12-05 21:26:15,010 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43725638023831626, 'Total loss': 0.43725638023831626} | train loss {'Reaction outcome loss': 0.15522788895618336, 'Total loss': 0.15522788895618336}
2022-12-05 21:26:15,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:15,010 INFO:     Epoch: 39
2022-12-05 21:26:15,814 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4147613018073819, 'Total loss': 0.4147613018073819} | train loss {'Reaction outcome loss': 0.15032677841467051, 'Total loss': 0.15032677841467051}
2022-12-05 21:26:15,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:15,814 INFO:     Epoch: 40
2022-12-05 21:26:16,619 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43302689560435037, 'Total loss': 0.43302689560435037} | train loss {'Reaction outcome loss': 0.15193122736676049, 'Total loss': 0.15193122736676049}
2022-12-05 21:26:16,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:16,620 INFO:     Epoch: 41
2022-12-05 21:26:17,424 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4261854131790725, 'Total loss': 0.4261854131790725} | train loss {'Reaction outcome loss': 0.15160130788025405, 'Total loss': 0.15160130788025405}
2022-12-05 21:26:17,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:17,424 INFO:     Epoch: 42
2022-12-05 21:26:18,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4267402853478085, 'Total loss': 0.4267402853478085} | train loss {'Reaction outcome loss': 0.1485789620095057, 'Total loss': 0.1485789620095057}
2022-12-05 21:26:18,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:18,231 INFO:     Epoch: 43
2022-12-05 21:26:19,033 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43627050959251146, 'Total loss': 0.43627050959251146} | train loss {'Reaction outcome loss': 0.1497914043786796, 'Total loss': 0.1497914043786796}
2022-12-05 21:26:19,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:19,034 INFO:     Epoch: 44
2022-12-05 21:26:19,836 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4393588582223112, 'Total loss': 0.4393588582223112} | train loss {'Reaction outcome loss': 0.15454073248974043, 'Total loss': 0.15454073248974043}
2022-12-05 21:26:19,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:19,837 INFO:     Epoch: 45
2022-12-05 21:26:20,639 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4411335794085806, 'Total loss': 0.4411335794085806} | train loss {'Reaction outcome loss': 0.14568596672236558, 'Total loss': 0.14568596672236558}
2022-12-05 21:26:20,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:20,639 INFO:     Epoch: 46
2022-12-05 21:26:21,442 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4416341188956391, 'Total loss': 0.4416341188956391} | train loss {'Reaction outcome loss': 0.15083830942765541, 'Total loss': 0.15083830942765541}
2022-12-05 21:26:21,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:21,442 INFO:     Epoch: 47
2022-12-05 21:26:22,245 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43797217919067905, 'Total loss': 0.43797217919067905} | train loss {'Reaction outcome loss': 0.14238459015322136, 'Total loss': 0.14238459015322136}
2022-12-05 21:26:22,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:22,245 INFO:     Epoch: 48
2022-12-05 21:26:23,051 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4318734034895897, 'Total loss': 0.4318734034895897} | train loss {'Reaction outcome loss': 0.1412874849507046, 'Total loss': 0.1412874849507046}
2022-12-05 21:26:23,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:23,051 INFO:     Epoch: 49
2022-12-05 21:26:23,859 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4350287558680231, 'Total loss': 0.4350287558680231} | train loss {'Reaction outcome loss': 0.14079835968750043, 'Total loss': 0.14079835968750043}
2022-12-05 21:26:23,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:23,859 INFO:     Epoch: 50
2022-12-05 21:26:24,661 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4195002761076797, 'Total loss': 0.4195002761076797} | train loss {'Reaction outcome loss': 0.1414921550317724, 'Total loss': 0.1414921550317724}
2022-12-05 21:26:24,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:24,661 INFO:     Epoch: 51
2022-12-05 21:26:25,474 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44454047608781944, 'Total loss': 0.44454047608781944} | train loss {'Reaction outcome loss': 0.13930412841751522, 'Total loss': 0.13930412841751522}
2022-12-05 21:26:25,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:25,474 INFO:     Epoch: 52
2022-12-05 21:26:26,278 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4557873589748686, 'Total loss': 0.4557873589748686} | train loss {'Reaction outcome loss': 0.13893434114241407, 'Total loss': 0.13893434114241407}
2022-12-05 21:26:26,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:26,278 INFO:     Epoch: 53
2022-12-05 21:26:27,080 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4233445001935417, 'Total loss': 0.4233445001935417} | train loss {'Reaction outcome loss': 0.13662295002746677, 'Total loss': 0.13662295002746677}
2022-12-05 21:26:27,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:27,080 INFO:     Epoch: 54
2022-12-05 21:26:27,883 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4362997306002812, 'Total loss': 0.4362997306002812} | train loss {'Reaction outcome loss': 0.1364908922418409, 'Total loss': 0.1364908922418409}
2022-12-05 21:26:27,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:27,884 INFO:     Epoch: 55
2022-12-05 21:26:28,691 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4337372752753171, 'Total loss': 0.4337372752753171} | train loss {'Reaction outcome loss': 0.13578867165726205, 'Total loss': 0.13578867165726205}
2022-12-05 21:26:28,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:28,692 INFO:     Epoch: 56
2022-12-05 21:26:29,495 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4151360583914952, 'Total loss': 0.4151360583914952} | train loss {'Reaction outcome loss': 0.13516463670381892, 'Total loss': 0.13516463670381892}
2022-12-05 21:26:29,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:29,495 INFO:     Epoch: 57
2022-12-05 21:26:30,297 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44299421002241696, 'Total loss': 0.44299421002241696} | train loss {'Reaction outcome loss': 0.13390288199580874, 'Total loss': 0.13390288199580874}
2022-12-05 21:26:30,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:30,298 INFO:     Epoch: 58
2022-12-05 21:26:31,100 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42753593217242847, 'Total loss': 0.42753593217242847} | train loss {'Reaction outcome loss': 0.13604832675142087, 'Total loss': 0.13604832675142087}
2022-12-05 21:26:31,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:31,100 INFO:     Epoch: 59
2022-12-05 21:26:31,903 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4400213784114881, 'Total loss': 0.4400213784114881} | train loss {'Reaction outcome loss': 0.13036361033368388, 'Total loss': 0.13036361033368388}
2022-12-05 21:26:31,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:31,903 INFO:     Epoch: 60
2022-12-05 21:26:32,711 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44532718712633307, 'Total loss': 0.44532718712633307} | train loss {'Reaction outcome loss': 0.13047644329306327, 'Total loss': 0.13047644329306327}
2022-12-05 21:26:32,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:32,711 INFO:     Epoch: 61
2022-12-05 21:26:33,517 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45214328271421517, 'Total loss': 0.45214328271421517} | train loss {'Reaction outcome loss': 0.1321993987283364, 'Total loss': 0.1321993987283364}
2022-12-05 21:26:33,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:33,517 INFO:     Epoch: 62
2022-12-05 21:26:34,323 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43522984128106723, 'Total loss': 0.43522984128106723} | train loss {'Reaction outcome loss': 0.1309226296186025, 'Total loss': 0.1309226296186025}
2022-12-05 21:26:34,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:34,323 INFO:     Epoch: 63
2022-12-05 21:26:35,126 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.432651566172188, 'Total loss': 0.432651566172188} | train loss {'Reaction outcome loss': 0.12731630663549612, 'Total loss': 0.12731630663549612}
2022-12-05 21:26:35,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:35,126 INFO:     Epoch: 64
2022-12-05 21:26:35,931 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4511798830194907, 'Total loss': 0.4511798830194907} | train loss {'Reaction outcome loss': 0.1294395598203042, 'Total loss': 0.1294395598203042}
2022-12-05 21:26:35,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:35,931 INFO:     Epoch: 65
2022-12-05 21:26:36,734 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43694431470199063, 'Total loss': 0.43694431470199063} | train loss {'Reaction outcome loss': 0.12813942203004108, 'Total loss': 0.12813942203004108}
2022-12-05 21:26:36,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:36,734 INFO:     Epoch: 66
2022-12-05 21:26:37,537 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43392903256145393, 'Total loss': 0.43392903256145393} | train loss {'Reaction outcome loss': 0.13620790377681555, 'Total loss': 0.13620790377681555}
2022-12-05 21:26:37,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:37,538 INFO:     Epoch: 67
2022-12-05 21:26:38,341 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4362577467479489, 'Total loss': 0.4362577467479489} | train loss {'Reaction outcome loss': 0.1260760648982969, 'Total loss': 0.1260760648982969}
2022-12-05 21:26:38,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:38,341 INFO:     Epoch: 68
2022-12-05 21:26:39,148 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46028575555167417, 'Total loss': 0.46028575555167417} | train loss {'Reaction outcome loss': 0.12988514832865733, 'Total loss': 0.12988514832865733}
2022-12-05 21:26:39,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:39,148 INFO:     Epoch: 69
2022-12-05 21:26:39,956 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44140845096924086, 'Total loss': 0.44140845096924086} | train loss {'Reaction outcome loss': 0.1290016975819401, 'Total loss': 0.1290016975819401}
2022-12-05 21:26:39,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:39,956 INFO:     Epoch: 70
2022-12-05 21:26:40,762 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4472816606814211, 'Total loss': 0.4472816606814211} | train loss {'Reaction outcome loss': 0.12620704518753642, 'Total loss': 0.12620704518753642}
2022-12-05 21:26:40,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:40,762 INFO:     Epoch: 71
2022-12-05 21:26:41,567 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44027278724719177, 'Total loss': 0.44027278724719177} | train loss {'Reaction outcome loss': 0.1238189964302578, 'Total loss': 0.1238189964302578}
2022-12-05 21:26:41,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:41,568 INFO:     Epoch: 72
2022-12-05 21:26:42,372 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44410175728526985, 'Total loss': 0.44410175728526985} | train loss {'Reaction outcome loss': 0.12528165244320144, 'Total loss': 0.12528165244320144}
2022-12-05 21:26:42,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:42,372 INFO:     Epoch: 73
2022-12-05 21:26:43,177 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44028422846035525, 'Total loss': 0.44028422846035525} | train loss {'Reaction outcome loss': 0.13842416112405448, 'Total loss': 0.13842416112405448}
2022-12-05 21:26:43,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:43,178 INFO:     Epoch: 74
2022-12-05 21:26:43,984 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44986625151200726, 'Total loss': 0.44986625151200726} | train loss {'Reaction outcome loss': 0.12266922767768022, 'Total loss': 0.12266922767768022}
2022-12-05 21:26:43,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:43,984 INFO:     Epoch: 75
2022-12-05 21:26:44,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4503490728410808, 'Total loss': 0.4503490728410808} | train loss {'Reaction outcome loss': 0.12203864190305172, 'Total loss': 0.12203864190305172}
2022-12-05 21:26:44,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:44,789 INFO:     Epoch: 76
2022-12-05 21:26:45,591 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4327655871483413, 'Total loss': 0.4327655871483413} | train loss {'Reaction outcome loss': 0.1207140625015218, 'Total loss': 0.1207140625015218}
2022-12-05 21:26:45,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:45,592 INFO:     Epoch: 77
2022-12-05 21:26:46,396 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4454035454175689, 'Total loss': 0.4454035454175689} | train loss {'Reaction outcome loss': 0.12515701963622802, 'Total loss': 0.12515701963622802}
2022-12-05 21:26:46,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:46,396 INFO:     Epoch: 78
2022-12-05 21:26:47,203 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4687494970858097, 'Total loss': 0.4687494970858097} | train loss {'Reaction outcome loss': 0.1242016031555756, 'Total loss': 0.1242016031555756}
2022-12-05 21:26:47,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:47,204 INFO:     Epoch: 79
2022-12-05 21:26:48,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4432832801883871, 'Total loss': 0.4432832801883871} | train loss {'Reaction outcome loss': 0.12211517810629235, 'Total loss': 0.12211517810629235}
2022-12-05 21:26:48,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:48,013 INFO:     Epoch: 80
2022-12-05 21:26:48,816 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4361469710076397, 'Total loss': 0.4361469710076397} | train loss {'Reaction outcome loss': 0.12354933916919145, 'Total loss': 0.12354933916919145}
2022-12-05 21:26:48,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:48,817 INFO:     Epoch: 81
2022-12-05 21:26:49,621 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44067425246943126, 'Total loss': 0.44067425246943126} | train loss {'Reaction outcome loss': 0.12388828367764047, 'Total loss': 0.12388828367764047}
2022-12-05 21:26:49,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:49,621 INFO:     Epoch: 82
2022-12-05 21:26:50,425 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4424409517510371, 'Total loss': 0.4424409517510371} | train loss {'Reaction outcome loss': 0.11941613898865185, 'Total loss': 0.11941613898865185}
2022-12-05 21:26:50,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:50,425 INFO:     Epoch: 83
2022-12-05 21:26:51,235 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4554799503054131, 'Total loss': 0.4554799503054131} | train loss {'Reaction outcome loss': 0.12470482240020023, 'Total loss': 0.12470482240020023}
2022-12-05 21:26:51,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:51,235 INFO:     Epoch: 84
2022-12-05 21:26:52,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4595613899556073, 'Total loss': 0.4595613899556073} | train loss {'Reaction outcome loss': 0.12855969416920232, 'Total loss': 0.12855969416920232}
2022-12-05 21:26:52,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:52,042 INFO:     Epoch: 85
2022-12-05 21:26:52,849 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4501544728197835, 'Total loss': 0.4501544728197835} | train loss {'Reaction outcome loss': 0.11827353116592415, 'Total loss': 0.11827353116592415}
2022-12-05 21:26:52,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:52,849 INFO:     Epoch: 86
2022-12-05 21:26:53,655 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45303342322056944, 'Total loss': 0.45303342322056944} | train loss {'Reaction outcome loss': 0.12524468784299697, 'Total loss': 0.12524468784299697}
2022-12-05 21:26:53,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:53,655 INFO:     Epoch: 87
2022-12-05 21:26:54,461 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4482586346566677, 'Total loss': 0.4482586346566677} | train loss {'Reaction outcome loss': 0.11649071838073281, 'Total loss': 0.11649071838073281}
2022-12-05 21:26:54,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:54,462 INFO:     Epoch: 88
2022-12-05 21:26:55,267 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45437661033462395, 'Total loss': 0.45437661033462395} | train loss {'Reaction outcome loss': 0.11677556539610451, 'Total loss': 0.11677556539610451}
2022-12-05 21:26:55,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:55,267 INFO:     Epoch: 89
2022-12-05 21:26:56,070 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4410958950492469, 'Total loss': 0.4410958950492469} | train loss {'Reaction outcome loss': 0.1176594562851164, 'Total loss': 0.1176594562851164}
2022-12-05 21:26:56,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:56,070 INFO:     Epoch: 90
2022-12-05 21:26:56,872 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44906554506583646, 'Total loss': 0.44906554506583646} | train loss {'Reaction outcome loss': 0.1174080749890703, 'Total loss': 0.1174080749890703}
2022-12-05 21:26:56,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:56,873 INFO:     Epoch: 91
2022-12-05 21:26:57,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44202744926918636, 'Total loss': 0.44202744926918636} | train loss {'Reaction outcome loss': 0.11826270526116676, 'Total loss': 0.11826270526116676}
2022-12-05 21:26:57,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:57,675 INFO:     Epoch: 92
2022-12-05 21:26:58,478 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45272216404026205, 'Total loss': 0.45272216404026205} | train loss {'Reaction outcome loss': 0.11729808620776724, 'Total loss': 0.11729808620776724}
2022-12-05 21:26:58,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:58,479 INFO:     Epoch: 93
2022-12-05 21:26:59,281 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44709302247925237, 'Total loss': 0.44709302247925237} | train loss {'Reaction outcome loss': 0.11718008491558943, 'Total loss': 0.11718008491558943}
2022-12-05 21:26:59,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:26:59,282 INFO:     Epoch: 94
2022-12-05 21:27:00,090 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45204799503765325, 'Total loss': 0.45204799503765325} | train loss {'Reaction outcome loss': 0.11811507743621162, 'Total loss': 0.11811507743621162}
2022-12-05 21:27:00,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:00,091 INFO:     Epoch: 95
2022-12-05 21:27:00,897 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4469814441082152, 'Total loss': 0.4469814441082152} | train loss {'Reaction outcome loss': 0.11685046689351078, 'Total loss': 0.11685046689351078}
2022-12-05 21:27:00,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:00,898 INFO:     Epoch: 96
2022-12-05 21:27:01,703 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4652829969471151, 'Total loss': 0.4652829969471151} | train loss {'Reaction outcome loss': 0.11841314929529934, 'Total loss': 0.11841314929529934}
2022-12-05 21:27:01,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:01,703 INFO:     Epoch: 97
2022-12-05 21:27:02,507 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4607165716588497, 'Total loss': 0.4607165716588497} | train loss {'Reaction outcome loss': 0.11307484422233484, 'Total loss': 0.11307484422233484}
2022-12-05 21:27:02,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:02,507 INFO:     Epoch: 98
2022-12-05 21:27:03,311 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4522407637401061, 'Total loss': 0.4522407637401061} | train loss {'Reaction outcome loss': 0.11446035692943374, 'Total loss': 0.11446035692943374}
2022-12-05 21:27:03,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:03,312 INFO:     Epoch: 99
2022-12-05 21:27:04,117 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44802011718804186, 'Total loss': 0.44802011718804186} | train loss {'Reaction outcome loss': 0.1167324996866316, 'Total loss': 0.1167324996866316}
2022-12-05 21:27:04,117 INFO:     Best model found after epoch 12 of 100.
2022-12-05 21:27:04,117 INFO:   Done with stage: TRAINING
2022-12-05 21:27:04,117 INFO:   Starting stage: EVALUATION
2022-12-05 21:27:04,243 INFO:   Done with stage: EVALUATION
2022-12-05 21:27:04,243 INFO:   Leaving out SEQ value Fold_5
2022-12-05 21:27:04,255 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:27:04,256 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:27:04,900 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:27:04,900 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:27:04,970 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:27:04,970 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:27:04,970 INFO:     No hyperparam tuning for this model
2022-12-05 21:27:04,970 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:27:04,970 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:27:04,971 INFO:     None feature selector for col prot
2022-12-05 21:27:04,971 INFO:     None feature selector for col prot
2022-12-05 21:27:04,971 INFO:     None feature selector for col prot
2022-12-05 21:27:04,972 INFO:     None feature selector for col chem
2022-12-05 21:27:04,972 INFO:     None feature selector for col chem
2022-12-05 21:27:04,972 INFO:     None feature selector for col chem
2022-12-05 21:27:04,972 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:27:04,972 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:27:04,974 INFO:     Number of params in model 215821
2022-12-05 21:27:04,977 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:27:04,977 INFO:   Starting stage: TRAINING
2022-12-05 21:27:05,037 INFO:     Val loss before train {'Reaction outcome loss': 0.9712193472818895, 'Total loss': 0.9712193472818895}
2022-12-05 21:27:05,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:05,037 INFO:     Epoch: 0
2022-12-05 21:27:05,843 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6103452396663752, 'Total loss': 0.6103452396663752} | train loss {'Reaction outcome loss': 0.7935885788211899, 'Total loss': 0.7935885788211899}
2022-12-05 21:27:05,843 INFO:     Found new best model at epoch 0
2022-12-05 21:27:05,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:05,844 INFO:     Epoch: 1
2022-12-05 21:27:06,652 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5239748372273012, 'Total loss': 0.5239748372273012} | train loss {'Reaction outcome loss': 0.5470479444390343, 'Total loss': 0.5470479444390343}
2022-12-05 21:27:06,652 INFO:     Found new best model at epoch 1
2022-12-05 21:27:06,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:06,653 INFO:     Epoch: 2
2022-12-05 21:27:07,461 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49396066536957567, 'Total loss': 0.49396066536957567} | train loss {'Reaction outcome loss': 0.47422836384465616, 'Total loss': 0.47422836384465616}
2022-12-05 21:27:07,461 INFO:     Found new best model at epoch 2
2022-12-05 21:27:07,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:07,462 INFO:     Epoch: 3
2022-12-05 21:27:08,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4717486680231311, 'Total loss': 0.4717486680231311} | train loss {'Reaction outcome loss': 0.43075942951104335, 'Total loss': 0.43075942951104335}
2022-12-05 21:27:08,270 INFO:     Found new best model at epoch 3
2022-12-05 21:27:08,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:08,271 INFO:     Epoch: 4
2022-12-05 21:27:09,083 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4628909192979336, 'Total loss': 0.4628909192979336} | train loss {'Reaction outcome loss': 0.40188582614064217, 'Total loss': 0.40188582614064217}
2022-12-05 21:27:09,083 INFO:     Found new best model at epoch 4
2022-12-05 21:27:09,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:09,084 INFO:     Epoch: 5
2022-12-05 21:27:09,892 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4483025283976035, 'Total loss': 0.4483025283976035} | train loss {'Reaction outcome loss': 0.3784369743399082, 'Total loss': 0.3784369743399082}
2022-12-05 21:27:09,892 INFO:     Found new best model at epoch 5
2022-12-05 21:27:09,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:09,893 INFO:     Epoch: 6
2022-12-05 21:27:10,704 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4457855468446558, 'Total loss': 0.4457855468446558} | train loss {'Reaction outcome loss': 0.35760285434944017, 'Total loss': 0.35760285434944017}
2022-12-05 21:27:10,704 INFO:     Found new best model at epoch 6
2022-12-05 21:27:10,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:10,705 INFO:     Epoch: 7
2022-12-05 21:27:11,513 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44378710368817503, 'Total loss': 0.44378710368817503} | train loss {'Reaction outcome loss': 0.34203800288659914, 'Total loss': 0.34203800288659914}
2022-12-05 21:27:11,513 INFO:     Found new best model at epoch 7
2022-12-05 21:27:11,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:11,514 INFO:     Epoch: 8
2022-12-05 21:27:12,326 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.432856523855166, 'Total loss': 0.432856523855166} | train loss {'Reaction outcome loss': 0.3248403851063021, 'Total loss': 0.3248403851063021}
2022-12-05 21:27:12,327 INFO:     Found new best model at epoch 8
2022-12-05 21:27:12,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:12,328 INFO:     Epoch: 9
2022-12-05 21:27:13,136 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4416977817362005, 'Total loss': 0.4416977817362005} | train loss {'Reaction outcome loss': 0.31059319628102167, 'Total loss': 0.31059319628102167}
2022-12-05 21:27:13,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:13,136 INFO:     Epoch: 10
2022-12-05 21:27:13,946 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43426525457338855, 'Total loss': 0.43426525457338855} | train loss {'Reaction outcome loss': 0.30229102141193803, 'Total loss': 0.30229102141193803}
2022-12-05 21:27:13,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:13,947 INFO:     Epoch: 11
2022-12-05 21:27:14,761 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43057921257886017, 'Total loss': 0.43057921257886017} | train loss {'Reaction outcome loss': 0.29055720567703247, 'Total loss': 0.29055720567703247}
2022-12-05 21:27:14,761 INFO:     Found new best model at epoch 11
2022-12-05 21:27:14,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:14,762 INFO:     Epoch: 12
2022-12-05 21:27:15,574 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43212883885611186, 'Total loss': 0.43212883885611186} | train loss {'Reaction outcome loss': 0.28295221266847465, 'Total loss': 0.28295221266847465}
2022-12-05 21:27:15,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:15,574 INFO:     Epoch: 13
2022-12-05 21:27:16,381 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43636091764677654, 'Total loss': 0.43636091764677654} | train loss {'Reaction outcome loss': 0.27197145063790584, 'Total loss': 0.27197145063790584}
2022-12-05 21:27:16,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:16,381 INFO:     Epoch: 14
2022-12-05 21:27:17,172 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43170042031190614, 'Total loss': 0.43170042031190614} | train loss {'Reaction outcome loss': 0.266235732924073, 'Total loss': 0.266235732924073}
2022-12-05 21:27:17,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:17,172 INFO:     Epoch: 15
2022-12-05 21:27:17,963 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4398634780875661, 'Total loss': 0.4398634780875661} | train loss {'Reaction outcome loss': 0.2555549297962458, 'Total loss': 0.2555549297962458}
2022-12-05 21:27:17,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:17,963 INFO:     Epoch: 16
2022-12-05 21:27:18,762 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43140252713452687, 'Total loss': 0.43140252713452687} | train loss {'Reaction outcome loss': 0.249297050428727, 'Total loss': 0.249297050428727}
2022-12-05 21:27:18,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:18,763 INFO:     Epoch: 17
2022-12-05 21:27:19,557 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4399381550875577, 'Total loss': 0.4399381550875577} | train loss {'Reaction outcome loss': 0.24184280198307767, 'Total loss': 0.24184280198307767}
2022-12-05 21:27:19,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:19,558 INFO:     Epoch: 18
2022-12-05 21:27:20,349 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42363244769248093, 'Total loss': 0.42363244769248093} | train loss {'Reaction outcome loss': 0.23855460693518962, 'Total loss': 0.23855460693518962}
2022-12-05 21:27:20,349 INFO:     Found new best model at epoch 18
2022-12-05 21:27:20,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:20,350 INFO:     Epoch: 19
2022-12-05 21:27:21,141 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42899796315892175, 'Total loss': 0.42899796315892175} | train loss {'Reaction outcome loss': 0.2326701966925494, 'Total loss': 0.2326701966925494}
2022-12-05 21:27:21,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:21,141 INFO:     Epoch: 20
2022-12-05 21:27:21,932 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43006173165684397, 'Total loss': 0.43006173165684397} | train loss {'Reaction outcome loss': 0.2275682346174313, 'Total loss': 0.2275682346174313}
2022-12-05 21:27:21,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:21,932 INFO:     Epoch: 21
2022-12-05 21:27:22,726 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4413866498930888, 'Total loss': 0.4413866498930888} | train loss {'Reaction outcome loss': 0.22162073536685878, 'Total loss': 0.22162073536685878}
2022-12-05 21:27:22,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:22,727 INFO:     Epoch: 22
2022-12-05 21:27:23,522 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43271716379306535, 'Total loss': 0.43271716379306535} | train loss {'Reaction outcome loss': 0.21881493721758166, 'Total loss': 0.21881493721758166}
2022-12-05 21:27:23,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:23,522 INFO:     Epoch: 23
2022-12-05 21:27:24,312 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42202307165346364, 'Total loss': 0.42202307165346364} | train loss {'Reaction outcome loss': 0.21260298542197673, 'Total loss': 0.21260298542197673}
2022-12-05 21:27:24,312 INFO:     Found new best model at epoch 23
2022-12-05 21:27:24,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:24,313 INFO:     Epoch: 24
2022-12-05 21:27:25,110 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42900205437432637, 'Total loss': 0.42900205437432637} | train loss {'Reaction outcome loss': 0.20796404316300346, 'Total loss': 0.20796404316300346}
2022-12-05 21:27:25,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:25,110 INFO:     Epoch: 25
2022-12-05 21:27:25,908 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43809378384189174, 'Total loss': 0.43809378384189174} | train loss {'Reaction outcome loss': 0.20581981267840152, 'Total loss': 0.20581981267840152}
2022-12-05 21:27:25,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:25,908 INFO:     Epoch: 26
2022-12-05 21:27:26,709 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43963379887017334, 'Total loss': 0.43963379887017334} | train loss {'Reaction outcome loss': 0.19887170679266414, 'Total loss': 0.19887170679266414}
2022-12-05 21:27:26,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:26,709 INFO:     Epoch: 27
2022-12-05 21:27:27,500 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44777680425481364, 'Total loss': 0.44777680425481364} | train loss {'Reaction outcome loss': 0.19466840142324085, 'Total loss': 0.19466840142324085}
2022-12-05 21:27:27,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:27,501 INFO:     Epoch: 28
2022-12-05 21:27:28,295 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4403484622863206, 'Total loss': 0.4403484622863206} | train loss {'Reaction outcome loss': 0.19478165697787078, 'Total loss': 0.19478165697787078}
2022-12-05 21:27:28,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:28,295 INFO:     Epoch: 29
2022-12-05 21:27:29,090 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4398581747981635, 'Total loss': 0.4398581747981635} | train loss {'Reaction outcome loss': 0.18887567224221363, 'Total loss': 0.18887567224221363}
2022-12-05 21:27:29,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:29,090 INFO:     Epoch: 30
2022-12-05 21:27:29,881 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43656165728514845, 'Total loss': 0.43656165728514845} | train loss {'Reaction outcome loss': 0.18517177973333146, 'Total loss': 0.18517177973333146}
2022-12-05 21:27:29,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:29,881 INFO:     Epoch: 31
2022-12-05 21:27:30,680 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4424843452870846, 'Total loss': 0.4424843452870846} | train loss {'Reaction outcome loss': 0.18260977600490855, 'Total loss': 0.18260977600490855}
2022-12-05 21:27:30,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:30,680 INFO:     Epoch: 32
2022-12-05 21:27:31,482 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4385652958669446, 'Total loss': 0.4385652958669446} | train loss {'Reaction outcome loss': 0.1800214334826676, 'Total loss': 0.1800214334826676}
2022-12-05 21:27:31,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:31,483 INFO:     Epoch: 33
2022-12-05 21:27:32,274 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43826535530388355, 'Total loss': 0.43826535530388355} | train loss {'Reaction outcome loss': 0.17876284460597222, 'Total loss': 0.17876284460597222}
2022-12-05 21:27:32,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:32,274 INFO:     Epoch: 34
2022-12-05 21:27:33,066 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4476021226834167, 'Total loss': 0.4476021226834167} | train loss {'Reaction outcome loss': 0.1721526320813404, 'Total loss': 0.1721526320813404}
2022-12-05 21:27:33,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:33,066 INFO:     Epoch: 35
2022-12-05 21:27:33,856 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43409813330932095, 'Total loss': 0.43409813330932095} | train loss {'Reaction outcome loss': 0.17425154356826697, 'Total loss': 0.17425154356826697}
2022-12-05 21:27:33,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:33,856 INFO:     Epoch: 36
2022-12-05 21:27:34,648 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4314340894872492, 'Total loss': 0.4314340894872492} | train loss {'Reaction outcome loss': 0.17210888386433643, 'Total loss': 0.17210888386433643}
2022-12-05 21:27:34,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:34,648 INFO:     Epoch: 37
2022-12-05 21:27:35,442 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43186310289258306, 'Total loss': 0.43186310289258306} | train loss {'Reaction outcome loss': 0.1702800857789454, 'Total loss': 0.1702800857789454}
2022-12-05 21:27:35,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:35,443 INFO:     Epoch: 38
2022-12-05 21:27:36,233 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4377625970677896, 'Total loss': 0.4377625970677896} | train loss {'Reaction outcome loss': 0.1640965092491599, 'Total loss': 0.1640965092491599}
2022-12-05 21:27:36,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:36,233 INFO:     Epoch: 39
2022-12-05 21:27:37,028 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4335062432695519, 'Total loss': 0.4335062432695519} | train loss {'Reaction outcome loss': 0.16391023700576154, 'Total loss': 0.16391023700576154}
2022-12-05 21:27:37,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:37,028 INFO:     Epoch: 40
2022-12-05 21:27:37,822 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4423402012749152, 'Total loss': 0.4423402012749152} | train loss {'Reaction outcome loss': 0.16091510104466109, 'Total loss': 0.16091510104466109}
2022-12-05 21:27:37,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:37,822 INFO:     Epoch: 41
2022-12-05 21:27:38,622 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4387689530849457, 'Total loss': 0.4387689530849457} | train loss {'Reaction outcome loss': 0.161222864633366, 'Total loss': 0.161222864633366}
2022-12-05 21:27:38,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:38,622 INFO:     Epoch: 42
2022-12-05 21:27:39,425 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4428228617391803, 'Total loss': 0.4428228617391803} | train loss {'Reaction outcome loss': 0.15774867796309053, 'Total loss': 0.15774867796309053}
2022-12-05 21:27:39,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:39,425 INFO:     Epoch: 43
2022-12-05 21:27:40,220 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43448005176403304, 'Total loss': 0.43448005176403304} | train loss {'Reaction outcome loss': 0.15543970122422662, 'Total loss': 0.15543970122422662}
2022-12-05 21:27:40,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:40,220 INFO:     Epoch: 44
2022-12-05 21:27:41,019 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4466715587133711, 'Total loss': 0.4466715587133711} | train loss {'Reaction outcome loss': 0.15455500364694144, 'Total loss': 0.15455500364694144}
2022-12-05 21:27:41,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:41,019 INFO:     Epoch: 45
2022-12-05 21:27:41,813 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4420003308491273, 'Total loss': 0.4420003308491273} | train loss {'Reaction outcome loss': 0.15279741279570566, 'Total loss': 0.15279741279570566}
2022-12-05 21:27:41,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:41,813 INFO:     Epoch: 46
2022-12-05 21:27:42,606 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44174342873421585, 'Total loss': 0.44174342873421585} | train loss {'Reaction outcome loss': 0.15401690086770442, 'Total loss': 0.15401690086770442}
2022-12-05 21:27:42,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:42,606 INFO:     Epoch: 47
2022-12-05 21:27:43,399 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44804029776291415, 'Total loss': 0.44804029776291415} | train loss {'Reaction outcome loss': 0.15113757154904306, 'Total loss': 0.15113757154904306}
2022-12-05 21:27:43,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:43,399 INFO:     Epoch: 48
2022-12-05 21:27:44,191 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4461690959605304, 'Total loss': 0.4461690959605304} | train loss {'Reaction outcome loss': 0.14811515777311737, 'Total loss': 0.14811515777311737}
2022-12-05 21:27:44,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:44,192 INFO:     Epoch: 49
2022-12-05 21:27:44,986 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4306869252838872, 'Total loss': 0.4306869252838872} | train loss {'Reaction outcome loss': 0.14961858101249223, 'Total loss': 0.14961858101249223}
2022-12-05 21:27:44,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:44,986 INFO:     Epoch: 50
2022-12-05 21:27:45,779 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4550622616979209, 'Total loss': 0.4550622616979209} | train loss {'Reaction outcome loss': 0.14702945642714058, 'Total loss': 0.14702945642714058}
2022-12-05 21:27:45,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:45,779 INFO:     Epoch: 51
2022-12-05 21:27:46,576 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44488230804828083, 'Total loss': 0.44488230804828083} | train loss {'Reaction outcome loss': 0.14774707972162193, 'Total loss': 0.14774707972162193}
2022-12-05 21:27:46,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:46,577 INFO:     Epoch: 52
2022-12-05 21:27:47,371 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44804515689611435, 'Total loss': 0.44804515689611435} | train loss {'Reaction outcome loss': 0.14341226517177758, 'Total loss': 0.14341226517177758}
2022-12-05 21:27:47,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:47,371 INFO:     Epoch: 53
2022-12-05 21:27:48,167 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4453265704214573, 'Total loss': 0.4453265704214573} | train loss {'Reaction outcome loss': 0.14521416428784328, 'Total loss': 0.14521416428784328}
2022-12-05 21:27:48,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:48,167 INFO:     Epoch: 54
2022-12-05 21:27:48,969 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4627284031700004, 'Total loss': 0.4627284031700004} | train loss {'Reaction outcome loss': 0.1407646441291417, 'Total loss': 0.1407646441291417}
2022-12-05 21:27:48,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:48,970 INFO:     Epoch: 55
2022-12-05 21:27:49,765 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4402149035172029, 'Total loss': 0.4402149035172029} | train loss {'Reaction outcome loss': 0.1412746797526075, 'Total loss': 0.1412746797526075}
2022-12-05 21:27:49,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:49,765 INFO:     Epoch: 56
2022-12-05 21:27:50,565 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45160725577311084, 'Total loss': 0.45160725577311084} | train loss {'Reaction outcome loss': 0.13943999067639873, 'Total loss': 0.13943999067639873}
2022-12-05 21:27:50,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:50,566 INFO:     Epoch: 57
2022-12-05 21:27:51,358 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44917299530722876, 'Total loss': 0.44917299530722876} | train loss {'Reaction outcome loss': 0.1393495387164876, 'Total loss': 0.1393495387164876}
2022-12-05 21:27:51,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:51,358 INFO:     Epoch: 58
2022-12-05 21:27:52,149 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4555198936299844, 'Total loss': 0.4555198936299844} | train loss {'Reaction outcome loss': 0.13676499589271243, 'Total loss': 0.13676499589271243}
2022-12-05 21:27:52,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:52,150 INFO:     Epoch: 59
2022-12-05 21:27:52,943 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4635680920698426, 'Total loss': 0.4635680920698426} | train loss {'Reaction outcome loss': 0.13730237810992665, 'Total loss': 0.13730237810992665}
2022-12-05 21:27:52,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:52,943 INFO:     Epoch: 60
2022-12-05 21:27:53,737 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45541503551331436, 'Total loss': 0.45541503551331436} | train loss {'Reaction outcome loss': 0.13597987831810548, 'Total loss': 0.13597987831810548}
2022-12-05 21:27:53,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:53,738 INFO:     Epoch: 61
2022-12-05 21:27:54,529 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4436093448576602, 'Total loss': 0.4436093448576602} | train loss {'Reaction outcome loss': 0.13539766041081278, 'Total loss': 0.13539766041081278}
2022-12-05 21:27:54,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:54,529 INFO:     Epoch: 62
2022-12-05 21:27:55,322 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44807139479301195, 'Total loss': 0.44807139479301195} | train loss {'Reaction outcome loss': 0.1352688570191423, 'Total loss': 0.1352688570191423}
2022-12-05 21:27:55,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:55,322 INFO:     Epoch: 63
2022-12-05 21:27:56,116 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4485070214352824, 'Total loss': 0.4485070214352824} | train loss {'Reaction outcome loss': 0.1360624741552578, 'Total loss': 0.1360624741552578}
2022-12-05 21:27:56,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:56,116 INFO:     Epoch: 64
2022-12-05 21:27:56,910 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4480216469277035, 'Total loss': 0.4480216469277035} | train loss {'Reaction outcome loss': 0.1342403136809627, 'Total loss': 0.1342403136809627}
2022-12-05 21:27:56,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:56,910 INFO:     Epoch: 65
2022-12-05 21:27:57,703 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4507736550136046, 'Total loss': 0.4507736550136046} | train loss {'Reaction outcome loss': 0.13269533302199335, 'Total loss': 0.13269533302199335}
2022-12-05 21:27:57,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:57,703 INFO:     Epoch: 66
2022-12-05 21:27:58,493 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45286293056878174, 'Total loss': 0.45286293056878174} | train loss {'Reaction outcome loss': 0.13199070559424017, 'Total loss': 0.13199070559424017}
2022-12-05 21:27:58,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:58,493 INFO:     Epoch: 67
2022-12-05 21:27:59,288 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4522087052464485, 'Total loss': 0.4522087052464485} | train loss {'Reaction outcome loss': 0.131904351731552, 'Total loss': 0.131904351731552}
2022-12-05 21:27:59,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:27:59,288 INFO:     Epoch: 68
2022-12-05 21:28:00,085 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45458916744047945, 'Total loss': 0.45458916744047945} | train loss {'Reaction outcome loss': 0.13401771595911874, 'Total loss': 0.13401771595911874}
2022-12-05 21:28:00,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:00,085 INFO:     Epoch: 69
2022-12-05 21:28:00,879 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4542405446144668, 'Total loss': 0.4542405446144668} | train loss {'Reaction outcome loss': 0.12770873546645406, 'Total loss': 0.12770873546645406}
2022-12-05 21:28:00,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:00,880 INFO:     Epoch: 70
2022-12-05 21:28:01,675 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4521131268279119, 'Total loss': 0.4521131268279119} | train loss {'Reaction outcome loss': 0.12836067320688838, 'Total loss': 0.12836067320688838}
2022-12-05 21:28:01,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:01,675 INFO:     Epoch: 71
2022-12-05 21:28:02,473 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4487115971066735, 'Total loss': 0.4487115971066735} | train loss {'Reaction outcome loss': 0.12969480244623077, 'Total loss': 0.12969480244623077}
2022-12-05 21:28:02,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:02,473 INFO:     Epoch: 72
2022-12-05 21:28:03,274 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45118553123690863, 'Total loss': 0.45118553123690863} | train loss {'Reaction outcome loss': 0.1328637586012783, 'Total loss': 0.1328637586012783}
2022-12-05 21:28:03,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:03,274 INFO:     Epoch: 73
2022-12-05 21:28:04,070 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44806351885199547, 'Total loss': 0.44806351885199547} | train loss {'Reaction outcome loss': 0.12655121397842922, 'Total loss': 0.12655121397842922}
2022-12-05 21:28:04,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:04,070 INFO:     Epoch: 74
2022-12-05 21:28:04,865 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45552705312994396, 'Total loss': 0.45552705312994396} | train loss {'Reaction outcome loss': 0.12647003745059332, 'Total loss': 0.12647003745059332}
2022-12-05 21:28:04,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:04,865 INFO:     Epoch: 75
2022-12-05 21:28:05,662 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45582356642593036, 'Total loss': 0.45582356642593036} | train loss {'Reaction outcome loss': 0.12785759708663869, 'Total loss': 0.12785759708663869}
2022-12-05 21:28:05,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:05,662 INFO:     Epoch: 76
2022-12-05 21:28:06,453 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44389975765212014, 'Total loss': 0.44389975765212014} | train loss {'Reaction outcome loss': 0.1248150540838739, 'Total loss': 0.1248150540838739}
2022-12-05 21:28:06,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:06,454 INFO:     Epoch: 77
2022-12-05 21:28:07,246 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4487655152651397, 'Total loss': 0.4487655152651397} | train loss {'Reaction outcome loss': 0.1246706718098252, 'Total loss': 0.1246706718098252}
2022-12-05 21:28:07,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:07,246 INFO:     Epoch: 78
2022-12-05 21:28:08,041 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4459718902680007, 'Total loss': 0.4459718902680007} | train loss {'Reaction outcome loss': 0.12561363397887157, 'Total loss': 0.12561363397887157}
2022-12-05 21:28:08,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:08,041 INFO:     Epoch: 79
2022-12-05 21:28:08,835 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43900152668356895, 'Total loss': 0.43900152668356895} | train loss {'Reaction outcome loss': 0.1240349269487084, 'Total loss': 0.1240349269487084}
2022-12-05 21:28:08,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:08,835 INFO:     Epoch: 80
2022-12-05 21:28:09,634 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45420399105007, 'Total loss': 0.45420399105007} | train loss {'Reaction outcome loss': 0.12584693707345473, 'Total loss': 0.12584693707345473}
2022-12-05 21:28:09,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:09,634 INFO:     Epoch: 81
2022-12-05 21:28:10,426 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43379958397285506, 'Total loss': 0.43379958397285506} | train loss {'Reaction outcome loss': 0.12263461625233534, 'Total loss': 0.12263461625233534}
2022-12-05 21:28:10,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:10,426 INFO:     Epoch: 82
2022-12-05 21:28:11,219 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44613767449151387, 'Total loss': 0.44613767449151387} | train loss {'Reaction outcome loss': 0.12577053152152426, 'Total loss': 0.12577053152152426}
2022-12-05 21:28:11,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:11,219 INFO:     Epoch: 83
2022-12-05 21:28:12,017 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44529529830271547, 'Total loss': 0.44529529830271547} | train loss {'Reaction outcome loss': 0.1230809489159935, 'Total loss': 0.1230809489159935}
2022-12-05 21:28:12,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:12,017 INFO:     Epoch: 84
2022-12-05 21:28:12,809 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45042371038686146, 'Total loss': 0.45042371038686146} | train loss {'Reaction outcome loss': 0.12198464109397103, 'Total loss': 0.12198464109397103}
2022-12-05 21:28:12,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:12,810 INFO:     Epoch: 85
2022-12-05 21:28:13,604 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47250715033574536, 'Total loss': 0.47250715033574536} | train loss {'Reaction outcome loss': 0.12496816065357698, 'Total loss': 0.12496816065357698}
2022-12-05 21:28:13,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:13,605 INFO:     Epoch: 86
2022-12-05 21:28:14,400 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.438629737123847, 'Total loss': 0.438629737123847} | train loss {'Reaction outcome loss': 0.12290725363944206, 'Total loss': 0.12290725363944206}
2022-12-05 21:28:14,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:14,401 INFO:     Epoch: 87
2022-12-05 21:28:15,194 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4569003057073463, 'Total loss': 0.4569003057073463} | train loss {'Reaction outcome loss': 0.12016386750544752, 'Total loss': 0.12016386750544752}
2022-12-05 21:28:15,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:15,196 INFO:     Epoch: 88
2022-12-05 21:28:15,992 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43933389776132326, 'Total loss': 0.43933389776132326} | train loss {'Reaction outcome loss': 0.12144521346706297, 'Total loss': 0.12144521346706297}
2022-12-05 21:28:15,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:15,992 INFO:     Epoch: 89
2022-12-05 21:28:16,789 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4473208673298359, 'Total loss': 0.4473208673298359} | train loss {'Reaction outcome loss': 0.12010609600017028, 'Total loss': 0.12010609600017028}
2022-12-05 21:28:16,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:16,789 INFO:     Epoch: 90
2022-12-05 21:28:17,587 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4501490059562705, 'Total loss': 0.4501490059562705} | train loss {'Reaction outcome loss': 0.11906770219831096, 'Total loss': 0.11906770219831096}
2022-12-05 21:28:17,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:17,587 INFO:     Epoch: 91
2022-12-05 21:28:18,384 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45119960233569145, 'Total loss': 0.45119960233569145} | train loss {'Reaction outcome loss': 0.12157974082736238, 'Total loss': 0.12157974082736238}
2022-12-05 21:28:18,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:18,384 INFO:     Epoch: 92
2022-12-05 21:28:19,186 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45781179212711076, 'Total loss': 0.45781179212711076} | train loss {'Reaction outcome loss': 0.11974235587272673, 'Total loss': 0.11974235587272673}
2022-12-05 21:28:19,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:19,186 INFO:     Epoch: 93
2022-12-05 21:28:19,984 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4425332590260289, 'Total loss': 0.4425332590260289} | train loss {'Reaction outcome loss': 0.12111505225390917, 'Total loss': 0.12111505225390917}
2022-12-05 21:28:19,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:19,984 INFO:     Epoch: 94
2022-12-05 21:28:20,784 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43281089243563736, 'Total loss': 0.43281089243563736} | train loss {'Reaction outcome loss': 0.12225950836774803, 'Total loss': 0.12225950836774803}
2022-12-05 21:28:20,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:20,785 INFO:     Epoch: 95
2022-12-05 21:28:21,583 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4497946650636467, 'Total loss': 0.4497946650636467} | train loss {'Reaction outcome loss': 0.12100316425822975, 'Total loss': 0.12100316425822975}
2022-12-05 21:28:21,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:21,584 INFO:     Epoch: 96
2022-12-05 21:28:22,386 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44578361037102615, 'Total loss': 0.44578361037102615} | train loss {'Reaction outcome loss': 0.11989645037664881, 'Total loss': 0.11989645037664881}
2022-12-05 21:28:22,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:22,387 INFO:     Epoch: 97
2022-12-05 21:28:23,184 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45248947766694153, 'Total loss': 0.45248947766694153} | train loss {'Reaction outcome loss': 0.11710032232616457, 'Total loss': 0.11710032232616457}
2022-12-05 21:28:23,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:23,185 INFO:     Epoch: 98
2022-12-05 21:28:23,987 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43981003761291504, 'Total loss': 0.43981003761291504} | train loss {'Reaction outcome loss': 0.11936749854019933, 'Total loss': 0.11936749854019933}
2022-12-05 21:28:23,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:23,987 INFO:     Epoch: 99
2022-12-05 21:28:24,789 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44772809980945155, 'Total loss': 0.44772809980945155} | train loss {'Reaction outcome loss': 0.11647539665066306, 'Total loss': 0.11647539665066306}
2022-12-05 21:28:24,789 INFO:     Best model found after epoch 24 of 100.
2022-12-05 21:28:24,789 INFO:   Done with stage: TRAINING
2022-12-05 21:28:24,789 INFO:   Starting stage: EVALUATION
2022-12-05 21:28:24,909 INFO:   Done with stage: EVALUATION
2022-12-05 21:28:24,909 INFO:   Leaving out SEQ value Fold_6
2022-12-05 21:28:24,922 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:28:24,922 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:28:25,564 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:28:25,564 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:28:25,633 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:28:25,634 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:28:25,634 INFO:     No hyperparam tuning for this model
2022-12-05 21:28:25,634 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:28:25,634 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:28:25,634 INFO:     None feature selector for col prot
2022-12-05 21:28:25,635 INFO:     None feature selector for col prot
2022-12-05 21:28:25,635 INFO:     None feature selector for col prot
2022-12-05 21:28:25,635 INFO:     None feature selector for col chem
2022-12-05 21:28:25,635 INFO:     None feature selector for col chem
2022-12-05 21:28:25,635 INFO:     None feature selector for col chem
2022-12-05 21:28:25,635 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:28:25,635 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:28:25,637 INFO:     Number of params in model 215821
2022-12-05 21:28:25,640 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:28:25,640 INFO:   Starting stage: TRAINING
2022-12-05 21:28:25,701 INFO:     Val loss before train {'Reaction outcome loss': 0.9814524054527283, 'Total loss': 0.9814524054527283}
2022-12-05 21:28:25,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:25,701 INFO:     Epoch: 0
2022-12-05 21:28:26,500 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5971924784508619, 'Total loss': 0.5971924784508619} | train loss {'Reaction outcome loss': 0.7860946232272733, 'Total loss': 0.7860946232272733}
2022-12-05 21:28:26,500 INFO:     Found new best model at epoch 0
2022-12-05 21:28:26,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:26,501 INFO:     Epoch: 1
2022-12-05 21:28:27,299 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5129360482096672, 'Total loss': 0.5129360482096672} | train loss {'Reaction outcome loss': 0.5324295862547813, 'Total loss': 0.5324295862547813}
2022-12-05 21:28:27,299 INFO:     Found new best model at epoch 1
2022-12-05 21:28:27,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:27,300 INFO:     Epoch: 2
2022-12-05 21:28:28,101 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47994326190514996, 'Total loss': 0.47994326190514996} | train loss {'Reaction outcome loss': 0.46245448862112337, 'Total loss': 0.46245448862112337}
2022-12-05 21:28:28,101 INFO:     Found new best model at epoch 2
2022-12-05 21:28:28,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:28,102 INFO:     Epoch: 3
2022-12-05 21:28:28,901 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4515078237110918, 'Total loss': 0.4515078237110918} | train loss {'Reaction outcome loss': 0.4223701383077329, 'Total loss': 0.4223701383077329}
2022-12-05 21:28:28,901 INFO:     Found new best model at epoch 3
2022-12-05 21:28:28,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:28,902 INFO:     Epoch: 4
2022-12-05 21:28:29,704 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4480950673195449, 'Total loss': 0.4480950673195449} | train loss {'Reaction outcome loss': 0.39043335923023764, 'Total loss': 0.39043335923023764}
2022-12-05 21:28:29,704 INFO:     Found new best model at epoch 4
2022-12-05 21:28:29,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:29,705 INFO:     Epoch: 5
2022-12-05 21:28:30,509 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42386918514966965, 'Total loss': 0.42386918514966965} | train loss {'Reaction outcome loss': 0.3718299031738312, 'Total loss': 0.3718299031738312}
2022-12-05 21:28:30,509 INFO:     Found new best model at epoch 5
2022-12-05 21:28:30,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:30,510 INFO:     Epoch: 6
2022-12-05 21:28:31,310 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.442850914191116, 'Total loss': 0.442850914191116} | train loss {'Reaction outcome loss': 0.35107834456909087, 'Total loss': 0.35107834456909087}
2022-12-05 21:28:31,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:31,310 INFO:     Epoch: 7
2022-12-05 21:28:32,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4174541797150265, 'Total loss': 0.4174541797150265} | train loss {'Reaction outcome loss': 0.33654570420302693, 'Total loss': 0.33654570420302693}
2022-12-05 21:28:32,114 INFO:     Found new best model at epoch 7
2022-12-05 21:28:32,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:32,115 INFO:     Epoch: 8
2022-12-05 21:28:32,914 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4153583784672347, 'Total loss': 0.4153583784672347} | train loss {'Reaction outcome loss': 0.31939108501518926, 'Total loss': 0.31939108501518926}
2022-12-05 21:28:32,914 INFO:     Found new best model at epoch 8
2022-12-05 21:28:32,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:32,915 INFO:     Epoch: 9
2022-12-05 21:28:33,717 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4179350584745407, 'Total loss': 0.4179350584745407} | train loss {'Reaction outcome loss': 0.30719022771283505, 'Total loss': 0.30719022771283505}
2022-12-05 21:28:33,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:33,718 INFO:     Epoch: 10
2022-12-05 21:28:34,517 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41978874836455693, 'Total loss': 0.41978874836455693} | train loss {'Reaction outcome loss': 0.29430858751819017, 'Total loss': 0.29430858751819017}
2022-12-05 21:28:34,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:34,518 INFO:     Epoch: 11
2022-12-05 21:28:35,317 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4144917872141708, 'Total loss': 0.4144917872141708} | train loss {'Reaction outcome loss': 0.2805363566975199, 'Total loss': 0.2805363566975199}
2022-12-05 21:28:35,317 INFO:     Found new best model at epoch 11
2022-12-05 21:28:35,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:35,318 INFO:     Epoch: 12
2022-12-05 21:28:36,119 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41067528013478627, 'Total loss': 0.41067528013478627} | train loss {'Reaction outcome loss': 0.27478852261218334, 'Total loss': 0.27478852261218334}
2022-12-05 21:28:36,119 INFO:     Found new best model at epoch 12
2022-12-05 21:28:36,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:36,120 INFO:     Epoch: 13
2022-12-05 21:28:36,927 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4149296839128841, 'Total loss': 0.4149296839128841} | train loss {'Reaction outcome loss': 0.26551270526984044, 'Total loss': 0.26551270526984044}
2022-12-05 21:28:36,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:36,928 INFO:     Epoch: 14
2022-12-05 21:28:37,739 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4080513637851585, 'Total loss': 0.4080513637851585} | train loss {'Reaction outcome loss': 0.25471311918039236, 'Total loss': 0.25471311918039236}
2022-12-05 21:28:37,739 INFO:     Found new best model at epoch 14
2022-12-05 21:28:37,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:37,740 INFO:     Epoch: 15
2022-12-05 21:28:38,545 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4044226157394322, 'Total loss': 0.4044226157394322} | train loss {'Reaction outcome loss': 0.24845993960456503, 'Total loss': 0.24845993960456503}
2022-12-05 21:28:38,545 INFO:     Found new best model at epoch 15
2022-12-05 21:28:38,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:38,546 INFO:     Epoch: 16
2022-12-05 21:28:39,349 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40697729028761387, 'Total loss': 0.40697729028761387} | train loss {'Reaction outcome loss': 0.243908932282319, 'Total loss': 0.243908932282319}
2022-12-05 21:28:39,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:39,349 INFO:     Epoch: 17
2022-12-05 21:28:40,155 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40341167050329124, 'Total loss': 0.40341167050329124} | train loss {'Reaction outcome loss': 0.23403490133463375, 'Total loss': 0.23403490133463375}
2022-12-05 21:28:40,155 INFO:     Found new best model at epoch 17
2022-12-05 21:28:40,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:40,156 INFO:     Epoch: 18
2022-12-05 21:28:40,962 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4139796197414398, 'Total loss': 0.4139796197414398} | train loss {'Reaction outcome loss': 0.22892004479804345, 'Total loss': 0.22892004479804345}
2022-12-05 21:28:40,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:40,963 INFO:     Epoch: 19
2022-12-05 21:28:41,765 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42413996769623324, 'Total loss': 0.42413996769623324} | train loss {'Reaction outcome loss': 0.2218750819804207, 'Total loss': 0.2218750819804207}
2022-12-05 21:28:41,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:41,765 INFO:     Epoch: 20
2022-12-05 21:28:42,574 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4126028388061307, 'Total loss': 0.4126028388061307} | train loss {'Reaction outcome loss': 0.21770746244357958, 'Total loss': 0.21770746244357958}
2022-12-05 21:28:42,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:42,574 INFO:     Epoch: 21
2022-12-05 21:28:43,372 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40511407059702004, 'Total loss': 0.40511407059702004} | train loss {'Reaction outcome loss': 0.21326409462058254, 'Total loss': 0.21326409462058254}
2022-12-05 21:28:43,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:43,372 INFO:     Epoch: 22
2022-12-05 21:28:44,172 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4135573018680919, 'Total loss': 0.4135573018680919} | train loss {'Reaction outcome loss': 0.20698578570098167, 'Total loss': 0.20698578570098167}
2022-12-05 21:28:44,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:44,172 INFO:     Epoch: 23
2022-12-05 21:28:44,971 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.417666809972037, 'Total loss': 0.417666809972037} | train loss {'Reaction outcome loss': 0.20716129772124753, 'Total loss': 0.20716129772124753}
2022-12-05 21:28:44,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:44,972 INFO:     Epoch: 24
2022-12-05 21:28:45,774 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4018010317601941, 'Total loss': 0.4018010317601941} | train loss {'Reaction outcome loss': 0.2017342595744037, 'Total loss': 0.2017342595744037}
2022-12-05 21:28:45,774 INFO:     Found new best model at epoch 24
2022-12-05 21:28:45,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:45,775 INFO:     Epoch: 25
2022-12-05 21:28:46,573 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4071584619920362, 'Total loss': 0.4071584619920362} | train loss {'Reaction outcome loss': 0.1985736482987, 'Total loss': 0.1985736482987}
2022-12-05 21:28:46,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:46,575 INFO:     Epoch: 26
2022-12-05 21:28:47,374 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3943448530679399, 'Total loss': 0.3943448530679399} | train loss {'Reaction outcome loss': 0.1951313935700924, 'Total loss': 0.1951313935700924}
2022-12-05 21:28:47,374 INFO:     Found new best model at epoch 26
2022-12-05 21:28:47,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:47,375 INFO:     Epoch: 27
2022-12-05 21:28:48,172 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40979004244912753, 'Total loss': 0.40979004244912753} | train loss {'Reaction outcome loss': 0.19052096723669, 'Total loss': 0.19052096723669}
2022-12-05 21:28:48,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:48,173 INFO:     Epoch: 28
2022-12-05 21:28:48,971 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41405466266653757, 'Total loss': 0.41405466266653757} | train loss {'Reaction outcome loss': 0.18836336693681416, 'Total loss': 0.18836336693681416}
2022-12-05 21:28:48,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:48,972 INFO:     Epoch: 29
2022-12-05 21:28:49,774 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4147929019210013, 'Total loss': 0.4147929019210013} | train loss {'Reaction outcome loss': 0.1856986997168391, 'Total loss': 0.1856986997168391}
2022-12-05 21:28:49,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:49,774 INFO:     Epoch: 30
2022-12-05 21:28:50,574 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41845455731857906, 'Total loss': 0.41845455731857906} | train loss {'Reaction outcome loss': 0.18339816930763905, 'Total loss': 0.18339816930763905}
2022-12-05 21:28:50,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:50,574 INFO:     Epoch: 31
2022-12-05 21:28:51,371 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41211086410013115, 'Total loss': 0.41211086410013115} | train loss {'Reaction outcome loss': 0.18313447400296648, 'Total loss': 0.18313447400296648}
2022-12-05 21:28:51,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:51,371 INFO:     Epoch: 32
2022-12-05 21:28:52,168 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4142110561105338, 'Total loss': 0.4142110561105338} | train loss {'Reaction outcome loss': 0.18008236264088942, 'Total loss': 0.18008236264088942}
2022-12-05 21:28:52,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:52,169 INFO:     Epoch: 33
2022-12-05 21:28:52,969 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41947251626036386, 'Total loss': 0.41947251626036386} | train loss {'Reaction outcome loss': 0.17424357195775356, 'Total loss': 0.17424357195775356}
2022-12-05 21:28:52,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:52,970 INFO:     Epoch: 34
2022-12-05 21:28:53,770 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43303838643160736, 'Total loss': 0.43303838643160736} | train loss {'Reaction outcome loss': 0.17382003763510334, 'Total loss': 0.17382003763510334}
2022-12-05 21:28:53,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:53,770 INFO:     Epoch: 35
2022-12-05 21:28:54,567 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4190773427147757, 'Total loss': 0.4190773427147757} | train loss {'Reaction outcome loss': 0.17130436554491038, 'Total loss': 0.17130436554491038}
2022-12-05 21:28:54,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:54,568 INFO:     Epoch: 36
2022-12-05 21:28:55,368 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44628903693096206, 'Total loss': 0.44628903693096206} | train loss {'Reaction outcome loss': 0.17071883486313444, 'Total loss': 0.17071883486313444}
2022-12-05 21:28:55,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:55,368 INFO:     Epoch: 37
2022-12-05 21:28:56,164 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42806820469823753, 'Total loss': 0.42806820469823753} | train loss {'Reaction outcome loss': 0.1691167873720969, 'Total loss': 0.1691167873720969}
2022-12-05 21:28:56,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:56,165 INFO:     Epoch: 38
2022-12-05 21:28:56,960 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4316881082274697, 'Total loss': 0.4316881082274697} | train loss {'Reaction outcome loss': 0.16677851504045388, 'Total loss': 0.16677851504045388}
2022-12-05 21:28:56,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:56,960 INFO:     Epoch: 39
2022-12-05 21:28:57,758 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4202897281131961, 'Total loss': 0.4202897281131961} | train loss {'Reaction outcome loss': 0.16198926863651122, 'Total loss': 0.16198926863651122}
2022-12-05 21:28:57,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:57,758 INFO:     Epoch: 40
2022-12-05 21:28:58,558 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4446009231561964, 'Total loss': 0.4446009231561964} | train loss {'Reaction outcome loss': 0.16076130914922443, 'Total loss': 0.16076130914922443}
2022-12-05 21:28:58,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:58,558 INFO:     Epoch: 41
2022-12-05 21:28:59,358 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42991345477375115, 'Total loss': 0.42991345477375115} | train loss {'Reaction outcome loss': 0.1569081466539853, 'Total loss': 0.1569081466539853}
2022-12-05 21:28:59,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:28:59,358 INFO:     Epoch: 42
2022-12-05 21:29:00,158 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42210972715507855, 'Total loss': 0.42210972715507855} | train loss {'Reaction outcome loss': 0.15904988089741598, 'Total loss': 0.15904988089741598}
2022-12-05 21:29:00,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:00,158 INFO:     Epoch: 43
2022-12-05 21:29:00,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4404268989508802, 'Total loss': 0.4404268989508802} | train loss {'Reaction outcome loss': 0.15954634016980568, 'Total loss': 0.15954634016980568}
2022-12-05 21:29:00,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:00,955 INFO:     Epoch: 44
2022-12-05 21:29:01,755 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4394291747700084, 'Total loss': 0.4394291747700084} | train loss {'Reaction outcome loss': 0.1589281891262339, 'Total loss': 0.1589281891262339}
2022-12-05 21:29:01,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:01,755 INFO:     Epoch: 45
2022-12-05 21:29:02,553 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4429702098396691, 'Total loss': 0.4429702098396691} | train loss {'Reaction outcome loss': 0.15495882034602185, 'Total loss': 0.15495882034602185}
2022-12-05 21:29:02,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:02,553 INFO:     Epoch: 46
2022-12-05 21:29:03,351 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43081442249769514, 'Total loss': 0.43081442249769514} | train loss {'Reaction outcome loss': 0.15385417788169317, 'Total loss': 0.15385417788169317}
2022-12-05 21:29:03,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:03,351 INFO:     Epoch: 47
2022-12-05 21:29:04,152 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.448377382687547, 'Total loss': 0.448377382687547} | train loss {'Reaction outcome loss': 0.15180447800535588, 'Total loss': 0.15180447800535588}
2022-12-05 21:29:04,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:04,152 INFO:     Epoch: 48
2022-12-05 21:29:04,954 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.442147848111662, 'Total loss': 0.442147848111662} | train loss {'Reaction outcome loss': 0.15354066653808038, 'Total loss': 0.15354066653808038}
2022-12-05 21:29:04,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:04,955 INFO:     Epoch: 49
2022-12-05 21:29:05,751 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4339294731616974, 'Total loss': 0.4339294731616974} | train loss {'Reaction outcome loss': 0.1516364157395137, 'Total loss': 0.1516364157395137}
2022-12-05 21:29:05,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:05,752 INFO:     Epoch: 50
2022-12-05 21:29:06,553 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43682392314076424, 'Total loss': 0.43682392314076424} | train loss {'Reaction outcome loss': 0.14969775871929503, 'Total loss': 0.14969775871929503}
2022-12-05 21:29:06,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:06,553 INFO:     Epoch: 51
2022-12-05 21:29:07,351 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43582574650645256, 'Total loss': 0.43582574650645256} | train loss {'Reaction outcome loss': 0.15337645458508162, 'Total loss': 0.15337645458508162}
2022-12-05 21:29:07,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:07,352 INFO:     Epoch: 52
2022-12-05 21:29:08,151 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4457879168066112, 'Total loss': 0.4457879168066112} | train loss {'Reaction outcome loss': 0.1493643378808854, 'Total loss': 0.1493643378808854}
2022-12-05 21:29:08,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:08,151 INFO:     Epoch: 53
2022-12-05 21:29:08,952 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43609391897916794, 'Total loss': 0.43609391897916794} | train loss {'Reaction outcome loss': 0.1482569893236242, 'Total loss': 0.1482569893236242}
2022-12-05 21:29:08,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:08,952 INFO:     Epoch: 54
2022-12-05 21:29:09,748 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.426224985583262, 'Total loss': 0.426224985583262} | train loss {'Reaction outcome loss': 0.14912450264748786, 'Total loss': 0.14912450264748786}
2022-12-05 21:29:09,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:09,748 INFO:     Epoch: 55
2022-12-05 21:29:10,548 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4305827504193241, 'Total loss': 0.4305827504193241} | train loss {'Reaction outcome loss': 0.14597517176861724, 'Total loss': 0.14597517176861724}
2022-12-05 21:29:10,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:10,548 INFO:     Epoch: 56
2022-12-05 21:29:11,345 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4357285038991408, 'Total loss': 0.4357285038991408} | train loss {'Reaction outcome loss': 0.14547917045532696, 'Total loss': 0.14547917045532696}
2022-12-05 21:29:11,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:11,345 INFO:     Epoch: 57
2022-12-05 21:29:12,148 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4510553093119101, 'Total loss': 0.4510553093119101} | train loss {'Reaction outcome loss': 0.14694543272977875, 'Total loss': 0.14694543272977875}
2022-12-05 21:29:12,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:12,149 INFO:     Epoch: 58
2022-12-05 21:29:12,949 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4489320848475803, 'Total loss': 0.4489320848475803} | train loss {'Reaction outcome loss': 0.14535285732633765, 'Total loss': 0.14535285732633765}
2022-12-05 21:29:12,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:12,949 INFO:     Epoch: 59
2022-12-05 21:29:13,750 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42348185554146767, 'Total loss': 0.42348185554146767} | train loss {'Reaction outcome loss': 0.14365636545323557, 'Total loss': 0.14365636545323557}
2022-12-05 21:29:13,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:13,750 INFO:     Epoch: 60
2022-12-05 21:29:14,549 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42884422974152997, 'Total loss': 0.42884422974152997} | train loss {'Reaction outcome loss': 0.14303819845700938, 'Total loss': 0.14303819845700938}
2022-12-05 21:29:14,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:14,550 INFO:     Epoch: 61
2022-12-05 21:29:15,356 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.429788200692697, 'Total loss': 0.429788200692697} | train loss {'Reaction outcome loss': 0.14503999381521415, 'Total loss': 0.14503999381521415}
2022-12-05 21:29:15,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:15,356 INFO:     Epoch: 62
2022-12-05 21:29:16,159 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44715466926043684, 'Total loss': 0.44715466926043684} | train loss {'Reaction outcome loss': 0.14449223234588582, 'Total loss': 0.14449223234588582}
2022-12-05 21:29:16,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:16,159 INFO:     Epoch: 63
2022-12-05 21:29:16,961 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44602595405145123, 'Total loss': 0.44602595405145123} | train loss {'Reaction outcome loss': 0.1397669113376328, 'Total loss': 0.1397669113376328}
2022-12-05 21:29:16,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:16,961 INFO:     Epoch: 64
2022-12-05 21:29:17,757 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4378612559627403, 'Total loss': 0.4378612559627403} | train loss {'Reaction outcome loss': 0.14052738321404304, 'Total loss': 0.14052738321404304}
2022-12-05 21:29:17,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:17,758 INFO:     Epoch: 65
2022-12-05 21:29:18,551 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42850951985879376, 'Total loss': 0.42850951985879376} | train loss {'Reaction outcome loss': 0.13861813578724622, 'Total loss': 0.13861813578724622}
2022-12-05 21:29:18,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:18,551 INFO:     Epoch: 66
2022-12-05 21:29:19,346 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43287272717465053, 'Total loss': 0.43287272717465053} | train loss {'Reaction outcome loss': 0.1399941796459438, 'Total loss': 0.1399941796459438}
2022-12-05 21:29:19,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:19,346 INFO:     Epoch: 67
2022-12-05 21:29:20,143 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4566498879681934, 'Total loss': 0.4566498879681934} | train loss {'Reaction outcome loss': 0.13828545484331348, 'Total loss': 0.13828545484331348}
2022-12-05 21:29:20,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:20,143 INFO:     Epoch: 68
2022-12-05 21:29:20,936 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44853309846737166, 'Total loss': 0.44853309846737166} | train loss {'Reaction outcome loss': 0.13994131950030644, 'Total loss': 0.13994131950030644}
2022-12-05 21:29:20,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:20,936 INFO:     Epoch: 69
2022-12-05 21:29:21,733 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4323925596069206, 'Total loss': 0.4323925596069206} | train loss {'Reaction outcome loss': 0.1379139379132539, 'Total loss': 0.1379139379132539}
2022-12-05 21:29:21,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:21,733 INFO:     Epoch: 70
2022-12-05 21:29:22,530 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4303476283834739, 'Total loss': 0.4303476283834739} | train loss {'Reaction outcome loss': 0.13915957030164258, 'Total loss': 0.13915957030164258}
2022-12-05 21:29:22,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:22,531 INFO:     Epoch: 71
2022-12-05 21:29:23,328 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4362691862677986, 'Total loss': 0.4362691862677986} | train loss {'Reaction outcome loss': 0.13780722564326658, 'Total loss': 0.13780722564326658}
2022-12-05 21:29:23,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:23,328 INFO:     Epoch: 72
2022-12-05 21:29:24,119 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4368601691147143, 'Total loss': 0.4368601691147143} | train loss {'Reaction outcome loss': 0.138851709049871, 'Total loss': 0.138851709049871}
2022-12-05 21:29:24,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:24,120 INFO:     Epoch: 73
2022-12-05 21:29:24,913 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43910090354355896, 'Total loss': 0.43910090354355896} | train loss {'Reaction outcome loss': 0.13624612083883897, 'Total loss': 0.13624612083883897}
2022-12-05 21:29:24,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:24,913 INFO:     Epoch: 74
2022-12-05 21:29:25,707 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4379853003404357, 'Total loss': 0.4379853003404357} | train loss {'Reaction outcome loss': 0.1344788433353026, 'Total loss': 0.1344788433353026}
2022-12-05 21:29:25,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:25,708 INFO:     Epoch: 75
2022-12-05 21:29:26,499 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4553372897207737, 'Total loss': 0.4553372897207737} | train loss {'Reaction outcome loss': 0.13243898356919206, 'Total loss': 0.13243898356919206}
2022-12-05 21:29:26,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:26,500 INFO:     Epoch: 76
2022-12-05 21:29:27,297 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44487576034258713, 'Total loss': 0.44487576034258713} | train loss {'Reaction outcome loss': 0.1343311807028048, 'Total loss': 0.1343311807028048}
2022-12-05 21:29:27,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:27,297 INFO:     Epoch: 77
2022-12-05 21:29:28,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4383555647324432, 'Total loss': 0.4383555647324432} | train loss {'Reaction outcome loss': 0.13461344649324253, 'Total loss': 0.13461344649324253}
2022-12-05 21:29:28,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:28,089 INFO:     Epoch: 78
2022-12-05 21:29:28,881 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4483784000304612, 'Total loss': 0.4483784000304612} | train loss {'Reaction outcome loss': 0.13469852056098922, 'Total loss': 0.13469852056098922}
2022-12-05 21:29:28,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:28,881 INFO:     Epoch: 79
2022-12-05 21:29:29,676 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4472515420480208, 'Total loss': 0.4472515420480208} | train loss {'Reaction outcome loss': 0.13370675439270394, 'Total loss': 0.13370675439270394}
2022-12-05 21:29:29,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:29,676 INFO:     Epoch: 80
2022-12-05 21:29:30,469 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4300403777001934, 'Total loss': 0.4300403777001934} | train loss {'Reaction outcome loss': 0.13434968132811087, 'Total loss': 0.13434968132811087}
2022-12-05 21:29:30,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:30,469 INFO:     Epoch: 81
2022-12-05 21:29:31,263 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42652123692360794, 'Total loss': 0.42652123692360794} | train loss {'Reaction outcome loss': 0.13214054980480502, 'Total loss': 0.13214054980480502}
2022-12-05 21:29:31,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:31,263 INFO:     Epoch: 82
2022-12-05 21:29:32,062 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43779641000384634, 'Total loss': 0.43779641000384634} | train loss {'Reaction outcome loss': 0.13045897975849408, 'Total loss': 0.13045897975849408}
2022-12-05 21:29:32,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:32,062 INFO:     Epoch: 83
2022-12-05 21:29:32,857 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4190629017962651, 'Total loss': 0.4190629017962651} | train loss {'Reaction outcome loss': 0.13309033774215007, 'Total loss': 0.13309033774215007}
2022-12-05 21:29:32,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:32,857 INFO:     Epoch: 84
2022-12-05 21:29:33,652 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45349948040463706, 'Total loss': 0.45349948040463706} | train loss {'Reaction outcome loss': 0.12971369358485624, 'Total loss': 0.12971369358485624}
2022-12-05 21:29:33,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:33,652 INFO:     Epoch: 85
2022-12-05 21:29:34,445 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44373947381973267, 'Total loss': 0.44373947381973267} | train loss {'Reaction outcome loss': 0.13068396788496042, 'Total loss': 0.13068396788496042}
2022-12-05 21:29:34,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:34,445 INFO:     Epoch: 86
2022-12-05 21:29:35,237 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4405612854117697, 'Total loss': 0.4405612854117697} | train loss {'Reaction outcome loss': 0.13183161607688113, 'Total loss': 0.13183161607688113}
2022-12-05 21:29:35,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:35,237 INFO:     Epoch: 87
2022-12-05 21:29:36,035 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44434684413400566, 'Total loss': 0.44434684413400566} | train loss {'Reaction outcome loss': 0.13320766428425426, 'Total loss': 0.13320766428425426}
2022-12-05 21:29:36,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:36,035 INFO:     Epoch: 88
2022-12-05 21:29:36,830 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4530934031036767, 'Total loss': 0.4530934031036767} | train loss {'Reaction outcome loss': 0.13348036240636102, 'Total loss': 0.13348036240636102}
2022-12-05 21:29:36,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:36,831 INFO:     Epoch: 89
2022-12-05 21:29:37,628 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4368078884753314, 'Total loss': 0.4368078884753314} | train loss {'Reaction outcome loss': 0.13019108703930773, 'Total loss': 0.13019108703930773}
2022-12-05 21:29:37,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:37,628 INFO:     Epoch: 90
2022-12-05 21:29:38,419 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44779647852886806, 'Total loss': 0.44779647852886806} | train loss {'Reaction outcome loss': 0.12997094846721138, 'Total loss': 0.12997094846721138}
2022-12-05 21:29:38,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:38,420 INFO:     Epoch: 91
2022-12-05 21:29:39,215 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4364524581892924, 'Total loss': 0.4364524581892924} | train loss {'Reaction outcome loss': 0.12724408424729783, 'Total loss': 0.12724408424729783}
2022-12-05 21:29:39,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:39,215 INFO:     Epoch: 92
2022-12-05 21:29:40,012 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4420547934079712, 'Total loss': 0.4420547934079712} | train loss {'Reaction outcome loss': 0.12553078528388492, 'Total loss': 0.12553078528388492}
2022-12-05 21:29:40,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:40,013 INFO:     Epoch: 93
2022-12-05 21:29:40,811 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4477999596433206, 'Total loss': 0.4477999596433206} | train loss {'Reaction outcome loss': 0.1279556154303493, 'Total loss': 0.1279556154303493}
2022-12-05 21:29:40,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:40,811 INFO:     Epoch: 94
2022-12-05 21:29:41,607 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44453804431991145, 'Total loss': 0.44453804431991145} | train loss {'Reaction outcome loss': 0.12910768684119947, 'Total loss': 0.12910768684119947}
2022-12-05 21:29:41,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:41,607 INFO:     Epoch: 95
2022-12-05 21:29:42,403 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43724487180059607, 'Total loss': 0.43724487180059607} | train loss {'Reaction outcome loss': 0.13023593982366183, 'Total loss': 0.13023593982366183}
2022-12-05 21:29:42,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:42,404 INFO:     Epoch: 96
2022-12-05 21:29:43,200 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4353181750259616, 'Total loss': 0.4353181750259616} | train loss {'Reaction outcome loss': 0.1253135961709514, 'Total loss': 0.1253135961709514}
2022-12-05 21:29:43,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:43,200 INFO:     Epoch: 97
2022-12-05 21:29:43,995 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43692429160529916, 'Total loss': 0.43692429160529916} | train loss {'Reaction outcome loss': 0.1284729532837387, 'Total loss': 0.1284729532837387}
2022-12-05 21:29:43,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:43,995 INFO:     Epoch: 98
2022-12-05 21:29:44,793 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44725449417125096, 'Total loss': 0.44725449417125096} | train loss {'Reaction outcome loss': 0.12650619638002208, 'Total loss': 0.12650619638002208}
2022-12-05 21:29:44,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:44,793 INFO:     Epoch: 99
2022-12-05 21:29:45,588 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42864994128996675, 'Total loss': 0.42864994128996675} | train loss {'Reaction outcome loss': 0.12762301449754065, 'Total loss': 0.12762301449754065}
2022-12-05 21:29:45,588 INFO:     Best model found after epoch 27 of 100.
2022-12-05 21:29:45,589 INFO:   Done with stage: TRAINING
2022-12-05 21:29:45,589 INFO:   Starting stage: EVALUATION
2022-12-05 21:29:45,708 INFO:   Done with stage: EVALUATION
2022-12-05 21:29:45,708 INFO:   Leaving out SEQ value Fold_7
2022-12-05 21:29:45,720 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:29:45,721 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:29:46,361 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:29:46,361 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:29:46,431 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:29:46,431 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:29:46,431 INFO:     No hyperparam tuning for this model
2022-12-05 21:29:46,431 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:29:46,431 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:29:46,432 INFO:     None feature selector for col prot
2022-12-05 21:29:46,432 INFO:     None feature selector for col prot
2022-12-05 21:29:46,432 INFO:     None feature selector for col prot
2022-12-05 21:29:46,433 INFO:     None feature selector for col chem
2022-12-05 21:29:46,433 INFO:     None feature selector for col chem
2022-12-05 21:29:46,433 INFO:     None feature selector for col chem
2022-12-05 21:29:46,433 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:29:46,433 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:29:46,435 INFO:     Number of params in model 215821
2022-12-05 21:29:46,438 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:29:46,438 INFO:   Starting stage: TRAINING
2022-12-05 21:29:46,498 INFO:     Val loss before train {'Reaction outcome loss': 1.0354513932358136, 'Total loss': 1.0354513932358136}
2022-12-05 21:29:46,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:46,498 INFO:     Epoch: 0
2022-12-05 21:29:47,285 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6293784725395116, 'Total loss': 0.6293784725395116} | train loss {'Reaction outcome loss': 0.8015923474723028, 'Total loss': 0.8015923474723028}
2022-12-05 21:29:47,286 INFO:     Found new best model at epoch 0
2022-12-05 21:29:47,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:47,286 INFO:     Epoch: 1
2022-12-05 21:29:48,073 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5424175966869701, 'Total loss': 0.5424175966869701} | train loss {'Reaction outcome loss': 0.5468439720118576, 'Total loss': 0.5468439720118576}
2022-12-05 21:29:48,073 INFO:     Found new best model at epoch 1
2022-12-05 21:29:48,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:48,074 INFO:     Epoch: 2
2022-12-05 21:29:48,861 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5026730525900017, 'Total loss': 0.5026730525900017} | train loss {'Reaction outcome loss': 0.47385820324875805, 'Total loss': 0.47385820324875805}
2022-12-05 21:29:48,862 INFO:     Found new best model at epoch 2
2022-12-05 21:29:48,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:48,863 INFO:     Epoch: 3
2022-12-05 21:29:49,650 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4854288189248605, 'Total loss': 0.4854288189248605} | train loss {'Reaction outcome loss': 0.43198529179943235, 'Total loss': 0.43198529179943235}
2022-12-05 21:29:49,651 INFO:     Found new best model at epoch 3
2022-12-05 21:29:49,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:49,651 INFO:     Epoch: 4
2022-12-05 21:29:50,446 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46214886534620414, 'Total loss': 0.46214886534620414} | train loss {'Reaction outcome loss': 0.40399867181594556, 'Total loss': 0.40399867181594556}
2022-12-05 21:29:50,447 INFO:     Found new best model at epoch 4
2022-12-05 21:29:50,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:50,448 INFO:     Epoch: 5
2022-12-05 21:29:51,239 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46136358278718864, 'Total loss': 0.46136358278718864} | train loss {'Reaction outcome loss': 0.37872449347847387, 'Total loss': 0.37872449347847387}
2022-12-05 21:29:51,240 INFO:     Found new best model at epoch 5
2022-12-05 21:29:51,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:51,240 INFO:     Epoch: 6
2022-12-05 21:29:52,036 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.450239015573805, 'Total loss': 0.450239015573805} | train loss {'Reaction outcome loss': 0.36548317425888077, 'Total loss': 0.36548317425888077}
2022-12-05 21:29:52,036 INFO:     Found new best model at epoch 6
2022-12-05 21:29:52,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:52,037 INFO:     Epoch: 7
2022-12-05 21:29:52,832 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46743303300304845, 'Total loss': 0.46743303300304845} | train loss {'Reaction outcome loss': 0.3440700078058822, 'Total loss': 0.3440700078058822}
2022-12-05 21:29:52,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:52,832 INFO:     Epoch: 8
2022-12-05 21:29:53,621 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45980833674019034, 'Total loss': 0.45980833674019034} | train loss {'Reaction outcome loss': 0.32480207324190147, 'Total loss': 0.32480207324190147}
2022-12-05 21:29:53,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:53,621 INFO:     Epoch: 9
2022-12-05 21:29:54,410 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44948715615001594, 'Total loss': 0.44948715615001594} | train loss {'Reaction outcome loss': 0.31360877641224066, 'Total loss': 0.31360877641224066}
2022-12-05 21:29:54,410 INFO:     Found new best model at epoch 9
2022-12-05 21:29:54,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:54,411 INFO:     Epoch: 10
2022-12-05 21:29:55,201 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44560733708468353, 'Total loss': 0.44560733708468353} | train loss {'Reaction outcome loss': 0.299892536541711, 'Total loss': 0.299892536541711}
2022-12-05 21:29:55,202 INFO:     Found new best model at epoch 10
2022-12-05 21:29:55,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:55,202 INFO:     Epoch: 11
2022-12-05 21:29:55,990 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43504436618902464, 'Total loss': 0.43504436618902464} | train loss {'Reaction outcome loss': 0.2917911288317157, 'Total loss': 0.2917911288317157}
2022-12-05 21:29:55,990 INFO:     Found new best model at epoch 11
2022-12-05 21:29:55,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:55,991 INFO:     Epoch: 12
2022-12-05 21:29:56,780 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44375128400596703, 'Total loss': 0.44375128400596703} | train loss {'Reaction outcome loss': 0.2829056377654616, 'Total loss': 0.2829056377654616}
2022-12-05 21:29:56,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:56,780 INFO:     Epoch: 13
2022-12-05 21:29:57,574 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43489306792616844, 'Total loss': 0.43489306792616844} | train loss {'Reaction outcome loss': 0.27196156444699177, 'Total loss': 0.27196156444699177}
2022-12-05 21:29:57,574 INFO:     Found new best model at epoch 13
2022-12-05 21:29:57,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:57,575 INFO:     Epoch: 14
2022-12-05 21:29:58,364 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44687077978795225, 'Total loss': 0.44687077978795225} | train loss {'Reaction outcome loss': 0.26454091799042, 'Total loss': 0.26454091799042}
2022-12-05 21:29:58,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:58,364 INFO:     Epoch: 15
2022-12-05 21:29:59,156 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4411246766420928, 'Total loss': 0.4411246766420928} | train loss {'Reaction outcome loss': 0.25875002296588684, 'Total loss': 0.25875002296588684}
2022-12-05 21:29:59,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:59,156 INFO:     Epoch: 16
2022-12-05 21:29:59,945 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4318257160484791, 'Total loss': 0.4318257160484791} | train loss {'Reaction outcome loss': 0.2500946865933627, 'Total loss': 0.2500946865933627}
2022-12-05 21:29:59,945 INFO:     Found new best model at epoch 16
2022-12-05 21:29:59,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:29:59,946 INFO:     Epoch: 17
2022-12-05 21:30:00,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4266332997517152, 'Total loss': 0.4266332997517152} | train loss {'Reaction outcome loss': 0.240232505721534, 'Total loss': 0.240232505721534}
2022-12-05 21:30:00,735 INFO:     Found new best model at epoch 17
2022-12-05 21:30:00,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:00,735 INFO:     Epoch: 18
2022-12-05 21:30:01,529 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4525657899000428, 'Total loss': 0.4525657899000428} | train loss {'Reaction outcome loss': 0.23643243628052565, 'Total loss': 0.23643243628052565}
2022-12-05 21:30:01,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:01,529 INFO:     Epoch: 19
2022-12-05 21:30:02,319 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4433632713149894, 'Total loss': 0.4433632713149894} | train loss {'Reaction outcome loss': 0.2319470769009338, 'Total loss': 0.2319470769009338}
2022-12-05 21:30:02,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:02,320 INFO:     Epoch: 20
2022-12-05 21:30:03,108 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4391957585784522, 'Total loss': 0.4391957585784522} | train loss {'Reaction outcome loss': 0.2243941859511832, 'Total loss': 0.2243941859511832}
2022-12-05 21:30:03,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:03,108 INFO:     Epoch: 21
2022-12-05 21:30:03,895 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4449650269340385, 'Total loss': 0.4449650269340385} | train loss {'Reaction outcome loss': 0.2174425677571687, 'Total loss': 0.2174425677571687}
2022-12-05 21:30:03,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:03,895 INFO:     Epoch: 22
2022-12-05 21:30:04,684 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4523593397303061, 'Total loss': 0.4523593397303061} | train loss {'Reaction outcome loss': 0.2134068401206119, 'Total loss': 0.2134068401206119}
2022-12-05 21:30:04,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:04,684 INFO:     Epoch: 23
2022-12-05 21:30:05,477 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46999904818155547, 'Total loss': 0.46999904818155547} | train loss {'Reaction outcome loss': 0.20775815917307186, 'Total loss': 0.20775815917307186}
2022-12-05 21:30:05,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:05,477 INFO:     Epoch: 24
2022-12-05 21:30:06,265 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4524348842149431, 'Total loss': 0.4524348842149431} | train loss {'Reaction outcome loss': 0.2036560057975382, 'Total loss': 0.2036560057975382}
2022-12-05 21:30:06,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:06,265 INFO:     Epoch: 25
2022-12-05 21:30:07,054 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44614163345911284, 'Total loss': 0.44614163345911284} | train loss {'Reaction outcome loss': 0.19968911393843441, 'Total loss': 0.19968911393843441}
2022-12-05 21:30:07,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:07,055 INFO:     Epoch: 26
2022-12-05 21:30:07,846 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4437965696508234, 'Total loss': 0.4437965696508234} | train loss {'Reaction outcome loss': 0.19880640295594326, 'Total loss': 0.19880640295594326}
2022-12-05 21:30:07,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:07,847 INFO:     Epoch: 27
2022-12-05 21:30:08,637 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45534389838576317, 'Total loss': 0.45534389838576317} | train loss {'Reaction outcome loss': 0.199624918574686, 'Total loss': 0.199624918574686}
2022-12-05 21:30:08,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:08,637 INFO:     Epoch: 28
2022-12-05 21:30:09,427 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4489587660540234, 'Total loss': 0.4489587660540234} | train loss {'Reaction outcome loss': 0.1928047967644838, 'Total loss': 0.1928047967644838}
2022-12-05 21:30:09,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:09,428 INFO:     Epoch: 29
2022-12-05 21:30:10,216 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45470079000700603, 'Total loss': 0.45470079000700603} | train loss {'Reaction outcome loss': 0.18696819441506135, 'Total loss': 0.18696819441506135}
2022-12-05 21:30:10,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:10,216 INFO:     Epoch: 30
2022-12-05 21:30:11,005 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45215690576217393, 'Total loss': 0.45215690576217393} | train loss {'Reaction outcome loss': 0.18285445240609016, 'Total loss': 0.18285445240609016}
2022-12-05 21:30:11,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:11,005 INFO:     Epoch: 31
2022-12-05 21:30:11,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4614216536283493, 'Total loss': 0.4614216536283493} | train loss {'Reaction outcome loss': 0.17965842422987768, 'Total loss': 0.17965842422987768}
2022-12-05 21:30:11,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:11,795 INFO:     Epoch: 32
2022-12-05 21:30:12,589 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4574503224681724, 'Total loss': 0.4574503224681724} | train loss {'Reaction outcome loss': 0.17752593449554463, 'Total loss': 0.17752593449554463}
2022-12-05 21:30:12,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:12,589 INFO:     Epoch: 33
2022-12-05 21:30:13,379 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45680541680617764, 'Total loss': 0.45680541680617764} | train loss {'Reaction outcome loss': 0.17887954928569103, 'Total loss': 0.17887954928569103}
2022-12-05 21:30:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:13,379 INFO:     Epoch: 34
2022-12-05 21:30:14,167 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.450698256153952, 'Total loss': 0.450698256153952} | train loss {'Reaction outcome loss': 0.17571528394695235, 'Total loss': 0.17571528394695235}
2022-12-05 21:30:14,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:14,167 INFO:     Epoch: 35
2022-12-05 21:30:14,954 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46000802889466286, 'Total loss': 0.46000802889466286} | train loss {'Reaction outcome loss': 0.17011318735868824, 'Total loss': 0.17011318735868824}
2022-12-05 21:30:14,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:14,955 INFO:     Epoch: 36
2022-12-05 21:30:15,745 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4814603613181548, 'Total loss': 0.4814603613181548} | train loss {'Reaction outcome loss': 0.1691216313089753, 'Total loss': 0.1691216313089753}
2022-12-05 21:30:15,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:15,745 INFO:     Epoch: 37
2022-12-05 21:30:16,536 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4765596623447808, 'Total loss': 0.4765596623447808} | train loss {'Reaction outcome loss': 0.16512432220855705, 'Total loss': 0.16512432220855705}
2022-12-05 21:30:16,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:16,537 INFO:     Epoch: 38
2022-12-05 21:30:17,325 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4655409302901138, 'Total loss': 0.4655409302901138} | train loss {'Reaction outcome loss': 0.16439299682826408, 'Total loss': 0.16439299682826408}
2022-12-05 21:30:17,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:17,325 INFO:     Epoch: 39
2022-12-05 21:30:18,122 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4726105715063485, 'Total loss': 0.4726105715063485} | train loss {'Reaction outcome loss': 0.16161529118051896, 'Total loss': 0.16161529118051896}
2022-12-05 21:30:18,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:18,122 INFO:     Epoch: 40
2022-12-05 21:30:18,915 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4627995579080148, 'Total loss': 0.4627995579080148} | train loss {'Reaction outcome loss': 0.16212380357720108, 'Total loss': 0.16212380357720108}
2022-12-05 21:30:18,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:18,916 INFO:     Epoch: 41
2022-12-05 21:30:19,705 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4515724947506731, 'Total loss': 0.4515724947506731} | train loss {'Reaction outcome loss': 0.16233028349304487, 'Total loss': 0.16233028349304487}
2022-12-05 21:30:19,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:19,706 INFO:     Epoch: 42
2022-12-05 21:30:20,495 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4771847586062821, 'Total loss': 0.4771847586062821} | train loss {'Reaction outcome loss': 0.15859515469724894, 'Total loss': 0.15859515469724894}
2022-12-05 21:30:20,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:20,495 INFO:     Epoch: 43
2022-12-05 21:30:21,287 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47643357583067636, 'Total loss': 0.47643357583067636} | train loss {'Reaction outcome loss': 0.15735952011667764, 'Total loss': 0.15735952011667764}
2022-12-05 21:30:21,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:21,287 INFO:     Epoch: 44
2022-12-05 21:30:22,082 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4613759907131845, 'Total loss': 0.4613759907131845} | train loss {'Reaction outcome loss': 0.15879711689736678, 'Total loss': 0.15879711689736678}
2022-12-05 21:30:22,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:22,082 INFO:     Epoch: 45
2022-12-05 21:30:22,875 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4741124371913346, 'Total loss': 0.4741124371913346} | train loss {'Reaction outcome loss': 0.15323278251356684, 'Total loss': 0.15323278251356684}
2022-12-05 21:30:22,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:22,875 INFO:     Epoch: 46
2022-12-05 21:30:23,671 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46596422588283365, 'Total loss': 0.46596422588283365} | train loss {'Reaction outcome loss': 0.15291233869789825, 'Total loss': 0.15291233869789825}
2022-12-05 21:30:23,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:23,671 INFO:     Epoch: 47
2022-12-05 21:30:24,464 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4728267148814418, 'Total loss': 0.4728267148814418} | train loss {'Reaction outcome loss': 0.1520938360498019, 'Total loss': 0.1520938360498019}
2022-12-05 21:30:24,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:24,464 INFO:     Epoch: 48
2022-12-05 21:30:25,260 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4652438387274742, 'Total loss': 0.4652438387274742} | train loss {'Reaction outcome loss': 0.1469612624043757, 'Total loss': 0.1469612624043757}
2022-12-05 21:30:25,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:25,260 INFO:     Epoch: 49
2022-12-05 21:30:26,057 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46786963601003995, 'Total loss': 0.46786963601003995} | train loss {'Reaction outcome loss': 0.1467751134705432, 'Total loss': 0.1467751134705432}
2022-12-05 21:30:26,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:26,058 INFO:     Epoch: 50
2022-12-05 21:30:26,858 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47602704844691535, 'Total loss': 0.47602704844691535} | train loss {'Reaction outcome loss': 0.14656007382641678, 'Total loss': 0.14656007382641678}
2022-12-05 21:30:26,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:26,859 INFO:     Epoch: 51
2022-12-05 21:30:27,657 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47956093976443465, 'Total loss': 0.47956093976443465} | train loss {'Reaction outcome loss': 0.14571965627960468, 'Total loss': 0.14571965627960468}
2022-12-05 21:30:27,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:27,658 INFO:     Epoch: 52
2022-12-05 21:30:28,452 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47885431349277496, 'Total loss': 0.47885431349277496} | train loss {'Reaction outcome loss': 0.14320523512025593, 'Total loss': 0.14320523512025593}
2022-12-05 21:30:28,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:28,452 INFO:     Epoch: 53
2022-12-05 21:30:29,246 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4747239994731816, 'Total loss': 0.4747239994731816} | train loss {'Reaction outcome loss': 0.14167663513829834, 'Total loss': 0.14167663513829834}
2022-12-05 21:30:29,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:29,246 INFO:     Epoch: 54
2022-12-05 21:30:30,040 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5039945722303607, 'Total loss': 0.5039945722303607} | train loss {'Reaction outcome loss': 0.14002482967096785, 'Total loss': 0.14002482967096785}
2022-12-05 21:30:30,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:30,040 INFO:     Epoch: 55
2022-12-05 21:30:30,832 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48488314415920863, 'Total loss': 0.48488314415920863} | train loss {'Reaction outcome loss': 0.14390606676447035, 'Total loss': 0.14390606676447035}
2022-12-05 21:30:30,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:30,832 INFO:     Epoch: 56
2022-12-05 21:30:31,627 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49405713785778393, 'Total loss': 0.49405713785778393} | train loss {'Reaction outcome loss': 0.1400618301893053, 'Total loss': 0.1400618301893053}
2022-12-05 21:30:31,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:31,627 INFO:     Epoch: 57
2022-12-05 21:30:32,428 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4755433425307274, 'Total loss': 0.4755433425307274} | train loss {'Reaction outcome loss': 0.14133535677695322, 'Total loss': 0.14133535677695322}
2022-12-05 21:30:32,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:32,428 INFO:     Epoch: 58
2022-12-05 21:30:33,223 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48014545610005205, 'Total loss': 0.48014545610005205} | train loss {'Reaction outcome loss': 0.1482141960623414, 'Total loss': 0.1482141960623414}
2022-12-05 21:30:33,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:33,223 INFO:     Epoch: 59
2022-12-05 21:30:34,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4861804890361699, 'Total loss': 0.4861804890361699} | train loss {'Reaction outcome loss': 0.14793107492721033, 'Total loss': 0.14793107492721033}
2022-12-05 21:30:34,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:34,020 INFO:     Epoch: 60
2022-12-05 21:30:34,812 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4854502772743052, 'Total loss': 0.4854502772743052} | train loss {'Reaction outcome loss': 0.14028109440406566, 'Total loss': 0.14028109440406566}
2022-12-05 21:30:34,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:34,812 INFO:     Epoch: 61
2022-12-05 21:30:35,608 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49646069820631633, 'Total loss': 0.49646069820631633} | train loss {'Reaction outcome loss': 0.13574269317799373, 'Total loss': 0.13574269317799373}
2022-12-05 21:30:35,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:35,608 INFO:     Epoch: 62
2022-12-05 21:30:36,406 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48448125848715956, 'Total loss': 0.48448125848715956} | train loss {'Reaction outcome loss': 0.13385157682461596, 'Total loss': 0.13385157682461596}
2022-12-05 21:30:36,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:36,406 INFO:     Epoch: 63
2022-12-05 21:30:37,201 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4788164215331728, 'Total loss': 0.4788164215331728} | train loss {'Reaction outcome loss': 0.13339062738288873, 'Total loss': 0.13339062738288873}
2022-12-05 21:30:37,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:37,202 INFO:     Epoch: 64
2022-12-05 21:30:37,997 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4880884401500225, 'Total loss': 0.4880884401500225} | train loss {'Reaction outcome loss': 0.13472125124985632, 'Total loss': 0.13472125124985632}
2022-12-05 21:30:37,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:37,997 INFO:     Epoch: 65
2022-12-05 21:30:38,789 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48977465080943977, 'Total loss': 0.48977465080943977} | train loss {'Reaction outcome loss': 0.13534509439043974, 'Total loss': 0.13534509439043974}
2022-12-05 21:30:38,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:38,790 INFO:     Epoch: 66
2022-12-05 21:30:39,584 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4907443384555253, 'Total loss': 0.4907443384555253} | train loss {'Reaction outcome loss': 0.13184281670477105, 'Total loss': 0.13184281670477105}
2022-12-05 21:30:39,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:39,585 INFO:     Epoch: 67
2022-12-05 21:30:40,381 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49520782609893516, 'Total loss': 0.49520782609893516} | train loss {'Reaction outcome loss': 0.13131126816562888, 'Total loss': 0.13131126816562888}
2022-12-05 21:30:40,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:40,381 INFO:     Epoch: 68
2022-12-05 21:30:41,176 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4855337989601222, 'Total loss': 0.4855337989601222} | train loss {'Reaction outcome loss': 0.13406865032771997, 'Total loss': 0.13406865032771997}
2022-12-05 21:30:41,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:41,176 INFO:     Epoch: 69
2022-12-05 21:30:41,968 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48821869831193576, 'Total loss': 0.48821869831193576} | train loss {'Reaction outcome loss': 0.13144198646966881, 'Total loss': 0.13144198646966881}
2022-12-05 21:30:41,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:41,968 INFO:     Epoch: 70
2022-12-05 21:30:42,760 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47590864585204556, 'Total loss': 0.47590864585204556} | train loss {'Reaction outcome loss': 0.13390703254609335, 'Total loss': 0.13390703254609335}
2022-12-05 21:30:42,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:42,761 INFO:     Epoch: 71
2022-12-05 21:30:43,553 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4979311349717053, 'Total loss': 0.4979311349717053} | train loss {'Reaction outcome loss': 0.1401885691577727, 'Total loss': 0.1401885691577727}
2022-12-05 21:30:43,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:43,553 INFO:     Epoch: 72
2022-12-05 21:30:44,347 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4965301420200955, 'Total loss': 0.4965301420200955} | train loss {'Reaction outcome loss': 0.13195980631587045, 'Total loss': 0.13195980631587045}
2022-12-05 21:30:44,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:44,347 INFO:     Epoch: 73
2022-12-05 21:30:45,138 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4949621426110918, 'Total loss': 0.4949621426110918} | train loss {'Reaction outcome loss': 0.12693052738150845, 'Total loss': 0.12693052738150845}
2022-12-05 21:30:45,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:45,139 INFO:     Epoch: 74
2022-12-05 21:30:45,931 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4810986075211655, 'Total loss': 0.4810986075211655} | train loss {'Reaction outcome loss': 0.1287301096627828, 'Total loss': 0.1287301096627828}
2022-12-05 21:30:45,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:45,931 INFO:     Epoch: 75
2022-12-05 21:30:46,719 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4913931820880283, 'Total loss': 0.4913931820880283} | train loss {'Reaction outcome loss': 0.1292757570709626, 'Total loss': 0.1292757570709626}
2022-12-05 21:30:46,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:46,719 INFO:     Epoch: 76
2022-12-05 21:30:47,507 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4825204475359483, 'Total loss': 0.4825204475359483} | train loss {'Reaction outcome loss': 0.13022001172431938, 'Total loss': 0.13022001172431938}
2022-12-05 21:30:47,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:47,508 INFO:     Epoch: 77
2022-12-05 21:30:48,303 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4899810688062148, 'Total loss': 0.4899810688062148} | train loss {'Reaction outcome loss': 0.12838577007147134, 'Total loss': 0.12838577007147134}
2022-12-05 21:30:48,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:48,303 INFO:     Epoch: 78
2022-12-05 21:30:49,094 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47999247536063194, 'Total loss': 0.47999247536063194} | train loss {'Reaction outcome loss': 0.12328107260343871, 'Total loss': 0.12328107260343871}
2022-12-05 21:30:49,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:49,095 INFO:     Epoch: 79
2022-12-05 21:30:49,886 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49066104739904404, 'Total loss': 0.49066104739904404} | train loss {'Reaction outcome loss': 0.12732938043386693, 'Total loss': 0.12732938043386693}
2022-12-05 21:30:49,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:49,886 INFO:     Epoch: 80
2022-12-05 21:30:50,674 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49831379848447716, 'Total loss': 0.49831379848447716} | train loss {'Reaction outcome loss': 0.1274710729574928, 'Total loss': 0.1274710729574928}
2022-12-05 21:30:50,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:50,676 INFO:     Epoch: 81
2022-12-05 21:30:51,463 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4969946996054866, 'Total loss': 0.4969946996054866} | train loss {'Reaction outcome loss': 0.1334435119465543, 'Total loss': 0.1334435119465543}
2022-12-05 21:30:51,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:51,464 INFO:     Epoch: 82
2022-12-05 21:30:52,253 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5000896992331202, 'Total loss': 0.5000896992331202} | train loss {'Reaction outcome loss': 0.132017843412077, 'Total loss': 0.132017843412077}
2022-12-05 21:30:52,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:52,253 INFO:     Epoch: 83
2022-12-05 21:30:53,047 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4918066490102898, 'Total loss': 0.4918066490102898} | train loss {'Reaction outcome loss': 0.13564688856392978, 'Total loss': 0.13564688856392978}
2022-12-05 21:30:53,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:53,047 INFO:     Epoch: 84
2022-12-05 21:30:53,840 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49389852583408356, 'Total loss': 0.49389852583408356} | train loss {'Reaction outcome loss': 0.13292623627629235, 'Total loss': 0.13292623627629235}
2022-12-05 21:30:53,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:53,840 INFO:     Epoch: 85
2022-12-05 21:30:54,632 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5037534517998045, 'Total loss': 0.5037534517998045} | train loss {'Reaction outcome loss': 0.12218593810175957, 'Total loss': 0.12218593810175957}
2022-12-05 21:30:54,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:54,632 INFO:     Epoch: 86
2022-12-05 21:30:55,430 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4970948293127797, 'Total loss': 0.4970948293127797} | train loss {'Reaction outcome loss': 0.12374021423705345, 'Total loss': 0.12374021423705345}
2022-12-05 21:30:55,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:55,430 INFO:     Epoch: 87
2022-12-05 21:30:56,224 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4902437302199277, 'Total loss': 0.4902437302199277} | train loss {'Reaction outcome loss': 0.12471993135873734, 'Total loss': 0.12471993135873734}
2022-12-05 21:30:56,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:56,225 INFO:     Epoch: 88
2022-12-05 21:30:57,014 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4884013912894509, 'Total loss': 0.4884013912894509} | train loss {'Reaction outcome loss': 0.12279091758072859, 'Total loss': 0.12279091758072859}
2022-12-05 21:30:57,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:57,015 INFO:     Epoch: 89
2022-12-05 21:30:57,812 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4844343709674748, 'Total loss': 0.4844343709674748} | train loss {'Reaction outcome loss': 0.126101870361248, 'Total loss': 0.126101870361248}
2022-12-05 21:30:57,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:57,812 INFO:     Epoch: 90
2022-12-05 21:30:58,600 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49526735564524477, 'Total loss': 0.49526735564524477} | train loss {'Reaction outcome loss': 0.12408814460476521, 'Total loss': 0.12408814460476521}
2022-12-05 21:30:58,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:58,601 INFO:     Epoch: 91
2022-12-05 21:30:59,387 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4991848008199172, 'Total loss': 0.4991848008199172} | train loss {'Reaction outcome loss': 0.12337554102152706, 'Total loss': 0.12337554102152706}
2022-12-05 21:30:59,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:30:59,388 INFO:     Epoch: 92
2022-12-05 21:31:00,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4963076114654541, 'Total loss': 0.4963076114654541} | train loss {'Reaction outcome loss': 0.13108314712567684, 'Total loss': 0.13108314712567684}
2022-12-05 21:31:00,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:00,179 INFO:     Epoch: 93
2022-12-05 21:31:00,970 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4987053010951389, 'Total loss': 0.4987053010951389} | train loss {'Reaction outcome loss': 0.12087142112125691, 'Total loss': 0.12087142112125691}
2022-12-05 21:31:00,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:00,970 INFO:     Epoch: 94
2022-12-05 21:31:01,760 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4900299832224846, 'Total loss': 0.4900299832224846} | train loss {'Reaction outcome loss': 0.12061297513077013, 'Total loss': 0.12061297513077013}
2022-12-05 21:31:01,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:01,760 INFO:     Epoch: 95
2022-12-05 21:31:02,553 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48466414941305463, 'Total loss': 0.48466414941305463} | train loss {'Reaction outcome loss': 0.11950923181949598, 'Total loss': 0.11950923181949598}
2022-12-05 21:31:02,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:02,553 INFO:     Epoch: 96
2022-12-05 21:31:03,344 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48304207826202566, 'Total loss': 0.48304207826202566} | train loss {'Reaction outcome loss': 0.12200596999058402, 'Total loss': 0.12200596999058402}
2022-12-05 21:31:03,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:03,345 INFO:     Epoch: 97
2022-12-05 21:31:04,135 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48244275322014635, 'Total loss': 0.48244275322014635} | train loss {'Reaction outcome loss': 0.1198954647029882, 'Total loss': 0.1198954647029882}
2022-12-05 21:31:04,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:04,136 INFO:     Epoch: 98
2022-12-05 21:31:04,929 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4982921520925381, 'Total loss': 0.4982921520925381} | train loss {'Reaction outcome loss': 0.1186572080666599, 'Total loss': 0.1186572080666599}
2022-12-05 21:31:04,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:04,929 INFO:     Epoch: 99
2022-12-05 21:31:05,718 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49035266702148045, 'Total loss': 0.49035266702148045} | train loss {'Reaction outcome loss': 0.12380527346187577, 'Total loss': 0.12380527346187577}
2022-12-05 21:31:05,718 INFO:     Best model found after epoch 18 of 100.
2022-12-05 21:31:05,718 INFO:   Done with stage: TRAINING
2022-12-05 21:31:05,718 INFO:   Starting stage: EVALUATION
2022-12-05 21:31:05,843 INFO:   Done with stage: EVALUATION
2022-12-05 21:31:05,843 INFO:   Leaving out SEQ value Fold_8
2022-12-05 21:31:05,856 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:31:05,856 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:31:06,489 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:31:06,489 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:31:06,557 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:31:06,557 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:31:06,557 INFO:     No hyperparam tuning for this model
2022-12-05 21:31:06,557 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:31:06,557 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:31:06,558 INFO:     None feature selector for col prot
2022-12-05 21:31:06,558 INFO:     None feature selector for col prot
2022-12-05 21:31:06,558 INFO:     None feature selector for col prot
2022-12-05 21:31:06,558 INFO:     None feature selector for col chem
2022-12-05 21:31:06,559 INFO:     None feature selector for col chem
2022-12-05 21:31:06,559 INFO:     None feature selector for col chem
2022-12-05 21:31:06,559 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:31:06,559 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:31:06,560 INFO:     Number of params in model 215821
2022-12-05 21:31:06,563 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:31:06,563 INFO:   Starting stage: TRAINING
2022-12-05 21:31:06,623 INFO:     Val loss before train {'Reaction outcome loss': 0.9631700366735458, 'Total loss': 0.9631700366735458}
2022-12-05 21:31:06,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:06,624 INFO:     Epoch: 0
2022-12-05 21:31:07,406 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.57612740654837, 'Total loss': 0.57612740654837} | train loss {'Reaction outcome loss': 0.8023767524836015, 'Total loss': 0.8023767524836015}
2022-12-05 21:31:07,406 INFO:     Found new best model at epoch 0
2022-12-05 21:31:07,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:07,407 INFO:     Epoch: 1
2022-12-05 21:31:08,195 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48945981738242234, 'Total loss': 0.48945981738242234} | train loss {'Reaction outcome loss': 0.5368902380369147, 'Total loss': 0.5368902380369147}
2022-12-05 21:31:08,196 INFO:     Found new best model at epoch 1
2022-12-05 21:31:08,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:08,196 INFO:     Epoch: 2
2022-12-05 21:31:08,977 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4456726810471578, 'Total loss': 0.4456726810471578} | train loss {'Reaction outcome loss': 0.4647687758718218, 'Total loss': 0.4647687758718218}
2022-12-05 21:31:08,977 INFO:     Found new best model at epoch 2
2022-12-05 21:31:08,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:08,978 INFO:     Epoch: 3
2022-12-05 21:31:09,761 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45841464840553026, 'Total loss': 0.45841464840553026} | train loss {'Reaction outcome loss': 0.42722669006610403, 'Total loss': 0.42722669006610403}
2022-12-05 21:31:09,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:09,762 INFO:     Epoch: 4
2022-12-05 21:31:10,545 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4335738274861466, 'Total loss': 0.4335738274861466} | train loss {'Reaction outcome loss': 0.39868785319279654, 'Total loss': 0.39868785319279654}
2022-12-05 21:31:10,545 INFO:     Found new best model at epoch 4
2022-12-05 21:31:10,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:10,546 INFO:     Epoch: 5
2022-12-05 21:31:11,334 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43168795718388125, 'Total loss': 0.43168795718388125} | train loss {'Reaction outcome loss': 0.37614033985502865, 'Total loss': 0.37614033985502865}
2022-12-05 21:31:11,334 INFO:     Found new best model at epoch 5
2022-12-05 21:31:11,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:11,335 INFO:     Epoch: 6
2022-12-05 21:31:12,126 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41648238931189885, 'Total loss': 0.41648238931189885} | train loss {'Reaction outcome loss': 0.35645577481814794, 'Total loss': 0.35645577481814794}
2022-12-05 21:31:12,126 INFO:     Found new best model at epoch 6
2022-12-05 21:31:12,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:12,127 INFO:     Epoch: 7
2022-12-05 21:31:12,912 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41295840726657346, 'Total loss': 0.41295840726657346} | train loss {'Reaction outcome loss': 0.3401290969276915, 'Total loss': 0.3401290969276915}
2022-12-05 21:31:12,912 INFO:     Found new best model at epoch 7
2022-12-05 21:31:12,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:12,913 INFO:     Epoch: 8
2022-12-05 21:31:13,698 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4108761042695154, 'Total loss': 0.4108761042695154} | train loss {'Reaction outcome loss': 0.3284994608285476, 'Total loss': 0.3284994608285476}
2022-12-05 21:31:13,698 INFO:     Found new best model at epoch 8
2022-12-05 21:31:13,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:13,699 INFO:     Epoch: 9
2022-12-05 21:31:14,485 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40965439954941923, 'Total loss': 0.40965439954941923} | train loss {'Reaction outcome loss': 0.31363668995244165, 'Total loss': 0.31363668995244165}
2022-12-05 21:31:14,485 INFO:     Found new best model at epoch 9
2022-12-05 21:31:14,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:14,486 INFO:     Epoch: 10
2022-12-05 21:31:15,266 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41539212955500593, 'Total loss': 0.41539212955500593} | train loss {'Reaction outcome loss': 0.29764200368401955, 'Total loss': 0.29764200368401955}
2022-12-05 21:31:15,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:15,266 INFO:     Epoch: 11
2022-12-05 21:31:16,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39776420254598965, 'Total loss': 0.39776420254598965} | train loss {'Reaction outcome loss': 0.28985000264887906, 'Total loss': 0.28985000264887906}
2022-12-05 21:31:16,050 INFO:     Found new best model at epoch 11
2022-12-05 21:31:16,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:16,051 INFO:     Epoch: 12
2022-12-05 21:31:16,835 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3947324991564859, 'Total loss': 0.3947324991564859} | train loss {'Reaction outcome loss': 0.2791801074329688, 'Total loss': 0.2791801074329688}
2022-12-05 21:31:16,835 INFO:     Found new best model at epoch 12
2022-12-05 21:31:16,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:16,836 INFO:     Epoch: 13
2022-12-05 21:31:17,621 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4361037202179432, 'Total loss': 0.4361037202179432} | train loss {'Reaction outcome loss': 0.26793330999053255, 'Total loss': 0.26793330999053255}
2022-12-05 21:31:17,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:17,621 INFO:     Epoch: 14
2022-12-05 21:31:18,408 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4104515930468386, 'Total loss': 0.4104515930468386} | train loss {'Reaction outcome loss': 0.2609907232681099, 'Total loss': 0.2609907232681099}
2022-12-05 21:31:18,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:18,408 INFO:     Epoch: 15
2022-12-05 21:31:19,189 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4056088163263418, 'Total loss': 0.4056088163263418} | train loss {'Reaction outcome loss': 0.2506625723777985, 'Total loss': 0.2506625723777985}
2022-12-05 21:31:19,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:19,189 INFO:     Epoch: 16
2022-12-05 21:31:19,973 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41283606297590514, 'Total loss': 0.41283606297590514} | train loss {'Reaction outcome loss': 0.2479377037712506, 'Total loss': 0.2479377037712506}
2022-12-05 21:31:19,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:19,973 INFO:     Epoch: 17
2022-12-05 21:31:20,754 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4017179960554296, 'Total loss': 0.4017179960554296} | train loss {'Reaction outcome loss': 0.23802414442203482, 'Total loss': 0.23802414442203482}
2022-12-05 21:31:20,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:20,754 INFO:     Epoch: 18
2022-12-05 21:31:21,533 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41756157272241334, 'Total loss': 0.41756157272241334} | train loss {'Reaction outcome loss': 0.2303910450667751, 'Total loss': 0.2303910450667751}
2022-12-05 21:31:21,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:21,534 INFO:     Epoch: 19
2022-12-05 21:31:22,320 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.406875040890141, 'Total loss': 0.406875040890141} | train loss {'Reaction outcome loss': 0.2223577624528992, 'Total loss': 0.2223577624528992}
2022-12-05 21:31:22,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:22,320 INFO:     Epoch: 20
2022-12-05 21:31:23,105 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.431185935031284, 'Total loss': 0.431185935031284} | train loss {'Reaction outcome loss': 0.2172758224211177, 'Total loss': 0.2172758224211177}
2022-12-05 21:31:23,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:23,105 INFO:     Epoch: 21
2022-12-05 21:31:23,891 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40881720049814746, 'Total loss': 0.40881720049814746} | train loss {'Reaction outcome loss': 0.2129781136251226, 'Total loss': 0.2129781136251226}
2022-12-05 21:31:23,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:23,891 INFO:     Epoch: 22
2022-12-05 21:31:24,680 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3964815618978305, 'Total loss': 0.3964815618978305} | train loss {'Reaction outcome loss': 0.2115333174488374, 'Total loss': 0.2115333174488374}
2022-12-05 21:31:24,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:24,681 INFO:     Epoch: 23
2022-12-05 21:31:25,468 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.444321680475365, 'Total loss': 0.444321680475365} | train loss {'Reaction outcome loss': 0.20506384032113212, 'Total loss': 0.20506384032113212}
2022-12-05 21:31:25,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:25,468 INFO:     Epoch: 24
2022-12-05 21:31:26,257 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42035667141052807, 'Total loss': 0.42035667141052807} | train loss {'Reaction outcome loss': 0.19852115527099493, 'Total loss': 0.19852115527099493}
2022-12-05 21:31:26,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:26,258 INFO:     Epoch: 25
2022-12-05 21:31:27,045 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41565971957011655, 'Total loss': 0.41565971957011655} | train loss {'Reaction outcome loss': 0.1978881416956381, 'Total loss': 0.1978881416956381}
2022-12-05 21:31:27,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:27,045 INFO:     Epoch: 26
2022-12-05 21:31:27,827 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4163028873471459, 'Total loss': 0.4163028873471459} | train loss {'Reaction outcome loss': 0.19245383300039234, 'Total loss': 0.19245383300039234}
2022-12-05 21:31:27,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:27,828 INFO:     Epoch: 27
2022-12-05 21:31:28,611 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4243747950954871, 'Total loss': 0.4243747950954871} | train loss {'Reaction outcome loss': 0.18734652667629476, 'Total loss': 0.18734652667629476}
2022-12-05 21:31:28,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:28,611 INFO:     Epoch: 28
2022-12-05 21:31:29,393 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4243628897450187, 'Total loss': 0.4243628897450187} | train loss {'Reaction outcome loss': 0.18515313780125306, 'Total loss': 0.18515313780125306}
2022-12-05 21:31:29,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:29,394 INFO:     Epoch: 29
2022-12-05 21:31:30,182 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42567112151829695, 'Total loss': 0.42567112151829695} | train loss {'Reaction outcome loss': 0.18376199906425816, 'Total loss': 0.18376199906425816}
2022-12-05 21:31:30,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:30,182 INFO:     Epoch: 30
2022-12-05 21:31:30,967 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44782505997202615, 'Total loss': 0.44782505997202615} | train loss {'Reaction outcome loss': 0.1807396131206532, 'Total loss': 0.1807396131206532}
2022-12-05 21:31:30,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:30,967 INFO:     Epoch: 31
2022-12-05 21:31:31,751 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42036817713894625, 'Total loss': 0.42036817713894625} | train loss {'Reaction outcome loss': 0.17809330821037292, 'Total loss': 0.17809330821037292}
2022-12-05 21:31:31,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:31,751 INFO:     Epoch: 32
2022-12-05 21:31:32,537 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42593763108280575, 'Total loss': 0.42593763108280575} | train loss {'Reaction outcome loss': 0.1721516719962261, 'Total loss': 0.1721516719962261}
2022-12-05 21:31:32,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:32,538 INFO:     Epoch: 33
2022-12-05 21:31:33,324 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4377144431187348, 'Total loss': 0.4377144431187348} | train loss {'Reaction outcome loss': 0.17029332282895945, 'Total loss': 0.17029332282895945}
2022-12-05 21:31:33,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:33,324 INFO:     Epoch: 34
2022-12-05 21:31:34,108 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.447841671041467, 'Total loss': 0.447841671041467} | train loss {'Reaction outcome loss': 0.16943181318287948, 'Total loss': 0.16943181318287948}
2022-12-05 21:31:34,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:34,109 INFO:     Epoch: 35
2022-12-05 21:31:34,892 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41780384528366005, 'Total loss': 0.41780384528366005} | train loss {'Reaction outcome loss': 0.1685550275581832, 'Total loss': 0.1685550275581832}
2022-12-05 21:31:34,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:34,893 INFO:     Epoch: 36
2022-12-05 21:31:35,679 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43129079111597757, 'Total loss': 0.43129079111597757} | train loss {'Reaction outcome loss': 0.16614768998507334, 'Total loss': 0.16614768998507334}
2022-12-05 21:31:35,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:35,679 INFO:     Epoch: 37
2022-12-05 21:31:36,464 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43662681532177056, 'Total loss': 0.43662681532177056} | train loss {'Reaction outcome loss': 0.1653801642776448, 'Total loss': 0.1653801642776448}
2022-12-05 21:31:36,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:36,465 INFO:     Epoch: 38
2022-12-05 21:31:37,253 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4301738464696841, 'Total loss': 0.4301738464696841} | train loss {'Reaction outcome loss': 0.1617275824048081, 'Total loss': 0.1617275824048081}
2022-12-05 21:31:37,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:37,254 INFO:     Epoch: 39
2022-12-05 21:31:38,037 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4457607360726053, 'Total loss': 0.4457607360726053} | train loss {'Reaction outcome loss': 0.16234896377641328, 'Total loss': 0.16234896377641328}
2022-12-05 21:31:38,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:38,037 INFO:     Epoch: 40
2022-12-05 21:31:38,822 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42575788413259114, 'Total loss': 0.42575788413259114} | train loss {'Reaction outcome loss': 0.15873983773041744, 'Total loss': 0.15873983773041744}
2022-12-05 21:31:38,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:38,823 INFO:     Epoch: 41
2022-12-05 21:31:39,609 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4221047982361845, 'Total loss': 0.4221047982361845} | train loss {'Reaction outcome loss': 0.15982058224629384, 'Total loss': 0.15982058224629384}
2022-12-05 21:31:39,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:39,609 INFO:     Epoch: 42
2022-12-05 21:31:40,394 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4214256726713343, 'Total loss': 0.4214256726713343} | train loss {'Reaction outcome loss': 0.15070135224686593, 'Total loss': 0.15070135224686593}
2022-12-05 21:31:40,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:40,395 INFO:     Epoch: 43
2022-12-05 21:31:41,179 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4481761956756765, 'Total loss': 0.4481761956756765} | train loss {'Reaction outcome loss': 0.1517494791320392, 'Total loss': 0.1517494791320392}
2022-12-05 21:31:41,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:41,180 INFO:     Epoch: 44
2022-12-05 21:31:41,968 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44359680807048624, 'Total loss': 0.44359680807048624} | train loss {'Reaction outcome loss': 0.15154610880631572, 'Total loss': 0.15154610880631572}
2022-12-05 21:31:41,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:41,969 INFO:     Epoch: 45
2022-12-05 21:31:42,757 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42756309554996813, 'Total loss': 0.42756309554996813} | train loss {'Reaction outcome loss': 0.15472917176631032, 'Total loss': 0.15472917176631032}
2022-12-05 21:31:42,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:42,757 INFO:     Epoch: 46
2022-12-05 21:31:43,545 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4320274909788912, 'Total loss': 0.4320274909788912} | train loss {'Reaction outcome loss': 0.1485357266147526, 'Total loss': 0.1485357266147526}
2022-12-05 21:31:43,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:43,546 INFO:     Epoch: 47
2022-12-05 21:31:44,333 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45037542419000104, 'Total loss': 0.45037542419000104} | train loss {'Reaction outcome loss': 0.14823113348411054, 'Total loss': 0.14823113348411054}
2022-12-05 21:31:44,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:44,333 INFO:     Epoch: 48
2022-12-05 21:31:45,118 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4188851927491752, 'Total loss': 0.4188851927491752} | train loss {'Reaction outcome loss': 0.14728068028557664, 'Total loss': 0.14728068028557664}
2022-12-05 21:31:45,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:45,118 INFO:     Epoch: 49
2022-12-05 21:31:45,905 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4234655858440833, 'Total loss': 0.4234655858440833} | train loss {'Reaction outcome loss': 0.14423200125064778, 'Total loss': 0.14423200125064778}
2022-12-05 21:31:45,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:45,905 INFO:     Epoch: 50
2022-12-05 21:31:46,693 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44174511603672395, 'Total loss': 0.44174511603672395} | train loss {'Reaction outcome loss': 0.14494229351759566, 'Total loss': 0.14494229351759566}
2022-12-05 21:31:46,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:46,693 INFO:     Epoch: 51
2022-12-05 21:31:47,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4234706871211529, 'Total loss': 0.4234706871211529} | train loss {'Reaction outcome loss': 0.1434364533393967, 'Total loss': 0.1434364533393967}
2022-12-05 21:31:47,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:47,478 INFO:     Epoch: 52
2022-12-05 21:31:48,266 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4312258836897937, 'Total loss': 0.4312258836897937} | train loss {'Reaction outcome loss': 0.14266018723422774, 'Total loss': 0.14266018723422774}
2022-12-05 21:31:48,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:48,266 INFO:     Epoch: 53
2022-12-05 21:31:49,051 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4378238763998855, 'Total loss': 0.4378238763998855} | train loss {'Reaction outcome loss': 0.14593707223479846, 'Total loss': 0.14593707223479846}
2022-12-05 21:31:49,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:49,052 INFO:     Epoch: 54
2022-12-05 21:31:49,834 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4238526861776005, 'Total loss': 0.4238526861776005} | train loss {'Reaction outcome loss': 0.13981276347625013, 'Total loss': 0.13981276347625013}
2022-12-05 21:31:49,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:49,834 INFO:     Epoch: 55
2022-12-05 21:31:50,623 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4275525124235587, 'Total loss': 0.4275525124235587} | train loss {'Reaction outcome loss': 0.13971514200069465, 'Total loss': 0.13971514200069465}
2022-12-05 21:31:50,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:50,623 INFO:     Epoch: 56
2022-12-05 21:31:51,414 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41353723643855617, 'Total loss': 0.41353723643855617} | train loss {'Reaction outcome loss': 0.1386678926342604, 'Total loss': 0.1386678926342604}
2022-12-05 21:31:51,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:51,414 INFO:     Epoch: 57
2022-12-05 21:31:52,195 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4356449483470483, 'Total loss': 0.4356449483470483} | train loss {'Reaction outcome loss': 0.13908395894936154, 'Total loss': 0.13908395894936154}
2022-12-05 21:31:52,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:52,197 INFO:     Epoch: 58
2022-12-05 21:31:52,979 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4591704874553464, 'Total loss': 0.4591704874553464} | train loss {'Reaction outcome loss': 0.13796206369083755, 'Total loss': 0.13796206369083755}
2022-12-05 21:31:52,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:52,979 INFO:     Epoch: 59
2022-12-05 21:31:53,757 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4274218285625631, 'Total loss': 0.4274218285625631} | train loss {'Reaction outcome loss': 0.13907805862931572, 'Total loss': 0.13907805862931572}
2022-12-05 21:31:53,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:53,758 INFO:     Epoch: 60
2022-12-05 21:31:54,536 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43842420828613365, 'Total loss': 0.43842420828613365} | train loss {'Reaction outcome loss': 0.1372779310357814, 'Total loss': 0.1372779310357814}
2022-12-05 21:31:54,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:54,536 INFO:     Epoch: 61
2022-12-05 21:31:55,322 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44543206556276843, 'Total loss': 0.44543206556276843} | train loss {'Reaction outcome loss': 0.13520898293627767, 'Total loss': 0.13520898293627767}
2022-12-05 21:31:55,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:55,322 INFO:     Epoch: 62
2022-12-05 21:31:56,107 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42311992970379914, 'Total loss': 0.42311992970379914} | train loss {'Reaction outcome loss': 0.13654368955413906, 'Total loss': 0.13654368955413906}
2022-12-05 21:31:56,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:56,107 INFO:     Epoch: 63
2022-12-05 21:31:56,894 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4413221409036355, 'Total loss': 0.4413221409036355} | train loss {'Reaction outcome loss': 0.13359743119502554, 'Total loss': 0.13359743119502554}
2022-12-05 21:31:56,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:56,894 INFO:     Epoch: 64
2022-12-05 21:31:57,679 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4256182290952314, 'Total loss': 0.4256182290952314} | train loss {'Reaction outcome loss': 0.13211850387481403, 'Total loss': 0.13211850387481403}
2022-12-05 21:31:57,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:57,680 INFO:     Epoch: 65
2022-12-05 21:31:58,459 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4149284613403407, 'Total loss': 0.4149284613403407} | train loss {'Reaction outcome loss': 0.1342350262844441, 'Total loss': 0.1342350262844441}
2022-12-05 21:31:58,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:58,460 INFO:     Epoch: 66
2022-12-05 21:31:59,243 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4210030968216332, 'Total loss': 0.4210030968216332} | train loss {'Reaction outcome loss': 0.1341741193618093, 'Total loss': 0.1341741193618093}
2022-12-05 21:31:59,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:31:59,243 INFO:     Epoch: 67
2022-12-05 21:32:00,032 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41936630687930365, 'Total loss': 0.41936630687930365} | train loss {'Reaction outcome loss': 0.1344466671347618, 'Total loss': 0.1344466671347618}
2022-12-05 21:32:00,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:00,032 INFO:     Epoch: 68
2022-12-05 21:32:00,813 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43383886208969424, 'Total loss': 0.43383886208969424} | train loss {'Reaction outcome loss': 0.1325791228258488, 'Total loss': 0.1325791228258488}
2022-12-05 21:32:00,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:00,813 INFO:     Epoch: 69
2022-12-05 21:32:01,594 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4497071748430079, 'Total loss': 0.4497071748430079} | train loss {'Reaction outcome loss': 0.13062044996007974, 'Total loss': 0.13062044996007974}
2022-12-05 21:32:01,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:01,594 INFO:     Epoch: 70
2022-12-05 21:32:02,375 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4325485893271186, 'Total loss': 0.4325485893271186} | train loss {'Reaction outcome loss': 0.13348201786985203, 'Total loss': 0.13348201786985203}
2022-12-05 21:32:02,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:02,375 INFO:     Epoch: 71
2022-12-05 21:32:03,158 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4317918155681003, 'Total loss': 0.4317918155681003} | train loss {'Reaction outcome loss': 0.12916704001171248, 'Total loss': 0.12916704001171248}
2022-12-05 21:32:03,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:03,158 INFO:     Epoch: 72
2022-12-05 21:32:03,939 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4306804304095832, 'Total loss': 0.4306804304095832} | train loss {'Reaction outcome loss': 0.1296067913766114, 'Total loss': 0.1296067913766114}
2022-12-05 21:32:03,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:03,940 INFO:     Epoch: 73
2022-12-05 21:32:04,719 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4468724876642227, 'Total loss': 0.4468724876642227} | train loss {'Reaction outcome loss': 0.13138477670751056, 'Total loss': 0.13138477670751056}
2022-12-05 21:32:04,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:04,719 INFO:     Epoch: 74
2022-12-05 21:32:05,499 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43708365613763983, 'Total loss': 0.43708365613763983} | train loss {'Reaction outcome loss': 0.12694774678699217, 'Total loss': 0.12694774678699217}
2022-12-05 21:32:05,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:05,499 INFO:     Epoch: 75
2022-12-05 21:32:06,283 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4188986193727363, 'Total loss': 0.4188986193727363} | train loss {'Reaction outcome loss': 0.1275867218949965, 'Total loss': 0.1275867218949965}
2022-12-05 21:32:06,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:06,283 INFO:     Epoch: 76
2022-12-05 21:32:07,064 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43033214353702287, 'Total loss': 0.43033214353702287} | train loss {'Reaction outcome loss': 0.12687099987298858, 'Total loss': 0.12687099987298858}
2022-12-05 21:32:07,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:07,064 INFO:     Epoch: 77
2022-12-05 21:32:07,848 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42524575763805345, 'Total loss': 0.42524575763805345} | train loss {'Reaction outcome loss': 0.1242512538268858, 'Total loss': 0.1242512538268858}
2022-12-05 21:32:07,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:07,848 INFO:     Epoch: 78
2022-12-05 21:32:08,632 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42734489149668, 'Total loss': 0.42734489149668} | train loss {'Reaction outcome loss': 0.12699675981563574, 'Total loss': 0.12699675981563574}
2022-12-05 21:32:08,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:08,632 INFO:     Epoch: 79
2022-12-05 21:32:09,418 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44860501858321106, 'Total loss': 0.44860501858321106} | train loss {'Reaction outcome loss': 0.12583322673275762, 'Total loss': 0.12583322673275762}
2022-12-05 21:32:09,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:09,418 INFO:     Epoch: 80
2022-12-05 21:32:10,201 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45171408041973005, 'Total loss': 0.45171408041973005} | train loss {'Reaction outcome loss': 0.1250858584000748, 'Total loss': 0.1250858584000748}
2022-12-05 21:32:10,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:10,201 INFO:     Epoch: 81
2022-12-05 21:32:10,986 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42731201714328065, 'Total loss': 0.42731201714328065} | train loss {'Reaction outcome loss': 0.12443619570409765, 'Total loss': 0.12443619570409765}
2022-12-05 21:32:10,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:10,987 INFO:     Epoch: 82
2022-12-05 21:32:11,769 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42289989892478014, 'Total loss': 0.42289989892478014} | train loss {'Reaction outcome loss': 0.12658228545772787, 'Total loss': 0.12658228545772787}
2022-12-05 21:32:11,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:11,769 INFO:     Epoch: 83
2022-12-05 21:32:12,548 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4408119134604931, 'Total loss': 0.4408119134604931} | train loss {'Reaction outcome loss': 0.12453031332745236, 'Total loss': 0.12453031332745236}
2022-12-05 21:32:12,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:12,548 INFO:     Epoch: 84
2022-12-05 21:32:13,327 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4441795101897283, 'Total loss': 0.4441795101897283} | train loss {'Reaction outcome loss': 0.12525566608017805, 'Total loss': 0.12525566608017805}
2022-12-05 21:32:13,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:13,327 INFO:     Epoch: 85
2022-12-05 21:32:14,113 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43299102173610166, 'Total loss': 0.43299102173610166} | train loss {'Reaction outcome loss': 0.12366254645000611, 'Total loss': 0.12366254645000611}
2022-12-05 21:32:14,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:14,113 INFO:     Epoch: 86
2022-12-05 21:32:14,896 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4406079077585177, 'Total loss': 0.4406079077585177} | train loss {'Reaction outcome loss': 0.12304085835206266, 'Total loss': 0.12304085835206266}
2022-12-05 21:32:14,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:14,896 INFO:     Epoch: 87
2022-12-05 21:32:15,676 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42952188747850334, 'Total loss': 0.42952188747850334} | train loss {'Reaction outcome loss': 0.12216115365641153, 'Total loss': 0.12216115365641153}
2022-12-05 21:32:15,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:15,676 INFO:     Epoch: 88
2022-12-05 21:32:16,459 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4363030984320424, 'Total loss': 0.4363030984320424} | train loss {'Reaction outcome loss': 0.12115070210883812, 'Total loss': 0.12115070210883812}
2022-12-05 21:32:16,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:16,459 INFO:     Epoch: 89
2022-12-05 21:32:17,243 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4335319906134497, 'Total loss': 0.4335319906134497} | train loss {'Reaction outcome loss': 0.12098531851887094, 'Total loss': 0.12098531851887094}
2022-12-05 21:32:17,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:17,243 INFO:     Epoch: 90
2022-12-05 21:32:18,031 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4799621904438192, 'Total loss': 0.4799621904438192} | train loss {'Reaction outcome loss': 0.12076510815900199, 'Total loss': 0.12076510815900199}
2022-12-05 21:32:18,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:18,031 INFO:     Epoch: 91
2022-12-05 21:32:18,810 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43753721700473264, 'Total loss': 0.43753721700473264} | train loss {'Reaction outcome loss': 0.12040990068748289, 'Total loss': 0.12040990068748289}
2022-12-05 21:32:18,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:18,810 INFO:     Epoch: 92
2022-12-05 21:32:19,593 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46632668443701486, 'Total loss': 0.46632668443701486} | train loss {'Reaction outcome loss': 0.12359211062442284, 'Total loss': 0.12359211062442284}
2022-12-05 21:32:19,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:19,593 INFO:     Epoch: 93
2022-12-05 21:32:20,375 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42893699556589127, 'Total loss': 0.42893699556589127} | train loss {'Reaction outcome loss': 0.11985539525215115, 'Total loss': 0.11985539525215115}
2022-12-05 21:32:20,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:20,375 INFO:     Epoch: 94
2022-12-05 21:32:21,154 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.450451176952232, 'Total loss': 0.450451176952232} | train loss {'Reaction outcome loss': 0.1201428272058161, 'Total loss': 0.1201428272058161}
2022-12-05 21:32:21,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:21,155 INFO:     Epoch: 95
2022-12-05 21:32:21,933 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4401179328560829, 'Total loss': 0.4401179328560829} | train loss {'Reaction outcome loss': 0.12161008280758955, 'Total loss': 0.12161008280758955}
2022-12-05 21:32:21,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:21,933 INFO:     Epoch: 96
2022-12-05 21:32:22,717 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44574744609946554, 'Total loss': 0.44574744609946554} | train loss {'Reaction outcome loss': 0.12266444032441597, 'Total loss': 0.12266444032441597}
2022-12-05 21:32:22,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:22,718 INFO:     Epoch: 97
2022-12-05 21:32:23,500 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43526099486784503, 'Total loss': 0.43526099486784503} | train loss {'Reaction outcome loss': 0.11885015161669985, 'Total loss': 0.11885015161669985}
2022-12-05 21:32:23,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:23,501 INFO:     Epoch: 98
2022-12-05 21:32:24,280 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44032063910906966, 'Total loss': 0.44032063910906966} | train loss {'Reaction outcome loss': 0.12013014041799672, 'Total loss': 0.12013014041799672}
2022-12-05 21:32:24,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:24,282 INFO:     Epoch: 99
2022-12-05 21:32:25,062 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.446436097337441, 'Total loss': 0.446436097337441} | train loss {'Reaction outcome loss': 0.1211203509903684, 'Total loss': 0.1211203509903684}
2022-12-05 21:32:25,062 INFO:     Best model found after epoch 13 of 100.
2022-12-05 21:32:25,062 INFO:   Done with stage: TRAINING
2022-12-05 21:32:25,062 INFO:   Starting stage: EVALUATION
2022-12-05 21:32:25,193 INFO:   Done with stage: EVALUATION
2022-12-05 21:32:25,194 INFO:   Leaving out SEQ value Fold_9
2022-12-05 21:32:25,206 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:32:25,206 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:32:25,849 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:32:25,849 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:32:25,918 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:32:25,918 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:32:25,918 INFO:     No hyperparam tuning for this model
2022-12-05 21:32:25,919 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:32:25,919 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:32:25,919 INFO:     None feature selector for col prot
2022-12-05 21:32:25,919 INFO:     None feature selector for col prot
2022-12-05 21:32:25,919 INFO:     None feature selector for col prot
2022-12-05 21:32:25,920 INFO:     None feature selector for col chem
2022-12-05 21:32:25,920 INFO:     None feature selector for col chem
2022-12-05 21:32:25,920 INFO:     None feature selector for col chem
2022-12-05 21:32:25,920 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:32:25,920 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:32:25,922 INFO:     Number of params in model 215821
2022-12-05 21:32:25,925 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:32:25,925 INFO:   Starting stage: TRAINING
2022-12-05 21:32:25,985 INFO:     Val loss before train {'Reaction outcome loss': 0.9900372665036808, 'Total loss': 0.9900372665036808}
2022-12-05 21:32:25,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:25,985 INFO:     Epoch: 0
2022-12-05 21:32:26,772 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6016634953292933, 'Total loss': 0.6016634953292933} | train loss {'Reaction outcome loss': 0.7977941257026997, 'Total loss': 0.7977941257026997}
2022-12-05 21:32:26,772 INFO:     Found new best model at epoch 0
2022-12-05 21:32:26,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:26,773 INFO:     Epoch: 1
2022-12-05 21:32:27,559 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5270805893973871, 'Total loss': 0.5270805893973871} | train loss {'Reaction outcome loss': 0.5374187842343259, 'Total loss': 0.5374187842343259}
2022-12-05 21:32:27,559 INFO:     Found new best model at epoch 1
2022-12-05 21:32:27,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:27,560 INFO:     Epoch: 2
2022-12-05 21:32:28,345 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4855121130293066, 'Total loss': 0.4855121130293066} | train loss {'Reaction outcome loss': 0.46942512727218116, 'Total loss': 0.46942512727218116}
2022-12-05 21:32:28,345 INFO:     Found new best model at epoch 2
2022-12-05 21:32:28,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:28,346 INFO:     Epoch: 3
2022-12-05 21:32:29,132 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46365721320564096, 'Total loss': 0.46365721320564096} | train loss {'Reaction outcome loss': 0.42585481253079316, 'Total loss': 0.42585481253079316}
2022-12-05 21:32:29,132 INFO:     Found new best model at epoch 3
2022-12-05 21:32:29,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:29,133 INFO:     Epoch: 4
2022-12-05 21:32:29,924 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45537877015092154, 'Total loss': 0.45537877015092154} | train loss {'Reaction outcome loss': 0.39767368353511157, 'Total loss': 0.39767368353511157}
2022-12-05 21:32:29,925 INFO:     Found new best model at epoch 4
2022-12-05 21:32:29,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:29,925 INFO:     Epoch: 5
2022-12-05 21:32:30,717 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4463649398901246, 'Total loss': 0.4463649398901246} | train loss {'Reaction outcome loss': 0.3721626105186669, 'Total loss': 0.3721626105186669}
2022-12-05 21:32:30,718 INFO:     Found new best model at epoch 5
2022-12-05 21:32:30,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:30,719 INFO:     Epoch: 6
2022-12-05 21:32:31,511 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44078329476443207, 'Total loss': 0.44078329476443207} | train loss {'Reaction outcome loss': 0.3516359852951186, 'Total loss': 0.3516359852951186}
2022-12-05 21:32:31,511 INFO:     Found new best model at epoch 6
2022-12-05 21:32:31,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:31,512 INFO:     Epoch: 7
2022-12-05 21:32:32,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44207137247378175, 'Total loss': 0.44207137247378175} | train loss {'Reaction outcome loss': 0.3352597892691611, 'Total loss': 0.3352597892691611}
2022-12-05 21:32:32,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:32,305 INFO:     Epoch: 8
2022-12-05 21:32:33,093 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4216170903633941, 'Total loss': 0.4216170903633941} | train loss {'Reaction outcome loss': 0.319162881507082, 'Total loss': 0.319162881507082}
2022-12-05 21:32:33,094 INFO:     Found new best model at epoch 8
2022-12-05 21:32:33,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:33,095 INFO:     Epoch: 9
2022-12-05 21:32:33,885 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41776285963979637, 'Total loss': 0.41776285963979637} | train loss {'Reaction outcome loss': 0.30680563382291604, 'Total loss': 0.30680563382291604}
2022-12-05 21:32:33,885 INFO:     Found new best model at epoch 9
2022-12-05 21:32:33,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:33,886 INFO:     Epoch: 10
2022-12-05 21:32:34,674 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43192431330680847, 'Total loss': 0.43192431330680847} | train loss {'Reaction outcome loss': 0.29282622337944597, 'Total loss': 0.29282622337944597}
2022-12-05 21:32:34,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:34,674 INFO:     Epoch: 11
2022-12-05 21:32:35,463 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4237783026288856, 'Total loss': 0.4237783026288856} | train loss {'Reaction outcome loss': 0.2826265148547014, 'Total loss': 0.2826265148547014}
2022-12-05 21:32:35,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:35,463 INFO:     Epoch: 12
2022-12-05 21:32:36,255 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4284313033250245, 'Total loss': 0.4284313033250245} | train loss {'Reaction outcome loss': 0.27018140306175964, 'Total loss': 0.27018140306175964}
2022-12-05 21:32:36,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:36,256 INFO:     Epoch: 13
2022-12-05 21:32:37,047 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4266051717779853, 'Total loss': 0.4266051717779853} | train loss {'Reaction outcome loss': 0.26087286682264044, 'Total loss': 0.26087286682264044}
2022-12-05 21:32:37,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:37,047 INFO:     Epoch: 14
2022-12-05 21:32:37,838 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4643842283297669, 'Total loss': 0.4643842283297669} | train loss {'Reaction outcome loss': 0.2528730505334613, 'Total loss': 0.2528730505334613}
2022-12-05 21:32:37,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:37,838 INFO:     Epoch: 15
2022-12-05 21:32:38,626 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4221846244551919, 'Total loss': 0.4221846244551919} | train loss {'Reaction outcome loss': 0.24235301941014856, 'Total loss': 0.24235301941014856}
2022-12-05 21:32:38,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:38,626 INFO:     Epoch: 16
2022-12-05 21:32:39,413 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4281552441587502, 'Total loss': 0.4281552441587502} | train loss {'Reaction outcome loss': 0.23531841248394506, 'Total loss': 0.23531841248394506}
2022-12-05 21:32:39,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:39,413 INFO:     Epoch: 17
2022-12-05 21:32:40,205 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43519448522817006, 'Total loss': 0.43519448522817006} | train loss {'Reaction outcome loss': 0.23120875241845726, 'Total loss': 0.23120875241845726}
2022-12-05 21:32:40,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:40,205 INFO:     Epoch: 18
2022-12-05 21:32:40,992 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43919382108883426, 'Total loss': 0.43919382108883426} | train loss {'Reaction outcome loss': 0.22911858918175462, 'Total loss': 0.22911858918175462}
2022-12-05 21:32:40,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:40,993 INFO:     Epoch: 19
2022-12-05 21:32:41,784 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43068614026362245, 'Total loss': 0.43068614026362245} | train loss {'Reaction outcome loss': 0.22552708669109384, 'Total loss': 0.22552708669109384}
2022-12-05 21:32:41,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:41,784 INFO:     Epoch: 20
2022-12-05 21:32:42,577 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4407042378390377, 'Total loss': 0.4407042378390377} | train loss {'Reaction outcome loss': 0.21752264890593556, 'Total loss': 0.21752264890593556}
2022-12-05 21:32:42,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:42,577 INFO:     Epoch: 21
2022-12-05 21:32:43,370 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4336050738665191, 'Total loss': 0.4336050738665191} | train loss {'Reaction outcome loss': 0.20798251123557826, 'Total loss': 0.20798251123557826}
2022-12-05 21:32:43,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:43,371 INFO:     Epoch: 22
2022-12-05 21:32:44,159 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45446761121804063, 'Total loss': 0.45446761121804063} | train loss {'Reaction outcome loss': 0.2017225362812942, 'Total loss': 0.2017225362812942}
2022-12-05 21:32:44,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:44,159 INFO:     Epoch: 23
2022-12-05 21:32:44,945 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43186623958701437, 'Total loss': 0.43186623958701437} | train loss {'Reaction outcome loss': 0.1988702576818616, 'Total loss': 0.1988702576818616}
2022-12-05 21:32:44,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:44,945 INFO:     Epoch: 24
2022-12-05 21:32:45,737 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44536694562570617, 'Total loss': 0.44536694562570617} | train loss {'Reaction outcome loss': 0.19442810327557447, 'Total loss': 0.19442810327557447}
2022-12-05 21:32:45,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:45,737 INFO:     Epoch: 25
2022-12-05 21:32:46,522 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44071301784027705, 'Total loss': 0.44071301784027705} | train loss {'Reaction outcome loss': 0.19207549684865755, 'Total loss': 0.19207549684865755}
2022-12-05 21:32:46,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:46,522 INFO:     Epoch: 26
2022-12-05 21:32:47,307 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4595013658770106, 'Total loss': 0.4595013658770106} | train loss {'Reaction outcome loss': 0.18708929986606243, 'Total loss': 0.18708929986606243}
2022-12-05 21:32:47,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:47,307 INFO:     Epoch: 27
2022-12-05 21:32:48,093 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45412941006096924, 'Total loss': 0.45412941006096924} | train loss {'Reaction outcome loss': 0.18604183055249304, 'Total loss': 0.18604183055249304}
2022-12-05 21:32:48,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:48,093 INFO:     Epoch: 28
2022-12-05 21:32:48,880 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4474511972882531, 'Total loss': 0.4474511972882531} | train loss {'Reaction outcome loss': 0.18052015694137286, 'Total loss': 0.18052015694137286}
2022-12-05 21:32:48,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:48,881 INFO:     Epoch: 29
2022-12-05 21:32:49,670 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46178590946576814, 'Total loss': 0.46178590946576814} | train loss {'Reaction outcome loss': 0.18026711203455775, 'Total loss': 0.18026711203455775}
2022-12-05 21:32:49,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:49,671 INFO:     Epoch: 30
2022-12-05 21:32:50,457 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45889766446568747, 'Total loss': 0.45889766446568747} | train loss {'Reaction outcome loss': 0.17498352487952362, 'Total loss': 0.17498352487952362}
2022-12-05 21:32:50,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:50,457 INFO:     Epoch: 31
2022-12-05 21:32:51,242 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4412393848496405, 'Total loss': 0.4412393848496405} | train loss {'Reaction outcome loss': 0.17006147999188256, 'Total loss': 0.17006147999188256}
2022-12-05 21:32:51,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:51,242 INFO:     Epoch: 32
2022-12-05 21:32:52,034 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4502252690832723, 'Total loss': 0.4502252690832723} | train loss {'Reaction outcome loss': 0.1663801411868107, 'Total loss': 0.1663801411868107}
2022-12-05 21:32:52,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:52,035 INFO:     Epoch: 33
2022-12-05 21:32:52,823 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4604816956614906, 'Total loss': 0.4604816956614906} | train loss {'Reaction outcome loss': 0.16907314144768695, 'Total loss': 0.16907314144768695}
2022-12-05 21:32:52,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:52,823 INFO:     Epoch: 34
2022-12-05 21:32:53,615 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4584888778626919, 'Total loss': 0.4584888778626919} | train loss {'Reaction outcome loss': 0.1659728650848272, 'Total loss': 0.1659728650848272}
2022-12-05 21:32:53,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:53,615 INFO:     Epoch: 35
2022-12-05 21:32:54,409 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4527324512600899, 'Total loss': 0.4527324512600899} | train loss {'Reaction outcome loss': 0.16400371267185038, 'Total loss': 0.16400371267185038}
2022-12-05 21:32:54,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:54,409 INFO:     Epoch: 36
2022-12-05 21:32:55,206 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.462177565659989, 'Total loss': 0.462177565659989} | train loss {'Reaction outcome loss': 0.16334534616695967, 'Total loss': 0.16334534616695967}
2022-12-05 21:32:55,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:55,207 INFO:     Epoch: 37
2022-12-05 21:32:56,009 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47470825436440384, 'Total loss': 0.47470825436440384} | train loss {'Reaction outcome loss': 0.15861321838576392, 'Total loss': 0.15861321838576392}
2022-12-05 21:32:56,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:56,009 INFO:     Epoch: 38
2022-12-05 21:32:56,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4728949730369178, 'Total loss': 0.4728949730369178} | train loss {'Reaction outcome loss': 0.15728851537991254, 'Total loss': 0.15728851537991254}
2022-12-05 21:32:56,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:56,807 INFO:     Epoch: 39
2022-12-05 21:32:57,600 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46559893001209607, 'Total loss': 0.46559893001209607} | train loss {'Reaction outcome loss': 0.15885497248064168, 'Total loss': 0.15885497248064168}
2022-12-05 21:32:57,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:57,601 INFO:     Epoch: 40
2022-12-05 21:32:58,402 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4690489647063342, 'Total loss': 0.4690489647063342} | train loss {'Reaction outcome loss': 0.15988168179958698, 'Total loss': 0.15988168179958698}
2022-12-05 21:32:58,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:58,403 INFO:     Epoch: 41
2022-12-05 21:32:59,199 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4704980846833099, 'Total loss': 0.4704980846833099} | train loss {'Reaction outcome loss': 0.15396720576684483, 'Total loss': 0.15396720576684483}
2022-12-05 21:32:59,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:59,200 INFO:     Epoch: 42
2022-12-05 21:32:59,998 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47780446064743126, 'Total loss': 0.47780446064743126} | train loss {'Reaction outcome loss': 0.15206354755440704, 'Total loss': 0.15206354755440704}
2022-12-05 21:32:59,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:32:59,998 INFO:     Epoch: 43
2022-12-05 21:33:00,795 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4807595346461643, 'Total loss': 0.4807595346461643} | train loss {'Reaction outcome loss': 0.15301474247519908, 'Total loss': 0.15301474247519908}
2022-12-05 21:33:00,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:00,796 INFO:     Epoch: 44
2022-12-05 21:33:01,593 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.486491245302287, 'Total loss': 0.486491245302287} | train loss {'Reaction outcome loss': 0.14958247522020388, 'Total loss': 0.14958247522020388}
2022-12-05 21:33:01,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:01,594 INFO:     Epoch: 45
2022-12-05 21:33:02,392 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.456670630723238, 'Total loss': 0.456670630723238} | train loss {'Reaction outcome loss': 0.15160940952697083, 'Total loss': 0.15160940952697083}
2022-12-05 21:33:02,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:02,393 INFO:     Epoch: 46
2022-12-05 21:33:03,194 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.469183989207853, 'Total loss': 0.469183989207853} | train loss {'Reaction outcome loss': 0.14672715203678197, 'Total loss': 0.14672715203678197}
2022-12-05 21:33:03,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:03,194 INFO:     Epoch: 47
2022-12-05 21:33:03,997 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47856770388104697, 'Total loss': 0.47856770388104697} | train loss {'Reaction outcome loss': 0.14251958922697947, 'Total loss': 0.14251958922697947}
2022-12-05 21:33:03,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:03,998 INFO:     Epoch: 48
2022-12-05 21:33:04,795 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48870552805337036, 'Total loss': 0.48870552805337036} | train loss {'Reaction outcome loss': 0.14281177345799048, 'Total loss': 0.14281177345799048}
2022-12-05 21:33:04,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:04,795 INFO:     Epoch: 49
2022-12-05 21:33:05,592 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47650085601278325, 'Total loss': 0.47650085601278325} | train loss {'Reaction outcome loss': 0.14616440992184013, 'Total loss': 0.14616440992184013}
2022-12-05 21:33:05,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:05,592 INFO:     Epoch: 50
2022-12-05 21:33:06,393 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4770101840523156, 'Total loss': 0.4770101840523156} | train loss {'Reaction outcome loss': 0.15420433255505178, 'Total loss': 0.15420433255505178}
2022-12-05 21:33:06,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:06,393 INFO:     Epoch: 51
2022-12-05 21:33:07,193 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47432548146356235, 'Total loss': 0.47432548146356235} | train loss {'Reaction outcome loss': 0.14419233265072712, 'Total loss': 0.14419233265072712}
2022-12-05 21:33:07,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:07,193 INFO:     Epoch: 52
2022-12-05 21:33:07,987 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4781307808377526, 'Total loss': 0.4781307808377526} | train loss {'Reaction outcome loss': 0.14790528283269722, 'Total loss': 0.14790528283269722}
2022-12-05 21:33:07,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:07,988 INFO:     Epoch: 53
2022-12-05 21:33:08,784 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46998015757311473, 'Total loss': 0.46998015757311473} | train loss {'Reaction outcome loss': 0.14581465332388033, 'Total loss': 0.14581465332388033}
2022-12-05 21:33:08,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:08,784 INFO:     Epoch: 54
2022-12-05 21:33:09,583 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47777201455425133, 'Total loss': 0.47777201455425133} | train loss {'Reaction outcome loss': 0.1512864632154947, 'Total loss': 0.1512864632154947}
2022-12-05 21:33:09,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:09,583 INFO:     Epoch: 55
2022-12-05 21:33:10,378 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46957889436320827, 'Total loss': 0.46957889436320827} | train loss {'Reaction outcome loss': 0.13671280899714783, 'Total loss': 0.13671280899714783}
2022-12-05 21:33:10,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:10,378 INFO:     Epoch: 56
2022-12-05 21:33:11,176 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4792660447684201, 'Total loss': 0.4792660447684201} | train loss {'Reaction outcome loss': 0.13344407672258585, 'Total loss': 0.13344407672258585}
2022-12-05 21:33:11,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:11,177 INFO:     Epoch: 57
2022-12-05 21:33:11,974 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4828460260548375, 'Total loss': 0.4828460260548375} | train loss {'Reaction outcome loss': 0.13490165800218157, 'Total loss': 0.13490165800218157}
2022-12-05 21:33:11,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:11,975 INFO:     Epoch: 58
2022-12-05 21:33:12,773 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46820822629061615, 'Total loss': 0.46820822629061615} | train loss {'Reaction outcome loss': 0.13352914902981114, 'Total loss': 0.13352914902981114}
2022-12-05 21:33:12,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:12,773 INFO:     Epoch: 59
2022-12-05 21:33:13,574 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48145027221603826, 'Total loss': 0.48145027221603826} | train loss {'Reaction outcome loss': 0.13510316335746966, 'Total loss': 0.13510316335746966}
2022-12-05 21:33:13,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:13,574 INFO:     Epoch: 60
2022-12-05 21:33:14,369 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47930610281499947, 'Total loss': 0.47930610281499947} | train loss {'Reaction outcome loss': 0.13513923850408208, 'Total loss': 0.13513923850408208}
2022-12-05 21:33:14,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:14,370 INFO:     Epoch: 61
2022-12-05 21:33:15,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4701510014181787, 'Total loss': 0.4701510014181787} | train loss {'Reaction outcome loss': 0.13593527827004673, 'Total loss': 0.13593527827004673}
2022-12-05 21:33:15,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:15,164 INFO:     Epoch: 62
2022-12-05 21:33:15,961 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4809756956317208, 'Total loss': 0.4809756956317208} | train loss {'Reaction outcome loss': 0.13919607395596562, 'Total loss': 0.13919607395596562}
2022-12-05 21:33:15,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:15,962 INFO:     Epoch: 63
2022-12-05 21:33:16,758 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46393150599165395, 'Total loss': 0.46393150599165395} | train loss {'Reaction outcome loss': 0.1313769553188491, 'Total loss': 0.1313769553188491}
2022-12-05 21:33:16,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:16,758 INFO:     Epoch: 64
2022-12-05 21:33:17,552 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46989623169330036, 'Total loss': 0.46989623169330036} | train loss {'Reaction outcome loss': 0.13357795791527038, 'Total loss': 0.13357795791527038}
2022-12-05 21:33:17,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:17,552 INFO:     Epoch: 65
2022-12-05 21:33:18,346 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4672368338162249, 'Total loss': 0.4672368338162249} | train loss {'Reaction outcome loss': 0.13371096013221317, 'Total loss': 0.13371096013221317}
2022-12-05 21:33:18,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:18,347 INFO:     Epoch: 66
2022-12-05 21:33:19,143 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4804515408521349, 'Total loss': 0.4804515408521349} | train loss {'Reaction outcome loss': 0.1264632759681292, 'Total loss': 0.1264632759681292}
2022-12-05 21:33:19,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:19,143 INFO:     Epoch: 67
2022-12-05 21:33:19,942 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.481510074978525, 'Total loss': 0.481510074978525} | train loss {'Reaction outcome loss': 0.13124570764435328, 'Total loss': 0.13124570764435328}
2022-12-05 21:33:19,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:19,942 INFO:     Epoch: 68
2022-12-05 21:33:20,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47216707501899113, 'Total loss': 0.47216707501899113} | train loss {'Reaction outcome loss': 0.13391424813175853, 'Total loss': 0.13391424813175853}
2022-12-05 21:33:20,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:20,740 INFO:     Epoch: 69
2022-12-05 21:33:21,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45844671909104695, 'Total loss': 0.45844671909104695} | train loss {'Reaction outcome loss': 0.12883336931610337, 'Total loss': 0.12883336931610337}
2022-12-05 21:33:21,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:21,535 INFO:     Epoch: 70
2022-12-05 21:33:22,337 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4793622243133458, 'Total loss': 0.4793622243133458} | train loss {'Reaction outcome loss': 0.12590527726122394, 'Total loss': 0.12590527726122394}
2022-12-05 21:33:22,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:22,337 INFO:     Epoch: 71
2022-12-05 21:33:23,132 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4668446233898232, 'Total loss': 0.4668446233898232} | train loss {'Reaction outcome loss': 0.12974733682839493, 'Total loss': 0.12974733682839493}
2022-12-05 21:33:23,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:23,132 INFO:     Epoch: 72
2022-12-05 21:33:23,926 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48375485329465434, 'Total loss': 0.48375485329465434} | train loss {'Reaction outcome loss': 0.12630703190703563, 'Total loss': 0.12630703190703563}
2022-12-05 21:33:23,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:23,926 INFO:     Epoch: 73
2022-12-05 21:33:24,720 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47309202125126665, 'Total loss': 0.47309202125126665} | train loss {'Reaction outcome loss': 0.12603289490708938, 'Total loss': 0.12603289490708938}
2022-12-05 21:33:24,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:24,720 INFO:     Epoch: 74
2022-12-05 21:33:25,514 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4892602623863654, 'Total loss': 0.4892602623863654} | train loss {'Reaction outcome loss': 0.12796101312300093, 'Total loss': 0.12796101312300093}
2022-12-05 21:33:25,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:25,515 INFO:     Epoch: 75
2022-12-05 21:33:26,309 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4806043782525442, 'Total loss': 0.4806043782525442} | train loss {'Reaction outcome loss': 0.12516349472971783, 'Total loss': 0.12516349472971783}
2022-12-05 21:33:26,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:26,311 INFO:     Epoch: 76
2022-12-05 21:33:27,105 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47839304262941534, 'Total loss': 0.47839304262941534} | train loss {'Reaction outcome loss': 0.12481042961797371, 'Total loss': 0.12481042961797371}
2022-12-05 21:33:27,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:27,105 INFO:     Epoch: 77
2022-12-05 21:33:27,900 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.483718525279652, 'Total loss': 0.483718525279652} | train loss {'Reaction outcome loss': 0.1265543221495103, 'Total loss': 0.1265543221495103}
2022-12-05 21:33:27,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:27,900 INFO:     Epoch: 78
2022-12-05 21:33:28,694 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4735987260937691, 'Total loss': 0.4735987260937691} | train loss {'Reaction outcome loss': 0.12203199211941647, 'Total loss': 0.12203199211941647}
2022-12-05 21:33:28,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:28,695 INFO:     Epoch: 79
2022-12-05 21:33:29,488 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4859150133349679, 'Total loss': 0.4859150133349679} | train loss {'Reaction outcome loss': 0.12170021727243778, 'Total loss': 0.12170021727243778}
2022-12-05 21:33:29,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:29,489 INFO:     Epoch: 80
2022-12-05 21:33:30,283 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4755543267185038, 'Total loss': 0.4755543267185038} | train loss {'Reaction outcome loss': 0.12468849590070817, 'Total loss': 0.12468849590070817}
2022-12-05 21:33:30,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:30,284 INFO:     Epoch: 81
2022-12-05 21:33:31,081 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48087197000330145, 'Total loss': 0.48087197000330145} | train loss {'Reaction outcome loss': 0.12317344826669244, 'Total loss': 0.12317344826669244}
2022-12-05 21:33:31,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:31,081 INFO:     Epoch: 82
2022-12-05 21:33:31,875 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4740426516668363, 'Total loss': 0.4740426516668363} | train loss {'Reaction outcome loss': 0.12033348989782304, 'Total loss': 0.12033348989782304}
2022-12-05 21:33:31,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:31,875 INFO:     Epoch: 83
2022-12-05 21:33:32,670 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4765518629415469, 'Total loss': 0.4765518629415469} | train loss {'Reaction outcome loss': 0.12019193241078603, 'Total loss': 0.12019193241078603}
2022-12-05 21:33:32,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:32,671 INFO:     Epoch: 84
2022-12-05 21:33:33,466 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4719986455007033, 'Total loss': 0.4719986455007033} | train loss {'Reaction outcome loss': 0.12418442452891998, 'Total loss': 0.12418442452891998}
2022-12-05 21:33:33,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:33,466 INFO:     Epoch: 85
2022-12-05 21:33:34,265 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47393061356111005, 'Total loss': 0.47393061356111005} | train loss {'Reaction outcome loss': 0.12140411205037388, 'Total loss': 0.12140411205037388}
2022-12-05 21:33:34,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:34,266 INFO:     Epoch: 86
2022-12-05 21:33:35,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4763230898163535, 'Total loss': 0.4763230898163535} | train loss {'Reaction outcome loss': 0.12038701122201534, 'Total loss': 0.12038701122201534}
2022-12-05 21:33:35,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:35,061 INFO:     Epoch: 87
2022-12-05 21:33:35,860 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4974902036853812, 'Total loss': 0.4974902036853812} | train loss {'Reaction outcome loss': 0.11798568339905276, 'Total loss': 0.11798568339905276}
2022-12-05 21:33:35,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:35,860 INFO:     Epoch: 88
2022-12-05 21:33:36,654 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4806258265267719, 'Total loss': 0.4806258265267719} | train loss {'Reaction outcome loss': 0.11937093928735326, 'Total loss': 0.11937093928735326}
2022-12-05 21:33:36,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:36,654 INFO:     Epoch: 89
2022-12-05 21:33:37,448 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47860808027061547, 'Total loss': 0.47860808027061547} | train loss {'Reaction outcome loss': 0.11890740136084287, 'Total loss': 0.11890740136084287}
2022-12-05 21:33:37,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:37,448 INFO:     Epoch: 90
2022-12-05 21:33:38,245 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46635458432137966, 'Total loss': 0.46635458432137966} | train loss {'Reaction outcome loss': 0.11965254915176857, 'Total loss': 0.11965254915176857}
2022-12-05 21:33:38,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:38,245 INFO:     Epoch: 91
2022-12-05 21:33:39,045 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4707878001711585, 'Total loss': 0.4707878001711585} | train loss {'Reaction outcome loss': 0.12171879496900478, 'Total loss': 0.12171879496900478}
2022-12-05 21:33:39,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:39,045 INFO:     Epoch: 92
2022-12-05 21:33:39,842 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48361005701801996, 'Total loss': 0.48361005701801996} | train loss {'Reaction outcome loss': 0.11933962391078592, 'Total loss': 0.11933962391078592}
2022-12-05 21:33:39,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:39,842 INFO:     Epoch: 93
2022-12-05 21:33:40,637 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4827269485050982, 'Total loss': 0.4827269485050982} | train loss {'Reaction outcome loss': 0.118612848919805, 'Total loss': 0.118612848919805}
2022-12-05 21:33:40,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:40,638 INFO:     Epoch: 94
2022-12-05 21:33:41,426 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4802098362283273, 'Total loss': 0.4802098362283273} | train loss {'Reaction outcome loss': 0.1189001351293282, 'Total loss': 0.1189001351293282}
2022-12-05 21:33:41,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:41,426 INFO:     Epoch: 95
2022-12-05 21:33:42,211 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4729457348585129, 'Total loss': 0.4729457348585129} | train loss {'Reaction outcome loss': 0.11772891124974379, 'Total loss': 0.11772891124974379}
2022-12-05 21:33:42,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:42,212 INFO:     Epoch: 96
2022-12-05 21:33:42,996 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4692964611405676, 'Total loss': 0.4692964611405676} | train loss {'Reaction outcome loss': 0.1166374893474434, 'Total loss': 0.1166374893474434}
2022-12-05 21:33:42,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:42,996 INFO:     Epoch: 97
2022-12-05 21:33:43,783 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47021872363984585, 'Total loss': 0.47021872363984585} | train loss {'Reaction outcome loss': 0.12067710445545282, 'Total loss': 0.12067710445545282}
2022-12-05 21:33:43,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:43,783 INFO:     Epoch: 98
2022-12-05 21:33:44,569 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4734653820368377, 'Total loss': 0.4734653820368377} | train loss {'Reaction outcome loss': 0.12051587316173652, 'Total loss': 0.12051587316173652}
2022-12-05 21:33:44,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:44,569 INFO:     Epoch: 99
2022-12-05 21:33:45,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45740089616314933, 'Total loss': 0.45740089616314933} | train loss {'Reaction outcome loss': 0.11926780727801294, 'Total loss': 0.11926780727801294}
2022-12-05 21:33:45,357 INFO:     Best model found after epoch 10 of 100.
2022-12-05 21:33:45,358 INFO:   Done with stage: TRAINING
2022-12-05 21:33:45,358 INFO:   Starting stage: EVALUATION
2022-12-05 21:33:45,482 INFO:   Done with stage: EVALUATION
2022-12-05 21:33:45,482 INFO: Done with stage: RUNNING SPLITS
2022-12-05 21:33:45,483 INFO: Starting stage: COMPUTE METRICS
2022-12-05 21:33:46,636 INFO: Done with stage: COMPUTE METRICS
2022-12-05 21:33:46,636 INFO: Starting stage: EXPORT RESULTS
2022-12-05 21:33:46,654 INFO:   Final results averaged over 50 folds: 
2022-12-05 21:33:46,657 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.175819           NaN  0.304297       NaN
2022-12-05 21:33:48,337 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-05 21:33:48,343 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-05 21:33:48,344 DEBUG:   interactive is False
2022-12-05 21:33:48,344 DEBUG:   platform is linux
2022-12-05 21:33:48,344 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-05 21:33:48,514 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-05 21:33:48,516 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-05 21:33:48,951 DEBUG:   Loaded backend agg version unknown.
2022-12-05 21:33:48,953 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 21:33:48,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:48,956 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,956 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 21:33:48,992 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-05 21:33:48,992 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,993 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 21:33:48,994 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:48,995 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:48,995 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 21:33:49,003 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:49,004 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 21:33:49,006 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 21:33:49,006 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 21:33:49,305 INFO: Done with stage: EXPORT RESULTS
2022-12-05 21:33:49,305 INFO: Starting stage: SAVE MODEL
2022-12-05 21:33:49,384 INFO: Done with stage: SAVE MODEL
2022-12-05 21:33:49,384 INFO: Wall time for program:  4013.38 seconds
