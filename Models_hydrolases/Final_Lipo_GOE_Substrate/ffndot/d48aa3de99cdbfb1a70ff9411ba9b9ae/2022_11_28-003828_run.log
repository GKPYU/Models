2022-11-28 01:41:40,495 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/d48aa3de99cdbfb1a70ff9411ba9b9ae/2022_11_28-003828",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.0015553873022161448,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 01:41:40,502 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 01:41:40,508 INFO:   Creating esm representation model
2022-11-28 01:41:40,508 INFO:   Done esm representation model
2022-11-28 01:41:40,508 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 01:41:40,508 INFO: Starting stage: BUILDING DATASET
2022-11-28 01:41:40,561 INFO: Done with stage: BUILDING DATASET
2022-11-28 01:41:40,562 INFO: Starting stage: FEATURIZING DATA
2022-11-28 01:41:40,562 INFO:   Featurizing proteins
2022-11-28 01:41:40,563 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 01:41:40,583 INFO:   Loaded feature cache of size 204
2022-11-28 01:41:40,584 INFO:   Starting to pool ESM Embeddings
2022-11-28 01:41:40,682 INFO:   Featurizing molecules
2022-11-28 01:41:40,704 INFO: Done with stage: FEATURIZING DATA
2022-11-28 01:41:40,704 INFO: Starting stage: RUNNING SPLITS
2022-11-28 01:41:40,713 INFO:   Leaving out SEQ value Fold_0
2022-11-28 01:41:40,727 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:41:40,727 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:41:41,380 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:41:41,380 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:41:41,447 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:41:41,448 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:41:41,448 INFO:     No hyperparam tuning for this model
2022-11-28 01:41:41,448 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:41:41,448 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:41:41,449 INFO:     None feature selector for col prot
2022-11-28 01:41:41,449 INFO:     None feature selector for col prot
2022-11-28 01:41:41,449 INFO:     None feature selector for col prot
2022-11-28 01:41:41,449 INFO:     None feature selector for col chem
2022-11-28 01:41:41,449 INFO:     None feature selector for col chem
2022-11-28 01:41:41,450 INFO:     None feature selector for col chem
2022-11-28 01:41:41,450 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:41:41,450 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:41:41,451 INFO:     Number of params in model 169741
2022-11-28 01:41:41,451 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:41:41,451 INFO:   Starting stage: TRAINING
2022-11-28 01:41:43,578 INFO:     Val loss before train {'Reaction outcome loss': 1.0253517003946526, 'Total loss': 1.0253517003946526}
2022-11-28 01:41:43,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:43,579 INFO:     Epoch: 0
2022-11-28 01:41:44,314 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.546245141084804, 'Total loss': 0.546245141084804} | train loss {'Reaction outcome loss': 0.6367304502207725, 'Total loss': 0.6367304502207725}
2022-11-28 01:41:44,314 INFO:     Found new best model at epoch 0
2022-11-28 01:41:44,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:44,315 INFO:     Epoch: 1
2022-11-28 01:41:45,046 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4786093820666158, 'Total loss': 0.4786093820666158} | train loss {'Reaction outcome loss': 0.4972106401549011, 'Total loss': 0.4972106401549011}
2022-11-28 01:41:45,046 INFO:     Found new best model at epoch 1
2022-11-28 01:41:45,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:45,047 INFO:     Epoch: 2
2022-11-28 01:41:45,782 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4922351033188576, 'Total loss': 0.4922351033188576} | train loss {'Reaction outcome loss': 0.47504984679036455, 'Total loss': 0.47504984679036455}
2022-11-28 01:41:45,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:45,782 INFO:     Epoch: 3
2022-11-28 01:41:46,518 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4722981511853462, 'Total loss': 0.4722981511853462} | train loss {'Reaction outcome loss': 0.4363348553659486, 'Total loss': 0.4363348553659486}
2022-11-28 01:41:46,518 INFO:     Found new best model at epoch 3
2022-11-28 01:41:46,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:46,519 INFO:     Epoch: 4
2022-11-28 01:41:47,253 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4767268688179726, 'Total loss': 0.4767268688179726} | train loss {'Reaction outcome loss': 0.4237859462861155, 'Total loss': 0.4237859462861155}
2022-11-28 01:41:47,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:47,253 INFO:     Epoch: 5
2022-11-28 01:41:47,991 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4744954757219137, 'Total loss': 0.4744954757219137} | train loss {'Reaction outcome loss': 0.40903744681692517, 'Total loss': 0.40903744681692517}
2022-11-28 01:41:47,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:47,992 INFO:     Epoch: 6
2022-11-28 01:41:48,729 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4439254746187565, 'Total loss': 0.4439254746187565} | train loss {'Reaction outcome loss': 0.41491366153369186, 'Total loss': 0.41491366153369186}
2022-11-28 01:41:48,729 INFO:     Found new best model at epoch 6
2022-11-28 01:41:48,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:48,730 INFO:     Epoch: 7
2022-11-28 01:41:49,462 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47567975174549015, 'Total loss': 0.47567975174549015} | train loss {'Reaction outcome loss': 0.39933788061874814, 'Total loss': 0.39933788061874814}
2022-11-28 01:41:49,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:49,462 INFO:     Epoch: 8
2022-11-28 01:41:50,195 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45322513129822045, 'Total loss': 0.45322513129822045} | train loss {'Reaction outcome loss': 0.39208443817056593, 'Total loss': 0.39208443817056593}
2022-11-28 01:41:50,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:50,196 INFO:     Epoch: 9
2022-11-28 01:41:50,935 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44182686750278916, 'Total loss': 0.44182686750278916} | train loss {'Reaction outcome loss': 0.38950535322188357, 'Total loss': 0.38950535322188357}
2022-11-28 01:41:50,935 INFO:     Found new best model at epoch 9
2022-11-28 01:41:50,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:50,936 INFO:     Epoch: 10
2022-11-28 01:41:51,669 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45803278511346773, 'Total loss': 0.45803278511346773} | train loss {'Reaction outcome loss': 0.3834971362633295, 'Total loss': 0.3834971362633295}
2022-11-28 01:41:51,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:51,669 INFO:     Epoch: 11
2022-11-28 01:41:52,404 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4491752250943073, 'Total loss': 0.4491752250943073} | train loss {'Reaction outcome loss': 0.38048152827092857, 'Total loss': 0.38048152827092857}
2022-11-28 01:41:52,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:52,405 INFO:     Epoch: 12
2022-11-28 01:41:53,147 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4439032278781713, 'Total loss': 0.4439032278781713} | train loss {'Reaction outcome loss': 0.3749213560682828, 'Total loss': 0.3749213560682828}
2022-11-28 01:41:53,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:53,147 INFO:     Epoch: 13
2022-11-28 01:41:53,892 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4927597233029299, 'Total loss': 0.4927597233029299} | train loss {'Reaction outcome loss': 0.37280537414013365, 'Total loss': 0.37280537414013365}
2022-11-28 01:41:53,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:53,892 INFO:     Epoch: 14
2022-11-28 01:41:54,629 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44083965483099913, 'Total loss': 0.44083965483099913} | train loss {'Reaction outcome loss': 0.3663288046468477, 'Total loss': 0.3663288046468477}
2022-11-28 01:41:54,629 INFO:     Found new best model at epoch 14
2022-11-28 01:41:54,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:54,630 INFO:     Epoch: 15
2022-11-28 01:41:55,370 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43049341093662175, 'Total loss': 0.43049341093662175} | train loss {'Reaction outcome loss': 0.3744855863271189, 'Total loss': 0.3744855863271189}
2022-11-28 01:41:55,370 INFO:     Found new best model at epoch 15
2022-11-28 01:41:55,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:55,371 INFO:     Epoch: 16
2022-11-28 01:41:56,105 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43078657568887224, 'Total loss': 0.43078657568887224} | train loss {'Reaction outcome loss': 0.37611301444837303, 'Total loss': 0.37611301444837303}
2022-11-28 01:41:56,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:56,106 INFO:     Epoch: 17
2022-11-28 01:41:56,843 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43240908169469167, 'Total loss': 0.43240908169469167} | train loss {'Reaction outcome loss': 0.3561942097654597, 'Total loss': 0.3561942097654597}
2022-11-28 01:41:56,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:56,843 INFO:     Epoch: 18
2022-11-28 01:41:57,575 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42693734966045205, 'Total loss': 0.42693734966045205} | train loss {'Reaction outcome loss': 0.3543091425214146, 'Total loss': 0.3543091425214146}
2022-11-28 01:41:57,576 INFO:     Found new best model at epoch 18
2022-11-28 01:41:57,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:57,576 INFO:     Epoch: 19
2022-11-28 01:41:58,312 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44214648736077683, 'Total loss': 0.44214648736077683} | train loss {'Reaction outcome loss': 0.3600929841765615, 'Total loss': 0.3600929841765615}
2022-11-28 01:41:58,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:58,312 INFO:     Epoch: 20
2022-11-28 01:41:59,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42556665352610656, 'Total loss': 0.42556665352610656} | train loss {'Reaction outcome loss': 0.36551551966637863, 'Total loss': 0.36551551966637863}
2022-11-28 01:41:59,047 INFO:     Found new best model at epoch 20
2022-11-28 01:41:59,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:59,048 INFO:     Epoch: 21
2022-11-28 01:41:59,784 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42566161758677906, 'Total loss': 0.42566161758677906} | train loss {'Reaction outcome loss': 0.3441704102776578, 'Total loss': 0.3441704102776578}
2022-11-28 01:41:59,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:59,784 INFO:     Epoch: 22
2022-11-28 01:42:00,517 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4393074176339216, 'Total loss': 0.4393074176339216} | train loss {'Reaction outcome loss': 0.3499529790133238, 'Total loss': 0.3499529790133238}
2022-11-28 01:42:00,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:00,518 INFO:     Epoch: 23
2022-11-28 01:42:01,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4647714348379956, 'Total loss': 0.4647714348379956} | train loss {'Reaction outcome loss': 0.3438651739451729, 'Total loss': 0.3438651739451729}
2022-11-28 01:42:01,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:01,254 INFO:     Epoch: 24
2022-11-28 01:42:01,988 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4056155698937039, 'Total loss': 0.4056155698937039} | train loss {'Reaction outcome loss': 0.34338276995132205, 'Total loss': 0.34338276995132205}
2022-11-28 01:42:01,988 INFO:     Found new best model at epoch 24
2022-11-28 01:42:01,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:01,989 INFO:     Epoch: 25
2022-11-28 01:42:02,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4532918524603511, 'Total loss': 0.4532918524603511} | train loss {'Reaction outcome loss': 0.3409319507171873, 'Total loss': 0.3409319507171873}
2022-11-28 01:42:02,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:02,725 INFO:     Epoch: 26
2022-11-28 01:42:03,459 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4515857027713643, 'Total loss': 0.4515857027713643} | train loss {'Reaction outcome loss': 0.34059515277870367, 'Total loss': 0.34059515277870367}
2022-11-28 01:42:03,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:03,459 INFO:     Epoch: 27
2022-11-28 01:42:04,194 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4184699820917706, 'Total loss': 0.4184699820917706} | train loss {'Reaction outcome loss': 0.34685801326862126, 'Total loss': 0.34685801326862126}
2022-11-28 01:42:04,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:04,194 INFO:     Epoch: 28
2022-11-28 01:42:04,924 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4104656164729318, 'Total loss': 0.4104656164729318} | train loss {'Reaction outcome loss': 0.3339703242889926, 'Total loss': 0.3339703242889926}
2022-11-28 01:42:04,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:04,924 INFO:     Epoch: 29
2022-11-28 01:42:05,659 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4324750973041667, 'Total loss': 0.4324750973041667} | train loss {'Reaction outcome loss': 0.3412438671364159, 'Total loss': 0.3412438671364159}
2022-11-28 01:42:05,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:05,659 INFO:     Epoch: 30
2022-11-28 01:42:06,394 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43249062500720803, 'Total loss': 0.43249062500720803} | train loss {'Reaction outcome loss': 0.32814028269809775, 'Total loss': 0.32814028269809775}
2022-11-28 01:42:06,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:06,394 INFO:     Epoch: 31
2022-11-28 01:42:07,128 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.435354147886121, 'Total loss': 0.435354147886121} | train loss {'Reaction outcome loss': 0.33128763130698047, 'Total loss': 0.33128763130698047}
2022-11-28 01:42:07,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:07,128 INFO:     Epoch: 32
2022-11-28 01:42:07,863 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44987608215143515, 'Total loss': 0.44987608215143515} | train loss {'Reaction outcome loss': 0.33535856118456264, 'Total loss': 0.33535856118456264}
2022-11-28 01:42:07,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:07,863 INFO:     Epoch: 33
2022-11-28 01:42:08,597 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43760676370110624, 'Total loss': 0.43760676370110624} | train loss {'Reaction outcome loss': 0.33829293928307586, 'Total loss': 0.33829293928307586}
2022-11-28 01:42:08,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:08,597 INFO:     Epoch: 34
2022-11-28 01:42:09,331 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4247884282539057, 'Total loss': 0.4247884282539057} | train loss {'Reaction outcome loss': 0.32954391409627726, 'Total loss': 0.32954391409627726}
2022-11-28 01:42:09,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:09,331 INFO:     Epoch: 35
2022-11-28 01:42:10,062 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42069630324840546, 'Total loss': 0.42069630324840546} | train loss {'Reaction outcome loss': 0.3329175571437742, 'Total loss': 0.3329175571437742}
2022-11-28 01:42:10,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:10,062 INFO:     Epoch: 36
2022-11-28 01:42:10,795 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4319731548081997, 'Total loss': 0.4319731548081997} | train loss {'Reaction outcome loss': 0.3284707769568338, 'Total loss': 0.3284707769568338}
2022-11-28 01:42:10,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:10,796 INFO:     Epoch: 37
2022-11-28 01:42:11,534 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41861870884895325, 'Total loss': 0.41861870884895325} | train loss {'Reaction outcome loss': 0.33268537448688607, 'Total loss': 0.33268537448688607}
2022-11-28 01:42:11,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:11,534 INFO:     Epoch: 38
2022-11-28 01:42:12,272 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44221673559310826, 'Total loss': 0.44221673559310826} | train loss {'Reaction outcome loss': 0.33086783090820077, 'Total loss': 0.33086783090820077}
2022-11-28 01:42:12,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:12,272 INFO:     Epoch: 39
2022-11-28 01:42:13,004 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4454048646743907, 'Total loss': 0.4454048646743907} | train loss {'Reaction outcome loss': 0.3171485536960793, 'Total loss': 0.3171485536960793}
2022-11-28 01:42:13,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:13,004 INFO:     Epoch: 40
2022-11-28 01:42:13,740 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4269897968963135, 'Total loss': 0.4269897968963135} | train loss {'Reaction outcome loss': 0.3258638508068245, 'Total loss': 0.3258638508068245}
2022-11-28 01:42:13,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:13,740 INFO:     Epoch: 41
2022-11-28 01:42:14,476 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4263864190772522, 'Total loss': 0.4263864190772522} | train loss {'Reaction outcome loss': 0.3345082387114402, 'Total loss': 0.3345082387114402}
2022-11-28 01:42:14,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:14,476 INFO:     Epoch: 42
2022-11-28 01:42:15,214 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43941097342690755, 'Total loss': 0.43941097342690755} | train loss {'Reaction outcome loss': 0.31523662920064127, 'Total loss': 0.31523662920064127}
2022-11-28 01:42:15,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:15,214 INFO:     Epoch: 43
2022-11-28 01:42:15,951 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40639370125393537, 'Total loss': 0.40639370125393537} | train loss {'Reaction outcome loss': 0.3185639665385739, 'Total loss': 0.3185639665385739}
2022-11-28 01:42:15,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:15,951 INFO:     Epoch: 44
2022-11-28 01:42:16,691 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4780987511540568, 'Total loss': 0.4780987511540568} | train loss {'Reaction outcome loss': 0.31971724361914106, 'Total loss': 0.31971724361914106}
2022-11-28 01:42:16,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:16,691 INFO:     Epoch: 45
2022-11-28 01:42:17,426 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.430894632325616, 'Total loss': 0.430894632325616} | train loss {'Reaction outcome loss': 0.324026867044998, 'Total loss': 0.324026867044998}
2022-11-28 01:42:17,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:17,427 INFO:     Epoch: 46
2022-11-28 01:42:18,169 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44366454350393875, 'Total loss': 0.44366454350393875} | train loss {'Reaction outcome loss': 0.320902642809221, 'Total loss': 0.320902642809221}
2022-11-28 01:42:18,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:18,169 INFO:     Epoch: 47
2022-11-28 01:42:18,906 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4412227780666462, 'Total loss': 0.4412227780666462} | train loss {'Reaction outcome loss': 0.326537524624804, 'Total loss': 0.326537524624804}
2022-11-28 01:42:18,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:18,907 INFO:     Epoch: 48
2022-11-28 01:42:19,647 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4220068160184594, 'Total loss': 0.4220068160184594} | train loss {'Reaction outcome loss': 0.3176141383401195, 'Total loss': 0.3176141383401195}
2022-11-28 01:42:19,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:19,647 INFO:     Epoch: 49
2022-11-28 01:42:20,388 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41681738371072813, 'Total loss': 0.41681738371072813} | train loss {'Reaction outcome loss': 0.31924608071930094, 'Total loss': 0.31924608071930094}
2022-11-28 01:42:20,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:20,389 INFO:     Epoch: 50
2022-11-28 01:42:21,127 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41376809221367505, 'Total loss': 0.41376809221367505} | train loss {'Reaction outcome loss': 0.3223515696457175, 'Total loss': 0.3223515696457175}
2022-11-28 01:42:21,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:21,127 INFO:     Epoch: 51
2022-11-28 01:42:21,868 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42023169128007665, 'Total loss': 0.42023169128007665} | train loss {'Reaction outcome loss': 0.3188522443724949, 'Total loss': 0.3188522443724949}
2022-11-28 01:42:21,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:21,868 INFO:     Epoch: 52
2022-11-28 01:42:22,607 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45505271228246913, 'Total loss': 0.45505271228246913} | train loss {'Reaction outcome loss': 0.31358211173019446, 'Total loss': 0.31358211173019446}
2022-11-28 01:42:22,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:22,608 INFO:     Epoch: 53
2022-11-28 01:42:23,343 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42634556737057, 'Total loss': 0.42634556737057} | train loss {'Reaction outcome loss': 0.3254185451698474, 'Total loss': 0.3254185451698474}
2022-11-28 01:42:23,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:23,343 INFO:     Epoch: 54
2022-11-28 01:42:24,077 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4363427470589793, 'Total loss': 0.4363427470589793} | train loss {'Reaction outcome loss': 0.31302409341222925, 'Total loss': 0.31302409341222925}
2022-11-28 01:42:24,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:24,078 INFO:     Epoch: 55
2022-11-28 01:42:24,819 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4350070832080619, 'Total loss': 0.4350070832080619} | train loss {'Reaction outcome loss': 0.3128030694044027, 'Total loss': 0.3128030694044027}
2022-11-28 01:42:24,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:24,819 INFO:     Epoch: 56
2022-11-28 01:42:25,562 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4243893668402073, 'Total loss': 0.4243893668402073} | train loss {'Reaction outcome loss': 0.31811694522983713, 'Total loss': 0.31811694522983713}
2022-11-28 01:42:25,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:25,562 INFO:     Epoch: 57
2022-11-28 01:42:26,307 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.417623822425687, 'Total loss': 0.417623822425687} | train loss {'Reaction outcome loss': 0.3148076519003657, 'Total loss': 0.3148076519003657}
2022-11-28 01:42:26,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:26,307 INFO:     Epoch: 58
2022-11-28 01:42:27,047 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4471292367508245, 'Total loss': 0.4471292367508245} | train loss {'Reaction outcome loss': 0.31037818274048506, 'Total loss': 0.31037818274048506}
2022-11-28 01:42:27,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:27,047 INFO:     Epoch: 59
2022-11-28 01:42:27,787 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4421237242776294, 'Total loss': 0.4421237242776294} | train loss {'Reaction outcome loss': 0.3155459308172347, 'Total loss': 0.3155459308172347}
2022-11-28 01:42:27,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:27,787 INFO:     Epoch: 60
2022-11-28 01:42:28,525 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4433872953577097, 'Total loss': 0.4433872953577097} | train loss {'Reaction outcome loss': 0.3151359045420025, 'Total loss': 0.3151359045420025}
2022-11-28 01:42:28,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:28,526 INFO:     Epoch: 61
2022-11-28 01:42:29,267 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4342677527388861, 'Total loss': 0.4342677527388861} | train loss {'Reaction outcome loss': 0.31717307425913266, 'Total loss': 0.31717307425913266}
2022-11-28 01:42:29,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:29,267 INFO:     Epoch: 62
2022-11-28 01:42:30,009 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4802104608957158, 'Total loss': 0.4802104608957158} | train loss {'Reaction outcome loss': 0.31401249821313093, 'Total loss': 0.31401249821313093}
2022-11-28 01:42:30,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:30,009 INFO:     Epoch: 63
2022-11-28 01:42:30,746 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4150302725475888, 'Total loss': 0.4150302725475888} | train loss {'Reaction outcome loss': 0.3154490286881318, 'Total loss': 0.3154490286881318}
2022-11-28 01:42:30,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:30,747 INFO:     Epoch: 64
2022-11-28 01:42:31,483 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41944338381290436, 'Total loss': 0.41944338381290436} | train loss {'Reaction outcome loss': 0.31989616126615983, 'Total loss': 0.31989616126615983}
2022-11-28 01:42:31,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:31,483 INFO:     Epoch: 65
2022-11-28 01:42:32,221 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43378705791262695, 'Total loss': 0.43378705791262695} | train loss {'Reaction outcome loss': 0.30822398860129663, 'Total loss': 0.30822398860129663}
2022-11-28 01:42:32,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:32,221 INFO:     Epoch: 66
2022-11-28 01:42:32,958 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4289208990196849, 'Total loss': 0.4289208990196849} | train loss {'Reaction outcome loss': 0.3139504252581811, 'Total loss': 0.3139504252581811}
2022-11-28 01:42:32,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:32,958 INFO:     Epoch: 67
2022-11-28 01:42:33,697 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42259555569914886, 'Total loss': 0.42259555569914886} | train loss {'Reaction outcome loss': 0.3087344755586542, 'Total loss': 0.3087344755586542}
2022-11-28 01:42:33,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:33,697 INFO:     Epoch: 68
2022-11-28 01:42:34,436 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4498863085064777, 'Total loss': 0.4498863085064777} | train loss {'Reaction outcome loss': 0.3076879946118007, 'Total loss': 0.3076879946118007}
2022-11-28 01:42:34,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:34,437 INFO:     Epoch: 69
2022-11-28 01:42:35,176 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4155421555042267, 'Total loss': 0.4155421555042267} | train loss {'Reaction outcome loss': 0.30497348439864447, 'Total loss': 0.30497348439864447}
2022-11-28 01:42:35,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:35,176 INFO:     Epoch: 70
2022-11-28 01:42:35,917 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41085399271443834, 'Total loss': 0.41085399271443834} | train loss {'Reaction outcome loss': 0.3036099033216473, 'Total loss': 0.3036099033216473}
2022-11-28 01:42:35,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:35,917 INFO:     Epoch: 71
2022-11-28 01:42:36,653 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4169518303039462, 'Total loss': 0.4169518303039462} | train loss {'Reaction outcome loss': 0.30855978381071913, 'Total loss': 0.30855978381071913}
2022-11-28 01:42:36,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:36,654 INFO:     Epoch: 72
2022-11-28 01:42:37,396 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.426819953461026, 'Total loss': 0.426819953461026} | train loss {'Reaction outcome loss': 0.3064843671793332, 'Total loss': 0.3064843671793332}
2022-11-28 01:42:37,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:37,396 INFO:     Epoch: 73
2022-11-28 01:42:38,136 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4134399703768797, 'Total loss': 0.4134399703768797} | train loss {'Reaction outcome loss': 0.31433604184354913, 'Total loss': 0.31433604184354913}
2022-11-28 01:42:38,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:38,136 INFO:     Epoch: 74
2022-11-28 01:42:38,876 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42185314831345583, 'Total loss': 0.42185314831345583} | train loss {'Reaction outcome loss': 0.3065848207772999, 'Total loss': 0.3065848207772999}
2022-11-28 01:42:38,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:38,877 INFO:     Epoch: 75
2022-11-28 01:42:39,613 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4271489749121111, 'Total loss': 0.4271489749121111} | train loss {'Reaction outcome loss': 0.30494502507394455, 'Total loss': 0.30494502507394455}
2022-11-28 01:42:39,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:39,613 INFO:     Epoch: 76
2022-11-28 01:42:40,350 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4133780667948168, 'Total loss': 0.4133780667948168} | train loss {'Reaction outcome loss': 0.3084241017760312, 'Total loss': 0.3084241017760312}
2022-11-28 01:42:40,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:40,350 INFO:     Epoch: 77
2022-11-28 01:42:41,087 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42837336520816005, 'Total loss': 0.42837336520816005} | train loss {'Reaction outcome loss': 0.30701887369400166, 'Total loss': 0.30701887369400166}
2022-11-28 01:42:41,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:41,087 INFO:     Epoch: 78
2022-11-28 01:42:41,826 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4190225303173065, 'Total loss': 0.4190225303173065} | train loss {'Reaction outcome loss': 0.3060735430965414, 'Total loss': 0.3060735430965414}
2022-11-28 01:42:41,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:41,826 INFO:     Epoch: 79
2022-11-28 01:42:42,569 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40692566785701484, 'Total loss': 0.40692566785701484} | train loss {'Reaction outcome loss': 0.30675318479904384, 'Total loss': 0.30675318479904384}
2022-11-28 01:42:42,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:42,569 INFO:     Epoch: 80
2022-11-28 01:42:43,311 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40280714942965395, 'Total loss': 0.40280714942965395} | train loss {'Reaction outcome loss': 0.3024442647507445, 'Total loss': 0.3024442647507445}
2022-11-28 01:42:43,311 INFO:     Found new best model at epoch 80
2022-11-28 01:42:43,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:43,312 INFO:     Epoch: 81
2022-11-28 01:42:44,055 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4088689466548521, 'Total loss': 0.4088689466548521} | train loss {'Reaction outcome loss': 0.31080120870629785, 'Total loss': 0.31080120870629785}
2022-11-28 01:42:44,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:44,056 INFO:     Epoch: 82
2022-11-28 01:42:44,799 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41205110210318896, 'Total loss': 0.41205110210318896} | train loss {'Reaction outcome loss': 0.3115190614595032, 'Total loss': 0.3115190614595032}
2022-11-28 01:42:44,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:44,799 INFO:     Epoch: 83
2022-11-28 01:42:45,539 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4253206221863281, 'Total loss': 0.4253206221863281} | train loss {'Reaction outcome loss': 0.3063615081129504, 'Total loss': 0.3063615081129504}
2022-11-28 01:42:45,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:45,540 INFO:     Epoch: 84
2022-11-28 01:42:46,278 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4350788494528726, 'Total loss': 0.4350788494528726} | train loss {'Reaction outcome loss': 0.30588787345246216, 'Total loss': 0.30588787345246216}
2022-11-28 01:42:46,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:46,279 INFO:     Epoch: 85
2022-11-28 01:42:47,017 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4107452433469684, 'Total loss': 0.4107452433469684} | train loss {'Reaction outcome loss': 0.30374071890579873, 'Total loss': 0.30374071890579873}
2022-11-28 01:42:47,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:47,017 INFO:     Epoch: 86
2022-11-28 01:42:47,759 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3973850101925606, 'Total loss': 0.3973850101925606} | train loss {'Reaction outcome loss': 0.3011617891368319, 'Total loss': 0.3011617891368319}
2022-11-28 01:42:47,759 INFO:     Found new best model at epoch 86
2022-11-28 01:42:47,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:47,760 INFO:     Epoch: 87
2022-11-28 01:42:48,504 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42001113052978073, 'Total loss': 0.42001113052978073} | train loss {'Reaction outcome loss': 0.3119099957288289, 'Total loss': 0.3119099957288289}
2022-11-28 01:42:48,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:48,505 INFO:     Epoch: 88
2022-11-28 01:42:49,246 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44188548659169397, 'Total loss': 0.44188548659169397} | train loss {'Reaction outcome loss': 0.30863602108276283, 'Total loss': 0.30863602108276283}
2022-11-28 01:42:49,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:49,247 INFO:     Epoch: 89
2022-11-28 01:42:49,985 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41337487049574073, 'Total loss': 0.41337487049574073} | train loss {'Reaction outcome loss': 0.30053947826267263, 'Total loss': 0.30053947826267263}
2022-11-28 01:42:49,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:49,985 INFO:     Epoch: 90
2022-11-28 01:42:50,725 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40411440820194955, 'Total loss': 0.40411440820194955} | train loss {'Reaction outcome loss': 0.30930786179836656, 'Total loss': 0.30930786179836656}
2022-11-28 01:42:50,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:50,726 INFO:     Epoch: 91
2022-11-28 01:42:51,465 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44216193626959654, 'Total loss': 0.44216193626959654} | train loss {'Reaction outcome loss': 0.3082019339666748, 'Total loss': 0.3082019339666748}
2022-11-28 01:42:51,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:51,466 INFO:     Epoch: 92
2022-11-28 01:42:52,201 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4356608449719673, 'Total loss': 0.4356608449719673} | train loss {'Reaction outcome loss': 0.30306436032911793, 'Total loss': 0.30306436032911793}
2022-11-28 01:42:52,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:52,202 INFO:     Epoch: 93
2022-11-28 01:42:52,935 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45318587037713026, 'Total loss': 0.45318587037713026} | train loss {'Reaction outcome loss': 0.30335680526665976, 'Total loss': 0.30335680526665976}
2022-11-28 01:42:52,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:52,935 INFO:     Epoch: 94
2022-11-28 01:42:53,674 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42056042510409686, 'Total loss': 0.42056042510409686} | train loss {'Reaction outcome loss': 0.3030370658599451, 'Total loss': 0.3030370658599451}
2022-11-28 01:42:53,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:53,674 INFO:     Epoch: 95
2022-11-28 01:42:54,418 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41979354342748953, 'Total loss': 0.41979354342748953} | train loss {'Reaction outcome loss': 0.30053145835389855, 'Total loss': 0.30053145835389855}
2022-11-28 01:42:54,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:54,419 INFO:     Epoch: 96
2022-11-28 01:42:55,164 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43822595996912134, 'Total loss': 0.43822595996912134} | train loss {'Reaction outcome loss': 0.29965195398716654, 'Total loss': 0.29965195398716654}
2022-11-28 01:42:55,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:55,165 INFO:     Epoch: 97
2022-11-28 01:42:55,904 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43699120089065197, 'Total loss': 0.43699120089065197} | train loss {'Reaction outcome loss': 0.2991148792207241, 'Total loss': 0.2991148792207241}
2022-11-28 01:42:55,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:55,904 INFO:     Epoch: 98
2022-11-28 01:42:56,642 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44637736816738927, 'Total loss': 0.44637736816738927} | train loss {'Reaction outcome loss': 0.30099547633015716, 'Total loss': 0.30099547633015716}
2022-11-28 01:42:56,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:56,642 INFO:     Epoch: 99
2022-11-28 01:42:57,380 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.438124785936156, 'Total loss': 0.438124785936156} | train loss {'Reaction outcome loss': 0.30189695419194024, 'Total loss': 0.30189695419194024}
2022-11-28 01:42:57,380 INFO:     Best model found after epoch 87 of 100.
2022-11-28 01:42:57,380 INFO:   Done with stage: TRAINING
2022-11-28 01:42:57,380 INFO:   Starting stage: EVALUATION
2022-11-28 01:42:57,518 INFO:   Done with stage: EVALUATION
2022-11-28 01:42:57,518 INFO:   Leaving out SEQ value Fold_1
2022-11-28 01:42:57,531 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:42:57,531 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:42:58,182 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:42:58,182 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:42:58,250 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:42:58,251 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:42:58,251 INFO:     No hyperparam tuning for this model
2022-11-28 01:42:58,251 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:42:58,251 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:42:58,251 INFO:     None feature selector for col prot
2022-11-28 01:42:58,252 INFO:     None feature selector for col prot
2022-11-28 01:42:58,252 INFO:     None feature selector for col prot
2022-11-28 01:42:58,252 INFO:     None feature selector for col chem
2022-11-28 01:42:58,252 INFO:     None feature selector for col chem
2022-11-28 01:42:58,252 INFO:     None feature selector for col chem
2022-11-28 01:42:58,252 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:42:58,252 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:42:58,254 INFO:     Number of params in model 169741
2022-11-28 01:42:58,257 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:42:58,257 INFO:   Starting stage: TRAINING
2022-11-28 01:42:58,311 INFO:     Val loss before train {'Reaction outcome loss': 1.0108397210186177, 'Total loss': 1.0108397210186177}
2022-11-28 01:42:58,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:58,311 INFO:     Epoch: 0
2022-11-28 01:42:59,057 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5074644783003763, 'Total loss': 0.5074644783003763} | train loss {'Reaction outcome loss': 0.6416974593753274, 'Total loss': 0.6416974593753274}
2022-11-28 01:42:59,057 INFO:     Found new best model at epoch 0
2022-11-28 01:42:59,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:59,058 INFO:     Epoch: 1
2022-11-28 01:42:59,806 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45946890623732045, 'Total loss': 0.45946890623732045} | train loss {'Reaction outcome loss': 0.5251254497797262, 'Total loss': 0.5251254497797262}
2022-11-28 01:42:59,806 INFO:     Found new best model at epoch 1
2022-11-28 01:42:59,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:42:59,807 INFO:     Epoch: 2
2022-11-28 01:43:00,554 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46754279326308856, 'Total loss': 0.46754279326308856} | train loss {'Reaction outcome loss': 0.46675975724436375, 'Total loss': 0.46675975724436375}
2022-11-28 01:43:00,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:00,555 INFO:     Epoch: 3
2022-11-28 01:43:01,302 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46288916502486577, 'Total loss': 0.46288916502486577} | train loss {'Reaction outcome loss': 0.45231941300123807, 'Total loss': 0.45231941300123807}
2022-11-28 01:43:01,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:01,302 INFO:     Epoch: 4
2022-11-28 01:43:02,054 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45934157530692493, 'Total loss': 0.45934157530692493} | train loss {'Reaction outcome loss': 0.4382156013145379, 'Total loss': 0.4382156013145379}
2022-11-28 01:43:02,054 INFO:     Found new best model at epoch 4
2022-11-28 01:43:02,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:02,055 INFO:     Epoch: 5
2022-11-28 01:43:02,806 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.439366855065931, 'Total loss': 0.439366855065931} | train loss {'Reaction outcome loss': 0.43182309309721956, 'Total loss': 0.43182309309721956}
2022-11-28 01:43:02,806 INFO:     Found new best model at epoch 5
2022-11-28 01:43:02,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:02,807 INFO:     Epoch: 6
2022-11-28 01:43:03,557 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4253107671710578, 'Total loss': 0.4253107671710578} | train loss {'Reaction outcome loss': 0.42127659527758354, 'Total loss': 0.42127659527758354}
2022-11-28 01:43:03,557 INFO:     Found new best model at epoch 6
2022-11-28 01:43:03,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:03,558 INFO:     Epoch: 7
2022-11-28 01:43:04,306 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4176436544141986, 'Total loss': 0.4176436544141986} | train loss {'Reaction outcome loss': 0.40491899708474455, 'Total loss': 0.40491899708474455}
2022-11-28 01:43:04,306 INFO:     Found new best model at epoch 7
2022-11-28 01:43:04,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:04,307 INFO:     Epoch: 8
2022-11-28 01:43:05,056 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46422004394910554, 'Total loss': 0.46422004394910554} | train loss {'Reaction outcome loss': 0.39928945693892504, 'Total loss': 0.39928945693892504}
2022-11-28 01:43:05,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:05,056 INFO:     Epoch: 9
2022-11-28 01:43:05,802 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41924578764221887, 'Total loss': 0.41924578764221887} | train loss {'Reaction outcome loss': 0.39424280246139054, 'Total loss': 0.39424280246139054}
2022-11-28 01:43:05,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:05,802 INFO:     Epoch: 10
2022-11-28 01:43:06,550 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42175852541219105, 'Total loss': 0.42175852541219105} | train loss {'Reaction outcome loss': 0.38524976635148167, 'Total loss': 0.38524976635148167}
2022-11-28 01:43:06,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:06,550 INFO:     Epoch: 11
2022-11-28 01:43:07,293 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43346479162573814, 'Total loss': 0.43346479162573814} | train loss {'Reaction outcome loss': 0.38757268082999025, 'Total loss': 0.38757268082999025}
2022-11-28 01:43:07,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:07,294 INFO:     Epoch: 12
2022-11-28 01:43:08,036 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5143068094145168, 'Total loss': 0.5143068094145168} | train loss {'Reaction outcome loss': 0.38859693956399255, 'Total loss': 0.38859693956399255}
2022-11-28 01:43:08,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:08,037 INFO:     Epoch: 13
2022-11-28 01:43:08,787 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44088586555285886, 'Total loss': 0.44088586555285886} | train loss {'Reaction outcome loss': 0.38244331545886484, 'Total loss': 0.38244331545886484}
2022-11-28 01:43:08,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:08,788 INFO:     Epoch: 14
2022-11-28 01:43:09,538 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41218801723285153, 'Total loss': 0.41218801723285153} | train loss {'Reaction outcome loss': 0.37316106959634465, 'Total loss': 0.37316106959634465}
2022-11-28 01:43:09,538 INFO:     Found new best model at epoch 14
2022-11-28 01:43:09,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:09,539 INFO:     Epoch: 15
2022-11-28 01:43:10,291 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4277049560438503, 'Total loss': 0.4277049560438503} | train loss {'Reaction outcome loss': 0.36400706028407404, 'Total loss': 0.36400706028407404}
2022-11-28 01:43:10,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:10,291 INFO:     Epoch: 16
2022-11-28 01:43:11,038 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4055908882821148, 'Total loss': 0.4055908882821148} | train loss {'Reaction outcome loss': 0.36774530141097816, 'Total loss': 0.36774530141097816}
2022-11-28 01:43:11,039 INFO:     Found new best model at epoch 16
2022-11-28 01:43:11,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:11,039 INFO:     Epoch: 17
2022-11-28 01:43:11,791 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42508095502853394, 'Total loss': 0.42508095502853394} | train loss {'Reaction outcome loss': 0.3724073233754046, 'Total loss': 0.3724073233754046}
2022-11-28 01:43:11,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:11,792 INFO:     Epoch: 18
2022-11-28 01:43:12,541 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41105707023631444, 'Total loss': 0.41105707023631444} | train loss {'Reaction outcome loss': 0.3568909588083248, 'Total loss': 0.3568909588083248}
2022-11-28 01:43:12,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:12,542 INFO:     Epoch: 19
2022-11-28 01:43:13,287 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4173369021578269, 'Total loss': 0.4173369021578269} | train loss {'Reaction outcome loss': 0.36095124103792525, 'Total loss': 0.36095124103792525}
2022-11-28 01:43:13,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:13,288 INFO:     Epoch: 20
2022-11-28 01:43:14,034 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41835854134776373, 'Total loss': 0.41835854134776373} | train loss {'Reaction outcome loss': 0.34599976737791227, 'Total loss': 0.34599976737791227}
2022-11-28 01:43:14,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:14,034 INFO:     Epoch: 21
2022-11-28 01:43:14,782 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3920522545549003, 'Total loss': 0.3920522545549003} | train loss {'Reaction outcome loss': 0.3563257202144094, 'Total loss': 0.3563257202144094}
2022-11-28 01:43:14,782 INFO:     Found new best model at epoch 21
2022-11-28 01:43:14,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:14,783 INFO:     Epoch: 22
2022-11-28 01:43:15,532 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41238698397170415, 'Total loss': 0.41238698397170415} | train loss {'Reaction outcome loss': 0.35657230782726035, 'Total loss': 0.35657230782726035}
2022-11-28 01:43:15,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:15,532 INFO:     Epoch: 23
2022-11-28 01:43:16,283 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.392751427536661, 'Total loss': 0.392751427536661} | train loss {'Reaction outcome loss': 0.3631095800865517, 'Total loss': 0.3631095800865517}
2022-11-28 01:43:16,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:16,283 INFO:     Epoch: 24
2022-11-28 01:43:17,031 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4123321548104286, 'Total loss': 0.4123321548104286} | train loss {'Reaction outcome loss': 0.3699417210180267, 'Total loss': 0.3699417210180267}
2022-11-28 01:43:17,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:17,032 INFO:     Epoch: 25
2022-11-28 01:43:17,781 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.417097808285193, 'Total loss': 0.417097808285193} | train loss {'Reaction outcome loss': 0.3523953523833742, 'Total loss': 0.3523953523833742}
2022-11-28 01:43:17,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:17,781 INFO:     Epoch: 26
2022-11-28 01:43:18,536 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4224641445008191, 'Total loss': 0.4224641445008191} | train loss {'Reaction outcome loss': 0.3478071243174163, 'Total loss': 0.3478071243174163}
2022-11-28 01:43:18,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:18,536 INFO:     Epoch: 27
2022-11-28 01:43:19,288 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41566578434272244, 'Total loss': 0.41566578434272244} | train loss {'Reaction outcome loss': 0.34830941070580046, 'Total loss': 0.34830941070580046}
2022-11-28 01:43:19,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:19,289 INFO:     Epoch: 28
2022-11-28 01:43:20,042 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3946976451711221, 'Total loss': 0.3946976451711221} | train loss {'Reaction outcome loss': 0.34874606274279507, 'Total loss': 0.34874606274279507}
2022-11-28 01:43:20,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:20,042 INFO:     Epoch: 29
2022-11-28 01:43:20,792 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40075011805377225, 'Total loss': 0.40075011805377225} | train loss {'Reaction outcome loss': 0.340957636006086, 'Total loss': 0.340957636006086}
2022-11-28 01:43:20,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:20,793 INFO:     Epoch: 30
2022-11-28 01:43:21,545 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40871191092512826, 'Total loss': 0.40871191092512826} | train loss {'Reaction outcome loss': 0.33759791717717524, 'Total loss': 0.33759791717717524}
2022-11-28 01:43:21,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:21,545 INFO:     Epoch: 31
2022-11-28 01:43:22,299 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42027253843843937, 'Total loss': 0.42027253843843937} | train loss {'Reaction outcome loss': 0.3439548261131835, 'Total loss': 0.3439548261131835}
2022-11-28 01:43:22,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:22,299 INFO:     Epoch: 32
2022-11-28 01:43:23,052 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40100629898634826, 'Total loss': 0.40100629898634826} | train loss {'Reaction outcome loss': 0.34461527179006624, 'Total loss': 0.34461527179006624}
2022-11-28 01:43:23,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:23,053 INFO:     Epoch: 33
2022-11-28 01:43:23,808 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3954418921335177, 'Total loss': 0.3954418921335177} | train loss {'Reaction outcome loss': 0.3360617487853476, 'Total loss': 0.3360617487853476}
2022-11-28 01:43:23,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:23,809 INFO:     Epoch: 34
2022-11-28 01:43:24,562 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42411423135887494, 'Total loss': 0.42411423135887494} | train loss {'Reaction outcome loss': 0.33969341161159367, 'Total loss': 0.33969341161159367}
2022-11-28 01:43:24,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:24,562 INFO:     Epoch: 35
2022-11-28 01:43:25,316 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3890825107016347, 'Total loss': 0.3890825107016347} | train loss {'Reaction outcome loss': 0.3494517135731725, 'Total loss': 0.3494517135731725}
2022-11-28 01:43:25,317 INFO:     Found new best model at epoch 35
2022-11-28 01:43:25,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:25,318 INFO:     Epoch: 36
2022-11-28 01:43:26,072 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4119545908814127, 'Total loss': 0.4119545908814127} | train loss {'Reaction outcome loss': 0.33015478545656574, 'Total loss': 0.33015478545656574}
2022-11-28 01:43:26,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:26,072 INFO:     Epoch: 37
2022-11-28 01:43:26,826 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37989854033697734, 'Total loss': 0.37989854033697734} | train loss {'Reaction outcome loss': 0.3524046598175759, 'Total loss': 0.3524046598175759}
2022-11-28 01:43:26,826 INFO:     Found new best model at epoch 37
2022-11-28 01:43:26,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:26,827 INFO:     Epoch: 38
2022-11-28 01:43:27,583 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42297773977572267, 'Total loss': 0.42297773977572267} | train loss {'Reaction outcome loss': 0.32525297215110377, 'Total loss': 0.32525297215110377}
2022-11-28 01:43:27,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:27,583 INFO:     Epoch: 39
2022-11-28 01:43:28,340 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40226847221228207, 'Total loss': 0.40226847221228207} | train loss {'Reaction outcome loss': 0.34941102544539554, 'Total loss': 0.34941102544539554}
2022-11-28 01:43:28,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:28,340 INFO:     Epoch: 40
2022-11-28 01:43:29,098 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.419363774697889, 'Total loss': 0.419363774697889} | train loss {'Reaction outcome loss': 0.33848254516652904, 'Total loss': 0.33848254516652904}
2022-11-28 01:43:29,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:29,098 INFO:     Epoch: 41
2022-11-28 01:43:29,852 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3897405686703595, 'Total loss': 0.3897405686703595} | train loss {'Reaction outcome loss': 0.32789896859934453, 'Total loss': 0.32789896859934453}
2022-11-28 01:43:29,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:29,852 INFO:     Epoch: 42
2022-11-28 01:43:30,604 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38225256702439353, 'Total loss': 0.38225256702439353} | train loss {'Reaction outcome loss': 0.32483402805531075, 'Total loss': 0.32483402805531075}
2022-11-28 01:43:30,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:30,605 INFO:     Epoch: 43
2022-11-28 01:43:31,359 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3907441584901376, 'Total loss': 0.3907441584901376} | train loss {'Reaction outcome loss': 0.3328809731824678, 'Total loss': 0.3328809731824678}
2022-11-28 01:43:31,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:31,359 INFO:     Epoch: 44
2022-11-28 01:43:32,109 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3857524215497754, 'Total loss': 0.3857524215497754} | train loss {'Reaction outcome loss': 0.34579405794862794, 'Total loss': 0.34579405794862794}
2022-11-28 01:43:32,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:32,109 INFO:     Epoch: 45
2022-11-28 01:43:32,864 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41133401746099646, 'Total loss': 0.41133401746099646} | train loss {'Reaction outcome loss': 0.325588502457388, 'Total loss': 0.325588502457388}
2022-11-28 01:43:32,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:32,864 INFO:     Epoch: 46
2022-11-28 01:43:33,618 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40465254709124565, 'Total loss': 0.40465254709124565} | train loss {'Reaction outcome loss': 0.3204286285498847, 'Total loss': 0.3204286285498847}
2022-11-28 01:43:33,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:33,618 INFO:     Epoch: 47
2022-11-28 01:43:34,369 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.392943680963733, 'Total loss': 0.392943680963733} | train loss {'Reaction outcome loss': 0.3230112161683409, 'Total loss': 0.3230112161683409}
2022-11-28 01:43:34,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:34,370 INFO:     Epoch: 48
2022-11-28 01:43:35,124 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4280400520021265, 'Total loss': 0.4280400520021265} | train loss {'Reaction outcome loss': 0.3216899318794007, 'Total loss': 0.3216899318794007}
2022-11-28 01:43:35,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:35,125 INFO:     Epoch: 49
2022-11-28 01:43:35,880 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.377267866903408, 'Total loss': 0.377267866903408} | train loss {'Reaction outcome loss': 0.32697507401604037, 'Total loss': 0.32697507401604037}
2022-11-28 01:43:35,880 INFO:     Found new best model at epoch 49
2022-11-28 01:43:35,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:35,881 INFO:     Epoch: 50
2022-11-28 01:43:36,636 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38532921638001094, 'Total loss': 0.38532921638001094} | train loss {'Reaction outcome loss': 0.32156599358267146, 'Total loss': 0.32156599358267146}
2022-11-28 01:43:36,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:36,636 INFO:     Epoch: 51
2022-11-28 01:43:37,390 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3939594526521184, 'Total loss': 0.3939594526521184} | train loss {'Reaction outcome loss': 0.3235025931647432, 'Total loss': 0.3235025931647432}
2022-11-28 01:43:37,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:37,391 INFO:     Epoch: 52
2022-11-28 01:43:38,148 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3900270499289036, 'Total loss': 0.3900270499289036} | train loss {'Reaction outcome loss': 0.3186622573598194, 'Total loss': 0.3186622573598194}
2022-11-28 01:43:38,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:38,148 INFO:     Epoch: 53
2022-11-28 01:43:38,903 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4172480914064429, 'Total loss': 0.4172480914064429} | train loss {'Reaction outcome loss': 0.3306587691068167, 'Total loss': 0.3306587691068167}
2022-11-28 01:43:38,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:38,903 INFO:     Epoch: 54
2022-11-28 01:43:39,657 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42977046458558604, 'Total loss': 0.42977046458558604} | train loss {'Reaction outcome loss': 0.3355651068301336, 'Total loss': 0.3355651068301336}
2022-11-28 01:43:39,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:39,657 INFO:     Epoch: 55
2022-11-28 01:43:40,411 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39274012026461685, 'Total loss': 0.39274012026461685} | train loss {'Reaction outcome loss': 0.3357051899618948, 'Total loss': 0.3357051899618948}
2022-11-28 01:43:40,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:40,412 INFO:     Epoch: 56
2022-11-28 01:43:41,171 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3850976550443606, 'Total loss': 0.3850976550443606} | train loss {'Reaction outcome loss': 0.32790375658054555, 'Total loss': 0.32790375658054555}
2022-11-28 01:43:41,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:41,171 INFO:     Epoch: 57
2022-11-28 01:43:41,928 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3902354616333138, 'Total loss': 0.3902354616333138} | train loss {'Reaction outcome loss': 0.3199780008450211, 'Total loss': 0.3199780008450211}
2022-11-28 01:43:41,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:41,928 INFO:     Epoch: 58
2022-11-28 01:43:42,682 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42341856624592433, 'Total loss': 0.42341856624592433} | train loss {'Reaction outcome loss': 0.3298969333953703, 'Total loss': 0.3298969333953703}
2022-11-28 01:43:42,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:42,682 INFO:     Epoch: 59
2022-11-28 01:43:43,436 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4135981652547013, 'Total loss': 0.4135981652547013} | train loss {'Reaction outcome loss': 0.3368455940774578, 'Total loss': 0.3368455940774578}
2022-11-28 01:43:43,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:43,436 INFO:     Epoch: 60
2022-11-28 01:43:44,191 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40824534642425453, 'Total loss': 0.40824534642425453} | train loss {'Reaction outcome loss': 0.33285834463803393, 'Total loss': 0.33285834463803393}
2022-11-28 01:43:44,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:44,191 INFO:     Epoch: 61
2022-11-28 01:43:44,950 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3903746676038612, 'Total loss': 0.3903746676038612} | train loss {'Reaction outcome loss': 0.35510210292074484, 'Total loss': 0.35510210292074484}
2022-11-28 01:43:44,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:44,951 INFO:     Epoch: 62
2022-11-28 01:43:45,708 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37512496587905014, 'Total loss': 0.37512496587905014} | train loss {'Reaction outcome loss': 0.3151733775732488, 'Total loss': 0.3151733775732488}
2022-11-28 01:43:45,708 INFO:     Found new best model at epoch 62
2022-11-28 01:43:45,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:45,709 INFO:     Epoch: 63
2022-11-28 01:43:46,465 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37768513336777687, 'Total loss': 0.37768513336777687} | train loss {'Reaction outcome loss': 0.32252484881616034, 'Total loss': 0.32252484881616034}
2022-11-28 01:43:46,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:46,465 INFO:     Epoch: 64
2022-11-28 01:43:47,220 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40465168113058264, 'Total loss': 0.40465168113058264} | train loss {'Reaction outcome loss': 0.32222854481776236, 'Total loss': 0.32222854481776236}
2022-11-28 01:43:47,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:47,220 INFO:     Epoch: 65
2022-11-28 01:43:47,974 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39875346710058773, 'Total loss': 0.39875346710058773} | train loss {'Reaction outcome loss': 0.32595631567693434, 'Total loss': 0.32595631567693434}
2022-11-28 01:43:47,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:47,974 INFO:     Epoch: 66
2022-11-28 01:43:48,727 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41770066845823417, 'Total loss': 0.41770066845823417} | train loss {'Reaction outcome loss': 0.3179134106044827, 'Total loss': 0.3179134106044827}
2022-11-28 01:43:48,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:48,727 INFO:     Epoch: 67
2022-11-28 01:43:49,480 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.397456130520864, 'Total loss': 0.397456130520864} | train loss {'Reaction outcome loss': 0.3449889791277256, 'Total loss': 0.3449889791277256}
2022-11-28 01:43:49,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:49,480 INFO:     Epoch: 68
2022-11-28 01:43:50,233 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38851782848889177, 'Total loss': 0.38851782848889177} | train loss {'Reaction outcome loss': 0.3231691400824974, 'Total loss': 0.3231691400824974}
2022-11-28 01:43:50,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:50,234 INFO:     Epoch: 69
2022-11-28 01:43:50,987 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43365961584177887, 'Total loss': 0.43365961584177887} | train loss {'Reaction outcome loss': 0.32512842553105914, 'Total loss': 0.32512842553105914}
2022-11-28 01:43:50,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:50,987 INFO:     Epoch: 70
2022-11-28 01:43:51,736 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3934802230108868, 'Total loss': 0.3934802230108868} | train loss {'Reaction outcome loss': 0.3234488125965904, 'Total loss': 0.3234488125965904}
2022-11-28 01:43:51,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:51,736 INFO:     Epoch: 71
2022-11-28 01:43:52,488 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4044208861887455, 'Total loss': 0.4044208861887455} | train loss {'Reaction outcome loss': 0.31221321406152086, 'Total loss': 0.31221321406152086}
2022-11-28 01:43:52,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:52,489 INFO:     Epoch: 72
2022-11-28 01:43:53,240 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40126256238330493, 'Total loss': 0.40126256238330493} | train loss {'Reaction outcome loss': 0.336383597782025, 'Total loss': 0.336383597782025}
2022-11-28 01:43:53,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:53,241 INFO:     Epoch: 73
2022-11-28 01:43:53,995 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.388329568234357, 'Total loss': 0.388329568234357} | train loss {'Reaction outcome loss': 0.3368015496836983, 'Total loss': 0.3368015496836983}
2022-11-28 01:43:53,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:53,995 INFO:     Epoch: 74
2022-11-28 01:43:54,744 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4229578490961682, 'Total loss': 0.4229578490961682} | train loss {'Reaction outcome loss': 0.32874562730070067, 'Total loss': 0.32874562730070067}
2022-11-28 01:43:54,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:54,744 INFO:     Epoch: 75
2022-11-28 01:43:55,495 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42914036695252766, 'Total loss': 0.42914036695252766} | train loss {'Reaction outcome loss': 0.3279360997938807, 'Total loss': 0.3279360997938807}
2022-11-28 01:43:55,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:55,495 INFO:     Epoch: 76
2022-11-28 01:43:56,243 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4280455610291524, 'Total loss': 0.4280455610291524} | train loss {'Reaction outcome loss': 0.31300583660087894, 'Total loss': 0.31300583660087894}
2022-11-28 01:43:56,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:56,244 INFO:     Epoch: 77
2022-11-28 01:43:56,995 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38048175180500204, 'Total loss': 0.38048175180500204} | train loss {'Reaction outcome loss': 0.3153175176578472, 'Total loss': 0.3153175176578472}
2022-11-28 01:43:56,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:56,995 INFO:     Epoch: 78
2022-11-28 01:43:57,745 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4113001823425293, 'Total loss': 0.4113001823425293} | train loss {'Reaction outcome loss': 0.3163186658611182, 'Total loss': 0.3163186658611182}
2022-11-28 01:43:57,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:57,745 INFO:     Epoch: 79
2022-11-28 01:43:58,493 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39452616972002114, 'Total loss': 0.39452616972002114} | train loss {'Reaction outcome loss': 0.320738406214667, 'Total loss': 0.320738406214667}
2022-11-28 01:43:58,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:58,493 INFO:     Epoch: 80
2022-11-28 01:43:59,242 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3904647017744454, 'Total loss': 0.3904647017744454} | train loss {'Reaction outcome loss': 0.30884982733365135, 'Total loss': 0.30884982733365135}
2022-11-28 01:43:59,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:59,243 INFO:     Epoch: 81
2022-11-28 01:43:59,993 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.433899668299339, 'Total loss': 0.433899668299339} | train loss {'Reaction outcome loss': 0.3125183724832197, 'Total loss': 0.3125183724832197}
2022-11-28 01:43:59,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:43:59,993 INFO:     Epoch: 82
2022-11-28 01:44:00,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4109292206439105, 'Total loss': 0.4109292206439105} | train loss {'Reaction outcome loss': 0.3254375761838607, 'Total loss': 0.3254375761838607}
2022-11-28 01:44:00,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:00,742 INFO:     Epoch: 83
2022-11-28 01:44:01,491 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37798215685920283, 'Total loss': 0.37798215685920283} | train loss {'Reaction outcome loss': 0.31894941864768983, 'Total loss': 0.31894941864768983}
2022-11-28 01:44:01,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:01,491 INFO:     Epoch: 84
2022-11-28 01:44:02,242 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42822670767253096, 'Total loss': 0.42822670767253096} | train loss {'Reaction outcome loss': 0.3162402639142897, 'Total loss': 0.3162402639142897}
2022-11-28 01:44:02,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:02,242 INFO:     Epoch: 85
2022-11-28 01:44:02,993 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4304388957944783, 'Total loss': 0.4304388957944783} | train loss {'Reaction outcome loss': 0.3163652216510372, 'Total loss': 0.3163652216510372}
2022-11-28 01:44:02,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:02,993 INFO:     Epoch: 86
2022-11-28 01:44:03,742 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3883277057585391, 'Total loss': 0.3883277057585391} | train loss {'Reaction outcome loss': 0.3237218137242292, 'Total loss': 0.3237218137242292}
2022-11-28 01:44:03,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:03,742 INFO:     Epoch: 87
2022-11-28 01:44:04,492 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45652879418974573, 'Total loss': 0.45652879418974573} | train loss {'Reaction outcome loss': 0.3188534590909597, 'Total loss': 0.3188534590909597}
2022-11-28 01:44:04,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:04,492 INFO:     Epoch: 88
2022-11-28 01:44:05,241 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3800071867352182, 'Total loss': 0.3800071867352182} | train loss {'Reaction outcome loss': 0.32070167766231666, 'Total loss': 0.32070167766231666}
2022-11-28 01:44:05,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:05,241 INFO:     Epoch: 89
2022-11-28 01:44:05,991 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4158180430531502, 'Total loss': 0.4158180430531502} | train loss {'Reaction outcome loss': 0.3090572276382202, 'Total loss': 0.3090572276382202}
2022-11-28 01:44:05,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:05,991 INFO:     Epoch: 90
2022-11-28 01:44:06,739 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.391147124835036, 'Total loss': 0.391147124835036} | train loss {'Reaction outcome loss': 0.3144321440443819, 'Total loss': 0.3144321440443819}
2022-11-28 01:44:06,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:06,740 INFO:     Epoch: 91
2022-11-28 01:44:07,489 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38714298233389854, 'Total loss': 0.38714298233389854} | train loss {'Reaction outcome loss': 0.33129016930324134, 'Total loss': 0.33129016930324134}
2022-11-28 01:44:07,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:07,489 INFO:     Epoch: 92
2022-11-28 01:44:08,239 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4272776181724938, 'Total loss': 0.4272776181724938} | train loss {'Reaction outcome loss': 0.31894449098353833, 'Total loss': 0.31894449098353833}
2022-11-28 01:44:08,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:08,239 INFO:     Epoch: 93
2022-11-28 01:44:08,989 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39193618864837015, 'Total loss': 0.39193618864837015} | train loss {'Reaction outcome loss': 0.3182953976260626, 'Total loss': 0.3182953976260626}
2022-11-28 01:44:08,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:08,990 INFO:     Epoch: 94
2022-11-28 01:44:09,742 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39790372448888695, 'Total loss': 0.39790372448888695} | train loss {'Reaction outcome loss': 0.3191646145362603, 'Total loss': 0.3191646145362603}
2022-11-28 01:44:09,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:09,742 INFO:     Epoch: 95
2022-11-28 01:44:10,491 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3737243188714439, 'Total loss': 0.3737243188714439} | train loss {'Reaction outcome loss': 0.3175811909350306, 'Total loss': 0.3175811909350306}
2022-11-28 01:44:10,491 INFO:     Found new best model at epoch 95
2022-11-28 01:44:10,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:10,492 INFO:     Epoch: 96
2022-11-28 01:44:11,243 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41085163537751546, 'Total loss': 0.41085163537751546} | train loss {'Reaction outcome loss': 0.3114406924868221, 'Total loss': 0.3114406924868221}
2022-11-28 01:44:11,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:11,243 INFO:     Epoch: 97
2022-11-28 01:44:11,993 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3866795086386529, 'Total loss': 0.3866795086386529} | train loss {'Reaction outcome loss': 0.3165189839507404, 'Total loss': 0.3165189839507404}
2022-11-28 01:44:11,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:11,993 INFO:     Epoch: 98
2022-11-28 01:44:12,746 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4063842902806672, 'Total loss': 0.4063842902806672} | train loss {'Reaction outcome loss': 0.32174689042182103, 'Total loss': 0.32174689042182103}
2022-11-28 01:44:12,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:12,746 INFO:     Epoch: 99
2022-11-28 01:44:13,498 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40413420816714113, 'Total loss': 0.40413420816714113} | train loss {'Reaction outcome loss': 0.31334507131292993, 'Total loss': 0.31334507131292993}
2022-11-28 01:44:13,498 INFO:     Best model found after epoch 96 of 100.
2022-11-28 01:44:13,498 INFO:   Done with stage: TRAINING
2022-11-28 01:44:13,498 INFO:   Starting stage: EVALUATION
2022-11-28 01:44:13,622 INFO:   Done with stage: EVALUATION
2022-11-28 01:44:13,622 INFO:   Leaving out SEQ value Fold_2
2022-11-28 01:44:13,635 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:44:13,635 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:44:14,279 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:44:14,279 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:44:14,349 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:44:14,349 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:44:14,349 INFO:     No hyperparam tuning for this model
2022-11-28 01:44:14,349 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:44:14,349 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:44:14,350 INFO:     None feature selector for col prot
2022-11-28 01:44:14,350 INFO:     None feature selector for col prot
2022-11-28 01:44:14,350 INFO:     None feature selector for col prot
2022-11-28 01:44:14,351 INFO:     None feature selector for col chem
2022-11-28 01:44:14,351 INFO:     None feature selector for col chem
2022-11-28 01:44:14,351 INFO:     None feature selector for col chem
2022-11-28 01:44:14,351 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:44:14,351 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:44:14,352 INFO:     Number of params in model 169741
2022-11-28 01:44:14,355 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:44:14,355 INFO:   Starting stage: TRAINING
2022-11-28 01:44:14,409 INFO:     Val loss before train {'Reaction outcome loss': 0.9677690010179173, 'Total loss': 0.9677690010179173}
2022-11-28 01:44:14,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:14,409 INFO:     Epoch: 0
2022-11-28 01:44:15,151 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5643096925182776, 'Total loss': 0.5643096925182776} | train loss {'Reaction outcome loss': 0.6318064977928084, 'Total loss': 0.6318064977928084}
2022-11-28 01:44:15,151 INFO:     Found new best model at epoch 0
2022-11-28 01:44:15,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:15,152 INFO:     Epoch: 1
2022-11-28 01:44:15,896 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48253012854944577, 'Total loss': 0.48253012854944577} | train loss {'Reaction outcome loss': 0.4943121995852918, 'Total loss': 0.4943121995852918}
2022-11-28 01:44:15,896 INFO:     Found new best model at epoch 1
2022-11-28 01:44:15,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:15,897 INFO:     Epoch: 2
2022-11-28 01:44:16,642 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45038579861548816, 'Total loss': 0.45038579861548816} | train loss {'Reaction outcome loss': 0.4602903067457433, 'Total loss': 0.4602903067457433}
2022-11-28 01:44:16,643 INFO:     Found new best model at epoch 2
2022-11-28 01:44:16,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:16,643 INFO:     Epoch: 3
2022-11-28 01:44:17,393 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44442677091468463, 'Total loss': 0.44442677091468463} | train loss {'Reaction outcome loss': 0.4339499132973807, 'Total loss': 0.4339499132973807}
2022-11-28 01:44:17,394 INFO:     Found new best model at epoch 3
2022-11-28 01:44:17,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:17,394 INFO:     Epoch: 4
2022-11-28 01:44:18,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47496236115694046, 'Total loss': 0.47496236115694046} | train loss {'Reaction outcome loss': 0.4231624983403148, 'Total loss': 0.4231624983403148}
2022-11-28 01:44:18,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:18,144 INFO:     Epoch: 5
2022-11-28 01:44:18,890 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43784271722490137, 'Total loss': 0.43784271722490137} | train loss {'Reaction outcome loss': 0.412215116802527, 'Total loss': 0.412215116802527}
2022-11-28 01:44:18,890 INFO:     Found new best model at epoch 5
2022-11-28 01:44:18,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:18,891 INFO:     Epoch: 6
2022-11-28 01:44:19,633 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44339940730821004, 'Total loss': 0.44339940730821004} | train loss {'Reaction outcome loss': 0.39727830844266077, 'Total loss': 0.39727830844266077}
2022-11-28 01:44:19,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:19,633 INFO:     Epoch: 7
2022-11-28 01:44:20,379 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42949754871766677, 'Total loss': 0.42949754871766677} | train loss {'Reaction outcome loss': 0.3904749140143394, 'Total loss': 0.3904749140143394}
2022-11-28 01:44:20,379 INFO:     Found new best model at epoch 7
2022-11-28 01:44:20,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:20,380 INFO:     Epoch: 8
2022-11-28 01:44:21,127 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4326366118409417, 'Total loss': 0.4326366118409417} | train loss {'Reaction outcome loss': 0.3858781579501775, 'Total loss': 0.3858781579501775}
2022-11-28 01:44:21,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:21,128 INFO:     Epoch: 9
2022-11-28 01:44:21,878 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41974229365587234, 'Total loss': 0.41974229365587234} | train loss {'Reaction outcome loss': 0.37619809064329884, 'Total loss': 0.37619809064329884}
2022-11-28 01:44:21,878 INFO:     Found new best model at epoch 9
2022-11-28 01:44:21,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:21,879 INFO:     Epoch: 10
2022-11-28 01:44:22,623 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4495634585618973, 'Total loss': 0.4495634585618973} | train loss {'Reaction outcome loss': 0.37295840303508604, 'Total loss': 0.37295840303508604}
2022-11-28 01:44:22,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:22,623 INFO:     Epoch: 11
2022-11-28 01:44:23,370 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4230206456374038, 'Total loss': 0.4230206456374038} | train loss {'Reaction outcome loss': 0.3679228831918872, 'Total loss': 0.3679228831918872}
2022-11-28 01:44:23,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:23,371 INFO:     Epoch: 12
2022-11-28 01:44:24,118 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41400944102894177, 'Total loss': 0.41400944102894177} | train loss {'Reaction outcome loss': 0.3539942453406295, 'Total loss': 0.3539942453406295}
2022-11-28 01:44:24,118 INFO:     Found new best model at epoch 12
2022-11-28 01:44:24,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:24,119 INFO:     Epoch: 13
2022-11-28 01:44:24,867 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43867409047247335, 'Total loss': 0.43867409047247335} | train loss {'Reaction outcome loss': 0.35936298917750925, 'Total loss': 0.35936298917750925}
2022-11-28 01:44:24,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:24,867 INFO:     Epoch: 14
2022-11-28 01:44:25,611 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4264113503423604, 'Total loss': 0.4264113503423604} | train loss {'Reaction outcome loss': 0.35300368517637254, 'Total loss': 0.35300368517637254}
2022-11-28 01:44:25,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:25,611 INFO:     Epoch: 15
2022-11-28 01:44:26,359 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4294772574000738, 'Total loss': 0.4294772574000738} | train loss {'Reaction outcome loss': 0.3516578994235214, 'Total loss': 0.3516578994235214}
2022-11-28 01:44:26,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:26,359 INFO:     Epoch: 16
2022-11-28 01:44:27,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4040534763850949, 'Total loss': 0.4040534763850949} | train loss {'Reaction outcome loss': 0.35380532445043933, 'Total loss': 0.35380532445043933}
2022-11-28 01:44:27,110 INFO:     Found new best model at epoch 16
2022-11-28 01:44:27,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:27,111 INFO:     Epoch: 17
2022-11-28 01:44:27,857 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4345072866840796, 'Total loss': 0.4345072866840796} | train loss {'Reaction outcome loss': 0.34312087038950045, 'Total loss': 0.34312087038950045}
2022-11-28 01:44:27,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:27,858 INFO:     Epoch: 18
2022-11-28 01:44:28,603 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41727260229262436, 'Total loss': 0.41727260229262436} | train loss {'Reaction outcome loss': 0.3449766033766221, 'Total loss': 0.3449766033766221}
2022-11-28 01:44:28,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:28,604 INFO:     Epoch: 19
2022-11-28 01:44:29,353 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4453957544809038, 'Total loss': 0.4453957544809038} | train loss {'Reaction outcome loss': 0.341884057345439, 'Total loss': 0.341884057345439}
2022-11-28 01:44:29,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:29,353 INFO:     Epoch: 20
2022-11-28 01:44:30,101 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4525900825180791, 'Total loss': 0.4525900825180791} | train loss {'Reaction outcome loss': 0.3341277155797092, 'Total loss': 0.3341277155797092}
2022-11-28 01:44:30,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:30,101 INFO:     Epoch: 21
2022-11-28 01:44:30,847 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4249620884656906, 'Total loss': 0.4249620884656906} | train loss {'Reaction outcome loss': 0.34399333012347316, 'Total loss': 0.34399333012347316}
2022-11-28 01:44:30,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:30,847 INFO:     Epoch: 22
2022-11-28 01:44:31,591 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4859923053194176, 'Total loss': 0.4859923053194176} | train loss {'Reaction outcome loss': 0.32960884041932165, 'Total loss': 0.32960884041932165}
2022-11-28 01:44:31,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:31,592 INFO:     Epoch: 23
2022-11-28 01:44:32,336 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40306260013444856, 'Total loss': 0.40306260013444856} | train loss {'Reaction outcome loss': 0.3404315998055497, 'Total loss': 0.3404315998055497}
2022-11-28 01:44:32,337 INFO:     Found new best model at epoch 23
2022-11-28 01:44:32,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:32,337 INFO:     Epoch: 24
2022-11-28 01:44:33,084 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4330851508473808, 'Total loss': 0.4330851508473808} | train loss {'Reaction outcome loss': 0.3342861562663195, 'Total loss': 0.3342861562663195}
2022-11-28 01:44:33,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:33,085 INFO:     Epoch: 25
2022-11-28 01:44:33,827 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4466547258198261, 'Total loss': 0.4466547258198261} | train loss {'Reaction outcome loss': 0.3314377570334746, 'Total loss': 0.3314377570334746}
2022-11-28 01:44:33,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:33,827 INFO:     Epoch: 26
2022-11-28 01:44:34,572 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3973359355533665, 'Total loss': 0.3973359355533665} | train loss {'Reaction outcome loss': 0.3293387866141845, 'Total loss': 0.3293387866141845}
2022-11-28 01:44:34,572 INFO:     Found new best model at epoch 26
2022-11-28 01:44:34,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:34,573 INFO:     Epoch: 27
2022-11-28 01:44:35,317 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4103820909830657, 'Total loss': 0.4103820909830657} | train loss {'Reaction outcome loss': 0.3254579855623294, 'Total loss': 0.3254579855623294}
2022-11-28 01:44:35,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:35,318 INFO:     Epoch: 28
2022-11-28 01:44:36,062 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4142562818120826, 'Total loss': 0.4142562818120826} | train loss {'Reaction outcome loss': 0.32884852366179834, 'Total loss': 0.32884852366179834}
2022-11-28 01:44:36,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:36,062 INFO:     Epoch: 29
2022-11-28 01:44:36,807 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43732207437807863, 'Total loss': 0.43732207437807863} | train loss {'Reaction outcome loss': 0.3262516752493625, 'Total loss': 0.3262516752493625}
2022-11-28 01:44:36,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:36,807 INFO:     Epoch: 30
2022-11-28 01:44:37,550 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42735395495864476, 'Total loss': 0.42735395495864476} | train loss {'Reaction outcome loss': 0.3357248901712651, 'Total loss': 0.3357248901712651}
2022-11-28 01:44:37,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:37,550 INFO:     Epoch: 31
2022-11-28 01:44:38,296 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40859671512787993, 'Total loss': 0.40859671512787993} | train loss {'Reaction outcome loss': 0.3258570533930039, 'Total loss': 0.3258570533930039}
2022-11-28 01:44:38,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:38,296 INFO:     Epoch: 32
2022-11-28 01:44:39,040 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4151722920889204, 'Total loss': 0.4151722920889204} | train loss {'Reaction outcome loss': 0.3241344415411657, 'Total loss': 0.3241344415411657}
2022-11-28 01:44:39,041 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:39,041 INFO:     Epoch: 33
2022-11-28 01:44:39,783 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4255793977274813, 'Total loss': 0.4255793977274813} | train loss {'Reaction outcome loss': 0.317081412870665, 'Total loss': 0.317081412870665}
2022-11-28 01:44:39,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:39,783 INFO:     Epoch: 34
2022-11-28 01:44:40,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43074858154762874, 'Total loss': 0.43074858154762874} | train loss {'Reaction outcome loss': 0.32675126383499226, 'Total loss': 0.32675126383499226}
2022-11-28 01:44:40,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:40,528 INFO:     Epoch: 35
2022-11-28 01:44:41,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4436639259484681, 'Total loss': 0.4436639259484681} | train loss {'Reaction outcome loss': 0.30834107849062703, 'Total loss': 0.30834107849062703}
2022-11-28 01:44:41,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:41,272 INFO:     Epoch: 36
2022-11-28 01:44:42,018 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4570928839119998, 'Total loss': 0.4570928839119998} | train loss {'Reaction outcome loss': 0.315398124590212, 'Total loss': 0.315398124590212}
2022-11-28 01:44:42,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:42,019 INFO:     Epoch: 37
2022-11-28 01:44:42,766 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4401652191511609, 'Total loss': 0.4401652191511609} | train loss {'Reaction outcome loss': 0.3144648305159442, 'Total loss': 0.3144648305159442}
2022-11-28 01:44:42,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:42,766 INFO:     Epoch: 38
2022-11-28 01:44:43,512 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42446607622233307, 'Total loss': 0.42446607622233307} | train loss {'Reaction outcome loss': 0.31834131369785384, 'Total loss': 0.31834131369785384}
2022-11-28 01:44:43,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:43,512 INFO:     Epoch: 39
2022-11-28 01:44:44,253 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4152961417355321, 'Total loss': 0.4152961417355321} | train loss {'Reaction outcome loss': 0.3186351727162089, 'Total loss': 0.3186351727162089}
2022-11-28 01:44:44,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:44,253 INFO:     Epoch: 40
2022-11-28 01:44:44,999 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42570898648012767, 'Total loss': 0.42570898648012767} | train loss {'Reaction outcome loss': 0.3147354482692115, 'Total loss': 0.3147354482692115}
2022-11-28 01:44:44,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:45,000 INFO:     Epoch: 41
2022-11-28 01:44:45,743 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4126722511666065, 'Total loss': 0.4126722511666065} | train loss {'Reaction outcome loss': 0.32054811360276475, 'Total loss': 0.32054811360276475}
2022-11-28 01:44:45,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:45,743 INFO:     Epoch: 42
2022-11-28 01:44:46,490 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4618459597907283, 'Total loss': 0.4618459597907283} | train loss {'Reaction outcome loss': 0.31776112467050555, 'Total loss': 0.31776112467050555}
2022-11-28 01:44:46,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:46,490 INFO:     Epoch: 43
2022-11-28 01:44:47,236 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43540880862962117, 'Total loss': 0.43540880862962117} | train loss {'Reaction outcome loss': 0.32078944961635436, 'Total loss': 0.32078944961635436}
2022-11-28 01:44:47,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:47,236 INFO:     Epoch: 44
2022-11-28 01:44:47,985 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43745258467441256, 'Total loss': 0.43745258467441256} | train loss {'Reaction outcome loss': 0.31093460221071634, 'Total loss': 0.31093460221071634}
2022-11-28 01:44:47,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:47,985 INFO:     Epoch: 45
2022-11-28 01:44:48,729 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41057785363359883, 'Total loss': 0.41057785363359883} | train loss {'Reaction outcome loss': 0.3170468532917451, 'Total loss': 0.3170468532917451}
2022-11-28 01:44:48,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:48,730 INFO:     Epoch: 46
2022-11-28 01:44:49,479 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4469666298140179, 'Total loss': 0.4469666298140179} | train loss {'Reaction outcome loss': 0.316607349502797, 'Total loss': 0.316607349502797}
2022-11-28 01:44:49,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:49,480 INFO:     Epoch: 47
2022-11-28 01:44:50,228 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.409396970983256, 'Total loss': 0.409396970983256} | train loss {'Reaction outcome loss': 0.31709917674259264, 'Total loss': 0.31709917674259264}
2022-11-28 01:44:50,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:50,228 INFO:     Epoch: 48
2022-11-28 01:44:50,978 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4036595954729075, 'Total loss': 0.4036595954729075} | train loss {'Reaction outcome loss': 0.3136334328246968, 'Total loss': 0.3136334328246968}
2022-11-28 01:44:50,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:50,978 INFO:     Epoch: 49
2022-11-28 01:44:51,726 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42030294628983195, 'Total loss': 0.42030294628983195} | train loss {'Reaction outcome loss': 0.3152712721301585, 'Total loss': 0.3152712721301585}
2022-11-28 01:44:51,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:51,726 INFO:     Epoch: 50
2022-11-28 01:44:52,474 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4369352019645951, 'Total loss': 0.4369352019645951} | train loss {'Reaction outcome loss': 0.30349486175240303, 'Total loss': 0.30349486175240303}
2022-11-28 01:44:52,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:52,475 INFO:     Epoch: 51
2022-11-28 01:44:53,222 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4352104196494276, 'Total loss': 0.4352104196494276} | train loss {'Reaction outcome loss': 0.3185395717316744, 'Total loss': 0.3185395717316744}
2022-11-28 01:44:53,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:53,222 INFO:     Epoch: 52
2022-11-28 01:44:53,964 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41389248113740573, 'Total loss': 0.41389248113740573} | train loss {'Reaction outcome loss': 0.30084729580854885, 'Total loss': 0.30084729580854885}
2022-11-28 01:44:53,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:53,964 INFO:     Epoch: 53
2022-11-28 01:44:54,707 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41452389769256115, 'Total loss': 0.41452389769256115} | train loss {'Reaction outcome loss': 0.3105644173768102, 'Total loss': 0.3105644173768102}
2022-11-28 01:44:54,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:54,707 INFO:     Epoch: 54
2022-11-28 01:44:55,449 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40389861505139957, 'Total loss': 0.40389861505139957} | train loss {'Reaction outcome loss': 0.3083491684222708, 'Total loss': 0.3083491684222708}
2022-11-28 01:44:55,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:55,449 INFO:     Epoch: 55
2022-11-28 01:44:56,194 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.422765198756348, 'Total loss': 0.422765198756348} | train loss {'Reaction outcome loss': 0.3089052803662358, 'Total loss': 0.3089052803662358}
2022-11-28 01:44:56,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:56,194 INFO:     Epoch: 56
2022-11-28 01:44:56,940 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42477645217017695, 'Total loss': 0.42477645217017695} | train loss {'Reaction outcome loss': 0.3078103675830121, 'Total loss': 0.3078103675830121}
2022-11-28 01:44:56,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:56,940 INFO:     Epoch: 57
2022-11-28 01:44:57,688 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41912970183925197, 'Total loss': 0.41912970183925197} | train loss {'Reaction outcome loss': 0.302579884428759, 'Total loss': 0.302579884428759}
2022-11-28 01:44:57,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:57,689 INFO:     Epoch: 58
2022-11-28 01:44:58,434 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4206087320027026, 'Total loss': 0.4206087320027026} | train loss {'Reaction outcome loss': 0.29684128414611427, 'Total loss': 0.29684128414611427}
2022-11-28 01:44:58,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:58,435 INFO:     Epoch: 59
2022-11-28 01:44:59,181 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43831503289667045, 'Total loss': 0.43831503289667045} | train loss {'Reaction outcome loss': 0.3083581277150281, 'Total loss': 0.3083581277150281}
2022-11-28 01:44:59,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:59,182 INFO:     Epoch: 60
2022-11-28 01:44:59,928 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40305201980200683, 'Total loss': 0.40305201980200683} | train loss {'Reaction outcome loss': 0.3105071656253873, 'Total loss': 0.3105071656253873}
2022-11-28 01:44:59,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:44:59,929 INFO:     Epoch: 61
2022-11-28 01:45:00,671 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41194109055636957, 'Total loss': 0.41194109055636957} | train loss {'Reaction outcome loss': 0.3034511375944225, 'Total loss': 0.3034511375944225}
2022-11-28 01:45:00,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:00,671 INFO:     Epoch: 62
2022-11-28 01:45:01,415 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4158444809304042, 'Total loss': 0.4158444809304042} | train loss {'Reaction outcome loss': 0.30488348387333813, 'Total loss': 0.30488348387333813}
2022-11-28 01:45:01,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:01,416 INFO:     Epoch: 63
2022-11-28 01:45:02,161 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4028857983648777, 'Total loss': 0.4028857983648777} | train loss {'Reaction outcome loss': 0.31319629676183874, 'Total loss': 0.31319629676183874}
2022-11-28 01:45:02,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:02,161 INFO:     Epoch: 64
2022-11-28 01:45:02,907 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43625645932148804, 'Total loss': 0.43625645932148804} | train loss {'Reaction outcome loss': 0.3045929196233652, 'Total loss': 0.3045929196233652}
2022-11-28 01:45:02,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:02,908 INFO:     Epoch: 65
2022-11-28 01:45:03,652 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45121134919199074, 'Total loss': 0.45121134919199074} | train loss {'Reaction outcome loss': 0.3049102459330948, 'Total loss': 0.3049102459330948}
2022-11-28 01:45:03,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:03,653 INFO:     Epoch: 66
2022-11-28 01:45:04,396 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41688281297683716, 'Total loss': 0.41688281297683716} | train loss {'Reaction outcome loss': 0.30449645412819726, 'Total loss': 0.30449645412819726}
2022-11-28 01:45:04,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:04,396 INFO:     Epoch: 67
2022-11-28 01:45:05,141 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4159050404348157, 'Total loss': 0.4159050404348157} | train loss {'Reaction outcome loss': 0.3015263942735536, 'Total loss': 0.3015263942735536}
2022-11-28 01:45:05,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:05,142 INFO:     Epoch: 68
2022-11-28 01:45:05,891 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4211535487662662, 'Total loss': 0.4211535487662662} | train loss {'Reaction outcome loss': 0.31085136192185536, 'Total loss': 0.31085136192185536}
2022-11-28 01:45:05,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:05,892 INFO:     Epoch: 69
2022-11-28 01:45:06,636 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4380059431899678, 'Total loss': 0.4380059431899678} | train loss {'Reaction outcome loss': 0.3019370653343444, 'Total loss': 0.3019370653343444}
2022-11-28 01:45:06,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:06,637 INFO:     Epoch: 70
2022-11-28 01:45:07,379 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4351689917120067, 'Total loss': 0.4351689917120067} | train loss {'Reaction outcome loss': 0.3067767680223499, 'Total loss': 0.3067767680223499}
2022-11-28 01:45:07,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:07,379 INFO:     Epoch: 71
2022-11-28 01:45:08,124 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4344642951407216, 'Total loss': 0.4344642951407216} | train loss {'Reaction outcome loss': 0.3030641101148664, 'Total loss': 0.3030641101148664}
2022-11-28 01:45:08,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:08,124 INFO:     Epoch: 72
2022-11-28 01:45:08,869 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46523984013633296, 'Total loss': 0.46523984013633296} | train loss {'Reaction outcome loss': 0.30038920999789726, 'Total loss': 0.30038920999789726}
2022-11-28 01:45:08,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:08,870 INFO:     Epoch: 73
2022-11-28 01:45:09,619 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4261255372654308, 'Total loss': 0.4261255372654308} | train loss {'Reaction outcome loss': 0.30963530297182046, 'Total loss': 0.30963530297182046}
2022-11-28 01:45:09,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:09,619 INFO:     Epoch: 74
2022-11-28 01:45:10,365 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4249447811056267, 'Total loss': 0.4249447811056267} | train loss {'Reaction outcome loss': 0.2997231345395653, 'Total loss': 0.2997231345395653}
2022-11-28 01:45:10,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:10,365 INFO:     Epoch: 75
2022-11-28 01:45:11,110 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.397887306753546, 'Total loss': 0.397887306753546} | train loss {'Reaction outcome loss': 0.3017871804991547, 'Total loss': 0.3017871804991547}
2022-11-28 01:45:11,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:11,110 INFO:     Epoch: 76
2022-11-28 01:45:11,857 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3906510455364531, 'Total loss': 0.3906510455364531} | train loss {'Reaction outcome loss': 0.31073493163804616, 'Total loss': 0.31073493163804616}
2022-11-28 01:45:11,858 INFO:     Found new best model at epoch 76
2022-11-28 01:45:11,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:11,859 INFO:     Epoch: 77
2022-11-28 01:45:12,601 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4144857329401103, 'Total loss': 0.4144857329401103} | train loss {'Reaction outcome loss': 0.298205838762984, 'Total loss': 0.298205838762984}
2022-11-28 01:45:12,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:12,602 INFO:     Epoch: 78
2022-11-28 01:45:13,349 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43288021958009765, 'Total loss': 0.43288021958009765} | train loss {'Reaction outcome loss': 0.30748999793918763, 'Total loss': 0.30748999793918763}
2022-11-28 01:45:13,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:13,349 INFO:     Epoch: 79
2022-11-28 01:45:14,091 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41218660467050294, 'Total loss': 0.41218660467050294} | train loss {'Reaction outcome loss': 0.30554304858859704, 'Total loss': 0.30554304858859704}
2022-11-28 01:45:14,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:14,091 INFO:     Epoch: 80
2022-11-28 01:45:14,835 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43192370470867236, 'Total loss': 0.43192370470867236} | train loss {'Reaction outcome loss': 0.3074736199056616, 'Total loss': 0.3074736199056616}
2022-11-28 01:45:14,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:14,835 INFO:     Epoch: 81
2022-11-28 01:45:15,580 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4143117778003216, 'Total loss': 0.4143117778003216} | train loss {'Reaction outcome loss': 0.3098392613688294, 'Total loss': 0.3098392613688294}
2022-11-28 01:45:15,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:15,580 INFO:     Epoch: 82
2022-11-28 01:45:16,326 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.401404670862989, 'Total loss': 0.401404670862989} | train loss {'Reaction outcome loss': 0.3041872945975284, 'Total loss': 0.3041872945975284}
2022-11-28 01:45:16,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:16,326 INFO:     Epoch: 83
2022-11-28 01:45:17,071 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41597990539263596, 'Total loss': 0.41597990539263596} | train loss {'Reaction outcome loss': 0.29532927422195066, 'Total loss': 0.29532927422195066}
2022-11-28 01:45:17,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:17,071 INFO:     Epoch: 84
2022-11-28 01:45:17,816 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4010034236337312, 'Total loss': 0.4010034236337312} | train loss {'Reaction outcome loss': 0.29777903873093275, 'Total loss': 0.29777903873093275}
2022-11-28 01:45:17,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:17,817 INFO:     Epoch: 85
2022-11-28 01:45:18,567 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4236955954269929, 'Total loss': 0.4236955954269929} | train loss {'Reaction outcome loss': 0.30491341668732314, 'Total loss': 0.30491341668732314}
2022-11-28 01:45:18,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:18,567 INFO:     Epoch: 86
2022-11-28 01:45:19,315 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4331697152123194, 'Total loss': 0.4331697152123194} | train loss {'Reaction outcome loss': 0.30733731530454694, 'Total loss': 0.30733731530454694}
2022-11-28 01:45:19,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:19,315 INFO:     Epoch: 87
2022-11-28 01:45:20,067 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4251540093259378, 'Total loss': 0.4251540093259378} | train loss {'Reaction outcome loss': 0.30072642602786726, 'Total loss': 0.30072642602786726}
2022-11-28 01:45:20,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:20,068 INFO:     Epoch: 88
2022-11-28 01:45:20,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.424617643722079, 'Total loss': 0.424617643722079} | train loss {'Reaction outcome loss': 0.2959666790554718, 'Total loss': 0.2959666790554718}
2022-11-28 01:45:20,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:20,815 INFO:     Epoch: 89
2022-11-28 01:45:21,562 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45929633284156973, 'Total loss': 0.45929633284156973} | train loss {'Reaction outcome loss': 0.30827359911434504, 'Total loss': 0.30827359911434504}
2022-11-28 01:45:21,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:21,563 INFO:     Epoch: 90
2022-11-28 01:45:22,314 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42424642260779033, 'Total loss': 0.42424642260779033} | train loss {'Reaction outcome loss': 0.29898604397871054, 'Total loss': 0.29898604397871054}
2022-11-28 01:45:22,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:22,314 INFO:     Epoch: 91
2022-11-28 01:45:23,059 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4407503987577828, 'Total loss': 0.4407503987577828} | train loss {'Reaction outcome loss': 0.3112077369677777, 'Total loss': 0.3112077369677777}
2022-11-28 01:45:23,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:23,059 INFO:     Epoch: 92
2022-11-28 01:45:23,807 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43568901091136714, 'Total loss': 0.43568901091136714} | train loss {'Reaction outcome loss': 0.2955064783747099, 'Total loss': 0.2955064783747099}
2022-11-28 01:45:23,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:23,808 INFO:     Epoch: 93
2022-11-28 01:45:24,555 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40495123163881624, 'Total loss': 0.40495123163881624} | train loss {'Reaction outcome loss': 0.3011357617317414, 'Total loss': 0.3011357617317414}
2022-11-28 01:45:24,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:24,556 INFO:     Epoch: 94
2022-11-28 01:45:25,301 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3966219841756604, 'Total loss': 0.3966219841756604} | train loss {'Reaction outcome loss': 0.299321045802564, 'Total loss': 0.299321045802564}
2022-11-28 01:45:25,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:25,301 INFO:     Epoch: 95
2022-11-28 01:45:26,047 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4526088238609108, 'Total loss': 0.4526088238609108} | train loss {'Reaction outcome loss': 0.3025359697791995, 'Total loss': 0.3025359697791995}
2022-11-28 01:45:26,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:26,047 INFO:     Epoch: 96
2022-11-28 01:45:26,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44254077767783945, 'Total loss': 0.44254077767783945} | train loss {'Reaction outcome loss': 0.308679294038792, 'Total loss': 0.308679294038792}
2022-11-28 01:45:26,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:26,796 INFO:     Epoch: 97
2022-11-28 01:45:27,542 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4296153865077279, 'Total loss': 0.4296153865077279} | train loss {'Reaction outcome loss': 0.2996231434904799, 'Total loss': 0.2996231434904799}
2022-11-28 01:45:27,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:27,542 INFO:     Epoch: 98
2022-11-28 01:45:28,291 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4293397275561636, 'Total loss': 0.4293397275561636} | train loss {'Reaction outcome loss': 0.29700749478473953, 'Total loss': 0.29700749478473953}
2022-11-28 01:45:28,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:28,291 INFO:     Epoch: 99
2022-11-28 01:45:29,041 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4255258644169027, 'Total loss': 0.4255258644169027} | train loss {'Reaction outcome loss': 0.29054522794120163, 'Total loss': 0.29054522794120163}
2022-11-28 01:45:29,041 INFO:     Best model found after epoch 77 of 100.
2022-11-28 01:45:29,041 INFO:   Done with stage: TRAINING
2022-11-28 01:45:29,041 INFO:   Starting stage: EVALUATION
2022-11-28 01:45:29,171 INFO:   Done with stage: EVALUATION
2022-11-28 01:45:29,171 INFO:   Leaving out SEQ value Fold_3
2022-11-28 01:45:29,184 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:45:29,184 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:45:29,830 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:45:29,830 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:45:29,899 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:45:29,900 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:45:29,900 INFO:     No hyperparam tuning for this model
2022-11-28 01:45:29,900 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:45:29,900 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:45:29,900 INFO:     None feature selector for col prot
2022-11-28 01:45:29,901 INFO:     None feature selector for col prot
2022-11-28 01:45:29,901 INFO:     None feature selector for col prot
2022-11-28 01:45:29,901 INFO:     None feature selector for col chem
2022-11-28 01:45:29,901 INFO:     None feature selector for col chem
2022-11-28 01:45:29,901 INFO:     None feature selector for col chem
2022-11-28 01:45:29,901 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:45:29,901 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:45:29,903 INFO:     Number of params in model 169741
2022-11-28 01:45:29,906 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:45:29,906 INFO:   Starting stage: TRAINING
2022-11-28 01:45:29,960 INFO:     Val loss before train {'Reaction outcome loss': 0.9956277629663778, 'Total loss': 0.9956277629663778}
2022-11-28 01:45:29,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:29,960 INFO:     Epoch: 0
2022-11-28 01:45:30,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.559271226788676, 'Total loss': 0.559271226788676} | train loss {'Reaction outcome loss': 0.6686540094555401, 'Total loss': 0.6686540094555401}
2022-11-28 01:45:30,706 INFO:     Found new best model at epoch 0
2022-11-28 01:45:30,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:30,707 INFO:     Epoch: 1
2022-11-28 01:45:31,456 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5250648447247439, 'Total loss': 0.5250648447247439} | train loss {'Reaction outcome loss': 0.5191129101592986, 'Total loss': 0.5191129101592986}
2022-11-28 01:45:31,456 INFO:     Found new best model at epoch 1
2022-11-28 01:45:31,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:31,457 INFO:     Epoch: 2
2022-11-28 01:45:32,201 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4810682621806167, 'Total loss': 0.4810682621806167} | train loss {'Reaction outcome loss': 0.47335266642516755, 'Total loss': 0.47335266642516755}
2022-11-28 01:45:32,201 INFO:     Found new best model at epoch 2
2022-11-28 01:45:32,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:32,202 INFO:     Epoch: 3
2022-11-28 01:45:32,941 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4884048714194187, 'Total loss': 0.4884048714194187} | train loss {'Reaction outcome loss': 0.45575291568749265, 'Total loss': 0.45575291568749265}
2022-11-28 01:45:32,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:32,942 INFO:     Epoch: 4
2022-11-28 01:45:33,680 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4440082855695902, 'Total loss': 0.4440082855695902} | train loss {'Reaction outcome loss': 0.43382209508878283, 'Total loss': 0.43382209508878283}
2022-11-28 01:45:33,680 INFO:     Found new best model at epoch 4
2022-11-28 01:45:33,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:33,681 INFO:     Epoch: 5
2022-11-28 01:45:34,426 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44473695755004883, 'Total loss': 0.44473695755004883} | train loss {'Reaction outcome loss': 0.41698831106062795, 'Total loss': 0.41698831106062795}
2022-11-28 01:45:34,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:34,426 INFO:     Epoch: 6
2022-11-28 01:45:35,168 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4508423826029134, 'Total loss': 0.4508423826029134} | train loss {'Reaction outcome loss': 0.4133591959710981, 'Total loss': 0.4133591959710981}
2022-11-28 01:45:35,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:35,168 INFO:     Epoch: 7
2022-11-28 01:45:35,909 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41969936739566716, 'Total loss': 0.41969936739566716} | train loss {'Reaction outcome loss': 0.40683660076045597, 'Total loss': 0.40683660076045597}
2022-11-28 01:45:35,909 INFO:     Found new best model at epoch 7
2022-11-28 01:45:35,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:35,910 INFO:     Epoch: 8
2022-11-28 01:45:36,650 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4314314442318539, 'Total loss': 0.4314314442318539} | train loss {'Reaction outcome loss': 0.4022591253284548, 'Total loss': 0.4022591253284548}
2022-11-28 01:45:36,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:36,651 INFO:     Epoch: 9
2022-11-28 01:45:37,392 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4528788497974706, 'Total loss': 0.4528788497974706} | train loss {'Reaction outcome loss': 0.39562982760491916, 'Total loss': 0.39562982760491916}
2022-11-28 01:45:37,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:37,392 INFO:     Epoch: 10
2022-11-28 01:45:38,133 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42838276853395063, 'Total loss': 0.42838276853395063} | train loss {'Reaction outcome loss': 0.3965399360864377, 'Total loss': 0.3965399360864377}
2022-11-28 01:45:38,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:38,133 INFO:     Epoch: 11
2022-11-28 01:45:38,881 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44498007415339, 'Total loss': 0.44498007415339} | train loss {'Reaction outcome loss': 0.38362080906136115, 'Total loss': 0.38362080906136115}
2022-11-28 01:45:38,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:38,881 INFO:     Epoch: 12
2022-11-28 01:45:39,625 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42813083858684053, 'Total loss': 0.42813083858684053} | train loss {'Reaction outcome loss': 0.38098093238277514, 'Total loss': 0.38098093238277514}
2022-11-28 01:45:39,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:39,625 INFO:     Epoch: 13
2022-11-28 01:45:40,363 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46747170596621757, 'Total loss': 0.46747170596621757} | train loss {'Reaction outcome loss': 0.3668141237414274, 'Total loss': 0.3668141237414274}
2022-11-28 01:45:40,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:40,364 INFO:     Epoch: 14
2022-11-28 01:45:41,104 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43028479883837145, 'Total loss': 0.43028479883837145} | train loss {'Reaction outcome loss': 0.37154833140370785, 'Total loss': 0.37154833140370785}
2022-11-28 01:45:41,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:41,105 INFO:     Epoch: 15
2022-11-28 01:45:41,847 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4157104502583659, 'Total loss': 0.4157104502583659} | train loss {'Reaction outcome loss': 0.370373704363821, 'Total loss': 0.370373704363821}
2022-11-28 01:45:41,847 INFO:     Found new best model at epoch 15
2022-11-28 01:45:41,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:41,848 INFO:     Epoch: 16
2022-11-28 01:45:42,594 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44278294229230214, 'Total loss': 0.44278294229230214} | train loss {'Reaction outcome loss': 0.3580342719911552, 'Total loss': 0.3580342719911552}
2022-11-28 01:45:42,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:42,594 INFO:     Epoch: 17
2022-11-28 01:45:43,338 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43595159227071806, 'Total loss': 0.43595159227071806} | train loss {'Reaction outcome loss': 0.36693648792436867, 'Total loss': 0.36693648792436867}
2022-11-28 01:45:43,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:43,338 INFO:     Epoch: 18
2022-11-28 01:45:44,079 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4362048548321391, 'Total loss': 0.4362048548321391} | train loss {'Reaction outcome loss': 0.3610564296546041, 'Total loss': 0.3610564296546041}
2022-11-28 01:45:44,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:44,079 INFO:     Epoch: 19
2022-11-28 01:45:44,826 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4531197035035422, 'Total loss': 0.4531197035035422} | train loss {'Reaction outcome loss': 0.3553943210205094, 'Total loss': 0.3553943210205094}
2022-11-28 01:45:44,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:44,826 INFO:     Epoch: 20
2022-11-28 01:45:45,570 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4321014836084011, 'Total loss': 0.4321014836084011} | train loss {'Reaction outcome loss': 0.3587176008302657, 'Total loss': 0.3587176008302657}
2022-11-28 01:45:45,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:45,570 INFO:     Epoch: 21
2022-11-28 01:45:46,315 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.432431977848674, 'Total loss': 0.432431977848674} | train loss {'Reaction outcome loss': 0.3596105482429266, 'Total loss': 0.3596105482429266}
2022-11-28 01:45:46,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:46,315 INFO:     Epoch: 22
2022-11-28 01:45:47,059 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4589368652465732, 'Total loss': 0.4589368652465732} | train loss {'Reaction outcome loss': 0.34918305396911553, 'Total loss': 0.34918305396911553}
2022-11-28 01:45:47,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:47,059 INFO:     Epoch: 23
2022-11-28 01:45:47,804 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43243754707103554, 'Total loss': 0.43243754707103554} | train loss {'Reaction outcome loss': 0.3555061782817127, 'Total loss': 0.3555061782817127}
2022-11-28 01:45:47,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:47,804 INFO:     Epoch: 24
2022-11-28 01:45:48,544 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41915598788926767, 'Total loss': 0.41915598788926767} | train loss {'Reaction outcome loss': 0.3517564910418186, 'Total loss': 0.3517564910418186}
2022-11-28 01:45:48,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:48,544 INFO:     Epoch: 25
2022-11-28 01:45:49,285 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4420050663310428, 'Total loss': 0.4420050663310428} | train loss {'Reaction outcome loss': 0.3445794142049844, 'Total loss': 0.3445794142049844}
2022-11-28 01:45:49,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:49,285 INFO:     Epoch: 26
2022-11-28 01:45:50,025 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43055636487727944, 'Total loss': 0.43055636487727944} | train loss {'Reaction outcome loss': 0.34512049967392544, 'Total loss': 0.34512049967392544}
2022-11-28 01:45:50,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:50,025 INFO:     Epoch: 27
2022-11-28 01:45:50,771 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45032340877277904, 'Total loss': 0.45032340877277904} | train loss {'Reaction outcome loss': 0.34887665699495646, 'Total loss': 0.34887665699495646}
2022-11-28 01:45:50,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:50,771 INFO:     Epoch: 28
2022-11-28 01:45:51,519 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4253897039696228, 'Total loss': 0.4253897039696228} | train loss {'Reaction outcome loss': 0.3412068661485539, 'Total loss': 0.3412068661485539}
2022-11-28 01:45:51,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:51,519 INFO:     Epoch: 29
2022-11-28 01:45:52,262 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44403561360614247, 'Total loss': 0.44403561360614247} | train loss {'Reaction outcome loss': 0.3364101826045357, 'Total loss': 0.3364101826045357}
2022-11-28 01:45:52,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:52,262 INFO:     Epoch: 30
2022-11-28 01:45:53,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.402078851537649, 'Total loss': 0.402078851537649} | train loss {'Reaction outcome loss': 0.3393255452640721, 'Total loss': 0.3393255452640721}
2022-11-28 01:45:53,012 INFO:     Found new best model at epoch 30
2022-11-28 01:45:53,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:53,013 INFO:     Epoch: 31
2022-11-28 01:45:53,759 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40963069869335306, 'Total loss': 0.40963069869335306} | train loss {'Reaction outcome loss': 0.34639675670959913, 'Total loss': 0.34639675670959913}
2022-11-28 01:45:53,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:53,760 INFO:     Epoch: 32
2022-11-28 01:45:54,503 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3926022738911385, 'Total loss': 0.3926022738911385} | train loss {'Reaction outcome loss': 0.34042921329497317, 'Total loss': 0.34042921329497317}
2022-11-28 01:45:54,503 INFO:     Found new best model at epoch 32
2022-11-28 01:45:54,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:54,504 INFO:     Epoch: 33
2022-11-28 01:45:55,247 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3969942916964376, 'Total loss': 0.3969942916964376} | train loss {'Reaction outcome loss': 0.3371688878377441, 'Total loss': 0.3371688878377441}
2022-11-28 01:45:55,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:55,248 INFO:     Epoch: 34
2022-11-28 01:45:55,990 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44031678833240684, 'Total loss': 0.44031678833240684} | train loss {'Reaction outcome loss': 0.3434396859746976, 'Total loss': 0.3434396859746976}
2022-11-28 01:45:55,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:55,990 INFO:     Epoch: 35
2022-11-28 01:45:56,735 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4249288942231688, 'Total loss': 0.4249288942231688} | train loss {'Reaction outcome loss': 0.33414120854596135, 'Total loss': 0.33414120854596135}
2022-11-28 01:45:56,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:56,735 INFO:     Epoch: 36
2022-11-28 01:45:57,478 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4037266210761181, 'Total loss': 0.4037266210761181} | train loss {'Reaction outcome loss': 0.3408425978278039, 'Total loss': 0.3408425978278039}
2022-11-28 01:45:57,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:57,478 INFO:     Epoch: 37
2022-11-28 01:45:58,221 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3980200647614723, 'Total loss': 0.3980200647614723} | train loss {'Reaction outcome loss': 0.32405169289864477, 'Total loss': 0.32405169289864477}
2022-11-28 01:45:58,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:58,221 INFO:     Epoch: 38
2022-11-28 01:45:58,963 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43491194587807325, 'Total loss': 0.43491194587807325} | train loss {'Reaction outcome loss': 0.3333575121264477, 'Total loss': 0.3333575121264477}
2022-11-28 01:45:58,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:58,963 INFO:     Epoch: 39
2022-11-28 01:45:59,706 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48256380232267604, 'Total loss': 0.48256380232267604} | train loss {'Reaction outcome loss': 0.3345156429854573, 'Total loss': 0.3345156429854573}
2022-11-28 01:45:59,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:45:59,706 INFO:     Epoch: 40
2022-11-28 01:46:00,449 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40710317638031274, 'Total loss': 0.40710317638031274} | train loss {'Reaction outcome loss': 0.3340789126079591, 'Total loss': 0.3340789126079591}
2022-11-28 01:46:00,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:00,449 INFO:     Epoch: 41
2022-11-28 01:46:01,193 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4329602744343669, 'Total loss': 0.4329602744343669} | train loss {'Reaction outcome loss': 0.3237647820630523, 'Total loss': 0.3237647820630523}
2022-11-28 01:46:01,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:01,194 INFO:     Epoch: 42
2022-11-28 01:46:01,937 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4761421011630879, 'Total loss': 0.4761421011630879} | train loss {'Reaction outcome loss': 0.3328897833030243, 'Total loss': 0.3328897833030243}
2022-11-28 01:46:01,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:01,938 INFO:     Epoch: 43
2022-11-28 01:46:02,680 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43551570177078247, 'Total loss': 0.43551570177078247} | train loss {'Reaction outcome loss': 0.3285351212701348, 'Total loss': 0.3285351212701348}
2022-11-28 01:46:02,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:02,681 INFO:     Epoch: 44
2022-11-28 01:46:03,424 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43937016711678617, 'Total loss': 0.43937016711678617} | train loss {'Reaction outcome loss': 0.3312647082827619, 'Total loss': 0.3312647082827619}
2022-11-28 01:46:03,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:03,425 INFO:     Epoch: 45
2022-11-28 01:46:04,167 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45175905976184577, 'Total loss': 0.45175905976184577} | train loss {'Reaction outcome loss': 0.3308790536811117, 'Total loss': 0.3308790536811117}
2022-11-28 01:46:04,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:04,167 INFO:     Epoch: 46
2022-11-28 01:46:04,911 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4547122328780418, 'Total loss': 0.4547122328780418} | train loss {'Reaction outcome loss': 0.33875867193106746, 'Total loss': 0.33875867193106746}
2022-11-28 01:46:04,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:04,911 INFO:     Epoch: 47
2022-11-28 01:46:05,652 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4348188732252565, 'Total loss': 0.4348188732252565} | train loss {'Reaction outcome loss': 0.3270058518916857, 'Total loss': 0.3270058518916857}
2022-11-28 01:46:05,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:05,652 INFO:     Epoch: 48
2022-11-28 01:46:06,393 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4288894010837688, 'Total loss': 0.4288894010837688} | train loss {'Reaction outcome loss': 0.3372688103833648, 'Total loss': 0.3372688103833648}
2022-11-28 01:46:06,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:06,394 INFO:     Epoch: 49
2022-11-28 01:46:07,137 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4173711961091951, 'Total loss': 0.4173711961091951} | train loss {'Reaction outcome loss': 0.3263517757725032, 'Total loss': 0.3263517757725032}
2022-11-28 01:46:07,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:07,137 INFO:     Epoch: 50
2022-11-28 01:46:07,880 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4454548331194146, 'Total loss': 0.4454548331194146} | train loss {'Reaction outcome loss': 0.3326409744007177, 'Total loss': 0.3326409744007177}
2022-11-28 01:46:07,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:07,880 INFO:     Epoch: 51
2022-11-28 01:46:08,630 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46507903448371, 'Total loss': 0.46507903448371} | train loss {'Reaction outcome loss': 0.3274624697009071, 'Total loss': 0.3274624697009071}
2022-11-28 01:46:08,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:08,630 INFO:     Epoch: 52
2022-11-28 01:46:09,381 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42160118561844495, 'Total loss': 0.42160118561844495} | train loss {'Reaction outcome loss': 0.3277060973961822, 'Total loss': 0.3277060973961822}
2022-11-28 01:46:09,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:09,381 INFO:     Epoch: 53
2022-11-28 01:46:10,126 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4027520608763362, 'Total loss': 0.4027520608763362} | train loss {'Reaction outcome loss': 0.3246468773081166, 'Total loss': 0.3246468773081166}
2022-11-28 01:46:10,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:10,126 INFO:     Epoch: 54
2022-11-28 01:46:10,871 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4090271259463111, 'Total loss': 0.4090271259463111} | train loss {'Reaction outcome loss': 0.31843195318198597, 'Total loss': 0.31843195318198597}
2022-11-28 01:46:10,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:10,871 INFO:     Epoch: 55
2022-11-28 01:46:11,615 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40874103474062545, 'Total loss': 0.40874103474062545} | train loss {'Reaction outcome loss': 0.3204443916128796, 'Total loss': 0.3204443916128796}
2022-11-28 01:46:11,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:11,615 INFO:     Epoch: 56
2022-11-28 01:46:12,360 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4319873424463494, 'Total loss': 0.4319873424463494} | train loss {'Reaction outcome loss': 0.32172840674881076, 'Total loss': 0.32172840674881076}
2022-11-28 01:46:12,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:12,360 INFO:     Epoch: 57
2022-11-28 01:46:13,103 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4181640361284101, 'Total loss': 0.4181640361284101} | train loss {'Reaction outcome loss': 0.32425859231562887, 'Total loss': 0.32425859231562887}
2022-11-28 01:46:13,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:13,104 INFO:     Epoch: 58
2022-11-28 01:46:13,846 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4552501245986584, 'Total loss': 0.4552501245986584} | train loss {'Reaction outcome loss': 0.3215420583995884, 'Total loss': 0.3215420583995884}
2022-11-28 01:46:13,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:13,846 INFO:     Epoch: 59
2022-11-28 01:46:14,588 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4196716193542924, 'Total loss': 0.4196716193542924} | train loss {'Reaction outcome loss': 0.3240565942508764, 'Total loss': 0.3240565942508764}
2022-11-28 01:46:14,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:14,589 INFO:     Epoch: 60
2022-11-28 01:46:15,330 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44761787874754083, 'Total loss': 0.44761787874754083} | train loss {'Reaction outcome loss': 0.3257177509367466, 'Total loss': 0.3257177509367466}
2022-11-28 01:46:15,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:15,330 INFO:     Epoch: 61
2022-11-28 01:46:16,074 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42398449882518413, 'Total loss': 0.42398449882518413} | train loss {'Reaction outcome loss': 0.3198045017350404, 'Total loss': 0.3198045017350404}
2022-11-28 01:46:16,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:16,074 INFO:     Epoch: 62
2022-11-28 01:46:16,818 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41603932460380155, 'Total loss': 0.41603932460380155} | train loss {'Reaction outcome loss': 0.33023708698446635, 'Total loss': 0.33023708698446635}
2022-11-28 01:46:16,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:16,818 INFO:     Epoch: 63
2022-11-28 01:46:17,558 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43804029912449594, 'Total loss': 0.43804029912449594} | train loss {'Reaction outcome loss': 0.3197397863889327, 'Total loss': 0.3197397863889327}
2022-11-28 01:46:17,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:17,559 INFO:     Epoch: 64
2022-11-28 01:46:18,299 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46474741815134535, 'Total loss': 0.46474741815134535} | train loss {'Reaction outcome loss': 0.32659411354020973, 'Total loss': 0.32659411354020973}
2022-11-28 01:46:18,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:18,299 INFO:     Epoch: 65
2022-11-28 01:46:19,046 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4132497622523197, 'Total loss': 0.4132497622523197} | train loss {'Reaction outcome loss': 0.3215095902197674, 'Total loss': 0.3215095902197674}
2022-11-28 01:46:19,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:19,047 INFO:     Epoch: 66
2022-11-28 01:46:19,792 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4826390244239985, 'Total loss': 0.4826390244239985} | train loss {'Reaction outcome loss': 0.30907548014379915, 'Total loss': 0.30907548014379915}
2022-11-28 01:46:19,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:19,792 INFO:     Epoch: 67
2022-11-28 01:46:20,534 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4258350168549737, 'Total loss': 0.4258350168549737} | train loss {'Reaction outcome loss': 0.32158269324019306, 'Total loss': 0.32158269324019306}
2022-11-28 01:46:20,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:20,535 INFO:     Epoch: 68
2022-11-28 01:46:21,277 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40828191991462265, 'Total loss': 0.40828191991462265} | train loss {'Reaction outcome loss': 0.3149284943327552, 'Total loss': 0.3149284943327552}
2022-11-28 01:46:21,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:21,278 INFO:     Epoch: 69
2022-11-28 01:46:22,019 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43372036759243454, 'Total loss': 0.43372036759243454} | train loss {'Reaction outcome loss': 0.3176894987337902, 'Total loss': 0.3176894987337902}
2022-11-28 01:46:22,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:22,019 INFO:     Epoch: 70
2022-11-28 01:46:22,762 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.421261124226243, 'Total loss': 0.421261124226243} | train loss {'Reaction outcome loss': 0.3257539508345186, 'Total loss': 0.3257539508345186}
2022-11-28 01:46:22,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:22,762 INFO:     Epoch: 71
2022-11-28 01:46:23,503 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4431712256614552, 'Total loss': 0.4431712256614552} | train loss {'Reaction outcome loss': 0.3221617746853926, 'Total loss': 0.3221617746853926}
2022-11-28 01:46:23,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:23,504 INFO:     Epoch: 72
2022-11-28 01:46:24,246 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4438184374986693, 'Total loss': 0.4438184374986693} | train loss {'Reaction outcome loss': 0.3204920496180898, 'Total loss': 0.3204920496180898}
2022-11-28 01:46:24,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:24,246 INFO:     Epoch: 73
2022-11-28 01:46:24,992 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3974819904149965, 'Total loss': 0.3974819904149965} | train loss {'Reaction outcome loss': 0.3159880202996438, 'Total loss': 0.3159880202996438}
2022-11-28 01:46:24,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:24,992 INFO:     Epoch: 74
2022-11-28 01:46:25,737 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.442875821576562, 'Total loss': 0.442875821576562} | train loss {'Reaction outcome loss': 0.3205135493676682, 'Total loss': 0.3205135493676682}
2022-11-28 01:46:25,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:25,737 INFO:     Epoch: 75
2022-11-28 01:46:26,479 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40381326093230135, 'Total loss': 0.40381326093230135} | train loss {'Reaction outcome loss': 0.3209134474640987, 'Total loss': 0.3209134474640987}
2022-11-28 01:46:26,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:26,480 INFO:     Epoch: 76
2022-11-28 01:46:27,223 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41753707410291185, 'Total loss': 0.41753707410291185} | train loss {'Reaction outcome loss': 0.31448720841378464, 'Total loss': 0.31448720841378464}
2022-11-28 01:46:27,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:27,223 INFO:     Epoch: 77
2022-11-28 01:46:27,968 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45001851490070655, 'Total loss': 0.45001851490070655} | train loss {'Reaction outcome loss': 0.3115347538326607, 'Total loss': 0.3115347538326607}
2022-11-28 01:46:27,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:27,969 INFO:     Epoch: 78
2022-11-28 01:46:28,712 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4329017445791599, 'Total loss': 0.4329017445791599} | train loss {'Reaction outcome loss': 0.314019790071933, 'Total loss': 0.314019790071933}
2022-11-28 01:46:28,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:28,713 INFO:     Epoch: 79
2022-11-28 01:46:29,458 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43950808810633285, 'Total loss': 0.43950808810633285} | train loss {'Reaction outcome loss': 0.3207333263498349, 'Total loss': 0.3207333263498349}
2022-11-28 01:46:29,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:29,458 INFO:     Epoch: 80
2022-11-28 01:46:30,199 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44217013065205063, 'Total loss': 0.44217013065205063} | train loss {'Reaction outcome loss': 0.3248501328568234, 'Total loss': 0.3248501328568234}
2022-11-28 01:46:30,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:30,200 INFO:     Epoch: 81
2022-11-28 01:46:30,940 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41400000522303027, 'Total loss': 0.41400000522303027} | train loss {'Reaction outcome loss': 0.316216157428676, 'Total loss': 0.316216157428676}
2022-11-28 01:46:30,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:30,940 INFO:     Epoch: 82
2022-11-28 01:46:31,683 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4308819743089898, 'Total loss': 0.4308819743089898} | train loss {'Reaction outcome loss': 0.3139925534363653, 'Total loss': 0.3139925534363653}
2022-11-28 01:46:31,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:31,684 INFO:     Epoch: 83
2022-11-28 01:46:32,427 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4387127715487813, 'Total loss': 0.4387127715487813} | train loss {'Reaction outcome loss': 0.3255592123681649, 'Total loss': 0.3255592123681649}
2022-11-28 01:46:32,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:32,428 INFO:     Epoch: 84
2022-11-28 01:46:33,174 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4152074262153271, 'Total loss': 0.4152074262153271} | train loss {'Reaction outcome loss': 0.3208190617685924, 'Total loss': 0.3208190617685924}
2022-11-28 01:46:33,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:33,175 INFO:     Epoch: 85
2022-11-28 01:46:33,917 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41974577377008837, 'Total loss': 0.41974577377008837} | train loss {'Reaction outcome loss': 0.32398024918969537, 'Total loss': 0.32398024918969537}
2022-11-28 01:46:33,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:33,917 INFO:     Epoch: 86
2022-11-28 01:46:34,661 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41530212032240493, 'Total loss': 0.41530212032240493} | train loss {'Reaction outcome loss': 0.319948798961571, 'Total loss': 0.319948798961571}
2022-11-28 01:46:34,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:34,661 INFO:     Epoch: 87
2022-11-28 01:46:35,403 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43082988158214924, 'Total loss': 0.43082988158214924} | train loss {'Reaction outcome loss': 0.3252918658869677, 'Total loss': 0.3252918658869677}
2022-11-28 01:46:35,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:35,403 INFO:     Epoch: 88
2022-11-28 01:46:36,146 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4158174842596054, 'Total loss': 0.4158174842596054} | train loss {'Reaction outcome loss': 0.3196506930179283, 'Total loss': 0.3196506930179283}
2022-11-28 01:46:36,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:36,146 INFO:     Epoch: 89
2022-11-28 01:46:36,890 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4349323417558226, 'Total loss': 0.4349323417558226} | train loss {'Reaction outcome loss': 0.3100222867653995, 'Total loss': 0.3100222867653995}
2022-11-28 01:46:36,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:36,890 INFO:     Epoch: 90
2022-11-28 01:46:37,633 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4187986272019009, 'Total loss': 0.4187986272019009} | train loss {'Reaction outcome loss': 0.3219593259215843, 'Total loss': 0.3219593259215843}
2022-11-28 01:46:37,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:37,633 INFO:     Epoch: 91
2022-11-28 01:46:38,377 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41615802430829335, 'Total loss': 0.41615802430829335} | train loss {'Reaction outcome loss': 0.31830065743234315, 'Total loss': 0.31830065743234315}
2022-11-28 01:46:38,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:38,377 INFO:     Epoch: 92
2022-11-28 01:46:39,125 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42597932212574535, 'Total loss': 0.42597932212574535} | train loss {'Reaction outcome loss': 0.3122928061018713, 'Total loss': 0.3122928061018713}
2022-11-28 01:46:39,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:39,125 INFO:     Epoch: 93
2022-11-28 01:46:39,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40080724414004837, 'Total loss': 0.40080724414004837} | train loss {'Reaction outcome loss': 0.32448745012039043, 'Total loss': 0.32448745012039043}
2022-11-28 01:46:39,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:39,868 INFO:     Epoch: 94
2022-11-28 01:46:40,612 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4467864618744961, 'Total loss': 0.4467864618744961} | train loss {'Reaction outcome loss': 0.329429299280536, 'Total loss': 0.329429299280536}
2022-11-28 01:46:40,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:40,613 INFO:     Epoch: 95
2022-11-28 01:46:41,354 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41806368668412053, 'Total loss': 0.41806368668412053} | train loss {'Reaction outcome loss': 0.31266033189890324, 'Total loss': 0.31266033189890324}
2022-11-28 01:46:41,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:41,354 INFO:     Epoch: 96
2022-11-28 01:46:42,098 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4257225574449051, 'Total loss': 0.4257225574449051} | train loss {'Reaction outcome loss': 0.3151579251146463, 'Total loss': 0.3151579251146463}
2022-11-28 01:46:42,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:42,098 INFO:     Epoch: 97
2022-11-28 01:46:42,841 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41266105064125946, 'Total loss': 0.41266105064125946} | train loss {'Reaction outcome loss': 0.31418938718003325, 'Total loss': 0.31418938718003325}
2022-11-28 01:46:42,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:42,842 INFO:     Epoch: 98
2022-11-28 01:46:43,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43926167730675186, 'Total loss': 0.43926167730675186} | train loss {'Reaction outcome loss': 0.32074319899509673, 'Total loss': 0.32074319899509673}
2022-11-28 01:46:43,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:43,585 INFO:     Epoch: 99
2022-11-28 01:46:44,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43453160205552743, 'Total loss': 0.43453160205552743} | train loss {'Reaction outcome loss': 0.3152029391866727, 'Total loss': 0.3152029391866727}
2022-11-28 01:46:44,329 INFO:     Best model found after epoch 33 of 100.
2022-11-28 01:46:44,329 INFO:   Done with stage: TRAINING
2022-11-28 01:46:44,329 INFO:   Starting stage: EVALUATION
2022-11-28 01:46:44,465 INFO:   Done with stage: EVALUATION
2022-11-28 01:46:44,466 INFO:   Leaving out SEQ value Fold_4
2022-11-28 01:46:44,478 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:46:44,478 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:46:45,122 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:46:45,122 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:46:45,190 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:46:45,191 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:46:45,191 INFO:     No hyperparam tuning for this model
2022-11-28 01:46:45,191 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:46:45,191 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:46:45,191 INFO:     None feature selector for col prot
2022-11-28 01:46:45,192 INFO:     None feature selector for col prot
2022-11-28 01:46:45,192 INFO:     None feature selector for col prot
2022-11-28 01:46:45,192 INFO:     None feature selector for col chem
2022-11-28 01:46:45,192 INFO:     None feature selector for col chem
2022-11-28 01:46:45,192 INFO:     None feature selector for col chem
2022-11-28 01:46:45,192 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:46:45,192 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:46:45,194 INFO:     Number of params in model 169741
2022-11-28 01:46:45,197 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:46:45,197 INFO:   Starting stage: TRAINING
2022-11-28 01:46:45,251 INFO:     Val loss before train {'Reaction outcome loss': 1.0432999418540434, 'Total loss': 1.0432999418540434}
2022-11-28 01:46:45,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:45,251 INFO:     Epoch: 0
2022-11-28 01:46:46,005 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5679880577054891, 'Total loss': 0.5679880577054891} | train loss {'Reaction outcome loss': 0.6309057811815892, 'Total loss': 0.6309057811815892}
2022-11-28 01:46:46,005 INFO:     Found new best model at epoch 0
2022-11-28 01:46:46,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:46,006 INFO:     Epoch: 1
2022-11-28 01:46:46,760 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5097774138504808, 'Total loss': 0.5097774138504808} | train loss {'Reaction outcome loss': 0.4900805284419367, 'Total loss': 0.4900805284419367}
2022-11-28 01:46:46,760 INFO:     Found new best model at epoch 1
2022-11-28 01:46:46,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:46,761 INFO:     Epoch: 2
2022-11-28 01:46:47,514 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.507836726917462, 'Total loss': 0.507836726917462} | train loss {'Reaction outcome loss': 0.45782365655947116, 'Total loss': 0.45782365655947116}
2022-11-28 01:46:47,515 INFO:     Found new best model at epoch 2
2022-11-28 01:46:47,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:47,515 INFO:     Epoch: 3
2022-11-28 01:46:48,267 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.504542080516165, 'Total loss': 0.504542080516165} | train loss {'Reaction outcome loss': 0.44017094602027246, 'Total loss': 0.44017094602027246}
2022-11-28 01:46:48,268 INFO:     Found new best model at epoch 3
2022-11-28 01:46:48,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:48,269 INFO:     Epoch: 4
2022-11-28 01:46:49,025 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48641768301075156, 'Total loss': 0.48641768301075156} | train loss {'Reaction outcome loss': 0.42818224724502335, 'Total loss': 0.42818224724502335}
2022-11-28 01:46:49,025 INFO:     Found new best model at epoch 4
2022-11-28 01:46:49,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:49,026 INFO:     Epoch: 5
2022-11-28 01:46:49,778 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45684642988172447, 'Total loss': 0.45684642988172447} | train loss {'Reaction outcome loss': 0.4140892397732504, 'Total loss': 0.4140892397732504}
2022-11-28 01:46:49,778 INFO:     Found new best model at epoch 5
2022-11-28 01:46:49,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:49,779 INFO:     Epoch: 6
2022-11-28 01:46:50,536 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4712313555858352, 'Total loss': 0.4712313555858352} | train loss {'Reaction outcome loss': 0.3999204479398266, 'Total loss': 0.3999204479398266}
2022-11-28 01:46:50,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:50,536 INFO:     Epoch: 7
2022-11-28 01:46:51,292 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.441798789257353, 'Total loss': 0.441798789257353} | train loss {'Reaction outcome loss': 0.39899022720994487, 'Total loss': 0.39899022720994487}
2022-11-28 01:46:51,292 INFO:     Found new best model at epoch 7
2022-11-28 01:46:51,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:51,293 INFO:     Epoch: 8
2022-11-28 01:46:52,047 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4767695577307181, 'Total loss': 0.4767695577307181} | train loss {'Reaction outcome loss': 0.375391990066536, 'Total loss': 0.375391990066536}
2022-11-28 01:46:52,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:52,047 INFO:     Epoch: 9
2022-11-28 01:46:52,800 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44983563673767174, 'Total loss': 0.44983563673767174} | train loss {'Reaction outcome loss': 0.37079699136196603, 'Total loss': 0.37079699136196603}
2022-11-28 01:46:52,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:52,800 INFO:     Epoch: 10
2022-11-28 01:46:53,550 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.445221984250979, 'Total loss': 0.445221984250979} | train loss {'Reaction outcome loss': 0.3709847048946446, 'Total loss': 0.3709847048946446}
2022-11-28 01:46:53,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:53,550 INFO:     Epoch: 11
2022-11-28 01:46:54,303 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5252229036255316, 'Total loss': 0.5252229036255316} | train loss {'Reaction outcome loss': 0.36566348878606675, 'Total loss': 0.36566348878606675}
2022-11-28 01:46:54,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:54,303 INFO:     Epoch: 12
2022-11-28 01:46:55,057 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45217798176136886, 'Total loss': 0.45217798176136886} | train loss {'Reaction outcome loss': 0.363006223924458, 'Total loss': 0.363006223924458}
2022-11-28 01:46:55,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:55,057 INFO:     Epoch: 13
2022-11-28 01:46:55,811 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4607538411563093, 'Total loss': 0.4607538411563093} | train loss {'Reaction outcome loss': 0.36756575854134654, 'Total loss': 0.36756575854134654}
2022-11-28 01:46:55,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:55,811 INFO:     Epoch: 14
2022-11-28 01:46:56,569 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49502790482206777, 'Total loss': 0.49502790482206777} | train loss {'Reaction outcome loss': 0.3569673201850345, 'Total loss': 0.3569673201850345}
2022-11-28 01:46:56,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:56,570 INFO:     Epoch: 15
2022-11-28 01:46:57,325 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4664343409240246, 'Total loss': 0.4664343409240246} | train loss {'Reaction outcome loss': 0.3595041329822233, 'Total loss': 0.3595041329822233}
2022-11-28 01:46:57,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:57,326 INFO:     Epoch: 16
2022-11-28 01:46:58,077 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4384255405854095, 'Total loss': 0.4384255405854095} | train loss {'Reaction outcome loss': 0.3543007738227325, 'Total loss': 0.3543007738227325}
2022-11-28 01:46:58,078 INFO:     Found new best model at epoch 16
2022-11-28 01:46:58,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:58,078 INFO:     Epoch: 17
2022-11-28 01:46:58,833 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43677218156782066, 'Total loss': 0.43677218156782066} | train loss {'Reaction outcome loss': 0.34659612001550777, 'Total loss': 0.34659612001550777}
2022-11-28 01:46:58,834 INFO:     Found new best model at epoch 17
2022-11-28 01:46:58,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:58,835 INFO:     Epoch: 18
2022-11-28 01:46:59,585 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46216206658970227, 'Total loss': 0.46216206658970227} | train loss {'Reaction outcome loss': 0.3491105982553094, 'Total loss': 0.3491105982553094}
2022-11-28 01:46:59,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:46:59,585 INFO:     Epoch: 19
2022-11-28 01:47:00,341 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4426492472941225, 'Total loss': 0.4426492472941225} | train loss {'Reaction outcome loss': 0.3413185231207359, 'Total loss': 0.3413185231207359}
2022-11-28 01:47:00,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:00,341 INFO:     Epoch: 20
2022-11-28 01:47:01,096 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4626775123178959, 'Total loss': 0.4626775123178959} | train loss {'Reaction outcome loss': 0.34074512721910594, 'Total loss': 0.34074512721910594}
2022-11-28 01:47:01,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:01,096 INFO:     Epoch: 21
2022-11-28 01:47:01,849 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44486689465967094, 'Total loss': 0.44486689465967094} | train loss {'Reaction outcome loss': 0.33971805014317075, 'Total loss': 0.33971805014317075}
2022-11-28 01:47:01,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:01,849 INFO:     Epoch: 22
2022-11-28 01:47:02,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4551582702181556, 'Total loss': 0.4551582702181556} | train loss {'Reaction outcome loss': 0.3474463011408525, 'Total loss': 0.3474463011408525}
2022-11-28 01:47:02,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:02,605 INFO:     Epoch: 23
2022-11-28 01:47:03,356 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4471175054257566, 'Total loss': 0.4471175054257566} | train loss {'Reaction outcome loss': 0.3322635093824037, 'Total loss': 0.3322635093824037}
2022-11-28 01:47:03,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:03,357 INFO:     Epoch: 24
2022-11-28 01:47:04,110 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4540117911317132, 'Total loss': 0.4540117911317132} | train loss {'Reaction outcome loss': 0.335924796159229, 'Total loss': 0.335924796159229}
2022-11-28 01:47:04,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:04,110 INFO:     Epoch: 25
2022-11-28 01:47:04,866 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46733359823172743, 'Total loss': 0.46733359823172743} | train loss {'Reaction outcome loss': 0.3332428287774805, 'Total loss': 0.3332428287774805}
2022-11-28 01:47:04,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:04,867 INFO:     Epoch: 26
2022-11-28 01:47:05,619 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47106317295269534, 'Total loss': 0.47106317295269534} | train loss {'Reaction outcome loss': 0.33256874877899406, 'Total loss': 0.33256874877899406}
2022-11-28 01:47:05,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:05,619 INFO:     Epoch: 27
2022-11-28 01:47:06,375 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44791868870908563, 'Total loss': 0.44791868870908563} | train loss {'Reaction outcome loss': 0.32596864734566017, 'Total loss': 0.32596864734566017}
2022-11-28 01:47:06,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:06,376 INFO:     Epoch: 28
2022-11-28 01:47:07,127 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.466374990276315, 'Total loss': 0.466374990276315} | train loss {'Reaction outcome loss': 0.3260149608456319, 'Total loss': 0.3260149608456319}
2022-11-28 01:47:07,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:07,127 INFO:     Epoch: 29
2022-11-28 01:47:07,882 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44306846606460487, 'Total loss': 0.44306846606460487} | train loss {'Reaction outcome loss': 0.32342259252383826, 'Total loss': 0.32342259252383826}
2022-11-28 01:47:07,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:07,882 INFO:     Epoch: 30
2022-11-28 01:47:08,636 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4475369587201964, 'Total loss': 0.4475369587201964} | train loss {'Reaction outcome loss': 0.32766615557334117, 'Total loss': 0.32766615557334117}
2022-11-28 01:47:08,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:08,636 INFO:     Epoch: 31
2022-11-28 01:47:09,392 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4433754442090338, 'Total loss': 0.4433754442090338} | train loss {'Reaction outcome loss': 0.3240825674166122, 'Total loss': 0.3240825674166122}
2022-11-28 01:47:09,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:09,392 INFO:     Epoch: 32
2022-11-28 01:47:10,144 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49058258364146407, 'Total loss': 0.49058258364146407} | train loss {'Reaction outcome loss': 0.3277514046058059, 'Total loss': 0.3277514046058059}
2022-11-28 01:47:10,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:10,145 INFO:     Epoch: 33
2022-11-28 01:47:10,896 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44448510625145654, 'Total loss': 0.44448510625145654} | train loss {'Reaction outcome loss': 0.32504564115116674, 'Total loss': 0.32504564115116674}
2022-11-28 01:47:10,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:10,897 INFO:     Epoch: 34
2022-11-28 01:47:11,651 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4610323536802422, 'Total loss': 0.4610323536802422} | train loss {'Reaction outcome loss': 0.3179919903557147, 'Total loss': 0.3179919903557147}
2022-11-28 01:47:11,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:11,651 INFO:     Epoch: 35
2022-11-28 01:47:12,407 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4530235058204694, 'Total loss': 0.4530235058204694} | train loss {'Reaction outcome loss': 0.32481251888337637, 'Total loss': 0.32481251888337637}
2022-11-28 01:47:12,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:12,407 INFO:     Epoch: 36
2022-11-28 01:47:13,160 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4550395076247779, 'Total loss': 0.4550395076247779} | train loss {'Reaction outcome loss': 0.31969388038100255, 'Total loss': 0.31969388038100255}
2022-11-28 01:47:13,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:13,161 INFO:     Epoch: 37
2022-11-28 01:47:13,911 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45773090489886026, 'Total loss': 0.45773090489886026} | train loss {'Reaction outcome loss': 0.32402230664006165, 'Total loss': 0.32402230664006165}
2022-11-28 01:47:13,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:13,911 INFO:     Epoch: 38
2022-11-28 01:47:14,663 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44722689722071995, 'Total loss': 0.44722689722071995} | train loss {'Reaction outcome loss': 0.3161718331938309, 'Total loss': 0.3161718331938309}
2022-11-28 01:47:14,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:14,664 INFO:     Epoch: 39
2022-11-28 01:47:15,418 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4717939496040344, 'Total loss': 0.4717939496040344} | train loss {'Reaction outcome loss': 0.307580592876841, 'Total loss': 0.307580592876841}
2022-11-28 01:47:15,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:15,419 INFO:     Epoch: 40
2022-11-28 01:47:16,170 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43653675202618947, 'Total loss': 0.43653675202618947} | train loss {'Reaction outcome loss': 0.32787841573477755, 'Total loss': 0.32787841573477755}
2022-11-28 01:47:16,170 INFO:     Found new best model at epoch 40
2022-11-28 01:47:16,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:16,172 INFO:     Epoch: 41
2022-11-28 01:47:16,929 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47729937224225566, 'Total loss': 0.47729937224225566} | train loss {'Reaction outcome loss': 0.3165806524695889, 'Total loss': 0.3165806524695889}
2022-11-28 01:47:16,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:16,929 INFO:     Epoch: 42
2022-11-28 01:47:17,686 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4463422042741017, 'Total loss': 0.4463422042741017} | train loss {'Reaction outcome loss': 0.30566104453417564, 'Total loss': 0.30566104453417564}
2022-11-28 01:47:17,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:17,687 INFO:     Epoch: 43
2022-11-28 01:47:18,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4254876488650387, 'Total loss': 0.4254876488650387} | train loss {'Reaction outcome loss': 0.3111401121282289, 'Total loss': 0.3111401121282289}
2022-11-28 01:47:18,444 INFO:     Found new best model at epoch 43
2022-11-28 01:47:18,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:18,445 INFO:     Epoch: 44
2022-11-28 01:47:19,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4463582032106139, 'Total loss': 0.4463582032106139} | train loss {'Reaction outcome loss': 0.31371990870684385, 'Total loss': 0.31371990870684385}
2022-11-28 01:47:19,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:19,201 INFO:     Epoch: 45
2022-11-28 01:47:19,955 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44618545743552124, 'Total loss': 0.44618545743552124} | train loss {'Reaction outcome loss': 0.31107623343386, 'Total loss': 0.31107623343386}
2022-11-28 01:47:19,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:19,955 INFO:     Epoch: 46
2022-11-28 01:47:20,711 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4618010007860986, 'Total loss': 0.4618010007860986} | train loss {'Reaction outcome loss': 0.31870885834007734, 'Total loss': 0.31870885834007734}
2022-11-28 01:47:20,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:20,711 INFO:     Epoch: 47
2022-11-28 01:47:21,468 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4364673722196709, 'Total loss': 0.4364673722196709} | train loss {'Reaction outcome loss': 0.31171567635911124, 'Total loss': 0.31171567635911124}
2022-11-28 01:47:21,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:21,468 INFO:     Epoch: 48
2022-11-28 01:47:22,228 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4373675100505352, 'Total loss': 0.4373675100505352} | train loss {'Reaction outcome loss': 0.306503462905605, 'Total loss': 0.306503462905605}
2022-11-28 01:47:22,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:22,228 INFO:     Epoch: 49
2022-11-28 01:47:22,988 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.436385551975532, 'Total loss': 0.436385551975532} | train loss {'Reaction outcome loss': 0.31348786037415266, 'Total loss': 0.31348786037415266}
2022-11-28 01:47:22,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:22,989 INFO:     Epoch: 50
2022-11-28 01:47:23,743 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46043978225101123, 'Total loss': 0.46043978225101123} | train loss {'Reaction outcome loss': 0.3123308946678956, 'Total loss': 0.3123308946678956}
2022-11-28 01:47:23,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:23,743 INFO:     Epoch: 51
2022-11-28 01:47:24,495 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44623654657466844, 'Total loss': 0.44623654657466844} | train loss {'Reaction outcome loss': 0.31263925787061453, 'Total loss': 0.31263925787061453}
2022-11-28 01:47:24,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:24,495 INFO:     Epoch: 52
2022-11-28 01:47:25,251 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42710785737091844, 'Total loss': 0.42710785737091844} | train loss {'Reaction outcome loss': 0.3030488767751282, 'Total loss': 0.3030488767751282}
2022-11-28 01:47:25,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:25,252 INFO:     Epoch: 53
2022-11-28 01:47:26,005 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43675959448922763, 'Total loss': 0.43675959448922763} | train loss {'Reaction outcome loss': 0.31151257269084454, 'Total loss': 0.31151257269084454}
2022-11-28 01:47:26,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:26,005 INFO:     Epoch: 54
2022-11-28 01:47:26,759 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45075070011344825, 'Total loss': 0.45075070011344825} | train loss {'Reaction outcome loss': 0.3173134559765458, 'Total loss': 0.3173134559765458}
2022-11-28 01:47:26,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:26,759 INFO:     Epoch: 55
2022-11-28 01:47:27,515 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4428914991969412, 'Total loss': 0.4428914991969412} | train loss {'Reaction outcome loss': 0.3149671539694311, 'Total loss': 0.3149671539694311}
2022-11-28 01:47:27,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:27,516 INFO:     Epoch: 56
2022-11-28 01:47:28,273 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4308276714926416, 'Total loss': 0.4308276714926416} | train loss {'Reaction outcome loss': 0.3034137198701501, 'Total loss': 0.3034137198701501}
2022-11-28 01:47:28,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:28,275 INFO:     Epoch: 57
2022-11-28 01:47:29,032 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5316429090770808, 'Total loss': 0.5316429090770808} | train loss {'Reaction outcome loss': 0.3031050055137565, 'Total loss': 0.3031050055137565}
2022-11-28 01:47:29,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:29,032 INFO:     Epoch: 58
2022-11-28 01:47:29,784 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44210165671326895, 'Total loss': 0.44210165671326895} | train loss {'Reaction outcome loss': 0.31864793475476966, 'Total loss': 0.31864793475476966}
2022-11-28 01:47:29,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:29,784 INFO:     Epoch: 59
2022-11-28 01:47:30,544 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44911866110156884, 'Total loss': 0.44911866110156884} | train loss {'Reaction outcome loss': 0.3045308003202081, 'Total loss': 0.3045308003202081}
2022-11-28 01:47:30,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:30,544 INFO:     Epoch: 60
2022-11-28 01:47:31,300 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44972866705872794, 'Total loss': 0.44972866705872794} | train loss {'Reaction outcome loss': 0.31141835592326617, 'Total loss': 0.31141835592326617}
2022-11-28 01:47:31,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:31,300 INFO:     Epoch: 61
2022-11-28 01:47:32,056 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4391396262428977, 'Total loss': 0.4391396262428977} | train loss {'Reaction outcome loss': 0.3028147332670708, 'Total loss': 0.3028147332670708}
2022-11-28 01:47:32,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:32,056 INFO:     Epoch: 62
2022-11-28 01:47:32,814 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4581640017303554, 'Total loss': 0.4581640017303554} | train loss {'Reaction outcome loss': 0.29946494342819335, 'Total loss': 0.29946494342819335}
2022-11-28 01:47:32,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:32,814 INFO:     Epoch: 63
2022-11-28 01:47:33,572 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47551019388166343, 'Total loss': 0.47551019388166343} | train loss {'Reaction outcome loss': 0.3149304162831076, 'Total loss': 0.3149304162831076}
2022-11-28 01:47:33,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:33,572 INFO:     Epoch: 64
2022-11-28 01:47:34,333 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4702916450121186, 'Total loss': 0.4702916450121186} | train loss {'Reaction outcome loss': 0.3105522248623592, 'Total loss': 0.3105522248623592}
2022-11-28 01:47:34,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:34,334 INFO:     Epoch: 65
2022-11-28 01:47:35,097 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43370225483720953, 'Total loss': 0.43370225483720953} | train loss {'Reaction outcome loss': 0.3095329013623057, 'Total loss': 0.3095329013623057}
2022-11-28 01:47:35,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:35,097 INFO:     Epoch: 66
2022-11-28 01:47:35,853 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4460495581681078, 'Total loss': 0.4460495581681078} | train loss {'Reaction outcome loss': 0.30154430385558834, 'Total loss': 0.30154430385558834}
2022-11-28 01:47:35,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:35,853 INFO:     Epoch: 67
2022-11-28 01:47:36,609 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45506272092461586, 'Total loss': 0.45506272092461586} | train loss {'Reaction outcome loss': 0.3029976685291096, 'Total loss': 0.3029976685291096}
2022-11-28 01:47:36,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:36,609 INFO:     Epoch: 68
2022-11-28 01:47:37,363 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4223765033212575, 'Total loss': 0.4223765033212575} | train loss {'Reaction outcome loss': 0.30537082396087145, 'Total loss': 0.30537082396087145}
2022-11-28 01:47:37,364 INFO:     Found new best model at epoch 68
2022-11-28 01:47:37,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:37,364 INFO:     Epoch: 69
2022-11-28 01:47:38,118 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4735096340829676, 'Total loss': 0.4735096340829676} | train loss {'Reaction outcome loss': 0.3043148209370913, 'Total loss': 0.3043148209370913}
2022-11-28 01:47:38,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:38,118 INFO:     Epoch: 70
2022-11-28 01:47:38,874 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44494261423295195, 'Total loss': 0.44494261423295195} | train loss {'Reaction outcome loss': 0.3014189919396754, 'Total loss': 0.3014189919396754}
2022-11-28 01:47:38,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:38,874 INFO:     Epoch: 71
2022-11-28 01:47:39,629 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47234708358618344, 'Total loss': 0.47234708358618344} | train loss {'Reaction outcome loss': 0.31526415413545983, 'Total loss': 0.31526415413545983}
2022-11-28 01:47:39,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:39,630 INFO:     Epoch: 72
2022-11-28 01:47:40,386 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4479550715874542, 'Total loss': 0.4479550715874542} | train loss {'Reaction outcome loss': 0.30687796778135723, 'Total loss': 0.30687796778135723}
2022-11-28 01:47:40,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:40,386 INFO:     Epoch: 73
2022-11-28 01:47:41,140 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47780839997259056, 'Total loss': 0.47780839997259056} | train loss {'Reaction outcome loss': 0.30139088600633607, 'Total loss': 0.30139088600633607}
2022-11-28 01:47:41,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:41,140 INFO:     Epoch: 74
2022-11-28 01:47:41,894 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45258103480393236, 'Total loss': 0.45258103480393236} | train loss {'Reaction outcome loss': 0.30271419346512807, 'Total loss': 0.30271419346512807}
2022-11-28 01:47:41,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:41,894 INFO:     Epoch: 75
2022-11-28 01:47:42,648 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4384252486581152, 'Total loss': 0.4384252486581152} | train loss {'Reaction outcome loss': 0.3120223778870798, 'Total loss': 0.3120223778870798}
2022-11-28 01:47:42,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:42,649 INFO:     Epoch: 76
2022-11-28 01:47:43,402 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43254430693658913, 'Total loss': 0.43254430693658913} | train loss {'Reaction outcome loss': 0.3200466261215268, 'Total loss': 0.3200466261215268}
2022-11-28 01:47:43,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:43,402 INFO:     Epoch: 77
2022-11-28 01:47:44,157 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4269700851291418, 'Total loss': 0.4269700851291418} | train loss {'Reaction outcome loss': 0.2994291609032981, 'Total loss': 0.2994291609032981}
2022-11-28 01:47:44,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:44,157 INFO:     Epoch: 78
2022-11-28 01:47:44,915 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42527980662205, 'Total loss': 0.42527980662205} | train loss {'Reaction outcome loss': 0.2984988045007471, 'Total loss': 0.2984988045007471}
2022-11-28 01:47:44,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:44,916 INFO:     Epoch: 79
2022-11-28 01:47:45,676 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46099998869679193, 'Total loss': 0.46099998869679193} | train loss {'Reaction outcome loss': 0.3128234584395203, 'Total loss': 0.3128234584395203}
2022-11-28 01:47:45,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:45,676 INFO:     Epoch: 80
2022-11-28 01:47:46,433 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4796437214721333, 'Total loss': 0.4796437214721333} | train loss {'Reaction outcome loss': 0.30486862893937333, 'Total loss': 0.30486862893937333}
2022-11-28 01:47:46,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:46,434 INFO:     Epoch: 81
2022-11-28 01:47:47,188 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4424992417069999, 'Total loss': 0.4424992417069999} | train loss {'Reaction outcome loss': 0.3000734779803503, 'Total loss': 0.3000734779803503}
2022-11-28 01:47:47,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:47,188 INFO:     Epoch: 82
2022-11-28 01:47:47,944 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42102679779583757, 'Total loss': 0.42102679779583757} | train loss {'Reaction outcome loss': 0.3094994917872452, 'Total loss': 0.3094994917872452}
2022-11-28 01:47:47,945 INFO:     Found new best model at epoch 82
2022-11-28 01:47:47,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:47,945 INFO:     Epoch: 83
2022-11-28 01:47:48,702 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4178861081600189, 'Total loss': 0.4178861081600189} | train loss {'Reaction outcome loss': 0.3085599443424613, 'Total loss': 0.3085599443424613}
2022-11-28 01:47:48,702 INFO:     Found new best model at epoch 83
2022-11-28 01:47:48,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:48,703 INFO:     Epoch: 84
2022-11-28 01:47:49,462 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4613173153590072, 'Total loss': 0.4613173153590072} | train loss {'Reaction outcome loss': 0.29642912933242416, 'Total loss': 0.29642912933242416}
2022-11-28 01:47:49,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:49,462 INFO:     Epoch: 85
2022-11-28 01:47:50,219 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4360204247588461, 'Total loss': 0.4360204247588461} | train loss {'Reaction outcome loss': 0.3121694123011924, 'Total loss': 0.3121694123011924}
2022-11-28 01:47:50,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:50,220 INFO:     Epoch: 86
2022-11-28 01:47:50,974 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4393884194168178, 'Total loss': 0.4393884194168178} | train loss {'Reaction outcome loss': 0.3042070297223906, 'Total loss': 0.3042070297223906}
2022-11-28 01:47:50,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:50,974 INFO:     Epoch: 87
2022-11-28 01:47:51,730 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44651769203218544, 'Total loss': 0.44651769203218544} | train loss {'Reaction outcome loss': 0.3106868950529925, 'Total loss': 0.3106868950529925}
2022-11-28 01:47:51,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:51,730 INFO:     Epoch: 88
2022-11-28 01:47:52,486 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4254938570613211, 'Total loss': 0.4254938570613211} | train loss {'Reaction outcome loss': 0.3168757643941189, 'Total loss': 0.3168757643941189}
2022-11-28 01:47:52,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:52,486 INFO:     Epoch: 89
2022-11-28 01:47:53,241 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42120329256762157, 'Total loss': 0.42120329256762157} | train loss {'Reaction outcome loss': 0.2987227869790889, 'Total loss': 0.2987227869790889}
2022-11-28 01:47:53,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:53,242 INFO:     Epoch: 90
2022-11-28 01:47:53,993 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41734733703461563, 'Total loss': 0.41734733703461563} | train loss {'Reaction outcome loss': 0.30360471484281365, 'Total loss': 0.30360471484281365}
2022-11-28 01:47:53,994 INFO:     Found new best model at epoch 90
2022-11-28 01:47:53,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:53,994 INFO:     Epoch: 91
2022-11-28 01:47:54,747 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4398230185562914, 'Total loss': 0.4398230185562914} | train loss {'Reaction outcome loss': 0.3016560288867162, 'Total loss': 0.3016560288867162}
2022-11-28 01:47:54,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:54,747 INFO:     Epoch: 92
2022-11-28 01:47:55,499 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46155124597928743, 'Total loss': 0.46155124597928743} | train loss {'Reaction outcome loss': 0.3002168553160323, 'Total loss': 0.3002168553160323}
2022-11-28 01:47:55,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:55,500 INFO:     Epoch: 93
2022-11-28 01:47:56,252 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4565317397090522, 'Total loss': 0.4565317397090522} | train loss {'Reaction outcome loss': 0.3030399438594618, 'Total loss': 0.3030399438594618}
2022-11-28 01:47:56,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:56,252 INFO:     Epoch: 94
2022-11-28 01:47:57,005 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43505358187989757, 'Total loss': 0.43505358187989757} | train loss {'Reaction outcome loss': 0.3075089802845351, 'Total loss': 0.3075089802845351}
2022-11-28 01:47:57,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:57,005 INFO:     Epoch: 95
2022-11-28 01:47:57,758 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4882336330007423, 'Total loss': 0.4882336330007423} | train loss {'Reaction outcome loss': 0.30390597825809834, 'Total loss': 0.30390597825809834}
2022-11-28 01:47:57,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:57,758 INFO:     Epoch: 96
2022-11-28 01:47:58,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44532524658875033, 'Total loss': 0.44532524658875033} | train loss {'Reaction outcome loss': 0.3067994148530547, 'Total loss': 0.3067994148530547}
2022-11-28 01:47:58,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:58,513 INFO:     Epoch: 97
2022-11-28 01:47:59,267 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4579422257163308, 'Total loss': 0.4579422257163308} | train loss {'Reaction outcome loss': 0.30126950006571507, 'Total loss': 0.30126950006571507}
2022-11-28 01:47:59,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:47:59,268 INFO:     Epoch: 98
2022-11-28 01:48:00,022 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4302702813663266, 'Total loss': 0.4302702813663266} | train loss {'Reaction outcome loss': 0.2981871060215898, 'Total loss': 0.2981871060215898}
2022-11-28 01:48:00,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:00,022 INFO:     Epoch: 99
2022-11-28 01:48:00,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4571259313009002, 'Total loss': 0.4571259313009002} | train loss {'Reaction outcome loss': 0.30012607754718873, 'Total loss': 0.30012607754718873}
2022-11-28 01:48:00,777 INFO:     Best model found after epoch 91 of 100.
2022-11-28 01:48:00,777 INFO:   Done with stage: TRAINING
2022-11-28 01:48:00,777 INFO:   Starting stage: EVALUATION
2022-11-28 01:48:00,895 INFO:   Done with stage: EVALUATION
2022-11-28 01:48:00,896 INFO:   Leaving out SEQ value Fold_5
2022-11-28 01:48:00,908 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:48:00,909 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:48:01,553 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:48:01,553 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:48:01,622 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:48:01,622 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:48:01,622 INFO:     No hyperparam tuning for this model
2022-11-28 01:48:01,622 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:48:01,622 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:48:01,622 INFO:     None feature selector for col prot
2022-11-28 01:48:01,623 INFO:     None feature selector for col prot
2022-11-28 01:48:01,623 INFO:     None feature selector for col prot
2022-11-28 01:48:01,623 INFO:     None feature selector for col chem
2022-11-28 01:48:01,623 INFO:     None feature selector for col chem
2022-11-28 01:48:01,623 INFO:     None feature selector for col chem
2022-11-28 01:48:01,623 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:48:01,624 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:48:01,625 INFO:     Number of params in model 169741
2022-11-28 01:48:01,628 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:48:01,628 INFO:   Starting stage: TRAINING
2022-11-28 01:48:01,682 INFO:     Val loss before train {'Reaction outcome loss': 1.0256535031578757, 'Total loss': 1.0256535031578757}
2022-11-28 01:48:01,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:01,682 INFO:     Epoch: 0
2022-11-28 01:48:02,436 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5253826467828318, 'Total loss': 0.5253826467828318} | train loss {'Reaction outcome loss': 0.636237210023307, 'Total loss': 0.636237210023307}
2022-11-28 01:48:02,436 INFO:     Found new best model at epoch 0
2022-11-28 01:48:02,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:02,437 INFO:     Epoch: 1
2022-11-28 01:48:03,191 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5525142150846395, 'Total loss': 0.5525142150846395} | train loss {'Reaction outcome loss': 0.5013237652639227, 'Total loss': 0.5013237652639227}
2022-11-28 01:48:03,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:03,191 INFO:     Epoch: 2
2022-11-28 01:48:03,943 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.478670750151981, 'Total loss': 0.478670750151981} | train loss {'Reaction outcome loss': 0.46008411200056154, 'Total loss': 0.46008411200056154}
2022-11-28 01:48:03,943 INFO:     Found new best model at epoch 2
2022-11-28 01:48:03,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:03,944 INFO:     Epoch: 3
2022-11-28 01:48:04,697 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49797656353224407, 'Total loss': 0.49797656353224407} | train loss {'Reaction outcome loss': 0.43207637509030683, 'Total loss': 0.43207637509030683}
2022-11-28 01:48:04,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:04,697 INFO:     Epoch: 4
2022-11-28 01:48:05,452 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4619178128513423, 'Total loss': 0.4619178128513423} | train loss {'Reaction outcome loss': 0.4268707022551567, 'Total loss': 0.4268707022551567}
2022-11-28 01:48:05,453 INFO:     Found new best model at epoch 4
2022-11-28 01:48:05,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:05,454 INFO:     Epoch: 5
2022-11-28 01:48:06,213 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4405366324565627, 'Total loss': 0.4405366324565627} | train loss {'Reaction outcome loss': 0.40743373406510197, 'Total loss': 0.40743373406510197}
2022-11-28 01:48:06,213 INFO:     Found new best model at epoch 5
2022-11-28 01:48:06,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:06,214 INFO:     Epoch: 6
2022-11-28 01:48:06,975 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4185849092900753, 'Total loss': 0.4185849092900753} | train loss {'Reaction outcome loss': 0.40128280120270865, 'Total loss': 0.40128280120270865}
2022-11-28 01:48:06,976 INFO:     Found new best model at epoch 6
2022-11-28 01:48:06,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:06,976 INFO:     Epoch: 7
2022-11-28 01:48:07,732 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49261440099640325, 'Total loss': 0.49261440099640325} | train loss {'Reaction outcome loss': 0.40396422403113497, 'Total loss': 0.40396422403113497}
2022-11-28 01:48:07,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:07,732 INFO:     Epoch: 8
2022-11-28 01:48:08,487 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42757627774368634, 'Total loss': 0.42757627774368634} | train loss {'Reaction outcome loss': 0.39444000367075205, 'Total loss': 0.39444000367075205}
2022-11-28 01:48:08,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:08,488 INFO:     Epoch: 9
2022-11-28 01:48:09,240 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4159656929021532, 'Total loss': 0.4159656929021532} | train loss {'Reaction outcome loss': 0.3828161127204376, 'Total loss': 0.3828161127204376}
2022-11-28 01:48:09,241 INFO:     Found new best model at epoch 9
2022-11-28 01:48:09,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:09,241 INFO:     Epoch: 10
2022-11-28 01:48:09,998 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4055453928356821, 'Total loss': 0.4055453928356821} | train loss {'Reaction outcome loss': 0.37877253058456606, 'Total loss': 0.37877253058456606}
2022-11-28 01:48:09,998 INFO:     Found new best model at epoch 10
2022-11-28 01:48:09,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:09,999 INFO:     Epoch: 11
2022-11-28 01:48:10,752 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45613374324007466, 'Total loss': 0.45613374324007466} | train loss {'Reaction outcome loss': 0.3648593819309627, 'Total loss': 0.3648593819309627}
2022-11-28 01:48:10,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:10,753 INFO:     Epoch: 12
2022-11-28 01:48:11,508 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4356789453463121, 'Total loss': 0.4356789453463121} | train loss {'Reaction outcome loss': 0.3653996906453563, 'Total loss': 0.3653996906453563}
2022-11-28 01:48:11,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:11,508 INFO:     Epoch: 13
2022-11-28 01:48:12,265 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4401068003340201, 'Total loss': 0.4401068003340201} | train loss {'Reaction outcome loss': 0.3616334768913446, 'Total loss': 0.3616334768913446}
2022-11-28 01:48:12,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:12,265 INFO:     Epoch: 14
2022-11-28 01:48:13,018 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46087560193105176, 'Total loss': 0.46087560193105176} | train loss {'Reaction outcome loss': 0.3669609251702505, 'Total loss': 0.3669609251702505}
2022-11-28 01:48:13,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:13,019 INFO:     Epoch: 15
2022-11-28 01:48:13,771 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4470433115281842, 'Total loss': 0.4470433115281842} | train loss {'Reaction outcome loss': 0.35854816025183084, 'Total loss': 0.35854816025183084}
2022-11-28 01:48:13,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:13,771 INFO:     Epoch: 16
2022-11-28 01:48:14,525 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4373745559291406, 'Total loss': 0.4373745559291406} | train loss {'Reaction outcome loss': 0.3579356539994478, 'Total loss': 0.3579356539994478}
2022-11-28 01:48:14,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:14,525 INFO:     Epoch: 17
2022-11-28 01:48:15,281 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42057663371617143, 'Total loss': 0.42057663371617143} | train loss {'Reaction outcome loss': 0.35125352640546137, 'Total loss': 0.35125352640546137}
2022-11-28 01:48:15,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:15,281 INFO:     Epoch: 18
2022-11-28 01:48:16,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43929228085008537, 'Total loss': 0.43929228085008537} | train loss {'Reaction outcome loss': 0.3552513918689182, 'Total loss': 0.3552513918689182}
2022-11-28 01:48:16,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:16,035 INFO:     Epoch: 19
2022-11-28 01:48:16,795 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.408295350657268, 'Total loss': 0.408295350657268} | train loss {'Reaction outcome loss': 0.3608948857253117, 'Total loss': 0.3608948857253117}
2022-11-28 01:48:16,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:16,795 INFO:     Epoch: 20
2022-11-28 01:48:17,550 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4602484462613409, 'Total loss': 0.4602484462613409} | train loss {'Reaction outcome loss': 0.34115940443570575, 'Total loss': 0.34115940443570575}
2022-11-28 01:48:17,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:17,551 INFO:     Epoch: 21
2022-11-28 01:48:18,306 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4317506748166951, 'Total loss': 0.4317506748166951} | train loss {'Reaction outcome loss': 0.34549318199917195, 'Total loss': 0.34549318199917195}
2022-11-28 01:48:18,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:18,306 INFO:     Epoch: 22
2022-11-28 01:48:19,066 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4592418091540987, 'Total loss': 0.4592418091540987} | train loss {'Reaction outcome loss': 0.33610672503709793, 'Total loss': 0.33610672503709793}
2022-11-28 01:48:19,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:19,066 INFO:     Epoch: 23
2022-11-28 01:48:19,825 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4281744933263822, 'Total loss': 0.4281744933263822} | train loss {'Reaction outcome loss': 0.3412287365945597, 'Total loss': 0.3412287365945597}
2022-11-28 01:48:19,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:19,825 INFO:     Epoch: 24
2022-11-28 01:48:20,581 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44134622744538565, 'Total loss': 0.44134622744538565} | train loss {'Reaction outcome loss': 0.3451138650998473, 'Total loss': 0.3451138650998473}
2022-11-28 01:48:20,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:20,581 INFO:     Epoch: 25
2022-11-28 01:48:21,338 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43825468488714914, 'Total loss': 0.43825468488714914} | train loss {'Reaction outcome loss': 0.3459526464162815, 'Total loss': 0.3459526464162815}
2022-11-28 01:48:21,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:21,338 INFO:     Epoch: 26
2022-11-28 01:48:22,093 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4292578568512743, 'Total loss': 0.4292578568512743} | train loss {'Reaction outcome loss': 0.33873338210246257, 'Total loss': 0.33873338210246257}
2022-11-28 01:48:22,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:22,093 INFO:     Epoch: 27
2022-11-28 01:48:22,847 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45710522444410756, 'Total loss': 0.45710522444410756} | train loss {'Reaction outcome loss': 0.3340058061219151, 'Total loss': 0.3340058061219151}
2022-11-28 01:48:22,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:22,848 INFO:     Epoch: 28
2022-11-28 01:48:23,601 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44298304769803176, 'Total loss': 0.44298304769803176} | train loss {'Reaction outcome loss': 0.33370308959556205, 'Total loss': 0.33370308959556205}
2022-11-28 01:48:23,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:23,601 INFO:     Epoch: 29
2022-11-28 01:48:24,360 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43278961357745255, 'Total loss': 0.43278961357745255} | train loss {'Reaction outcome loss': 0.33404836518269393, 'Total loss': 0.33404836518269393}
2022-11-28 01:48:24,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:24,360 INFO:     Epoch: 30
2022-11-28 01:48:25,115 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4183658307248896, 'Total loss': 0.4183658307248896} | train loss {'Reaction outcome loss': 0.3370297664115506, 'Total loss': 0.3370297664115506}
2022-11-28 01:48:25,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:25,115 INFO:     Epoch: 31
2022-11-28 01:48:25,871 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4315468557178974, 'Total loss': 0.4315468557178974} | train loss {'Reaction outcome loss': 0.3312372572179283, 'Total loss': 0.3312372572179283}
2022-11-28 01:48:25,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:25,872 INFO:     Epoch: 32
2022-11-28 01:48:26,627 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.409782100468874, 'Total loss': 0.409782100468874} | train loss {'Reaction outcome loss': 0.33258848982833084, 'Total loss': 0.33258848982833084}
2022-11-28 01:48:26,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:26,627 INFO:     Epoch: 33
2022-11-28 01:48:27,381 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42284804074601695, 'Total loss': 0.42284804074601695} | train loss {'Reaction outcome loss': 0.3310422870000043, 'Total loss': 0.3310422870000043}
2022-11-28 01:48:27,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:27,381 INFO:     Epoch: 34
2022-11-28 01:48:28,137 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4305012182078578, 'Total loss': 0.4305012182078578} | train loss {'Reaction outcome loss': 0.3389304951734601, 'Total loss': 0.3389304951734601}
2022-11-28 01:48:28,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:28,137 INFO:     Epoch: 35
2022-11-28 01:48:28,895 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4230014116249301, 'Total loss': 0.4230014116249301} | train loss {'Reaction outcome loss': 0.33412028997836096, 'Total loss': 0.33412028997836096}
2022-11-28 01:48:28,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:28,895 INFO:     Epoch: 36
2022-11-28 01:48:29,650 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.424240321259607, 'Total loss': 0.424240321259607} | train loss {'Reaction outcome loss': 0.32947494714490827, 'Total loss': 0.32947494714490827}
2022-11-28 01:48:29,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:29,650 INFO:     Epoch: 37
2022-11-28 01:48:30,403 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43071336536244914, 'Total loss': 0.43071336536244914} | train loss {'Reaction outcome loss': 0.33278073139128184, 'Total loss': 0.33278073139128184}
2022-11-28 01:48:30,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:30,404 INFO:     Epoch: 38
2022-11-28 01:48:31,159 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42097673869945784, 'Total loss': 0.42097673869945784} | train loss {'Reaction outcome loss': 0.32572175421181226, 'Total loss': 0.32572175421181226}
2022-11-28 01:48:31,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:31,159 INFO:     Epoch: 39
2022-11-28 01:48:31,917 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4461580795997923, 'Total loss': 0.4461580795997923} | train loss {'Reaction outcome loss': 0.3280320588138796, 'Total loss': 0.3280320588138796}
2022-11-28 01:48:31,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:31,917 INFO:     Epoch: 40
2022-11-28 01:48:32,672 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4440041756765409, 'Total loss': 0.4440041756765409} | train loss {'Reaction outcome loss': 0.33211957188623564, 'Total loss': 0.33211957188623564}
2022-11-28 01:48:32,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:32,673 INFO:     Epoch: 41
2022-11-28 01:48:33,425 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4769139095124873, 'Total loss': 0.4769139095124873} | train loss {'Reaction outcome loss': 0.35049702257158294, 'Total loss': 0.35049702257158294}
2022-11-28 01:48:33,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:33,425 INFO:     Epoch: 42
2022-11-28 01:48:34,179 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.399891638958996, 'Total loss': 0.399891638958996} | train loss {'Reaction outcome loss': 0.33000000235774823, 'Total loss': 0.33000000235774823}
2022-11-28 01:48:34,180 INFO:     Found new best model at epoch 42
2022-11-28 01:48:34,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:34,180 INFO:     Epoch: 43
2022-11-28 01:48:34,935 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42075897550041025, 'Total loss': 0.42075897550041025} | train loss {'Reaction outcome loss': 0.3186985538791745, 'Total loss': 0.3186985538791745}
2022-11-28 01:48:34,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:34,935 INFO:     Epoch: 44
2022-11-28 01:48:35,689 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44145590405572543, 'Total loss': 0.44145590405572543} | train loss {'Reaction outcome loss': 0.3219681332008012, 'Total loss': 0.3219681332008012}
2022-11-28 01:48:35,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:35,689 INFO:     Epoch: 45
2022-11-28 01:48:36,445 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4062790315259587, 'Total loss': 0.4062790315259587} | train loss {'Reaction outcome loss': 0.32728091968343626, 'Total loss': 0.32728091968343626}
2022-11-28 01:48:36,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:36,446 INFO:     Epoch: 46
2022-11-28 01:48:37,207 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4404475580562245, 'Total loss': 0.4404475580562245} | train loss {'Reaction outcome loss': 0.32636600483449235, 'Total loss': 0.32636600483449235}
2022-11-28 01:48:37,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:37,207 INFO:     Epoch: 47
2022-11-28 01:48:37,969 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4361430782486092, 'Total loss': 0.4361430782486092} | train loss {'Reaction outcome loss': 0.31869806820947316, 'Total loss': 0.31869806820947316}
2022-11-28 01:48:37,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:37,970 INFO:     Epoch: 48
2022-11-28 01:48:38,729 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4442458833483132, 'Total loss': 0.4442458833483132} | train loss {'Reaction outcome loss': 0.32008489813174934, 'Total loss': 0.32008489813174934}
2022-11-28 01:48:38,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:38,729 INFO:     Epoch: 49
2022-11-28 01:48:39,482 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.424066232686693, 'Total loss': 0.424066232686693} | train loss {'Reaction outcome loss': 0.32554349656246845, 'Total loss': 0.32554349656246845}
2022-11-28 01:48:39,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:39,482 INFO:     Epoch: 50
2022-11-28 01:48:40,236 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4167806089601733, 'Total loss': 0.4167806089601733} | train loss {'Reaction outcome loss': 0.3298115713461753, 'Total loss': 0.3298115713461753}
2022-11-28 01:48:40,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:40,236 INFO:     Epoch: 51
2022-11-28 01:48:40,993 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43566823344339023, 'Total loss': 0.43566823344339023} | train loss {'Reaction outcome loss': 0.3266189525264405, 'Total loss': 0.3266189525264405}
2022-11-28 01:48:40,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:40,993 INFO:     Epoch: 52
2022-11-28 01:48:41,747 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39166228202256287, 'Total loss': 0.39166228202256287} | train loss {'Reaction outcome loss': 0.32030264726809915, 'Total loss': 0.32030264726809915}
2022-11-28 01:48:41,747 INFO:     Found new best model at epoch 52
2022-11-28 01:48:41,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:41,748 INFO:     Epoch: 53
2022-11-28 01:48:42,502 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4158350915055383, 'Total loss': 0.4158350915055383} | train loss {'Reaction outcome loss': 0.3263367418380034, 'Total loss': 0.3263367418380034}
2022-11-28 01:48:42,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:42,502 INFO:     Epoch: 54
2022-11-28 01:48:43,257 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40633391216397285, 'Total loss': 0.40633391216397285} | train loss {'Reaction outcome loss': 0.31628393336770033, 'Total loss': 0.31628393336770033}
2022-11-28 01:48:43,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:43,258 INFO:     Epoch: 55
2022-11-28 01:48:44,010 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4341219099746509, 'Total loss': 0.4341219099746509} | train loss {'Reaction outcome loss': 0.3151970057928514, 'Total loss': 0.3151970057928514}
2022-11-28 01:48:44,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:44,011 INFO:     Epoch: 56
2022-11-28 01:48:44,765 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42227065630934457, 'Total loss': 0.42227065630934457} | train loss {'Reaction outcome loss': 0.32180685952546134, 'Total loss': 0.32180685952546134}
2022-11-28 01:48:44,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:44,765 INFO:     Epoch: 57
2022-11-28 01:48:45,520 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4304047003388405, 'Total loss': 0.4304047003388405} | train loss {'Reaction outcome loss': 0.32420732092953497, 'Total loss': 0.32420732092953497}
2022-11-28 01:48:45,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:45,521 INFO:     Epoch: 58
2022-11-28 01:48:46,276 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4825263060629368, 'Total loss': 0.4825263060629368} | train loss {'Reaction outcome loss': 0.3200692081553561, 'Total loss': 0.3200692081553561}
2022-11-28 01:48:46,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:46,277 INFO:     Epoch: 59
2022-11-28 01:48:47,026 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4343842984261838, 'Total loss': 0.4343842984261838} | train loss {'Reaction outcome loss': 0.32094991985227794, 'Total loss': 0.32094991985227794}
2022-11-28 01:48:47,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:47,026 INFO:     Epoch: 60
2022-11-28 01:48:47,778 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4667575254359029, 'Total loss': 0.4667575254359029} | train loss {'Reaction outcome loss': 0.32248424047664287, 'Total loss': 0.32248424047664287}
2022-11-28 01:48:47,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:47,778 INFO:     Epoch: 61
2022-11-28 01:48:48,531 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4230695619163188, 'Total loss': 0.4230695619163188} | train loss {'Reaction outcome loss': 0.3171743781516148, 'Total loss': 0.3171743781516148}
2022-11-28 01:48:48,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:48,532 INFO:     Epoch: 62
2022-11-28 01:48:49,287 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4083772128955884, 'Total loss': 0.4083772128955884} | train loss {'Reaction outcome loss': 0.3162445161611803, 'Total loss': 0.3162445161611803}
2022-11-28 01:48:49,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:49,288 INFO:     Epoch: 63
2022-11-28 01:48:50,042 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41009662994606927, 'Total loss': 0.41009662994606927} | train loss {'Reaction outcome loss': 0.3201540677898353, 'Total loss': 0.3201540677898353}
2022-11-28 01:48:50,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:50,042 INFO:     Epoch: 64
2022-11-28 01:48:50,795 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4536424743180925, 'Total loss': 0.4536424743180925} | train loss {'Reaction outcome loss': 0.31811185667832054, 'Total loss': 0.31811185667832054}
2022-11-28 01:48:50,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:50,796 INFO:     Epoch: 65
2022-11-28 01:48:51,551 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4047852520915595, 'Total loss': 0.4047852520915595} | train loss {'Reaction outcome loss': 0.31261398449480055, 'Total loss': 0.31261398449480055}
2022-11-28 01:48:51,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:51,551 INFO:     Epoch: 66
2022-11-28 01:48:52,303 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4362309652126648, 'Total loss': 0.4362309652126648} | train loss {'Reaction outcome loss': 0.3153097529955689, 'Total loss': 0.3153097529955689}
2022-11-28 01:48:52,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:52,304 INFO:     Epoch: 67
2022-11-28 01:48:53,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40483639761805534, 'Total loss': 0.40483639761805534} | train loss {'Reaction outcome loss': 0.32182028021423087, 'Total loss': 0.32182028021423087}
2022-11-28 01:48:53,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:53,055 INFO:     Epoch: 68
2022-11-28 01:48:53,810 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43539407375183975, 'Total loss': 0.43539407375183975} | train loss {'Reaction outcome loss': 0.31490421171991095, 'Total loss': 0.31490421171991095}
2022-11-28 01:48:53,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:53,810 INFO:     Epoch: 69
2022-11-28 01:48:54,563 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4342698138207197, 'Total loss': 0.4342698138207197} | train loss {'Reaction outcome loss': 0.3214422246861842, 'Total loss': 0.3214422246861842}
2022-11-28 01:48:54,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:54,563 INFO:     Epoch: 70
2022-11-28 01:48:55,316 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.428992420096289, 'Total loss': 0.428992420096289} | train loss {'Reaction outcome loss': 0.316376582418959, 'Total loss': 0.316376582418959}
2022-11-28 01:48:55,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:55,316 INFO:     Epoch: 71
2022-11-28 01:48:56,072 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4321147667413408, 'Total loss': 0.4321147667413408} | train loss {'Reaction outcome loss': 0.3159580010800592, 'Total loss': 0.3159580010800592}
2022-11-28 01:48:56,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:56,072 INFO:     Epoch: 72
2022-11-28 01:48:56,826 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4680650569498539, 'Total loss': 0.4680650569498539} | train loss {'Reaction outcome loss': 0.3204876042361702, 'Total loss': 0.3204876042361702}
2022-11-28 01:48:56,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:56,826 INFO:     Epoch: 73
2022-11-28 01:48:57,579 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42860054004598747, 'Total loss': 0.42860054004598747} | train loss {'Reaction outcome loss': 0.31675101293911856, 'Total loss': 0.31675101293911856}
2022-11-28 01:48:57,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:57,579 INFO:     Epoch: 74
2022-11-28 01:48:58,330 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4427663539959626, 'Total loss': 0.4427663539959626} | train loss {'Reaction outcome loss': 0.31275594814289964, 'Total loss': 0.31275594814289964}
2022-11-28 01:48:58,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:58,330 INFO:     Epoch: 75
2022-11-28 01:48:59,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4769203618846156, 'Total loss': 0.4769203618846156} | train loss {'Reaction outcome loss': 0.3149911081418395, 'Total loss': 0.3149911081418395}
2022-11-28 01:48:59,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:59,083 INFO:     Epoch: 76
2022-11-28 01:48:59,838 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40751637010411784, 'Total loss': 0.40751637010411784} | train loss {'Reaction outcome loss': 0.3178618629463017, 'Total loss': 0.3178618629463017}
2022-11-28 01:48:59,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:48:59,838 INFO:     Epoch: 77
2022-11-28 01:49:00,594 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4558925459330732, 'Total loss': 0.4558925459330732} | train loss {'Reaction outcome loss': 0.317200914445904, 'Total loss': 0.317200914445904}
2022-11-28 01:49:00,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:00,594 INFO:     Epoch: 78
2022-11-28 01:49:01,349 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42560069770975545, 'Total loss': 0.42560069770975545} | train loss {'Reaction outcome loss': 0.31677479269884284, 'Total loss': 0.31677479269884284}
2022-11-28 01:49:01,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:01,351 INFO:     Epoch: 79
2022-11-28 01:49:02,106 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4393661499700763, 'Total loss': 0.4393661499700763} | train loss {'Reaction outcome loss': 0.31900435920444226, 'Total loss': 0.31900435920444226}
2022-11-28 01:49:02,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:02,107 INFO:     Epoch: 80
2022-11-28 01:49:02,863 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41377750056033785, 'Total loss': 0.41377750056033785} | train loss {'Reaction outcome loss': 0.31534419696958316, 'Total loss': 0.31534419696958316}
2022-11-28 01:49:02,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:02,863 INFO:     Epoch: 81
2022-11-28 01:49:03,619 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41233277083797887, 'Total loss': 0.41233277083797887} | train loss {'Reaction outcome loss': 0.31827889483482125, 'Total loss': 0.31827889483482125}
2022-11-28 01:49:03,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:03,620 INFO:     Epoch: 82
2022-11-28 01:49:04,375 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46445825255729933, 'Total loss': 0.46445825255729933} | train loss {'Reaction outcome loss': 0.30862521707651114, 'Total loss': 0.30862521707651114}
2022-11-28 01:49:04,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:04,375 INFO:     Epoch: 83
2022-11-28 01:49:05,130 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4237206886437806, 'Total loss': 0.4237206886437806} | train loss {'Reaction outcome loss': 0.32394512784817525, 'Total loss': 0.32394512784817525}
2022-11-28 01:49:05,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:05,130 INFO:     Epoch: 84
2022-11-28 01:49:05,885 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.434562739323486, 'Total loss': 0.434562739323486} | train loss {'Reaction outcome loss': 0.3266094367830984, 'Total loss': 0.3266094367830984}
2022-11-28 01:49:05,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:05,885 INFO:     Epoch: 85
2022-11-28 01:49:06,647 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42773978073488583, 'Total loss': 0.42773978073488583} | train loss {'Reaction outcome loss': 0.3173860964034834, 'Total loss': 0.3173860964034834}
2022-11-28 01:49:06,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:06,647 INFO:     Epoch: 86
2022-11-28 01:49:07,409 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4293200539594347, 'Total loss': 0.4293200539594347} | train loss {'Reaction outcome loss': 0.3118999910150324, 'Total loss': 0.3118999910150324}
2022-11-28 01:49:07,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:07,410 INFO:     Epoch: 87
2022-11-28 01:49:08,173 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4360412518409165, 'Total loss': 0.4360412518409165} | train loss {'Reaction outcome loss': 0.311495719462513, 'Total loss': 0.311495719462513}
2022-11-28 01:49:08,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:08,173 INFO:     Epoch: 88
2022-11-28 01:49:08,932 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43770277813415637, 'Total loss': 0.43770277813415637} | train loss {'Reaction outcome loss': 0.3105765987458008, 'Total loss': 0.3105765987458008}
2022-11-28 01:49:08,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:08,932 INFO:     Epoch: 89
2022-11-28 01:49:09,688 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4403462552211501, 'Total loss': 0.4403462552211501} | train loss {'Reaction outcome loss': 0.3192828266971534, 'Total loss': 0.3192828266971534}
2022-11-28 01:49:09,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:09,689 INFO:     Epoch: 90
2022-11-28 01:49:10,443 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4433612098748034, 'Total loss': 0.4433612098748034} | train loss {'Reaction outcome loss': 0.30824112593226377, 'Total loss': 0.30824112593226377}
2022-11-28 01:49:10,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:10,443 INFO:     Epoch: 91
2022-11-28 01:49:11,197 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4319988451898098, 'Total loss': 0.4319988451898098} | train loss {'Reaction outcome loss': 0.31660362071688136, 'Total loss': 0.31660362071688136}
2022-11-28 01:49:11,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:11,197 INFO:     Epoch: 92
2022-11-28 01:49:11,951 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4607344994490797, 'Total loss': 0.4607344994490797} | train loss {'Reaction outcome loss': 0.3103681788329155, 'Total loss': 0.3103681788329155}
2022-11-28 01:49:11,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:11,951 INFO:     Epoch: 93
2022-11-28 01:49:12,709 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4282864130694758, 'Total loss': 0.4282864130694758} | train loss {'Reaction outcome loss': 0.3114588431893818, 'Total loss': 0.3114588431893818}
2022-11-28 01:49:12,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:12,709 INFO:     Epoch: 94
2022-11-28 01:49:13,463 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4399236770854755, 'Total loss': 0.4399236770854755} | train loss {'Reaction outcome loss': 0.3077352888161136, 'Total loss': 0.3077352888161136}
2022-11-28 01:49:13,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:13,464 INFO:     Epoch: 95
2022-11-28 01:49:14,217 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43598122928630223, 'Total loss': 0.43598122928630223} | train loss {'Reaction outcome loss': 0.307162998724849, 'Total loss': 0.307162998724849}
2022-11-28 01:49:14,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:14,217 INFO:     Epoch: 96
2022-11-28 01:49:14,975 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43053484369408, 'Total loss': 0.43053484369408} | train loss {'Reaction outcome loss': 0.3134303176024508, 'Total loss': 0.3134303176024508}
2022-11-28 01:49:14,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:14,975 INFO:     Epoch: 97
2022-11-28 01:49:15,731 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4378669976510785, 'Total loss': 0.4378669976510785} | train loss {'Reaction outcome loss': 0.32272080848774604, 'Total loss': 0.32272080848774604}
2022-11-28 01:49:15,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:15,731 INFO:     Epoch: 98
2022-11-28 01:49:16,483 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42832222140648146, 'Total loss': 0.42832222140648146} | train loss {'Reaction outcome loss': 0.31492084082997135, 'Total loss': 0.31492084082997135}
2022-11-28 01:49:16,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:16,484 INFO:     Epoch: 99
2022-11-28 01:49:17,237 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41035999171435833, 'Total loss': 0.41035999171435833} | train loss {'Reaction outcome loss': 0.31333615399536585, 'Total loss': 0.31333615399536585}
2022-11-28 01:49:17,237 INFO:     Best model found after epoch 53 of 100.
2022-11-28 01:49:17,237 INFO:   Done with stage: TRAINING
2022-11-28 01:49:17,237 INFO:   Starting stage: EVALUATION
2022-11-28 01:49:17,356 INFO:   Done with stage: EVALUATION
2022-11-28 01:49:17,356 INFO:   Leaving out SEQ value Fold_6
2022-11-28 01:49:17,369 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:49:17,369 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:49:18,018 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:49:18,018 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:49:18,087 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:49:18,087 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:49:18,087 INFO:     No hyperparam tuning for this model
2022-11-28 01:49:18,087 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:49:18,087 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:49:18,088 INFO:     None feature selector for col prot
2022-11-28 01:49:18,088 INFO:     None feature selector for col prot
2022-11-28 01:49:18,088 INFO:     None feature selector for col prot
2022-11-28 01:49:18,088 INFO:     None feature selector for col chem
2022-11-28 01:49:18,089 INFO:     None feature selector for col chem
2022-11-28 01:49:18,089 INFO:     None feature selector for col chem
2022-11-28 01:49:18,089 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:49:18,089 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:49:18,090 INFO:     Number of params in model 169741
2022-11-28 01:49:18,093 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:49:18,093 INFO:   Starting stage: TRAINING
2022-11-28 01:49:18,148 INFO:     Val loss before train {'Reaction outcome loss': 0.9833637570792978, 'Total loss': 0.9833637570792978}
2022-11-28 01:49:18,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:18,148 INFO:     Epoch: 0
2022-11-28 01:49:18,908 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5556234595450488, 'Total loss': 0.5556234595450488} | train loss {'Reaction outcome loss': 0.6379369983990346, 'Total loss': 0.6379369983990346}
2022-11-28 01:49:18,908 INFO:     Found new best model at epoch 0
2022-11-28 01:49:18,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:18,909 INFO:     Epoch: 1
2022-11-28 01:49:19,662 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4775999716737054, 'Total loss': 0.4775999716737054} | train loss {'Reaction outcome loss': 0.512841078542894, 'Total loss': 0.512841078542894}
2022-11-28 01:49:19,663 INFO:     Found new best model at epoch 1
2022-11-28 01:49:19,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:19,664 INFO:     Epoch: 2
2022-11-28 01:49:20,415 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4757836213843389, 'Total loss': 0.4757836213843389} | train loss {'Reaction outcome loss': 0.46759517106317705, 'Total loss': 0.46759517106317705}
2022-11-28 01:49:20,415 INFO:     Found new best model at epoch 2
2022-11-28 01:49:20,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:20,416 INFO:     Epoch: 3
2022-11-28 01:49:21,173 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4318311383778399, 'Total loss': 0.4318311383778399} | train loss {'Reaction outcome loss': 0.44468014501035213, 'Total loss': 0.44468014501035213}
2022-11-28 01:49:21,173 INFO:     Found new best model at epoch 3
2022-11-28 01:49:21,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:21,174 INFO:     Epoch: 4
2022-11-28 01:49:21,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4669537103988908, 'Total loss': 0.4669537103988908} | train loss {'Reaction outcome loss': 0.4327825096345717, 'Total loss': 0.4327825096345717}
2022-11-28 01:49:21,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:21,926 INFO:     Epoch: 5
2022-11-28 01:49:22,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46956010738557036, 'Total loss': 0.46956010738557036} | train loss {'Reaction outcome loss': 0.41850440609719486, 'Total loss': 0.41850440609719486}
2022-11-28 01:49:22,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:22,673 INFO:     Epoch: 6
2022-11-28 01:49:23,420 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43250814283435995, 'Total loss': 0.43250814283435995} | train loss {'Reaction outcome loss': 0.40746819176861354, 'Total loss': 0.40746819176861354}
2022-11-28 01:49:23,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:23,420 INFO:     Epoch: 7
2022-11-28 01:49:24,172 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42795762182636693, 'Total loss': 0.42795762182636693} | train loss {'Reaction outcome loss': 0.3983246318455185, 'Total loss': 0.3983246318455185}
2022-11-28 01:49:24,172 INFO:     Found new best model at epoch 7
2022-11-28 01:49:24,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:24,173 INFO:     Epoch: 8
2022-11-28 01:49:24,923 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4522628371011127, 'Total loss': 0.4522628371011127} | train loss {'Reaction outcome loss': 0.39156679682914286, 'Total loss': 0.39156679682914286}
2022-11-28 01:49:24,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:24,923 INFO:     Epoch: 9
2022-11-28 01:49:25,676 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4587933841076764, 'Total loss': 0.4587933841076764} | train loss {'Reaction outcome loss': 0.390772987457533, 'Total loss': 0.390772987457533}
2022-11-28 01:49:25,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:25,677 INFO:     Epoch: 10
2022-11-28 01:49:26,431 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.421169249848886, 'Total loss': 0.421169249848886} | train loss {'Reaction outcome loss': 0.38621661517648925, 'Total loss': 0.38621661517648925}
2022-11-28 01:49:26,431 INFO:     Found new best model at epoch 10
2022-11-28 01:49:26,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:26,432 INFO:     Epoch: 11
2022-11-28 01:49:27,182 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43168439428237354, 'Total loss': 0.43168439428237354} | train loss {'Reaction outcome loss': 0.37599895470925876, 'Total loss': 0.37599895470925876}
2022-11-28 01:49:27,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:27,182 INFO:     Epoch: 12
2022-11-28 01:49:27,930 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4639073864302852, 'Total loss': 0.4639073864302852} | train loss {'Reaction outcome loss': 0.38042103997882337, 'Total loss': 0.38042103997882337}
2022-11-28 01:49:27,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:27,930 INFO:     Epoch: 13
2022-11-28 01:49:28,677 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4144912599162622, 'Total loss': 0.4144912599162622} | train loss {'Reaction outcome loss': 0.376845418054971, 'Total loss': 0.376845418054971}
2022-11-28 01:49:28,677 INFO:     Found new best model at epoch 13
2022-11-28 01:49:28,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:28,678 INFO:     Epoch: 14
2022-11-28 01:49:29,423 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4380500851707025, 'Total loss': 0.4380500851707025} | train loss {'Reaction outcome loss': 0.3693502546107817, 'Total loss': 0.3693502546107817}
2022-11-28 01:49:29,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:29,423 INFO:     Epoch: 15
2022-11-28 01:49:30,173 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4464691792699424, 'Total loss': 0.4464691792699424} | train loss {'Reaction outcome loss': 0.3714351134014226, 'Total loss': 0.3714351134014226}
2022-11-28 01:49:30,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:30,173 INFO:     Epoch: 16
2022-11-28 01:49:30,922 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42992207915945485, 'Total loss': 0.42992207915945485} | train loss {'Reaction outcome loss': 0.3612719551630078, 'Total loss': 0.3612719551630078}
2022-11-28 01:49:30,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:30,922 INFO:     Epoch: 17
2022-11-28 01:49:31,671 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43301367658105766, 'Total loss': 0.43301367658105766} | train loss {'Reaction outcome loss': 0.3629316760587596, 'Total loss': 0.3629316760587596}
2022-11-28 01:49:31,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:31,671 INFO:     Epoch: 18
2022-11-28 01:49:32,420 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42819836871190503, 'Total loss': 0.42819836871190503} | train loss {'Reaction outcome loss': 0.3718001314048325, 'Total loss': 0.3718001314048325}
2022-11-28 01:49:32,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:32,422 INFO:     Epoch: 19
2022-11-28 01:49:33,170 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4281778977337209, 'Total loss': 0.4281778977337209} | train loss {'Reaction outcome loss': 0.36025078180095843, 'Total loss': 0.36025078180095843}
2022-11-28 01:49:33,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:33,170 INFO:     Epoch: 20
2022-11-28 01:49:33,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4206020317294381, 'Total loss': 0.4206020317294381} | train loss {'Reaction outcome loss': 0.3524348131350933, 'Total loss': 0.3524348131350933}
2022-11-28 01:49:33,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:33,920 INFO:     Epoch: 21
2022-11-28 01:49:34,666 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4319203136996789, 'Total loss': 0.4319203136996789} | train loss {'Reaction outcome loss': 0.3542986516990969, 'Total loss': 0.3542986516990969}
2022-11-28 01:49:34,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:34,667 INFO:     Epoch: 22
2022-11-28 01:49:35,415 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4363685358654369, 'Total loss': 0.4363685358654369} | train loss {'Reaction outcome loss': 0.3523309482862392, 'Total loss': 0.3523309482862392}
2022-11-28 01:49:35,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:35,415 INFO:     Epoch: 23
2022-11-28 01:49:36,163 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42254362390799954, 'Total loss': 0.42254362390799954} | train loss {'Reaction outcome loss': 0.3430000146730773, 'Total loss': 0.3430000146730773}
2022-11-28 01:49:36,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:36,163 INFO:     Epoch: 24
2022-11-28 01:49:36,911 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43765684217214584, 'Total loss': 0.43765684217214584} | train loss {'Reaction outcome loss': 0.347652664918813, 'Total loss': 0.347652664918813}
2022-11-28 01:49:36,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:36,911 INFO:     Epoch: 25
2022-11-28 01:49:37,659 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43846755440939555, 'Total loss': 0.43846755440939555} | train loss {'Reaction outcome loss': 0.34731223686568197, 'Total loss': 0.34731223686568197}
2022-11-28 01:49:37,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:37,659 INFO:     Epoch: 26
2022-11-28 01:49:38,412 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43913534706966445, 'Total loss': 0.43913534706966445} | train loss {'Reaction outcome loss': 0.34150529445539557, 'Total loss': 0.34150529445539557}
2022-11-28 01:49:38,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:38,413 INFO:     Epoch: 27
2022-11-28 01:49:39,161 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44754308902404527, 'Total loss': 0.44754308902404527} | train loss {'Reaction outcome loss': 0.33894859967873464, 'Total loss': 0.33894859967873464}
2022-11-28 01:49:39,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:39,162 INFO:     Epoch: 28
2022-11-28 01:49:39,911 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41656581075354054, 'Total loss': 0.41656581075354054} | train loss {'Reaction outcome loss': 0.33961665341931, 'Total loss': 0.33961665341931}
2022-11-28 01:49:39,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:39,911 INFO:     Epoch: 29
2022-11-28 01:49:40,659 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42742206901311874, 'Total loss': 0.42742206901311874} | train loss {'Reaction outcome loss': 0.33698342193759256, 'Total loss': 0.33698342193759256}
2022-11-28 01:49:40,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:40,659 INFO:     Epoch: 30
2022-11-28 01:49:41,407 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40542407062920655, 'Total loss': 0.40542407062920655} | train loss {'Reaction outcome loss': 0.32992072538622924, 'Total loss': 0.32992072538622924}
2022-11-28 01:49:41,407 INFO:     Found new best model at epoch 30
2022-11-28 01:49:41,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:41,408 INFO:     Epoch: 31
2022-11-28 01:49:42,161 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40539664605801756, 'Total loss': 0.40539664605801756} | train loss {'Reaction outcome loss': 0.34058999985216126, 'Total loss': 0.34058999985216126}
2022-11-28 01:49:42,161 INFO:     Found new best model at epoch 31
2022-11-28 01:49:42,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:42,162 INFO:     Epoch: 32
2022-11-28 01:49:42,912 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4375566948543895, 'Total loss': 0.4375566948543895} | train loss {'Reaction outcome loss': 0.33889130478905094, 'Total loss': 0.33889130478905094}
2022-11-28 01:49:42,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:42,912 INFO:     Epoch: 33
2022-11-28 01:49:43,661 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40576355887407606, 'Total loss': 0.40576355887407606} | train loss {'Reaction outcome loss': 0.3375778537123434, 'Total loss': 0.3375778537123434}
2022-11-28 01:49:43,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:43,661 INFO:     Epoch: 34
2022-11-28 01:49:44,407 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3998875523155386, 'Total loss': 0.3998875523155386} | train loss {'Reaction outcome loss': 0.3283217701640341, 'Total loss': 0.3283217701640341}
2022-11-28 01:49:44,407 INFO:     Found new best model at epoch 34
2022-11-28 01:49:44,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:44,408 INFO:     Epoch: 35
2022-11-28 01:49:45,153 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4112580950287255, 'Total loss': 0.4112580950287255} | train loss {'Reaction outcome loss': 0.3362175117006465, 'Total loss': 0.3362175117006465}
2022-11-28 01:49:45,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:45,154 INFO:     Epoch: 36
2022-11-28 01:49:45,902 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4247917217964476, 'Total loss': 0.4247917217964476} | train loss {'Reaction outcome loss': 0.325297670679227, 'Total loss': 0.325297670679227}
2022-11-28 01:49:45,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:45,902 INFO:     Epoch: 37
2022-11-28 01:49:46,653 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4137350532480262, 'Total loss': 0.4137350532480262} | train loss {'Reaction outcome loss': 0.3286779570363222, 'Total loss': 0.3286779570363222}
2022-11-28 01:49:46,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:46,653 INFO:     Epoch: 38
2022-11-28 01:49:47,406 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4049459424885837, 'Total loss': 0.4049459424885837} | train loss {'Reaction outcome loss': 0.3324521754477774, 'Total loss': 0.3324521754477774}
2022-11-28 01:49:47,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:47,406 INFO:     Epoch: 39
2022-11-28 01:49:48,155 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4732881249351935, 'Total loss': 0.4732881249351935} | train loss {'Reaction outcome loss': 0.3272769651525924, 'Total loss': 0.3272769651525924}
2022-11-28 01:49:48,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:48,156 INFO:     Epoch: 40
2022-11-28 01:49:48,907 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3981319052929228, 'Total loss': 0.3981319052929228} | train loss {'Reaction outcome loss': 0.3426751286512421, 'Total loss': 0.3426751286512421}
2022-11-28 01:49:48,908 INFO:     Found new best model at epoch 40
2022-11-28 01:49:48,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:48,908 INFO:     Epoch: 41
2022-11-28 01:49:49,661 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4166820205070756, 'Total loss': 0.4166820205070756} | train loss {'Reaction outcome loss': 0.32745809159091405, 'Total loss': 0.32745809159091405}
2022-11-28 01:49:49,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:49,662 INFO:     Epoch: 42
2022-11-28 01:49:50,411 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.389300118454478, 'Total loss': 0.389300118454478} | train loss {'Reaction outcome loss': 0.3250677809720078, 'Total loss': 0.3250677809720078}
2022-11-28 01:49:50,411 INFO:     Found new best model at epoch 42
2022-11-28 01:49:50,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:50,412 INFO:     Epoch: 43
2022-11-28 01:49:51,164 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4071858697994189, 'Total loss': 0.4071858697994189} | train loss {'Reaction outcome loss': 0.32359212024077294, 'Total loss': 0.32359212024077294}
2022-11-28 01:49:51,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:51,165 INFO:     Epoch: 44
2022-11-28 01:49:51,926 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40250830149108713, 'Total loss': 0.40250830149108713} | train loss {'Reaction outcome loss': 0.3202467571883913, 'Total loss': 0.3202467571883913}
2022-11-28 01:49:51,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:51,927 INFO:     Epoch: 45
2022-11-28 01:49:52,682 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4219041202556003, 'Total loss': 0.4219041202556003} | train loss {'Reaction outcome loss': 0.3372033024807611, 'Total loss': 0.3372033024807611}
2022-11-28 01:49:52,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:52,683 INFO:     Epoch: 46
2022-11-28 01:49:53,427 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44375354796648026, 'Total loss': 0.44375354796648026} | train loss {'Reaction outcome loss': 0.3226904981439152, 'Total loss': 0.3226904981439152}
2022-11-28 01:49:53,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:53,428 INFO:     Epoch: 47
2022-11-28 01:49:54,171 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4623026136647571, 'Total loss': 0.4623026136647571} | train loss {'Reaction outcome loss': 0.3260557212296032, 'Total loss': 0.3260557212296032}
2022-11-28 01:49:54,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:54,171 INFO:     Epoch: 48
2022-11-28 01:49:54,918 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42760075290094723, 'Total loss': 0.42760075290094723} | train loss {'Reaction outcome loss': 0.3439694296929144, 'Total loss': 0.3439694296929144}
2022-11-28 01:49:54,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:54,919 INFO:     Epoch: 49
2022-11-28 01:49:55,668 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40316968445073476, 'Total loss': 0.40316968445073476} | train loss {'Reaction outcome loss': 0.3236675973861448, 'Total loss': 0.3236675973861448}
2022-11-28 01:49:55,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:55,668 INFO:     Epoch: 50
2022-11-28 01:49:56,423 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40153583918105473, 'Total loss': 0.40153583918105473} | train loss {'Reaction outcome loss': 0.32092411777064683, 'Total loss': 0.32092411777064683}
2022-11-28 01:49:56,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:56,423 INFO:     Epoch: 51
2022-11-28 01:49:57,172 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3887122320857915, 'Total loss': 0.3887122320857915} | train loss {'Reaction outcome loss': 0.331251249258076, 'Total loss': 0.331251249258076}
2022-11-28 01:49:57,172 INFO:     Found new best model at epoch 51
2022-11-28 01:49:57,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:57,173 INFO:     Epoch: 52
2022-11-28 01:49:57,919 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3954032469879497, 'Total loss': 0.3954032469879497} | train loss {'Reaction outcome loss': 0.3248050258825383, 'Total loss': 0.3248050258825383}
2022-11-28 01:49:57,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:57,919 INFO:     Epoch: 53
2022-11-28 01:49:58,668 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40004359879954293, 'Total loss': 0.40004359879954293} | train loss {'Reaction outcome loss': 0.3163067430197712, 'Total loss': 0.3163067430197712}
2022-11-28 01:49:58,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:58,668 INFO:     Epoch: 54
2022-11-28 01:49:59,417 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43239139867099846, 'Total loss': 0.43239139867099846} | train loss {'Reaction outcome loss': 0.3285574181486041, 'Total loss': 0.3285574181486041}
2022-11-28 01:49:59,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:49:59,418 INFO:     Epoch: 55
2022-11-28 01:50:00,166 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40361395850777626, 'Total loss': 0.40361395850777626} | train loss {'Reaction outcome loss': 0.3199002216119439, 'Total loss': 0.3199002216119439}
2022-11-28 01:50:00,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:00,166 INFO:     Epoch: 56
2022-11-28 01:50:00,920 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.414545419879935, 'Total loss': 0.414545419879935} | train loss {'Reaction outcome loss': 0.32877844238593695, 'Total loss': 0.32877844238593695}
2022-11-28 01:50:00,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:00,920 INFO:     Epoch: 57
2022-11-28 01:50:01,671 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48685612935911526, 'Total loss': 0.48685612935911526} | train loss {'Reaction outcome loss': 0.32134865014062775, 'Total loss': 0.32134865014062775}
2022-11-28 01:50:01,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:01,671 INFO:     Epoch: 58
2022-11-28 01:50:02,421 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4351299350911921, 'Total loss': 0.4351299350911921} | train loss {'Reaction outcome loss': 0.326593863537475, 'Total loss': 0.326593863537475}
2022-11-28 01:50:02,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:02,421 INFO:     Epoch: 59
2022-11-28 01:50:03,171 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3912813428112052, 'Total loss': 0.3912813428112052} | train loss {'Reaction outcome loss': 0.3223784035672584, 'Total loss': 0.3223784035672584}
2022-11-28 01:50:03,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:03,171 INFO:     Epoch: 60
2022-11-28 01:50:03,923 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41112494231625035, 'Total loss': 0.41112494231625035} | train loss {'Reaction outcome loss': 0.30773278217642536, 'Total loss': 0.30773278217642536}
2022-11-28 01:50:03,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:03,924 INFO:     Epoch: 61
2022-11-28 01:50:04,673 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4085352546112104, 'Total loss': 0.4085352546112104} | train loss {'Reaction outcome loss': 0.31811371625911805, 'Total loss': 0.31811371625911805}
2022-11-28 01:50:04,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:04,673 INFO:     Epoch: 62
2022-11-28 01:50:05,420 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4043344713070176, 'Total loss': 0.4043344713070176} | train loss {'Reaction outcome loss': 0.32056755740796367, 'Total loss': 0.32056755740796367}
2022-11-28 01:50:05,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:05,420 INFO:     Epoch: 63
2022-11-28 01:50:06,167 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4197552806951783, 'Total loss': 0.4197552806951783} | train loss {'Reaction outcome loss': 0.31465429096152225, 'Total loss': 0.31465429096152225}
2022-11-28 01:50:06,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:06,167 INFO:     Epoch: 64
2022-11-28 01:50:06,914 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40111331844871695, 'Total loss': 0.40111331844871695} | train loss {'Reaction outcome loss': 0.3162005617613754, 'Total loss': 0.3162005617613754}
2022-11-28 01:50:06,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:06,914 INFO:     Epoch: 65
2022-11-28 01:50:07,662 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3991921977563338, 'Total loss': 0.3991921977563338} | train loss {'Reaction outcome loss': 0.3121500621970382, 'Total loss': 0.3121500621970382}
2022-11-28 01:50:07,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:07,662 INFO:     Epoch: 66
2022-11-28 01:50:08,413 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4055039919912815, 'Total loss': 0.4055039919912815} | train loss {'Reaction outcome loss': 0.31949126762488195, 'Total loss': 0.31949126762488195}
2022-11-28 01:50:08,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:08,414 INFO:     Epoch: 67
2022-11-28 01:50:09,162 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3855549581348896, 'Total loss': 0.3855549581348896} | train loss {'Reaction outcome loss': 0.31974160558574144, 'Total loss': 0.31974160558574144}
2022-11-28 01:50:09,162 INFO:     Found new best model at epoch 67
2022-11-28 01:50:09,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:09,163 INFO:     Epoch: 68
2022-11-28 01:50:09,910 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40827426822348073, 'Total loss': 0.40827426822348073} | train loss {'Reaction outcome loss': 0.315936156383325, 'Total loss': 0.315936156383325}
2022-11-28 01:50:09,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:09,910 INFO:     Epoch: 69
2022-11-28 01:50:10,658 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4481175257401033, 'Total loss': 0.4481175257401033} | train loss {'Reaction outcome loss': 0.3159236503584731, 'Total loss': 0.3159236503584731}
2022-11-28 01:50:10,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:10,659 INFO:     Epoch: 70
2022-11-28 01:50:11,408 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40875881707126444, 'Total loss': 0.40875881707126444} | train loss {'Reaction outcome loss': 0.30913800783755796, 'Total loss': 0.30913800783755796}
2022-11-28 01:50:11,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:11,409 INFO:     Epoch: 71
2022-11-28 01:50:12,158 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40621769292788074, 'Total loss': 0.40621769292788074} | train loss {'Reaction outcome loss': 0.3172985780082883, 'Total loss': 0.3172985780082883}
2022-11-28 01:50:12,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:12,158 INFO:     Epoch: 72
2022-11-28 01:50:12,907 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4281026676974513, 'Total loss': 0.4281026676974513} | train loss {'Reaction outcome loss': 0.3106353077436647, 'Total loss': 0.3106353077436647}
2022-11-28 01:50:12,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:12,908 INFO:     Epoch: 73
2022-11-28 01:50:13,659 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45956057581034576, 'Total loss': 0.45956057581034576} | train loss {'Reaction outcome loss': 0.3186761538438018, 'Total loss': 0.3186761538438018}
2022-11-28 01:50:13,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:13,659 INFO:     Epoch: 74
2022-11-28 01:50:14,410 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41746276447718794, 'Total loss': 0.41746276447718794} | train loss {'Reaction outcome loss': 0.3133021503867161, 'Total loss': 0.3133021503867161}
2022-11-28 01:50:14,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:14,410 INFO:     Epoch: 75
2022-11-28 01:50:15,163 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4149622722444209, 'Total loss': 0.4149622722444209} | train loss {'Reaction outcome loss': 0.3111215137966698, 'Total loss': 0.3111215137966698}
2022-11-28 01:50:15,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:15,163 INFO:     Epoch: 76
2022-11-28 01:50:15,912 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39812911132519896, 'Total loss': 0.39812911132519896} | train loss {'Reaction outcome loss': 0.3156247387129453, 'Total loss': 0.3156247387129453}
2022-11-28 01:50:15,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:15,912 INFO:     Epoch: 77
2022-11-28 01:50:16,662 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40441495840522373, 'Total loss': 0.40441495840522373} | train loss {'Reaction outcome loss': 0.3136410501545235, 'Total loss': 0.3136410501545235}
2022-11-28 01:50:16,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:16,663 INFO:     Epoch: 78
2022-11-28 01:50:17,412 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4441517845473506, 'Total loss': 0.4441517845473506} | train loss {'Reaction outcome loss': 0.3140589210294908, 'Total loss': 0.3140589210294908}
2022-11-28 01:50:17,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:17,412 INFO:     Epoch: 79
2022-11-28 01:50:18,161 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44159738245335495, 'Total loss': 0.44159738245335495} | train loss {'Reaction outcome loss': 0.3308901065179417, 'Total loss': 0.3308901065179417}
2022-11-28 01:50:18,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:18,161 INFO:     Epoch: 80
2022-11-28 01:50:18,911 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41374230571091175, 'Total loss': 0.41374230571091175} | train loss {'Reaction outcome loss': 0.31505128341696914, 'Total loss': 0.31505128341696914}
2022-11-28 01:50:18,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:18,911 INFO:     Epoch: 81
2022-11-28 01:50:19,658 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4024911180815913, 'Total loss': 0.4024911180815913} | train loss {'Reaction outcome loss': 0.3122253497431596, 'Total loss': 0.3122253497431596}
2022-11-28 01:50:19,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:19,658 INFO:     Epoch: 82
2022-11-28 01:50:20,406 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43709372864528134, 'Total loss': 0.43709372864528134} | train loss {'Reaction outcome loss': 0.3148415113438762, 'Total loss': 0.3148415113438762}
2022-11-28 01:50:20,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:20,406 INFO:     Epoch: 83
2022-11-28 01:50:21,158 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4112944796004079, 'Total loss': 0.4112944796004079} | train loss {'Reaction outcome loss': 0.31370482834116103, 'Total loss': 0.31370482834116103}
2022-11-28 01:50:21,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:21,158 INFO:     Epoch: 84
2022-11-28 01:50:21,907 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.405682309107347, 'Total loss': 0.405682309107347} | train loss {'Reaction outcome loss': 0.31801966950297356, 'Total loss': 0.31801966950297356}
2022-11-28 01:50:21,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:21,907 INFO:     Epoch: 85
2022-11-28 01:50:22,661 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45295091887766664, 'Total loss': 0.45295091887766664} | train loss {'Reaction outcome loss': 0.30849389770939467, 'Total loss': 0.30849389770939467}
2022-11-28 01:50:22,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:22,662 INFO:     Epoch: 86
2022-11-28 01:50:23,410 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43678489462895825, 'Total loss': 0.43678489462895825} | train loss {'Reaction outcome loss': 0.31377518627672424, 'Total loss': 0.31377518627672424}
2022-11-28 01:50:23,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:23,410 INFO:     Epoch: 87
2022-11-28 01:50:24,158 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4057642805644057, 'Total loss': 0.4057642805644057} | train loss {'Reaction outcome loss': 0.32288788380326644, 'Total loss': 0.32288788380326644}
2022-11-28 01:50:24,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:24,159 INFO:     Epoch: 88
2022-11-28 01:50:24,910 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4089375412599607, 'Total loss': 0.4089375412599607} | train loss {'Reaction outcome loss': 0.30716982749741406, 'Total loss': 0.30716982749741406}
2022-11-28 01:50:24,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:24,910 INFO:     Epoch: 89
2022-11-28 01:50:25,663 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3948165588080883, 'Total loss': 0.3948165588080883} | train loss {'Reaction outcome loss': 0.31277462873127193, 'Total loss': 0.31277462873127193}
2022-11-28 01:50:25,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:25,663 INFO:     Epoch: 90
2022-11-28 01:50:26,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4525780880993063, 'Total loss': 0.4525780880993063} | train loss {'Reaction outcome loss': 0.31755641679609975, 'Total loss': 0.31755641679609975}
2022-11-28 01:50:26,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:26,408 INFO:     Epoch: 91
2022-11-28 01:50:27,156 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4008647528561679, 'Total loss': 0.4008647528561679} | train loss {'Reaction outcome loss': 0.3190957214232654, 'Total loss': 0.3190957214232654}
2022-11-28 01:50:27,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:27,157 INFO:     Epoch: 92
2022-11-28 01:50:27,906 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40334151075644925, 'Total loss': 0.40334151075644925} | train loss {'Reaction outcome loss': 0.31423566682684806, 'Total loss': 0.31423566682684806}
2022-11-28 01:50:27,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:27,907 INFO:     Epoch: 93
2022-11-28 01:50:28,658 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4053791771558198, 'Total loss': 0.4053791771558198} | train loss {'Reaction outcome loss': 0.3084615642625478, 'Total loss': 0.3084615642625478}
2022-11-28 01:50:28,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:28,658 INFO:     Epoch: 94
2022-11-28 01:50:29,407 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4083961753005331, 'Total loss': 0.4083961753005331} | train loss {'Reaction outcome loss': 0.3079367698050074, 'Total loss': 0.3079367698050074}
2022-11-28 01:50:29,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:29,407 INFO:     Epoch: 95
2022-11-28 01:50:30,158 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40336334705352783, 'Total loss': 0.40336334705352783} | train loss {'Reaction outcome loss': 0.3039384758881023, 'Total loss': 0.3039384758881023}
2022-11-28 01:50:30,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:30,159 INFO:     Epoch: 96
2022-11-28 01:50:30,906 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41346684165976266, 'Total loss': 0.41346684165976266} | train loss {'Reaction outcome loss': 0.3154672513445539, 'Total loss': 0.3154672513445539}
2022-11-28 01:50:30,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:30,906 INFO:     Epoch: 97
2022-11-28 01:50:31,657 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38881062072786415, 'Total loss': 0.38881062072786415} | train loss {'Reaction outcome loss': 0.3117293082027426, 'Total loss': 0.3117293082027426}
2022-11-28 01:50:31,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:31,657 INFO:     Epoch: 98
2022-11-28 01:50:32,408 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43060898645357654, 'Total loss': 0.43060898645357654} | train loss {'Reaction outcome loss': 0.31328611236606396, 'Total loss': 0.31328611236606396}
2022-11-28 01:50:32,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:32,408 INFO:     Epoch: 99
2022-11-28 01:50:33,162 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.407107007435777, 'Total loss': 0.407107007435777} | train loss {'Reaction outcome loss': 0.30991774542076933, 'Total loss': 0.30991774542076933}
2022-11-28 01:50:33,162 INFO:     Best model found after epoch 68 of 100.
2022-11-28 01:50:33,162 INFO:   Done with stage: TRAINING
2022-11-28 01:50:33,162 INFO:   Starting stage: EVALUATION
2022-11-28 01:50:33,281 INFO:   Done with stage: EVALUATION
2022-11-28 01:50:33,281 INFO:   Leaving out SEQ value Fold_7
2022-11-28 01:50:33,294 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:50:33,294 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:50:33,926 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:50:33,926 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:50:33,993 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:50:33,994 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:50:33,994 INFO:     No hyperparam tuning for this model
2022-11-28 01:50:33,994 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:50:33,994 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:50:33,994 INFO:     None feature selector for col prot
2022-11-28 01:50:33,995 INFO:     None feature selector for col prot
2022-11-28 01:50:33,995 INFO:     None feature selector for col prot
2022-11-28 01:50:33,995 INFO:     None feature selector for col chem
2022-11-28 01:50:33,995 INFO:     None feature selector for col chem
2022-11-28 01:50:33,995 INFO:     None feature selector for col chem
2022-11-28 01:50:33,995 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:50:33,995 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:50:33,997 INFO:     Number of params in model 169741
2022-11-28 01:50:34,000 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:50:34,000 INFO:   Starting stage: TRAINING
2022-11-28 01:50:34,052 INFO:     Val loss before train {'Reaction outcome loss': 1.0367759341417357, 'Total loss': 1.0367759341417357}
2022-11-28 01:50:34,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:34,052 INFO:     Epoch: 0
2022-11-28 01:50:34,788 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5099975480589756, 'Total loss': 0.5099975480589756} | train loss {'Reaction outcome loss': 0.629816162354145, 'Total loss': 0.629816162354145}
2022-11-28 01:50:34,789 INFO:     Found new best model at epoch 0
2022-11-28 01:50:34,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:34,790 INFO:     Epoch: 1
2022-11-28 01:50:35,526 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.515991106282833, 'Total loss': 0.515991106282833} | train loss {'Reaction outcome loss': 0.4929419266762304, 'Total loss': 0.4929419266762304}
2022-11-28 01:50:35,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:35,526 INFO:     Epoch: 2
2022-11-28 01:50:36,261 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4898380737665088, 'Total loss': 0.4898380737665088} | train loss {'Reaction outcome loss': 0.4492768488946508, 'Total loss': 0.4492768488946508}
2022-11-28 01:50:36,261 INFO:     Found new best model at epoch 2
2022-11-28 01:50:36,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:36,262 INFO:     Epoch: 3
2022-11-28 01:50:37,002 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5032036162393038, 'Total loss': 0.5032036162393038} | train loss {'Reaction outcome loss': 0.4254364371910447, 'Total loss': 0.4254364371910447}
2022-11-28 01:50:37,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:37,002 INFO:     Epoch: 4
2022-11-28 01:50:37,745 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47779071053793265, 'Total loss': 0.47779071053793265} | train loss {'Reaction outcome loss': 0.4119798575268417, 'Total loss': 0.4119798575268417}
2022-11-28 01:50:37,745 INFO:     Found new best model at epoch 4
2022-11-28 01:50:37,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:37,746 INFO:     Epoch: 5
2022-11-28 01:50:38,487 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5158866373605506, 'Total loss': 0.5158866373605506} | train loss {'Reaction outcome loss': 0.40659452736622, 'Total loss': 0.40659452736622}
2022-11-28 01:50:38,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:38,487 INFO:     Epoch: 6
2022-11-28 01:50:39,231 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4609230448340261, 'Total loss': 0.4609230448340261} | train loss {'Reaction outcome loss': 0.39389590683897013, 'Total loss': 0.39389590683897013}
2022-11-28 01:50:39,231 INFO:     Found new best model at epoch 6
2022-11-28 01:50:39,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:39,232 INFO:     Epoch: 7
2022-11-28 01:50:39,976 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4787447570368301, 'Total loss': 0.4787447570368301} | train loss {'Reaction outcome loss': 0.3870554352942549, 'Total loss': 0.3870554352942549}
2022-11-28 01:50:39,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:39,976 INFO:     Epoch: 8
2022-11-28 01:50:40,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4617096483707428, 'Total loss': 0.4617096483707428} | train loss {'Reaction outcome loss': 0.37861651119577594, 'Total loss': 0.37861651119577594}
2022-11-28 01:50:40,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:40,719 INFO:     Epoch: 9
2022-11-28 01:50:41,457 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44158554181110027, 'Total loss': 0.44158554181110027} | train loss {'Reaction outcome loss': 0.374714018624337, 'Total loss': 0.374714018624337}
2022-11-28 01:50:41,458 INFO:     Found new best model at epoch 9
2022-11-28 01:50:41,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:41,458 INFO:     Epoch: 10
2022-11-28 01:50:42,196 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4419388854226401, 'Total loss': 0.4419388854226401} | train loss {'Reaction outcome loss': 0.3707868750588816, 'Total loss': 0.3707868750588816}
2022-11-28 01:50:42,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:42,196 INFO:     Epoch: 11
2022-11-28 01:50:42,933 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48082172420135766, 'Total loss': 0.48082172420135766} | train loss {'Reaction outcome loss': 0.3710182009295362, 'Total loss': 0.3710182009295362}
2022-11-28 01:50:42,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:42,934 INFO:     Epoch: 12
2022-11-28 01:50:43,669 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4764367872199347, 'Total loss': 0.4764367872199347} | train loss {'Reaction outcome loss': 0.36171989139841226, 'Total loss': 0.36171989139841226}
2022-11-28 01:50:43,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:43,670 INFO:     Epoch: 13
2022-11-28 01:50:44,406 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44697391778923745, 'Total loss': 0.44697391778923745} | train loss {'Reaction outcome loss': 0.3663371268843041, 'Total loss': 0.3663371268843041}
2022-11-28 01:50:44,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:44,406 INFO:     Epoch: 14
2022-11-28 01:50:45,142 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43965024033258127, 'Total loss': 0.43965024033258127} | train loss {'Reaction outcome loss': 0.34359610752492653, 'Total loss': 0.34359610752492653}
2022-11-28 01:50:45,142 INFO:     Found new best model at epoch 14
2022-11-28 01:50:45,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:45,143 INFO:     Epoch: 15
2022-11-28 01:50:45,878 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4298370924106864, 'Total loss': 0.4298370924106864} | train loss {'Reaction outcome loss': 0.34369948878884315, 'Total loss': 0.34369948878884315}
2022-11-28 01:50:45,878 INFO:     Found new best model at epoch 15
2022-11-28 01:50:45,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:45,879 INFO:     Epoch: 16
2022-11-28 01:50:46,617 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4345156287038049, 'Total loss': 0.4345156287038049} | train loss {'Reaction outcome loss': 0.34307171379933593, 'Total loss': 0.34307171379933593}
2022-11-28 01:50:46,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:46,617 INFO:     Epoch: 17
2022-11-28 01:50:47,356 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4552018503810084, 'Total loss': 0.4552018503810084} | train loss {'Reaction outcome loss': 0.34144038874961313, 'Total loss': 0.34144038874961313}
2022-11-28 01:50:47,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:47,356 INFO:     Epoch: 18
2022-11-28 01:50:48,099 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4657038682421973, 'Total loss': 0.4657038682421973} | train loss {'Reaction outcome loss': 0.34213775335276714, 'Total loss': 0.34213775335276714}
2022-11-28 01:50:48,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:48,099 INFO:     Epoch: 19
2022-11-28 01:50:48,834 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4557902187455532, 'Total loss': 0.4557902187455532} | train loss {'Reaction outcome loss': 0.34517935300093205, 'Total loss': 0.34517935300093205}
2022-11-28 01:50:48,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:48,834 INFO:     Epoch: 20
2022-11-28 01:50:49,570 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4315500893565111, 'Total loss': 0.4315500893565111} | train loss {'Reaction outcome loss': 0.3333501942211487, 'Total loss': 0.3333501942211487}
2022-11-28 01:50:49,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:49,570 INFO:     Epoch: 21
2022-11-28 01:50:50,306 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4576438412416813, 'Total loss': 0.4576438412416813} | train loss {'Reaction outcome loss': 0.3359362107136699, 'Total loss': 0.3359362107136699}
2022-11-28 01:50:50,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:50,307 INFO:     Epoch: 22
2022-11-28 01:50:51,047 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4392844753903012, 'Total loss': 0.4392844753903012} | train loss {'Reaction outcome loss': 0.330322124125039, 'Total loss': 0.330322124125039}
2022-11-28 01:50:51,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:51,047 INFO:     Epoch: 23
2022-11-28 01:50:51,782 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4480447044899297, 'Total loss': 0.4480447044899297} | train loss {'Reaction outcome loss': 0.326297918090322, 'Total loss': 0.326297918090322}
2022-11-28 01:50:51,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:51,783 INFO:     Epoch: 24
2022-11-28 01:50:52,516 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46054579144300417, 'Total loss': 0.46054579144300417} | train loss {'Reaction outcome loss': 0.342038609056932, 'Total loss': 0.342038609056932}
2022-11-28 01:50:52,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:52,516 INFO:     Epoch: 25
2022-11-28 01:50:53,249 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43052923194197723, 'Total loss': 0.43052923194197723} | train loss {'Reaction outcome loss': 0.32514101358466463, 'Total loss': 0.32514101358466463}
2022-11-28 01:50:53,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:53,249 INFO:     Epoch: 26
2022-11-28 01:50:53,985 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.485610441066498, 'Total loss': 0.485610441066498} | train loss {'Reaction outcome loss': 0.326829209893209, 'Total loss': 0.326829209893209}
2022-11-28 01:50:53,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:53,986 INFO:     Epoch: 27
2022-11-28 01:50:54,727 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43745169598002764, 'Total loss': 0.43745169598002764} | train loss {'Reaction outcome loss': 0.32224352770775067, 'Total loss': 0.32224352770775067}
2022-11-28 01:50:54,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:54,727 INFO:     Epoch: 28
2022-11-28 01:50:55,464 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47915836510270143, 'Total loss': 0.47915836510270143} | train loss {'Reaction outcome loss': 0.321519937518923, 'Total loss': 0.321519937518923}
2022-11-28 01:50:55,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:55,464 INFO:     Epoch: 29
2022-11-28 01:50:56,199 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44437403110570683, 'Total loss': 0.44437403110570683} | train loss {'Reaction outcome loss': 0.3246653153881675, 'Total loss': 0.3246653153881675}
2022-11-28 01:50:56,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:56,199 INFO:     Epoch: 30
2022-11-28 01:50:56,935 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.464733270711677, 'Total loss': 0.464733270711677} | train loss {'Reaction outcome loss': 0.32204624570784024, 'Total loss': 0.32204624570784024}
2022-11-28 01:50:56,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:56,936 INFO:     Epoch: 31
2022-11-28 01:50:57,671 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46810680835746055, 'Total loss': 0.46810680835746055} | train loss {'Reaction outcome loss': 0.31935766824811207, 'Total loss': 0.31935766824811207}
2022-11-28 01:50:57,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:57,671 INFO:     Epoch: 32
2022-11-28 01:50:58,405 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43730710134949796, 'Total loss': 0.43730710134949796} | train loss {'Reaction outcome loss': 0.31661359089441965, 'Total loss': 0.31661359089441965}
2022-11-28 01:50:58,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:58,406 INFO:     Epoch: 33
2022-11-28 01:50:59,139 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4398709684610367, 'Total loss': 0.4398709684610367} | train loss {'Reaction outcome loss': 0.311430174307745, 'Total loss': 0.311430174307745}
2022-11-28 01:50:59,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:59,139 INFO:     Epoch: 34
2022-11-28 01:50:59,878 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4298333955365558, 'Total loss': 0.4298333955365558} | train loss {'Reaction outcome loss': 0.3117025013951982, 'Total loss': 0.3117025013951982}
2022-11-28 01:50:59,878 INFO:     Found new best model at epoch 34
2022-11-28 01:50:59,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:50:59,879 INFO:     Epoch: 35
2022-11-28 01:51:00,620 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4858067721821541, 'Total loss': 0.4858067721821541} | train loss {'Reaction outcome loss': 0.31342643258146574, 'Total loss': 0.31342643258146574}
2022-11-28 01:51:00,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:00,620 INFO:     Epoch: 36
2022-11-28 01:51:01,361 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44889145569745886, 'Total loss': 0.44889145569745886} | train loss {'Reaction outcome loss': 0.31240380578292687, 'Total loss': 0.31240380578292687}
2022-11-28 01:51:01,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:01,362 INFO:     Epoch: 37
2022-11-28 01:51:02,101 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4321240470852963, 'Total loss': 0.4321240470852963} | train loss {'Reaction outcome loss': 0.31680781452260054, 'Total loss': 0.31680781452260054}
2022-11-28 01:51:02,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:02,101 INFO:     Epoch: 38
2022-11-28 01:51:02,841 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4689037841419841, 'Total loss': 0.4689037841419841} | train loss {'Reaction outcome loss': 0.3000119625606009, 'Total loss': 0.3000119625606009}
2022-11-28 01:51:02,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:02,841 INFO:     Epoch: 39
2022-11-28 01:51:03,579 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42462270932142127, 'Total loss': 0.42462270932142127} | train loss {'Reaction outcome loss': 0.3078556198657292, 'Total loss': 0.3078556198657292}
2022-11-28 01:51:03,579 INFO:     Found new best model at epoch 39
2022-11-28 01:51:03,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:03,580 INFO:     Epoch: 40
2022-11-28 01:51:04,324 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46371169007101726, 'Total loss': 0.46371169007101726} | train loss {'Reaction outcome loss': 0.3080434450177384, 'Total loss': 0.3080434450177384}
2022-11-28 01:51:04,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:04,324 INFO:     Epoch: 41
2022-11-28 01:51:05,065 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44337180360805156, 'Total loss': 0.44337180360805156} | train loss {'Reaction outcome loss': 0.30955109736103503, 'Total loss': 0.30955109736103503}
2022-11-28 01:51:05,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:05,065 INFO:     Epoch: 42
2022-11-28 01:51:05,805 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44882328565730606, 'Total loss': 0.44882328565730606} | train loss {'Reaction outcome loss': 0.3089542313188803, 'Total loss': 0.3089542313188803}
2022-11-28 01:51:05,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:05,805 INFO:     Epoch: 43
2022-11-28 01:51:06,544 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45163766762544943, 'Total loss': 0.45163766762544943} | train loss {'Reaction outcome loss': 0.31962771017531877, 'Total loss': 0.31962771017531877}
2022-11-28 01:51:06,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:06,545 INFO:     Epoch: 44
2022-11-28 01:51:07,288 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4698390357716139, 'Total loss': 0.4698390357716139} | train loss {'Reaction outcome loss': 0.32255350526605475, 'Total loss': 0.32255350526605475}
2022-11-28 01:51:07,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:07,288 INFO:     Epoch: 45
2022-11-28 01:51:08,031 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4694184303976769, 'Total loss': 0.4694184303976769} | train loss {'Reaction outcome loss': 0.3041828204801337, 'Total loss': 0.3041828204801337}
2022-11-28 01:51:08,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:08,031 INFO:     Epoch: 46
2022-11-28 01:51:08,774 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43980836798978407, 'Total loss': 0.43980836798978407} | train loss {'Reaction outcome loss': 0.3032075974662773, 'Total loss': 0.3032075974662773}
2022-11-28 01:51:08,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:08,774 INFO:     Epoch: 47
2022-11-28 01:51:09,515 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44304613803708276, 'Total loss': 0.44304613803708276} | train loss {'Reaction outcome loss': 0.30278953192297553, 'Total loss': 0.30278953192297553}
2022-11-28 01:51:09,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:09,515 INFO:     Epoch: 48
2022-11-28 01:51:10,256 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4430753709964974, 'Total loss': 0.4430753709964974} | train loss {'Reaction outcome loss': 0.3074287473850074, 'Total loss': 0.3074287473850074}
2022-11-28 01:51:10,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:10,256 INFO:     Epoch: 49
2022-11-28 01:51:10,996 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45880655684443405, 'Total loss': 0.45880655684443405} | train loss {'Reaction outcome loss': 0.3146472631602502, 'Total loss': 0.3146472631602502}
2022-11-28 01:51:10,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:10,997 INFO:     Epoch: 50
2022-11-28 01:51:11,735 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47123625181442086, 'Total loss': 0.47123625181442086} | train loss {'Reaction outcome loss': 0.31032712894995684, 'Total loss': 0.31032712894995684}
2022-11-28 01:51:11,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:11,735 INFO:     Epoch: 51
2022-11-28 01:51:12,473 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4449919871119566, 'Total loss': 0.4449919871119566} | train loss {'Reaction outcome loss': 0.3121362983508677, 'Total loss': 0.3121362983508677}
2022-11-28 01:51:12,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:12,474 INFO:     Epoch: 52
2022-11-28 01:51:13,211 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4549318219340125, 'Total loss': 0.4549318219340125} | train loss {'Reaction outcome loss': 0.30156045156668443, 'Total loss': 0.30156045156668443}
2022-11-28 01:51:13,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:13,212 INFO:     Epoch: 53
2022-11-28 01:51:13,947 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4951124364553496, 'Total loss': 0.4951124364553496} | train loss {'Reaction outcome loss': 0.31017242149129265, 'Total loss': 0.31017242149129265}
2022-11-28 01:51:13,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:13,947 INFO:     Epoch: 54
2022-11-28 01:51:14,683 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4583292016109755, 'Total loss': 0.4583292016109755} | train loss {'Reaction outcome loss': 0.3100737081077255, 'Total loss': 0.3100737081077255}
2022-11-28 01:51:14,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:14,683 INFO:     Epoch: 55
2022-11-28 01:51:15,419 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43972680838995204, 'Total loss': 0.43972680838995204} | train loss {'Reaction outcome loss': 0.3064940866143977, 'Total loss': 0.3064940866143977}
2022-11-28 01:51:15,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:15,420 INFO:     Epoch: 56
2022-11-28 01:51:16,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4254464905622394, 'Total loss': 0.4254464905622394} | train loss {'Reaction outcome loss': 0.3101992053208781, 'Total loss': 0.3101992053208781}
2022-11-28 01:51:16,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:16,155 INFO:     Epoch: 57
2022-11-28 01:51:16,891 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4238052201825519, 'Total loss': 0.4238052201825519} | train loss {'Reaction outcome loss': 0.3108117823168391, 'Total loss': 0.3108117823168391}
2022-11-28 01:51:16,891 INFO:     Found new best model at epoch 57
2022-11-28 01:51:16,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:16,892 INFO:     Epoch: 58
2022-11-28 01:51:17,626 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4207330713438433, 'Total loss': 0.4207330713438433} | train loss {'Reaction outcome loss': 0.31102025142458617, 'Total loss': 0.31102025142458617}
2022-11-28 01:51:17,626 INFO:     Found new best model at epoch 58
2022-11-28 01:51:17,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:17,627 INFO:     Epoch: 59
2022-11-28 01:51:18,365 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43424895076557646, 'Total loss': 0.43424895076557646} | train loss {'Reaction outcome loss': 0.29986463250500744, 'Total loss': 0.29986463250500744}
2022-11-28 01:51:18,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:18,365 INFO:     Epoch: 60
2022-11-28 01:51:19,104 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42675390458384227, 'Total loss': 0.42675390458384227} | train loss {'Reaction outcome loss': 0.3064523997151705, 'Total loss': 0.3064523997151705}
2022-11-28 01:51:19,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:19,104 INFO:     Epoch: 61
2022-11-28 01:51:19,844 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4226328347658002, 'Total loss': 0.4226328347658002} | train loss {'Reaction outcome loss': 0.2965550996424233, 'Total loss': 0.2965550996424233}
2022-11-28 01:51:19,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:19,844 INFO:     Epoch: 62
2022-11-28 01:51:20,581 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44287109097769095, 'Total loss': 0.44287109097769095} | train loss {'Reaction outcome loss': 0.30344637971921046, 'Total loss': 0.30344637971921046}
2022-11-28 01:51:20,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:20,581 INFO:     Epoch: 63
2022-11-28 01:51:21,321 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41641849244749823, 'Total loss': 0.41641849244749823} | train loss {'Reaction outcome loss': 0.3054011435415901, 'Total loss': 0.3054011435415901}
2022-11-28 01:51:21,321 INFO:     Found new best model at epoch 63
2022-11-28 01:51:21,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:21,322 INFO:     Epoch: 64
2022-11-28 01:51:22,059 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4282971329467241, 'Total loss': 0.4282971329467241} | train loss {'Reaction outcome loss': 0.30005459618739416, 'Total loss': 0.30005459618739416}
2022-11-28 01:51:22,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:22,059 INFO:     Epoch: 65
2022-11-28 01:51:22,796 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46407138088414834, 'Total loss': 0.46407138088414834} | train loss {'Reaction outcome loss': 0.3060097974099097, 'Total loss': 0.3060097974099097}
2022-11-28 01:51:22,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:22,796 INFO:     Epoch: 66
2022-11-28 01:51:23,535 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44060823945112004, 'Total loss': 0.44060823945112004} | train loss {'Reaction outcome loss': 0.3080693554194247, 'Total loss': 0.3080693554194247}
2022-11-28 01:51:23,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:23,535 INFO:     Epoch: 67
2022-11-28 01:51:24,271 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44490546542544696, 'Total loss': 0.44490546542544696} | train loss {'Reaction outcome loss': 0.30001663303643955, 'Total loss': 0.30001663303643955}
2022-11-28 01:51:24,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:24,272 INFO:     Epoch: 68
2022-11-28 01:51:25,009 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4408371486636095, 'Total loss': 0.4408371486636095} | train loss {'Reaction outcome loss': 0.29948907892112847, 'Total loss': 0.29948907892112847}
2022-11-28 01:51:25,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:25,009 INFO:     Epoch: 69
2022-11-28 01:51:25,747 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43808915032896883, 'Total loss': 0.43808915032896883} | train loss {'Reaction outcome loss': 0.29792828022761914, 'Total loss': 0.29792828022761914}
2022-11-28 01:51:25,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:25,748 INFO:     Epoch: 70
2022-11-28 01:51:26,486 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43224742714055747, 'Total loss': 0.43224742714055747} | train loss {'Reaction outcome loss': 0.2998536787927151, 'Total loss': 0.2998536787927151}
2022-11-28 01:51:26,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:26,486 INFO:     Epoch: 71
2022-11-28 01:51:27,225 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46025426616502363, 'Total loss': 0.46025426616502363} | train loss {'Reaction outcome loss': 0.29870464591706386, 'Total loss': 0.29870464591706386}
2022-11-28 01:51:27,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:27,225 INFO:     Epoch: 72
2022-11-28 01:51:27,962 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46601466834545135, 'Total loss': 0.46601466834545135} | train loss {'Reaction outcome loss': 0.29494394145173125, 'Total loss': 0.29494394145173125}
2022-11-28 01:51:27,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:27,962 INFO:     Epoch: 73
2022-11-28 01:51:28,699 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4302275267451309, 'Total loss': 0.4302275267451309} | train loss {'Reaction outcome loss': 0.30253150440813575, 'Total loss': 0.30253150440813575}
2022-11-28 01:51:28,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:28,699 INFO:     Epoch: 74
2022-11-28 01:51:29,440 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45571101196976593, 'Total loss': 0.45571101196976593} | train loss {'Reaction outcome loss': 0.29626733281451173, 'Total loss': 0.29626733281451173}
2022-11-28 01:51:29,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:29,440 INFO:     Epoch: 75
2022-11-28 01:51:30,180 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47740131166092187, 'Total loss': 0.47740131166092187} | train loss {'Reaction outcome loss': 0.30518657057622417, 'Total loss': 0.30518657057622417}
2022-11-28 01:51:30,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:30,181 INFO:     Epoch: 76
2022-11-28 01:51:30,929 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45134487055068795, 'Total loss': 0.45134487055068795} | train loss {'Reaction outcome loss': 0.3044607184644117, 'Total loss': 0.3044607184644117}
2022-11-28 01:51:30,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:30,930 INFO:     Epoch: 77
2022-11-28 01:51:31,674 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4211812681236932, 'Total loss': 0.4211812681236932} | train loss {'Reaction outcome loss': 0.29289702648205346, 'Total loss': 0.29289702648205346}
2022-11-28 01:51:31,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:31,674 INFO:     Epoch: 78
2022-11-28 01:51:32,417 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43428884689197983, 'Total loss': 0.43428884689197983} | train loss {'Reaction outcome loss': 0.29258997462018105, 'Total loss': 0.29258997462018105}
2022-11-28 01:51:32,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:32,417 INFO:     Epoch: 79
2022-11-28 01:51:33,163 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45133032077966734, 'Total loss': 0.45133032077966734} | train loss {'Reaction outcome loss': 0.304941041914166, 'Total loss': 0.304941041914166}
2022-11-28 01:51:33,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:33,164 INFO:     Epoch: 80
2022-11-28 01:51:33,906 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43474290121433345, 'Total loss': 0.43474290121433345} | train loss {'Reaction outcome loss': 0.29629954167443223, 'Total loss': 0.29629954167443223}
2022-11-28 01:51:33,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:33,906 INFO:     Epoch: 81
2022-11-28 01:51:34,649 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4421325876962307, 'Total loss': 0.4421325876962307} | train loss {'Reaction outcome loss': 0.30834531674131016, 'Total loss': 0.30834531674131016}
2022-11-28 01:51:34,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:34,649 INFO:     Epoch: 82
2022-11-28 01:51:35,390 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43322204989056257, 'Total loss': 0.43322204989056257} | train loss {'Reaction outcome loss': 0.29527884489688716, 'Total loss': 0.29527884489688716}
2022-11-28 01:51:35,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:35,391 INFO:     Epoch: 83
2022-11-28 01:51:36,135 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4244722226677939, 'Total loss': 0.4244722226677939} | train loss {'Reaction outcome loss': 0.3044116453679859, 'Total loss': 0.3044116453679859}
2022-11-28 01:51:36,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:36,135 INFO:     Epoch: 84
2022-11-28 01:51:36,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.455935969082422, 'Total loss': 0.455935969082422} | train loss {'Reaction outcome loss': 0.30860658249527706, 'Total loss': 0.30860658249527706}
2022-11-28 01:51:36,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:36,877 INFO:     Epoch: 85
2022-11-28 01:51:37,616 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4402360011671865, 'Total loss': 0.4402360011671865} | train loss {'Reaction outcome loss': 0.3070999166516007, 'Total loss': 0.3070999166516007}
2022-11-28 01:51:37,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:37,617 INFO:     Epoch: 86
2022-11-28 01:51:38,356 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48350291612536406, 'Total loss': 0.48350291612536406} | train loss {'Reaction outcome loss': 0.2943747448200574, 'Total loss': 0.2943747448200574}
2022-11-28 01:51:38,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:38,357 INFO:     Epoch: 87
2022-11-28 01:51:39,097 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4834633563147035, 'Total loss': 0.4834633563147035} | train loss {'Reaction outcome loss': 0.2975562020418707, 'Total loss': 0.2975562020418707}
2022-11-28 01:51:39,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:39,097 INFO:     Epoch: 88
2022-11-28 01:51:39,840 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4458272425934326, 'Total loss': 0.4458272425934326} | train loss {'Reaction outcome loss': 0.29581673985316614, 'Total loss': 0.29581673985316614}
2022-11-28 01:51:39,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:39,840 INFO:     Epoch: 89
2022-11-28 01:51:40,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4470801401969998, 'Total loss': 0.4470801401969998} | train loss {'Reaction outcome loss': 0.30263591921109645, 'Total loss': 0.30263591921109645}
2022-11-28 01:51:40,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:40,582 INFO:     Epoch: 90
2022-11-28 01:51:41,326 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44454142659209495, 'Total loss': 0.44454142659209495} | train loss {'Reaction outcome loss': 0.3080725254887929, 'Total loss': 0.3080725254887929}
2022-11-28 01:51:41,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:41,327 INFO:     Epoch: 91
2022-11-28 01:51:42,073 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44809612857047904, 'Total loss': 0.44809612857047904} | train loss {'Reaction outcome loss': 0.29632391435567473, 'Total loss': 0.29632391435567473}
2022-11-28 01:51:42,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:42,074 INFO:     Epoch: 92
2022-11-28 01:51:42,817 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.460357857824758, 'Total loss': 0.460357857824758} | train loss {'Reaction outcome loss': 0.29937579778984924, 'Total loss': 0.29937579778984924}
2022-11-28 01:51:42,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:42,817 INFO:     Epoch: 93
2022-11-28 01:51:43,566 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43011190101157787, 'Total loss': 0.43011190101157787} | train loss {'Reaction outcome loss': 0.3045511086944674, 'Total loss': 0.3045511086944674}
2022-11-28 01:51:43,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:43,566 INFO:     Epoch: 94
2022-11-28 01:51:44,309 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.433960736837498, 'Total loss': 0.433960736837498} | train loss {'Reaction outcome loss': 0.2963380185642936, 'Total loss': 0.2963380185642936}
2022-11-28 01:51:44,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:44,310 INFO:     Epoch: 95
2022-11-28 01:51:45,050 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4341944875412209, 'Total loss': 0.4341944875412209} | train loss {'Reaction outcome loss': 0.2992749543341457, 'Total loss': 0.2992749543341457}
2022-11-28 01:51:45,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:45,050 INFO:     Epoch: 96
2022-11-28 01:51:45,790 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42381873137729115, 'Total loss': 0.42381873137729115} | train loss {'Reaction outcome loss': 0.30251700797530473, 'Total loss': 0.30251700797530473}
2022-11-28 01:51:45,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:45,790 INFO:     Epoch: 97
2022-11-28 01:51:46,533 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44009863793156867, 'Total loss': 0.44009863793156867} | train loss {'Reaction outcome loss': 0.2937646184849446, 'Total loss': 0.2937646184849446}
2022-11-28 01:51:46,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:46,533 INFO:     Epoch: 98
2022-11-28 01:51:47,276 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4454314355240312, 'Total loss': 0.4454314355240312} | train loss {'Reaction outcome loss': 0.29524917030310044, 'Total loss': 0.29524917030310044}
2022-11-28 01:51:47,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:47,276 INFO:     Epoch: 99
2022-11-28 01:51:48,024 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4664174151975055, 'Total loss': 0.4664174151975055} | train loss {'Reaction outcome loss': 0.29667036267394414, 'Total loss': 0.29667036267394414}
2022-11-28 01:51:48,024 INFO:     Best model found after epoch 64 of 100.
2022-11-28 01:51:48,024 INFO:   Done with stage: TRAINING
2022-11-28 01:51:48,024 INFO:   Starting stage: EVALUATION
2022-11-28 01:51:48,161 INFO:   Done with stage: EVALUATION
2022-11-28 01:51:48,161 INFO:   Leaving out SEQ value Fold_8
2022-11-28 01:51:48,173 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:51:48,173 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:51:48,816 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:51:48,816 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:51:48,885 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:51:48,885 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:51:48,885 INFO:     No hyperparam tuning for this model
2022-11-28 01:51:48,885 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:51:48,885 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:51:48,886 INFO:     None feature selector for col prot
2022-11-28 01:51:48,886 INFO:     None feature selector for col prot
2022-11-28 01:51:48,887 INFO:     None feature selector for col prot
2022-11-28 01:51:48,887 INFO:     None feature selector for col chem
2022-11-28 01:51:48,887 INFO:     None feature selector for col chem
2022-11-28 01:51:48,887 INFO:     None feature selector for col chem
2022-11-28 01:51:48,887 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:51:48,887 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:51:48,889 INFO:     Number of params in model 169741
2022-11-28 01:51:48,892 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:51:48,892 INFO:   Starting stage: TRAINING
2022-11-28 01:51:48,946 INFO:     Val loss before train {'Reaction outcome loss': 0.9839899336749857, 'Total loss': 0.9839899336749857}
2022-11-28 01:51:48,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:48,946 INFO:     Epoch: 0
2022-11-28 01:51:49,697 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5048992545767264, 'Total loss': 0.5048992545767264} | train loss {'Reaction outcome loss': 0.6547718838400204, 'Total loss': 0.6547718838400204}
2022-11-28 01:51:49,698 INFO:     Found new best model at epoch 0
2022-11-28 01:51:49,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:49,698 INFO:     Epoch: 1
2022-11-28 01:51:50,452 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5493767017667944, 'Total loss': 0.5493767017667944} | train loss {'Reaction outcome loss': 0.5076674774952745, 'Total loss': 0.5076674774952745}
2022-11-28 01:51:50,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:50,453 INFO:     Epoch: 2
2022-11-28 01:51:51,203 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4496203139424324, 'Total loss': 0.4496203139424324} | train loss {'Reaction outcome loss': 0.46909822215918107, 'Total loss': 0.46909822215918107}
2022-11-28 01:51:51,203 INFO:     Found new best model at epoch 2
2022-11-28 01:51:51,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:51,204 INFO:     Epoch: 3
2022-11-28 01:51:51,958 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45170341195030644, 'Total loss': 0.45170341195030644} | train loss {'Reaction outcome loss': 0.44861648246826913, 'Total loss': 0.44861648246826913}
2022-11-28 01:51:51,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:51,958 INFO:     Epoch: 4
2022-11-28 01:51:52,716 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47572763365778054, 'Total loss': 0.47572763365778054} | train loss {'Reaction outcome loss': 0.4279840888402723, 'Total loss': 0.4279840888402723}
2022-11-28 01:51:52,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:52,716 INFO:     Epoch: 5
2022-11-28 01:51:53,466 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4426027871668339, 'Total loss': 0.4426027871668339} | train loss {'Reaction outcome loss': 0.4171056618276787, 'Total loss': 0.4171056618276787}
2022-11-28 01:51:53,466 INFO:     Found new best model at epoch 5
2022-11-28 01:51:53,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:53,467 INFO:     Epoch: 6
2022-11-28 01:51:54,218 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4723212569952011, 'Total loss': 0.4723212569952011} | train loss {'Reaction outcome loss': 0.4095788835453601, 'Total loss': 0.4095788835453601}
2022-11-28 01:51:54,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:54,218 INFO:     Epoch: 7
2022-11-28 01:51:54,968 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4456218851899559, 'Total loss': 0.4456218851899559} | train loss {'Reaction outcome loss': 0.3991263913601516, 'Total loss': 0.3991263913601516}
2022-11-28 01:51:54,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:54,969 INFO:     Epoch: 8
2022-11-28 01:51:55,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47818410921503196, 'Total loss': 0.47818410921503196} | train loss {'Reaction outcome loss': 0.39356503957460226, 'Total loss': 0.39356503957460226}
2022-11-28 01:51:55,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:55,719 INFO:     Epoch: 9
2022-11-28 01:51:56,468 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4318635114891963, 'Total loss': 0.4318635114891963} | train loss {'Reaction outcome loss': 0.38828800158643045, 'Total loss': 0.38828800158643045}
2022-11-28 01:51:56,468 INFO:     Found new best model at epoch 9
2022-11-28 01:51:56,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:56,469 INFO:     Epoch: 10
2022-11-28 01:51:57,222 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4634431339800358, 'Total loss': 0.4634431339800358} | train loss {'Reaction outcome loss': 0.3778963875975686, 'Total loss': 0.3778963875975686}
2022-11-28 01:51:57,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:57,222 INFO:     Epoch: 11
2022-11-28 01:51:57,974 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43835088034922426, 'Total loss': 0.43835088034922426} | train loss {'Reaction outcome loss': 0.37204773902614047, 'Total loss': 0.37204773902614047}
2022-11-28 01:51:57,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:57,974 INFO:     Epoch: 12
2022-11-28 01:51:58,724 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4384783130477775, 'Total loss': 0.4384783130477775} | train loss {'Reaction outcome loss': 0.3730503466665586, 'Total loss': 0.3730503466665586}
2022-11-28 01:51:58,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:58,724 INFO:     Epoch: 13
2022-11-28 01:51:59,478 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44344485822049057, 'Total loss': 0.44344485822049057} | train loss {'Reaction outcome loss': 0.3626563503192021, 'Total loss': 0.3626563503192021}
2022-11-28 01:51:59,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:51:59,478 INFO:     Epoch: 14
2022-11-28 01:52:00,233 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44701019539074466, 'Total loss': 0.44701019539074466} | train loss {'Reaction outcome loss': 0.3739549118557922, 'Total loss': 0.3739549118557922}
2022-11-28 01:52:00,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:00,233 INFO:     Epoch: 15
2022-11-28 01:52:00,986 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43679908696900716, 'Total loss': 0.43679908696900716} | train loss {'Reaction outcome loss': 0.35759689318023713, 'Total loss': 0.35759689318023713}
2022-11-28 01:52:00,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:00,986 INFO:     Epoch: 16
2022-11-28 01:52:01,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4446969560601495, 'Total loss': 0.4446969560601495} | train loss {'Reaction outcome loss': 0.3522608046333196, 'Total loss': 0.3522608046333196}
2022-11-28 01:52:01,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:01,737 INFO:     Epoch: 17
2022-11-28 01:52:02,492 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4518206299028613, 'Total loss': 0.4518206299028613} | train loss {'Reaction outcome loss': 0.3531367321807876, 'Total loss': 0.3531367321807876}
2022-11-28 01:52:02,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:02,493 INFO:     Epoch: 18
2022-11-28 01:52:03,246 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43033887581391767, 'Total loss': 0.43033887581391767} | train loss {'Reaction outcome loss': 0.3463047615851951, 'Total loss': 0.3463047615851951}
2022-11-28 01:52:03,246 INFO:     Found new best model at epoch 18
2022-11-28 01:52:03,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:03,247 INFO:     Epoch: 19
2022-11-28 01:52:04,003 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43836143003268674, 'Total loss': 0.43836143003268674} | train loss {'Reaction outcome loss': 0.3540530572475692, 'Total loss': 0.3540530572475692}
2022-11-28 01:52:04,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:04,004 INFO:     Epoch: 20
2022-11-28 01:52:04,753 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4258560013364662, 'Total loss': 0.4258560013364662} | train loss {'Reaction outcome loss': 0.3465288394118512, 'Total loss': 0.3465288394118512}
2022-11-28 01:52:04,753 INFO:     Found new best model at epoch 20
2022-11-28 01:52:04,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:04,754 INFO:     Epoch: 21
2022-11-28 01:52:05,508 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4187347939745946, 'Total loss': 0.4187347939745946} | train loss {'Reaction outcome loss': 0.34637181091344793, 'Total loss': 0.34637181091344793}
2022-11-28 01:52:05,508 INFO:     Found new best model at epoch 21
2022-11-28 01:52:05,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:05,509 INFO:     Epoch: 22
2022-11-28 01:52:06,264 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3918240803547881, 'Total loss': 0.3918240803547881} | train loss {'Reaction outcome loss': 0.34107594291570215, 'Total loss': 0.34107594291570215}
2022-11-28 01:52:06,264 INFO:     Found new best model at epoch 22
2022-11-28 01:52:06,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:06,265 INFO:     Epoch: 23
2022-11-28 01:52:07,015 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4440335434946147, 'Total loss': 0.4440335434946147} | train loss {'Reaction outcome loss': 0.3395399289424362, 'Total loss': 0.3395399289424362}
2022-11-28 01:52:07,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:07,015 INFO:     Epoch: 24
2022-11-28 01:52:07,763 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4206974177875302, 'Total loss': 0.4206974177875302} | train loss {'Reaction outcome loss': 0.33935945010027635, 'Total loss': 0.33935945010027635}
2022-11-28 01:52:07,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:07,763 INFO:     Epoch: 25
2022-11-28 01:52:08,506 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40252654017372563, 'Total loss': 0.40252654017372563} | train loss {'Reaction outcome loss': 0.3390734465981302, 'Total loss': 0.3390734465981302}
2022-11-28 01:52:08,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:08,507 INFO:     Epoch: 26
2022-11-28 01:52:09,259 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4032601951198144, 'Total loss': 0.4032601951198144} | train loss {'Reaction outcome loss': 0.33675283709397685, 'Total loss': 0.33675283709397685}
2022-11-28 01:52:09,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:09,259 INFO:     Epoch: 27
2022-11-28 01:52:10,009 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.414219528097998, 'Total loss': 0.414219528097998} | train loss {'Reaction outcome loss': 0.33574257083689635, 'Total loss': 0.33574257083689635}
2022-11-28 01:52:10,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:10,009 INFO:     Epoch: 28
2022-11-28 01:52:10,762 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4312962835485285, 'Total loss': 0.4312962835485285} | train loss {'Reaction outcome loss': 0.3475303603449331, 'Total loss': 0.3475303603449331}
2022-11-28 01:52:10,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:10,763 INFO:     Epoch: 29
2022-11-28 01:52:11,512 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4092724558219991, 'Total loss': 0.4092724558219991} | train loss {'Reaction outcome loss': 0.330659253252689, 'Total loss': 0.330659253252689}
2022-11-28 01:52:11,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:11,512 INFO:     Epoch: 30
2022-11-28 01:52:12,260 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4554510367187587, 'Total loss': 0.4554510367187587} | train loss {'Reaction outcome loss': 0.3268353342585174, 'Total loss': 0.3268353342585174}
2022-11-28 01:52:12,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:12,260 INFO:     Epoch: 31
2022-11-28 01:52:13,009 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4053136940029534, 'Total loss': 0.4053136940029534} | train loss {'Reaction outcome loss': 0.3258167275770564, 'Total loss': 0.3258167275770564}
2022-11-28 01:52:13,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:13,009 INFO:     Epoch: 32
2022-11-28 01:52:13,759 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4315343075855212, 'Total loss': 0.4315343075855212} | train loss {'Reaction outcome loss': 0.3189603431142776, 'Total loss': 0.3189603431142776}
2022-11-28 01:52:13,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:13,759 INFO:     Epoch: 33
2022-11-28 01:52:14,505 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3951284692368724, 'Total loss': 0.3951284692368724} | train loss {'Reaction outcome loss': 0.325554302120619, 'Total loss': 0.325554302120619}
2022-11-28 01:52:14,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:14,505 INFO:     Epoch: 34
2022-11-28 01:52:15,258 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42507478527047415, 'Total loss': 0.42507478527047415} | train loss {'Reaction outcome loss': 0.33483184382379777, 'Total loss': 0.33483184382379777}
2022-11-28 01:52:15,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:15,259 INFO:     Epoch: 35
2022-11-28 01:52:16,006 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4169337541203607, 'Total loss': 0.4169337541203607} | train loss {'Reaction outcome loss': 0.3252241578677043, 'Total loss': 0.3252241578677043}
2022-11-28 01:52:16,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:16,007 INFO:     Epoch: 36
2022-11-28 01:52:16,754 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4045594818890095, 'Total loss': 0.4045594818890095} | train loss {'Reaction outcome loss': 0.3245981021026368, 'Total loss': 0.3245981021026368}
2022-11-28 01:52:16,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:16,754 INFO:     Epoch: 37
2022-11-28 01:52:17,504 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41304637999697164, 'Total loss': 0.41304637999697164} | train loss {'Reaction outcome loss': 0.317949708303727, 'Total loss': 0.317949708303727}
2022-11-28 01:52:17,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:17,504 INFO:     Epoch: 38
2022-11-28 01:52:18,255 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4067919481207024, 'Total loss': 0.4067919481207024} | train loss {'Reaction outcome loss': 0.3242239180484764, 'Total loss': 0.3242239180484764}
2022-11-28 01:52:18,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:18,256 INFO:     Epoch: 39
2022-11-28 01:52:19,005 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40807595899836585, 'Total loss': 0.40807595899836585} | train loss {'Reaction outcome loss': 0.3287611444049933, 'Total loss': 0.3287611444049933}
2022-11-28 01:52:19,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:19,006 INFO:     Epoch: 40
2022-11-28 01:52:19,755 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3997616097331047, 'Total loss': 0.3997616097331047} | train loss {'Reaction outcome loss': 0.317597739247658, 'Total loss': 0.317597739247658}
2022-11-28 01:52:19,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:19,755 INFO:     Epoch: 41
2022-11-28 01:52:20,505 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4011076746339148, 'Total loss': 0.4011076746339148} | train loss {'Reaction outcome loss': 0.32081826987416157, 'Total loss': 0.32081826987416157}
2022-11-28 01:52:20,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:20,505 INFO:     Epoch: 42
2022-11-28 01:52:21,250 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42019321938807314, 'Total loss': 0.42019321938807314} | train loss {'Reaction outcome loss': 0.32346387850007546, 'Total loss': 0.32346387850007546}
2022-11-28 01:52:21,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:21,250 INFO:     Epoch: 43
2022-11-28 01:52:21,998 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3965156835249879, 'Total loss': 0.3965156835249879} | train loss {'Reaction outcome loss': 0.32503506399314996, 'Total loss': 0.32503506399314996}
2022-11-28 01:52:21,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:21,999 INFO:     Epoch: 44
2022-11-28 01:52:22,750 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42409023811871355, 'Total loss': 0.42409023811871355} | train loss {'Reaction outcome loss': 0.3178471796184416, 'Total loss': 0.3178471796184416}
2022-11-28 01:52:22,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:22,751 INFO:     Epoch: 45
2022-11-28 01:52:23,498 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40749727020209486, 'Total loss': 0.40749727020209486} | train loss {'Reaction outcome loss': 0.32552567549683303, 'Total loss': 0.32552567549683303}
2022-11-28 01:52:23,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:23,499 INFO:     Epoch: 46
2022-11-28 01:52:24,247 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4329771196300333, 'Total loss': 0.4329771196300333} | train loss {'Reaction outcome loss': 0.31953842894208095, 'Total loss': 0.31953842894208095}
2022-11-28 01:52:24,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:24,248 INFO:     Epoch: 47
2022-11-28 01:52:24,995 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45479717952283943, 'Total loss': 0.45479717952283943} | train loss {'Reaction outcome loss': 0.3481956618849324, 'Total loss': 0.3481956618849324}
2022-11-28 01:52:24,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:24,995 INFO:     Epoch: 48
2022-11-28 01:52:25,745 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4220588230951266, 'Total loss': 0.4220588230951266} | train loss {'Reaction outcome loss': 0.3183442451029654, 'Total loss': 0.3183442451029654}
2022-11-28 01:52:25,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:25,745 INFO:     Epoch: 49
2022-11-28 01:52:26,493 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43464030393145303, 'Total loss': 0.43464030393145303} | train loss {'Reaction outcome loss': 0.32458809941728045, 'Total loss': 0.32458809941728045}
2022-11-28 01:52:26,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:26,494 INFO:     Epoch: 50
2022-11-28 01:52:27,243 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42406261001120915, 'Total loss': 0.42406261001120915} | train loss {'Reaction outcome loss': 0.31371590365403096, 'Total loss': 0.31371590365403096}
2022-11-28 01:52:27,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:27,243 INFO:     Epoch: 51
2022-11-28 01:52:27,993 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4478581740774892, 'Total loss': 0.4478581740774892} | train loss {'Reaction outcome loss': 0.32749353554326033, 'Total loss': 0.32749353554326033}
2022-11-28 01:52:27,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:27,994 INFO:     Epoch: 52
2022-11-28 01:52:28,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45015776631507004, 'Total loss': 0.45015776631507004} | train loss {'Reaction outcome loss': 0.324471588469693, 'Total loss': 0.324471588469693}
2022-11-28 01:52:28,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:28,741 INFO:     Epoch: 53
2022-11-28 01:52:29,492 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41909362545067613, 'Total loss': 0.41909362545067613} | train loss {'Reaction outcome loss': 0.3133492142957473, 'Total loss': 0.3133492142957473}
2022-11-28 01:52:29,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:29,492 INFO:     Epoch: 54
2022-11-28 01:52:30,245 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42579035223885014, 'Total loss': 0.42579035223885014} | train loss {'Reaction outcome loss': 0.31309072683878275, 'Total loss': 0.31309072683878275}
2022-11-28 01:52:30,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:30,245 INFO:     Epoch: 55
2022-11-28 01:52:30,994 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4206426577134566, 'Total loss': 0.4206426577134566} | train loss {'Reaction outcome loss': 0.3103439327525465, 'Total loss': 0.3103439327525465}
2022-11-28 01:52:30,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:30,994 INFO:     Epoch: 56
2022-11-28 01:52:31,744 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45714081823825836, 'Total loss': 0.45714081823825836} | train loss {'Reaction outcome loss': 0.3173758640040753, 'Total loss': 0.3173758640040753}
2022-11-28 01:52:31,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:31,745 INFO:     Epoch: 57
2022-11-28 01:52:32,497 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42609564316543663, 'Total loss': 0.42609564316543663} | train loss {'Reaction outcome loss': 0.3185252057094323, 'Total loss': 0.3185252057094323}
2022-11-28 01:52:32,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:32,497 INFO:     Epoch: 58
2022-11-28 01:52:33,249 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4191027334467931, 'Total loss': 0.4191027334467931} | train loss {'Reaction outcome loss': 0.3077916265604947, 'Total loss': 0.3077916265604947}
2022-11-28 01:52:33,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:33,249 INFO:     Epoch: 59
2022-11-28 01:52:34,009 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41133887523954565, 'Total loss': 0.41133887523954565} | train loss {'Reaction outcome loss': 0.30245746059818307, 'Total loss': 0.30245746059818307}
2022-11-28 01:52:34,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:34,009 INFO:     Epoch: 60
2022-11-28 01:52:34,765 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43824766779487784, 'Total loss': 0.43824766779487784} | train loss {'Reaction outcome loss': 0.3173084808324995, 'Total loss': 0.3173084808324995}
2022-11-28 01:52:34,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:34,765 INFO:     Epoch: 61
2022-11-28 01:52:35,517 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4165751524269581, 'Total loss': 0.4165751524269581} | train loss {'Reaction outcome loss': 0.3287616673449756, 'Total loss': 0.3287616673449756}
2022-11-28 01:52:35,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:35,517 INFO:     Epoch: 62
2022-11-28 01:52:36,268 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43545904145999387, 'Total loss': 0.43545904145999387} | train loss {'Reaction outcome loss': 0.33485930781012124, 'Total loss': 0.33485930781012124}
2022-11-28 01:52:36,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:36,268 INFO:     Epoch: 63
2022-11-28 01:52:37,021 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.403514834290201, 'Total loss': 0.403514834290201} | train loss {'Reaction outcome loss': 0.3580434732893218, 'Total loss': 0.3580434732893218}
2022-11-28 01:52:37,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:37,021 INFO:     Epoch: 64
2022-11-28 01:52:37,776 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41310785473747685, 'Total loss': 0.41310785473747685} | train loss {'Reaction outcome loss': 0.33042059908149696, 'Total loss': 0.33042059908149696}
2022-11-28 01:52:37,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:37,776 INFO:     Epoch: 65
2022-11-28 01:52:38,525 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4450899929824201, 'Total loss': 0.4450899929824201} | train loss {'Reaction outcome loss': 0.31269688436738874, 'Total loss': 0.31269688436738874}
2022-11-28 01:52:38,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:38,526 INFO:     Epoch: 66
2022-11-28 01:52:39,277 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4229225860061971, 'Total loss': 0.4229225860061971} | train loss {'Reaction outcome loss': 0.31592931028319754, 'Total loss': 0.31592931028319754}
2022-11-28 01:52:39,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:39,278 INFO:     Epoch: 67
2022-11-28 01:52:40,031 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4442488720471209, 'Total loss': 0.4442488720471209} | train loss {'Reaction outcome loss': 0.30799469858528633, 'Total loss': 0.30799469858528633}
2022-11-28 01:52:40,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:40,031 INFO:     Epoch: 68
2022-11-28 01:52:40,783 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4246585267511281, 'Total loss': 0.4246585267511281} | train loss {'Reaction outcome loss': 0.3023274230548305, 'Total loss': 0.3023274230548305}
2022-11-28 01:52:40,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:40,783 INFO:     Epoch: 69
2022-11-28 01:52:41,535 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42858631180768664, 'Total loss': 0.42858631180768664} | train loss {'Reaction outcome loss': 0.3153682574478962, 'Total loss': 0.3153682574478962}
2022-11-28 01:52:41,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:41,535 INFO:     Epoch: 70
2022-11-28 01:52:42,286 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4195049415257844, 'Total loss': 0.4195049415257844} | train loss {'Reaction outcome loss': 0.3101514917817193, 'Total loss': 0.3101514917817193}
2022-11-28 01:52:42,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:42,286 INFO:     Epoch: 71
2022-11-28 01:52:43,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4476255174218254, 'Total loss': 0.4476255174218254} | train loss {'Reaction outcome loss': 0.30930387984342905, 'Total loss': 0.30930387984342905}
2022-11-28 01:52:43,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:43,035 INFO:     Epoch: 72
2022-11-28 01:52:43,787 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43064517358487303, 'Total loss': 0.43064517358487303} | train loss {'Reaction outcome loss': 0.30967341811369786, 'Total loss': 0.30967341811369786}
2022-11-28 01:52:43,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:43,787 INFO:     Epoch: 73
2022-11-28 01:52:44,536 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4363591398366473, 'Total loss': 0.4363591398366473} | train loss {'Reaction outcome loss': 0.3178943839482209, 'Total loss': 0.3178943839482209}
2022-11-28 01:52:44,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:44,536 INFO:     Epoch: 74
2022-11-28 01:52:45,283 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.425803446972912, 'Total loss': 0.425803446972912} | train loss {'Reaction outcome loss': 0.32540718706120614, 'Total loss': 0.32540718706120614}
2022-11-28 01:52:45,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:45,284 INFO:     Epoch: 75
2022-11-28 01:52:46,033 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40322703969749535, 'Total loss': 0.40322703969749535} | train loss {'Reaction outcome loss': 0.3029972610180737, 'Total loss': 0.3029972610180737}
2022-11-28 01:52:46,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:46,034 INFO:     Epoch: 76
2022-11-28 01:52:46,783 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4299802692099051, 'Total loss': 0.4299802692099051} | train loss {'Reaction outcome loss': 0.3109009818132469, 'Total loss': 0.3109009818132469}
2022-11-28 01:52:46,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:46,783 INFO:     Epoch: 77
2022-11-28 01:52:47,532 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40573633783920243, 'Total loss': 0.40573633783920243} | train loss {'Reaction outcome loss': 0.30348264528551566, 'Total loss': 0.30348264528551566}
2022-11-28 01:52:47,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:47,532 INFO:     Epoch: 78
2022-11-28 01:52:48,283 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44133270836689253, 'Total loss': 0.44133270836689253} | train loss {'Reaction outcome loss': 0.3125373227936536, 'Total loss': 0.3125373227936536}
2022-11-28 01:52:48,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:48,283 INFO:     Epoch: 79
2022-11-28 01:52:49,032 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4430625049228018, 'Total loss': 0.4430625049228018} | train loss {'Reaction outcome loss': 0.3010479606733269, 'Total loss': 0.3010479606733269}
2022-11-28 01:52:49,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:49,032 INFO:     Epoch: 80
2022-11-28 01:52:49,779 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4327367517081174, 'Total loss': 0.4327367517081174} | train loss {'Reaction outcome loss': 0.3137491263057056, 'Total loss': 0.3137491263057056}
2022-11-28 01:52:49,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:49,780 INFO:     Epoch: 81
2022-11-28 01:52:50,527 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4628243453123353, 'Total loss': 0.4628243453123353} | train loss {'Reaction outcome loss': 0.3137540251378588, 'Total loss': 0.3137540251378588}
2022-11-28 01:52:50,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:50,528 INFO:     Epoch: 82
2022-11-28 01:52:51,279 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41397824680263345, 'Total loss': 0.41397824680263345} | train loss {'Reaction outcome loss': 0.3128835875842615, 'Total loss': 0.3128835875842615}
2022-11-28 01:52:51,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:51,279 INFO:     Epoch: 83
2022-11-28 01:52:52,029 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4239309001713991, 'Total loss': 0.4239309001713991} | train loss {'Reaction outcome loss': 0.3040480599531278, 'Total loss': 0.3040480599531278}
2022-11-28 01:52:52,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:52,029 INFO:     Epoch: 84
2022-11-28 01:52:52,779 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4506986335935918, 'Total loss': 0.4506986335935918} | train loss {'Reaction outcome loss': 0.3111775083097852, 'Total loss': 0.3111775083097852}
2022-11-28 01:52:52,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:52,779 INFO:     Epoch: 85
2022-11-28 01:52:53,527 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4289053670046004, 'Total loss': 0.4289053670046004} | train loss {'Reaction outcome loss': 0.3074752842698261, 'Total loss': 0.3074752842698261}
2022-11-28 01:52:53,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:53,527 INFO:     Epoch: 86
2022-11-28 01:52:54,278 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42554347826675937, 'Total loss': 0.42554347826675937} | train loss {'Reaction outcome loss': 0.32488733333976644, 'Total loss': 0.32488733333976644}
2022-11-28 01:52:54,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:54,278 INFO:     Epoch: 87
2022-11-28 01:52:55,027 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43709328093312005, 'Total loss': 0.43709328093312005} | train loss {'Reaction outcome loss': 0.31493485206172533, 'Total loss': 0.31493485206172533}
2022-11-28 01:52:55,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:55,027 INFO:     Epoch: 88
2022-11-28 01:52:55,775 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42992189221761445, 'Total loss': 0.42992189221761445} | train loss {'Reaction outcome loss': 0.32704088167261014, 'Total loss': 0.32704088167261014}
2022-11-28 01:52:55,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:55,775 INFO:     Epoch: 89
2022-11-28 01:52:56,527 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42831131782044063, 'Total loss': 0.42831131782044063} | train loss {'Reaction outcome loss': 0.3022630962765651, 'Total loss': 0.3022630962765651}
2022-11-28 01:52:56,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:56,528 INFO:     Epoch: 90
2022-11-28 01:52:57,276 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43112340434031055, 'Total loss': 0.43112340434031055} | train loss {'Reaction outcome loss': 0.32027437711353246, 'Total loss': 0.32027437711353246}
2022-11-28 01:52:57,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:57,277 INFO:     Epoch: 91
2022-11-28 01:52:58,025 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4401829401877793, 'Total loss': 0.4401829401877793} | train loss {'Reaction outcome loss': 0.3128024576842664, 'Total loss': 0.3128024576842664}
2022-11-28 01:52:58,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:58,026 INFO:     Epoch: 92
2022-11-28 01:52:58,776 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4292942143299363, 'Total loss': 0.4292942143299363} | train loss {'Reaction outcome loss': 0.3052285716299586, 'Total loss': 0.3052285716299586}
2022-11-28 01:52:58,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:58,776 INFO:     Epoch: 93
2022-11-28 01:52:59,527 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4299802126532251, 'Total loss': 0.4299802126532251} | train loss {'Reaction outcome loss': 0.31638002102282126, 'Total loss': 0.31638002102282126}
2022-11-28 01:52:59,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:52:59,528 INFO:     Epoch: 94
2022-11-28 01:53:00,278 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4221827032213861, 'Total loss': 0.4221827032213861} | train loss {'Reaction outcome loss': 0.30530787736690235, 'Total loss': 0.30530787736690235}
2022-11-28 01:53:00,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:00,278 INFO:     Epoch: 95
2022-11-28 01:53:01,031 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42641082795506174, 'Total loss': 0.42641082795506174} | train loss {'Reaction outcome loss': 0.3102852549735713, 'Total loss': 0.3102852549735713}
2022-11-28 01:53:01,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:01,031 INFO:     Epoch: 96
2022-11-28 01:53:01,787 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42620692910118535, 'Total loss': 0.42620692910118535} | train loss {'Reaction outcome loss': 0.3015388976075585, 'Total loss': 0.3015388976075585}
2022-11-28 01:53:01,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:01,787 INFO:     Epoch: 97
2022-11-28 01:53:02,540 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4243608127263459, 'Total loss': 0.4243608127263459} | train loss {'Reaction outcome loss': 0.2985976789644373, 'Total loss': 0.2985976789644373}
2022-11-28 01:53:02,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:02,540 INFO:     Epoch: 98
2022-11-28 01:53:03,292 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4494523253630508, 'Total loss': 0.4494523253630508} | train loss {'Reaction outcome loss': 0.312466989448558, 'Total loss': 0.312466989448558}
2022-11-28 01:53:03,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:03,292 INFO:     Epoch: 99
2022-11-28 01:53:04,043 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4649795385246927, 'Total loss': 0.4649795385246927} | train loss {'Reaction outcome loss': 0.31656403643520253, 'Total loss': 0.31656403643520253}
2022-11-28 01:53:04,043 INFO:     Best model found after epoch 23 of 100.
2022-11-28 01:53:04,043 INFO:   Done with stage: TRAINING
2022-11-28 01:53:04,043 INFO:   Starting stage: EVALUATION
2022-11-28 01:53:04,168 INFO:   Done with stage: EVALUATION
2022-11-28 01:53:04,168 INFO:   Leaving out SEQ value Fold_9
2022-11-28 01:53:04,181 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:53:04,181 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:53:04,831 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:53:04,831 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:53:04,899 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:53:04,899 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:53:04,899 INFO:     No hyperparam tuning for this model
2022-11-28 01:53:04,899 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:53:04,899 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:53:04,900 INFO:     None feature selector for col prot
2022-11-28 01:53:04,900 INFO:     None feature selector for col prot
2022-11-28 01:53:04,900 INFO:     None feature selector for col prot
2022-11-28 01:53:04,900 INFO:     None feature selector for col chem
2022-11-28 01:53:04,900 INFO:     None feature selector for col chem
2022-11-28 01:53:04,900 INFO:     None feature selector for col chem
2022-11-28 01:53:04,900 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:53:04,901 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:53:04,902 INFO:     Number of params in model 169741
2022-11-28 01:53:04,905 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:53:04,905 INFO:   Starting stage: TRAINING
2022-11-28 01:53:04,958 INFO:     Val loss before train {'Reaction outcome loss': 1.0002637708728963, 'Total loss': 1.0002637708728963}
2022-11-28 01:53:04,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:04,959 INFO:     Epoch: 0
2022-11-28 01:53:05,712 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.47877715866674075, 'Total loss': 0.47877715866674075} | train loss {'Reaction outcome loss': 0.6430509750418335, 'Total loss': 0.6430509750418335}
2022-11-28 01:53:05,712 INFO:     Found new best model at epoch 0
2022-11-28 01:53:05,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:05,713 INFO:     Epoch: 1
2022-11-28 01:53:06,462 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4558468894525008, 'Total loss': 0.4558468894525008} | train loss {'Reaction outcome loss': 0.5099555409630301, 'Total loss': 0.5099555409630301}
2022-11-28 01:53:06,462 INFO:     Found new best model at epoch 1
2022-11-28 01:53:06,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:06,463 INFO:     Epoch: 2
2022-11-28 01:53:07,215 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49120080132376065, 'Total loss': 0.49120080132376065} | train loss {'Reaction outcome loss': 0.46930073316280657, 'Total loss': 0.46930073316280657}
2022-11-28 01:53:07,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:07,215 INFO:     Epoch: 3
2022-11-28 01:53:07,968 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45528085495937953, 'Total loss': 0.45528085495937953} | train loss {'Reaction outcome loss': 0.4380304892717103, 'Total loss': 0.4380304892717103}
2022-11-28 01:53:07,968 INFO:     Found new best model at epoch 3
2022-11-28 01:53:07,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:07,969 INFO:     Epoch: 4
2022-11-28 01:53:08,719 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4232790493829684, 'Total loss': 0.4232790493829684} | train loss {'Reaction outcome loss': 0.41947779786369577, 'Total loss': 0.41947779786369577}
2022-11-28 01:53:08,719 INFO:     Found new best model at epoch 4
2022-11-28 01:53:08,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:08,720 INFO:     Epoch: 5
2022-11-28 01:53:09,472 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41358704323118384, 'Total loss': 0.41358704323118384} | train loss {'Reaction outcome loss': 0.40721886526597173, 'Total loss': 0.40721886526597173}
2022-11-28 01:53:09,473 INFO:     Found new best model at epoch 5
2022-11-28 01:53:09,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:09,473 INFO:     Epoch: 6
2022-11-28 01:53:10,226 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4004357491027225, 'Total loss': 0.4004357491027225} | train loss {'Reaction outcome loss': 0.3898653777105063, 'Total loss': 0.3898653777105063}
2022-11-28 01:53:10,227 INFO:     Found new best model at epoch 6
2022-11-28 01:53:10,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:10,228 INFO:     Epoch: 7
2022-11-28 01:53:10,986 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43413905646990647, 'Total loss': 0.43413905646990647} | train loss {'Reaction outcome loss': 0.3793083368046473, 'Total loss': 0.3793083368046473}
2022-11-28 01:53:10,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:10,986 INFO:     Epoch: 8
2022-11-28 01:53:11,746 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40963229638609017, 'Total loss': 0.40963229638609017} | train loss {'Reaction outcome loss': 0.37585039563507205, 'Total loss': 0.37585039563507205}
2022-11-28 01:53:11,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:11,747 INFO:     Epoch: 9
2022-11-28 01:53:12,501 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4156938862394203, 'Total loss': 0.4156938862394203} | train loss {'Reaction outcome loss': 0.37629059086806377, 'Total loss': 0.37629059086806377}
2022-11-28 01:53:12,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:12,501 INFO:     Epoch: 10
2022-11-28 01:53:13,255 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40300615944645624, 'Total loss': 0.40300615944645624} | train loss {'Reaction outcome loss': 0.3684318754444962, 'Total loss': 0.3684318754444962}
2022-11-28 01:53:13,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:13,255 INFO:     Epoch: 11
2022-11-28 01:53:14,009 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39347369596362114, 'Total loss': 0.39347369596362114} | train loss {'Reaction outcome loss': 0.36166057074376523, 'Total loss': 0.36166057074376523}
2022-11-28 01:53:14,009 INFO:     Found new best model at epoch 11
2022-11-28 01:53:14,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:14,010 INFO:     Epoch: 12
2022-11-28 01:53:14,767 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43428915806792, 'Total loss': 0.43428915806792} | train loss {'Reaction outcome loss': 0.3634190981084036, 'Total loss': 0.3634190981084036}
2022-11-28 01:53:14,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:14,768 INFO:     Epoch: 13
2022-11-28 01:53:15,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41403318636796693, 'Total loss': 0.41403318636796693} | train loss {'Reaction outcome loss': 0.3763414291657417, 'Total loss': 0.3763414291657417}
2022-11-28 01:53:15,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:15,520 INFO:     Epoch: 14
2022-11-28 01:53:16,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40423568947748706, 'Total loss': 0.40423568947748706} | train loss {'Reaction outcome loss': 0.35817873159325436, 'Total loss': 0.35817873159325436}
2022-11-28 01:53:16,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:16,276 INFO:     Epoch: 15
2022-11-28 01:53:17,034 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3956837183372541, 'Total loss': 0.3956837183372541} | train loss {'Reaction outcome loss': 0.34720083473906344, 'Total loss': 0.34720083473906344}
2022-11-28 01:53:17,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:17,035 INFO:     Epoch: 16
2022-11-28 01:53:17,787 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3868835893544284, 'Total loss': 0.3868835893544284} | train loss {'Reaction outcome loss': 0.35370772211295876, 'Total loss': 0.35370772211295876}
2022-11-28 01:53:17,787 INFO:     Found new best model at epoch 16
2022-11-28 01:53:17,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:17,788 INFO:     Epoch: 17
2022-11-28 01:53:18,540 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43903202698989346, 'Total loss': 0.43903202698989346} | train loss {'Reaction outcome loss': 0.3461559318036203, 'Total loss': 0.3461559318036203}
2022-11-28 01:53:18,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:18,541 INFO:     Epoch: 18
2022-11-28 01:53:19,293 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40468335964462976, 'Total loss': 0.40468335964462976} | train loss {'Reaction outcome loss': 0.34697921999432296, 'Total loss': 0.34697921999432296}
2022-11-28 01:53:19,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:19,293 INFO:     Epoch: 19
2022-11-28 01:53:20,051 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3935845139097761, 'Total loss': 0.3935845139097761} | train loss {'Reaction outcome loss': 0.34011045840346377, 'Total loss': 0.34011045840346377}
2022-11-28 01:53:20,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:20,051 INFO:     Epoch: 20
2022-11-28 01:53:20,805 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43387108939615165, 'Total loss': 0.43387108939615165} | train loss {'Reaction outcome loss': 0.3409739878737492, 'Total loss': 0.3409739878737492}
2022-11-28 01:53:20,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:20,805 INFO:     Epoch: 21
2022-11-28 01:53:21,558 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4108598083257675, 'Total loss': 0.4108598083257675} | train loss {'Reaction outcome loss': 0.33245444306839816, 'Total loss': 0.33245444306839816}
2022-11-28 01:53:21,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:21,558 INFO:     Epoch: 22
2022-11-28 01:53:22,310 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39502921903675253, 'Total loss': 0.39502921903675253} | train loss {'Reaction outcome loss': 0.3377269196214705, 'Total loss': 0.3377269196214705}
2022-11-28 01:53:22,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:22,310 INFO:     Epoch: 23
2022-11-28 01:53:23,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4203527010977268, 'Total loss': 0.4203527010977268} | train loss {'Reaction outcome loss': 0.3406734521960772, 'Total loss': 0.3406734521960772}
2022-11-28 01:53:23,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:23,065 INFO:     Epoch: 24
2022-11-28 01:53:23,818 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.415672398426316, 'Total loss': 0.415672398426316} | train loss {'Reaction outcome loss': 0.3288857247963216, 'Total loss': 0.3288857247963216}
2022-11-28 01:53:23,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:23,818 INFO:     Epoch: 25
2022-11-28 01:53:24,568 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3984884416515177, 'Total loss': 0.3984884416515177} | train loss {'Reaction outcome loss': 0.33516647416329093, 'Total loss': 0.33516647416329093}
2022-11-28 01:53:24,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:24,569 INFO:     Epoch: 26
2022-11-28 01:53:25,320 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42150597443634813, 'Total loss': 0.42150597443634813} | train loss {'Reaction outcome loss': 0.32113118671438834, 'Total loss': 0.32113118671438834}
2022-11-28 01:53:25,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:25,321 INFO:     Epoch: 27
2022-11-28 01:53:26,070 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41552408039569855, 'Total loss': 0.41552408039569855} | train loss {'Reaction outcome loss': 0.3226405055778712, 'Total loss': 0.3226405055778712}
2022-11-28 01:53:26,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:26,070 INFO:     Epoch: 28
2022-11-28 01:53:26,821 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3826339371841062, 'Total loss': 0.3826339371841062} | train loss {'Reaction outcome loss': 0.3334165247164757, 'Total loss': 0.3334165247164757}
2022-11-28 01:53:26,821 INFO:     Found new best model at epoch 28
2022-11-28 01:53:26,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:26,822 INFO:     Epoch: 29
2022-11-28 01:53:27,573 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39970421757210384, 'Total loss': 0.39970421757210384} | train loss {'Reaction outcome loss': 0.3213777819324119, 'Total loss': 0.3213777819324119}
2022-11-28 01:53:27,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:27,573 INFO:     Epoch: 30
2022-11-28 01:53:28,326 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4067568213424899, 'Total loss': 0.4067568213424899} | train loss {'Reaction outcome loss': 0.31923784436243263, 'Total loss': 0.31923784436243263}
2022-11-28 01:53:28,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:28,327 INFO:     Epoch: 31
2022-11-28 01:53:29,079 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3737001283602281, 'Total loss': 0.3737001283602281} | train loss {'Reaction outcome loss': 0.3211400912478868, 'Total loss': 0.3211400912478868}
2022-11-28 01:53:29,079 INFO:     Found new best model at epoch 31
2022-11-28 01:53:29,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:29,080 INFO:     Epoch: 32
2022-11-28 01:53:29,831 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41091224551200867, 'Total loss': 0.41091224551200867} | train loss {'Reaction outcome loss': 0.3714178938659941, 'Total loss': 0.3714178938659941}
2022-11-28 01:53:29,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:29,831 INFO:     Epoch: 33
2022-11-28 01:53:30,585 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38893763517791574, 'Total loss': 0.38893763517791574} | train loss {'Reaction outcome loss': 0.33224408514986215, 'Total loss': 0.33224408514986215}
2022-11-28 01:53:30,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:30,585 INFO:     Epoch: 34
2022-11-28 01:53:31,340 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41562483916905796, 'Total loss': 0.41562483916905796} | train loss {'Reaction outcome loss': 0.32269353143185536, 'Total loss': 0.32269353143185536}
2022-11-28 01:53:31,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:31,340 INFO:     Epoch: 35
2022-11-28 01:53:32,095 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41251426257870416, 'Total loss': 0.41251426257870416} | train loss {'Reaction outcome loss': 0.31002857065514516, 'Total loss': 0.31002857065514516}
2022-11-28 01:53:32,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:32,095 INFO:     Epoch: 36
2022-11-28 01:53:32,850 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.382002055644989, 'Total loss': 0.382002055644989} | train loss {'Reaction outcome loss': 0.3302994906329192, 'Total loss': 0.3302994906329192}
2022-11-28 01:53:32,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:32,850 INFO:     Epoch: 37
2022-11-28 01:53:33,604 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.384714200838723, 'Total loss': 0.384714200838723} | train loss {'Reaction outcome loss': 0.34552168821998935, 'Total loss': 0.34552168821998935}
2022-11-28 01:53:33,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:33,605 INFO:     Epoch: 38
2022-11-28 01:53:34,360 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38943513381210243, 'Total loss': 0.38943513381210243} | train loss {'Reaction outcome loss': 0.3172835353527431, 'Total loss': 0.3172835353527431}
2022-11-28 01:53:34,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:34,360 INFO:     Epoch: 39
2022-11-28 01:53:35,114 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38886769251389935, 'Total loss': 0.38886769251389935} | train loss {'Reaction outcome loss': 0.31935672814908783, 'Total loss': 0.31935672814908783}
2022-11-28 01:53:35,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:35,114 INFO:     Epoch: 40
2022-11-28 01:53:35,869 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37750076231631363, 'Total loss': 0.37750076231631363} | train loss {'Reaction outcome loss': 0.31955503250061257, 'Total loss': 0.31955503250061257}
2022-11-28 01:53:35,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:35,869 INFO:     Epoch: 41
2022-11-28 01:53:36,622 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38744958862662315, 'Total loss': 0.38744958862662315} | train loss {'Reaction outcome loss': 0.3121704729514287, 'Total loss': 0.3121704729514287}
2022-11-28 01:53:36,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:36,623 INFO:     Epoch: 42
2022-11-28 01:53:37,377 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4016800438138572, 'Total loss': 0.4016800438138572} | train loss {'Reaction outcome loss': 0.3115452507789801, 'Total loss': 0.3115452507789801}
2022-11-28 01:53:37,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:37,378 INFO:     Epoch: 43
2022-11-28 01:53:38,129 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39716039411723614, 'Total loss': 0.39716039411723614} | train loss {'Reaction outcome loss': 0.3361254557062257, 'Total loss': 0.3361254557062257}
2022-11-28 01:53:38,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:38,129 INFO:     Epoch: 44
2022-11-28 01:53:38,882 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4194894548166882, 'Total loss': 0.4194894548166882} | train loss {'Reaction outcome loss': 0.30847877055512146, 'Total loss': 0.30847877055512146}
2022-11-28 01:53:38,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:38,882 INFO:     Epoch: 45
2022-11-28 01:53:39,636 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4105465591631152, 'Total loss': 0.4105465591631152} | train loss {'Reaction outcome loss': 0.30705413874144466, 'Total loss': 0.30705413874144466}
2022-11-28 01:53:39,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:39,636 INFO:     Epoch: 46
2022-11-28 01:53:40,391 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4097754643722014, 'Total loss': 0.4097754643722014} | train loss {'Reaction outcome loss': 0.31005615232746125, 'Total loss': 0.31005615232746125}
2022-11-28 01:53:40,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:40,392 INFO:     Epoch: 47
2022-11-28 01:53:41,145 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40196230821311474, 'Total loss': 0.40196230821311474} | train loss {'Reaction outcome loss': 0.3216634161076565, 'Total loss': 0.3216634161076565}
2022-11-28 01:53:41,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:41,146 INFO:     Epoch: 48
2022-11-28 01:53:41,899 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39352349970828404, 'Total loss': 0.39352349970828404} | train loss {'Reaction outcome loss': 0.3187400175914591, 'Total loss': 0.3187400175914591}
2022-11-28 01:53:41,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:41,899 INFO:     Epoch: 49
2022-11-28 01:53:42,656 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4253855334086852, 'Total loss': 0.4253855334086852} | train loss {'Reaction outcome loss': 0.30895833343810397, 'Total loss': 0.30895833343810397}
2022-11-28 01:53:42,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:42,656 INFO:     Epoch: 50
2022-11-28 01:53:43,410 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38105887885798106, 'Total loss': 0.38105887885798106} | train loss {'Reaction outcome loss': 0.3036058750154398, 'Total loss': 0.3036058750154398}
2022-11-28 01:53:43,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:43,410 INFO:     Epoch: 51
2022-11-28 01:53:44,162 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.369933851740577, 'Total loss': 0.369933851740577} | train loss {'Reaction outcome loss': 0.30261294303559944, 'Total loss': 0.30261294303559944}
2022-11-28 01:53:44,162 INFO:     Found new best model at epoch 51
2022-11-28 01:53:44,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:44,163 INFO:     Epoch: 52
2022-11-28 01:53:44,919 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4206599501723593, 'Total loss': 0.4206599501723593} | train loss {'Reaction outcome loss': 0.300603943039863, 'Total loss': 0.300603943039863}
2022-11-28 01:53:44,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:44,919 INFO:     Epoch: 53
2022-11-28 01:53:45,672 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4047180192375725, 'Total loss': 0.4047180192375725} | train loss {'Reaction outcome loss': 0.3074750901475126, 'Total loss': 0.3074750901475126}
2022-11-28 01:53:45,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:45,673 INFO:     Epoch: 54
2022-11-28 01:53:46,426 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39846827022053977, 'Total loss': 0.39846827022053977} | train loss {'Reaction outcome loss': 0.3147603853451096, 'Total loss': 0.3147603853451096}
2022-11-28 01:53:46,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:46,426 INFO:     Epoch: 55
2022-11-28 01:53:47,181 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41128167374567554, 'Total loss': 0.41128167374567554} | train loss {'Reaction outcome loss': 0.3062465595824244, 'Total loss': 0.3062465595824244}
2022-11-28 01:53:47,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:47,181 INFO:     Epoch: 56
2022-11-28 01:53:47,935 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3768777281723239, 'Total loss': 0.3768777281723239} | train loss {'Reaction outcome loss': 0.302226209914998, 'Total loss': 0.302226209914998}
2022-11-28 01:53:47,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:47,935 INFO:     Epoch: 57
2022-11-28 01:53:48,685 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38592002473094245, 'Total loss': 0.38592002473094245} | train loss {'Reaction outcome loss': 0.3075495272693846, 'Total loss': 0.3075495272693846}
2022-11-28 01:53:48,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:48,686 INFO:     Epoch: 58
2022-11-28 01:53:49,442 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38595026460560883, 'Total loss': 0.38595026460560883} | train loss {'Reaction outcome loss': 0.32924656361824106, 'Total loss': 0.32924656361824106}
2022-11-28 01:53:49,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:49,442 INFO:     Epoch: 59
2022-11-28 01:53:50,199 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4294761117886413, 'Total loss': 0.4294761117886413} | train loss {'Reaction outcome loss': 0.32364142839966514, 'Total loss': 0.32364142839966514}
2022-11-28 01:53:50,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:50,199 INFO:     Epoch: 60
2022-11-28 01:53:50,952 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3917329233478416, 'Total loss': 0.3917329233478416} | train loss {'Reaction outcome loss': 0.3157296311939776, 'Total loss': 0.3157296311939776}
2022-11-28 01:53:50,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:50,953 INFO:     Epoch: 61
2022-11-28 01:53:51,708 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38920540785924956, 'Total loss': 0.38920540785924956} | train loss {'Reaction outcome loss': 0.31447294316733415, 'Total loss': 0.31447294316733415}
2022-11-28 01:53:51,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:51,708 INFO:     Epoch: 62
2022-11-28 01:53:52,466 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41498473117297346, 'Total loss': 0.41498473117297346} | train loss {'Reaction outcome loss': 0.30654381506704925, 'Total loss': 0.30654381506704925}
2022-11-28 01:53:52,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:52,466 INFO:     Epoch: 63
2022-11-28 01:53:53,221 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3715531325645067, 'Total loss': 0.3715531325645067} | train loss {'Reaction outcome loss': 0.3058175318553923, 'Total loss': 0.3058175318553923}
2022-11-28 01:53:53,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:53,221 INFO:     Epoch: 64
2022-11-28 01:53:53,973 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3753089641474865, 'Total loss': 0.3753089641474865} | train loss {'Reaction outcome loss': 0.3020705246792631, 'Total loss': 0.3020705246792631}
2022-11-28 01:53:53,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:53,973 INFO:     Epoch: 65
2022-11-28 01:53:54,724 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39608411423184653, 'Total loss': 0.39608411423184653} | train loss {'Reaction outcome loss': 0.33021740116148823, 'Total loss': 0.33021740116148823}
2022-11-28 01:53:54,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:54,724 INFO:     Epoch: 66
2022-11-28 01:53:55,478 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3973926552994685, 'Total loss': 0.3973926552994685} | train loss {'Reaction outcome loss': 0.32813001570512396, 'Total loss': 0.32813001570512396}
2022-11-28 01:53:55,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:55,479 INFO:     Epoch: 67
2022-11-28 01:53:56,234 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3994805430146781, 'Total loss': 0.3994805430146781} | train loss {'Reaction outcome loss': 0.312104126491286, 'Total loss': 0.312104126491286}
2022-11-28 01:53:56,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:56,234 INFO:     Epoch: 68
2022-11-28 01:53:56,985 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39176811040802434, 'Total loss': 0.39176811040802434} | train loss {'Reaction outcome loss': 0.31128345115729117, 'Total loss': 0.31128345115729117}
2022-11-28 01:53:56,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:56,985 INFO:     Epoch: 69
2022-11-28 01:53:57,739 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40674482387575234, 'Total loss': 0.40674482387575234} | train loss {'Reaction outcome loss': 0.30132349592215013, 'Total loss': 0.30132349592215013}
2022-11-28 01:53:57,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:57,739 INFO:     Epoch: 70
2022-11-28 01:53:58,492 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4052176070822911, 'Total loss': 0.4052176070822911} | train loss {'Reaction outcome loss': 0.3073233190661406, 'Total loss': 0.3073233190661406}
2022-11-28 01:53:58,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:58,492 INFO:     Epoch: 71
2022-11-28 01:53:59,247 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42074500430714, 'Total loss': 0.42074500430714} | train loss {'Reaction outcome loss': 0.2976005838048995, 'Total loss': 0.2976005838048995}
2022-11-28 01:53:59,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:53:59,248 INFO:     Epoch: 72
2022-11-28 01:54:00,006 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4508798315443776, 'Total loss': 0.4508798315443776} | train loss {'Reaction outcome loss': 0.30397382711893634, 'Total loss': 0.30397382711893634}
2022-11-28 01:54:00,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:00,006 INFO:     Epoch: 73
2022-11-28 01:54:00,759 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3853502781553702, 'Total loss': 0.3853502781553702} | train loss {'Reaction outcome loss': 0.3264226758407678, 'Total loss': 0.3264226758407678}
2022-11-28 01:54:00,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:00,759 INFO:     Epoch: 74
2022-11-28 01:54:01,511 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37386428530920635, 'Total loss': 0.37386428530920635} | train loss {'Reaction outcome loss': 0.3137427470552535, 'Total loss': 0.3137427470552535}
2022-11-28 01:54:01,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:01,511 INFO:     Epoch: 75
2022-11-28 01:54:02,262 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4000960684127428, 'Total loss': 0.4000960684127428} | train loss {'Reaction outcome loss': 0.2959076763632206, 'Total loss': 0.2959076763632206}
2022-11-28 01:54:02,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:02,263 INFO:     Epoch: 76
2022-11-28 01:54:03,011 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3741964447227391, 'Total loss': 0.3741964447227391} | train loss {'Reaction outcome loss': 0.30730585586505865, 'Total loss': 0.30730585586505865}
2022-11-28 01:54:03,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:03,011 INFO:     Epoch: 77
2022-11-28 01:54:03,765 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39902377738194034, 'Total loss': 0.39902377738194034} | train loss {'Reaction outcome loss': 0.30673518663777516, 'Total loss': 0.30673518663777516}
2022-11-28 01:54:03,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:03,765 INFO:     Epoch: 78
2022-11-28 01:54:04,518 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40120918642390857, 'Total loss': 0.40120918642390857} | train loss {'Reaction outcome loss': 0.30099332994717337, 'Total loss': 0.30099332994717337}
2022-11-28 01:54:04,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:04,518 INFO:     Epoch: 79
2022-11-28 01:54:05,263 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3991297801787203, 'Total loss': 0.3991297801787203} | train loss {'Reaction outcome loss': 0.30077460892347674, 'Total loss': 0.30077460892347674}
2022-11-28 01:54:05,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:05,263 INFO:     Epoch: 80
2022-11-28 01:54:06,010 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3927737614986571, 'Total loss': 0.3927737614986571} | train loss {'Reaction outcome loss': 0.3198822497235619, 'Total loss': 0.3198822497235619}
2022-11-28 01:54:06,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:06,011 INFO:     Epoch: 81
2022-11-28 01:54:06,761 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38885383087803016, 'Total loss': 0.38885383087803016} | train loss {'Reaction outcome loss': 0.3246968004867615, 'Total loss': 0.3246968004867615}
2022-11-28 01:54:06,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:06,762 INFO:     Epoch: 82
2022-11-28 01:54:07,509 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40422051907940343, 'Total loss': 0.40422051907940343} | train loss {'Reaction outcome loss': 0.30334123653861195, 'Total loss': 0.30334123653861195}
2022-11-28 01:54:07,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:07,509 INFO:     Epoch: 83
2022-11-28 01:54:08,260 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39482071928002616, 'Total loss': 0.39482071928002616} | train loss {'Reaction outcome loss': 0.3066179536373509, 'Total loss': 0.3066179536373509}
2022-11-28 01:54:08,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:08,261 INFO:     Epoch: 84
2022-11-28 01:54:09,013 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37783469225872646, 'Total loss': 0.37783469225872646} | train loss {'Reaction outcome loss': 0.3166683666739869, 'Total loss': 0.3166683666739869}
2022-11-28 01:54:09,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:09,013 INFO:     Epoch: 85
2022-11-28 01:54:09,763 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3841719947416674, 'Total loss': 0.3841719947416674} | train loss {'Reaction outcome loss': 0.3100985455126897, 'Total loss': 0.3100985455126897}
2022-11-28 01:54:09,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:09,763 INFO:     Epoch: 86
2022-11-28 01:54:10,512 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42228069054809486, 'Total loss': 0.42228069054809486} | train loss {'Reaction outcome loss': 0.32966646365067254, 'Total loss': 0.32966646365067254}
2022-11-28 01:54:10,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:10,512 INFO:     Epoch: 87
2022-11-28 01:54:11,261 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3929244852201505, 'Total loss': 0.3929244852201505} | train loss {'Reaction outcome loss': 0.31829767481156207, 'Total loss': 0.31829767481156207}
2022-11-28 01:54:11,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:11,261 INFO:     Epoch: 88
2022-11-28 01:54:12,008 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40274178541519423, 'Total loss': 0.40274178541519423} | train loss {'Reaction outcome loss': 0.3108207709212535, 'Total loss': 0.3108207709212535}
2022-11-28 01:54:12,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:12,010 INFO:     Epoch: 89
2022-11-28 01:54:12,761 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39242295954715123, 'Total loss': 0.39242295954715123} | train loss {'Reaction outcome loss': 0.3049219906299944, 'Total loss': 0.3049219906299944}
2022-11-28 01:54:12,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:12,762 INFO:     Epoch: 90
2022-11-28 01:54:13,515 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40029963410713454, 'Total loss': 0.40029963410713454} | train loss {'Reaction outcome loss': 0.3035317489251434, 'Total loss': 0.3035317489251434}
2022-11-28 01:54:13,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:13,515 INFO:     Epoch: 91
2022-11-28 01:54:14,267 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40772890570488846, 'Total loss': 0.40772890570488846} | train loss {'Reaction outcome loss': 0.3123032776073285, 'Total loss': 0.3123032776073285}
2022-11-28 01:54:14,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:14,267 INFO:     Epoch: 92
2022-11-28 01:54:15,016 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41946089470928366, 'Total loss': 0.41946089470928366} | train loss {'Reaction outcome loss': 0.3044172001904563, 'Total loss': 0.3044172001904563}
2022-11-28 01:54:15,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:15,016 INFO:     Epoch: 93
2022-11-28 01:54:15,770 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43078775026581506, 'Total loss': 0.43078775026581506} | train loss {'Reaction outcome loss': 0.30366932184469364, 'Total loss': 0.30366932184469364}
2022-11-28 01:54:15,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:15,770 INFO:     Epoch: 94
2022-11-28 01:54:16,517 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3944138970903375, 'Total loss': 0.3944138970903375} | train loss {'Reaction outcome loss': 0.30426922380200283, 'Total loss': 0.30426922380200283}
2022-11-28 01:54:16,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:16,517 INFO:     Epoch: 95
2022-11-28 01:54:17,267 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43962893973697315, 'Total loss': 0.43962893973697315} | train loss {'Reaction outcome loss': 0.3139741632499193, 'Total loss': 0.3139741632499193}
2022-11-28 01:54:17,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:17,267 INFO:     Epoch: 96
2022-11-28 01:54:18,015 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39349737390875816, 'Total loss': 0.39349737390875816} | train loss {'Reaction outcome loss': 0.31028917739507156, 'Total loss': 0.31028917739507156}
2022-11-28 01:54:18,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:18,016 INFO:     Epoch: 97
2022-11-28 01:54:18,761 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4273815114389766, 'Total loss': 0.4273815114389766} | train loss {'Reaction outcome loss': 0.297776715475538, 'Total loss': 0.297776715475538}
2022-11-28 01:54:18,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:18,761 INFO:     Epoch: 98
2022-11-28 01:54:19,506 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39530577849258075, 'Total loss': 0.39530577849258075} | train loss {'Reaction outcome loss': 0.32757435877796126, 'Total loss': 0.32757435877796126}
2022-11-28 01:54:19,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:19,506 INFO:     Epoch: 99
2022-11-28 01:54:20,258 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4041460379958153, 'Total loss': 0.4041460379958153} | train loss {'Reaction outcome loss': 0.30627679423643994, 'Total loss': 0.30627679423643994}
2022-11-28 01:54:20,258 INFO:     Best model found after epoch 52 of 100.
2022-11-28 01:54:20,258 INFO:   Done with stage: TRAINING
2022-11-28 01:54:20,258 INFO:   Starting stage: EVALUATION
2022-11-28 01:54:20,383 INFO:   Done with stage: EVALUATION
2022-11-28 01:54:20,392 INFO:   Leaving out SEQ value Fold_0
2022-11-28 01:54:20,405 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:54:20,405 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:54:21,059 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:54:21,059 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:54:21,129 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:54:21,129 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:54:21,129 INFO:     No hyperparam tuning for this model
2022-11-28 01:54:21,129 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:54:21,129 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:54:21,130 INFO:     None feature selector for col prot
2022-11-28 01:54:21,130 INFO:     None feature selector for col prot
2022-11-28 01:54:21,130 INFO:     None feature selector for col prot
2022-11-28 01:54:21,130 INFO:     None feature selector for col chem
2022-11-28 01:54:21,130 INFO:     None feature selector for col chem
2022-11-28 01:54:21,131 INFO:     None feature selector for col chem
2022-11-28 01:54:21,131 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:54:21,131 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:54:21,132 INFO:     Number of params in model 169741
2022-11-28 01:54:21,135 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:54:21,135 INFO:   Starting stage: TRAINING
2022-11-28 01:54:21,189 INFO:     Val loss before train {'Reaction outcome loss': 0.988053826445883, 'Total loss': 0.988053826445883}
2022-11-28 01:54:21,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:21,190 INFO:     Epoch: 0
2022-11-28 01:54:21,935 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5000320076942444, 'Total loss': 0.5000320076942444} | train loss {'Reaction outcome loss': 0.6351891259553462, 'Total loss': 0.6351891259553462}
2022-11-28 01:54:21,935 INFO:     Found new best model at epoch 0
2022-11-28 01:54:21,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:21,936 INFO:     Epoch: 1
2022-11-28 01:54:22,682 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44872205213389615, 'Total loss': 0.44872205213389615} | train loss {'Reaction outcome loss': 0.49616326756684886, 'Total loss': 0.49616326756684886}
2022-11-28 01:54:22,682 INFO:     Found new best model at epoch 1
2022-11-28 01:54:22,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:22,683 INFO:     Epoch: 2
2022-11-28 01:54:23,429 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44207683578133583, 'Total loss': 0.44207683578133583} | train loss {'Reaction outcome loss': 0.45682717769252146, 'Total loss': 0.45682717769252146}
2022-11-28 01:54:23,429 INFO:     Found new best model at epoch 2
2022-11-28 01:54:23,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:23,430 INFO:     Epoch: 3
2022-11-28 01:54:24,176 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4331174536862157, 'Total loss': 0.4331174536862157} | train loss {'Reaction outcome loss': 0.4477050446034202, 'Total loss': 0.4477050446034202}
2022-11-28 01:54:24,176 INFO:     Found new best model at epoch 3
2022-11-28 01:54:24,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:24,177 INFO:     Epoch: 4
2022-11-28 01:54:24,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46366845951838925, 'Total loss': 0.46366845951838925} | train loss {'Reaction outcome loss': 0.4283869887894464, 'Total loss': 0.4283869887894464}
2022-11-28 01:54:24,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:24,926 INFO:     Epoch: 5
2022-11-28 01:54:25,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4538604584945874, 'Total loss': 0.4538604584945874} | train loss {'Reaction outcome loss': 0.42568380165437936, 'Total loss': 0.42568380165437936}
2022-11-28 01:54:25,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:25,673 INFO:     Epoch: 6
2022-11-28 01:54:26,425 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4203122449530797, 'Total loss': 0.4203122449530797} | train loss {'Reaction outcome loss': 0.4035822274050249, 'Total loss': 0.4035822274050249}
2022-11-28 01:54:26,425 INFO:     Found new best model at epoch 6
2022-11-28 01:54:26,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:26,426 INFO:     Epoch: 7
2022-11-28 01:54:27,174 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42408000203696167, 'Total loss': 0.42408000203696167} | train loss {'Reaction outcome loss': 0.3965936423795909, 'Total loss': 0.3965936423795909}
2022-11-28 01:54:27,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:27,174 INFO:     Epoch: 8
2022-11-28 01:54:27,921 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3918401734395461, 'Total loss': 0.3918401734395461} | train loss {'Reaction outcome loss': 0.4036077683271184, 'Total loss': 0.4036077683271184}
2022-11-28 01:54:27,921 INFO:     Found new best model at epoch 8
2022-11-28 01:54:27,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:27,922 INFO:     Epoch: 9
2022-11-28 01:54:28,668 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39731842414899304, 'Total loss': 0.39731842414899304} | train loss {'Reaction outcome loss': 0.39699408591457225, 'Total loss': 0.39699408591457225}
2022-11-28 01:54:28,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:28,668 INFO:     Epoch: 10
2022-11-28 01:54:29,416 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4055252107368274, 'Total loss': 0.4055252107368274} | train loss {'Reaction outcome loss': 0.3747899522062255, 'Total loss': 0.3747899522062255}
2022-11-28 01:54:29,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:29,417 INFO:     Epoch: 11
2022-11-28 01:54:30,159 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4217044868591157, 'Total loss': 0.4217044868591157} | train loss {'Reaction outcome loss': 0.37021451365006597, 'Total loss': 0.37021451365006597}
2022-11-28 01:54:30,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:30,160 INFO:     Epoch: 12
2022-11-28 01:54:30,908 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4326269287954677, 'Total loss': 0.4326269287954677} | train loss {'Reaction outcome loss': 0.3632610233176334, 'Total loss': 0.3632610233176334}
2022-11-28 01:54:30,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:30,909 INFO:     Epoch: 13
2022-11-28 01:54:31,655 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.394798857583241, 'Total loss': 0.394798857583241} | train loss {'Reaction outcome loss': 0.36012398964359693, 'Total loss': 0.36012398964359693}
2022-11-28 01:54:31,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:31,655 INFO:     Epoch: 14
2022-11-28 01:54:32,404 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40708676793358545, 'Total loss': 0.40708676793358545} | train loss {'Reaction outcome loss': 0.35127396599544203, 'Total loss': 0.35127396599544203}
2022-11-28 01:54:32,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:32,404 INFO:     Epoch: 15
2022-11-28 01:54:33,151 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4080636508085511, 'Total loss': 0.4080636508085511} | train loss {'Reaction outcome loss': 0.3578555284724062, 'Total loss': 0.3578555284724062}
2022-11-28 01:54:33,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:33,151 INFO:     Epoch: 16
2022-11-28 01:54:33,900 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41802969642660837, 'Total loss': 0.41802969642660837} | train loss {'Reaction outcome loss': 0.3612203828553077, 'Total loss': 0.3612203828553077}
2022-11-28 01:54:33,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:33,901 INFO:     Epoch: 17
2022-11-28 01:54:34,650 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3919779241762378, 'Total loss': 0.3919779241762378} | train loss {'Reaction outcome loss': 0.3654378936116995, 'Total loss': 0.3654378936116995}
2022-11-28 01:54:34,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:34,650 INFO:     Epoch: 18
2022-11-28 01:54:35,397 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3905870413238352, 'Total loss': 0.3905870413238352} | train loss {'Reaction outcome loss': 0.3674691831655348, 'Total loss': 0.3674691831655348}
2022-11-28 01:54:35,397 INFO:     Found new best model at epoch 18
2022-11-28 01:54:35,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:35,398 INFO:     Epoch: 19
2022-11-28 01:54:36,144 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4082107513465665, 'Total loss': 0.4082107513465665} | train loss {'Reaction outcome loss': 0.34735718514272557, 'Total loss': 0.34735718514272557}
2022-11-28 01:54:36,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:36,144 INFO:     Epoch: 20
2022-11-28 01:54:36,892 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4248951900411736, 'Total loss': 0.4248951900411736} | train loss {'Reaction outcome loss': 0.3490388962149861, 'Total loss': 0.3490388962149861}
2022-11-28 01:54:36,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:36,892 INFO:     Epoch: 21
2022-11-28 01:54:37,639 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4353795214132829, 'Total loss': 0.4353795214132829} | train loss {'Reaction outcome loss': 0.34462119228685434, 'Total loss': 0.34462119228685434}
2022-11-28 01:54:37,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:37,640 INFO:     Epoch: 22
2022-11-28 01:54:38,392 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42777091467922385, 'Total loss': 0.42777091467922385} | train loss {'Reaction outcome loss': 0.3477400752304778, 'Total loss': 0.3477400752304778}
2022-11-28 01:54:38,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:38,393 INFO:     Epoch: 23
2022-11-28 01:54:39,138 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41671632399613207, 'Total loss': 0.41671632399613207} | train loss {'Reaction outcome loss': 0.34415116601506707, 'Total loss': 0.34415116601506707}
2022-11-28 01:54:39,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:39,138 INFO:     Epoch: 24
2022-11-28 01:54:39,886 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40966560488397424, 'Total loss': 0.40966560488397424} | train loss {'Reaction outcome loss': 0.3826023613966187, 'Total loss': 0.3826023613966187}
2022-11-28 01:54:39,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:39,886 INFO:     Epoch: 25
2022-11-28 01:54:40,639 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3749101399020715, 'Total loss': 0.3749101399020715} | train loss {'Reaction outcome loss': 0.3388433390059452, 'Total loss': 0.3388433390059452}
2022-11-28 01:54:40,639 INFO:     Found new best model at epoch 25
2022-11-28 01:54:40,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:40,640 INFO:     Epoch: 26
2022-11-28 01:54:41,389 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4168221676214175, 'Total loss': 0.4168221676214175} | train loss {'Reaction outcome loss': 0.3345227410436159, 'Total loss': 0.3345227410436159}
2022-11-28 01:54:41,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:41,390 INFO:     Epoch: 27
2022-11-28 01:54:42,140 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4026567129926248, 'Total loss': 0.4026567129926248} | train loss {'Reaction outcome loss': 0.3368663638226899, 'Total loss': 0.3368663638226899}
2022-11-28 01:54:42,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:42,140 INFO:     Epoch: 28
2022-11-28 01:54:42,889 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38380013914270833, 'Total loss': 0.38380013914270833} | train loss {'Reaction outcome loss': 0.33145895874813985, 'Total loss': 0.33145895874813985}
2022-11-28 01:54:42,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:42,891 INFO:     Epoch: 29
2022-11-28 01:54:43,640 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3984806310724128, 'Total loss': 0.3984806310724128} | train loss {'Reaction outcome loss': 0.33144755049152413, 'Total loss': 0.33144755049152413}
2022-11-28 01:54:43,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:43,640 INFO:     Epoch: 30
2022-11-28 01:54:44,386 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39015162651511753, 'Total loss': 0.39015162651511753} | train loss {'Reaction outcome loss': 0.3258941434776252, 'Total loss': 0.3258941434776252}
2022-11-28 01:54:44,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:44,386 INFO:     Epoch: 31
2022-11-28 01:54:45,136 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4006665000184016, 'Total loss': 0.4006665000184016} | train loss {'Reaction outcome loss': 0.33318728107491485, 'Total loss': 0.33318728107491485}
2022-11-28 01:54:45,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:45,137 INFO:     Epoch: 32
2022-11-28 01:54:45,883 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41074997085061943, 'Total loss': 0.41074997085061943} | train loss {'Reaction outcome loss': 0.32472165506465084, 'Total loss': 0.32472165506465084}
2022-11-28 01:54:45,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:45,884 INFO:     Epoch: 33
2022-11-28 01:54:46,633 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43026779321106995, 'Total loss': 0.43026779321106995} | train loss {'Reaction outcome loss': 0.3303435662919693, 'Total loss': 0.3303435662919693}
2022-11-28 01:54:46,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:46,633 INFO:     Epoch: 34
2022-11-28 01:54:47,386 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38980232196098025, 'Total loss': 0.38980232196098025} | train loss {'Reaction outcome loss': 0.328062198853924, 'Total loss': 0.328062198853924}
2022-11-28 01:54:47,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:47,386 INFO:     Epoch: 35
2022-11-28 01:54:48,139 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4099112163213166, 'Total loss': 0.4099112163213166} | train loss {'Reaction outcome loss': 0.3282317828975226, 'Total loss': 0.3282317828975226}
2022-11-28 01:54:48,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:48,139 INFO:     Epoch: 36
2022-11-28 01:54:48,892 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4042958542704582, 'Total loss': 0.4042958542704582} | train loss {'Reaction outcome loss': 0.3269503190811829, 'Total loss': 0.3269503190811829}
2022-11-28 01:54:48,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:48,893 INFO:     Epoch: 37
2022-11-28 01:54:49,640 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4429464179345153, 'Total loss': 0.4429464179345153} | train loss {'Reaction outcome loss': 0.3209379181899281, 'Total loss': 0.3209379181899281}
2022-11-28 01:54:49,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:49,640 INFO:     Epoch: 38
2022-11-28 01:54:50,389 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39593704942275176, 'Total loss': 0.39593704942275176} | train loss {'Reaction outcome loss': 0.3234997645080814, 'Total loss': 0.3234997645080814}
2022-11-28 01:54:50,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:50,389 INFO:     Epoch: 39
2022-11-28 01:54:51,140 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39445245977152477, 'Total loss': 0.39445245977152477} | train loss {'Reaction outcome loss': 0.36613937268252317, 'Total loss': 0.36613937268252317}
2022-11-28 01:54:51,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:51,141 INFO:     Epoch: 40
2022-11-28 01:54:51,890 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3942996194078164, 'Total loss': 0.3942996194078164} | train loss {'Reaction outcome loss': 0.32992703567149667, 'Total loss': 0.32992703567149667}
2022-11-28 01:54:51,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:51,890 INFO:     Epoch: 41
2022-11-28 01:54:52,637 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38927859846841206, 'Total loss': 0.38927859846841206} | train loss {'Reaction outcome loss': 0.3251416491352112, 'Total loss': 0.3251416491352112}
2022-11-28 01:54:52,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:52,637 INFO:     Epoch: 42
2022-11-28 01:54:53,386 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3977008036930453, 'Total loss': 0.3977008036930453} | train loss {'Reaction outcome loss': 0.32289825502703173, 'Total loss': 0.32289825502703173}
2022-11-28 01:54:53,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:53,386 INFO:     Epoch: 43
2022-11-28 01:54:54,134 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40501333129676903, 'Total loss': 0.40501333129676903} | train loss {'Reaction outcome loss': 0.3180379808733338, 'Total loss': 0.3180379808733338}
2022-11-28 01:54:54,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:54,134 INFO:     Epoch: 44
2022-11-28 01:54:54,883 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3936752739616416, 'Total loss': 0.3936752739616416} | train loss {'Reaction outcome loss': 0.32393573471891735, 'Total loss': 0.32393573471891735}
2022-11-28 01:54:54,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:54,883 INFO:     Epoch: 45
2022-11-28 01:54:55,630 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3946663642471487, 'Total loss': 0.3946663642471487} | train loss {'Reaction outcome loss': 0.3285063664741844, 'Total loss': 0.3285063664741844}
2022-11-28 01:54:55,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:55,630 INFO:     Epoch: 46
2022-11-28 01:54:56,379 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40028161301531573, 'Total loss': 0.40028161301531573} | train loss {'Reaction outcome loss': 0.3237889554532554, 'Total loss': 0.3237889554532554}
2022-11-28 01:54:56,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:56,379 INFO:     Epoch: 47
2022-11-28 01:54:57,128 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38521291383288125, 'Total loss': 0.38521291383288125} | train loss {'Reaction outcome loss': 0.3189979373187068, 'Total loss': 0.3189979373187068}
2022-11-28 01:54:57,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:57,128 INFO:     Epoch: 48
2022-11-28 01:54:57,876 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41922691582956095, 'Total loss': 0.41922691582956095} | train loss {'Reaction outcome loss': 0.3205486025722737, 'Total loss': 0.3205486025722737}
2022-11-28 01:54:57,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:57,877 INFO:     Epoch: 49
2022-11-28 01:54:58,624 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39580795947800984, 'Total loss': 0.39580795947800984} | train loss {'Reaction outcome loss': 0.32401672560676387, 'Total loss': 0.32401672560676387}
2022-11-28 01:54:58,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:58,624 INFO:     Epoch: 50
2022-11-28 01:54:59,372 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4251192899590189, 'Total loss': 0.4251192899590189} | train loss {'Reaction outcome loss': 0.3169453638032652, 'Total loss': 0.3169453638032652}
2022-11-28 01:54:59,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:54:59,373 INFO:     Epoch: 51
2022-11-28 01:55:00,121 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3972886343571273, 'Total loss': 0.3972886343571273} | train loss {'Reaction outcome loss': 0.31815559548062017, 'Total loss': 0.31815559548062017}
2022-11-28 01:55:00,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:00,121 INFO:     Epoch: 52
2022-11-28 01:55:00,871 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3865610831840472, 'Total loss': 0.3865610831840472} | train loss {'Reaction outcome loss': 0.31459024585882456, 'Total loss': 0.31459024585882456}
2022-11-28 01:55:00,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:00,871 INFO:     Epoch: 53
2022-11-28 01:55:01,622 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40746417980302463, 'Total loss': 0.40746417980302463} | train loss {'Reaction outcome loss': 0.3265939138920201, 'Total loss': 0.3265939138920201}
2022-11-28 01:55:01,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:01,623 INFO:     Epoch: 54
2022-11-28 01:55:02,369 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4081563478843732, 'Total loss': 0.4081563478843732} | train loss {'Reaction outcome loss': 0.3212274690931625, 'Total loss': 0.3212274690931625}
2022-11-28 01:55:02,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:02,369 INFO:     Epoch: 55
2022-11-28 01:55:03,120 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39589854109693656, 'Total loss': 0.39589854109693656} | train loss {'Reaction outcome loss': 0.31999597963660215, 'Total loss': 0.31999597963660215}
2022-11-28 01:55:03,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:03,121 INFO:     Epoch: 56
2022-11-28 01:55:03,872 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41127485798841174, 'Total loss': 0.41127485798841174} | train loss {'Reaction outcome loss': 0.31132459604223295, 'Total loss': 0.31132459604223295}
2022-11-28 01:55:03,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:03,873 INFO:     Epoch: 57
2022-11-28 01:55:04,622 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44247898391701956, 'Total loss': 0.44247898391701956} | train loss {'Reaction outcome loss': 0.3195727254124547, 'Total loss': 0.3195727254124547}
2022-11-28 01:55:04,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:04,622 INFO:     Epoch: 58
2022-11-28 01:55:05,370 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4068722674115138, 'Total loss': 0.4068722674115138} | train loss {'Reaction outcome loss': 0.3211030733586866, 'Total loss': 0.3211030733586866}
2022-11-28 01:55:05,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:05,371 INFO:     Epoch: 59
2022-11-28 01:55:06,120 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3915213058617982, 'Total loss': 0.3915213058617982} | train loss {'Reaction outcome loss': 0.3270431934037672, 'Total loss': 0.3270431934037672}
2022-11-28 01:55:06,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:06,120 INFO:     Epoch: 60
2022-11-28 01:55:06,868 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4103564301675016, 'Total loss': 0.4103564301675016} | train loss {'Reaction outcome loss': 0.33047659921380673, 'Total loss': 0.33047659921380673}
2022-11-28 01:55:06,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:06,868 INFO:     Epoch: 61
2022-11-28 01:55:07,618 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3931005708873272, 'Total loss': 0.3931005708873272} | train loss {'Reaction outcome loss': 0.3155204256174535, 'Total loss': 0.3155204256174535}
2022-11-28 01:55:07,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:07,618 INFO:     Epoch: 62
2022-11-28 01:55:08,364 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3945853752507405, 'Total loss': 0.3945853752507405} | train loss {'Reaction outcome loss': 0.3160564772452903, 'Total loss': 0.3160564772452903}
2022-11-28 01:55:08,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:08,364 INFO:     Epoch: 63
2022-11-28 01:55:09,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39825682748447766, 'Total loss': 0.39825682748447766} | train loss {'Reaction outcome loss': 0.32090322139035715, 'Total loss': 0.32090322139035715}
2022-11-28 01:55:09,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:09,114 INFO:     Epoch: 64
2022-11-28 01:55:09,862 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4102458235892383, 'Total loss': 0.4102458235892383} | train loss {'Reaction outcome loss': 0.3142051412931338, 'Total loss': 0.3142051412931338}
2022-11-28 01:55:09,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:09,862 INFO:     Epoch: 65
2022-11-28 01:55:10,612 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4312183426862413, 'Total loss': 0.4312183426862413} | train loss {'Reaction outcome loss': 0.3168894766929562, 'Total loss': 0.3168894766929562}
2022-11-28 01:55:10,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:10,612 INFO:     Epoch: 66
2022-11-28 01:55:11,360 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.391751346940344, 'Total loss': 0.391751346940344} | train loss {'Reaction outcome loss': 0.3106036561160435, 'Total loss': 0.3106036561160435}
2022-11-28 01:55:11,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:11,361 INFO:     Epoch: 67
2022-11-28 01:55:12,108 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4047228798947551, 'Total loss': 0.4047228798947551} | train loss {'Reaction outcome loss': 0.313075450726814, 'Total loss': 0.313075450726814}
2022-11-28 01:55:12,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:12,108 INFO:     Epoch: 68
2022-11-28 01:55:12,856 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3946047973903743, 'Total loss': 0.3946047973903743} | train loss {'Reaction outcome loss': 0.31348932654359324, 'Total loss': 0.31348932654359324}
2022-11-28 01:55:12,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:12,857 INFO:     Epoch: 69
2022-11-28 01:55:13,604 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39896512912078336, 'Total loss': 0.39896512912078336} | train loss {'Reaction outcome loss': 0.31590480194521336, 'Total loss': 0.31590480194521336}
2022-11-28 01:55:13,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:13,605 INFO:     Epoch: 70
2022-11-28 01:55:14,351 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39158140343021264, 'Total loss': 0.39158140343021264} | train loss {'Reaction outcome loss': 0.32523114205364456, 'Total loss': 0.32523114205364456}
2022-11-28 01:55:14,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:14,351 INFO:     Epoch: 71
2022-11-28 01:55:15,100 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3847911242734302, 'Total loss': 0.3847911242734302} | train loss {'Reaction outcome loss': 0.3154466742204751, 'Total loss': 0.3154466742204751}
2022-11-28 01:55:15,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:15,100 INFO:     Epoch: 72
2022-11-28 01:55:15,846 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3912517062642358, 'Total loss': 0.3912517062642358} | train loss {'Reaction outcome loss': 0.32764446810792813, 'Total loss': 0.32764446810792813}
2022-11-28 01:55:15,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:15,847 INFO:     Epoch: 73
2022-11-28 01:55:16,594 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3893746936863119, 'Total loss': 0.3893746936863119} | train loss {'Reaction outcome loss': 0.32027360142363226, 'Total loss': 0.32027360142363226}
2022-11-28 01:55:16,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:16,594 INFO:     Epoch: 74
2022-11-28 01:55:17,343 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3984841314906424, 'Total loss': 0.3984841314906424} | train loss {'Reaction outcome loss': 0.3286230332304833, 'Total loss': 0.3286230332304833}
2022-11-28 01:55:17,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:17,343 INFO:     Epoch: 75
2022-11-28 01:55:18,091 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36779116635972803, 'Total loss': 0.36779116635972803} | train loss {'Reaction outcome loss': 0.3160318737276472, 'Total loss': 0.3160318737276472}
2022-11-28 01:55:18,091 INFO:     Found new best model at epoch 75
2022-11-28 01:55:18,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:18,092 INFO:     Epoch: 76
2022-11-28 01:55:18,840 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39736939255486836, 'Total loss': 0.39736939255486836} | train loss {'Reaction outcome loss': 0.30334070490801385, 'Total loss': 0.30334070490801385}
2022-11-28 01:55:18,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:18,840 INFO:     Epoch: 77
2022-11-28 01:55:19,587 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4009096453135664, 'Total loss': 0.4009096453135664} | train loss {'Reaction outcome loss': 0.3212386716745402, 'Total loss': 0.3212386716745402}
2022-11-28 01:55:19,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:19,587 INFO:     Epoch: 78
2022-11-28 01:55:20,337 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37823315913026984, 'Total loss': 0.37823315913026984} | train loss {'Reaction outcome loss': 0.31340950552509866, 'Total loss': 0.31340950552509866}
2022-11-28 01:55:20,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:20,338 INFO:     Epoch: 79
2022-11-28 01:55:21,083 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.397606357593428, 'Total loss': 0.397606357593428} | train loss {'Reaction outcome loss': 0.3365556893018093, 'Total loss': 0.3365556893018093}
2022-11-28 01:55:21,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:21,083 INFO:     Epoch: 80
2022-11-28 01:55:21,834 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37949172576720064, 'Total loss': 0.37949172576720064} | train loss {'Reaction outcome loss': 0.32390631503813905, 'Total loss': 0.32390631503813905}
2022-11-28 01:55:21,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:21,835 INFO:     Epoch: 81
2022-11-28 01:55:22,587 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.388459079306234, 'Total loss': 0.388459079306234} | train loss {'Reaction outcome loss': 0.3064214699752704, 'Total loss': 0.3064214699752704}
2022-11-28 01:55:22,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:22,587 INFO:     Epoch: 82
2022-11-28 01:55:23,335 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3761483735658906, 'Total loss': 0.3761483735658906} | train loss {'Reaction outcome loss': 0.3025078969264803, 'Total loss': 0.3025078969264803}
2022-11-28 01:55:23,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:23,335 INFO:     Epoch: 83
2022-11-28 01:55:24,082 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41167347776618873, 'Total loss': 0.41167347776618873} | train loss {'Reaction outcome loss': 0.3117680446459697, 'Total loss': 0.3117680446459697}
2022-11-28 01:55:24,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:24,082 INFO:     Epoch: 84
2022-11-28 01:55:24,835 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3885246242650531, 'Total loss': 0.3885246242650531} | train loss {'Reaction outcome loss': 0.33616178651690964, 'Total loss': 0.33616178651690964}
2022-11-28 01:55:24,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:24,835 INFO:     Epoch: 85
2022-11-28 01:55:25,586 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38939787091856654, 'Total loss': 0.38939787091856654} | train loss {'Reaction outcome loss': 0.3191136606490081, 'Total loss': 0.3191136606490081}
2022-11-28 01:55:25,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:25,586 INFO:     Epoch: 86
2022-11-28 01:55:26,336 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4228988868946379, 'Total loss': 0.4228988868946379} | train loss {'Reaction outcome loss': 0.3265397050663045, 'Total loss': 0.3265397050663045}
2022-11-28 01:55:26,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:26,336 INFO:     Epoch: 87
2022-11-28 01:55:27,085 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4063289522786032, 'Total loss': 0.4063289522786032} | train loss {'Reaction outcome loss': 0.3172821569301731, 'Total loss': 0.3172821569301731}
2022-11-28 01:55:27,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:27,085 INFO:     Epoch: 88
2022-11-28 01:55:27,836 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39819076691161504, 'Total loss': 0.39819076691161504} | train loss {'Reaction outcome loss': 0.3114724907013569, 'Total loss': 0.3114724907013569}
2022-11-28 01:55:27,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:27,836 INFO:     Epoch: 89
2022-11-28 01:55:28,583 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4149296354841102, 'Total loss': 0.4149296354841102} | train loss {'Reaction outcome loss': 0.32553193897618016, 'Total loss': 0.32553193897618016}
2022-11-28 01:55:28,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:28,583 INFO:     Epoch: 90
2022-11-28 01:55:29,329 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38246023146943614, 'Total loss': 0.38246023146943614} | train loss {'Reaction outcome loss': 0.31682121101201244, 'Total loss': 0.31682121101201244}
2022-11-28 01:55:29,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:29,329 INFO:     Epoch: 91
2022-11-28 01:55:30,074 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3962110663679513, 'Total loss': 0.3962110663679513} | train loss {'Reaction outcome loss': 0.3060551076988536, 'Total loss': 0.3060551076988536}
2022-11-28 01:55:30,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:30,075 INFO:     Epoch: 92
2022-11-28 01:55:30,825 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4245349388908256, 'Total loss': 0.4245349388908256} | train loss {'Reaction outcome loss': 0.3049504973959585, 'Total loss': 0.3049504973959585}
2022-11-28 01:55:30,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:30,825 INFO:     Epoch: 93
2022-11-28 01:55:31,575 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38979542086070235, 'Total loss': 0.38979542086070235} | train loss {'Reaction outcome loss': 0.33541953222833665, 'Total loss': 0.33541953222833665}
2022-11-28 01:55:31,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:31,575 INFO:     Epoch: 94
2022-11-28 01:55:32,327 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3990190289914608, 'Total loss': 0.3990190289914608} | train loss {'Reaction outcome loss': 0.31829470417156874, 'Total loss': 0.31829470417156874}
2022-11-28 01:55:32,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:32,327 INFO:     Epoch: 95
2022-11-28 01:55:33,078 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3872723635286093, 'Total loss': 0.3872723635286093} | train loss {'Reaction outcome loss': 0.31364196869224187, 'Total loss': 0.31364196869224187}
2022-11-28 01:55:33,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:33,078 INFO:     Epoch: 96
2022-11-28 01:55:33,824 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38798296417702327, 'Total loss': 0.38798296417702327} | train loss {'Reaction outcome loss': 0.30243147172312806, 'Total loss': 0.30243147172312806}
2022-11-28 01:55:33,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:33,824 INFO:     Epoch: 97
2022-11-28 01:55:34,572 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45788362520662224, 'Total loss': 0.45788362520662224} | train loss {'Reaction outcome loss': 0.31343933585503325, 'Total loss': 0.31343933585503325}
2022-11-28 01:55:34,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:34,572 INFO:     Epoch: 98
2022-11-28 01:55:35,319 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4243712028996511, 'Total loss': 0.4243712028996511} | train loss {'Reaction outcome loss': 0.32774489685169117, 'Total loss': 0.32774489685169117}
2022-11-28 01:55:35,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:35,319 INFO:     Epoch: 99
2022-11-28 01:55:36,066 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.407945954664187, 'Total loss': 0.407945954664187} | train loss {'Reaction outcome loss': 0.30683181493690137, 'Total loss': 0.30683181493690137}
2022-11-28 01:55:36,066 INFO:     Best model found after epoch 76 of 100.
2022-11-28 01:55:36,066 INFO:   Done with stage: TRAINING
2022-11-28 01:55:36,067 INFO:   Starting stage: EVALUATION
2022-11-28 01:55:36,193 INFO:   Done with stage: EVALUATION
2022-11-28 01:55:36,193 INFO:   Leaving out SEQ value Fold_1
2022-11-28 01:55:36,206 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:55:36,206 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:55:36,848 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:55:36,848 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:55:36,916 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:55:36,916 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:55:36,916 INFO:     No hyperparam tuning for this model
2022-11-28 01:55:36,916 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:55:36,916 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:55:36,917 INFO:     None feature selector for col prot
2022-11-28 01:55:36,917 INFO:     None feature selector for col prot
2022-11-28 01:55:36,917 INFO:     None feature selector for col prot
2022-11-28 01:55:36,918 INFO:     None feature selector for col chem
2022-11-28 01:55:36,918 INFO:     None feature selector for col chem
2022-11-28 01:55:36,918 INFO:     None feature selector for col chem
2022-11-28 01:55:36,918 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:55:36,918 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:55:36,919 INFO:     Number of params in model 169741
2022-11-28 01:55:36,923 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:55:36,923 INFO:   Starting stage: TRAINING
2022-11-28 01:55:36,976 INFO:     Val loss before train {'Reaction outcome loss': 0.985012682324106, 'Total loss': 0.985012682324106}
2022-11-28 01:55:36,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:36,977 INFO:     Epoch: 0
2022-11-28 01:55:37,723 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5888009423559363, 'Total loss': 0.5888009423559363} | train loss {'Reaction outcome loss': 0.6415236235750832, 'Total loss': 0.6415236235750832}
2022-11-28 01:55:37,723 INFO:     Found new best model at epoch 0
2022-11-28 01:55:37,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:37,724 INFO:     Epoch: 1
2022-11-28 01:55:38,471 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49468385157260025, 'Total loss': 0.49468385157260025} | train loss {'Reaction outcome loss': 0.5128222896381911, 'Total loss': 0.5128222896381911}
2022-11-28 01:55:38,471 INFO:     Found new best model at epoch 1
2022-11-28 01:55:38,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:38,472 INFO:     Epoch: 2
2022-11-28 01:55:39,222 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45425379276275635, 'Total loss': 0.45425379276275635} | train loss {'Reaction outcome loss': 0.47270575956053096, 'Total loss': 0.47270575956053096}
2022-11-28 01:55:39,222 INFO:     Found new best model at epoch 2
2022-11-28 01:55:39,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:39,223 INFO:     Epoch: 3
2022-11-28 01:55:39,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4631195092065768, 'Total loss': 0.4631195092065768} | train loss {'Reaction outcome loss': 0.4636451626566016, 'Total loss': 0.4636451626566016}
2022-11-28 01:55:39,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:39,975 INFO:     Epoch: 4
2022-11-28 01:55:40,724 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4659458361566067, 'Total loss': 0.4659458361566067} | train loss {'Reaction outcome loss': 0.44358189090302114, 'Total loss': 0.44358189090302114}
2022-11-28 01:55:40,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:40,724 INFO:     Epoch: 5
2022-11-28 01:55:41,473 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46631295708092774, 'Total loss': 0.46631295708092774} | train loss {'Reaction outcome loss': 0.4226269210096796, 'Total loss': 0.4226269210096796}
2022-11-28 01:55:41,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:41,474 INFO:     Epoch: 6
2022-11-28 01:55:42,221 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4636302654716102, 'Total loss': 0.4636302654716102} | train loss {'Reaction outcome loss': 0.41762335613550927, 'Total loss': 0.41762335613550927}
2022-11-28 01:55:42,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:42,221 INFO:     Epoch: 7
2022-11-28 01:55:42,971 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4380966912616383, 'Total loss': 0.4380966912616383} | train loss {'Reaction outcome loss': 0.402404524989215, 'Total loss': 0.402404524989215}
2022-11-28 01:55:42,971 INFO:     Found new best model at epoch 7
2022-11-28 01:55:42,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:42,972 INFO:     Epoch: 8
2022-11-28 01:55:43,721 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46561421860348096, 'Total loss': 0.46561421860348096} | train loss {'Reaction outcome loss': 0.3853481690048689, 'Total loss': 0.3853481690048689}
2022-11-28 01:55:43,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:43,721 INFO:     Epoch: 9
2022-11-28 01:55:44,470 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4527734731408683, 'Total loss': 0.4527734731408683} | train loss {'Reaction outcome loss': 0.3927634167164443, 'Total loss': 0.3927634167164443}
2022-11-28 01:55:44,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:44,471 INFO:     Epoch: 10
2022-11-28 01:55:45,219 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4037607816809958, 'Total loss': 0.4037607816809958} | train loss {'Reaction outcome loss': 0.4050381659466004, 'Total loss': 0.4050381659466004}
2022-11-28 01:55:45,219 INFO:     Found new best model at epoch 10
2022-11-28 01:55:45,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:45,220 INFO:     Epoch: 11
2022-11-28 01:55:45,969 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4282205186106942, 'Total loss': 0.4282205186106942} | train loss {'Reaction outcome loss': 0.37337459301055687, 'Total loss': 0.37337459301055687}
2022-11-28 01:55:45,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:45,970 INFO:     Epoch: 12
2022-11-28 01:55:46,719 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4234689748422666, 'Total loss': 0.4234689748422666} | train loss {'Reaction outcome loss': 0.38486703406163464, 'Total loss': 0.38486703406163464}
2022-11-28 01:55:46,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:46,720 INFO:     Epoch: 13
2022-11-28 01:55:47,472 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43317741951481864, 'Total loss': 0.43317741951481864} | train loss {'Reaction outcome loss': 0.3602182913895862, 'Total loss': 0.3602182913895862}
2022-11-28 01:55:47,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:47,472 INFO:     Epoch: 14
2022-11-28 01:55:48,220 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43090535497123544, 'Total loss': 0.43090535497123544} | train loss {'Reaction outcome loss': 0.3558466680619398, 'Total loss': 0.3558466680619398}
2022-11-28 01:55:48,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:48,220 INFO:     Epoch: 15
2022-11-28 01:55:48,970 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4560367935760455, 'Total loss': 0.4560367935760455} | train loss {'Reaction outcome loss': 0.361774327214581, 'Total loss': 0.361774327214581}
2022-11-28 01:55:48,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:48,970 INFO:     Epoch: 16
2022-11-28 01:55:49,718 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3988093032755635, 'Total loss': 0.3988093032755635} | train loss {'Reaction outcome loss': 0.3590384411968683, 'Total loss': 0.3590384411968683}
2022-11-28 01:55:49,718 INFO:     Found new best model at epoch 16
2022-11-28 01:55:49,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:49,719 INFO:     Epoch: 17
2022-11-28 01:55:50,468 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4203582964837551, 'Total loss': 0.4203582964837551} | train loss {'Reaction outcome loss': 0.3533131462570868, 'Total loss': 0.3533131462570868}
2022-11-28 01:55:50,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:50,469 INFO:     Epoch: 18
2022-11-28 01:55:51,216 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3961832018738443, 'Total loss': 0.3961832018738443} | train loss {'Reaction outcome loss': 0.3474029148947674, 'Total loss': 0.3474029148947674}
2022-11-28 01:55:51,216 INFO:     Found new best model at epoch 18
2022-11-28 01:55:51,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:51,217 INFO:     Epoch: 19
2022-11-28 01:55:51,963 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4380731548775326, 'Total loss': 0.4380731548775326} | train loss {'Reaction outcome loss': 0.35342487882868, 'Total loss': 0.35342487882868}
2022-11-28 01:55:51,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:51,964 INFO:     Epoch: 20
2022-11-28 01:55:52,709 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40999320742081513, 'Total loss': 0.40999320742081513} | train loss {'Reaction outcome loss': 0.3574652467903338, 'Total loss': 0.3574652467903338}
2022-11-28 01:55:52,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:52,709 INFO:     Epoch: 21
2022-11-28 01:55:53,457 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4008532376451926, 'Total loss': 0.4008532376451926} | train loss {'Reaction outcome loss': 0.3459110017941307, 'Total loss': 0.3459110017941307}
2022-11-28 01:55:53,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:53,457 INFO:     Epoch: 22
2022-11-28 01:55:54,203 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42914572899991815, 'Total loss': 0.42914572899991815} | train loss {'Reaction outcome loss': 0.35396554607611436, 'Total loss': 0.35396554607611436}
2022-11-28 01:55:54,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:54,203 INFO:     Epoch: 23
2022-11-28 01:55:54,951 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46399662051011215, 'Total loss': 0.46399662051011215} | train loss {'Reaction outcome loss': 0.3447219168692865, 'Total loss': 0.3447219168692865}
2022-11-28 01:55:54,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:54,951 INFO:     Epoch: 24
2022-11-28 01:55:55,699 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39289371195164596, 'Total loss': 0.39289371195164596} | train loss {'Reaction outcome loss': 0.3388751330936275, 'Total loss': 0.3388751330936275}
2022-11-28 01:55:55,700 INFO:     Found new best model at epoch 24
2022-11-28 01:55:55,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:55,701 INFO:     Epoch: 25
2022-11-28 01:55:56,450 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.435522804714062, 'Total loss': 0.435522804714062} | train loss {'Reaction outcome loss': 0.33071267040755586, 'Total loss': 0.33071267040755586}
2022-11-28 01:55:56,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:56,450 INFO:     Epoch: 26
2022-11-28 01:55:57,198 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4283937087113207, 'Total loss': 0.4283937087113207} | train loss {'Reaction outcome loss': 0.350618139844433, 'Total loss': 0.350618139844433}
2022-11-28 01:55:57,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:57,199 INFO:     Epoch: 27
2022-11-28 01:55:57,944 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4250755767253312, 'Total loss': 0.4250755767253312} | train loss {'Reaction outcome loss': 0.34901506459785375, 'Total loss': 0.34901506459785375}
2022-11-28 01:55:57,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:57,945 INFO:     Epoch: 28
2022-11-28 01:55:58,688 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42914559014818887, 'Total loss': 0.42914559014818887} | train loss {'Reaction outcome loss': 0.3426272762026864, 'Total loss': 0.3426272762026864}
2022-11-28 01:55:58,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:58,688 INFO:     Epoch: 29
2022-11-28 01:55:59,433 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4451666254211556, 'Total loss': 0.4451666254211556} | train loss {'Reaction outcome loss': 0.3369689305343096, 'Total loss': 0.3369689305343096}
2022-11-28 01:55:59,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:55:59,433 INFO:     Epoch: 30
2022-11-28 01:56:00,181 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41853624006563966, 'Total loss': 0.41853624006563966} | train loss {'Reaction outcome loss': 0.340036282293227, 'Total loss': 0.340036282293227}
2022-11-28 01:56:00,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:00,181 INFO:     Epoch: 31
2022-11-28 01:56:00,933 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4186330579898574, 'Total loss': 0.4186330579898574} | train loss {'Reaction outcome loss': 0.37910385585959383, 'Total loss': 0.37910385585959383}
2022-11-28 01:56:00,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:00,933 INFO:     Epoch: 32
2022-11-28 01:56:01,679 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41735606064850633, 'Total loss': 0.41735606064850633} | train loss {'Reaction outcome loss': 0.33093286519832454, 'Total loss': 0.33093286519832454}
2022-11-28 01:56:01,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:01,679 INFO:     Epoch: 33
2022-11-28 01:56:02,425 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.481988710435954, 'Total loss': 0.481988710435954} | train loss {'Reaction outcome loss': 0.333113453540902, 'Total loss': 0.333113453540902}
2022-11-28 01:56:02,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:02,425 INFO:     Epoch: 34
2022-11-28 01:56:03,173 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44919936468994076, 'Total loss': 0.44919936468994076} | train loss {'Reaction outcome loss': 0.32565683597766676, 'Total loss': 0.32565683597766676}
2022-11-28 01:56:03,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:03,173 INFO:     Epoch: 35
2022-11-28 01:56:03,918 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39235336672176013, 'Total loss': 0.39235336672176013} | train loss {'Reaction outcome loss': 0.3375489604376588, 'Total loss': 0.3375489604376588}
2022-11-28 01:56:03,918 INFO:     Found new best model at epoch 35
2022-11-28 01:56:03,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:03,919 INFO:     Epoch: 36
2022-11-28 01:56:04,664 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4131773832169446, 'Total loss': 0.4131773832169446} | train loss {'Reaction outcome loss': 0.34001869089931613, 'Total loss': 0.34001869089931613}
2022-11-28 01:56:04,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:04,665 INFO:     Epoch: 37
2022-11-28 01:56:05,414 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43321312591433525, 'Total loss': 0.43321312591433525} | train loss {'Reaction outcome loss': 0.3394965564077748, 'Total loss': 0.3394965564077748}
2022-11-28 01:56:05,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:05,415 INFO:     Epoch: 38
2022-11-28 01:56:06,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4158664576031945, 'Total loss': 0.4158664576031945} | train loss {'Reaction outcome loss': 0.33151495815650656, 'Total loss': 0.33151495815650656}
2022-11-28 01:56:06,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:06,162 INFO:     Epoch: 39
2022-11-28 01:56:06,912 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4063806217163801, 'Total loss': 0.4063806217163801} | train loss {'Reaction outcome loss': 0.34887494078954223, 'Total loss': 0.34887494078954223}
2022-11-28 01:56:06,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:06,912 INFO:     Epoch: 40
2022-11-28 01:56:07,661 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4053567932410674, 'Total loss': 0.4053567932410674} | train loss {'Reaction outcome loss': 0.3256021999299898, 'Total loss': 0.3256021999299898}
2022-11-28 01:56:07,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:07,661 INFO:     Epoch: 41
2022-11-28 01:56:08,413 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41375925933772867, 'Total loss': 0.41375925933772867} | train loss {'Reaction outcome loss': 0.31805371825144013, 'Total loss': 0.31805371825144013}
2022-11-28 01:56:08,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:08,413 INFO:     Epoch: 42
2022-11-28 01:56:09,161 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4520890617912466, 'Total loss': 0.4520890617912466} | train loss {'Reaction outcome loss': 0.3199644322216752, 'Total loss': 0.3199644322216752}
2022-11-28 01:56:09,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:09,161 INFO:     Epoch: 43
2022-11-28 01:56:09,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4234107028354298, 'Total loss': 0.4234107028354298} | train loss {'Reaction outcome loss': 0.330419675933446, 'Total loss': 0.330419675933446}
2022-11-28 01:56:09,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:09,909 INFO:     Epoch: 44
2022-11-28 01:56:10,655 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45718658478422597, 'Total loss': 0.45718658478422597} | train loss {'Reaction outcome loss': 0.3364428309667177, 'Total loss': 0.3364428309667177}
2022-11-28 01:56:10,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:10,655 INFO:     Epoch: 45
2022-11-28 01:56:11,402 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44035283306782896, 'Total loss': 0.44035283306782896} | train loss {'Reaction outcome loss': 0.3234783241804312, 'Total loss': 0.3234783241804312}
2022-11-28 01:56:11,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:11,403 INFO:     Epoch: 46
2022-11-28 01:56:12,151 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40717975388873706, 'Total loss': 0.40717975388873706} | train loss {'Reaction outcome loss': 0.340497101034954, 'Total loss': 0.340497101034954}
2022-11-28 01:56:12,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:12,151 INFO:     Epoch: 47
2022-11-28 01:56:12,903 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4056282134895975, 'Total loss': 0.4056282134895975} | train loss {'Reaction outcome loss': 0.3385054856260224, 'Total loss': 0.3385054856260224}
2022-11-28 01:56:12,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:12,903 INFO:     Epoch: 48
2022-11-28 01:56:13,650 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43017023378475144, 'Total loss': 0.43017023378475144} | train loss {'Reaction outcome loss': 0.31385352073410744, 'Total loss': 0.31385352073410744}
2022-11-28 01:56:13,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:13,650 INFO:     Epoch: 49
2022-11-28 01:56:14,396 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4149169586598873, 'Total loss': 0.4149169586598873} | train loss {'Reaction outcome loss': 0.31066591576164065, 'Total loss': 0.31066591576164065}
2022-11-28 01:56:14,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:14,396 INFO:     Epoch: 50
2022-11-28 01:56:15,139 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3903542916205796, 'Total loss': 0.3903542916205796} | train loss {'Reaction outcome loss': 0.3281389329627699, 'Total loss': 0.3281389329627699}
2022-11-28 01:56:15,139 INFO:     Found new best model at epoch 50
2022-11-28 01:56:15,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:15,140 INFO:     Epoch: 51
2022-11-28 01:56:15,881 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45676515793258493, 'Total loss': 0.45676515793258493} | train loss {'Reaction outcome loss': 0.3313166582259361, 'Total loss': 0.3313166582259361}
2022-11-28 01:56:15,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:15,883 INFO:     Epoch: 52
2022-11-28 01:56:16,624 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.405883457088335, 'Total loss': 0.405883457088335} | train loss {'Reaction outcome loss': 0.31788111568583166, 'Total loss': 0.31788111568583166}
2022-11-28 01:56:16,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:16,624 INFO:     Epoch: 53
2022-11-28 01:56:17,367 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4167293557389216, 'Total loss': 0.4167293557389216} | train loss {'Reaction outcome loss': 0.3218585837345857, 'Total loss': 0.3218585837345857}
2022-11-28 01:56:17,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:17,367 INFO:     Epoch: 54
2022-11-28 01:56:18,112 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3936574726619504, 'Total loss': 0.3936574726619504} | train loss {'Reaction outcome loss': 0.33294309962254304, 'Total loss': 0.33294309962254304}
2022-11-28 01:56:18,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:18,113 INFO:     Epoch: 55
2022-11-28 01:56:18,859 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38945524496111, 'Total loss': 0.38945524496111} | train loss {'Reaction outcome loss': 0.31221293683657764, 'Total loss': 0.31221293683657764}
2022-11-28 01:56:18,859 INFO:     Found new best model at epoch 55
2022-11-28 01:56:18,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:18,860 INFO:     Epoch: 56
2022-11-28 01:56:19,601 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3920366239141334, 'Total loss': 0.3920366239141334} | train loss {'Reaction outcome loss': 0.31813224881646124, 'Total loss': 0.31813224881646124}
2022-11-28 01:56:19,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:19,601 INFO:     Epoch: 57
2022-11-28 01:56:20,342 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3990212096409364, 'Total loss': 0.3990212096409364} | train loss {'Reaction outcome loss': 0.3252677862581454, 'Total loss': 0.3252677862581454}
2022-11-28 01:56:20,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:20,342 INFO:     Epoch: 58
2022-11-28 01:56:21,090 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39578728106888855, 'Total loss': 0.39578728106888855} | train loss {'Reaction outcome loss': 0.31401682236356293, 'Total loss': 0.31401682236356293}
2022-11-28 01:56:21,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:21,090 INFO:     Epoch: 59
2022-11-28 01:56:21,833 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4101108122955669, 'Total loss': 0.4101108122955669} | train loss {'Reaction outcome loss': 0.3227067783565415, 'Total loss': 0.3227067783565415}
2022-11-28 01:56:21,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:21,833 INFO:     Epoch: 60
2022-11-28 01:56:22,574 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42088835042986, 'Total loss': 0.42088835042986} | train loss {'Reaction outcome loss': 0.3342706796671697, 'Total loss': 0.3342706796671697}
2022-11-28 01:56:22,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:22,575 INFO:     Epoch: 61
2022-11-28 01:56:23,323 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4136949228969487, 'Total loss': 0.4136949228969487} | train loss {'Reaction outcome loss': 0.32182467741295995, 'Total loss': 0.32182467741295995}
2022-11-28 01:56:23,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:23,323 INFO:     Epoch: 62
2022-11-28 01:56:24,066 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4128844870085066, 'Total loss': 0.4128844870085066} | train loss {'Reaction outcome loss': 0.31475449991431315, 'Total loss': 0.31475449991431315}
2022-11-28 01:56:24,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:24,066 INFO:     Epoch: 63
2022-11-28 01:56:24,813 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4066017661243677, 'Total loss': 0.4066017661243677} | train loss {'Reaction outcome loss': 0.3190185875303832, 'Total loss': 0.3190185875303832}
2022-11-28 01:56:24,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:24,813 INFO:     Epoch: 64
2022-11-28 01:56:25,558 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4288695657795126, 'Total loss': 0.4288695657795126} | train loss {'Reaction outcome loss': 0.32747119713408746, 'Total loss': 0.32747119713408746}
2022-11-28 01:56:25,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:25,558 INFO:     Epoch: 65
2022-11-28 01:56:26,306 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4107311151244424, 'Total loss': 0.4107311151244424} | train loss {'Reaction outcome loss': 0.3314706289213196, 'Total loss': 0.3314706289213196}
2022-11-28 01:56:26,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:26,306 INFO:     Epoch: 66
2022-11-28 01:56:27,049 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39652063054117287, 'Total loss': 0.39652063054117287} | train loss {'Reaction outcome loss': 0.32619983597700053, 'Total loss': 0.32619983597700053}
2022-11-28 01:56:27,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:27,049 INFO:     Epoch: 67
2022-11-28 01:56:27,792 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.435737897049297, 'Total loss': 0.435737897049297} | train loss {'Reaction outcome loss': 0.3090438965089649, 'Total loss': 0.3090438965089649}
2022-11-28 01:56:27,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:27,792 INFO:     Epoch: 68
2022-11-28 01:56:28,536 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4448467801240357, 'Total loss': 0.4448467801240357} | train loss {'Reaction outcome loss': 0.3194091318529627, 'Total loss': 0.3194091318529627}
2022-11-28 01:56:28,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:28,537 INFO:     Epoch: 69
2022-11-28 01:56:29,280 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41107015345584264, 'Total loss': 0.41107015345584264} | train loss {'Reaction outcome loss': 0.32261326488273345, 'Total loss': 0.32261326488273345}
2022-11-28 01:56:29,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:29,280 INFO:     Epoch: 70
2022-11-28 01:56:30,027 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38942508365620265, 'Total loss': 0.38942508365620265} | train loss {'Reaction outcome loss': 0.3310141867773253, 'Total loss': 0.3310141867773253}
2022-11-28 01:56:30,027 INFO:     Found new best model at epoch 70
2022-11-28 01:56:30,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:30,028 INFO:     Epoch: 71
2022-11-28 01:56:30,774 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44396842101758177, 'Total loss': 0.44396842101758177} | train loss {'Reaction outcome loss': 0.30757169693478414, 'Total loss': 0.30757169693478414}
2022-11-28 01:56:30,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:30,774 INFO:     Epoch: 72
2022-11-28 01:56:31,517 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4098506529222835, 'Total loss': 0.4098506529222835} | train loss {'Reaction outcome loss': 0.3188250379689671, 'Total loss': 0.3188250379689671}
2022-11-28 01:56:31,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:31,518 INFO:     Epoch: 73
2022-11-28 01:56:32,269 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43226434696804394, 'Total loss': 0.43226434696804394} | train loss {'Reaction outcome loss': 0.31726409264120015, 'Total loss': 0.31726409264120015}
2022-11-28 01:56:32,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:32,269 INFO:     Epoch: 74
2022-11-28 01:56:33,012 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4065237201072953, 'Total loss': 0.4065237201072953} | train loss {'Reaction outcome loss': 0.3172217922319134, 'Total loss': 0.3172217922319134}
2022-11-28 01:56:33,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:33,012 INFO:     Epoch: 75
2022-11-28 01:56:33,761 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4337197267873721, 'Total loss': 0.4337197267873721} | train loss {'Reaction outcome loss': 0.318756544819245, 'Total loss': 0.318756544819245}
2022-11-28 01:56:33,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:33,761 INFO:     Epoch: 76
2022-11-28 01:56:34,509 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4268483248623935, 'Total loss': 0.4268483248623935} | train loss {'Reaction outcome loss': 0.3379291132137722, 'Total loss': 0.3379291132137722}
2022-11-28 01:56:34,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:34,509 INFO:     Epoch: 77
2022-11-28 01:56:35,252 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41415363042192027, 'Total loss': 0.41415363042192027} | train loss {'Reaction outcome loss': 0.31259282434034924, 'Total loss': 0.31259282434034924}
2022-11-28 01:56:35,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:35,252 INFO:     Epoch: 78
2022-11-28 01:56:35,995 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39126241173256526, 'Total loss': 0.39126241173256526} | train loss {'Reaction outcome loss': 0.31329857280500506, 'Total loss': 0.31329857280500506}
2022-11-28 01:56:35,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:35,995 INFO:     Epoch: 79
2022-11-28 01:56:36,739 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4422945359891111, 'Total loss': 0.4422945359891111} | train loss {'Reaction outcome loss': 0.3184298543553603, 'Total loss': 0.3184298543553603}
2022-11-28 01:56:36,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:36,739 INFO:     Epoch: 80
2022-11-28 01:56:37,487 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4247649325565858, 'Total loss': 0.4247649325565858} | train loss {'Reaction outcome loss': 0.3276955456386211, 'Total loss': 0.3276955456386211}
2022-11-28 01:56:37,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:37,487 INFO:     Epoch: 81
2022-11-28 01:56:38,234 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42886943166906183, 'Total loss': 0.42886943166906183} | train loss {'Reaction outcome loss': 0.3096190209492008, 'Total loss': 0.3096190209492008}
2022-11-28 01:56:38,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:38,234 INFO:     Epoch: 82
2022-11-28 01:56:38,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4168634531511502, 'Total loss': 0.4168634531511502} | train loss {'Reaction outcome loss': 0.32126166360068176, 'Total loss': 0.32126166360068176}
2022-11-28 01:56:38,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:38,978 INFO:     Epoch: 83
2022-11-28 01:56:39,722 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3660542902282693, 'Total loss': 0.3660542902282693} | train loss {'Reaction outcome loss': 0.316025804464332, 'Total loss': 0.316025804464332}
2022-11-28 01:56:39,722 INFO:     Found new best model at epoch 83
2022-11-28 01:56:39,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:39,723 INFO:     Epoch: 84
2022-11-28 01:56:40,470 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4245134029876102, 'Total loss': 0.4245134029876102} | train loss {'Reaction outcome loss': 0.31188688816329246, 'Total loss': 0.31188688816329246}
2022-11-28 01:56:40,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:40,470 INFO:     Epoch: 85
2022-11-28 01:56:41,216 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43404668535698543, 'Total loss': 0.43404668535698543} | train loss {'Reaction outcome loss': 0.3348341711876001, 'Total loss': 0.3348341711876001}
2022-11-28 01:56:41,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:41,216 INFO:     Epoch: 86
2022-11-28 01:56:41,961 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39049224995753984, 'Total loss': 0.39049224995753984} | train loss {'Reaction outcome loss': 0.31358996247835, 'Total loss': 0.31358996247835}
2022-11-28 01:56:41,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:41,961 INFO:     Epoch: 87
2022-11-28 01:56:42,707 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44625104117122566, 'Total loss': 0.44625104117122566} | train loss {'Reaction outcome loss': 0.32190710217182933, 'Total loss': 0.32190710217182933}
2022-11-28 01:56:42,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:42,707 INFO:     Epoch: 88
2022-11-28 01:56:43,450 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4009826525368474, 'Total loss': 0.4009826525368474} | train loss {'Reaction outcome loss': 0.3543520749882165, 'Total loss': 0.3543520749882165}
2022-11-28 01:56:43,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:43,450 INFO:     Epoch: 89
2022-11-28 01:56:44,193 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40508373149416665, 'Total loss': 0.40508373149416665} | train loss {'Reaction outcome loss': 0.3131182483333325, 'Total loss': 0.3131182483333325}
2022-11-28 01:56:44,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:44,193 INFO:     Epoch: 90
2022-11-28 01:56:44,936 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3993211706930941, 'Total loss': 0.3993211706930941} | train loss {'Reaction outcome loss': 0.3162979428931648, 'Total loss': 0.3162979428931648}
2022-11-28 01:56:44,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:44,936 INFO:     Epoch: 91
2022-11-28 01:56:45,677 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41632394899021496, 'Total loss': 0.41632394899021496} | train loss {'Reaction outcome loss': 0.30805788882951507, 'Total loss': 0.30805788882951507}
2022-11-28 01:56:45,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:45,678 INFO:     Epoch: 92
2022-11-28 01:56:46,423 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39630117639899254, 'Total loss': 0.39630117639899254} | train loss {'Reaction outcome loss': 0.3068887680045024, 'Total loss': 0.3068887680045024}
2022-11-28 01:56:46,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:46,423 INFO:     Epoch: 93
2022-11-28 01:56:47,169 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4159833790565079, 'Total loss': 0.4159833790565079} | train loss {'Reaction outcome loss': 0.32474975153683167, 'Total loss': 0.32474975153683167}
2022-11-28 01:56:47,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:47,170 INFO:     Epoch: 94
2022-11-28 01:56:47,916 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.405858827246861, 'Total loss': 0.405858827246861} | train loss {'Reaction outcome loss': 0.3231773541199594, 'Total loss': 0.3231773541199594}
2022-11-28 01:56:47,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:47,916 INFO:     Epoch: 95
2022-11-28 01:56:48,660 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4093716537410563, 'Total loss': 0.4093716537410563} | train loss {'Reaction outcome loss': 0.3064274568005129, 'Total loss': 0.3064274568005129}
2022-11-28 01:56:48,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:48,660 INFO:     Epoch: 96
2022-11-28 01:56:49,404 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4011586620049043, 'Total loss': 0.4011586620049043} | train loss {'Reaction outcome loss': 0.30300303101200265, 'Total loss': 0.30300303101200265}
2022-11-28 01:56:49,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:49,404 INFO:     Epoch: 97
2022-11-28 01:56:50,151 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4298326020891016, 'Total loss': 0.4298326020891016} | train loss {'Reaction outcome loss': 0.3185030586172936, 'Total loss': 0.3185030586172936}
2022-11-28 01:56:50,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:50,151 INFO:     Epoch: 98
2022-11-28 01:56:50,895 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43062875589186494, 'Total loss': 0.43062875589186494} | train loss {'Reaction outcome loss': 0.3178361813850731, 'Total loss': 0.3178361813850731}
2022-11-28 01:56:50,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:50,896 INFO:     Epoch: 99
2022-11-28 01:56:51,641 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40413307889618655, 'Total loss': 0.40413307889618655} | train loss {'Reaction outcome loss': 0.3364931123730866, 'Total loss': 0.3364931123730866}
2022-11-28 01:56:51,641 INFO:     Best model found after epoch 84 of 100.
2022-11-28 01:56:51,641 INFO:   Done with stage: TRAINING
2022-11-28 01:56:51,641 INFO:   Starting stage: EVALUATION
2022-11-28 01:56:51,765 INFO:   Done with stage: EVALUATION
2022-11-28 01:56:51,765 INFO:   Leaving out SEQ value Fold_2
2022-11-28 01:56:51,778 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:56:51,778 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:56:52,402 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:56:52,403 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:56:52,469 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:56:52,469 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:56:52,469 INFO:     No hyperparam tuning for this model
2022-11-28 01:56:52,469 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:56:52,469 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:56:52,470 INFO:     None feature selector for col prot
2022-11-28 01:56:52,470 INFO:     None feature selector for col prot
2022-11-28 01:56:52,470 INFO:     None feature selector for col prot
2022-11-28 01:56:52,471 INFO:     None feature selector for col chem
2022-11-28 01:56:52,471 INFO:     None feature selector for col chem
2022-11-28 01:56:52,471 INFO:     None feature selector for col chem
2022-11-28 01:56:52,471 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:56:52,471 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:56:52,473 INFO:     Number of params in model 169741
2022-11-28 01:56:52,475 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:56:52,476 INFO:   Starting stage: TRAINING
2022-11-28 01:56:52,527 INFO:     Val loss before train {'Reaction outcome loss': 1.0246596641318744, 'Total loss': 1.0246596641318744}
2022-11-28 01:56:52,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:52,528 INFO:     Epoch: 0
2022-11-28 01:56:53,256 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5589356983816901, 'Total loss': 0.5589356983816901} | train loss {'Reaction outcome loss': 0.6259893541086893, 'Total loss': 0.6259893541086893}
2022-11-28 01:56:53,257 INFO:     Found new best model at epoch 0
2022-11-28 01:56:53,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:53,258 INFO:     Epoch: 1
2022-11-28 01:56:53,991 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5290936758351881, 'Total loss': 0.5290936758351881} | train loss {'Reaction outcome loss': 0.49307825825497753, 'Total loss': 0.49307825825497753}
2022-11-28 01:56:53,992 INFO:     Found new best model at epoch 1
2022-11-28 01:56:53,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:53,993 INFO:     Epoch: 2
2022-11-28 01:56:54,729 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47264162745586663, 'Total loss': 0.47264162745586663} | train loss {'Reaction outcome loss': 0.4614929950139562, 'Total loss': 0.4614929950139562}
2022-11-28 01:56:54,730 INFO:     Found new best model at epoch 2
2022-11-28 01:56:54,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:54,730 INFO:     Epoch: 3
2022-11-28 01:56:55,466 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4913709437431291, 'Total loss': 0.4913709437431291} | train loss {'Reaction outcome loss': 0.4365920706606302, 'Total loss': 0.4365920706606302}
2022-11-28 01:56:55,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:55,467 INFO:     Epoch: 4
2022-11-28 01:56:56,202 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4558582583139109, 'Total loss': 0.4558582583139109} | train loss {'Reaction outcome loss': 0.41814571719799865, 'Total loss': 0.41814571719799865}
2022-11-28 01:56:56,202 INFO:     Found new best model at epoch 4
2022-11-28 01:56:56,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:56,203 INFO:     Epoch: 5
2022-11-28 01:56:56,938 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46629034225330795, 'Total loss': 0.46629034225330795} | train loss {'Reaction outcome loss': 0.4089796030741246, 'Total loss': 0.4089796030741246}
2022-11-28 01:56:56,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:56,938 INFO:     Epoch: 6
2022-11-28 01:56:57,673 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5222646680682205, 'Total loss': 0.5222646680682205} | train loss {'Reaction outcome loss': 0.3948218933321902, 'Total loss': 0.3948218933321902}
2022-11-28 01:56:57,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:57,673 INFO:     Epoch: 7
2022-11-28 01:56:58,408 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.444658400360928, 'Total loss': 0.444658400360928} | train loss {'Reaction outcome loss': 0.4016199917150814, 'Total loss': 0.4016199917150814}
2022-11-28 01:56:58,409 INFO:     Found new best model at epoch 7
2022-11-28 01:56:58,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:58,409 INFO:     Epoch: 8
2022-11-28 01:56:59,143 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4770287576802941, 'Total loss': 0.4770287576802941} | train loss {'Reaction outcome loss': 0.3751808274537325, 'Total loss': 0.3751808274537325}
2022-11-28 01:56:59,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:59,143 INFO:     Epoch: 9
2022-11-28 01:56:59,877 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4519990824682768, 'Total loss': 0.4519990824682768} | train loss {'Reaction outcome loss': 0.38054674885189926, 'Total loss': 0.38054674885189926}
2022-11-28 01:56:59,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:56:59,877 INFO:     Epoch: 10
2022-11-28 01:57:00,614 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4388089107219563, 'Total loss': 0.4388089107219563} | train loss {'Reaction outcome loss': 0.374979557622163, 'Total loss': 0.374979557622163}
2022-11-28 01:57:00,614 INFO:     Found new best model at epoch 10
2022-11-28 01:57:00,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:00,615 INFO:     Epoch: 11
2022-11-28 01:57:01,349 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44673137886579645, 'Total loss': 0.44673137886579645} | train loss {'Reaction outcome loss': 0.3680232075333107, 'Total loss': 0.3680232075333107}
2022-11-28 01:57:01,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:01,350 INFO:     Epoch: 12
2022-11-28 01:57:02,083 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4140432416353115, 'Total loss': 0.4140432416353115} | train loss {'Reaction outcome loss': 0.36216794284152204, 'Total loss': 0.36216794284152204}
2022-11-28 01:57:02,083 INFO:     Found new best model at epoch 12
2022-11-28 01:57:02,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:02,084 INFO:     Epoch: 13
2022-11-28 01:57:02,816 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4688275116820668, 'Total loss': 0.4688275116820668} | train loss {'Reaction outcome loss': 0.3548323909950549, 'Total loss': 0.3548323909950549}
2022-11-28 01:57:02,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:02,816 INFO:     Epoch: 14
2022-11-28 01:57:03,548 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46238147796586504, 'Total loss': 0.46238147796586504} | train loss {'Reaction outcome loss': 0.35311209833341056, 'Total loss': 0.35311209833341056}
2022-11-28 01:57:03,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:03,549 INFO:     Epoch: 15
2022-11-28 01:57:04,281 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5221726301797601, 'Total loss': 0.5221726301797601} | train loss {'Reaction outcome loss': 0.35812057304333467, 'Total loss': 0.35812057304333467}
2022-11-28 01:57:04,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:04,281 INFO:     Epoch: 16
2022-11-28 01:57:05,015 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42314796738846355, 'Total loss': 0.42314796738846355} | train loss {'Reaction outcome loss': 0.35582510672021106, 'Total loss': 0.35582510672021106}
2022-11-28 01:57:05,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:05,016 INFO:     Epoch: 17
2022-11-28 01:57:05,748 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4309671247421309, 'Total loss': 0.4309671247421309} | train loss {'Reaction outcome loss': 0.35988584817310826, 'Total loss': 0.35988584817310826}
2022-11-28 01:57:05,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:05,749 INFO:     Epoch: 18
2022-11-28 01:57:06,482 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4873285321302192, 'Total loss': 0.4873285321302192} | train loss {'Reaction outcome loss': 0.3399409606716916, 'Total loss': 0.3399409606716916}
2022-11-28 01:57:06,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:06,482 INFO:     Epoch: 19
2022-11-28 01:57:07,214 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4279309275538422, 'Total loss': 0.4279309275538422} | train loss {'Reaction outcome loss': 0.3517066121528872, 'Total loss': 0.3517066121528872}
2022-11-28 01:57:07,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:07,215 INFO:     Epoch: 20
2022-11-28 01:57:07,949 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4505519010992937, 'Total loss': 0.4505519010992937} | train loss {'Reaction outcome loss': 0.3448690220896826, 'Total loss': 0.3448690220896826}
2022-11-28 01:57:07,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:07,950 INFO:     Epoch: 21
2022-11-28 01:57:08,682 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4158553791254066, 'Total loss': 0.4158553791254066} | train loss {'Reaction outcome loss': 0.3438291536857847, 'Total loss': 0.3438291536857847}
2022-11-28 01:57:08,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:08,683 INFO:     Epoch: 22
2022-11-28 01:57:09,415 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46647060679834945, 'Total loss': 0.46647060679834945} | train loss {'Reaction outcome loss': 0.337098904946422, 'Total loss': 0.337098904946422}
2022-11-28 01:57:09,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:09,415 INFO:     Epoch: 23
2022-11-28 01:57:10,148 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43076229545959205, 'Total loss': 0.43076229545959205} | train loss {'Reaction outcome loss': 0.3464996050127217, 'Total loss': 0.3464996050127217}
2022-11-28 01:57:10,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:10,148 INFO:     Epoch: 24
2022-11-28 01:57:10,880 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4401200964700344, 'Total loss': 0.4401200964700344} | train loss {'Reaction outcome loss': 0.3411986126304894, 'Total loss': 0.3411986126304894}
2022-11-28 01:57:10,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:10,880 INFO:     Epoch: 25
2022-11-28 01:57:11,614 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4206555787214013, 'Total loss': 0.4206555787214013} | train loss {'Reaction outcome loss': 0.33480235827384425, 'Total loss': 0.33480235827384425}
2022-11-28 01:57:11,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:11,614 INFO:     Epoch: 26
2022-11-28 01:57:12,349 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42988821309666303, 'Total loss': 0.42988821309666303} | train loss {'Reaction outcome loss': 0.3323821910947073, 'Total loss': 0.3323821910947073}
2022-11-28 01:57:12,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:12,349 INFO:     Epoch: 27
2022-11-28 01:57:13,082 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41104720532894135, 'Total loss': 0.41104720532894135} | train loss {'Reaction outcome loss': 0.3398421998670111, 'Total loss': 0.3398421998670111}
2022-11-28 01:57:13,082 INFO:     Found new best model at epoch 27
2022-11-28 01:57:13,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:13,083 INFO:     Epoch: 28
2022-11-28 01:57:13,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4134702701554742, 'Total loss': 0.4134702701554742} | train loss {'Reaction outcome loss': 0.3375693202079808, 'Total loss': 0.3375693202079808}
2022-11-28 01:57:13,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:13,816 INFO:     Epoch: 29
2022-11-28 01:57:14,554 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4394933796206186, 'Total loss': 0.4394933796206186} | train loss {'Reaction outcome loss': 0.3375113410111822, 'Total loss': 0.3375113410111822}
2022-11-28 01:57:14,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:14,554 INFO:     Epoch: 30
2022-11-28 01:57:15,285 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4785278144963952, 'Total loss': 0.4785278144963952} | train loss {'Reaction outcome loss': 0.326446487415643, 'Total loss': 0.326446487415643}
2022-11-28 01:57:15,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:15,285 INFO:     Epoch: 31
2022-11-28 01:57:16,021 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4291151058535243, 'Total loss': 0.4291151058535243} | train loss {'Reaction outcome loss': 0.3397713318680886, 'Total loss': 0.3397713318680886}
2022-11-28 01:57:16,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:16,021 INFO:     Epoch: 32
2022-11-28 01:57:16,756 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4451237090451773, 'Total loss': 0.4451237090451773} | train loss {'Reaction outcome loss': 0.3362343052524279, 'Total loss': 0.3362343052524279}
2022-11-28 01:57:16,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:16,756 INFO:     Epoch: 33
2022-11-28 01:57:17,489 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45482789257238077, 'Total loss': 0.45482789257238077} | train loss {'Reaction outcome loss': 0.32986732636440974, 'Total loss': 0.32986732636440974}
2022-11-28 01:57:17,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:17,489 INFO:     Epoch: 34
2022-11-28 01:57:18,223 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.430320646180663, 'Total loss': 0.430320646180663} | train loss {'Reaction outcome loss': 0.32427978039276406, 'Total loss': 0.32427978039276406}
2022-11-28 01:57:18,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:18,224 INFO:     Epoch: 35
2022-11-28 01:57:18,960 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4184819276249686, 'Total loss': 0.4184819276249686} | train loss {'Reaction outcome loss': 0.33791441726879995, 'Total loss': 0.33791441726879995}
2022-11-28 01:57:18,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:18,960 INFO:     Epoch: 36
2022-11-28 01:57:19,694 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4274373647085456, 'Total loss': 0.4274373647085456} | train loss {'Reaction outcome loss': 0.31890694757343313, 'Total loss': 0.31890694757343313}
2022-11-28 01:57:19,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:19,695 INFO:     Epoch: 37
2022-11-28 01:57:20,430 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4471095731092054, 'Total loss': 0.4471095731092054} | train loss {'Reaction outcome loss': 0.3288513847061845, 'Total loss': 0.3288513847061845}
2022-11-28 01:57:20,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:20,430 INFO:     Epoch: 38
2022-11-28 01:57:21,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4449001474435939, 'Total loss': 0.4449001474435939} | train loss {'Reaction outcome loss': 0.33686348808104877, 'Total loss': 0.33686348808104877}
2022-11-28 01:57:21,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:21,165 INFO:     Epoch: 39
2022-11-28 01:57:21,899 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43614566291487494, 'Total loss': 0.43614566291487494} | train loss {'Reaction outcome loss': 0.330451869665355, 'Total loss': 0.330451869665355}
2022-11-28 01:57:21,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:21,899 INFO:     Epoch: 40
2022-11-28 01:57:22,635 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4343432693980461, 'Total loss': 0.4343432693980461} | train loss {'Reaction outcome loss': 0.32435330809628377, 'Total loss': 0.32435330809628377}
2022-11-28 01:57:22,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:22,635 INFO:     Epoch: 41
2022-11-28 01:57:23,370 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4367466191219729, 'Total loss': 0.4367466191219729} | train loss {'Reaction outcome loss': 0.32395359745523966, 'Total loss': 0.32395359745523966}
2022-11-28 01:57:23,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:23,370 INFO:     Epoch: 42
2022-11-28 01:57:24,105 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45805873981741974, 'Total loss': 0.45805873981741974} | train loss {'Reaction outcome loss': 0.3264832755886629, 'Total loss': 0.3264832755886629}
2022-11-28 01:57:24,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:24,105 INFO:     Epoch: 43
2022-11-28 01:57:24,841 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.425326359826465, 'Total loss': 0.425326359826465} | train loss {'Reaction outcome loss': 0.32444737718791744, 'Total loss': 0.32444737718791744}
2022-11-28 01:57:24,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:24,842 INFO:     Epoch: 44
2022-11-28 01:57:25,576 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4247117354426273, 'Total loss': 0.4247117354426273} | train loss {'Reaction outcome loss': 0.3178528034296192, 'Total loss': 0.3178528034296192}
2022-11-28 01:57:25,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:25,576 INFO:     Epoch: 45
2022-11-28 01:57:26,317 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42004218091105305, 'Total loss': 0.42004218091105305} | train loss {'Reaction outcome loss': 0.32191961331934227, 'Total loss': 0.32191961331934227}
2022-11-28 01:57:26,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:26,317 INFO:     Epoch: 46
2022-11-28 01:57:27,058 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.448393295324126, 'Total loss': 0.448393295324126} | train loss {'Reaction outcome loss': 0.3258170018613827, 'Total loss': 0.3258170018613827}
2022-11-28 01:57:27,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:27,058 INFO:     Epoch: 47
2022-11-28 01:57:27,802 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4430016442093738, 'Total loss': 0.4430016442093738} | train loss {'Reaction outcome loss': 0.32118892700212903, 'Total loss': 0.32118892700212903}
2022-11-28 01:57:27,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:27,802 INFO:     Epoch: 48
2022-11-28 01:57:28,545 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43139831513859506, 'Total loss': 0.43139831513859506} | train loss {'Reaction outcome loss': 0.3211122599781537, 'Total loss': 0.3211122599781537}
2022-11-28 01:57:28,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:28,546 INFO:     Epoch: 49
2022-11-28 01:57:29,284 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3865048244248989, 'Total loss': 0.3865048244248989} | train loss {'Reaction outcome loss': 0.3094094266168407, 'Total loss': 0.3094094266168407}
2022-11-28 01:57:29,284 INFO:     Found new best model at epoch 49
2022-11-28 01:57:29,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:29,285 INFO:     Epoch: 50
2022-11-28 01:57:30,028 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4793430109356725, 'Total loss': 0.4793430109356725} | train loss {'Reaction outcome loss': 0.31449395436488214, 'Total loss': 0.31449395436488214}
2022-11-28 01:57:30,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:30,028 INFO:     Epoch: 51
2022-11-28 01:57:30,766 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4393680622411329, 'Total loss': 0.4393680622411329} | train loss {'Reaction outcome loss': 0.3140689959352622, 'Total loss': 0.3140689959352622}
2022-11-28 01:57:30,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:30,766 INFO:     Epoch: 52
2022-11-28 01:57:31,507 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4627483494059984, 'Total loss': 0.4627483494059984} | train loss {'Reaction outcome loss': 0.3108380966071711, 'Total loss': 0.3108380966071711}
2022-11-28 01:57:31,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:31,508 INFO:     Epoch: 53
2022-11-28 01:57:32,249 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40433266031187637, 'Total loss': 0.40433266031187637} | train loss {'Reaction outcome loss': 0.31621687724942066, 'Total loss': 0.31621687724942066}
2022-11-28 01:57:32,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:32,249 INFO:     Epoch: 54
2022-11-28 01:57:32,990 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4128624185226684, 'Total loss': 0.4128624185226684} | train loss {'Reaction outcome loss': 0.3217795945276491, 'Total loss': 0.3217795945276491}
2022-11-28 01:57:32,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:32,991 INFO:     Epoch: 55
2022-11-28 01:57:33,730 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42171116519805996, 'Total loss': 0.42171116519805996} | train loss {'Reaction outcome loss': 0.3225736916675919, 'Total loss': 0.3225736916675919}
2022-11-28 01:57:33,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:33,730 INFO:     Epoch: 56
2022-11-28 01:57:34,470 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4255444178747576, 'Total loss': 0.4255444178747576} | train loss {'Reaction outcome loss': 0.31814374287658537, 'Total loss': 0.31814374287658537}
2022-11-28 01:57:34,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:34,470 INFO:     Epoch: 57
2022-11-28 01:57:35,209 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4313746112030606, 'Total loss': 0.4313746112030606} | train loss {'Reaction outcome loss': 0.3120997298325672, 'Total loss': 0.3120997298325672}
2022-11-28 01:57:35,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:35,209 INFO:     Epoch: 58
2022-11-28 01:57:35,949 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41151409994724186, 'Total loss': 0.41151409994724186} | train loss {'Reaction outcome loss': 0.31434417796916647, 'Total loss': 0.31434417796916647}
2022-11-28 01:57:35,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:35,949 INFO:     Epoch: 59
2022-11-28 01:57:36,690 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.409383395730063, 'Total loss': 0.409383395730063} | train loss {'Reaction outcome loss': 0.3122392004264183, 'Total loss': 0.3122392004264183}
2022-11-28 01:57:36,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:36,691 INFO:     Epoch: 60
2022-11-28 01:57:37,433 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4203236539696538, 'Total loss': 0.4203236539696538} | train loss {'Reaction outcome loss': 0.3084969544691629, 'Total loss': 0.3084969544691629}
2022-11-28 01:57:37,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:37,434 INFO:     Epoch: 61
2022-11-28 01:57:38,174 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4082720297020535, 'Total loss': 0.4082720297020535} | train loss {'Reaction outcome loss': 0.31432837369989175, 'Total loss': 0.31432837369989175}
2022-11-28 01:57:38,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:38,175 INFO:     Epoch: 62
2022-11-28 01:57:38,916 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4223035404155421, 'Total loss': 0.4223035404155421} | train loss {'Reaction outcome loss': 0.3096004813359898, 'Total loss': 0.3096004813359898}
2022-11-28 01:57:38,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:38,917 INFO:     Epoch: 63
2022-11-28 01:57:39,659 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4145502872591795, 'Total loss': 0.4145502872591795} | train loss {'Reaction outcome loss': 0.31809247236271376, 'Total loss': 0.31809247236271376}
2022-11-28 01:57:39,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:39,659 INFO:     Epoch: 64
2022-11-28 01:57:40,400 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41581900175227676, 'Total loss': 0.41581900175227676} | train loss {'Reaction outcome loss': 0.30759723666200384, 'Total loss': 0.30759723666200384}
2022-11-28 01:57:40,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:40,400 INFO:     Epoch: 65
2022-11-28 01:57:41,143 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43421557095161706, 'Total loss': 0.43421557095161706} | train loss {'Reaction outcome loss': 0.30490925505024485, 'Total loss': 0.30490925505024485}
2022-11-28 01:57:41,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:41,143 INFO:     Epoch: 66
2022-11-28 01:57:41,881 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4354881491771964, 'Total loss': 0.4354881491771964} | train loss {'Reaction outcome loss': 0.31604973382515006, 'Total loss': 0.31604973382515006}
2022-11-28 01:57:41,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:41,882 INFO:     Epoch: 67
2022-11-28 01:57:42,622 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42962008437445, 'Total loss': 0.42962008437445} | train loss {'Reaction outcome loss': 0.3173443922681398, 'Total loss': 0.3173443922681398}
2022-11-28 01:57:42,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:42,622 INFO:     Epoch: 68
2022-11-28 01:57:43,362 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46779948472976685, 'Total loss': 0.46779948472976685} | train loss {'Reaction outcome loss': 0.3167065140470618, 'Total loss': 0.3167065140470618}
2022-11-28 01:57:43,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:43,362 INFO:     Epoch: 69
2022-11-28 01:57:44,104 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38741018120632614, 'Total loss': 0.38741018120632614} | train loss {'Reaction outcome loss': 0.30912921985336506, 'Total loss': 0.30912921985336506}
2022-11-28 01:57:44,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:44,104 INFO:     Epoch: 70
2022-11-28 01:57:44,846 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4108320062243661, 'Total loss': 0.4108320062243661} | train loss {'Reaction outcome loss': 0.30750056655436264, 'Total loss': 0.30750056655436264}
2022-11-28 01:57:44,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:44,846 INFO:     Epoch: 71
2022-11-28 01:57:45,587 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46872868960679964, 'Total loss': 0.46872868960679964} | train loss {'Reaction outcome loss': 0.32023518633280623, 'Total loss': 0.32023518633280623}
2022-11-28 01:57:45,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:45,587 INFO:     Epoch: 72
2022-11-28 01:57:46,334 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4418217640283496, 'Total loss': 0.4418217640283496} | train loss {'Reaction outcome loss': 0.3085943840627299, 'Total loss': 0.3085943840627299}
2022-11-28 01:57:46,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:46,334 INFO:     Epoch: 73
2022-11-28 01:57:47,074 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42537879597309025, 'Total loss': 0.42537879597309025} | train loss {'Reaction outcome loss': 0.3113359004014828, 'Total loss': 0.3113359004014828}
2022-11-28 01:57:47,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:47,074 INFO:     Epoch: 74
2022-11-28 01:57:47,816 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4495152567708215, 'Total loss': 0.4495152567708215} | train loss {'Reaction outcome loss': 0.3110166567408281, 'Total loss': 0.3110166567408281}
2022-11-28 01:57:47,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:47,816 INFO:     Epoch: 75
2022-11-28 01:57:48,557 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4114674121834511, 'Total loss': 0.4114674121834511} | train loss {'Reaction outcome loss': 0.3079778453732123, 'Total loss': 0.3079778453732123}
2022-11-28 01:57:48,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:48,557 INFO:     Epoch: 76
2022-11-28 01:57:49,295 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4240061318458513, 'Total loss': 0.4240061318458513} | train loss {'Reaction outcome loss': 0.31599772999399023, 'Total loss': 0.31599772999399023}
2022-11-28 01:57:49,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:49,297 INFO:     Epoch: 77
2022-11-28 01:57:50,036 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.456296356264935, 'Total loss': 0.456296356264935} | train loss {'Reaction outcome loss': 0.3084408148023926, 'Total loss': 0.3084408148023926}
2022-11-28 01:57:50,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:50,036 INFO:     Epoch: 78
2022-11-28 01:57:50,779 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4320586424234302, 'Total loss': 0.4320586424234302} | train loss {'Reaction outcome loss': 0.3108791433824379, 'Total loss': 0.3108791433824379}
2022-11-28 01:57:50,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:50,779 INFO:     Epoch: 79
2022-11-28 01:57:51,517 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41616616831269376, 'Total loss': 0.41616616831269376} | train loss {'Reaction outcome loss': 0.31081695257701347, 'Total loss': 0.31081695257701347}
2022-11-28 01:57:51,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:51,517 INFO:     Epoch: 80
2022-11-28 01:57:52,256 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46380860133226526, 'Total loss': 0.46380860133226526} | train loss {'Reaction outcome loss': 0.30694921352885296, 'Total loss': 0.30694921352885296}
2022-11-28 01:57:52,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:52,257 INFO:     Epoch: 81
2022-11-28 01:57:52,997 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42261732213718944, 'Total loss': 0.42261732213718944} | train loss {'Reaction outcome loss': 0.30916918029428503, 'Total loss': 0.30916918029428503}
2022-11-28 01:57:52,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:52,997 INFO:     Epoch: 82
2022-11-28 01:57:53,739 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45678593045057253, 'Total loss': 0.45678593045057253} | train loss {'Reaction outcome loss': 0.3096975445686305, 'Total loss': 0.3096975445686305}
2022-11-28 01:57:53,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:53,740 INFO:     Epoch: 83
2022-11-28 01:57:54,479 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44357573986053467, 'Total loss': 0.44357573986053467} | train loss {'Reaction outcome loss': 0.3134185288895349, 'Total loss': 0.3134185288895349}
2022-11-28 01:57:54,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:54,479 INFO:     Epoch: 84
2022-11-28 01:57:55,217 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4435265400381975, 'Total loss': 0.4435265400381975} | train loss {'Reaction outcome loss': 0.30377828977147087, 'Total loss': 0.30377828977147087}
2022-11-28 01:57:55,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:55,217 INFO:     Epoch: 85
2022-11-28 01:57:55,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42787668802017387, 'Total loss': 0.42787668802017387} | train loss {'Reaction outcome loss': 0.2957819450310752, 'Total loss': 0.2957819450310752}
2022-11-28 01:57:55,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:55,958 INFO:     Epoch: 86
2022-11-28 01:57:56,700 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43526019814402556, 'Total loss': 0.43526019814402556} | train loss {'Reaction outcome loss': 0.31091553113255344, 'Total loss': 0.31091553113255344}
2022-11-28 01:57:56,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:56,701 INFO:     Epoch: 87
2022-11-28 01:57:57,441 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.438856341464575, 'Total loss': 0.438856341464575} | train loss {'Reaction outcome loss': 0.30545088865595765, 'Total loss': 0.30545088865595765}
2022-11-28 01:57:57,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:57,442 INFO:     Epoch: 88
2022-11-28 01:57:58,180 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4235973193548446, 'Total loss': 0.4235973193548446} | train loss {'Reaction outcome loss': 0.32549496621015617, 'Total loss': 0.32549496621015617}
2022-11-28 01:57:58,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:58,180 INFO:     Epoch: 89
2022-11-28 01:57:58,924 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4234384395355402, 'Total loss': 0.4234384395355402} | train loss {'Reaction outcome loss': 0.2982183153145626, 'Total loss': 0.2982183153145626}
2022-11-28 01:57:58,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:58,924 INFO:     Epoch: 90
2022-11-28 01:57:59,666 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44588211317395055, 'Total loss': 0.44588211317395055} | train loss {'Reaction outcome loss': 0.3046848530438347, 'Total loss': 0.3046848530438347}
2022-11-28 01:57:59,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:57:59,666 INFO:     Epoch: 91
2022-11-28 01:58:00,408 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39679731913777283, 'Total loss': 0.39679731913777283} | train loss {'Reaction outcome loss': 0.3120032195612544, 'Total loss': 0.3120032195612544}
2022-11-28 01:58:00,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:00,409 INFO:     Epoch: 92
2022-11-28 01:58:01,150 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41654762937579043, 'Total loss': 0.41654762937579043} | train loss {'Reaction outcome loss': 0.307193389208224, 'Total loss': 0.307193389208224}
2022-11-28 01:58:01,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:01,150 INFO:     Epoch: 93
2022-11-28 01:58:01,889 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43984971940517426, 'Total loss': 0.43984971940517426} | train loss {'Reaction outcome loss': 0.30571760947159565, 'Total loss': 0.30571760947159565}
2022-11-28 01:58:01,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:01,889 INFO:     Epoch: 94
2022-11-28 01:58:02,633 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42320371436518295, 'Total loss': 0.42320371436518295} | train loss {'Reaction outcome loss': 0.30792929955803955, 'Total loss': 0.30792929955803955}
2022-11-28 01:58:02,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:02,633 INFO:     Epoch: 95
2022-11-28 01:58:03,374 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4217680571384208, 'Total loss': 0.4217680571384208} | train loss {'Reaction outcome loss': 0.3036008961804089, 'Total loss': 0.3036008961804089}
2022-11-28 01:58:03,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:03,374 INFO:     Epoch: 96
2022-11-28 01:58:04,114 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42735053564226905, 'Total loss': 0.42735053564226905} | train loss {'Reaction outcome loss': 0.305324221090948, 'Total loss': 0.305324221090948}
2022-11-28 01:58:04,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:04,115 INFO:     Epoch: 97
2022-11-28 01:58:04,856 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42372503980647686, 'Total loss': 0.42372503980647686} | train loss {'Reaction outcome loss': 0.3079213981867814, 'Total loss': 0.3079213981867814}
2022-11-28 01:58:04,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:04,856 INFO:     Epoch: 98
2022-11-28 01:58:05,599 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44943879458100294, 'Total loss': 0.44943879458100294} | train loss {'Reaction outcome loss': 0.30462396566252237, 'Total loss': 0.30462396566252237}
2022-11-28 01:58:05,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:05,599 INFO:     Epoch: 99
2022-11-28 01:58:06,342 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4135529641495195, 'Total loss': 0.4135529641495195} | train loss {'Reaction outcome loss': 0.29733202571324147, 'Total loss': 0.29733202571324147}
2022-11-28 01:58:06,342 INFO:     Best model found after epoch 50 of 100.
2022-11-28 01:58:06,342 INFO:   Done with stage: TRAINING
2022-11-28 01:58:06,342 INFO:   Starting stage: EVALUATION
2022-11-28 01:58:06,478 INFO:   Done with stage: EVALUATION
2022-11-28 01:58:06,478 INFO:   Leaving out SEQ value Fold_3
2022-11-28 01:58:06,491 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:58:06,491 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:58:07,132 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:58:07,132 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:58:07,200 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:58:07,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:58:07,200 INFO:     No hyperparam tuning for this model
2022-11-28 01:58:07,201 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:58:07,201 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:58:07,201 INFO:     None feature selector for col prot
2022-11-28 01:58:07,201 INFO:     None feature selector for col prot
2022-11-28 01:58:07,202 INFO:     None feature selector for col prot
2022-11-28 01:58:07,202 INFO:     None feature selector for col chem
2022-11-28 01:58:07,202 INFO:     None feature selector for col chem
2022-11-28 01:58:07,202 INFO:     None feature selector for col chem
2022-11-28 01:58:07,202 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:58:07,202 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:58:07,204 INFO:     Number of params in model 169741
2022-11-28 01:58:07,207 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:58:07,207 INFO:   Starting stage: TRAINING
2022-11-28 01:58:07,261 INFO:     Val loss before train {'Reaction outcome loss': 0.9965846728194844, 'Total loss': 0.9965846728194844}
2022-11-28 01:58:07,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:07,261 INFO:     Epoch: 0
2022-11-28 01:58:08,008 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5573938168077306, 'Total loss': 0.5573938168077306} | train loss {'Reaction outcome loss': 0.6549031689458964, 'Total loss': 0.6549031689458964}
2022-11-28 01:58:08,009 INFO:     Found new best model at epoch 0
2022-11-28 01:58:08,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:08,010 INFO:     Epoch: 1
2022-11-28 01:58:08,755 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49443666433746164, 'Total loss': 0.49443666433746164} | train loss {'Reaction outcome loss': 0.5191076254358097, 'Total loss': 0.5191076254358097}
2022-11-28 01:58:08,756 INFO:     Found new best model at epoch 1
2022-11-28 01:58:08,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:08,757 INFO:     Epoch: 2
2022-11-28 01:58:09,499 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49012687463652005, 'Total loss': 0.49012687463652005} | train loss {'Reaction outcome loss': 0.47231674711314997, 'Total loss': 0.47231674711314997}
2022-11-28 01:58:09,499 INFO:     Found new best model at epoch 2
2022-11-28 01:58:09,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:09,500 INFO:     Epoch: 3
2022-11-28 01:58:10,239 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4456976665691896, 'Total loss': 0.4456976665691896} | train loss {'Reaction outcome loss': 0.45170539848658503, 'Total loss': 0.45170539848658503}
2022-11-28 01:58:10,239 INFO:     Found new best model at epoch 3
2022-11-28 01:58:10,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:10,240 INFO:     Epoch: 4
2022-11-28 01:58:10,986 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4503435197878968, 'Total loss': 0.4503435197878968} | train loss {'Reaction outcome loss': 0.42977010510405717, 'Total loss': 0.42977010510405717}
2022-11-28 01:58:10,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:10,987 INFO:     Epoch: 5
2022-11-28 01:58:11,730 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4760991426354105, 'Total loss': 0.4760991426354105} | train loss {'Reaction outcome loss': 0.42477971789788227, 'Total loss': 0.42477971789788227}
2022-11-28 01:58:11,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:11,731 INFO:     Epoch: 6
2022-11-28 01:58:12,479 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46445957300337876, 'Total loss': 0.46445957300337876} | train loss {'Reaction outcome loss': 0.40569683292082376, 'Total loss': 0.40569683292082376}
2022-11-28 01:58:12,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:12,479 INFO:     Epoch: 7
2022-11-28 01:58:13,225 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4331506385721944, 'Total loss': 0.4331506385721944} | train loss {'Reaction outcome loss': 0.40227284775096545, 'Total loss': 0.40227284775096545}
2022-11-28 01:58:13,225 INFO:     Found new best model at epoch 7
2022-11-28 01:58:13,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:13,226 INFO:     Epoch: 8
2022-11-28 01:58:13,969 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45838862555948173, 'Total loss': 0.45838862555948173} | train loss {'Reaction outcome loss': 0.38748851315099364, 'Total loss': 0.38748851315099364}
2022-11-28 01:58:13,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:13,969 INFO:     Epoch: 9
2022-11-28 01:58:14,713 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4394195018844171, 'Total loss': 0.4394195018844171} | train loss {'Reaction outcome loss': 0.38535664026834526, 'Total loss': 0.38535664026834526}
2022-11-28 01:58:14,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:14,713 INFO:     Epoch: 10
2022-11-28 01:58:15,456 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4311134771189906, 'Total loss': 0.4311134771189906} | train loss {'Reaction outcome loss': 0.3828838752544656, 'Total loss': 0.3828838752544656}
2022-11-28 01:58:15,456 INFO:     Found new best model at epoch 10
2022-11-28 01:58:15,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:15,457 INFO:     Epoch: 11
2022-11-28 01:58:16,197 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4834606661037965, 'Total loss': 0.4834606661037965} | train loss {'Reaction outcome loss': 0.37153912560672175, 'Total loss': 0.37153912560672175}
2022-11-28 01:58:16,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:16,198 INFO:     Epoch: 12
2022-11-28 01:58:16,941 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4433103400197896, 'Total loss': 0.4433103400197896} | train loss {'Reaction outcome loss': 0.37390753736301346, 'Total loss': 0.37390753736301346}
2022-11-28 01:58:16,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:16,942 INFO:     Epoch: 13
2022-11-28 01:58:17,687 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4379893019795418, 'Total loss': 0.4379893019795418} | train loss {'Reaction outcome loss': 0.36732193371471095, 'Total loss': 0.36732193371471095}
2022-11-28 01:58:17,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:17,688 INFO:     Epoch: 14
2022-11-28 01:58:18,431 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42751923643729905, 'Total loss': 0.42751923643729905} | train loss {'Reaction outcome loss': 0.36392323855234654, 'Total loss': 0.36392323855234654}
2022-11-28 01:58:18,431 INFO:     Found new best model at epoch 14
2022-11-28 01:58:18,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:18,432 INFO:     Epoch: 15
2022-11-28 01:58:19,174 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4152252145788886, 'Total loss': 0.4152252145788886} | train loss {'Reaction outcome loss': 0.3533702270717037, 'Total loss': 0.3533702270717037}
2022-11-28 01:58:19,174 INFO:     Found new best model at epoch 15
2022-11-28 01:58:19,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:19,175 INFO:     Epoch: 16
2022-11-28 01:58:19,916 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46452777917412197, 'Total loss': 0.46452777917412197} | train loss {'Reaction outcome loss': 0.35684618177462596, 'Total loss': 0.35684618177462596}
2022-11-28 01:58:19,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:19,917 INFO:     Epoch: 17
2022-11-28 01:58:20,662 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4489718787372112, 'Total loss': 0.4489718787372112} | train loss {'Reaction outcome loss': 0.3522482197503654, 'Total loss': 0.3522482197503654}
2022-11-28 01:58:20,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:20,663 INFO:     Epoch: 18
2022-11-28 01:58:21,409 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46061242845925415, 'Total loss': 0.46061242845925415} | train loss {'Reaction outcome loss': 0.35294751518843126, 'Total loss': 0.35294751518843126}
2022-11-28 01:58:21,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:21,410 INFO:     Epoch: 19
2022-11-28 01:58:22,152 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4289839301596988, 'Total loss': 0.4289839301596988} | train loss {'Reaction outcome loss': 0.34672233033545163, 'Total loss': 0.34672233033545163}
2022-11-28 01:58:22,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:22,152 INFO:     Epoch: 20
2022-11-28 01:58:22,894 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47068822468546306, 'Total loss': 0.47068822468546306} | train loss {'Reaction outcome loss': 0.34907287444387164, 'Total loss': 0.34907287444387164}
2022-11-28 01:58:22,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:22,894 INFO:     Epoch: 21
2022-11-28 01:58:23,637 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44605614041740244, 'Total loss': 0.44605614041740244} | train loss {'Reaction outcome loss': 0.3393362152029057, 'Total loss': 0.3393362152029057}
2022-11-28 01:58:23,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:23,638 INFO:     Epoch: 22
2022-11-28 01:58:24,382 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4531928487122059, 'Total loss': 0.4531928487122059} | train loss {'Reaction outcome loss': 0.3409673745534858, 'Total loss': 0.3409673745534858}
2022-11-28 01:58:24,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:24,382 INFO:     Epoch: 23
2022-11-28 01:58:25,122 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40923657115887513, 'Total loss': 0.40923657115887513} | train loss {'Reaction outcome loss': 0.3406276937041964, 'Total loss': 0.3406276937041964}
2022-11-28 01:58:25,122 INFO:     Found new best model at epoch 23
2022-11-28 01:58:25,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:25,123 INFO:     Epoch: 24
2022-11-28 01:58:25,864 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4654873518103903, 'Total loss': 0.4654873518103903} | train loss {'Reaction outcome loss': 0.33559311889872256, 'Total loss': 0.33559311889872256}
2022-11-28 01:58:25,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:25,864 INFO:     Epoch: 25
2022-11-28 01:58:26,606 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46434201435609296, 'Total loss': 0.46434201435609296} | train loss {'Reaction outcome loss': 0.33468591236338324, 'Total loss': 0.33468591236338324}
2022-11-28 01:58:26,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:26,607 INFO:     Epoch: 26
2022-11-28 01:58:27,351 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43932612299580465, 'Total loss': 0.43932612299580465} | train loss {'Reaction outcome loss': 0.33387496772469305, 'Total loss': 0.33387496772469305}
2022-11-28 01:58:27,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:27,352 INFO:     Epoch: 27
2022-11-28 01:58:28,095 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43926674347709527, 'Total loss': 0.43926674347709527} | train loss {'Reaction outcome loss': 0.32487185789006096, 'Total loss': 0.32487185789006096}
2022-11-28 01:58:28,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:28,096 INFO:     Epoch: 28
2022-11-28 01:58:28,838 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.456601430746642, 'Total loss': 0.456601430746642} | train loss {'Reaction outcome loss': 0.32693063762723185, 'Total loss': 0.32693063762723185}
2022-11-28 01:58:28,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:28,839 INFO:     Epoch: 29
2022-11-28 01:58:29,582 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4121889526193792, 'Total loss': 0.4121889526193792} | train loss {'Reaction outcome loss': 0.3287339163678033, 'Total loss': 0.3287339163678033}
2022-11-28 01:58:29,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:29,582 INFO:     Epoch: 30
2022-11-28 01:58:30,324 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4163840287788348, 'Total loss': 0.4163840287788348} | train loss {'Reaction outcome loss': 0.3323820255544721, 'Total loss': 0.3323820255544721}
2022-11-28 01:58:30,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:30,325 INFO:     Epoch: 31
2022-11-28 01:58:31,069 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4253868318416856, 'Total loss': 0.4253868318416856} | train loss {'Reaction outcome loss': 0.3289881007099638, 'Total loss': 0.3289881007099638}
2022-11-28 01:58:31,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:31,069 INFO:     Epoch: 32
2022-11-28 01:58:31,815 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4434424586255442, 'Total loss': 0.4434424586255442} | train loss {'Reaction outcome loss': 0.32205958442420374, 'Total loss': 0.32205958442420374}
2022-11-28 01:58:31,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:31,815 INFO:     Epoch: 33
2022-11-28 01:58:32,563 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44249873371286824, 'Total loss': 0.44249873371286824} | train loss {'Reaction outcome loss': 0.32203477846116435, 'Total loss': 0.32203477846116435}
2022-11-28 01:58:32,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:32,564 INFO:     Epoch: 34
2022-11-28 01:58:33,309 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4367579838091677, 'Total loss': 0.4367579838091677} | train loss {'Reaction outcome loss': 0.3186257545133026, 'Total loss': 0.3186257545133026}
2022-11-28 01:58:33,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:33,309 INFO:     Epoch: 35
2022-11-28 01:58:34,053 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46317930348132824, 'Total loss': 0.46317930348132824} | train loss {'Reaction outcome loss': 0.31992472215574613, 'Total loss': 0.31992472215574613}
2022-11-28 01:58:34,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:34,053 INFO:     Epoch: 36
2022-11-28 01:58:34,796 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43776516802608967, 'Total loss': 0.43776516802608967} | train loss {'Reaction outcome loss': 0.3208191449848973, 'Total loss': 0.3208191449848973}
2022-11-28 01:58:34,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:34,796 INFO:     Epoch: 37
2022-11-28 01:58:35,538 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4173091341826049, 'Total loss': 0.4173091341826049} | train loss {'Reaction outcome loss': 0.3157324689079304, 'Total loss': 0.3157324689079304}
2022-11-28 01:58:35,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:35,538 INFO:     Epoch: 38
2022-11-28 01:58:36,278 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42089352384209633, 'Total loss': 0.42089352384209633} | train loss {'Reaction outcome loss': 0.3121936383600138, 'Total loss': 0.3121936383600138}
2022-11-28 01:58:36,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:36,279 INFO:     Epoch: 39
2022-11-28 01:58:37,018 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44185281612656335, 'Total loss': 0.44185281612656335} | train loss {'Reaction outcome loss': 0.328940318555248, 'Total loss': 0.328940318555248}
2022-11-28 01:58:37,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:37,018 INFO:     Epoch: 40
2022-11-28 01:58:37,762 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4214370877228, 'Total loss': 0.4214370877228} | train loss {'Reaction outcome loss': 0.31419951015589187, 'Total loss': 0.31419951015589187}
2022-11-28 01:58:37,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:37,762 INFO:     Epoch: 41
2022-11-28 01:58:38,504 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42975454608147795, 'Total loss': 0.42975454608147795} | train loss {'Reaction outcome loss': 0.31389474141962675, 'Total loss': 0.31389474141962675}
2022-11-28 01:58:38,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:38,505 INFO:     Epoch: 42
2022-11-28 01:58:39,247 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4541400084060363, 'Total loss': 0.4541400084060363} | train loss {'Reaction outcome loss': 0.32693893073164687, 'Total loss': 0.32693893073164687}
2022-11-28 01:58:39,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:39,248 INFO:     Epoch: 43
2022-11-28 01:58:39,990 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4268395369025794, 'Total loss': 0.4268395369025794} | train loss {'Reaction outcome loss': 0.31476432465168896, 'Total loss': 0.31476432465168896}
2022-11-28 01:58:39,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:39,991 INFO:     Epoch: 44
2022-11-28 01:58:40,734 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43481826172633603, 'Total loss': 0.43481826172633603} | train loss {'Reaction outcome loss': 0.3160669751617373, 'Total loss': 0.3160669751617373}
2022-11-28 01:58:40,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:40,734 INFO:     Epoch: 45
2022-11-28 01:58:41,477 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4586811588907784, 'Total loss': 0.4586811588907784} | train loss {'Reaction outcome loss': 0.31586967797911897, 'Total loss': 0.31586967797911897}
2022-11-28 01:58:41,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:41,477 INFO:     Epoch: 46
2022-11-28 01:58:42,222 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4303114607252858, 'Total loss': 0.4303114607252858} | train loss {'Reaction outcome loss': 0.3177322335997406, 'Total loss': 0.3177322335997406}
2022-11-28 01:58:42,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:42,222 INFO:     Epoch: 47
2022-11-28 01:58:42,965 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4333367036147551, 'Total loss': 0.4333367036147551} | train loss {'Reaction outcome loss': 0.30862975157037076, 'Total loss': 0.30862975157037076}
2022-11-28 01:58:42,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:42,966 INFO:     Epoch: 48
2022-11-28 01:58:43,706 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43513555147431116, 'Total loss': 0.43513555147431116} | train loss {'Reaction outcome loss': 0.3165781017620953, 'Total loss': 0.3165781017620953}
2022-11-28 01:58:43,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:43,707 INFO:     Epoch: 49
2022-11-28 01:58:44,448 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4352889677340334, 'Total loss': 0.4352889677340334} | train loss {'Reaction outcome loss': 0.3173652958200902, 'Total loss': 0.3173652958200902}
2022-11-28 01:58:44,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:44,448 INFO:     Epoch: 50
2022-11-28 01:58:45,192 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4210887514054775, 'Total loss': 0.4210887514054775} | train loss {'Reaction outcome loss': 0.3147821492078353, 'Total loss': 0.3147821492078353}
2022-11-28 01:58:45,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:45,193 INFO:     Epoch: 51
2022-11-28 01:58:45,934 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44933512519029056, 'Total loss': 0.44933512519029056} | train loss {'Reaction outcome loss': 0.30989551953971384, 'Total loss': 0.30989551953971384}
2022-11-28 01:58:45,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:45,935 INFO:     Epoch: 52
2022-11-28 01:58:46,676 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41426090083338996, 'Total loss': 0.41426090083338996} | train loss {'Reaction outcome loss': 0.3215114887879819, 'Total loss': 0.3215114887879819}
2022-11-28 01:58:46,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:46,676 INFO:     Epoch: 53
2022-11-28 01:58:47,418 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4324781031093814, 'Total loss': 0.4324781031093814} | train loss {'Reaction outcome loss': 0.31758190329585756, 'Total loss': 0.31758190329585756}
2022-11-28 01:58:47,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:47,419 INFO:     Epoch: 54
2022-11-28 01:58:48,162 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4124609192155979, 'Total loss': 0.4124609192155979} | train loss {'Reaction outcome loss': 0.3198625186420217, 'Total loss': 0.3198625186420217}
2022-11-28 01:58:48,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:48,162 INFO:     Epoch: 55
2022-11-28 01:58:48,906 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4343830952420831, 'Total loss': 0.4343830952420831} | train loss {'Reaction outcome loss': 0.30812556842456057, 'Total loss': 0.30812556842456057}
2022-11-28 01:58:48,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:48,907 INFO:     Epoch: 56
2022-11-28 01:58:49,653 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4100256322417408, 'Total loss': 0.4100256322417408} | train loss {'Reaction outcome loss': 0.31477312495817944, 'Total loss': 0.31477312495817944}
2022-11-28 01:58:49,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:49,653 INFO:     Epoch: 57
2022-11-28 01:58:50,399 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4142928865145553, 'Total loss': 0.4142928865145553} | train loss {'Reaction outcome loss': 0.3059689850223308, 'Total loss': 0.3059689850223308}
2022-11-28 01:58:50,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:50,399 INFO:     Epoch: 58
2022-11-28 01:58:51,143 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4552190195430409, 'Total loss': 0.4552190195430409} | train loss {'Reaction outcome loss': 0.3048637333269022, 'Total loss': 0.3048637333269022}
2022-11-28 01:58:51,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:51,143 INFO:     Epoch: 59
2022-11-28 01:58:51,891 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43174291478300636, 'Total loss': 0.43174291478300636} | train loss {'Reaction outcome loss': 0.31404615473382325, 'Total loss': 0.31404615473382325}
2022-11-28 01:58:51,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:51,892 INFO:     Epoch: 60
2022-11-28 01:58:52,637 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43732320043173706, 'Total loss': 0.43732320043173706} | train loss {'Reaction outcome loss': 0.31214148216709797, 'Total loss': 0.31214148216709797}
2022-11-28 01:58:52,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:52,638 INFO:     Epoch: 61
2022-11-28 01:58:53,379 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42290473204444756, 'Total loss': 0.42290473204444756} | train loss {'Reaction outcome loss': 0.30624385105103863, 'Total loss': 0.30624385105103863}
2022-11-28 01:58:53,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:53,380 INFO:     Epoch: 62
2022-11-28 01:58:54,121 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4244142808020115, 'Total loss': 0.4244142808020115} | train loss {'Reaction outcome loss': 0.3044779945392998, 'Total loss': 0.3044779945392998}
2022-11-28 01:58:54,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:54,121 INFO:     Epoch: 63
2022-11-28 01:58:54,865 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4316428757526658, 'Total loss': 0.4316428757526658} | train loss {'Reaction outcome loss': 0.3122564892379605, 'Total loss': 0.3122564892379605}
2022-11-28 01:58:54,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:54,865 INFO:     Epoch: 64
2022-11-28 01:58:55,610 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4686153625900095, 'Total loss': 0.4686153625900095} | train loss {'Reaction outcome loss': 0.31202725540010295, 'Total loss': 0.31202725540010295}
2022-11-28 01:58:55,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:55,610 INFO:     Epoch: 65
2022-11-28 01:58:56,352 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43815442987463693, 'Total loss': 0.43815442987463693} | train loss {'Reaction outcome loss': 0.31240852478207376, 'Total loss': 0.31240852478207376}
2022-11-28 01:58:56,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:56,353 INFO:     Epoch: 66
2022-11-28 01:58:57,097 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42698039808733895, 'Total loss': 0.42698039808733895} | train loss {'Reaction outcome loss': 0.3019003687768566, 'Total loss': 0.3019003687768566}
2022-11-28 01:58:57,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:57,098 INFO:     Epoch: 67
2022-11-28 01:58:57,840 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44165312160145154, 'Total loss': 0.44165312160145154} | train loss {'Reaction outcome loss': 0.3076726123690605, 'Total loss': 0.3076726123690605}
2022-11-28 01:58:57,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:57,841 INFO:     Epoch: 68
2022-11-28 01:58:58,584 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42448641563003714, 'Total loss': 0.42448641563003714} | train loss {'Reaction outcome loss': 0.3043625253803876, 'Total loss': 0.3043625253803876}
2022-11-28 01:58:58,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:58,585 INFO:     Epoch: 69
2022-11-28 01:58:59,324 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42237846350128, 'Total loss': 0.42237846350128} | train loss {'Reaction outcome loss': 0.3042686209994919, 'Total loss': 0.3042686209994919}
2022-11-28 01:58:59,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:58:59,324 INFO:     Epoch: 70
2022-11-28 01:59:00,066 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4283412782983346, 'Total loss': 0.4283412782983346} | train loss {'Reaction outcome loss': 0.31482515231687197, 'Total loss': 0.31482515231687197}
2022-11-28 01:59:00,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:00,067 INFO:     Epoch: 71
2022-11-28 01:59:00,814 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42408367178656836, 'Total loss': 0.42408367178656836} | train loss {'Reaction outcome loss': 0.30514944206391065, 'Total loss': 0.30514944206391065}
2022-11-28 01:59:00,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:00,815 INFO:     Epoch: 72
2022-11-28 01:59:01,558 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44277540187944064, 'Total loss': 0.44277540187944064} | train loss {'Reaction outcome loss': 0.3025665223294375, 'Total loss': 0.3025665223294375}
2022-11-28 01:59:01,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:01,558 INFO:     Epoch: 73
2022-11-28 01:59:02,302 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4312962860884992, 'Total loss': 0.4312962860884992} | train loss {'Reaction outcome loss': 0.30813505620676646, 'Total loss': 0.30813505620676646}
2022-11-28 01:59:02,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:02,302 INFO:     Epoch: 74
2022-11-28 01:59:03,043 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43640408089215105, 'Total loss': 0.43640408089215105} | train loss {'Reaction outcome loss': 0.3023690825974455, 'Total loss': 0.3023690825974455}
2022-11-28 01:59:03,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:03,044 INFO:     Epoch: 75
2022-11-28 01:59:03,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41823456893590366, 'Total loss': 0.41823456893590366} | train loss {'Reaction outcome loss': 0.3107149153643725, 'Total loss': 0.3107149153643725}
2022-11-28 01:59:03,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:03,789 INFO:     Epoch: 76
2022-11-28 01:59:04,533 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4363156431777911, 'Total loss': 0.4363156431777911} | train loss {'Reaction outcome loss': 0.30604605991013195, 'Total loss': 0.30604605991013195}
2022-11-28 01:59:04,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:04,533 INFO:     Epoch: 77
2022-11-28 01:59:05,275 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4357742629945278, 'Total loss': 0.4357742629945278} | train loss {'Reaction outcome loss': 0.3197782069140551, 'Total loss': 0.3197782069140551}
2022-11-28 01:59:05,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:05,275 INFO:     Epoch: 78
2022-11-28 01:59:06,017 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43517600728029554, 'Total loss': 0.43517600728029554} | train loss {'Reaction outcome loss': 0.30622940007217075, 'Total loss': 0.30622940007217075}
2022-11-28 01:59:06,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:06,017 INFO:     Epoch: 79
2022-11-28 01:59:06,759 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40355955669656396, 'Total loss': 0.40355955669656396} | train loss {'Reaction outcome loss': 0.3164063044044436, 'Total loss': 0.3164063044044436}
2022-11-28 01:59:06,759 INFO:     Found new best model at epoch 79
2022-11-28 01:59:06,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:06,760 INFO:     Epoch: 80
2022-11-28 01:59:07,500 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43810694698582997, 'Total loss': 0.43810694698582997} | train loss {'Reaction outcome loss': 0.30006787059258444, 'Total loss': 0.30006787059258444}
2022-11-28 01:59:07,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:07,501 INFO:     Epoch: 81
2022-11-28 01:59:08,242 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4166186743161895, 'Total loss': 0.4166186743161895} | train loss {'Reaction outcome loss': 0.3158713749780947, 'Total loss': 0.3158713749780947}
2022-11-28 01:59:08,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:08,243 INFO:     Epoch: 82
2022-11-28 01:59:08,983 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4133102903989228, 'Total loss': 0.4133102903989228} | train loss {'Reaction outcome loss': 0.3035694163368673, 'Total loss': 0.3035694163368673}
2022-11-28 01:59:08,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:08,983 INFO:     Epoch: 83
2022-11-28 01:59:09,725 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46415056085044687, 'Total loss': 0.46415056085044687} | train loss {'Reaction outcome loss': 0.3150604117281583, 'Total loss': 0.3150604117281583}
2022-11-28 01:59:09,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:09,725 INFO:     Epoch: 84
2022-11-28 01:59:10,468 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45641375942663714, 'Total loss': 0.45641375942663714} | train loss {'Reaction outcome loss': 0.31081294943483506, 'Total loss': 0.31081294943483506}
2022-11-28 01:59:10,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:10,468 INFO:     Epoch: 85
2022-11-28 01:59:11,209 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4298010075634176, 'Total loss': 0.4298010075634176} | train loss {'Reaction outcome loss': 0.3072722765560053, 'Total loss': 0.3072722765560053}
2022-11-28 01:59:11,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:11,210 INFO:     Epoch: 86
2022-11-28 01:59:11,951 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43091564693234186, 'Total loss': 0.43091564693234186} | train loss {'Reaction outcome loss': 0.3172484101993697, 'Total loss': 0.3172484101993697}
2022-11-28 01:59:11,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:11,951 INFO:     Epoch: 87
2022-11-28 01:59:12,695 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4172373048283837, 'Total loss': 0.4172373048283837} | train loss {'Reaction outcome loss': 0.30362476834229063, 'Total loss': 0.30362476834229063}
2022-11-28 01:59:12,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:12,695 INFO:     Epoch: 88
2022-11-28 01:59:13,441 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4228613454933194, 'Total loss': 0.4228613454933194} | train loss {'Reaction outcome loss': 0.3093980360396054, 'Total loss': 0.3093980360396054}
2022-11-28 01:59:13,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:13,441 INFO:     Epoch: 89
2022-11-28 01:59:14,182 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4383691403676163, 'Total loss': 0.4383691403676163} | train loss {'Reaction outcome loss': 0.3023886055666573, 'Total loss': 0.3023886055666573}
2022-11-28 01:59:14,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:14,183 INFO:     Epoch: 90
2022-11-28 01:59:14,925 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46038843623616477, 'Total loss': 0.46038843623616477} | train loss {'Reaction outcome loss': 0.31607225783625426, 'Total loss': 0.31607225783625426}
2022-11-28 01:59:14,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:14,926 INFO:     Epoch: 91
2022-11-28 01:59:15,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4390313836999915, 'Total loss': 0.4390313836999915} | train loss {'Reaction outcome loss': 0.29525933843486163, 'Total loss': 0.29525933843486163}
2022-11-28 01:59:15,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:15,667 INFO:     Epoch: 92
2022-11-28 01:59:16,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4412163123488426, 'Total loss': 0.4412163123488426} | train loss {'Reaction outcome loss': 0.3085934659200055, 'Total loss': 0.3085934659200055}
2022-11-28 01:59:16,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:16,410 INFO:     Epoch: 93
2022-11-28 01:59:17,152 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40993212400512263, 'Total loss': 0.40993212400512263} | train loss {'Reaction outcome loss': 0.31111138426527685, 'Total loss': 0.31111138426527685}
2022-11-28 01:59:17,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:17,152 INFO:     Epoch: 94
2022-11-28 01:59:17,896 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4459962858395143, 'Total loss': 0.4459962858395143} | train loss {'Reaction outcome loss': 0.2929399072211616, 'Total loss': 0.2929399072211616}
2022-11-28 01:59:17,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:17,897 INFO:     Epoch: 95
2022-11-28 01:59:18,638 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4136438639940355, 'Total loss': 0.4136438639940355} | train loss {'Reaction outcome loss': 0.30630104192057434, 'Total loss': 0.30630104192057434}
2022-11-28 01:59:18,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:18,638 INFO:     Epoch: 96
2022-11-28 01:59:19,384 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43787880817597563, 'Total loss': 0.43787880817597563} | train loss {'Reaction outcome loss': 0.3132249413096175, 'Total loss': 0.3132249413096175}
2022-11-28 01:59:19,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:19,384 INFO:     Epoch: 97
2022-11-28 01:59:20,127 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4208249690180475, 'Total loss': 0.4208249690180475} | train loss {'Reaction outcome loss': 0.304091544540561, 'Total loss': 0.304091544540561}
2022-11-28 01:59:20,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:20,127 INFO:     Epoch: 98
2022-11-28 01:59:20,870 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48966482146219775, 'Total loss': 0.48966482146219775} | train loss {'Reaction outcome loss': 0.3057967373911215, 'Total loss': 0.3057967373911215}
2022-11-28 01:59:20,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:20,871 INFO:     Epoch: 99
2022-11-28 01:59:21,614 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4302692403170196, 'Total loss': 0.4302692403170196} | train loss {'Reaction outcome loss': 0.3069529336630082, 'Total loss': 0.3069529336630082}
2022-11-28 01:59:21,614 INFO:     Best model found after epoch 80 of 100.
2022-11-28 01:59:21,614 INFO:   Done with stage: TRAINING
2022-11-28 01:59:21,614 INFO:   Starting stage: EVALUATION
2022-11-28 01:59:21,743 INFO:   Done with stage: EVALUATION
2022-11-28 01:59:21,744 INFO:   Leaving out SEQ value Fold_4
2022-11-28 01:59:21,756 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:59:21,756 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:59:22,398 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:59:22,398 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:59:22,467 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:59:22,467 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:59:22,467 INFO:     No hyperparam tuning for this model
2022-11-28 01:59:22,467 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:59:22,467 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:59:22,468 INFO:     None feature selector for col prot
2022-11-28 01:59:22,468 INFO:     None feature selector for col prot
2022-11-28 01:59:22,468 INFO:     None feature selector for col prot
2022-11-28 01:59:22,469 INFO:     None feature selector for col chem
2022-11-28 01:59:22,469 INFO:     None feature selector for col chem
2022-11-28 01:59:22,469 INFO:     None feature selector for col chem
2022-11-28 01:59:22,469 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:59:22,469 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:59:22,470 INFO:     Number of params in model 169741
2022-11-28 01:59:22,473 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:59:22,473 INFO:   Starting stage: TRAINING
2022-11-28 01:59:22,527 INFO:     Val loss before train {'Reaction outcome loss': 1.0257094028321179, 'Total loss': 1.0257094028321179}
2022-11-28 01:59:22,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:22,527 INFO:     Epoch: 0
2022-11-28 01:59:23,272 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5551361035216938, 'Total loss': 0.5551361035216938} | train loss {'Reaction outcome loss': 0.6483601065661743, 'Total loss': 0.6483601065661743}
2022-11-28 01:59:23,273 INFO:     Found new best model at epoch 0
2022-11-28 01:59:23,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:23,274 INFO:     Epoch: 1
2022-11-28 01:59:24,021 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49123667790131137, 'Total loss': 0.49123667790131137} | train loss {'Reaction outcome loss': 0.5134533263162261, 'Total loss': 0.5134533263162261}
2022-11-28 01:59:24,021 INFO:     Found new best model at epoch 1
2022-11-28 01:59:24,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:24,022 INFO:     Epoch: 2
2022-11-28 01:59:24,771 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4785058420490135, 'Total loss': 0.4785058420490135} | train loss {'Reaction outcome loss': 0.4684088679581036, 'Total loss': 0.4684088679581036}
2022-11-28 01:59:24,771 INFO:     Found new best model at epoch 2
2022-11-28 01:59:24,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:24,772 INFO:     Epoch: 3
2022-11-28 01:59:25,515 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5230901376767592, 'Total loss': 0.5230901376767592} | train loss {'Reaction outcome loss': 0.4605807614350608, 'Total loss': 0.4605807614350608}
2022-11-28 01:59:25,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:25,515 INFO:     Epoch: 4
2022-11-28 01:59:26,263 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45235237072814594, 'Total loss': 0.45235237072814594} | train loss {'Reaction outcome loss': 0.4415891766548157, 'Total loss': 0.4415891766548157}
2022-11-28 01:59:26,263 INFO:     Found new best model at epoch 4
2022-11-28 01:59:26,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:26,264 INFO:     Epoch: 5
2022-11-28 01:59:27,012 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45729060826653783, 'Total loss': 0.45729060826653783} | train loss {'Reaction outcome loss': 0.4283505798834056, 'Total loss': 0.4283505798834056}
2022-11-28 01:59:27,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:27,012 INFO:     Epoch: 6
2022-11-28 01:59:27,761 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4510973769832741, 'Total loss': 0.4510973769832741} | train loss {'Reaction outcome loss': 0.4146130822659263, 'Total loss': 0.4146130822659263}
2022-11-28 01:59:27,762 INFO:     Found new best model at epoch 6
2022-11-28 01:59:27,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:27,762 INFO:     Epoch: 7
2022-11-28 01:59:28,510 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44463667408986524, 'Total loss': 0.44463667408986524} | train loss {'Reaction outcome loss': 0.4017083780304623, 'Total loss': 0.4017083780304623}
2022-11-28 01:59:28,510 INFO:     Found new best model at epoch 7
2022-11-28 01:59:28,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:28,511 INFO:     Epoch: 8
2022-11-28 01:59:29,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5047356940128587, 'Total loss': 0.5047356940128587} | train loss {'Reaction outcome loss': 0.4095307814507832, 'Total loss': 0.4095307814507832}
2022-11-28 01:59:29,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:29,260 INFO:     Epoch: 9
2022-11-28 01:59:30,008 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42241826314817776, 'Total loss': 0.42241826314817776} | train loss {'Reaction outcome loss': 0.4020820001841557, 'Total loss': 0.4020820001841557}
2022-11-28 01:59:30,009 INFO:     Found new best model at epoch 9
2022-11-28 01:59:30,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:30,010 INFO:     Epoch: 10
2022-11-28 01:59:30,758 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.437929823317311, 'Total loss': 0.437929823317311} | train loss {'Reaction outcome loss': 0.40401167627650236, 'Total loss': 0.40401167627650236}
2022-11-28 01:59:30,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:30,758 INFO:     Epoch: 11
2022-11-28 01:59:31,503 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4244037348438393, 'Total loss': 0.4244037348438393} | train loss {'Reaction outcome loss': 0.3896303955420309, 'Total loss': 0.3896303955420309}
2022-11-28 01:59:31,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:31,504 INFO:     Epoch: 12
2022-11-28 01:59:32,249 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45326975191181357, 'Total loss': 0.45326975191181357} | train loss {'Reaction outcome loss': 0.38144356341135166, 'Total loss': 0.38144356341135166}
2022-11-28 01:59:32,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:32,249 INFO:     Epoch: 13
2022-11-28 01:59:32,997 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4123292365534739, 'Total loss': 0.4123292365534739} | train loss {'Reaction outcome loss': 0.3815942451900799, 'Total loss': 0.3815942451900799}
2022-11-28 01:59:32,997 INFO:     Found new best model at epoch 13
2022-11-28 01:59:32,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:32,998 INFO:     Epoch: 14
2022-11-28 01:59:33,744 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4380218142812902, 'Total loss': 0.4380218142812902} | train loss {'Reaction outcome loss': 0.38550452577319705, 'Total loss': 0.38550452577319705}
2022-11-28 01:59:33,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:33,745 INFO:     Epoch: 15
2022-11-28 01:59:34,492 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4561101150783626, 'Total loss': 0.4561101150783626} | train loss {'Reaction outcome loss': 0.3773520657347764, 'Total loss': 0.3773520657347764}
2022-11-28 01:59:34,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:34,493 INFO:     Epoch: 16
2022-11-28 01:59:35,239 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4638748209584843, 'Total loss': 0.4638748209584843} | train loss {'Reaction outcome loss': 0.3778745137486863, 'Total loss': 0.3778745137486863}
2022-11-28 01:59:35,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:35,239 INFO:     Epoch: 17
2022-11-28 01:59:35,985 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48815078085119074, 'Total loss': 0.48815078085119074} | train loss {'Reaction outcome loss': 0.37657761151491387, 'Total loss': 0.37657761151491387}
2022-11-28 01:59:35,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:35,985 INFO:     Epoch: 18
2022-11-28 01:59:36,733 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42364617640321905, 'Total loss': 0.42364617640321905} | train loss {'Reaction outcome loss': 0.382818699742739, 'Total loss': 0.382818699742739}
2022-11-28 01:59:36,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:36,733 INFO:     Epoch: 19
2022-11-28 01:59:37,484 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4135234294967218, 'Total loss': 0.4135234294967218} | train loss {'Reaction outcome loss': 0.3655585658996694, 'Total loss': 0.3655585658996694}
2022-11-28 01:59:37,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:37,485 INFO:     Epoch: 20
2022-11-28 01:59:38,233 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42335783995010634, 'Total loss': 0.42335783995010634} | train loss {'Reaction outcome loss': 0.36728885217837476, 'Total loss': 0.36728885217837476}
2022-11-28 01:59:38,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:38,234 INFO:     Epoch: 21
2022-11-28 01:59:38,984 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42575501345775346, 'Total loss': 0.42575501345775346} | train loss {'Reaction outcome loss': 0.3566188322161494, 'Total loss': 0.3566188322161494}
2022-11-28 01:59:38,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:38,984 INFO:     Epoch: 22
2022-11-28 01:59:39,731 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4178252992304889, 'Total loss': 0.4178252992304889} | train loss {'Reaction outcome loss': 0.3647312667326406, 'Total loss': 0.3647312667326406}
2022-11-28 01:59:39,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:39,731 INFO:     Epoch: 23
2022-11-28 01:59:40,478 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42126271704381163, 'Total loss': 0.42126271704381163} | train loss {'Reaction outcome loss': 0.3637738648937781, 'Total loss': 0.3637738648937781}
2022-11-28 01:59:40,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:40,479 INFO:     Epoch: 24
2022-11-28 01:59:41,227 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4110893112691966, 'Total loss': 0.4110893112691966} | train loss {'Reaction outcome loss': 0.35732737702396716, 'Total loss': 0.35732737702396716}
2022-11-28 01:59:41,227 INFO:     Found new best model at epoch 24
2022-11-28 01:59:41,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:41,228 INFO:     Epoch: 25
2022-11-28 01:59:41,976 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4280152808536183, 'Total loss': 0.4280152808536183} | train loss {'Reaction outcome loss': 0.3610049101263888, 'Total loss': 0.3610049101263888}
2022-11-28 01:59:41,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:41,977 INFO:     Epoch: 26
2022-11-28 01:59:42,723 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44882538508285175, 'Total loss': 0.44882538508285175} | train loss {'Reaction outcome loss': 0.35651063671720173, 'Total loss': 0.35651063671720173}
2022-11-28 01:59:42,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:42,724 INFO:     Epoch: 27
2022-11-28 01:59:43,468 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4139915159480138, 'Total loss': 0.4139915159480138} | train loss {'Reaction outcome loss': 0.3638707003914393, 'Total loss': 0.3638707003914393}
2022-11-28 01:59:43,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:43,468 INFO:     Epoch: 28
2022-11-28 01:59:44,213 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43762968480587006, 'Total loss': 0.43762968480587006} | train loss {'Reaction outcome loss': 0.37461029514972016, 'Total loss': 0.37461029514972016}
2022-11-28 01:59:44,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:44,213 INFO:     Epoch: 29
2022-11-28 01:59:44,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42312845604663546, 'Total loss': 0.42312845604663546} | train loss {'Reaction outcome loss': 0.35640725257042005, 'Total loss': 0.35640725257042005}
2022-11-28 01:59:44,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:44,963 INFO:     Epoch: 30
2022-11-28 01:59:45,709 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41348020427606325, 'Total loss': 0.41348020427606325} | train loss {'Reaction outcome loss': 0.35218588025488246, 'Total loss': 0.35218588025488246}
2022-11-28 01:59:45,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:45,709 INFO:     Epoch: 31
2022-11-28 01:59:46,454 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45168397982012143, 'Total loss': 0.45168397982012143} | train loss {'Reaction outcome loss': 0.35003711545636296, 'Total loss': 0.35003711545636296}
2022-11-28 01:59:46,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:46,454 INFO:     Epoch: 32
2022-11-28 01:59:47,201 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4227688851004297, 'Total loss': 0.4227688851004297} | train loss {'Reaction outcome loss': 0.34861440115798215, 'Total loss': 0.34861440115798215}
2022-11-28 01:59:47,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:47,202 INFO:     Epoch: 33
2022-11-28 01:59:47,946 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4372673671353947, 'Total loss': 0.4372673671353947} | train loss {'Reaction outcome loss': 0.34313550353925, 'Total loss': 0.34313550353925}
2022-11-28 01:59:47,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:47,947 INFO:     Epoch: 34
2022-11-28 01:59:48,691 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4399299848486077, 'Total loss': 0.4399299848486077} | train loss {'Reaction outcome loss': 0.3411005141914856, 'Total loss': 0.3411005141914856}
2022-11-28 01:59:48,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:48,692 INFO:     Epoch: 35
2022-11-28 01:59:49,438 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4444170384244485, 'Total loss': 0.4444170384244485} | train loss {'Reaction outcome loss': 0.34639739555868543, 'Total loss': 0.34639739555868543}
2022-11-28 01:59:49,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:49,438 INFO:     Epoch: 36
2022-11-28 01:59:50,187 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4493858329951763, 'Total loss': 0.4493858329951763} | train loss {'Reaction outcome loss': 0.3457495196070145, 'Total loss': 0.3457495196070145}
2022-11-28 01:59:50,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:50,187 INFO:     Epoch: 37
2022-11-28 01:59:50,934 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40887951071966777, 'Total loss': 0.40887951071966777} | train loss {'Reaction outcome loss': 0.34136345976518717, 'Total loss': 0.34136345976518717}
2022-11-28 01:59:50,934 INFO:     Found new best model at epoch 37
2022-11-28 01:59:50,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:50,935 INFO:     Epoch: 38
2022-11-28 01:59:51,681 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4214252816005187, 'Total loss': 0.4214252816005187} | train loss {'Reaction outcome loss': 0.3500869423754302, 'Total loss': 0.3500869423754302}
2022-11-28 01:59:51,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:51,681 INFO:     Epoch: 39
2022-11-28 01:59:52,429 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42324767769737676, 'Total loss': 0.42324767769737676} | train loss {'Reaction outcome loss': 0.3542972306611567, 'Total loss': 0.3542972306611567}
2022-11-28 01:59:52,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:52,429 INFO:     Epoch: 40
2022-11-28 01:59:53,179 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4156761352311481, 'Total loss': 0.4156761352311481} | train loss {'Reaction outcome loss': 0.3540498606468502, 'Total loss': 0.3540498606468502}
2022-11-28 01:59:53,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:53,179 INFO:     Epoch: 41
2022-11-28 01:59:53,926 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44789497689767316, 'Total loss': 0.44789497689767316} | train loss {'Reaction outcome loss': 0.3469727743070135, 'Total loss': 0.3469727743070135}
2022-11-28 01:59:53,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:53,927 INFO:     Epoch: 42
2022-11-28 01:59:54,676 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40310762263834476, 'Total loss': 0.40310762263834476} | train loss {'Reaction outcome loss': 0.34688485084998943, 'Total loss': 0.34688485084998943}
2022-11-28 01:59:54,676 INFO:     Found new best model at epoch 42
2022-11-28 01:59:54,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:54,677 INFO:     Epoch: 43
2022-11-28 01:59:55,423 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40201597491448576, 'Total loss': 0.40201597491448576} | train loss {'Reaction outcome loss': 0.34130282117890925, 'Total loss': 0.34130282117890925}
2022-11-28 01:59:55,423 INFO:     Found new best model at epoch 43
2022-11-28 01:59:55,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:55,424 INFO:     Epoch: 44
2022-11-28 01:59:56,173 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4071622622961348, 'Total loss': 0.4071622622961348} | train loss {'Reaction outcome loss': 0.37246435409720974, 'Total loss': 0.37246435409720974}
2022-11-28 01:59:56,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:56,173 INFO:     Epoch: 45
2022-11-28 01:59:56,925 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39889599454843183, 'Total loss': 0.39889599454843183} | train loss {'Reaction outcome loss': 0.34339995895651915, 'Total loss': 0.34339995895651915}
2022-11-28 01:59:56,925 INFO:     Found new best model at epoch 45
2022-11-28 01:59:56,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:56,926 INFO:     Epoch: 46
2022-11-28 01:59:57,673 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4351581087843938, 'Total loss': 0.4351581087843938} | train loss {'Reaction outcome loss': 0.33737159181039345, 'Total loss': 0.33737159181039345}
2022-11-28 01:59:57,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:57,673 INFO:     Epoch: 47
2022-11-28 01:59:58,421 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3950926463373683, 'Total loss': 0.3950926463373683} | train loss {'Reaction outcome loss': 0.33143732389095826, 'Total loss': 0.33143732389095826}
2022-11-28 01:59:58,421 INFO:     Found new best model at epoch 47
2022-11-28 01:59:58,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:58,422 INFO:     Epoch: 48
2022-11-28 01:59:59,170 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4289320175620643, 'Total loss': 0.4289320175620643} | train loss {'Reaction outcome loss': 0.3338934066988196, 'Total loss': 0.3338934066988196}
2022-11-28 01:59:59,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:59,171 INFO:     Epoch: 49
2022-11-28 01:59:59,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.417361434887756, 'Total loss': 0.417361434887756} | train loss {'Reaction outcome loss': 0.34354618627121786, 'Total loss': 0.34354618627121786}
2022-11-28 01:59:59,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:59:59,915 INFO:     Epoch: 50
2022-11-28 02:00:00,662 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39985328167676926, 'Total loss': 0.39985328167676926} | train loss {'Reaction outcome loss': 0.33099678355540846, 'Total loss': 0.33099678355540846}
2022-11-28 02:00:00,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:00,663 INFO:     Epoch: 51
2022-11-28 02:00:01,411 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40929432213306427, 'Total loss': 0.40929432213306427} | train loss {'Reaction outcome loss': 0.33763302294047254, 'Total loss': 0.33763302294047254}
2022-11-28 02:00:01,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:01,411 INFO:     Epoch: 52
2022-11-28 02:00:02,161 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41471326571296563, 'Total loss': 0.41471326571296563} | train loss {'Reaction outcome loss': 0.33736013669354714, 'Total loss': 0.33736013669354714}
2022-11-28 02:00:02,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:02,161 INFO:     Epoch: 53
2022-11-28 02:00:02,907 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40058803727680986, 'Total loss': 0.40058803727680986} | train loss {'Reaction outcome loss': 0.33402710458886364, 'Total loss': 0.33402710458886364}
2022-11-28 02:00:02,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:02,907 INFO:     Epoch: 54
2022-11-28 02:00:03,654 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4135389802130786, 'Total loss': 0.4135389802130786} | train loss {'Reaction outcome loss': 0.33749561174678416, 'Total loss': 0.33749561174678416}
2022-11-28 02:00:03,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:03,655 INFO:     Epoch: 55
2022-11-28 02:00:04,401 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4166458274491809, 'Total loss': 0.4166458274491809} | train loss {'Reaction outcome loss': 0.33623459386198146, 'Total loss': 0.33623459386198146}
2022-11-28 02:00:04,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:04,401 INFO:     Epoch: 56
2022-11-28 02:00:05,149 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42257594351064076, 'Total loss': 0.42257594351064076} | train loss {'Reaction outcome loss': 0.35520366055755176, 'Total loss': 0.35520366055755176}
2022-11-28 02:00:05,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:05,149 INFO:     Epoch: 57
2022-11-28 02:00:05,898 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39019669423049147, 'Total loss': 0.39019669423049147} | train loss {'Reaction outcome loss': 0.3281864713017757, 'Total loss': 0.3281864713017757}
2022-11-28 02:00:05,898 INFO:     Found new best model at epoch 57
2022-11-28 02:00:05,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:05,899 INFO:     Epoch: 58
2022-11-28 02:00:06,643 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49543864923444664, 'Total loss': 0.49543864923444664} | train loss {'Reaction outcome loss': 0.3428724974936802, 'Total loss': 0.3428724974936802}
2022-11-28 02:00:06,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:06,643 INFO:     Epoch: 59
2022-11-28 02:00:07,389 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37535171007568185, 'Total loss': 0.37535171007568185} | train loss {'Reaction outcome loss': 0.34662002733784164, 'Total loss': 0.34662002733784164}
2022-11-28 02:00:07,389 INFO:     Found new best model at epoch 59
2022-11-28 02:00:07,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:07,390 INFO:     Epoch: 60
2022-11-28 02:00:08,135 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39923584359613334, 'Total loss': 0.39923584359613334} | train loss {'Reaction outcome loss': 0.3276090839395096, 'Total loss': 0.3276090839395096}
2022-11-28 02:00:08,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:08,136 INFO:     Epoch: 61
2022-11-28 02:00:08,882 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3906059569933198, 'Total loss': 0.3906059569933198} | train loss {'Reaction outcome loss': 0.32502789184171144, 'Total loss': 0.32502789184171144}
2022-11-28 02:00:08,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:08,883 INFO:     Epoch: 62
2022-11-28 02:00:09,629 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42836580019105563, 'Total loss': 0.42836580019105563} | train loss {'Reaction outcome loss': 0.32660636200233994, 'Total loss': 0.32660636200233994}
2022-11-28 02:00:09,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:09,629 INFO:     Epoch: 63
2022-11-28 02:00:10,378 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41517983546311205, 'Total loss': 0.41517983546311205} | train loss {'Reaction outcome loss': 0.3325535311601181, 'Total loss': 0.3325535311601181}
2022-11-28 02:00:10,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:10,378 INFO:     Epoch: 64
2022-11-28 02:00:11,124 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4092503074895252, 'Total loss': 0.4092503074895252} | train loss {'Reaction outcome loss': 0.32558005572266513, 'Total loss': 0.32558005572266513}
2022-11-28 02:00:11,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:11,124 INFO:     Epoch: 65
2022-11-28 02:00:11,870 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4091663538393649, 'Total loss': 0.4091663538393649} | train loss {'Reaction outcome loss': 0.32769085959293826, 'Total loss': 0.32769085959293826}
2022-11-28 02:00:11,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:11,871 INFO:     Epoch: 66
2022-11-28 02:00:12,619 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3992387821728533, 'Total loss': 0.3992387821728533} | train loss {'Reaction outcome loss': 0.32994034068153694, 'Total loss': 0.32994034068153694}
2022-11-28 02:00:12,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:12,619 INFO:     Epoch: 67
2022-11-28 02:00:13,368 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3931631369685585, 'Total loss': 0.3931631369685585} | train loss {'Reaction outcome loss': 0.32641982439498185, 'Total loss': 0.32641982439498185}
2022-11-28 02:00:13,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:13,369 INFO:     Epoch: 68
2022-11-28 02:00:14,119 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40428868325596506, 'Total loss': 0.40428868325596506} | train loss {'Reaction outcome loss': 0.32242856783734525, 'Total loss': 0.32242856783734525}
2022-11-28 02:00:14,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:14,119 INFO:     Epoch: 69
2022-11-28 02:00:14,867 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4319382699375803, 'Total loss': 0.4319382699375803} | train loss {'Reaction outcome loss': 0.33433024120716914, 'Total loss': 0.33433024120716914}
2022-11-28 02:00:14,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:14,867 INFO:     Epoch: 70
2022-11-28 02:00:15,614 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4112035557627678, 'Total loss': 0.4112035557627678} | train loss {'Reaction outcome loss': 0.3328776384825415, 'Total loss': 0.3328776384825415}
2022-11-28 02:00:15,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:15,614 INFO:     Epoch: 71
2022-11-28 02:00:16,360 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39247822998599574, 'Total loss': 0.39247822998599574} | train loss {'Reaction outcome loss': 0.3257003100174159, 'Total loss': 0.3257003100174159}
2022-11-28 02:00:16,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:16,360 INFO:     Epoch: 72
2022-11-28 02:00:17,106 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41145099699497223, 'Total loss': 0.41145099699497223} | train loss {'Reaction outcome loss': 0.32351334640654444, 'Total loss': 0.32351334640654444}
2022-11-28 02:00:17,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:17,106 INFO:     Epoch: 73
2022-11-28 02:00:17,853 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42045655914328317, 'Total loss': 0.42045655914328317} | train loss {'Reaction outcome loss': 0.32579476015287856, 'Total loss': 0.32579476015287856}
2022-11-28 02:00:17,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:17,854 INFO:     Epoch: 74
2022-11-28 02:00:18,601 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.407216438176957, 'Total loss': 0.407216438176957} | train loss {'Reaction outcome loss': 0.3256467204043257, 'Total loss': 0.3256467204043257}
2022-11-28 02:00:18,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:18,602 INFO:     Epoch: 75
2022-11-28 02:00:19,351 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4176848056641492, 'Total loss': 0.4176848056641492} | train loss {'Reaction outcome loss': 0.34415122920926283, 'Total loss': 0.34415122920926283}
2022-11-28 02:00:19,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:19,352 INFO:     Epoch: 76
2022-11-28 02:00:20,097 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4029118401760405, 'Total loss': 0.4029118401760405} | train loss {'Reaction outcome loss': 0.3257455000963047, 'Total loss': 0.3257455000963047}
2022-11-28 02:00:20,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:20,097 INFO:     Epoch: 77
2022-11-28 02:00:20,844 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41966184736652806, 'Total loss': 0.41966184736652806} | train loss {'Reaction outcome loss': 0.3228898384388695, 'Total loss': 0.3228898384388695}
2022-11-28 02:00:20,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:20,844 INFO:     Epoch: 78
2022-11-28 02:00:21,592 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4246627292172475, 'Total loss': 0.4246627292172475} | train loss {'Reaction outcome loss': 0.3220886801508998, 'Total loss': 0.3220886801508998}
2022-11-28 02:00:21,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:21,593 INFO:     Epoch: 79
2022-11-28 02:00:22,341 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4455001320351254, 'Total loss': 0.4455001320351254} | train loss {'Reaction outcome loss': 0.32806984105935466, 'Total loss': 0.32806984105935466}
2022-11-28 02:00:22,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:22,341 INFO:     Epoch: 80
2022-11-28 02:00:23,085 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40038249269127846, 'Total loss': 0.40038249269127846} | train loss {'Reaction outcome loss': 0.32322048308725587, 'Total loss': 0.32322048308725587}
2022-11-28 02:00:23,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:23,085 INFO:     Epoch: 81
2022-11-28 02:00:23,834 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3947665671055967, 'Total loss': 0.3947665671055967} | train loss {'Reaction outcome loss': 0.32950385742884897, 'Total loss': 0.32950385742884897}
2022-11-28 02:00:23,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:23,834 INFO:     Epoch: 82
2022-11-28 02:00:24,579 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3894824091006409, 'Total loss': 0.3894824091006409} | train loss {'Reaction outcome loss': 0.3305616064019773, 'Total loss': 0.3305616064019773}
2022-11-28 02:00:24,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:24,581 INFO:     Epoch: 83
2022-11-28 02:00:25,327 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4069936890155077, 'Total loss': 0.4069936890155077} | train loss {'Reaction outcome loss': 0.3254545863551891, 'Total loss': 0.3254545863551891}
2022-11-28 02:00:25,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:25,328 INFO:     Epoch: 84
2022-11-28 02:00:26,075 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43134771524505183, 'Total loss': 0.43134771524505183} | train loss {'Reaction outcome loss': 0.3540454752411437, 'Total loss': 0.3540454752411437}
2022-11-28 02:00:26,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:26,075 INFO:     Epoch: 85
2022-11-28 02:00:26,826 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41043452952395787, 'Total loss': 0.41043452952395787} | train loss {'Reaction outcome loss': 0.33264674679168804, 'Total loss': 0.33264674679168804}
2022-11-28 02:00:26,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:26,826 INFO:     Epoch: 86
2022-11-28 02:00:27,582 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4084635954350233, 'Total loss': 0.4084635954350233} | train loss {'Reaction outcome loss': 0.3255560823041297, 'Total loss': 0.3255560823041297}
2022-11-28 02:00:27,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:27,582 INFO:     Epoch: 87
2022-11-28 02:00:28,335 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3901027085428888, 'Total loss': 0.3901027085428888} | train loss {'Reaction outcome loss': 0.33744047131452537, 'Total loss': 0.33744047131452537}
2022-11-28 02:00:28,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:28,335 INFO:     Epoch: 88
2022-11-28 02:00:29,087 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39536750790747727, 'Total loss': 0.39536750790747727} | train loss {'Reaction outcome loss': 0.3153729494892038, 'Total loss': 0.3153729494892038}
2022-11-28 02:00:29,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:29,087 INFO:     Epoch: 89
2022-11-28 02:00:29,844 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3819039867005565, 'Total loss': 0.3819039867005565} | train loss {'Reaction outcome loss': 0.32990443486313104, 'Total loss': 0.32990443486313104}
2022-11-28 02:00:29,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:29,844 INFO:     Epoch: 90
2022-11-28 02:00:30,598 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38555925813588227, 'Total loss': 0.38555925813588227} | train loss {'Reaction outcome loss': 0.34731273181163347, 'Total loss': 0.34731273181163347}
2022-11-28 02:00:30,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:30,599 INFO:     Epoch: 91
2022-11-28 02:00:31,356 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3859824033623392, 'Total loss': 0.3859824033623392} | train loss {'Reaction outcome loss': 0.3205647015310673, 'Total loss': 0.3205647015310673}
2022-11-28 02:00:31,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:31,357 INFO:     Epoch: 92
2022-11-28 02:00:32,109 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3930919153446501, 'Total loss': 0.3930919153446501} | train loss {'Reaction outcome loss': 0.31669722174705284, 'Total loss': 0.31669722174705284}
2022-11-28 02:00:32,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:32,110 INFO:     Epoch: 93
2022-11-28 02:00:32,863 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38341618955812673, 'Total loss': 0.38341618955812673} | train loss {'Reaction outcome loss': 0.3200237269914871, 'Total loss': 0.3200237269914871}
2022-11-28 02:00:32,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:32,863 INFO:     Epoch: 94
2022-11-28 02:00:33,615 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42470190911130473, 'Total loss': 0.42470190911130473} | train loss {'Reaction outcome loss': 0.31914124803745797, 'Total loss': 0.31914124803745797}
2022-11-28 02:00:33,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:33,616 INFO:     Epoch: 95
2022-11-28 02:00:34,369 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40357431092045526, 'Total loss': 0.40357431092045526} | train loss {'Reaction outcome loss': 0.329208456281467, 'Total loss': 0.329208456281467}
2022-11-28 02:00:34,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:34,369 INFO:     Epoch: 96
2022-11-28 02:00:35,124 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40303512815047393, 'Total loss': 0.40303512815047393} | train loss {'Reaction outcome loss': 0.32378071225304833, 'Total loss': 0.32378071225304833}
2022-11-28 02:00:35,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:35,125 INFO:     Epoch: 97
2022-11-28 02:00:35,879 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40007442032749, 'Total loss': 0.40007442032749} | train loss {'Reaction outcome loss': 0.3327448277881271, 'Total loss': 0.3327448277881271}
2022-11-28 02:00:35,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:35,879 INFO:     Epoch: 98
2022-11-28 02:00:36,629 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.440920046784661, 'Total loss': 0.440920046784661} | train loss {'Reaction outcome loss': 0.3205331791086718, 'Total loss': 0.3205331791086718}
2022-11-28 02:00:36,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:36,630 INFO:     Epoch: 99
2022-11-28 02:00:37,386 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.440716298466379, 'Total loss': 0.440716298466379} | train loss {'Reaction outcome loss': 0.31600082817775865, 'Total loss': 0.31600082817775865}
2022-11-28 02:00:37,386 INFO:     Best model found after epoch 60 of 100.
2022-11-28 02:00:37,386 INFO:   Done with stage: TRAINING
2022-11-28 02:00:37,386 INFO:   Starting stage: EVALUATION
2022-11-28 02:00:37,511 INFO:   Done with stage: EVALUATION
2022-11-28 02:00:37,511 INFO:   Leaving out SEQ value Fold_5
2022-11-28 02:00:37,523 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:00:37,524 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:00:38,173 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:00:38,173 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:00:38,241 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:00:38,241 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:00:38,241 INFO:     No hyperparam tuning for this model
2022-11-28 02:00:38,241 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:00:38,241 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:00:38,242 INFO:     None feature selector for col prot
2022-11-28 02:00:38,242 INFO:     None feature selector for col prot
2022-11-28 02:00:38,242 INFO:     None feature selector for col prot
2022-11-28 02:00:38,243 INFO:     None feature selector for col chem
2022-11-28 02:00:38,243 INFO:     None feature selector for col chem
2022-11-28 02:00:38,243 INFO:     None feature selector for col chem
2022-11-28 02:00:38,243 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:00:38,243 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:00:38,245 INFO:     Number of params in model 169741
2022-11-28 02:00:38,248 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:00:38,248 INFO:   Starting stage: TRAINING
2022-11-28 02:00:38,302 INFO:     Val loss before train {'Reaction outcome loss': 0.9659714143384587, 'Total loss': 0.9659714143384587}
2022-11-28 02:00:38,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:38,302 INFO:     Epoch: 0
2022-11-28 02:00:39,060 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.544684424996376, 'Total loss': 0.544684424996376} | train loss {'Reaction outcome loss': 0.6422778932798293, 'Total loss': 0.6422778932798293}
2022-11-28 02:00:39,060 INFO:     Found new best model at epoch 0
2022-11-28 02:00:39,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:39,061 INFO:     Epoch: 1
2022-11-28 02:00:39,821 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4924442520873113, 'Total loss': 0.4924442520873113} | train loss {'Reaction outcome loss': 0.5042765262506662, 'Total loss': 0.5042765262506662}
2022-11-28 02:00:39,821 INFO:     Found new best model at epoch 1
2022-11-28 02:00:39,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:39,822 INFO:     Epoch: 2
2022-11-28 02:00:40,578 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4804498085921461, 'Total loss': 0.4804498085921461} | train loss {'Reaction outcome loss': 0.4609320557285701, 'Total loss': 0.4609320557285701}
2022-11-28 02:00:40,579 INFO:     Found new best model at epoch 2
2022-11-28 02:00:40,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:40,579 INFO:     Epoch: 3
2022-11-28 02:00:41,339 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.480525826188651, 'Total loss': 0.480525826188651} | train loss {'Reaction outcome loss': 0.4392671819716211, 'Total loss': 0.4392671819716211}
2022-11-28 02:00:41,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:41,339 INFO:     Epoch: 4
2022-11-28 02:00:42,111 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4542036486620253, 'Total loss': 0.4542036486620253} | train loss {'Reaction outcome loss': 0.4234391246591845, 'Total loss': 0.4234391246591845}
2022-11-28 02:00:42,111 INFO:     Found new best model at epoch 4
2022-11-28 02:00:42,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:42,112 INFO:     Epoch: 5
2022-11-28 02:00:42,882 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43591711297631264, 'Total loss': 0.43591711297631264} | train loss {'Reaction outcome loss': 0.4129715250624764, 'Total loss': 0.4129715250624764}
2022-11-28 02:00:42,882 INFO:     Found new best model at epoch 5
2022-11-28 02:00:42,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:42,883 INFO:     Epoch: 6
2022-11-28 02:00:43,648 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4618267970667644, 'Total loss': 0.4618267970667644} | train loss {'Reaction outcome loss': 0.40569179481075657, 'Total loss': 0.40569179481075657}
2022-11-28 02:00:43,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:43,649 INFO:     Epoch: 7
2022-11-28 02:00:44,419 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44957423718138173, 'Total loss': 0.44957423718138173} | train loss {'Reaction outcome loss': 0.38962514503228085, 'Total loss': 0.38962514503228085}
2022-11-28 02:00:44,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:44,420 INFO:     Epoch: 8
2022-11-28 02:00:45,188 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46489131450653076, 'Total loss': 0.46489131450653076} | train loss {'Reaction outcome loss': 0.3929220293498328, 'Total loss': 0.3929220293498328}
2022-11-28 02:00:45,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:45,188 INFO:     Epoch: 9
2022-11-28 02:00:45,955 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45594760894098063, 'Total loss': 0.45594760894098063} | train loss {'Reaction outcome loss': 0.38826085092319595, 'Total loss': 0.38826085092319595}
2022-11-28 02:00:45,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:45,956 INFO:     Epoch: 10
2022-11-28 02:00:46,723 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47291992604732513, 'Total loss': 0.47291992604732513} | train loss {'Reaction outcome loss': 0.37536068792424854, 'Total loss': 0.37536068792424854}
2022-11-28 02:00:46,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:46,723 INFO:     Epoch: 11
2022-11-28 02:00:47,494 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43765015696937387, 'Total loss': 0.43765015696937387} | train loss {'Reaction outcome loss': 0.3732504908355974, 'Total loss': 0.3732504908355974}
2022-11-28 02:00:47,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:47,494 INFO:     Epoch: 12
2022-11-28 02:00:48,261 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42847133275460114, 'Total loss': 0.42847133275460114} | train loss {'Reaction outcome loss': 0.3675743759038948, 'Total loss': 0.3675743759038948}
2022-11-28 02:00:48,262 INFO:     Found new best model at epoch 12
2022-11-28 02:00:48,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:48,262 INFO:     Epoch: 13
2022-11-28 02:00:49,035 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4235958399420435, 'Total loss': 0.4235958399420435} | train loss {'Reaction outcome loss': 0.3597934483400276, 'Total loss': 0.3597934483400276}
2022-11-28 02:00:49,035 INFO:     Found new best model at epoch 13
2022-11-28 02:00:49,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:49,036 INFO:     Epoch: 14
2022-11-28 02:00:49,807 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4262117956849662, 'Total loss': 0.4262117956849662} | train loss {'Reaction outcome loss': 0.36677029581680415, 'Total loss': 0.36677029581680415}
2022-11-28 02:00:49,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:49,807 INFO:     Epoch: 15
2022-11-28 02:00:50,580 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47412947937846184, 'Total loss': 0.47412947937846184} | train loss {'Reaction outcome loss': 0.35831219468626285, 'Total loss': 0.35831219468626285}
2022-11-28 02:00:50,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:50,580 INFO:     Epoch: 16
2022-11-28 02:00:51,352 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41663056645881047, 'Total loss': 0.41663056645881047} | train loss {'Reaction outcome loss': 0.36010597036370345, 'Total loss': 0.36010597036370345}
2022-11-28 02:00:51,352 INFO:     Found new best model at epoch 16
2022-11-28 02:00:51,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:51,353 INFO:     Epoch: 17
2022-11-28 02:00:52,124 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4372773780064149, 'Total loss': 0.4372773780064149} | train loss {'Reaction outcome loss': 0.36171367127568493, 'Total loss': 0.36171367127568493}
2022-11-28 02:00:52,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:52,124 INFO:     Epoch: 18
2022-11-28 02:00:52,895 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4171546067703854, 'Total loss': 0.4171546067703854} | train loss {'Reaction outcome loss': 0.3465259940393509, 'Total loss': 0.3465259940393509}
2022-11-28 02:00:52,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:52,895 INFO:     Epoch: 19
2022-11-28 02:00:53,664 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45290050554004585, 'Total loss': 0.45290050554004585} | train loss {'Reaction outcome loss': 0.3486919873243859, 'Total loss': 0.3486919873243859}
2022-11-28 02:00:53,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:53,665 INFO:     Epoch: 20
2022-11-28 02:00:54,437 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4387472580102357, 'Total loss': 0.4387472580102357} | train loss {'Reaction outcome loss': 0.3533530515889006, 'Total loss': 0.3533530515889006}
2022-11-28 02:00:54,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:54,437 INFO:     Epoch: 21
2022-11-28 02:00:55,206 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.432230914180929, 'Total loss': 0.432230914180929} | train loss {'Reaction outcome loss': 0.3435826015268122, 'Total loss': 0.3435826015268122}
2022-11-28 02:00:55,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:55,206 INFO:     Epoch: 22
2022-11-28 02:00:55,973 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44800471277399495, 'Total loss': 0.44800471277399495} | train loss {'Reaction outcome loss': 0.346649753891172, 'Total loss': 0.346649753891172}
2022-11-28 02:00:55,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:55,974 INFO:     Epoch: 23
2022-11-28 02:00:56,747 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4384458705105565, 'Total loss': 0.4384458705105565} | train loss {'Reaction outcome loss': 0.3371001218535727, 'Total loss': 0.3371001218535727}
2022-11-28 02:00:56,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:56,747 INFO:     Epoch: 24
2022-11-28 02:00:57,518 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42647579684853554, 'Total loss': 0.42647579684853554} | train loss {'Reaction outcome loss': 0.33047249630814596, 'Total loss': 0.33047249630814596}
2022-11-28 02:00:57,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:57,518 INFO:     Epoch: 25
2022-11-28 02:00:58,291 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.431521342897957, 'Total loss': 0.431521342897957} | train loss {'Reaction outcome loss': 0.3389869748704856, 'Total loss': 0.3389869748704856}
2022-11-28 02:00:58,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:58,291 INFO:     Epoch: 26
2022-11-28 02:00:59,060 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48224322057583113, 'Total loss': 0.48224322057583113} | train loss {'Reaction outcome loss': 0.34081481084708243, 'Total loss': 0.34081481084708243}
2022-11-28 02:00:59,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:59,060 INFO:     Epoch: 27
2022-11-28 02:00:59,829 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4133136983622204, 'Total loss': 0.4133136983622204} | train loss {'Reaction outcome loss': 0.34518069440438864, 'Total loss': 0.34518069440438864}
2022-11-28 02:00:59,830 INFO:     Found new best model at epoch 27
2022-11-28 02:00:59,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:00:59,830 INFO:     Epoch: 28
2022-11-28 02:01:00,598 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4135683346539736, 'Total loss': 0.4135683346539736} | train loss {'Reaction outcome loss': 0.33066253925883965, 'Total loss': 0.33066253925883965}
2022-11-28 02:01:00,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:00,599 INFO:     Epoch: 29
2022-11-28 02:01:01,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42446543648838997, 'Total loss': 0.42446543648838997} | train loss {'Reaction outcome loss': 0.33015565656786483, 'Total loss': 0.33015565656786483}
2022-11-28 02:01:01,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:01,365 INFO:     Epoch: 30
2022-11-28 02:01:02,136 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40496590665795584, 'Total loss': 0.40496590665795584} | train loss {'Reaction outcome loss': 0.3275093005579566, 'Total loss': 0.3275093005579566}
2022-11-28 02:01:02,137 INFO:     Found new best model at epoch 30
2022-11-28 02:01:02,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:02,138 INFO:     Epoch: 31
2022-11-28 02:01:02,909 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4079428174617616, 'Total loss': 0.4079428174617616} | train loss {'Reaction outcome loss': 0.33101891747285284, 'Total loss': 0.33101891747285284}
2022-11-28 02:01:02,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:02,909 INFO:     Epoch: 32
2022-11-28 02:01:03,677 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4082255187359723, 'Total loss': 0.4082255187359723} | train loss {'Reaction outcome loss': 0.3349618182908143, 'Total loss': 0.3349618182908143}
2022-11-28 02:01:03,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:03,677 INFO:     Epoch: 33
2022-11-28 02:01:04,448 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4155941256745295, 'Total loss': 0.4155941256745295} | train loss {'Reaction outcome loss': 0.33101092197842175, 'Total loss': 0.33101092197842175}
2022-11-28 02:01:04,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:04,448 INFO:     Epoch: 34
2022-11-28 02:01:05,216 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4129411486739462, 'Total loss': 0.4129411486739462} | train loss {'Reaction outcome loss': 0.32911991886794567, 'Total loss': 0.32911991886794567}
2022-11-28 02:01:05,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:05,216 INFO:     Epoch: 35
2022-11-28 02:01:05,989 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4214241755279628, 'Total loss': 0.4214241755279628} | train loss {'Reaction outcome loss': 0.32547013768024985, 'Total loss': 0.32547013768024985}
2022-11-28 02:01:05,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:05,990 INFO:     Epoch: 36
2022-11-28 02:01:06,758 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4175249896943569, 'Total loss': 0.4175249896943569} | train loss {'Reaction outcome loss': 0.33467273981941326, 'Total loss': 0.33467273981941326}
2022-11-28 02:01:06,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:06,758 INFO:     Epoch: 37
2022-11-28 02:01:07,529 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4713425759903409, 'Total loss': 0.4713425759903409} | train loss {'Reaction outcome loss': 0.31833490386845603, 'Total loss': 0.31833490386845603}
2022-11-28 02:01:07,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:07,529 INFO:     Epoch: 38
2022-11-28 02:01:08,298 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46119609339670703, 'Total loss': 0.46119609339670703} | train loss {'Reaction outcome loss': 0.33199624518953985, 'Total loss': 0.33199624518953985}
2022-11-28 02:01:08,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:08,298 INFO:     Epoch: 39
2022-11-28 02:01:09,071 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44180152531374584, 'Total loss': 0.44180152531374584} | train loss {'Reaction outcome loss': 0.3202783255988071, 'Total loss': 0.3202783255988071}
2022-11-28 02:01:09,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:09,071 INFO:     Epoch: 40
2022-11-28 02:01:09,841 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4028739580376582, 'Total loss': 0.4028739580376582} | train loss {'Reaction outcome loss': 0.3219327961335019, 'Total loss': 0.3219327961335019}
2022-11-28 02:01:09,841 INFO:     Found new best model at epoch 40
2022-11-28 02:01:09,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:09,842 INFO:     Epoch: 41
2022-11-28 02:01:10,612 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40519199638881465, 'Total loss': 0.40519199638881465} | train loss {'Reaction outcome loss': 0.3211041961856667, 'Total loss': 0.3211041961856667}
2022-11-28 02:01:10,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:10,612 INFO:     Epoch: 42
2022-11-28 02:01:11,383 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4092797158624638, 'Total loss': 0.4092797158624638} | train loss {'Reaction outcome loss': 0.32667961371161286, 'Total loss': 0.32667961371161286}
2022-11-28 02:01:11,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:11,383 INFO:     Epoch: 43
2022-11-28 02:01:12,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41292979940772057, 'Total loss': 0.41292979940772057} | train loss {'Reaction outcome loss': 0.3213593239235061, 'Total loss': 0.3213593239235061}
2022-11-28 02:01:12,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:12,153 INFO:     Epoch: 44
2022-11-28 02:01:12,922 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4042035923762755, 'Total loss': 0.4042035923762755} | train loss {'Reaction outcome loss': 0.3194868653832424, 'Total loss': 0.3194868653832424}
2022-11-28 02:01:12,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:12,922 INFO:     Epoch: 45
2022-11-28 02:01:13,692 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4188695732842792, 'Total loss': 0.4188695732842792} | train loss {'Reaction outcome loss': 0.3217417888283249, 'Total loss': 0.3217417888283249}
2022-11-28 02:01:13,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:13,693 INFO:     Epoch: 46
2022-11-28 02:01:14,459 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4183784455738284, 'Total loss': 0.4183784455738284} | train loss {'Reaction outcome loss': 0.3227552092303672, 'Total loss': 0.3227552092303672}
2022-11-28 02:01:14,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:14,460 INFO:     Epoch: 47
2022-11-28 02:01:15,229 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4461456449194388, 'Total loss': 0.4461456449194388} | train loss {'Reaction outcome loss': 0.31682292272847506, 'Total loss': 0.31682292272847506}
2022-11-28 02:01:15,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:15,229 INFO:     Epoch: 48
2022-11-28 02:01:15,999 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43193012509833684, 'Total loss': 0.43193012509833684} | train loss {'Reaction outcome loss': 0.3222119536461128, 'Total loss': 0.3222119536461128}
2022-11-28 02:01:16,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:16,000 INFO:     Epoch: 49
2022-11-28 02:01:16,772 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3923203636976806, 'Total loss': 0.3923203636976806} | train loss {'Reaction outcome loss': 0.32037422756454154, 'Total loss': 0.32037422756454154}
2022-11-28 02:01:16,772 INFO:     Found new best model at epoch 49
2022-11-28 02:01:16,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:16,773 INFO:     Epoch: 50
2022-11-28 02:01:17,546 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4137652428312735, 'Total loss': 0.4137652428312735} | train loss {'Reaction outcome loss': 0.32368145738878557, 'Total loss': 0.32368145738878557}
2022-11-28 02:01:17,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:17,546 INFO:     Epoch: 51
2022-11-28 02:01:18,319 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4072149968282743, 'Total loss': 0.4072149968282743} | train loss {'Reaction outcome loss': 0.3137235886777841, 'Total loss': 0.3137235886777841}
2022-11-28 02:01:18,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:18,319 INFO:     Epoch: 52
2022-11-28 02:01:19,092 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4392824372784658, 'Total loss': 0.4392824372784658} | train loss {'Reaction outcome loss': 0.32704788626682374, 'Total loss': 0.32704788626682374}
2022-11-28 02:01:19,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:19,093 INFO:     Epoch: 53
2022-11-28 02:01:19,863 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3836995866149664, 'Total loss': 0.3836995866149664} | train loss {'Reaction outcome loss': 0.31833769801643585, 'Total loss': 0.31833769801643585}
2022-11-28 02:01:19,863 INFO:     Found new best model at epoch 53
2022-11-28 02:01:19,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:19,864 INFO:     Epoch: 54
2022-11-28 02:01:20,635 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4419437436894937, 'Total loss': 0.4419437436894937} | train loss {'Reaction outcome loss': 0.3224846765759491, 'Total loss': 0.3224846765759491}
2022-11-28 02:01:20,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:20,636 INFO:     Epoch: 55
2022-11-28 02:01:21,405 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40918422219428147, 'Total loss': 0.40918422219428147} | train loss {'Reaction outcome loss': 0.31056752146011396, 'Total loss': 0.31056752146011396}
2022-11-28 02:01:21,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:21,405 INFO:     Epoch: 56
2022-11-28 02:01:22,175 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4075188518247821, 'Total loss': 0.4075188518247821} | train loss {'Reaction outcome loss': 0.32068357804429626, 'Total loss': 0.32068357804429626}
2022-11-28 02:01:22,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:22,175 INFO:     Epoch: 57
2022-11-28 02:01:22,945 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3904376449910077, 'Total loss': 0.3904376449910077} | train loss {'Reaction outcome loss': 0.31144238709502164, 'Total loss': 0.31144238709502164}
2022-11-28 02:01:22,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:22,946 INFO:     Epoch: 58
2022-11-28 02:01:23,717 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40066030333665287, 'Total loss': 0.40066030333665287} | train loss {'Reaction outcome loss': 0.31452513311899477, 'Total loss': 0.31452513311899477}
2022-11-28 02:01:23,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:23,717 INFO:     Epoch: 59
2022-11-28 02:01:24,489 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45533839240670204, 'Total loss': 0.45533839240670204} | train loss {'Reaction outcome loss': 0.31479752571472236, 'Total loss': 0.31479752571472236}
2022-11-28 02:01:24,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:24,489 INFO:     Epoch: 60
2022-11-28 02:01:25,258 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39855912632562895, 'Total loss': 0.39855912632562895} | train loss {'Reaction outcome loss': 0.3185576104048279, 'Total loss': 0.3185576104048279}
2022-11-28 02:01:25,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:25,258 INFO:     Epoch: 61
2022-11-28 02:01:26,028 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40664623711596837, 'Total loss': 0.40664623711596837} | train loss {'Reaction outcome loss': 0.3157936303816255, 'Total loss': 0.3157936303816255}
2022-11-28 02:01:26,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:26,028 INFO:     Epoch: 62
2022-11-28 02:01:26,802 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39417842572385614, 'Total loss': 0.39417842572385614} | train loss {'Reaction outcome loss': 0.31373652955517173, 'Total loss': 0.31373652955517173}
2022-11-28 02:01:26,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:26,803 INFO:     Epoch: 63
2022-11-28 02:01:27,575 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42317531850527634, 'Total loss': 0.42317531850527634} | train loss {'Reaction outcome loss': 0.3197802582214917, 'Total loss': 0.3197802582214917}
2022-11-28 02:01:27,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:27,575 INFO:     Epoch: 64
2022-11-28 02:01:28,347 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4314413412728093, 'Total loss': 0.4314413412728093} | train loss {'Reaction outcome loss': 0.30784334521740675, 'Total loss': 0.30784334521740675}
2022-11-28 02:01:28,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:28,347 INFO:     Epoch: 65
2022-11-28 02:01:29,117 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40632380672137847, 'Total loss': 0.40632380672137847} | train loss {'Reaction outcome loss': 0.3133345622749579, 'Total loss': 0.3133345622749579}
2022-11-28 02:01:29,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:29,117 INFO:     Epoch: 66
2022-11-28 02:01:29,886 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3935303061523221, 'Total loss': 0.3935303061523221} | train loss {'Reaction outcome loss': 0.30847203934324846, 'Total loss': 0.30847203934324846}
2022-11-28 02:01:29,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:29,886 INFO:     Epoch: 67
2022-11-28 02:01:30,656 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3904647170142694, 'Total loss': 0.3904647170142694} | train loss {'Reaction outcome loss': 0.3027264896419741, 'Total loss': 0.3027264896419741}
2022-11-28 02:01:30,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:30,656 INFO:     Epoch: 68
2022-11-28 02:01:31,426 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39592975784431805, 'Total loss': 0.39592975784431805} | train loss {'Reaction outcome loss': 0.31045853034142523, 'Total loss': 0.31045853034142523}
2022-11-28 02:01:31,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:31,426 INFO:     Epoch: 69
2022-11-28 02:01:32,196 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4407255405729467, 'Total loss': 0.4407255405729467} | train loss {'Reaction outcome loss': 0.310584160964936, 'Total loss': 0.310584160964936}
2022-11-28 02:01:32,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:32,197 INFO:     Epoch: 70
2022-11-28 02:01:32,969 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42558433894406666, 'Total loss': 0.42558433894406666} | train loss {'Reaction outcome loss': 0.3182001587664408, 'Total loss': 0.3182001587664408}
2022-11-28 02:01:32,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:32,970 INFO:     Epoch: 71
2022-11-28 02:01:33,739 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40668880651620304, 'Total loss': 0.40668880651620304} | train loss {'Reaction outcome loss': 0.30737555696959457, 'Total loss': 0.30737555696959457}
2022-11-28 02:01:33,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:33,739 INFO:     Epoch: 72
2022-11-28 02:01:34,508 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41837106323377654, 'Total loss': 0.41837106323377654} | train loss {'Reaction outcome loss': 0.31435173602714656, 'Total loss': 0.31435173602714656}
2022-11-28 02:01:34,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:34,508 INFO:     Epoch: 73
2022-11-28 02:01:35,278 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3966252671724016, 'Total loss': 0.3966252671724016} | train loss {'Reaction outcome loss': 0.3204059364093888, 'Total loss': 0.3204059364093888}
2022-11-28 02:01:35,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:35,278 INFO:     Epoch: 74
2022-11-28 02:01:36,039 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4127242368730632, 'Total loss': 0.4127242368730632} | train loss {'Reaction outcome loss': 0.30837100720213306, 'Total loss': 0.30837100720213306}
2022-11-28 02:01:36,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:36,039 INFO:     Epoch: 75
2022-11-28 02:01:36,791 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41356376998803834, 'Total loss': 0.41356376998803834} | train loss {'Reaction outcome loss': 0.30568107507461983, 'Total loss': 0.30568107507461983}
2022-11-28 02:01:36,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:36,792 INFO:     Epoch: 76
2022-11-28 02:01:37,542 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4095898385752331, 'Total loss': 0.4095898385752331} | train loss {'Reaction outcome loss': 0.30736511317832815, 'Total loss': 0.30736511317832815}
2022-11-28 02:01:37,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:37,542 INFO:     Epoch: 77
2022-11-28 02:01:38,293 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41091088916767726, 'Total loss': 0.41091088916767726} | train loss {'Reaction outcome loss': 0.30750427896817845, 'Total loss': 0.30750427896817845}
2022-11-28 02:01:38,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:38,293 INFO:     Epoch: 78
2022-11-28 02:01:39,044 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38735387034036894, 'Total loss': 0.38735387034036894} | train loss {'Reaction outcome loss': 0.30834607179126433, 'Total loss': 0.30834607179126433}
2022-11-28 02:01:39,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:39,044 INFO:     Epoch: 79
2022-11-28 02:01:39,799 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39292882653799927, 'Total loss': 0.39292882653799927} | train loss {'Reaction outcome loss': 0.310057392764476, 'Total loss': 0.310057392764476}
2022-11-28 02:01:39,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:39,799 INFO:     Epoch: 80
2022-11-28 02:01:40,551 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41032449528574944, 'Total loss': 0.41032449528574944} | train loss {'Reaction outcome loss': 0.31015501617484037, 'Total loss': 0.31015501617484037}
2022-11-28 02:01:40,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:40,551 INFO:     Epoch: 81
2022-11-28 02:01:41,301 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5765483579175039, 'Total loss': 0.5765483579175039} | train loss {'Reaction outcome loss': 0.30852812841053934, 'Total loss': 0.30852812841053934}
2022-11-28 02:01:41,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:41,301 INFO:     Epoch: 82
2022-11-28 02:01:42,049 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40543739531527867, 'Total loss': 0.40543739531527867} | train loss {'Reaction outcome loss': 0.31783694106965293, 'Total loss': 0.31783694106965293}
2022-11-28 02:01:42,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:42,049 INFO:     Epoch: 83
2022-11-28 02:01:42,807 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43975416164506564, 'Total loss': 0.43975416164506564} | train loss {'Reaction outcome loss': 0.30476730797559987, 'Total loss': 0.30476730797559987}
2022-11-28 02:01:42,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:42,807 INFO:     Epoch: 84
2022-11-28 02:01:43,566 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4060754941945726, 'Total loss': 0.4060754941945726} | train loss {'Reaction outcome loss': 0.30224988961051547, 'Total loss': 0.30224988961051547}
2022-11-28 02:01:43,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:43,566 INFO:     Epoch: 85
2022-11-28 02:01:44,316 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4205228694799272, 'Total loss': 0.4205228694799272} | train loss {'Reaction outcome loss': 0.3032084057828592, 'Total loss': 0.3032084057828592}
2022-11-28 02:01:44,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:44,317 INFO:     Epoch: 86
2022-11-28 02:01:45,071 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3878645058721304, 'Total loss': 0.3878645058721304} | train loss {'Reaction outcome loss': 0.3215483445073328, 'Total loss': 0.3215483445073328}
2022-11-28 02:01:45,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:45,072 INFO:     Epoch: 87
2022-11-28 02:01:45,825 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40442844395610417, 'Total loss': 0.40442844395610417} | train loss {'Reaction outcome loss': 0.3096176939265382, 'Total loss': 0.3096176939265382}
2022-11-28 02:01:45,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:45,826 INFO:     Epoch: 88
2022-11-28 02:01:46,579 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38912383297627623, 'Total loss': 0.38912383297627623} | train loss {'Reaction outcome loss': 0.3039662157666058, 'Total loss': 0.3039662157666058}
2022-11-28 02:01:46,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:46,579 INFO:     Epoch: 89
2022-11-28 02:01:47,330 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41361600668592885, 'Total loss': 0.41361600668592885} | train loss {'Reaction outcome loss': 0.3061453621053407, 'Total loss': 0.3061453621053407}
2022-11-28 02:01:47,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:47,330 INFO:     Epoch: 90
2022-11-28 02:01:48,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38368827544830064, 'Total loss': 0.38368827544830064} | train loss {'Reaction outcome loss': 0.30085400313199046, 'Total loss': 0.30085400313199046}
2022-11-28 02:01:48,080 INFO:     Found new best model at epoch 90
2022-11-28 02:01:48,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:48,081 INFO:     Epoch: 91
2022-11-28 02:01:48,840 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4274359250610525, 'Total loss': 0.4274359250610525} | train loss {'Reaction outcome loss': 0.29995320910107226, 'Total loss': 0.29995320910107226}
2022-11-28 02:01:48,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:48,840 INFO:     Epoch: 92
2022-11-28 02:01:49,594 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4356393776834011, 'Total loss': 0.4356393776834011} | train loss {'Reaction outcome loss': 0.3048777740388628, 'Total loss': 0.3048777740388628}
2022-11-28 02:01:49,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:49,594 INFO:     Epoch: 93
2022-11-28 02:01:50,349 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39570071463557804, 'Total loss': 0.39570071463557804} | train loss {'Reaction outcome loss': 0.31050781741918576, 'Total loss': 0.31050781741918576}
2022-11-28 02:01:50,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:50,349 INFO:     Epoch: 94
2022-11-28 02:01:51,102 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3907289416952567, 'Total loss': 0.3907289416952567} | train loss {'Reaction outcome loss': 0.3006411598424517, 'Total loss': 0.3006411598424517}
2022-11-28 02:01:51,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:51,102 INFO:     Epoch: 95
2022-11-28 02:01:51,853 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4208235281773589, 'Total loss': 0.4208235281773589} | train loss {'Reaction outcome loss': 0.3005925961019051, 'Total loss': 0.3005925961019051}
2022-11-28 02:01:51,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:51,853 INFO:     Epoch: 96
2022-11-28 02:01:52,602 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4119345891204747, 'Total loss': 0.4119345891204747} | train loss {'Reaction outcome loss': 0.3134018553781413, 'Total loss': 0.3134018553781413}
2022-11-28 02:01:52,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:52,602 INFO:     Epoch: 97
2022-11-28 02:01:53,354 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3964781954207204, 'Total loss': 0.3964781954207204} | train loss {'Reaction outcome loss': 0.30555018488197555, 'Total loss': 0.30555018488197555}
2022-11-28 02:01:53,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:53,354 INFO:     Epoch: 98
2022-11-28 02:01:54,103 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3868933013555678, 'Total loss': 0.3868933013555678} | train loss {'Reaction outcome loss': 0.30038405939816465, 'Total loss': 0.30038405939816465}
2022-11-28 02:01:54,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:54,103 INFO:     Epoch: 99
2022-11-28 02:01:54,857 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41240849007259717, 'Total loss': 0.41240849007259717} | train loss {'Reaction outcome loss': 0.3071102601506056, 'Total loss': 0.3071102601506056}
2022-11-28 02:01:54,857 INFO:     Best model found after epoch 91 of 100.
2022-11-28 02:01:54,857 INFO:   Done with stage: TRAINING
2022-11-28 02:01:54,858 INFO:   Starting stage: EVALUATION
2022-11-28 02:01:54,976 INFO:   Done with stage: EVALUATION
2022-11-28 02:01:54,976 INFO:   Leaving out SEQ value Fold_6
2022-11-28 02:01:54,989 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:01:54,989 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:01:55,621 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:01:55,621 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:01:55,688 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:01:55,689 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:01:55,689 INFO:     No hyperparam tuning for this model
2022-11-28 02:01:55,689 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:01:55,689 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:01:55,689 INFO:     None feature selector for col prot
2022-11-28 02:01:55,690 INFO:     None feature selector for col prot
2022-11-28 02:01:55,690 INFO:     None feature selector for col prot
2022-11-28 02:01:55,690 INFO:     None feature selector for col chem
2022-11-28 02:01:55,690 INFO:     None feature selector for col chem
2022-11-28 02:01:55,690 INFO:     None feature selector for col chem
2022-11-28 02:01:55,690 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:01:55,690 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:01:55,692 INFO:     Number of params in model 169741
2022-11-28 02:01:55,695 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:01:55,695 INFO:   Starting stage: TRAINING
2022-11-28 02:01:55,749 INFO:     Val loss before train {'Reaction outcome loss': 1.000217304988341, 'Total loss': 1.000217304988341}
2022-11-28 02:01:55,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:55,749 INFO:     Epoch: 0
2022-11-28 02:01:56,489 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5176232328469103, 'Total loss': 0.5176232328469103} | train loss {'Reaction outcome loss': 0.6408723044152163, 'Total loss': 0.6408723044152163}
2022-11-28 02:01:56,489 INFO:     Found new best model at epoch 0
2022-11-28 02:01:56,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:56,490 INFO:     Epoch: 1
2022-11-28 02:01:57,232 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4811572845686566, 'Total loss': 0.4811572845686566} | train loss {'Reaction outcome loss': 0.5022508802462597, 'Total loss': 0.5022508802462597}
2022-11-28 02:01:57,232 INFO:     Found new best model at epoch 1
2022-11-28 02:01:57,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:57,233 INFO:     Epoch: 2
2022-11-28 02:01:57,979 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43516515161503444, 'Total loss': 0.43516515161503444} | train loss {'Reaction outcome loss': 0.4717365157847502, 'Total loss': 0.4717365157847502}
2022-11-28 02:01:57,979 INFO:     Found new best model at epoch 2
2022-11-28 02:01:57,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:57,980 INFO:     Epoch: 3
2022-11-28 02:01:58,725 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4434292766858231, 'Total loss': 0.4434292766858231} | train loss {'Reaction outcome loss': 0.43547620165104767, 'Total loss': 0.43547620165104767}
2022-11-28 02:01:58,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:58,726 INFO:     Epoch: 4
2022-11-28 02:01:59,472 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47222321649843996, 'Total loss': 0.47222321649843996} | train loss {'Reaction outcome loss': 0.42159885107254497, 'Total loss': 0.42159885107254497}
2022-11-28 02:01:59,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:01:59,472 INFO:     Epoch: 5
2022-11-28 02:02:00,222 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43166232244534924, 'Total loss': 0.43166232244534924} | train loss {'Reaction outcome loss': 0.4146319867396841, 'Total loss': 0.4146319867396841}
2022-11-28 02:02:00,222 INFO:     Found new best model at epoch 5
2022-11-28 02:02:00,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:00,223 INFO:     Epoch: 6
2022-11-28 02:02:00,967 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41137378239496186, 'Total loss': 0.41137378239496186} | train loss {'Reaction outcome loss': 0.3969408968273474, 'Total loss': 0.3969408968273474}
2022-11-28 02:02:00,967 INFO:     Found new best model at epoch 6
2022-11-28 02:02:00,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:00,968 INFO:     Epoch: 7
2022-11-28 02:02:01,719 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4031824574551799, 'Total loss': 0.4031824574551799} | train loss {'Reaction outcome loss': 0.38953159889396355, 'Total loss': 0.38953159889396355}
2022-11-28 02:02:01,719 INFO:     Found new best model at epoch 7
2022-11-28 02:02:01,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:01,720 INFO:     Epoch: 8
2022-11-28 02:02:02,464 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46237136592919176, 'Total loss': 0.46237136592919176} | train loss {'Reaction outcome loss': 0.37596409299543926, 'Total loss': 0.37596409299543926}
2022-11-28 02:02:02,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:02,464 INFO:     Epoch: 9
2022-11-28 02:02:03,209 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4260534369810061, 'Total loss': 0.4260534369810061} | train loss {'Reaction outcome loss': 0.3882310041663598, 'Total loss': 0.3882310041663598}
2022-11-28 02:02:03,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:03,209 INFO:     Epoch: 10
2022-11-28 02:02:03,954 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44628932868892496, 'Total loss': 0.44628932868892496} | train loss {'Reaction outcome loss': 0.3711489264150055, 'Total loss': 0.3711489264150055}
2022-11-28 02:02:03,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:03,954 INFO:     Epoch: 11
2022-11-28 02:02:04,697 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3878685642372478, 'Total loss': 0.3878685642372478} | train loss {'Reaction outcome loss': 0.3734578044742954, 'Total loss': 0.3734578044742954}
2022-11-28 02:02:04,697 INFO:     Found new best model at epoch 11
2022-11-28 02:02:04,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:04,698 INFO:     Epoch: 12
2022-11-28 02:02:05,442 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42121333539993927, 'Total loss': 0.42121333539993927} | train loss {'Reaction outcome loss': 0.35993647262149925, 'Total loss': 0.35993647262149925}
2022-11-28 02:02:05,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:05,443 INFO:     Epoch: 13
2022-11-28 02:02:06,188 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4404392831704833, 'Total loss': 0.4404392831704833} | train loss {'Reaction outcome loss': 0.3660195598492817, 'Total loss': 0.3660195598492817}
2022-11-28 02:02:06,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:06,189 INFO:     Epoch: 14
2022-11-28 02:02:06,939 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4055778187784282, 'Total loss': 0.4055778187784282} | train loss {'Reaction outcome loss': 0.3532643616351546, 'Total loss': 0.3532643616351546}
2022-11-28 02:02:06,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:06,939 INFO:     Epoch: 15
2022-11-28 02:02:07,682 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44559177553111856, 'Total loss': 0.44559177553111856} | train loss {'Reaction outcome loss': 0.34770515381681677, 'Total loss': 0.34770515381681677}
2022-11-28 02:02:07,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:07,683 INFO:     Epoch: 16
2022-11-28 02:02:08,431 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43790455907583237, 'Total loss': 0.43790455907583237} | train loss {'Reaction outcome loss': 0.35196901736210806, 'Total loss': 0.35196901736210806}
2022-11-28 02:02:08,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:08,431 INFO:     Epoch: 17
2022-11-28 02:02:09,176 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4274543256244876, 'Total loss': 0.4274543256244876} | train loss {'Reaction outcome loss': 0.34505586885676093, 'Total loss': 0.34505586885676093}
2022-11-28 02:02:09,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:09,176 INFO:     Epoch: 18
2022-11-28 02:02:09,921 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41215796184472064, 'Total loss': 0.41215796184472064} | train loss {'Reaction outcome loss': 0.34534776067855405, 'Total loss': 0.34534776067855405}
2022-11-28 02:02:09,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:09,921 INFO:     Epoch: 19
2022-11-28 02:02:10,661 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3964597432958809, 'Total loss': 0.3964597432958809} | train loss {'Reaction outcome loss': 0.34156390820838967, 'Total loss': 0.34156390820838967}
2022-11-28 02:02:10,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:10,661 INFO:     Epoch: 20
2022-11-28 02:02:11,405 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4908263977955688, 'Total loss': 0.4908263977955688} | train loss {'Reaction outcome loss': 0.33754444607362455, 'Total loss': 0.33754444607362455}
2022-11-28 02:02:11,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:11,406 INFO:     Epoch: 21
2022-11-28 02:02:12,146 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3982951637696136, 'Total loss': 0.3982951637696136} | train loss {'Reaction outcome loss': 0.33961542279136425, 'Total loss': 0.33961542279136425}
2022-11-28 02:02:12,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:12,146 INFO:     Epoch: 22
2022-11-28 02:02:12,891 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42399604855613277, 'Total loss': 0.42399604855613277} | train loss {'Reaction outcome loss': 0.33220064621798845, 'Total loss': 0.33220064621798845}
2022-11-28 02:02:12,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:12,891 INFO:     Epoch: 23
2022-11-28 02:02:13,637 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4221689027141441, 'Total loss': 0.4221689027141441} | train loss {'Reaction outcome loss': 0.3387694118886578, 'Total loss': 0.3387694118886578}
2022-11-28 02:02:13,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:13,638 INFO:     Epoch: 24
2022-11-28 02:02:14,384 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4182467306540771, 'Total loss': 0.4182467306540771} | train loss {'Reaction outcome loss': 0.3221716869850548, 'Total loss': 0.3221716869850548}
2022-11-28 02:02:14,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:14,384 INFO:     Epoch: 25
2022-11-28 02:02:15,128 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39589009298519656, 'Total loss': 0.39589009298519656} | train loss {'Reaction outcome loss': 0.32789890608009026, 'Total loss': 0.32789890608009026}
2022-11-28 02:02:15,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:15,128 INFO:     Epoch: 26
2022-11-28 02:02:15,872 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4086337228390304, 'Total loss': 0.4086337228390304} | train loss {'Reaction outcome loss': 0.3271586314451938, 'Total loss': 0.3271586314451938}
2022-11-28 02:02:15,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:15,873 INFO:     Epoch: 27
2022-11-28 02:02:16,615 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41812269508161326, 'Total loss': 0.41812269508161326} | train loss {'Reaction outcome loss': 0.32385518830649707, 'Total loss': 0.32385518830649707}
2022-11-28 02:02:16,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:16,615 INFO:     Epoch: 28
2022-11-28 02:02:17,359 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42127960395406594, 'Total loss': 0.42127960395406594} | train loss {'Reaction outcome loss': 0.3302094714982169, 'Total loss': 0.3302094714982169}
2022-11-28 02:02:17,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:17,360 INFO:     Epoch: 29
2022-11-28 02:02:18,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44291229063475673, 'Total loss': 0.44291229063475673} | train loss {'Reaction outcome loss': 0.31697381239156336, 'Total loss': 0.31697381239156336}
2022-11-28 02:02:18,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:18,106 INFO:     Epoch: 30
2022-11-28 02:02:18,852 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3896221410144459, 'Total loss': 0.3896221410144459} | train loss {'Reaction outcome loss': 0.32472846702653535, 'Total loss': 0.32472846702653535}
2022-11-28 02:02:18,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:18,853 INFO:     Epoch: 31
2022-11-28 02:02:19,601 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4178911809894172, 'Total loss': 0.4178911809894172} | train loss {'Reaction outcome loss': 0.32588355100276517, 'Total loss': 0.32588355100276517}
2022-11-28 02:02:19,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:19,601 INFO:     Epoch: 32
2022-11-28 02:02:20,344 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40992252850397065, 'Total loss': 0.40992252850397065} | train loss {'Reaction outcome loss': 0.32476038472080715, 'Total loss': 0.32476038472080715}
2022-11-28 02:02:20,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:20,345 INFO:     Epoch: 33
2022-11-28 02:02:21,089 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4156749478795312, 'Total loss': 0.4156749478795312} | train loss {'Reaction outcome loss': 0.31911212943342265, 'Total loss': 0.31911212943342265}
2022-11-28 02:02:21,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:21,089 INFO:     Epoch: 34
2022-11-28 02:02:21,832 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43639521300792694, 'Total loss': 0.43639521300792694} | train loss {'Reaction outcome loss': 0.31873046266181126, 'Total loss': 0.31873046266181126}
2022-11-28 02:02:21,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:21,832 INFO:     Epoch: 35
2022-11-28 02:02:22,576 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4096869115125049, 'Total loss': 0.4096869115125049} | train loss {'Reaction outcome loss': 0.31816896507326436, 'Total loss': 0.31816896507326436}
2022-11-28 02:02:22,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:22,577 INFO:     Epoch: 36
2022-11-28 02:02:23,318 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4297183167866685, 'Total loss': 0.4297183167866685} | train loss {'Reaction outcome loss': 0.32276329921976643, 'Total loss': 0.32276329921976643}
2022-11-28 02:02:23,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:23,318 INFO:     Epoch: 37
2022-11-28 02:02:24,059 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37714401550527493, 'Total loss': 0.37714401550527493} | train loss {'Reaction outcome loss': 0.3219787879865997, 'Total loss': 0.3219787879865997}
2022-11-28 02:02:24,059 INFO:     Found new best model at epoch 37
2022-11-28 02:02:24,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:24,060 INFO:     Epoch: 38
2022-11-28 02:02:24,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3969255096533082, 'Total loss': 0.3969255096533082} | train loss {'Reaction outcome loss': 0.31909732140448627, 'Total loss': 0.31909732140448627}
2022-11-28 02:02:24,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:24,806 INFO:     Epoch: 39
2022-11-28 02:02:25,553 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42426003447987815, 'Total loss': 0.42426003447987815} | train loss {'Reaction outcome loss': 0.3278605225438974, 'Total loss': 0.3278605225438974}
2022-11-28 02:02:25,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:25,553 INFO:     Epoch: 40
2022-11-28 02:02:26,296 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43491201305931265, 'Total loss': 0.43491201305931265} | train loss {'Reaction outcome loss': 0.33070760722063025, 'Total loss': 0.33070760722063025}
2022-11-28 02:02:26,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:26,296 INFO:     Epoch: 41
2022-11-28 02:02:27,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42875243655659934, 'Total loss': 0.42875243655659934} | train loss {'Reaction outcome loss': 0.3191206259082775, 'Total loss': 0.3191206259082775}
2022-11-28 02:02:27,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:27,040 INFO:     Epoch: 42
2022-11-28 02:02:27,784 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4396730625832623, 'Total loss': 0.4396730625832623} | train loss {'Reaction outcome loss': 0.31745933712441093, 'Total loss': 0.31745933712441093}
2022-11-28 02:02:27,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:27,784 INFO:     Epoch: 43
2022-11-28 02:02:28,526 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42295109514485707, 'Total loss': 0.42295109514485707} | train loss {'Reaction outcome loss': 0.31107209963457927, 'Total loss': 0.31107209963457927}
2022-11-28 02:02:28,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:28,526 INFO:     Epoch: 44
2022-11-28 02:02:29,271 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3874625883657824, 'Total loss': 0.3874625883657824} | train loss {'Reaction outcome loss': 0.30814633489567406, 'Total loss': 0.30814633489567406}
2022-11-28 02:02:29,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:29,271 INFO:     Epoch: 45
2022-11-28 02:02:30,011 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39183318140831863, 'Total loss': 0.39183318140831863} | train loss {'Reaction outcome loss': 0.31436937898397443, 'Total loss': 0.31436937898397443}
2022-11-28 02:02:30,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:30,012 INFO:     Epoch: 46
2022-11-28 02:02:30,756 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39018786304884334, 'Total loss': 0.39018786304884334} | train loss {'Reaction outcome loss': 0.3085736090431408, 'Total loss': 0.3085736090431408}
2022-11-28 02:02:30,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:30,756 INFO:     Epoch: 47
2022-11-28 02:02:31,497 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4027827534485947, 'Total loss': 0.4027827534485947} | train loss {'Reaction outcome loss': 0.31390100744914035, 'Total loss': 0.31390100744914035}
2022-11-28 02:02:31,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:31,498 INFO:     Epoch: 48
2022-11-28 02:02:32,242 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40008083460005844, 'Total loss': 0.40008083460005844} | train loss {'Reaction outcome loss': 0.3101323915683493, 'Total loss': 0.3101323915683493}
2022-11-28 02:02:32,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:32,243 INFO:     Epoch: 49
2022-11-28 02:02:32,985 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3894341222793711, 'Total loss': 0.3894341222793711} | train loss {'Reaction outcome loss': 0.31086877526677387, 'Total loss': 0.31086877526677387}
2022-11-28 02:02:32,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:32,986 INFO:     Epoch: 50
2022-11-28 02:02:33,733 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3822054256769744, 'Total loss': 0.3822054256769744} | train loss {'Reaction outcome loss': 0.3154614228375104, 'Total loss': 0.3154614228375104}
2022-11-28 02:02:33,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:33,733 INFO:     Epoch: 51
2022-11-28 02:02:34,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3998591231012886, 'Total loss': 0.3998591231012886} | train loss {'Reaction outcome loss': 0.319955102977704, 'Total loss': 0.319955102977704}
2022-11-28 02:02:34,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:34,484 INFO:     Epoch: 52
2022-11-28 02:02:35,234 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4052461991933259, 'Total loss': 0.4052461991933259} | train loss {'Reaction outcome loss': 0.31259401224705635, 'Total loss': 0.31259401224705635}
2022-11-28 02:02:35,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:35,234 INFO:     Epoch: 53
2022-11-28 02:02:35,979 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42251811041073367, 'Total loss': 0.42251811041073367} | train loss {'Reaction outcome loss': 0.31349517030983554, 'Total loss': 0.31349517030983554}
2022-11-28 02:02:35,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:35,980 INFO:     Epoch: 54
2022-11-28 02:02:36,736 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39132537573194975, 'Total loss': 0.39132537573194975} | train loss {'Reaction outcome loss': 0.3107272657204647, 'Total loss': 0.3107272657204647}
2022-11-28 02:02:36,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:36,737 INFO:     Epoch: 55
2022-11-28 02:02:37,494 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40249626541679556, 'Total loss': 0.40249626541679556} | train loss {'Reaction outcome loss': 0.3028533193225763, 'Total loss': 0.3028533193225763}
2022-11-28 02:02:37,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:37,494 INFO:     Epoch: 56
2022-11-28 02:02:38,247 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3964714993807403, 'Total loss': 0.3964714993807403} | train loss {'Reaction outcome loss': 0.3071028028519786, 'Total loss': 0.3071028028519786}
2022-11-28 02:02:38,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:38,248 INFO:     Epoch: 57
2022-11-28 02:02:39,002 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42628002945672383, 'Total loss': 0.42628002945672383} | train loss {'Reaction outcome loss': 0.3061410237635885, 'Total loss': 0.3061410237635885}
2022-11-28 02:02:39,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:39,002 INFO:     Epoch: 58
2022-11-28 02:02:39,754 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4199836775660515, 'Total loss': 0.4199836775660515} | train loss {'Reaction outcome loss': 0.31319768054752933, 'Total loss': 0.31319768054752933}
2022-11-28 02:02:39,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:39,755 INFO:     Epoch: 59
2022-11-28 02:02:40,510 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41618262739344075, 'Total loss': 0.41618262739344075} | train loss {'Reaction outcome loss': 0.3142807973738836, 'Total loss': 0.3142807973738836}
2022-11-28 02:02:40,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:40,510 INFO:     Epoch: 60
2022-11-28 02:02:41,267 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40840538997541775, 'Total loss': 0.40840538997541775} | train loss {'Reaction outcome loss': 0.30676551068923913, 'Total loss': 0.30676551068923913}
2022-11-28 02:02:41,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:41,268 INFO:     Epoch: 61
2022-11-28 02:02:42,020 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39035479859872296, 'Total loss': 0.39035479859872296} | train loss {'Reaction outcome loss': 0.30590987984015017, 'Total loss': 0.30590987984015017}
2022-11-28 02:02:42,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:42,020 INFO:     Epoch: 62
2022-11-28 02:02:42,773 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38219803029840643, 'Total loss': 0.38219803029840643} | train loss {'Reaction outcome loss': 0.30142549528759355, 'Total loss': 0.30142549528759355}
2022-11-28 02:02:42,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:42,773 INFO:     Epoch: 63
2022-11-28 02:02:43,528 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40782419947737997, 'Total loss': 0.40782419947737997} | train loss {'Reaction outcome loss': 0.3043521401681462, 'Total loss': 0.3043521401681462}
2022-11-28 02:02:43,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:43,528 INFO:     Epoch: 64
2022-11-28 02:02:44,282 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39361892809922044, 'Total loss': 0.39361892809922044} | train loss {'Reaction outcome loss': 0.305444220240627, 'Total loss': 0.305444220240627}
2022-11-28 02:02:44,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:44,282 INFO:     Epoch: 65
2022-11-28 02:02:45,040 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41964092528955504, 'Total loss': 0.41964092528955504} | train loss {'Reaction outcome loss': 0.3000821204209814, 'Total loss': 0.3000821204209814}
2022-11-28 02:02:45,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:45,040 INFO:     Epoch: 66
2022-11-28 02:02:45,796 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3992061706429178, 'Total loss': 0.3992061706429178} | train loss {'Reaction outcome loss': 0.3159336971537191, 'Total loss': 0.3159336971537191}
2022-11-28 02:02:45,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:45,796 INFO:     Epoch: 67
2022-11-28 02:02:46,552 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3922227787869898, 'Total loss': 0.3922227787869898} | train loss {'Reaction outcome loss': 0.301496768301847, 'Total loss': 0.301496768301847}
2022-11-28 02:02:46,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:46,552 INFO:     Epoch: 68
2022-11-28 02:02:47,306 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38486799360676244, 'Total loss': 0.38486799360676244} | train loss {'Reaction outcome loss': 0.30212070479684944, 'Total loss': 0.30212070479684944}
2022-11-28 02:02:47,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:47,306 INFO:     Epoch: 69
2022-11-28 02:02:48,064 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40533725172281265, 'Total loss': 0.40533725172281265} | train loss {'Reaction outcome loss': 0.3075999405615184, 'Total loss': 0.3075999405615184}
2022-11-28 02:02:48,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:48,064 INFO:     Epoch: 70
2022-11-28 02:02:48,818 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3883177793838761, 'Total loss': 0.3883177793838761} | train loss {'Reaction outcome loss': 0.3102800291259678, 'Total loss': 0.3102800291259678}
2022-11-28 02:02:48,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:48,819 INFO:     Epoch: 71
2022-11-28 02:02:49,575 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3939638950607993, 'Total loss': 0.3939638950607993} | train loss {'Reaction outcome loss': 0.30119806339546124, 'Total loss': 0.30119806339546124}
2022-11-28 02:02:49,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:49,576 INFO:     Epoch: 72
2022-11-28 02:02:50,335 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37602775408463046, 'Total loss': 0.37602775408463046} | train loss {'Reaction outcome loss': 0.3031958314229031, 'Total loss': 0.3031958314229031}
2022-11-28 02:02:50,335 INFO:     Found new best model at epoch 72
2022-11-28 02:02:50,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:50,336 INFO:     Epoch: 73
2022-11-28 02:02:51,093 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3874045242978768, 'Total loss': 0.3874045242978768} | train loss {'Reaction outcome loss': 0.29920149591504314, 'Total loss': 0.29920149591504314}
2022-11-28 02:02:51,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:51,094 INFO:     Epoch: 74
2022-11-28 02:02:51,848 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38696117394349794, 'Total loss': 0.38696117394349794} | train loss {'Reaction outcome loss': 0.3003492692295386, 'Total loss': 0.3003492692295386}
2022-11-28 02:02:51,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:51,849 INFO:     Epoch: 75
2022-11-28 02:02:52,602 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42880887673659757, 'Total loss': 0.42880887673659757} | train loss {'Reaction outcome loss': 0.3117725098011445, 'Total loss': 0.3117725098011445}
2022-11-28 02:02:52,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:52,602 INFO:     Epoch: 76
2022-11-28 02:02:53,359 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4252970567481084, 'Total loss': 0.4252970567481084} | train loss {'Reaction outcome loss': 0.31230416589853716, 'Total loss': 0.31230416589853716}
2022-11-28 02:02:53,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:53,359 INFO:     Epoch: 77
2022-11-28 02:02:54,118 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4546110951765017, 'Total loss': 0.4546110951765017} | train loss {'Reaction outcome loss': 0.3140472997512136, 'Total loss': 0.3140472997512136}
2022-11-28 02:02:54,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:54,118 INFO:     Epoch: 78
2022-11-28 02:02:54,872 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3981029348955913, 'Total loss': 0.3981029348955913} | train loss {'Reaction outcome loss': 0.30873553874541304, 'Total loss': 0.30873553874541304}
2022-11-28 02:02:54,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:54,873 INFO:     Epoch: 79
2022-11-28 02:02:55,630 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4166032939471982, 'Total loss': 0.4166032939471982} | train loss {'Reaction outcome loss': 0.3063770533368296, 'Total loss': 0.3063770533368296}
2022-11-28 02:02:55,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:55,631 INFO:     Epoch: 80
2022-11-28 02:02:56,383 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3904902381314473, 'Total loss': 0.3904902381314473} | train loss {'Reaction outcome loss': 0.3064760271992002, 'Total loss': 0.3064760271992002}
2022-11-28 02:02:56,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:56,383 INFO:     Epoch: 81
2022-11-28 02:02:57,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4280219260941852, 'Total loss': 0.4280219260941852} | train loss {'Reaction outcome loss': 0.3047180885715144, 'Total loss': 0.3047180885715144}
2022-11-28 02:02:57,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:57,140 INFO:     Epoch: 82
2022-11-28 02:02:57,893 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4272023629058491, 'Total loss': 0.4272023629058491} | train loss {'Reaction outcome loss': 0.30647039215783684, 'Total loss': 0.30647039215783684}
2022-11-28 02:02:57,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:57,893 INFO:     Epoch: 83
2022-11-28 02:02:58,647 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4299814694307067, 'Total loss': 0.4299814694307067} | train loss {'Reaction outcome loss': 0.3231483296624252, 'Total loss': 0.3231483296624252}
2022-11-28 02:02:58,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:58,647 INFO:     Epoch: 84
2022-11-28 02:02:59,403 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.387372035194527, 'Total loss': 0.387372035194527} | train loss {'Reaction outcome loss': 0.30897493721271047, 'Total loss': 0.30897493721271047}
2022-11-28 02:02:59,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:02:59,403 INFO:     Epoch: 85
2022-11-28 02:03:00,159 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3929095163264058, 'Total loss': 0.3929095163264058} | train loss {'Reaction outcome loss': 0.3119694165733396, 'Total loss': 0.3119694165733396}
2022-11-28 02:03:00,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:00,160 INFO:     Epoch: 86
2022-11-28 02:03:00,909 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43086721714247356, 'Total loss': 0.43086721714247356} | train loss {'Reaction outcome loss': 0.30662058461077357, 'Total loss': 0.30662058461077357}
2022-11-28 02:03:00,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:00,910 INFO:     Epoch: 87
2022-11-28 02:03:01,662 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4129676451398568, 'Total loss': 0.4129676451398568} | train loss {'Reaction outcome loss': 0.3097422728733141, 'Total loss': 0.3097422728733141}
2022-11-28 02:03:01,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:01,662 INFO:     Epoch: 88
2022-11-28 02:03:02,416 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41503958556462417, 'Total loss': 0.41503958556462417} | train loss {'Reaction outcome loss': 0.292584533563682, 'Total loss': 0.292584533563682}
2022-11-28 02:03:02,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:02,416 INFO:     Epoch: 89
2022-11-28 02:03:03,169 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42230861871079967, 'Total loss': 0.42230861871079967} | train loss {'Reaction outcome loss': 0.30699360887615046, 'Total loss': 0.30699360887615046}
2022-11-28 02:03:03,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:03,169 INFO:     Epoch: 90
2022-11-28 02:03:03,927 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4600898173045028, 'Total loss': 0.4600898173045028} | train loss {'Reaction outcome loss': 0.2963827409762509, 'Total loss': 0.2963827409762509}
2022-11-28 02:03:03,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:03,927 INFO:     Epoch: 91
2022-11-28 02:03:04,683 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43698813224380667, 'Total loss': 0.43698813224380667} | train loss {'Reaction outcome loss': 0.3068533756295029, 'Total loss': 0.3068533756295029}
2022-11-28 02:03:04,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:04,683 INFO:     Epoch: 92
2022-11-28 02:03:05,439 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3989472529872067, 'Total loss': 0.3989472529872067} | train loss {'Reaction outcome loss': 0.2976732459603524, 'Total loss': 0.2976732459603524}
2022-11-28 02:03:05,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:05,439 INFO:     Epoch: 93
2022-11-28 02:03:06,191 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4184050817381252, 'Total loss': 0.4184050817381252} | train loss {'Reaction outcome loss': 0.30451176367243943, 'Total loss': 0.30451176367243943}
2022-11-28 02:03:06,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:06,191 INFO:     Epoch: 94
2022-11-28 02:03:06,946 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.413354793055491, 'Total loss': 0.413354793055491} | train loss {'Reaction outcome loss': 0.295714959836736, 'Total loss': 0.295714959836736}
2022-11-28 02:03:06,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:06,947 INFO:     Epoch: 95
2022-11-28 02:03:07,700 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40508098087527533, 'Total loss': 0.40508098087527533} | train loss {'Reaction outcome loss': 0.30119202950475166, 'Total loss': 0.30119202950475166}
2022-11-28 02:03:07,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:07,701 INFO:     Epoch: 96
2022-11-28 02:03:08,456 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41035230965776875, 'Total loss': 0.41035230965776875} | train loss {'Reaction outcome loss': 0.29684207159645704, 'Total loss': 0.29684207159645704}
2022-11-28 02:03:08,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:08,456 INFO:     Epoch: 97
2022-11-28 02:03:09,211 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4339531240138141, 'Total loss': 0.4339531240138141} | train loss {'Reaction outcome loss': 0.2971763882862062, 'Total loss': 0.2971763882862062}
2022-11-28 02:03:09,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:09,211 INFO:     Epoch: 98
2022-11-28 02:03:09,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40037737278775737, 'Total loss': 0.40037737278775737} | train loss {'Reaction outcome loss': 0.3085040627997749, 'Total loss': 0.3085040627997749}
2022-11-28 02:03:09,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:09,971 INFO:     Epoch: 99
2022-11-28 02:03:10,726 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40405105088244786, 'Total loss': 0.40405105088244786} | train loss {'Reaction outcome loss': 0.29656585162999677, 'Total loss': 0.29656585162999677}
2022-11-28 02:03:10,726 INFO:     Best model found after epoch 73 of 100.
2022-11-28 02:03:10,726 INFO:   Done with stage: TRAINING
2022-11-28 02:03:10,726 INFO:   Starting stage: EVALUATION
2022-11-28 02:03:10,857 INFO:   Done with stage: EVALUATION
2022-11-28 02:03:10,857 INFO:   Leaving out SEQ value Fold_7
2022-11-28 02:03:10,869 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:03:10,869 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:03:11,522 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:03:11,523 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:03:11,590 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:03:11,591 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:03:11,591 INFO:     No hyperparam tuning for this model
2022-11-28 02:03:11,591 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:03:11,591 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:03:11,591 INFO:     None feature selector for col prot
2022-11-28 02:03:11,592 INFO:     None feature selector for col prot
2022-11-28 02:03:11,592 INFO:     None feature selector for col prot
2022-11-28 02:03:11,592 INFO:     None feature selector for col chem
2022-11-28 02:03:11,592 INFO:     None feature selector for col chem
2022-11-28 02:03:11,592 INFO:     None feature selector for col chem
2022-11-28 02:03:11,592 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:03:11,592 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:03:11,594 INFO:     Number of params in model 169741
2022-11-28 02:03:11,597 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:03:11,597 INFO:   Starting stage: TRAINING
2022-11-28 02:03:11,652 INFO:     Val loss before train {'Reaction outcome loss': 1.0387741232460195, 'Total loss': 1.0387741232460195}
2022-11-28 02:03:11,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:11,652 INFO:     Epoch: 0
2022-11-28 02:03:12,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5361271141604944, 'Total loss': 0.5361271141604944} | train loss {'Reaction outcome loss': 0.62668438718027, 'Total loss': 0.62668438718027}
2022-11-28 02:03:12,410 INFO:     Found new best model at epoch 0
2022-11-28 02:03:12,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:12,411 INFO:     Epoch: 1
2022-11-28 02:03:13,169 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5397055768831209, 'Total loss': 0.5397055768831209} | train loss {'Reaction outcome loss': 0.4964193382433483, 'Total loss': 0.4964193382433483}
2022-11-28 02:03:13,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:13,169 INFO:     Epoch: 2
2022-11-28 02:03:13,921 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47713696550239215, 'Total loss': 0.47713696550239215} | train loss {'Reaction outcome loss': 0.4610787498707674, 'Total loss': 0.4610787498707674}
2022-11-28 02:03:13,922 INFO:     Found new best model at epoch 2
2022-11-28 02:03:13,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:13,922 INFO:     Epoch: 3
2022-11-28 02:03:14,680 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5334837538274851, 'Total loss': 0.5334837538274851} | train loss {'Reaction outcome loss': 0.4349449654014743, 'Total loss': 0.4349449654014743}
2022-11-28 02:03:14,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:14,680 INFO:     Epoch: 4
2022-11-28 02:03:15,437 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47305210916833446, 'Total loss': 0.47305210916833446} | train loss {'Reaction outcome loss': 0.42461482605763845, 'Total loss': 0.42461482605763845}
2022-11-28 02:03:15,437 INFO:     Found new best model at epoch 4
2022-11-28 02:03:15,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:15,438 INFO:     Epoch: 5
2022-11-28 02:03:16,193 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47381244938481937, 'Total loss': 0.47381244938481937} | train loss {'Reaction outcome loss': 0.41116668487689934, 'Total loss': 0.41116668487689934}
2022-11-28 02:03:16,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:16,193 INFO:     Epoch: 6
2022-11-28 02:03:16,950 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4846508949995041, 'Total loss': 0.4846508949995041} | train loss {'Reaction outcome loss': 0.40620350189963167, 'Total loss': 0.40620350189963167}
2022-11-28 02:03:16,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:16,950 INFO:     Epoch: 7
2022-11-28 02:03:17,702 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5386728935621001, 'Total loss': 0.5386728935621001} | train loss {'Reaction outcome loss': 0.3987105306922173, 'Total loss': 0.3987105306922173}
2022-11-28 02:03:17,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:17,702 INFO:     Epoch: 8
2022-11-28 02:03:18,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.449747004292228, 'Total loss': 0.449747004292228} | train loss {'Reaction outcome loss': 0.3854023227278067, 'Total loss': 0.3854023227278067}
2022-11-28 02:03:18,457 INFO:     Found new best model at epoch 8
2022-11-28 02:03:18,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:18,458 INFO:     Epoch: 9
2022-11-28 02:03:19,214 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4645017840984193, 'Total loss': 0.4645017840984193} | train loss {'Reaction outcome loss': 0.3827646464109421, 'Total loss': 0.3827646464109421}
2022-11-28 02:03:19,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:19,215 INFO:     Epoch: 10
2022-11-28 02:03:19,966 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41426693377169693, 'Total loss': 0.41426693377169693} | train loss {'Reaction outcome loss': 0.38391169838759365, 'Total loss': 0.38391169838759365}
2022-11-28 02:03:19,966 INFO:     Found new best model at epoch 10
2022-11-28 02:03:19,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:19,967 INFO:     Epoch: 11
2022-11-28 02:03:20,723 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42373104054819455, 'Total loss': 0.42373104054819455} | train loss {'Reaction outcome loss': 0.37433819363311843, 'Total loss': 0.37433819363311843}
2022-11-28 02:03:20,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:20,723 INFO:     Epoch: 12
2022-11-28 02:03:21,480 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4283422780307857, 'Total loss': 0.4283422780307857} | train loss {'Reaction outcome loss': 0.363030947896899, 'Total loss': 0.363030947896899}
2022-11-28 02:03:21,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:21,480 INFO:     Epoch: 13
2022-11-28 02:03:22,232 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.423854737457904, 'Total loss': 0.423854737457904} | train loss {'Reaction outcome loss': 0.3696975528281562, 'Total loss': 0.3696975528281562}
2022-11-28 02:03:22,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:22,233 INFO:     Epoch: 14
2022-11-28 02:03:22,987 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43314676018516446, 'Total loss': 0.43314676018516446} | train loss {'Reaction outcome loss': 0.3535603255945809, 'Total loss': 0.3535603255945809}
2022-11-28 02:03:22,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:22,988 INFO:     Epoch: 15
2022-11-28 02:03:23,743 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4317043779248541, 'Total loss': 0.4317043779248541} | train loss {'Reaction outcome loss': 0.3600129261612892, 'Total loss': 0.3600129261612892}
2022-11-28 02:03:23,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:23,743 INFO:     Epoch: 16
2022-11-28 02:03:24,499 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4007660299539566, 'Total loss': 0.4007660299539566} | train loss {'Reaction outcome loss': 0.3514312073284266, 'Total loss': 0.3514312073284266}
2022-11-28 02:03:24,499 INFO:     Found new best model at epoch 16
2022-11-28 02:03:24,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:24,500 INFO:     Epoch: 17
2022-11-28 02:03:25,256 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44273195280270145, 'Total loss': 0.44273195280270145} | train loss {'Reaction outcome loss': 0.3481097825631803, 'Total loss': 0.3481097825631803}
2022-11-28 02:03:25,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:25,257 INFO:     Epoch: 18
2022-11-28 02:03:26,011 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4483048536560752, 'Total loss': 0.4483048536560752} | train loss {'Reaction outcome loss': 0.34345919985552226, 'Total loss': 0.34345919985552226}
2022-11-28 02:03:26,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:26,011 INFO:     Epoch: 19
2022-11-28 02:03:26,764 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42854222892360255, 'Total loss': 0.42854222892360255} | train loss {'Reaction outcome loss': 0.3399829066529566, 'Total loss': 0.3399829066529566}
2022-11-28 02:03:26,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:26,764 INFO:     Epoch: 20
2022-11-28 02:03:27,517 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4251163527369499, 'Total loss': 0.4251163527369499} | train loss {'Reaction outcome loss': 0.3452872942905037, 'Total loss': 0.3452872942905037}
2022-11-28 02:03:27,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:27,518 INFO:     Epoch: 21
2022-11-28 02:03:28,275 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42534121024337684, 'Total loss': 0.42534121024337684} | train loss {'Reaction outcome loss': 0.33920744541956455, 'Total loss': 0.33920744541956455}
2022-11-28 02:03:28,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:28,276 INFO:     Epoch: 22
2022-11-28 02:03:29,031 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43628738007762213, 'Total loss': 0.43628738007762213} | train loss {'Reaction outcome loss': 0.349023934864268, 'Total loss': 0.349023934864268}
2022-11-28 02:03:29,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:29,031 INFO:     Epoch: 23
2022-11-28 02:03:29,783 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43765187568285246, 'Total loss': 0.43765187568285246} | train loss {'Reaction outcome loss': 0.3314484218857726, 'Total loss': 0.3314484218857726}
2022-11-28 02:03:29,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:29,783 INFO:     Epoch: 24
2022-11-28 02:03:30,540 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41411998063664546, 'Total loss': 0.41411998063664546} | train loss {'Reaction outcome loss': 0.34043783737080435, 'Total loss': 0.34043783737080435}
2022-11-28 02:03:30,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:30,541 INFO:     Epoch: 25
2022-11-28 02:03:31,295 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4629498327320272, 'Total loss': 0.4629498327320272} | train loss {'Reaction outcome loss': 0.32720826110061335, 'Total loss': 0.32720826110061335}
2022-11-28 02:03:31,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:31,295 INFO:     Epoch: 26
2022-11-28 02:03:32,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.437974579970945, 'Total loss': 0.437974579970945} | train loss {'Reaction outcome loss': 0.33365552419302413, 'Total loss': 0.33365552419302413}
2022-11-28 02:03:32,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:32,053 INFO:     Epoch: 27
2022-11-28 02:03:32,809 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43351308290253987, 'Total loss': 0.43351308290253987} | train loss {'Reaction outcome loss': 0.3240157140761006, 'Total loss': 0.3240157140761006}
2022-11-28 02:03:32,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:32,809 INFO:     Epoch: 28
2022-11-28 02:03:33,564 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42426221106540074, 'Total loss': 0.42426221106540074} | train loss {'Reaction outcome loss': 0.3310893548690543, 'Total loss': 0.3310893548690543}
2022-11-28 02:03:33,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:33,564 INFO:     Epoch: 29
2022-11-28 02:03:34,328 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4284958145157857, 'Total loss': 0.4284958145157857} | train loss {'Reaction outcome loss': 0.3285827617560114, 'Total loss': 0.3285827617560114}
2022-11-28 02:03:34,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:34,328 INFO:     Epoch: 30
2022-11-28 02:03:35,085 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40392188931053336, 'Total loss': 0.40392188931053336} | train loss {'Reaction outcome loss': 0.3142621332285356, 'Total loss': 0.3142621332285356}
2022-11-28 02:03:35,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:35,085 INFO:     Epoch: 31
2022-11-28 02:03:35,841 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41810801726850594, 'Total loss': 0.41810801726850594} | train loss {'Reaction outcome loss': 0.3261280693569962, 'Total loss': 0.3261280693569962}
2022-11-28 02:03:35,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:35,841 INFO:     Epoch: 32
2022-11-28 02:03:36,600 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40556494654579595, 'Total loss': 0.40556494654579595} | train loss {'Reaction outcome loss': 0.3280087597820224, 'Total loss': 0.3280087597820224}
2022-11-28 02:03:36,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:36,600 INFO:     Epoch: 33
2022-11-28 02:03:37,355 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41711638969453896, 'Total loss': 0.41711638969453896} | train loss {'Reaction outcome loss': 0.3236645227792312, 'Total loss': 0.3236645227792312}
2022-11-28 02:03:37,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:37,356 INFO:     Epoch: 34
2022-11-28 02:03:38,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4175406467508186, 'Total loss': 0.4175406467508186} | train loss {'Reaction outcome loss': 0.332643314040437, 'Total loss': 0.332643314040437}
2022-11-28 02:03:38,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:38,120 INFO:     Epoch: 35
2022-11-28 02:03:38,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4161997979337519, 'Total loss': 0.4161997979337519} | train loss {'Reaction outcome loss': 0.3186757258614715, 'Total loss': 0.3186757258614715}
2022-11-28 02:03:38,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:38,878 INFO:     Epoch: 36
2022-11-28 02:03:39,632 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4172590354626829, 'Total loss': 0.4172590354626829} | train loss {'Reaction outcome loss': 0.32068611103661204, 'Total loss': 0.32068611103661204}
2022-11-28 02:03:39,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:39,633 INFO:     Epoch: 37
2022-11-28 02:03:40,389 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4303910841276361, 'Total loss': 0.4303910841276361} | train loss {'Reaction outcome loss': 0.3162389994884024, 'Total loss': 0.3162389994884024}
2022-11-28 02:03:40,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:40,389 INFO:     Epoch: 38
2022-11-28 02:03:41,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4147260622544722, 'Total loss': 0.4147260622544722} | train loss {'Reaction outcome loss': 0.3247373343730459, 'Total loss': 0.3247373343730459}
2022-11-28 02:03:41,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:41,144 INFO:     Epoch: 39
2022-11-28 02:03:41,899 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42998856780203903, 'Total loss': 0.42998856780203903} | train loss {'Reaction outcome loss': 0.31076672992536, 'Total loss': 0.31076672992536}
2022-11-28 02:03:41,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:41,900 INFO:     Epoch: 40
2022-11-28 02:03:42,655 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43551031161438336, 'Total loss': 0.43551031161438336} | train loss {'Reaction outcome loss': 0.32087271929699546, 'Total loss': 0.32087271929699546}
2022-11-28 02:03:42,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:42,655 INFO:     Epoch: 41
2022-11-28 02:03:43,408 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4222697527571158, 'Total loss': 0.4222697527571158} | train loss {'Reaction outcome loss': 0.3195538457863185, 'Total loss': 0.3195538457863185}
2022-11-28 02:03:43,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:43,408 INFO:     Epoch: 42
2022-11-28 02:03:44,163 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4165467582643032, 'Total loss': 0.4165467582643032} | train loss {'Reaction outcome loss': 0.3202772414805938, 'Total loss': 0.3202772414805938}
2022-11-28 02:03:44,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:44,163 INFO:     Epoch: 43
2022-11-28 02:03:44,917 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42406920004974713, 'Total loss': 0.42406920004974713} | train loss {'Reaction outcome loss': 0.3111926247118687, 'Total loss': 0.3111926247118687}
2022-11-28 02:03:44,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:44,917 INFO:     Epoch: 44
2022-11-28 02:03:45,672 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4164698394862088, 'Total loss': 0.4164698394862088} | train loss {'Reaction outcome loss': 0.32236449271440504, 'Total loss': 0.32236449271440504}
2022-11-28 02:03:45,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:45,673 INFO:     Epoch: 45
2022-11-28 02:03:46,432 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4139782041311264, 'Total loss': 0.4139782041311264} | train loss {'Reaction outcome loss': 0.3161308891310984, 'Total loss': 0.3161308891310984}
2022-11-28 02:03:46,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:46,432 INFO:     Epoch: 46
2022-11-28 02:03:47,189 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4391259014267813, 'Total loss': 0.4391259014267813} | train loss {'Reaction outcome loss': 0.32362878076276, 'Total loss': 0.32362878076276}
2022-11-28 02:03:47,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:47,189 INFO:     Epoch: 47
2022-11-28 02:03:47,948 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44099937726489524, 'Total loss': 0.44099937726489524} | train loss {'Reaction outcome loss': 0.314189629864936, 'Total loss': 0.314189629864936}
2022-11-28 02:03:47,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:47,948 INFO:     Epoch: 48
2022-11-28 02:03:48,702 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4256601980464025, 'Total loss': 0.4256601980464025} | train loss {'Reaction outcome loss': 0.3184206260102136, 'Total loss': 0.3184206260102136}
2022-11-28 02:03:48,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:48,702 INFO:     Epoch: 49
2022-11-28 02:03:49,456 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4167922951958396, 'Total loss': 0.4167922951958396} | train loss {'Reaction outcome loss': 0.31223673685168735, 'Total loss': 0.31223673685168735}
2022-11-28 02:03:49,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:49,457 INFO:     Epoch: 50
2022-11-28 02:03:50,213 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4010662690482356, 'Total loss': 0.4010662690482356} | train loss {'Reaction outcome loss': 0.3126580423086273, 'Total loss': 0.3126580423086273}
2022-11-28 02:03:50,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:50,214 INFO:     Epoch: 51
2022-11-28 02:03:50,972 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4154948209497062, 'Total loss': 0.4154948209497062} | train loss {'Reaction outcome loss': 0.3100682057288228, 'Total loss': 0.3100682057288228}
2022-11-28 02:03:50,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:50,973 INFO:     Epoch: 52
2022-11-28 02:03:51,735 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4084350361742757, 'Total loss': 0.4084350361742757} | train loss {'Reaction outcome loss': 0.3117437943207974, 'Total loss': 0.3117437943207974}
2022-11-28 02:03:51,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:51,735 INFO:     Epoch: 53
2022-11-28 02:03:52,489 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42058299312537367, 'Total loss': 0.42058299312537367} | train loss {'Reaction outcome loss': 0.31580039714368024, 'Total loss': 0.31580039714368024}
2022-11-28 02:03:52,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:52,489 INFO:     Epoch: 54
2022-11-28 02:03:53,242 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44244418073106895, 'Total loss': 0.44244418073106895} | train loss {'Reaction outcome loss': 0.3196744191707397, 'Total loss': 0.3196744191707397}
2022-11-28 02:03:53,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:53,242 INFO:     Epoch: 55
2022-11-28 02:03:53,998 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4232057194140824, 'Total loss': 0.4232057194140824} | train loss {'Reaction outcome loss': 0.3210217436053315, 'Total loss': 0.3210217436053315}
2022-11-28 02:03:53,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:53,999 INFO:     Epoch: 56
2022-11-28 02:03:54,759 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44065926698121155, 'Total loss': 0.44065926698121155} | train loss {'Reaction outcome loss': 0.30081249136401683, 'Total loss': 0.30081249136401683}
2022-11-28 02:03:54,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:54,759 INFO:     Epoch: 57
2022-11-28 02:03:55,516 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4328335286541419, 'Total loss': 0.4328335286541419} | train loss {'Reaction outcome loss': 0.31704405692158916, 'Total loss': 0.31704405692158916}
2022-11-28 02:03:55,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:55,516 INFO:     Epoch: 58
2022-11-28 02:03:56,275 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.430368189107288, 'Total loss': 0.430368189107288} | train loss {'Reaction outcome loss': 0.31205451987227617, 'Total loss': 0.31205451987227617}
2022-11-28 02:03:56,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:56,275 INFO:     Epoch: 59
2022-11-28 02:03:57,034 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43781471777368675, 'Total loss': 0.43781471777368675} | train loss {'Reaction outcome loss': 0.3093540800165157, 'Total loss': 0.3093540800165157}
2022-11-28 02:03:57,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:57,035 INFO:     Epoch: 60
2022-11-28 02:03:57,789 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4411136531694369, 'Total loss': 0.4411136531694369} | train loss {'Reaction outcome loss': 0.309459573212935, 'Total loss': 0.309459573212935}
2022-11-28 02:03:57,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:57,789 INFO:     Epoch: 61
2022-11-28 02:03:58,544 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4267026754942807, 'Total loss': 0.4267026754942807} | train loss {'Reaction outcome loss': 0.30999331154993603, 'Total loss': 0.30999331154993603}
2022-11-28 02:03:58,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:58,544 INFO:     Epoch: 62
2022-11-28 02:03:59,301 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40618637830696325, 'Total loss': 0.40618637830696325} | train loss {'Reaction outcome loss': 0.3112554814514457, 'Total loss': 0.3112554814514457}
2022-11-28 02:03:59,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:03:59,302 INFO:     Epoch: 63
2022-11-28 02:04:00,060 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4180773963982409, 'Total loss': 0.4180773963982409} | train loss {'Reaction outcome loss': 0.3025817464504923, 'Total loss': 0.3025817464504923}
2022-11-28 02:04:00,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:00,061 INFO:     Epoch: 64
2022-11-28 02:04:00,821 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40997992745939305, 'Total loss': 0.40997992745939305} | train loss {'Reaction outcome loss': 0.3090906281100244, 'Total loss': 0.3090906281100244}
2022-11-28 02:04:00,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:00,821 INFO:     Epoch: 65
2022-11-28 02:04:01,580 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43212148174643517, 'Total loss': 0.43212148174643517} | train loss {'Reaction outcome loss': 0.3085524607677849, 'Total loss': 0.3085524607677849}
2022-11-28 02:04:01,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:01,580 INFO:     Epoch: 66
2022-11-28 02:04:02,337 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41596265509724617, 'Total loss': 0.41596265509724617} | train loss {'Reaction outcome loss': 0.3033288274188431, 'Total loss': 0.3033288274188431}
2022-11-28 02:04:02,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:02,337 INFO:     Epoch: 67
2022-11-28 02:04:03,096 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43766176598993217, 'Total loss': 0.43766176598993217} | train loss {'Reaction outcome loss': 0.3153757858033083, 'Total loss': 0.3153757858033083}
2022-11-28 02:04:03,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:03,097 INFO:     Epoch: 68
2022-11-28 02:04:03,853 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4371028230948882, 'Total loss': 0.4371028230948882} | train loss {'Reaction outcome loss': 0.3098591462385898, 'Total loss': 0.3098591462385898}
2022-11-28 02:04:03,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:03,853 INFO:     Epoch: 69
2022-11-28 02:04:04,612 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4268845624544404, 'Total loss': 0.4268845624544404} | train loss {'Reaction outcome loss': 0.3057237538756156, 'Total loss': 0.3057237538756156}
2022-11-28 02:04:04,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:04,612 INFO:     Epoch: 70
2022-11-28 02:04:05,373 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41099113259803166, 'Total loss': 0.41099113259803166} | train loss {'Reaction outcome loss': 0.30773825955634215, 'Total loss': 0.30773825955634215}
2022-11-28 02:04:05,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:05,373 INFO:     Epoch: 71
2022-11-28 02:04:06,130 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4311930396678773, 'Total loss': 0.4311930396678773} | train loss {'Reaction outcome loss': 0.3062629238379245, 'Total loss': 0.3062629238379245}
2022-11-28 02:04:06,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:06,130 INFO:     Epoch: 72
2022-11-28 02:04:06,886 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41146948832002556, 'Total loss': 0.41146948832002556} | train loss {'Reaction outcome loss': 0.30765145317632325, 'Total loss': 0.30765145317632325}
2022-11-28 02:04:06,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:06,886 INFO:     Epoch: 73
2022-11-28 02:04:07,647 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43834975954483857, 'Total loss': 0.43834975954483857} | train loss {'Reaction outcome loss': 0.2991552481541828, 'Total loss': 0.2991552481541828}
2022-11-28 02:04:07,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:07,647 INFO:     Epoch: 74
2022-11-28 02:04:08,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4200306096198884, 'Total loss': 0.4200306096198884} | train loss {'Reaction outcome loss': 0.30098686215220666, 'Total loss': 0.30098686215220666}
2022-11-28 02:04:08,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:08,406 INFO:     Epoch: 75
2022-11-28 02:04:09,165 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.461410079151392, 'Total loss': 0.461410079151392} | train loss {'Reaction outcome loss': 0.304593088082513, 'Total loss': 0.304593088082513}
2022-11-28 02:04:09,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:09,166 INFO:     Epoch: 76
2022-11-28 02:04:09,924 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4111343219198964, 'Total loss': 0.4111343219198964} | train loss {'Reaction outcome loss': 0.3011807156156521, 'Total loss': 0.3011807156156521}
2022-11-28 02:04:09,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:09,924 INFO:     Epoch: 77
2022-11-28 02:04:10,682 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45474788174033165, 'Total loss': 0.45474788174033165} | train loss {'Reaction outcome loss': 0.30177525354891405, 'Total loss': 0.30177525354891405}
2022-11-28 02:04:10,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:10,682 INFO:     Epoch: 78
2022-11-28 02:04:11,441 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4111667685210705, 'Total loss': 0.4111667685210705} | train loss {'Reaction outcome loss': 0.3127628063973115, 'Total loss': 0.3127628063973115}
2022-11-28 02:04:11,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:11,442 INFO:     Epoch: 79
2022-11-28 02:04:12,195 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4109946380115368, 'Total loss': 0.4109946380115368} | train loss {'Reaction outcome loss': 0.304616937573467, 'Total loss': 0.304616937573467}
2022-11-28 02:04:12,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:12,195 INFO:     Epoch: 80
2022-11-28 02:04:12,950 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41870737784880807, 'Total loss': 0.41870737784880807} | train loss {'Reaction outcome loss': 0.3165510490384637, 'Total loss': 0.3165510490384637}
2022-11-28 02:04:12,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:12,950 INFO:     Epoch: 81
2022-11-28 02:04:13,708 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4200976707718589, 'Total loss': 0.4200976707718589} | train loss {'Reaction outcome loss': 0.3115020174000944, 'Total loss': 0.3115020174000944}
2022-11-28 02:04:13,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:13,708 INFO:     Epoch: 82
2022-11-28 02:04:14,468 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43106377531181683, 'Total loss': 0.43106377531181683} | train loss {'Reaction outcome loss': 0.3079880653899543, 'Total loss': 0.3079880653899543}
2022-11-28 02:04:14,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:14,468 INFO:     Epoch: 83
2022-11-28 02:04:15,226 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4169394654983824, 'Total loss': 0.4169394654983824} | train loss {'Reaction outcome loss': 0.30021212160283206, 'Total loss': 0.30021212160283206}
2022-11-28 02:04:15,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:15,226 INFO:     Epoch: 84
2022-11-28 02:04:15,977 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40845027642155235, 'Total loss': 0.40845027642155235} | train loss {'Reaction outcome loss': 0.30001320589561853, 'Total loss': 0.30001320589561853}
2022-11-28 02:04:15,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:15,978 INFO:     Epoch: 85
2022-11-28 02:04:16,734 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4323355606333776, 'Total loss': 0.4323355606333776} | train loss {'Reaction outcome loss': 0.29804431294300116, 'Total loss': 0.29804431294300116}
2022-11-28 02:04:16,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:16,734 INFO:     Epoch: 86
2022-11-28 02:04:17,495 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4021291011436419, 'Total loss': 0.4021291011436419} | train loss {'Reaction outcome loss': 0.30982247563649196, 'Total loss': 0.30982247563649196}
2022-11-28 02:04:17,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:17,496 INFO:     Epoch: 87
2022-11-28 02:04:18,256 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4005112644623626, 'Total loss': 0.4005112644623626} | train loss {'Reaction outcome loss': 0.302693372508701, 'Total loss': 0.302693372508701}
2022-11-28 02:04:18,256 INFO:     Found new best model at epoch 87
2022-11-28 02:04:18,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:18,257 INFO:     Epoch: 88
2022-11-28 02:04:19,012 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45200909403237427, 'Total loss': 0.45200909403237427} | train loss {'Reaction outcome loss': 0.29690550936728105, 'Total loss': 0.29690550936728105}
2022-11-28 02:04:19,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:19,012 INFO:     Epoch: 89
2022-11-28 02:04:19,767 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40213777361945674, 'Total loss': 0.40213777361945674} | train loss {'Reaction outcome loss': 0.312789680489472, 'Total loss': 0.312789680489472}
2022-11-28 02:04:19,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:19,767 INFO:     Epoch: 90
2022-11-28 02:04:20,520 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45118542455814103, 'Total loss': 0.45118542455814103} | train loss {'Reaction outcome loss': 0.30070609613036625, 'Total loss': 0.30070609613036625}
2022-11-28 02:04:20,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:20,520 INFO:     Epoch: 91
2022-11-28 02:04:21,280 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4106657633727247, 'Total loss': 0.4106657633727247} | train loss {'Reaction outcome loss': 0.310788365529508, 'Total loss': 0.310788365529508}
2022-11-28 02:04:21,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:21,281 INFO:     Epoch: 92
2022-11-28 02:04:22,038 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4431296431205489, 'Total loss': 0.4431296431205489} | train loss {'Reaction outcome loss': 0.2896977505361547, 'Total loss': 0.2896977505361547}
2022-11-28 02:04:22,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:22,038 INFO:     Epoch: 93
2022-11-28 02:04:22,796 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42668432606892154, 'Total loss': 0.42668432606892154} | train loss {'Reaction outcome loss': 0.31214758087785877, 'Total loss': 0.31214758087785877}
2022-11-28 02:04:22,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:22,796 INFO:     Epoch: 94
2022-11-28 02:04:23,551 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43932324393906375, 'Total loss': 0.43932324393906375} | train loss {'Reaction outcome loss': 0.3026144300036284, 'Total loss': 0.3026144300036284}
2022-11-28 02:04:23,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:23,551 INFO:     Epoch: 95
2022-11-28 02:04:24,306 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4237847165627913, 'Total loss': 0.4237847165627913} | train loss {'Reaction outcome loss': 0.31173957929927476, 'Total loss': 0.31173957929927476}
2022-11-28 02:04:24,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:24,306 INFO:     Epoch: 96
2022-11-28 02:04:25,061 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46003877303817053, 'Total loss': 0.46003877303817053} | train loss {'Reaction outcome loss': 0.29946741738489696, 'Total loss': 0.29946741738489696}
2022-11-28 02:04:25,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:25,061 INFO:     Epoch: 97
2022-11-28 02:04:25,817 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39559359484436835, 'Total loss': 0.39559359484436835} | train loss {'Reaction outcome loss': 0.30497791183238127, 'Total loss': 0.30497791183238127}
2022-11-28 02:04:25,817 INFO:     Found new best model at epoch 97
2022-11-28 02:04:25,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:25,818 INFO:     Epoch: 98
2022-11-28 02:04:26,575 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43921876343136484, 'Total loss': 0.43921876343136484} | train loss {'Reaction outcome loss': 0.29729184891496385, 'Total loss': 0.29729184891496385}
2022-11-28 02:04:26,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:26,575 INFO:     Epoch: 99
2022-11-28 02:04:27,330 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42897076362913306, 'Total loss': 0.42897076362913306} | train loss {'Reaction outcome loss': 0.29927677220227766, 'Total loss': 0.29927677220227766}
2022-11-28 02:04:27,330 INFO:     Best model found after epoch 98 of 100.
2022-11-28 02:04:27,330 INFO:   Done with stage: TRAINING
2022-11-28 02:04:27,331 INFO:   Starting stage: EVALUATION
2022-11-28 02:04:27,461 INFO:   Done with stage: EVALUATION
2022-11-28 02:04:27,462 INFO:   Leaving out SEQ value Fold_8
2022-11-28 02:04:27,474 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:04:27,474 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:04:28,126 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:04:28,127 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:04:28,196 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:04:28,196 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:04:28,196 INFO:     No hyperparam tuning for this model
2022-11-28 02:04:28,196 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:04:28,196 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:04:28,197 INFO:     None feature selector for col prot
2022-11-28 02:04:28,197 INFO:     None feature selector for col prot
2022-11-28 02:04:28,197 INFO:     None feature selector for col prot
2022-11-28 02:04:28,198 INFO:     None feature selector for col chem
2022-11-28 02:04:28,198 INFO:     None feature selector for col chem
2022-11-28 02:04:28,198 INFO:     None feature selector for col chem
2022-11-28 02:04:28,198 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:04:28,198 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:04:28,200 INFO:     Number of params in model 169741
2022-11-28 02:04:28,203 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:04:28,203 INFO:   Starting stage: TRAINING
2022-11-28 02:04:28,258 INFO:     Val loss before train {'Reaction outcome loss': 0.9892432892864401, 'Total loss': 0.9892432892864401}
2022-11-28 02:04:28,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:28,258 INFO:     Epoch: 0
2022-11-28 02:04:29,021 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5393732447515834, 'Total loss': 0.5393732447515834} | train loss {'Reaction outcome loss': 0.6394428736980884, 'Total loss': 0.6394428736980884}
2022-11-28 02:04:29,021 INFO:     Found new best model at epoch 0
2022-11-28 02:04:29,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:29,022 INFO:     Epoch: 1
2022-11-28 02:04:29,787 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49026650393551047, 'Total loss': 0.49026650393551047} | train loss {'Reaction outcome loss': 0.5038693127252402, 'Total loss': 0.5038693127252402}
2022-11-28 02:04:29,787 INFO:     Found new best model at epoch 1
2022-11-28 02:04:29,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:29,788 INFO:     Epoch: 2
2022-11-28 02:04:30,549 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.475006486881863, 'Total loss': 0.475006486881863} | train loss {'Reaction outcome loss': 0.4582003115285789, 'Total loss': 0.4582003115285789}
2022-11-28 02:04:30,550 INFO:     Found new best model at epoch 2
2022-11-28 02:04:30,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:30,551 INFO:     Epoch: 3
2022-11-28 02:04:31,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44004420699043706, 'Total loss': 0.44004420699043706} | train loss {'Reaction outcome loss': 0.44410607074537584, 'Total loss': 0.44410607074537584}
2022-11-28 02:04:31,312 INFO:     Found new best model at epoch 3
2022-11-28 02:04:31,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:31,313 INFO:     Epoch: 4
2022-11-28 02:04:32,074 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46108319847421214, 'Total loss': 0.46108319847421214} | train loss {'Reaction outcome loss': 0.4252591270412649, 'Total loss': 0.4252591270412649}
2022-11-28 02:04:32,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:32,074 INFO:     Epoch: 5
2022-11-28 02:04:32,838 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4366194639693607, 'Total loss': 0.4366194639693607} | train loss {'Reaction outcome loss': 0.40998328182726135, 'Total loss': 0.40998328182726135}
2022-11-28 02:04:32,839 INFO:     Found new best model at epoch 5
2022-11-28 02:04:32,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:32,839 INFO:     Epoch: 6
2022-11-28 02:04:33,604 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4355430848557841, 'Total loss': 0.4355430848557841} | train loss {'Reaction outcome loss': 0.4094701294877356, 'Total loss': 0.4094701294877356}
2022-11-28 02:04:33,604 INFO:     Found new best model at epoch 6
2022-11-28 02:04:33,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:33,605 INFO:     Epoch: 7
2022-11-28 02:04:34,371 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45876434309916064, 'Total loss': 0.45876434309916064} | train loss {'Reaction outcome loss': 0.3923900155050139, 'Total loss': 0.3923900155050139}
2022-11-28 02:04:34,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:34,372 INFO:     Epoch: 8
2022-11-28 02:04:35,137 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43479724634777417, 'Total loss': 0.43479724634777417} | train loss {'Reaction outcome loss': 0.39181922598471564, 'Total loss': 0.39181922598471564}
2022-11-28 02:04:35,137 INFO:     Found new best model at epoch 8
2022-11-28 02:04:35,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:35,138 INFO:     Epoch: 9
2022-11-28 02:04:35,901 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46975408867001534, 'Total loss': 0.46975408867001534} | train loss {'Reaction outcome loss': 0.3807354018452667, 'Total loss': 0.3807354018452667}
2022-11-28 02:04:35,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:35,902 INFO:     Epoch: 10
2022-11-28 02:04:36,667 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4291751493107189, 'Total loss': 0.4291751493107189} | train loss {'Reaction outcome loss': 0.3785051991261782, 'Total loss': 0.3785051991261782}
2022-11-28 02:04:36,667 INFO:     Found new best model at epoch 10
2022-11-28 02:04:36,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:36,668 INFO:     Epoch: 11
2022-11-28 02:04:37,430 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4119242030111226, 'Total loss': 0.4119242030111226} | train loss {'Reaction outcome loss': 0.37173016279214816, 'Total loss': 0.37173016279214816}
2022-11-28 02:04:37,430 INFO:     Found new best model at epoch 11
2022-11-28 02:04:37,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:37,431 INFO:     Epoch: 12
2022-11-28 02:04:38,192 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42538106407631526, 'Total loss': 0.42538106407631526} | train loss {'Reaction outcome loss': 0.3619215911134116, 'Total loss': 0.3619215911134116}
2022-11-28 02:04:38,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:38,192 INFO:     Epoch: 13
2022-11-28 02:04:38,955 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4198395325378938, 'Total loss': 0.4198395325378938} | train loss {'Reaction outcome loss': 0.3559544021864572, 'Total loss': 0.3559544021864572}
2022-11-28 02:04:38,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:38,955 INFO:     Epoch: 14
2022-11-28 02:04:39,724 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40769698030569335, 'Total loss': 0.40769698030569335} | train loss {'Reaction outcome loss': 0.355865849422351, 'Total loss': 0.355865849422351}
2022-11-28 02:04:39,724 INFO:     Found new best model at epoch 14
2022-11-28 02:04:39,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:39,725 INFO:     Epoch: 15
2022-11-28 02:04:40,491 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4515701877799901, 'Total loss': 0.4515701877799901} | train loss {'Reaction outcome loss': 0.35654289509740567, 'Total loss': 0.35654289509740567}
2022-11-28 02:04:40,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:40,492 INFO:     Epoch: 16
2022-11-28 02:04:41,257 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4196412654762918, 'Total loss': 0.4196412654762918} | train loss {'Reaction outcome loss': 0.3562684726691054, 'Total loss': 0.3562684726691054}
2022-11-28 02:04:41,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:41,257 INFO:     Epoch: 17
2022-11-28 02:04:42,020 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4189423573288051, 'Total loss': 0.4189423573288051} | train loss {'Reaction outcome loss': 0.3485292957554902, 'Total loss': 0.3485292957554902}
2022-11-28 02:04:42,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:42,021 INFO:     Epoch: 18
2022-11-28 02:04:42,789 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4047761041332375, 'Total loss': 0.4047761041332375} | train loss {'Reaction outcome loss': 0.3522622810316182, 'Total loss': 0.3522622810316182}
2022-11-28 02:04:42,789 INFO:     Found new best model at epoch 18
2022-11-28 02:04:42,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:42,790 INFO:     Epoch: 19
2022-11-28 02:04:43,557 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4280315857719291, 'Total loss': 0.4280315857719291} | train loss {'Reaction outcome loss': 0.34245088969868037, 'Total loss': 0.34245088969868037}
2022-11-28 02:04:43,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:43,557 INFO:     Epoch: 20
2022-11-28 02:04:44,325 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45377641543745995, 'Total loss': 0.45377641543745995} | train loss {'Reaction outcome loss': 0.35271563370441716, 'Total loss': 0.35271563370441716}
2022-11-28 02:04:44,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:44,325 INFO:     Epoch: 21
2022-11-28 02:04:45,085 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4109636555341157, 'Total loss': 0.4109636555341157} | train loss {'Reaction outcome loss': 0.3433065546316005, 'Total loss': 0.3433065546316005}
2022-11-28 02:04:45,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:45,085 INFO:     Epoch: 22
2022-11-28 02:04:45,845 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42602201517332683, 'Total loss': 0.42602201517332683} | train loss {'Reaction outcome loss': 0.34193762133438743, 'Total loss': 0.34193762133438743}
2022-11-28 02:04:45,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:45,846 INFO:     Epoch: 23
2022-11-28 02:04:46,607 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42175054854967375, 'Total loss': 0.42175054854967375} | train loss {'Reaction outcome loss': 0.3363612457629173, 'Total loss': 0.3363612457629173}
2022-11-28 02:04:46,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:46,607 INFO:     Epoch: 24
2022-11-28 02:04:47,367 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4104193879122084, 'Total loss': 0.4104193879122084} | train loss {'Reaction outcome loss': 0.3402053739334787, 'Total loss': 0.3402053739334787}
2022-11-28 02:04:47,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:47,367 INFO:     Epoch: 25
2022-11-28 02:04:48,132 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3892913304946639, 'Total loss': 0.3892913304946639} | train loss {'Reaction outcome loss': 0.33193577086973575, 'Total loss': 0.33193577086973575}
2022-11-28 02:04:48,132 INFO:     Found new best model at epoch 25
2022-11-28 02:04:48,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:48,133 INFO:     Epoch: 26
2022-11-28 02:04:48,902 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4116763062775135, 'Total loss': 0.4116763062775135} | train loss {'Reaction outcome loss': 0.331709643705718, 'Total loss': 0.331709643705718}
2022-11-28 02:04:48,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:48,902 INFO:     Epoch: 27
2022-11-28 02:04:49,664 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4177395863966508, 'Total loss': 0.4177395863966508} | train loss {'Reaction outcome loss': 0.3408287036863546, 'Total loss': 0.3408287036863546}
2022-11-28 02:04:49,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:49,664 INFO:     Epoch: 28
2022-11-28 02:04:50,427 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42568414285779, 'Total loss': 0.42568414285779} | train loss {'Reaction outcome loss': 0.32759699850313123, 'Total loss': 0.32759699850313123}
2022-11-28 02:04:50,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:50,427 INFO:     Epoch: 29
2022-11-28 02:04:51,191 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46757593615488574, 'Total loss': 0.46757593615488574} | train loss {'Reaction outcome loss': 0.32823636686249125, 'Total loss': 0.32823636686249125}
2022-11-28 02:04:51,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:51,191 INFO:     Epoch: 30
2022-11-28 02:04:51,953 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4212811687453227, 'Total loss': 0.4212811687453227} | train loss {'Reaction outcome loss': 0.3255784544012239, 'Total loss': 0.3255784544012239}
2022-11-28 02:04:51,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:51,954 INFO:     Epoch: 31
2022-11-28 02:04:52,716 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4214825259352272, 'Total loss': 0.4214825259352272} | train loss {'Reaction outcome loss': 0.32953166195581995, 'Total loss': 0.32953166195581995}
2022-11-28 02:04:52,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:52,717 INFO:     Epoch: 32
2022-11-28 02:04:53,484 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4372353293001652, 'Total loss': 0.4372353293001652} | train loss {'Reaction outcome loss': 0.3292824966051886, 'Total loss': 0.3292824966051886}
2022-11-28 02:04:53,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:53,485 INFO:     Epoch: 33
2022-11-28 02:04:54,249 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4357275160198862, 'Total loss': 0.4357275160198862} | train loss {'Reaction outcome loss': 0.3292563677495045, 'Total loss': 0.3292563677495045}
2022-11-28 02:04:54,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:54,249 INFO:     Epoch: 34
2022-11-28 02:04:55,014 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43273449181155726, 'Total loss': 0.43273449181155726} | train loss {'Reaction outcome loss': 0.32297094301470824, 'Total loss': 0.32297094301470824}
2022-11-28 02:04:55,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:55,014 INFO:     Epoch: 35
2022-11-28 02:04:55,780 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40801542184569617, 'Total loss': 0.40801542184569617} | train loss {'Reaction outcome loss': 0.3165006040925941, 'Total loss': 0.3165006040925941}
2022-11-28 02:04:55,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:55,780 INFO:     Epoch: 36
2022-11-28 02:04:56,543 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4315121241591193, 'Total loss': 0.4315121241591193} | train loss {'Reaction outcome loss': 0.3230777889369957, 'Total loss': 0.3230777889369957}
2022-11-28 02:04:56,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:56,543 INFO:     Epoch: 37
2022-11-28 02:04:57,310 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4236615357751196, 'Total loss': 0.4236615357751196} | train loss {'Reaction outcome loss': 0.3316733643953358, 'Total loss': 0.3316733643953358}
2022-11-28 02:04:57,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:57,310 INFO:     Epoch: 38
2022-11-28 02:04:58,078 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4123323549601165, 'Total loss': 0.4123323549601165} | train loss {'Reaction outcome loss': 0.32729519466539064, 'Total loss': 0.32729519466539064}
2022-11-28 02:04:58,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:58,079 INFO:     Epoch: 39
2022-11-28 02:04:58,840 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4322377450086854, 'Total loss': 0.4322377450086854} | train loss {'Reaction outcome loss': 0.31943834530970744, 'Total loss': 0.31943834530970744}
2022-11-28 02:04:58,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:58,841 INFO:     Epoch: 40
2022-11-28 02:04:59,606 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4333692149005153, 'Total loss': 0.4333692149005153} | train loss {'Reaction outcome loss': 0.3173730533059326, 'Total loss': 0.3173730533059326}
2022-11-28 02:04:59,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:04:59,606 INFO:     Epoch: 41
2022-11-28 02:05:00,367 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4095677384598689, 'Total loss': 0.4095677384598689} | train loss {'Reaction outcome loss': 0.322333203027806, 'Total loss': 0.322333203027806}
2022-11-28 02:05:00,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:00,367 INFO:     Epoch: 42
2022-11-28 02:05:01,125 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42617192424156447, 'Total loss': 0.42617192424156447} | train loss {'Reaction outcome loss': 0.32029422369575306, 'Total loss': 0.32029422369575306}
2022-11-28 02:05:01,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:01,126 INFO:     Epoch: 43
2022-11-28 02:05:01,882 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43249799277294765, 'Total loss': 0.43249799277294765} | train loss {'Reaction outcome loss': 0.326375940258825, 'Total loss': 0.326375940258825}
2022-11-28 02:05:01,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:01,882 INFO:     Epoch: 44
2022-11-28 02:05:02,638 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42894592678005045, 'Total loss': 0.42894592678005045} | train loss {'Reaction outcome loss': 0.3182716277998782, 'Total loss': 0.3182716277998782}
2022-11-28 02:05:02,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:02,638 INFO:     Epoch: 45
2022-11-28 02:05:03,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4425919357348572, 'Total loss': 0.4425919357348572} | train loss {'Reaction outcome loss': 0.31722599637484356, 'Total loss': 0.31722599637484356}
2022-11-28 02:05:03,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:03,397 INFO:     Epoch: 46
2022-11-28 02:05:04,155 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44186373021114955, 'Total loss': 0.44186373021114955} | train loss {'Reaction outcome loss': 0.3168099795978877, 'Total loss': 0.3168099795978877}
2022-11-28 02:05:04,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:04,155 INFO:     Epoch: 47
2022-11-28 02:05:04,913 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4513880471614274, 'Total loss': 0.4513880471614274} | train loss {'Reaction outcome loss': 0.3065205398316105, 'Total loss': 0.3065205398316105}
2022-11-28 02:05:04,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:04,913 INFO:     Epoch: 48
2022-11-28 02:05:05,674 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4623106701130217, 'Total loss': 0.4623106701130217} | train loss {'Reaction outcome loss': 0.32986768004634687, 'Total loss': 0.32986768004634687}
2022-11-28 02:05:05,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:05,676 INFO:     Epoch: 49
2022-11-28 02:05:06,444 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4208949038928205, 'Total loss': 0.4208949038928205} | train loss {'Reaction outcome loss': 0.31327950775683405, 'Total loss': 0.31327950775683405}
2022-11-28 02:05:06,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:06,444 INFO:     Epoch: 50
2022-11-28 02:05:07,207 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4253959269686179, 'Total loss': 0.4253959269686179} | train loss {'Reaction outcome loss': 0.3199069804602092, 'Total loss': 0.3199069804602092}
2022-11-28 02:05:07,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:07,207 INFO:     Epoch: 51
2022-11-28 02:05:07,967 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47639514167200436, 'Total loss': 0.47639514167200436} | train loss {'Reaction outcome loss': 0.3128934605948387, 'Total loss': 0.3128934605948387}
2022-11-28 02:05:07,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:07,967 INFO:     Epoch: 52
2022-11-28 02:05:08,724 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4038825932551514, 'Total loss': 0.4038825932551514} | train loss {'Reaction outcome loss': 0.31333549819406004, 'Total loss': 0.31333549819406004}
2022-11-28 02:05:08,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:08,725 INFO:     Epoch: 53
2022-11-28 02:05:09,480 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47224168242378667, 'Total loss': 0.47224168242378667} | train loss {'Reaction outcome loss': 0.3083404787786065, 'Total loss': 0.3083404787786065}
2022-11-28 02:05:09,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:09,480 INFO:     Epoch: 54
2022-11-28 02:05:10,240 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4209372198039835, 'Total loss': 0.4209372198039835} | train loss {'Reaction outcome loss': 0.3178861845104444, 'Total loss': 0.3178861845104444}
2022-11-28 02:05:10,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:10,240 INFO:     Epoch: 55
2022-11-28 02:05:10,998 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43729140355505725, 'Total loss': 0.43729140355505725} | train loss {'Reaction outcome loss': 0.3197541164174195, 'Total loss': 0.3197541164174195}
2022-11-28 02:05:10,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:10,999 INFO:     Epoch: 56
2022-11-28 02:05:11,757 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4187313941392032, 'Total loss': 0.4187313941392032} | train loss {'Reaction outcome loss': 0.31665982043130264, 'Total loss': 0.31665982043130264}
2022-11-28 02:05:11,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:11,758 INFO:     Epoch: 57
2022-11-28 02:05:12,519 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43006951768289914, 'Total loss': 0.43006951768289914} | train loss {'Reaction outcome loss': 0.3097579257502671, 'Total loss': 0.3097579257502671}
2022-11-28 02:05:12,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:12,519 INFO:     Epoch: 58
2022-11-28 02:05:13,275 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4288200803778388, 'Total loss': 0.4288200803778388} | train loss {'Reaction outcome loss': 0.309392374099022, 'Total loss': 0.309392374099022}
2022-11-28 02:05:13,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:13,275 INFO:     Epoch: 59
2022-11-28 02:05:14,032 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43821446275846526, 'Total loss': 0.43821446275846526} | train loss {'Reaction outcome loss': 0.30748865098482175, 'Total loss': 0.30748865098482175}
2022-11-28 02:05:14,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:14,032 INFO:     Epoch: 60
2022-11-28 02:05:14,792 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42114491625265643, 'Total loss': 0.42114491625265643} | train loss {'Reaction outcome loss': 0.3117328805308188, 'Total loss': 0.3117328805308188}
2022-11-28 02:05:14,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:14,793 INFO:     Epoch: 61
2022-11-28 02:05:15,549 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4439335802400654, 'Total loss': 0.4439335802400654} | train loss {'Reaction outcome loss': 0.3119286263601915, 'Total loss': 0.3119286263601915}
2022-11-28 02:05:15,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:15,549 INFO:     Epoch: 62
2022-11-28 02:05:16,302 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4315669702535326, 'Total loss': 0.4315669702535326} | train loss {'Reaction outcome loss': 0.31115149553384513, 'Total loss': 0.31115149553384513}
2022-11-28 02:05:16,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:16,302 INFO:     Epoch: 63
2022-11-28 02:05:17,057 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42855044826865196, 'Total loss': 0.42855044826865196} | train loss {'Reaction outcome loss': 0.31586681495630936, 'Total loss': 0.31586681495630936}
2022-11-28 02:05:17,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:17,057 INFO:     Epoch: 64
2022-11-28 02:05:17,818 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4431160732426427, 'Total loss': 0.4431160732426427} | train loss {'Reaction outcome loss': 0.3082746126418633, 'Total loss': 0.3082746126418633}
2022-11-28 02:05:17,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:17,818 INFO:     Epoch: 65
2022-11-28 02:05:18,589 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43783763457428326, 'Total loss': 0.43783763457428326} | train loss {'Reaction outcome loss': 0.3135621264997509, 'Total loss': 0.3135621264997509}
2022-11-28 02:05:18,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:18,590 INFO:     Epoch: 66
2022-11-28 02:05:19,357 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4345564093779434, 'Total loss': 0.4345564093779434} | train loss {'Reaction outcome loss': 0.3119165490892145, 'Total loss': 0.3119165490892145}
2022-11-28 02:05:19,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:19,358 INFO:     Epoch: 67
2022-11-28 02:05:20,123 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4237904374233701, 'Total loss': 0.4237904374233701} | train loss {'Reaction outcome loss': 0.30477247669571833, 'Total loss': 0.30477247669571833}
2022-11-28 02:05:20,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:20,123 INFO:     Epoch: 68
2022-11-28 02:05:20,893 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4328685812652111, 'Total loss': 0.4328685812652111} | train loss {'Reaction outcome loss': 0.31191657447526533, 'Total loss': 0.31191657447526533}
2022-11-28 02:05:20,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:20,894 INFO:     Epoch: 69
2022-11-28 02:05:21,660 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45674545487219637, 'Total loss': 0.45674545487219637} | train loss {'Reaction outcome loss': 0.31141060134095533, 'Total loss': 0.31141060134095533}
2022-11-28 02:05:21,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:21,660 INFO:     Epoch: 70
2022-11-28 02:05:22,428 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4363062893125144, 'Total loss': 0.4363062893125144} | train loss {'Reaction outcome loss': 0.31311153880350534, 'Total loss': 0.31311153880350534}
2022-11-28 02:05:22,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:22,429 INFO:     Epoch: 71
2022-11-28 02:05:23,196 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4228135235607624, 'Total loss': 0.4228135235607624} | train loss {'Reaction outcome loss': 0.2991474150349536, 'Total loss': 0.2991474150349536}
2022-11-28 02:05:23,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:23,197 INFO:     Epoch: 72
2022-11-28 02:05:23,969 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4354353587735783, 'Total loss': 0.4354353587735783} | train loss {'Reaction outcome loss': 0.30955112850924416, 'Total loss': 0.30955112850924416}
2022-11-28 02:05:23,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:23,969 INFO:     Epoch: 73
2022-11-28 02:05:24,738 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39834029227495193, 'Total loss': 0.39834029227495193} | train loss {'Reaction outcome loss': 0.30328357475058687, 'Total loss': 0.30328357475058687}
2022-11-28 02:05:24,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:24,739 INFO:     Epoch: 74
2022-11-28 02:05:25,508 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42989896136251365, 'Total loss': 0.42989896136251365} | train loss {'Reaction outcome loss': 0.313996473868047, 'Total loss': 0.313996473868047}
2022-11-28 02:05:25,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:25,508 INFO:     Epoch: 75
2022-11-28 02:05:26,275 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4304211444475434, 'Total loss': 0.4304211444475434} | train loss {'Reaction outcome loss': 0.31732320597755814, 'Total loss': 0.31732320597755814}
2022-11-28 02:05:26,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:26,275 INFO:     Epoch: 76
2022-11-28 02:05:27,040 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45505135286260734, 'Total loss': 0.45505135286260734} | train loss {'Reaction outcome loss': 0.30182954629943254, 'Total loss': 0.30182954629943254}
2022-11-28 02:05:27,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:27,041 INFO:     Epoch: 77
2022-11-28 02:05:27,806 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3937540819699114, 'Total loss': 0.3937540819699114} | train loss {'Reaction outcome loss': 0.30061574063954816, 'Total loss': 0.30061574063954816}
2022-11-28 02:05:27,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:27,806 INFO:     Epoch: 78
2022-11-28 02:05:28,569 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4172627983445471, 'Total loss': 0.4172627983445471} | train loss {'Reaction outcome loss': 0.31317011098707875, 'Total loss': 0.31317011098707875}
2022-11-28 02:05:28,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:28,570 INFO:     Epoch: 79
2022-11-28 02:05:29,335 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40367574989795685, 'Total loss': 0.40367574989795685} | train loss {'Reaction outcome loss': 0.30720158043738094, 'Total loss': 0.30720158043738094}
2022-11-28 02:05:29,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:29,335 INFO:     Epoch: 80
2022-11-28 02:05:30,101 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4357456371865489, 'Total loss': 0.4357456371865489} | train loss {'Reaction outcome loss': 0.31893727694067264, 'Total loss': 0.31893727694067264}
2022-11-28 02:05:30,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:30,101 INFO:     Epoch: 81
2022-11-28 02:05:30,867 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4154749075797471, 'Total loss': 0.4154749075797471} | train loss {'Reaction outcome loss': 0.31882263428621715, 'Total loss': 0.31882263428621715}
2022-11-28 02:05:30,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:30,867 INFO:     Epoch: 82
2022-11-28 02:05:31,633 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4298708042637868, 'Total loss': 0.4298708042637868} | train loss {'Reaction outcome loss': 0.3131447331979871, 'Total loss': 0.3131447331979871}
2022-11-28 02:05:31,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:31,634 INFO:     Epoch: 83
2022-11-28 02:05:32,400 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4405710365284573, 'Total loss': 0.4405710365284573} | train loss {'Reaction outcome loss': 0.3011322036355494, 'Total loss': 0.3011322036355494}
2022-11-28 02:05:32,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:32,401 INFO:     Epoch: 84
2022-11-28 02:05:33,167 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42468236589973624, 'Total loss': 0.42468236589973624} | train loss {'Reaction outcome loss': 0.30085719499977365, 'Total loss': 0.30085719499977365}
2022-11-28 02:05:33,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:33,167 INFO:     Epoch: 85
2022-11-28 02:05:33,935 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4189986322413791, 'Total loss': 0.4189986322413791} | train loss {'Reaction outcome loss': 0.31455343550131204, 'Total loss': 0.31455343550131204}
2022-11-28 02:05:33,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:33,935 INFO:     Epoch: 86
2022-11-28 02:05:34,701 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41076730157841335, 'Total loss': 0.41076730157841335} | train loss {'Reaction outcome loss': 0.3056113589104385, 'Total loss': 0.3056113589104385}
2022-11-28 02:05:34,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:34,701 INFO:     Epoch: 87
2022-11-28 02:05:35,468 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42822817018763587, 'Total loss': 0.42822817018763587} | train loss {'Reaction outcome loss': 0.3029470047613065, 'Total loss': 0.3029470047613065}
2022-11-28 02:05:35,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:35,468 INFO:     Epoch: 88
2022-11-28 02:05:36,234 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42279177091338416, 'Total loss': 0.42279177091338416} | train loss {'Reaction outcome loss': 0.31316974479705095, 'Total loss': 0.31316974479705095}
2022-11-28 02:05:36,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:36,234 INFO:     Epoch: 89
2022-11-28 02:05:36,998 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41952772777188907, 'Total loss': 0.41952772777188907} | train loss {'Reaction outcome loss': 0.3007693263672052, 'Total loss': 0.3007693263672052}
2022-11-28 02:05:36,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:36,999 INFO:     Epoch: 90
2022-11-28 02:05:37,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4168046633289619, 'Total loss': 0.4168046633289619} | train loss {'Reaction outcome loss': 0.3085667717931492, 'Total loss': 0.3085667717931492}
2022-11-28 02:05:37,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:37,765 INFO:     Epoch: 91
2022-11-28 02:05:38,531 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4000841084529053, 'Total loss': 0.4000841084529053} | train loss {'Reaction outcome loss': 0.30119767730995534, 'Total loss': 0.30119767730995534}
2022-11-28 02:05:38,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:38,531 INFO:     Epoch: 92
2022-11-28 02:05:39,296 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4220190959220583, 'Total loss': 0.4220190959220583} | train loss {'Reaction outcome loss': 0.2986785492469226, 'Total loss': 0.2986785492469226}
2022-11-28 02:05:39,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:39,296 INFO:     Epoch: 93
2022-11-28 02:05:40,063 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4234757423400879, 'Total loss': 0.4234757423400879} | train loss {'Reaction outcome loss': 0.2990002570253226, 'Total loss': 0.2990002570253226}
2022-11-28 02:05:40,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:40,064 INFO:     Epoch: 94
2022-11-28 02:05:40,831 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4725753184069287, 'Total loss': 0.4725753184069287} | train loss {'Reaction outcome loss': 0.3115644472080373, 'Total loss': 0.3115644472080373}
2022-11-28 02:05:40,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:40,831 INFO:     Epoch: 95
2022-11-28 02:05:41,599 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4155374013564803, 'Total loss': 0.4155374013564803} | train loss {'Reaction outcome loss': 0.30524565276479526, 'Total loss': 0.30524565276479526}
2022-11-28 02:05:41,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:41,599 INFO:     Epoch: 96
2022-11-28 02:05:42,366 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48184434832497075, 'Total loss': 0.48184434832497075} | train loss {'Reaction outcome loss': 0.2965150886185227, 'Total loss': 0.2965150886185227}
2022-11-28 02:05:42,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:42,366 INFO:     Epoch: 97
2022-11-28 02:05:43,136 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46593658355149353, 'Total loss': 0.46593658355149353} | train loss {'Reaction outcome loss': 0.30849401736932414, 'Total loss': 0.30849401736932414}
2022-11-28 02:05:43,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:43,136 INFO:     Epoch: 98
2022-11-28 02:05:43,905 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4519655061039058, 'Total loss': 0.4519655061039058} | train loss {'Reaction outcome loss': 0.3049853733034744, 'Total loss': 0.3049853733034744}
2022-11-28 02:05:43,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:43,905 INFO:     Epoch: 99
2022-11-28 02:05:44,673 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4022656460715966, 'Total loss': 0.4022656460715966} | train loss {'Reaction outcome loss': 0.30608612997457385, 'Total loss': 0.30608612997457385}
2022-11-28 02:05:44,673 INFO:     Best model found after epoch 26 of 100.
2022-11-28 02:05:44,673 INFO:   Done with stage: TRAINING
2022-11-28 02:05:44,673 INFO:   Starting stage: EVALUATION
2022-11-28 02:05:44,792 INFO:   Done with stage: EVALUATION
2022-11-28 02:05:44,792 INFO:   Leaving out SEQ value Fold_9
2022-11-28 02:05:44,805 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:05:44,805 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:05:45,447 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:05:45,447 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:05:45,515 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:05:45,515 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:05:45,515 INFO:     No hyperparam tuning for this model
2022-11-28 02:05:45,515 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:05:45,515 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:05:45,516 INFO:     None feature selector for col prot
2022-11-28 02:05:45,516 INFO:     None feature selector for col prot
2022-11-28 02:05:45,516 INFO:     None feature selector for col prot
2022-11-28 02:05:45,517 INFO:     None feature selector for col chem
2022-11-28 02:05:45,517 INFO:     None feature selector for col chem
2022-11-28 02:05:45,517 INFO:     None feature selector for col chem
2022-11-28 02:05:45,517 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:05:45,517 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:05:45,518 INFO:     Number of params in model 169741
2022-11-28 02:05:45,521 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:05:45,521 INFO:   Starting stage: TRAINING
2022-11-28 02:05:45,575 INFO:     Val loss before train {'Reaction outcome loss': 1.0436623895710164, 'Total loss': 1.0436623895710164}
2022-11-28 02:05:45,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:45,575 INFO:     Epoch: 0
2022-11-28 02:05:46,335 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5458013621920889, 'Total loss': 0.5458013621920889} | train loss {'Reaction outcome loss': 0.6303185680691077, 'Total loss': 0.6303185680691077}
2022-11-28 02:05:46,335 INFO:     Found new best model at epoch 0
2022-11-28 02:05:46,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:46,336 INFO:     Epoch: 1
2022-11-28 02:05:47,098 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4785761626606638, 'Total loss': 0.4785761626606638} | train loss {'Reaction outcome loss': 0.4911583271561837, 'Total loss': 0.4911583271561837}
2022-11-28 02:05:47,098 INFO:     Found new best model at epoch 1
2022-11-28 02:05:47,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:47,099 INFO:     Epoch: 2
2022-11-28 02:05:47,860 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48534382541071286, 'Total loss': 0.48534382541071286} | train loss {'Reaction outcome loss': 0.4455996641090938, 'Total loss': 0.4455996641090938}
2022-11-28 02:05:47,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:47,860 INFO:     Epoch: 3
2022-11-28 02:05:48,623 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4639977724714713, 'Total loss': 0.4639977724714713} | train loss {'Reaction outcome loss': 0.424376319287991, 'Total loss': 0.424376319287991}
2022-11-28 02:05:48,623 INFO:     Found new best model at epoch 3
2022-11-28 02:05:48,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:48,624 INFO:     Epoch: 4
2022-11-28 02:05:49,384 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5123546062545343, 'Total loss': 0.5123546062545343} | train loss {'Reaction outcome loss': 0.4163880926613905, 'Total loss': 0.4163880926613905}
2022-11-28 02:05:49,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:49,384 INFO:     Epoch: 5
2022-11-28 02:05:50,141 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47504374638877134, 'Total loss': 0.47504374638877134} | train loss {'Reaction outcome loss': 0.3985409350419531, 'Total loss': 0.3985409350419531}
2022-11-28 02:05:50,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:50,142 INFO:     Epoch: 6
2022-11-28 02:05:50,904 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4551849155263467, 'Total loss': 0.4551849155263467} | train loss {'Reaction outcome loss': 0.39197669631364396, 'Total loss': 0.39197669631364396}
2022-11-28 02:05:50,904 INFO:     Found new best model at epoch 6
2022-11-28 02:05:50,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:50,905 INFO:     Epoch: 7
2022-11-28 02:05:51,669 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42641070747578685, 'Total loss': 0.42641070747578685} | train loss {'Reaction outcome loss': 0.3802754415541279, 'Total loss': 0.3802754415541279}
2022-11-28 02:05:51,669 INFO:     Found new best model at epoch 7
2022-11-28 02:05:51,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:51,670 INFO:     Epoch: 8
2022-11-28 02:05:52,430 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4613589878109368, 'Total loss': 0.4613589878109368} | train loss {'Reaction outcome loss': 0.37313921938137135, 'Total loss': 0.37313921938137135}
2022-11-28 02:05:52,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:52,430 INFO:     Epoch: 9
2022-11-28 02:05:53,187 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4394567437808622, 'Total loss': 0.4394567437808622} | train loss {'Reaction outcome loss': 0.3689161790268762, 'Total loss': 0.3689161790268762}
2022-11-28 02:05:53,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:53,187 INFO:     Epoch: 10
2022-11-28 02:05:53,943 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45747445218942384, 'Total loss': 0.45747445218942384} | train loss {'Reaction outcome loss': 0.36431259686241346, 'Total loss': 0.36431259686241346}
2022-11-28 02:05:53,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:53,944 INFO:     Epoch: 11
2022-11-28 02:05:54,703 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46218448887917807, 'Total loss': 0.46218448887917807} | train loss {'Reaction outcome loss': 0.36423216389150037, 'Total loss': 0.36423216389150037}
2022-11-28 02:05:54,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:54,703 INFO:     Epoch: 12
2022-11-28 02:05:55,464 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4641585201025009, 'Total loss': 0.4641585201025009} | train loss {'Reaction outcome loss': 0.3565344472928923, 'Total loss': 0.3565344472928923}
2022-11-28 02:05:55,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:55,465 INFO:     Epoch: 13
2022-11-28 02:05:56,228 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4328926314007152, 'Total loss': 0.4328926314007152} | train loss {'Reaction outcome loss': 0.35667156114870185, 'Total loss': 0.35667156114870185}
2022-11-28 02:05:56,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:56,228 INFO:     Epoch: 14
2022-11-28 02:05:56,990 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4317061633548953, 'Total loss': 0.4317061633548953} | train loss {'Reaction outcome loss': 0.3453751892459636, 'Total loss': 0.3453751892459636}
2022-11-28 02:05:56,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:56,990 INFO:     Epoch: 15
2022-11-28 02:05:57,752 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44295870745554566, 'Total loss': 0.44295870745554566} | train loss {'Reaction outcome loss': 0.34550093494507733, 'Total loss': 0.34550093494507733}
2022-11-28 02:05:57,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:57,752 INFO:     Epoch: 16
2022-11-28 02:05:58,513 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4569402035664428, 'Total loss': 0.4569402035664428} | train loss {'Reaction outcome loss': 0.33755420300425315, 'Total loss': 0.33755420300425315}
2022-11-28 02:05:58,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:58,513 INFO:     Epoch: 17
2022-11-28 02:05:59,263 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4926225922324441, 'Total loss': 0.4926225922324441} | train loss {'Reaction outcome loss': 0.34519345331556944, 'Total loss': 0.34519345331556944}
2022-11-28 02:05:59,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:05:59,264 INFO:     Epoch: 18
2022-11-28 02:06:00,011 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43481183096512477, 'Total loss': 0.43481183096512477} | train loss {'Reaction outcome loss': 0.3378474835534485, 'Total loss': 0.3378474835534485}
2022-11-28 02:06:00,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:00,011 INFO:     Epoch: 19
2022-11-28 02:06:00,760 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44340393743054435, 'Total loss': 0.44340393743054435} | train loss {'Reaction outcome loss': 0.3326313845053011, 'Total loss': 0.3326313845053011}
2022-11-28 02:06:00,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:00,760 INFO:     Epoch: 20
2022-11-28 02:06:01,512 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4369167275726795, 'Total loss': 0.4369167275726795} | train loss {'Reaction outcome loss': 0.3321709238144816, 'Total loss': 0.3321709238144816}
2022-11-28 02:06:01,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:01,513 INFO:     Epoch: 21
2022-11-28 02:06:02,262 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4465019025585868, 'Total loss': 0.4465019025585868} | train loss {'Reaction outcome loss': 0.32077388270777096, 'Total loss': 0.32077388270777096}
2022-11-28 02:06:02,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:02,262 INFO:     Epoch: 22
2022-11-28 02:06:03,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4829933846538717, 'Total loss': 0.4829933846538717} | train loss {'Reaction outcome loss': 0.3292701490071355, 'Total loss': 0.3292701490071355}
2022-11-28 02:06:03,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:03,010 INFO:     Epoch: 23
2022-11-28 02:06:03,756 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45676284994591365, 'Total loss': 0.45676284994591365} | train loss {'Reaction outcome loss': 0.32591726834676704, 'Total loss': 0.32591726834676704}
2022-11-28 02:06:03,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:03,756 INFO:     Epoch: 24
2022-11-28 02:06:04,505 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43350895324891264, 'Total loss': 0.43350895324891264} | train loss {'Reaction outcome loss': 0.32209944649010286, 'Total loss': 0.32209944649010286}
2022-11-28 02:06:04,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:04,506 INFO:     Epoch: 25
2022-11-28 02:06:05,266 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4698506427759474, 'Total loss': 0.4698506427759474} | train loss {'Reaction outcome loss': 0.31806548006680546, 'Total loss': 0.31806548006680546}
2022-11-28 02:06:05,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:05,266 INFO:     Epoch: 26
2022-11-28 02:06:06,027 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4361415680667216, 'Total loss': 0.4361415680667216} | train loss {'Reaction outcome loss': 0.31797087600036544, 'Total loss': 0.31797087600036544}
2022-11-28 02:06:06,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:06,028 INFO:     Epoch: 27
2022-11-28 02:06:06,789 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46359583803198556, 'Total loss': 0.46359583803198556} | train loss {'Reaction outcome loss': 0.31392070409290646, 'Total loss': 0.31392070409290646}
2022-11-28 02:06:06,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:06,789 INFO:     Epoch: 28
2022-11-28 02:06:07,552 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4443798976188356, 'Total loss': 0.4443798976188356} | train loss {'Reaction outcome loss': 0.3300439713560805, 'Total loss': 0.3300439713560805}
2022-11-28 02:06:07,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:07,552 INFO:     Epoch: 29
2022-11-28 02:06:08,309 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4659008685160767, 'Total loss': 0.4659008685160767} | train loss {'Reaction outcome loss': 0.3262395184867236, 'Total loss': 0.3262395184867236}
2022-11-28 02:06:08,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:08,310 INFO:     Epoch: 30
2022-11-28 02:06:09,074 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.461625183170492, 'Total loss': 0.461625183170492} | train loss {'Reaction outcome loss': 0.31960727113242055, 'Total loss': 0.31960727113242055}
2022-11-28 02:06:09,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:09,075 INFO:     Epoch: 31
2022-11-28 02:06:09,840 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4438910067758777, 'Total loss': 0.4438910067758777} | train loss {'Reaction outcome loss': 0.31729634598809847, 'Total loss': 0.31729634598809847}
2022-11-28 02:06:09,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:09,840 INFO:     Epoch: 32
2022-11-28 02:06:10,601 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43309080736203626, 'Total loss': 0.43309080736203626} | train loss {'Reaction outcome loss': 0.3129142955553775, 'Total loss': 0.3129142955553775}
2022-11-28 02:06:10,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:10,601 INFO:     Epoch: 33
2022-11-28 02:06:11,361 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4372359432957389, 'Total loss': 0.4372359432957389} | train loss {'Reaction outcome loss': 0.31305629340361574, 'Total loss': 0.31305629340361574}
2022-11-28 02:06:11,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:11,361 INFO:     Epoch: 34
2022-11-28 02:06:12,120 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45053152638402855, 'Total loss': 0.45053152638402855} | train loss {'Reaction outcome loss': 0.3198900897740101, 'Total loss': 0.3198900897740101}
2022-11-28 02:06:12,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:12,121 INFO:     Epoch: 35
2022-11-28 02:06:12,882 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4903388876806606, 'Total loss': 0.4903388876806606} | train loss {'Reaction outcome loss': 0.3153601952657408, 'Total loss': 0.3153601952657408}
2022-11-28 02:06:12,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:12,882 INFO:     Epoch: 36
2022-11-28 02:06:13,646 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4592329383912412, 'Total loss': 0.4592329383912412} | train loss {'Reaction outcome loss': 0.30769022922126615, 'Total loss': 0.30769022922126615}
2022-11-28 02:06:13,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:13,646 INFO:     Epoch: 37
2022-11-28 02:06:14,404 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4586532578210939, 'Total loss': 0.4586532578210939} | train loss {'Reaction outcome loss': 0.3247065239718982, 'Total loss': 0.3247065239718982}
2022-11-28 02:06:14,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:14,405 INFO:     Epoch: 38
2022-11-28 02:06:15,170 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5113938074897636, 'Total loss': 0.5113938074897636} | train loss {'Reaction outcome loss': 0.3195686003991536, 'Total loss': 0.3195686003991536}
2022-11-28 02:06:15,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:15,171 INFO:     Epoch: 39
2022-11-28 02:06:15,931 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44131833247163077, 'Total loss': 0.44131833247163077} | train loss {'Reaction outcome loss': 0.3117367422702361, 'Total loss': 0.3117367422702361}
2022-11-28 02:06:15,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:15,932 INFO:     Epoch: 40
2022-11-28 02:06:16,693 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4537654962729324, 'Total loss': 0.4537654962729324} | train loss {'Reaction outcome loss': 0.30575820916161245, 'Total loss': 0.30575820916161245}
2022-11-28 02:06:16,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:16,693 INFO:     Epoch: 41
2022-11-28 02:06:17,455 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46996189721605997, 'Total loss': 0.46996189721605997} | train loss {'Reaction outcome loss': 0.30303628555670076, 'Total loss': 0.30303628555670076}
2022-11-28 02:06:17,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:17,455 INFO:     Epoch: 42
2022-11-28 02:06:18,219 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5038269241763786, 'Total loss': 0.5038269241763786} | train loss {'Reaction outcome loss': 0.31198721421616415, 'Total loss': 0.31198721421616415}
2022-11-28 02:06:18,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:18,219 INFO:     Epoch: 43
2022-11-28 02:06:18,984 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44215808338247536, 'Total loss': 0.44215808338247536} | train loss {'Reaction outcome loss': 0.30468180407674944, 'Total loss': 0.30468180407674944}
2022-11-28 02:06:18,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:18,985 INFO:     Epoch: 44
2022-11-28 02:06:19,749 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4849575459957123, 'Total loss': 0.4849575459957123} | train loss {'Reaction outcome loss': 0.3134342934099995, 'Total loss': 0.3134342934099995}
2022-11-28 02:06:19,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:19,749 INFO:     Epoch: 45
2022-11-28 02:06:20,510 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4896209866485812, 'Total loss': 0.4896209866485812} | train loss {'Reaction outcome loss': 0.30649300056452655, 'Total loss': 0.30649300056452655}
2022-11-28 02:06:20,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:20,511 INFO:     Epoch: 46
2022-11-28 02:06:21,271 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4656238584694537, 'Total loss': 0.4656238584694537} | train loss {'Reaction outcome loss': 0.3101140726281672, 'Total loss': 0.3101140726281672}
2022-11-28 02:06:21,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:21,271 INFO:     Epoch: 47
2022-11-28 02:06:22,029 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4757685153321786, 'Total loss': 0.4757685153321786} | train loss {'Reaction outcome loss': 0.30504903568297015, 'Total loss': 0.30504903568297015}
2022-11-28 02:06:22,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:22,030 INFO:     Epoch: 48
2022-11-28 02:06:22,789 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4839300442148339, 'Total loss': 0.4839300442148339} | train loss {'Reaction outcome loss': 0.3060483218455801, 'Total loss': 0.3060483218455801}
2022-11-28 02:06:22,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:22,789 INFO:     Epoch: 49
2022-11-28 02:06:23,553 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.472069285471331, 'Total loss': 0.472069285471331} | train loss {'Reaction outcome loss': 0.31238445609199755, 'Total loss': 0.31238445609199755}
2022-11-28 02:06:23,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:23,553 INFO:     Epoch: 50
2022-11-28 02:06:24,314 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4409331115470691, 'Total loss': 0.4409331115470691} | train loss {'Reaction outcome loss': 0.30841710807717576, 'Total loss': 0.30841710807717576}
2022-11-28 02:06:24,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:24,314 INFO:     Epoch: 51
2022-11-28 02:06:25,075 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4570694650967859, 'Total loss': 0.4570694650967859} | train loss {'Reaction outcome loss': 0.29556867708357015, 'Total loss': 0.29556867708357015}
2022-11-28 02:06:25,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:25,075 INFO:     Epoch: 52
2022-11-28 02:06:25,836 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47842473164200783, 'Total loss': 0.47842473164200783} | train loss {'Reaction outcome loss': 0.3047519047041329, 'Total loss': 0.3047519047041329}
2022-11-28 02:06:25,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:25,836 INFO:     Epoch: 53
2022-11-28 02:06:26,599 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4611841877075759, 'Total loss': 0.4611841877075759} | train loss {'Reaction outcome loss': 0.31178147643044285, 'Total loss': 0.31178147643044285}
2022-11-28 02:06:26,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:26,600 INFO:     Epoch: 54
2022-11-28 02:06:27,361 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4227560602805831, 'Total loss': 0.4227560602805831} | train loss {'Reaction outcome loss': 0.30485151993985077, 'Total loss': 0.30485151993985077}
2022-11-28 02:06:27,362 INFO:     Found new best model at epoch 54
2022-11-28 02:06:27,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:27,362 INFO:     Epoch: 55
2022-11-28 02:06:28,123 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4714797552336346, 'Total loss': 0.4714797552336346} | train loss {'Reaction outcome loss': 0.3016342955432376, 'Total loss': 0.3016342955432376}
2022-11-28 02:06:28,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:28,123 INFO:     Epoch: 56
2022-11-28 02:06:28,884 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44089470871470193, 'Total loss': 0.44089470871470193} | train loss {'Reaction outcome loss': 0.3124172893105721, 'Total loss': 0.3124172893105721}
2022-11-28 02:06:28,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:28,884 INFO:     Epoch: 57
2022-11-28 02:06:29,647 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4420166350901127, 'Total loss': 0.4420166350901127} | train loss {'Reaction outcome loss': 0.2997798796819181, 'Total loss': 0.2997798796819181}
2022-11-28 02:06:29,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:29,648 INFO:     Epoch: 58
2022-11-28 02:06:30,409 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46328758651560004, 'Total loss': 0.46328758651560004} | train loss {'Reaction outcome loss': 0.29812139631534107, 'Total loss': 0.29812139631534107}
2022-11-28 02:06:30,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:30,409 INFO:     Epoch: 59
2022-11-28 02:06:31,174 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4534752175889232, 'Total loss': 0.4534752175889232} | train loss {'Reaction outcome loss': 0.3058088981983613, 'Total loss': 0.3058088981983613}
2022-11-28 02:06:31,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:31,174 INFO:     Epoch: 60
2022-11-28 02:06:31,936 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48919217457825487, 'Total loss': 0.48919217457825487} | train loss {'Reaction outcome loss': 0.3117119878226397, 'Total loss': 0.3117119878226397}
2022-11-28 02:06:31,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:31,936 INFO:     Epoch: 61
2022-11-28 02:06:32,699 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41324069802860985, 'Total loss': 0.41324069802860985} | train loss {'Reaction outcome loss': 0.2992251777983442, 'Total loss': 0.2992251777983442}
2022-11-28 02:06:32,699 INFO:     Found new best model at epoch 61
2022-11-28 02:06:32,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:32,700 INFO:     Epoch: 62
2022-11-28 02:06:33,459 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46927995031530206, 'Total loss': 0.46927995031530206} | train loss {'Reaction outcome loss': 0.30490674735332024, 'Total loss': 0.30490674735332024}
2022-11-28 02:06:33,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:33,459 INFO:     Epoch: 63
2022-11-28 02:06:34,221 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4408492405306209, 'Total loss': 0.4408492405306209} | train loss {'Reaction outcome loss': 0.3034022394871833, 'Total loss': 0.3034022394871833}
2022-11-28 02:06:34,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:34,221 INFO:     Epoch: 64
2022-11-28 02:06:34,982 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4623477872122418, 'Total loss': 0.4623477872122418} | train loss {'Reaction outcome loss': 0.29921552192191686, 'Total loss': 0.29921552192191686}
2022-11-28 02:06:34,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:34,982 INFO:     Epoch: 65
2022-11-28 02:06:35,749 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49639023218796036, 'Total loss': 0.49639023218796036} | train loss {'Reaction outcome loss': 0.2992688767155822, 'Total loss': 0.2992688767155822}
2022-11-28 02:06:35,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:35,749 INFO:     Epoch: 66
2022-11-28 02:06:36,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43615511508489196, 'Total loss': 0.43615511508489196} | train loss {'Reaction outcome loss': 0.3035768041805345, 'Total loss': 0.3035768041805345}
2022-11-28 02:06:36,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:36,513 INFO:     Epoch: 67
2022-11-28 02:06:37,274 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4688328809358857, 'Total loss': 0.4688328809358857} | train loss {'Reaction outcome loss': 0.2983720342571638, 'Total loss': 0.2983720342571638}
2022-11-28 02:06:37,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:37,274 INFO:     Epoch: 68
2022-11-28 02:06:38,040 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.477879099547863, 'Total loss': 0.477879099547863} | train loss {'Reaction outcome loss': 0.31196163202426874, 'Total loss': 0.31196163202426874}
2022-11-28 02:06:38,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:38,040 INFO:     Epoch: 69
2022-11-28 02:06:38,802 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4510457275265997, 'Total loss': 0.4510457275265997} | train loss {'Reaction outcome loss': 0.2988784483804995, 'Total loss': 0.2988784483804995}
2022-11-28 02:06:38,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:38,803 INFO:     Epoch: 70
2022-11-28 02:06:39,567 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4813757640394298, 'Total loss': 0.4813757640394298} | train loss {'Reaction outcome loss': 0.2934715031361093, 'Total loss': 0.2934715031361093}
2022-11-28 02:06:39,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:39,570 INFO:     Epoch: 71
2022-11-28 02:06:40,331 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.440143243748356, 'Total loss': 0.440143243748356} | train loss {'Reaction outcome loss': 0.30725320384514576, 'Total loss': 0.30725320384514576}
2022-11-28 02:06:40,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:40,331 INFO:     Epoch: 72
2022-11-28 02:06:41,092 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4397696075453, 'Total loss': 0.4397696075453} | train loss {'Reaction outcome loss': 0.30499569881631405, 'Total loss': 0.30499569881631405}
2022-11-28 02:06:41,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:41,092 INFO:     Epoch: 73
2022-11-28 02:06:41,858 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43240052597089246, 'Total loss': 0.43240052597089246} | train loss {'Reaction outcome loss': 0.3029440892290096, 'Total loss': 0.3029440892290096}
2022-11-28 02:06:41,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:41,858 INFO:     Epoch: 74
2022-11-28 02:06:42,620 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4298218851062385, 'Total loss': 0.4298218851062385} | train loss {'Reaction outcome loss': 0.2974241517332135, 'Total loss': 0.2974241517332135}
2022-11-28 02:06:42,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:42,620 INFO:     Epoch: 75
2022-11-28 02:06:43,384 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45685926774008706, 'Total loss': 0.45685926774008706} | train loss {'Reaction outcome loss': 0.3008012656350525, 'Total loss': 0.3008012656350525}
2022-11-28 02:06:43,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:43,384 INFO:     Epoch: 76
2022-11-28 02:06:44,146 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4443690614266829, 'Total loss': 0.4443690614266829} | train loss {'Reaction outcome loss': 0.2932635423480248, 'Total loss': 0.2932635423480248}
2022-11-28 02:06:44,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:44,146 INFO:     Epoch: 77
2022-11-28 02:06:44,912 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45242402397773485, 'Total loss': 0.45242402397773485} | train loss {'Reaction outcome loss': 0.2955322324621434, 'Total loss': 0.2955322324621434}
2022-11-28 02:06:44,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:44,912 INFO:     Epoch: 78
2022-11-28 02:06:45,672 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46972085095264693, 'Total loss': 0.46972085095264693} | train loss {'Reaction outcome loss': 0.30592260787985764, 'Total loss': 0.30592260787985764}
2022-11-28 02:06:45,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:45,673 INFO:     Epoch: 79
2022-11-28 02:06:46,436 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4454499425535852, 'Total loss': 0.4454499425535852} | train loss {'Reaction outcome loss': 0.300211130751639, 'Total loss': 0.300211130751639}
2022-11-28 02:06:46,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:46,437 INFO:     Epoch: 80
2022-11-28 02:06:47,199 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4388577750122005, 'Total loss': 0.4388577750122005} | train loss {'Reaction outcome loss': 0.2973538053583126, 'Total loss': 0.2973538053583126}
2022-11-28 02:06:47,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:47,199 INFO:     Epoch: 81
2022-11-28 02:06:47,964 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4681741195646199, 'Total loss': 0.4681741195646199} | train loss {'Reaction outcome loss': 0.30215164499015223, 'Total loss': 0.30215164499015223}
2022-11-28 02:06:47,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:47,965 INFO:     Epoch: 82
2022-11-28 02:06:48,724 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4452831540680067, 'Total loss': 0.4452831540680067} | train loss {'Reaction outcome loss': 0.2983738357315258, 'Total loss': 0.2983738357315258}
2022-11-28 02:06:48,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:48,724 INFO:     Epoch: 83
2022-11-28 02:06:49,486 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44935505295341666, 'Total loss': 0.44935505295341666} | train loss {'Reaction outcome loss': 0.29901256834974094, 'Total loss': 0.29901256834974094}
2022-11-28 02:06:49,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:49,486 INFO:     Epoch: 84
2022-11-28 02:06:50,246 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4550037631257014, 'Total loss': 0.4550037631257014} | train loss {'Reaction outcome loss': 0.29650063426518924, 'Total loss': 0.29650063426518924}
2022-11-28 02:06:50,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:50,246 INFO:     Epoch: 85
2022-11-28 02:06:51,005 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47307403351772914, 'Total loss': 0.47307403351772914} | train loss {'Reaction outcome loss': 0.3046083826495677, 'Total loss': 0.3046083826495677}
2022-11-28 02:06:51,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:51,006 INFO:     Epoch: 86
2022-11-28 02:06:51,764 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4388149553401904, 'Total loss': 0.4388149553401904} | train loss {'Reaction outcome loss': 0.3012222626683663, 'Total loss': 0.3012222626683663}
2022-11-28 02:06:51,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:51,764 INFO:     Epoch: 87
2022-11-28 02:06:52,524 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48683270236307924, 'Total loss': 0.48683270236307924} | train loss {'Reaction outcome loss': 0.30362851854641826, 'Total loss': 0.30362851854641826}
2022-11-28 02:06:52,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:52,524 INFO:     Epoch: 88
2022-11-28 02:06:53,284 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.452798337421634, 'Total loss': 0.452798337421634} | train loss {'Reaction outcome loss': 0.300083650770236, 'Total loss': 0.300083650770236}
2022-11-28 02:06:53,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:53,284 INFO:     Epoch: 89
2022-11-28 02:06:54,049 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42608773382380605, 'Total loss': 0.42608773382380605} | train loss {'Reaction outcome loss': 0.29521615006485763, 'Total loss': 0.29521615006485763}
2022-11-28 02:06:54,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:54,049 INFO:     Epoch: 90
2022-11-28 02:06:54,812 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42784222858873283, 'Total loss': 0.42784222858873283} | train loss {'Reaction outcome loss': 0.29560967300619395, 'Total loss': 0.29560967300619395}
2022-11-28 02:06:54,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:54,812 INFO:     Epoch: 91
2022-11-28 02:06:55,573 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4506852542134849, 'Total loss': 0.4506852542134849} | train loss {'Reaction outcome loss': 0.3029552893066893, 'Total loss': 0.3029552893066893}
2022-11-28 02:06:55,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:55,573 INFO:     Epoch: 92
2022-11-28 02:06:56,340 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43617946849289263, 'Total loss': 0.43617946849289263} | train loss {'Reaction outcome loss': 0.30028974444282297, 'Total loss': 0.30028974444282297}
2022-11-28 02:06:56,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:56,340 INFO:     Epoch: 93
2022-11-28 02:06:57,084 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4412350006062876, 'Total loss': 0.4412350006062876} | train loss {'Reaction outcome loss': 0.29326934703454677, 'Total loss': 0.29326934703454677}
2022-11-28 02:06:57,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:57,084 INFO:     Epoch: 94
2022-11-28 02:06:57,828 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4560881345109506, 'Total loss': 0.4560881345109506} | train loss {'Reaction outcome loss': 0.30861813410812494, 'Total loss': 0.30861813410812494}
2022-11-28 02:06:57,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:57,829 INFO:     Epoch: 95
2022-11-28 02:06:58,570 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4532338541678407, 'Total loss': 0.4532338541678407} | train loss {'Reaction outcome loss': 0.29011594789976974, 'Total loss': 0.29011594789976974}
2022-11-28 02:06:58,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:58,570 INFO:     Epoch: 96
2022-11-28 02:06:59,317 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4447426257485693, 'Total loss': 0.4447426257485693} | train loss {'Reaction outcome loss': 0.29951569900220754, 'Total loss': 0.29951569900220754}
2022-11-28 02:06:59,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:06:59,317 INFO:     Epoch: 97
2022-11-28 02:07:00,060 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47642423110929405, 'Total loss': 0.47642423110929405} | train loss {'Reaction outcome loss': 0.2958684711127865, 'Total loss': 0.2958684711127865}
2022-11-28 02:07:00,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:00,061 INFO:     Epoch: 98
2022-11-28 02:07:00,803 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4403084421699697, 'Total loss': 0.4403084421699697} | train loss {'Reaction outcome loss': 0.28691172171003965, 'Total loss': 0.28691172171003965}
2022-11-28 02:07:00,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:00,803 INFO:     Epoch: 99
2022-11-28 02:07:01,552 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4596143134615638, 'Total loss': 0.4596143134615638} | train loss {'Reaction outcome loss': 0.3015626670298528, 'Total loss': 0.3015626670298528}
2022-11-28 02:07:01,552 INFO:     Best model found after epoch 62 of 100.
2022-11-28 02:07:01,553 INFO:   Done with stage: TRAINING
2022-11-28 02:07:01,553 INFO:   Starting stage: EVALUATION
2022-11-28 02:07:01,683 INFO:   Done with stage: EVALUATION
2022-11-28 02:07:01,691 INFO:   Leaving out SEQ value Fold_0
2022-11-28 02:07:01,705 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:07:01,705 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:07:02,342 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:07:02,342 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:07:02,410 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:07:02,410 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:07:02,410 INFO:     No hyperparam tuning for this model
2022-11-28 02:07:02,410 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:07:02,410 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:07:02,411 INFO:     None feature selector for col prot
2022-11-28 02:07:02,411 INFO:     None feature selector for col prot
2022-11-28 02:07:02,411 INFO:     None feature selector for col prot
2022-11-28 02:07:02,412 INFO:     None feature selector for col chem
2022-11-28 02:07:02,412 INFO:     None feature selector for col chem
2022-11-28 02:07:02,412 INFO:     None feature selector for col chem
2022-11-28 02:07:02,412 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:07:02,412 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:07:02,413 INFO:     Number of params in model 169741
2022-11-28 02:07:02,416 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:07:02,417 INFO:   Starting stage: TRAINING
2022-11-28 02:07:02,469 INFO:     Val loss before train {'Reaction outcome loss': 1.0194297945776651, 'Total loss': 1.0194297945776651}
2022-11-28 02:07:02,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:02,470 INFO:     Epoch: 0
2022-11-28 02:07:03,211 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5468243901119676, 'Total loss': 0.5468243901119676} | train loss {'Reaction outcome loss': 0.639084129243112, 'Total loss': 0.639084129243112}
2022-11-28 02:07:03,211 INFO:     Found new best model at epoch 0
2022-11-28 02:07:03,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:03,212 INFO:     Epoch: 1
2022-11-28 02:07:03,951 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5022289240083029, 'Total loss': 0.5022289240083029} | train loss {'Reaction outcome loss': 0.4985929286321167, 'Total loss': 0.4985929286321167}
2022-11-28 02:07:03,951 INFO:     Found new best model at epoch 1
2022-11-28 02:07:03,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:03,952 INFO:     Epoch: 2
2022-11-28 02:07:04,692 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47386587463146035, 'Total loss': 0.47386587463146035} | train loss {'Reaction outcome loss': 0.4625487373378433, 'Total loss': 0.4625487373378433}
2022-11-28 02:07:04,692 INFO:     Found new best model at epoch 2
2022-11-28 02:07:04,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:04,693 INFO:     Epoch: 3
2022-11-28 02:07:05,432 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47232568090738253, 'Total loss': 0.47232568090738253} | train loss {'Reaction outcome loss': 0.44280016645178444, 'Total loss': 0.44280016645178444}
2022-11-28 02:07:05,432 INFO:     Found new best model at epoch 3
2022-11-28 02:07:05,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:05,433 INFO:     Epoch: 4
2022-11-28 02:07:06,172 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4426353112902752, 'Total loss': 0.4426353112902752} | train loss {'Reaction outcome loss': 0.43198756146870676, 'Total loss': 0.43198756146870676}
2022-11-28 02:07:06,172 INFO:     Found new best model at epoch 4
2022-11-28 02:07:06,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:06,173 INFO:     Epoch: 5
2022-11-28 02:07:06,912 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46507407759511193, 'Total loss': 0.46507407759511193} | train loss {'Reaction outcome loss': 0.4195840669582125, 'Total loss': 0.4195840669582125}
2022-11-28 02:07:06,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:06,913 INFO:     Epoch: 6
2022-11-28 02:07:07,653 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4592336759317753, 'Total loss': 0.4592336759317753} | train loss {'Reaction outcome loss': 0.4138620816415451, 'Total loss': 0.4138620816415451}
2022-11-28 02:07:07,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:07,653 INFO:     Epoch: 7
2022-11-28 02:07:08,392 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46918379394120946, 'Total loss': 0.46918379394120946} | train loss {'Reaction outcome loss': 0.3976662167515911, 'Total loss': 0.3976662167515911}
2022-11-28 02:07:08,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:08,392 INFO:     Epoch: 8
2022-11-28 02:07:09,130 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4784187251745268, 'Total loss': 0.4784187251745268} | train loss {'Reaction outcome loss': 0.3853433779517158, 'Total loss': 0.3853433779517158}
2022-11-28 02:07:09,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:09,130 INFO:     Epoch: 9
2022-11-28 02:07:09,869 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45630386263825173, 'Total loss': 0.45630386263825173} | train loss {'Reaction outcome loss': 0.37431058396020384, 'Total loss': 0.37431058396020384}
2022-11-28 02:07:09,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:09,869 INFO:     Epoch: 10
2022-11-28 02:07:10,611 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45650064113528227, 'Total loss': 0.45650064113528227} | train loss {'Reaction outcome loss': 0.375724498152, 'Total loss': 0.375724498152}
2022-11-28 02:07:10,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:10,613 INFO:     Epoch: 11
2022-11-28 02:07:11,355 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44310540757900063, 'Total loss': 0.44310540757900063} | train loss {'Reaction outcome loss': 0.37111130750692284, 'Total loss': 0.37111130750692284}
2022-11-28 02:07:11,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:11,355 INFO:     Epoch: 12
2022-11-28 02:07:12,098 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.472416490316391, 'Total loss': 0.472416490316391} | train loss {'Reaction outcome loss': 0.37289441022716585, 'Total loss': 0.37289441022716585}
2022-11-28 02:07:12,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:12,098 INFO:     Epoch: 13
2022-11-28 02:07:12,838 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4443970547859059, 'Total loss': 0.4443970547859059} | train loss {'Reaction outcome loss': 0.3769042804592945, 'Total loss': 0.3769042804592945}
2022-11-28 02:07:12,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:12,839 INFO:     Epoch: 14
2022-11-28 02:07:13,578 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4433387675604155, 'Total loss': 0.4433387675604155} | train loss {'Reaction outcome loss': 0.3507590688398627, 'Total loss': 0.3507590688398627}
2022-11-28 02:07:13,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:13,578 INFO:     Epoch: 15
2022-11-28 02:07:14,317 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4368447668330614, 'Total loss': 0.4368447668330614} | train loss {'Reaction outcome loss': 0.3666268135802668, 'Total loss': 0.3666268135802668}
2022-11-28 02:07:14,317 INFO:     Found new best model at epoch 15
2022-11-28 02:07:14,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:14,318 INFO:     Epoch: 16
2022-11-28 02:07:15,060 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4433619937924452, 'Total loss': 0.4433619937924452} | train loss {'Reaction outcome loss': 0.353292975422056, 'Total loss': 0.353292975422056}
2022-11-28 02:07:15,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:15,060 INFO:     Epoch: 17
2022-11-28 02:07:15,803 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43326918364957323, 'Total loss': 0.43326918364957323} | train loss {'Reaction outcome loss': 0.3586899052511473, 'Total loss': 0.3586899052511473}
2022-11-28 02:07:15,803 INFO:     Found new best model at epoch 17
2022-11-28 02:07:15,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:15,804 INFO:     Epoch: 18
2022-11-28 02:07:16,545 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.443784115272899, 'Total loss': 0.443784115272899} | train loss {'Reaction outcome loss': 0.3442417580451145, 'Total loss': 0.3442417580451145}
2022-11-28 02:07:16,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:16,546 INFO:     Epoch: 19
2022-11-28 02:07:17,289 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42620544690032336, 'Total loss': 0.42620544690032336} | train loss {'Reaction outcome loss': 0.3504875219869809, 'Total loss': 0.3504875219869809}
2022-11-28 02:07:17,290 INFO:     Found new best model at epoch 19
2022-11-28 02:07:17,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:17,291 INFO:     Epoch: 20
2022-11-28 02:07:18,032 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45219211384307506, 'Total loss': 0.45219211384307506} | train loss {'Reaction outcome loss': 0.3546857123919686, 'Total loss': 0.3546857123919686}
2022-11-28 02:07:18,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:18,033 INFO:     Epoch: 21
2022-11-28 02:07:18,771 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4354671156683633, 'Total loss': 0.4354671156683633} | train loss {'Reaction outcome loss': 0.34295053364800626, 'Total loss': 0.34295053364800626}
2022-11-28 02:07:18,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:18,772 INFO:     Epoch: 22
2022-11-28 02:07:19,515 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43014268091944763, 'Total loss': 0.43014268091944763} | train loss {'Reaction outcome loss': 0.3439179307124654, 'Total loss': 0.3439179307124654}
2022-11-28 02:07:19,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:19,515 INFO:     Epoch: 23
2022-11-28 02:07:20,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42335582541864974, 'Total loss': 0.42335582541864974} | train loss {'Reaction outcome loss': 0.3388217165913494, 'Total loss': 0.3388217165913494}
2022-11-28 02:07:20,254 INFO:     Found new best model at epoch 23
2022-11-28 02:07:20,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:20,255 INFO:     Epoch: 24
2022-11-28 02:07:21,000 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42453655323316886, 'Total loss': 0.42453655323316886} | train loss {'Reaction outcome loss': 0.33851283167290397, 'Total loss': 0.33851283167290397}
2022-11-28 02:07:21,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:21,001 INFO:     Epoch: 25
2022-11-28 02:07:21,744 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.468695524473523, 'Total loss': 0.468695524473523} | train loss {'Reaction outcome loss': 0.3438621737429353, 'Total loss': 0.3438621737429353}
2022-11-28 02:07:21,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:21,744 INFO:     Epoch: 26
2022-11-28 02:07:22,483 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4215070432008699, 'Total loss': 0.4215070432008699} | train loss {'Reaction outcome loss': 0.3514446912669256, 'Total loss': 0.3514446912669256}
2022-11-28 02:07:22,483 INFO:     Found new best model at epoch 26
2022-11-28 02:07:22,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:22,484 INFO:     Epoch: 27
2022-11-28 02:07:23,221 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4309497671418412, 'Total loss': 0.4309497671418412} | train loss {'Reaction outcome loss': 0.32795946260334036, 'Total loss': 0.32795946260334036}
2022-11-28 02:07:23,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:23,221 INFO:     Epoch: 28
2022-11-28 02:07:23,960 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.422283066913139, 'Total loss': 0.422283066913139} | train loss {'Reaction outcome loss': 0.3355751102637561, 'Total loss': 0.3355751102637561}
2022-11-28 02:07:23,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:23,960 INFO:     Epoch: 29
2022-11-28 02:07:24,702 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4229118536378062, 'Total loss': 0.4229118536378062} | train loss {'Reaction outcome loss': 0.337764851871084, 'Total loss': 0.337764851871084}
2022-11-28 02:07:24,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:24,702 INFO:     Epoch: 30
2022-11-28 02:07:25,444 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41175037865028824, 'Total loss': 0.41175037865028824} | train loss {'Reaction outcome loss': 0.3305189032718295, 'Total loss': 0.3305189032718295}
2022-11-28 02:07:25,444 INFO:     Found new best model at epoch 30
2022-11-28 02:07:25,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:25,445 INFO:     Epoch: 31
2022-11-28 02:07:26,191 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4424732850734578, 'Total loss': 0.4424732850734578} | train loss {'Reaction outcome loss': 0.33677753219839, 'Total loss': 0.33677753219839}
2022-11-28 02:07:26,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:26,192 INFO:     Epoch: 32
2022-11-28 02:07:26,930 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4213670648114626, 'Total loss': 0.4213670648114626} | train loss {'Reaction outcome loss': 0.33651814237236977, 'Total loss': 0.33651814237236977}
2022-11-28 02:07:26,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:26,931 INFO:     Epoch: 33
2022-11-28 02:07:27,671 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44767027434914614, 'Total loss': 0.44767027434914614} | train loss {'Reaction outcome loss': 0.33648838774591194, 'Total loss': 0.33648838774591194}
2022-11-28 02:07:27,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:27,671 INFO:     Epoch: 34
2022-11-28 02:07:28,415 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4275888804086419, 'Total loss': 0.4275888804086419} | train loss {'Reaction outcome loss': 0.34394698248046346, 'Total loss': 0.34394698248046346}
2022-11-28 02:07:28,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:28,415 INFO:     Epoch: 35
2022-11-28 02:07:29,154 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4381965608444325, 'Total loss': 0.4381965608444325} | train loss {'Reaction outcome loss': 0.337051751397428, 'Total loss': 0.337051751397428}
2022-11-28 02:07:29,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:29,154 INFO:     Epoch: 36
2022-11-28 02:07:29,893 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4300400739492372, 'Total loss': 0.4300400739492372} | train loss {'Reaction outcome loss': 0.3287957185024365, 'Total loss': 0.3287957185024365}
2022-11-28 02:07:29,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:29,894 INFO:     Epoch: 37
2022-11-28 02:07:30,634 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42331212655056355, 'Total loss': 0.42331212655056355} | train loss {'Reaction outcome loss': 0.33335298876904074, 'Total loss': 0.33335298876904074}
2022-11-28 02:07:30,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:30,634 INFO:     Epoch: 38
2022-11-28 02:07:31,374 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42399352477040403, 'Total loss': 0.42399352477040403} | train loss {'Reaction outcome loss': 0.3350561651874517, 'Total loss': 0.3350561651874517}
2022-11-28 02:07:31,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:31,374 INFO:     Epoch: 39
2022-11-28 02:07:32,114 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4298836138359336, 'Total loss': 0.4298836138359336} | train loss {'Reaction outcome loss': 0.3351726194568833, 'Total loss': 0.3351726194568833}
2022-11-28 02:07:32,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:32,114 INFO:     Epoch: 40
2022-11-28 02:07:32,854 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40697199175524157, 'Total loss': 0.40697199175524157} | train loss {'Reaction outcome loss': 0.3236445140276776, 'Total loss': 0.3236445140276776}
2022-11-28 02:07:32,854 INFO:     Found new best model at epoch 40
2022-11-28 02:07:32,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:32,855 INFO:     Epoch: 41
2022-11-28 02:07:33,596 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4318083597477092, 'Total loss': 0.4318083597477092} | train loss {'Reaction outcome loss': 0.3300043610153628, 'Total loss': 0.3300043610153628}
2022-11-28 02:07:33,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:33,597 INFO:     Epoch: 42
2022-11-28 02:07:34,339 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4241364619066549, 'Total loss': 0.4241364619066549} | train loss {'Reaction outcome loss': 0.3309649505087587, 'Total loss': 0.3309649505087587}
2022-11-28 02:07:34,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:34,339 INFO:     Epoch: 43
2022-11-28 02:07:35,079 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4241213313368864, 'Total loss': 0.4241213313368864} | train loss {'Reaction outcome loss': 0.33048282017106895, 'Total loss': 0.33048282017106895}
2022-11-28 02:07:35,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:35,079 INFO:     Epoch: 44
2022-11-28 02:07:35,820 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40512562560480697, 'Total loss': 0.40512562560480697} | train loss {'Reaction outcome loss': 0.3309773683059411, 'Total loss': 0.3309773683059411}
2022-11-28 02:07:35,821 INFO:     Found new best model at epoch 44
2022-11-28 02:07:35,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:35,822 INFO:     Epoch: 45
2022-11-28 02:07:36,563 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42986511595027393, 'Total loss': 0.42986511595027393} | train loss {'Reaction outcome loss': 0.32981195499296073, 'Total loss': 0.32981195499296073}
2022-11-28 02:07:36,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:36,563 INFO:     Epoch: 46
2022-11-28 02:07:37,304 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44140988553679267, 'Total loss': 0.44140988553679267} | train loss {'Reaction outcome loss': 0.32285363398125916, 'Total loss': 0.32285363398125916}
2022-11-28 02:07:37,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:37,304 INFO:     Epoch: 47
2022-11-28 02:07:38,043 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4238349500783654, 'Total loss': 0.4238349500783654} | train loss {'Reaction outcome loss': 0.33432330255259257, 'Total loss': 0.33432330255259257}
2022-11-28 02:07:38,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:38,043 INFO:     Epoch: 48
2022-11-28 02:07:38,787 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4274017325667448, 'Total loss': 0.4274017325667448} | train loss {'Reaction outcome loss': 0.32272825884770173, 'Total loss': 0.32272825884770173}
2022-11-28 02:07:38,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:38,787 INFO:     Epoch: 49
2022-11-28 02:07:39,530 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4255141404479049, 'Total loss': 0.4255141404479049} | train loss {'Reaction outcome loss': 0.32484651763053213, 'Total loss': 0.32484651763053213}
2022-11-28 02:07:39,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:39,530 INFO:     Epoch: 50
2022-11-28 02:07:40,273 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42123719218165373, 'Total loss': 0.42123719218165373} | train loss {'Reaction outcome loss': 0.3237358902382558, 'Total loss': 0.3237358902382558}
2022-11-28 02:07:40,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:40,273 INFO:     Epoch: 51
2022-11-28 02:07:41,013 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4212097726589025, 'Total loss': 0.4212097726589025} | train loss {'Reaction outcome loss': 0.31759129107364864, 'Total loss': 0.31759129107364864}
2022-11-28 02:07:41,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:41,013 INFO:     Epoch: 52
2022-11-28 02:07:41,751 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43527389646962633, 'Total loss': 0.43527389646962633} | train loss {'Reaction outcome loss': 0.33039787686506256, 'Total loss': 0.33039787686506256}
2022-11-28 02:07:41,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:41,752 INFO:     Epoch: 53
2022-11-28 02:07:42,494 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39693055284577744, 'Total loss': 0.39693055284577744} | train loss {'Reaction outcome loss': 0.32559020241691927, 'Total loss': 0.32559020241691927}
2022-11-28 02:07:42,495 INFO:     Found new best model at epoch 53
2022-11-28 02:07:42,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:42,495 INFO:     Epoch: 54
2022-11-28 02:07:43,237 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4187809623951136, 'Total loss': 0.4187809623951136} | train loss {'Reaction outcome loss': 0.3202076374446271, 'Total loss': 0.3202076374446271}
2022-11-28 02:07:43,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:43,237 INFO:     Epoch: 55
2022-11-28 02:07:43,980 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4362313865229141, 'Total loss': 0.4362313865229141} | train loss {'Reaction outcome loss': 0.31962194290683893, 'Total loss': 0.31962194290683893}
2022-11-28 02:07:43,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:43,980 INFO:     Epoch: 56
2022-11-28 02:07:44,722 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4366667821656826, 'Total loss': 0.4366667821656826} | train loss {'Reaction outcome loss': 0.32437200948107436, 'Total loss': 0.32437200948107436}
2022-11-28 02:07:44,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:44,722 INFO:     Epoch: 57
2022-11-28 02:07:45,460 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42336124597593794, 'Total loss': 0.42336124597593794} | train loss {'Reaction outcome loss': 0.331275574862957, 'Total loss': 0.331275574862957}
2022-11-28 02:07:45,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:45,460 INFO:     Epoch: 58
2022-11-28 02:07:46,202 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42032651048760084, 'Total loss': 0.42032651048760084} | train loss {'Reaction outcome loss': 0.31675739812313536, 'Total loss': 0.31675739812313536}
2022-11-28 02:07:46,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:46,202 INFO:     Epoch: 59
2022-11-28 02:07:46,945 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4224126900351325, 'Total loss': 0.4224126900351325} | train loss {'Reaction outcome loss': 0.31408133402039284, 'Total loss': 0.31408133402039284}
2022-11-28 02:07:46,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:46,945 INFO:     Epoch: 60
2022-11-28 02:07:47,687 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4220720699360204, 'Total loss': 0.4220720699360204} | train loss {'Reaction outcome loss': 0.31572314260191603, 'Total loss': 0.31572314260191603}
2022-11-28 02:07:47,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:47,687 INFO:     Epoch: 61
2022-11-28 02:07:48,427 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4177930784779926, 'Total loss': 0.4177930784779926} | train loss {'Reaction outcome loss': 0.3185447463307713, 'Total loss': 0.3185447463307713}
2022-11-28 02:07:48,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:48,428 INFO:     Epoch: 62
2022-11-28 02:07:49,168 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41989074647426605, 'Total loss': 0.41989074647426605} | train loss {'Reaction outcome loss': 0.3254705037860597, 'Total loss': 0.3254705037860597}
2022-11-28 02:07:49,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:49,168 INFO:     Epoch: 63
2022-11-28 02:07:49,912 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4300709976706394, 'Total loss': 0.4300709976706394} | train loss {'Reaction outcome loss': 0.3136658580882139, 'Total loss': 0.3136658580882139}
2022-11-28 02:07:49,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:49,912 INFO:     Epoch: 64
2022-11-28 02:07:50,655 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4250143208476, 'Total loss': 0.4250143208476} | train loss {'Reaction outcome loss': 0.3166698458925134, 'Total loss': 0.3166698458925134}
2022-11-28 02:07:50,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:50,655 INFO:     Epoch: 65
2022-11-28 02:07:51,398 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45043517094711927, 'Total loss': 0.45043517094711927} | train loss {'Reaction outcome loss': 0.32332358802439737, 'Total loss': 0.32332358802439737}
2022-11-28 02:07:51,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:51,398 INFO:     Epoch: 66
2022-11-28 02:07:52,140 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44148719830568445, 'Total loss': 0.44148719830568445} | train loss {'Reaction outcome loss': 0.32053260076180345, 'Total loss': 0.32053260076180345}
2022-11-28 02:07:52,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:52,140 INFO:     Epoch: 67
2022-11-28 02:07:52,879 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41545314220495, 'Total loss': 0.41545314220495} | train loss {'Reaction outcome loss': 0.3169086139771293, 'Total loss': 0.3169086139771293}
2022-11-28 02:07:52,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:52,880 INFO:     Epoch: 68
2022-11-28 02:07:53,622 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4252538310233937, 'Total loss': 0.4252538310233937} | train loss {'Reaction outcome loss': 0.31498036667948864, 'Total loss': 0.31498036667948864}
2022-11-28 02:07:53,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:53,622 INFO:     Epoch: 69
2022-11-28 02:07:54,367 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4173967748187309, 'Total loss': 0.4173967748187309} | train loss {'Reaction outcome loss': 0.30840880381035024, 'Total loss': 0.30840880381035024}
2022-11-28 02:07:54,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:54,367 INFO:     Epoch: 70
2022-11-28 02:07:55,112 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4174828047669211, 'Total loss': 0.4174828047669211} | train loss {'Reaction outcome loss': 0.3250163685164002, 'Total loss': 0.3250163685164002}
2022-11-28 02:07:55,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:55,113 INFO:     Epoch: 71
2022-11-28 02:07:55,856 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42319786236729734, 'Total loss': 0.42319786236729734} | train loss {'Reaction outcome loss': 0.31876708321334396, 'Total loss': 0.31876708321334396}
2022-11-28 02:07:55,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:55,856 INFO:     Epoch: 72
2022-11-28 02:07:56,597 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45157715678215027, 'Total loss': 0.45157715678215027} | train loss {'Reaction outcome loss': 0.3238118150134067, 'Total loss': 0.3238118150134067}
2022-11-28 02:07:56,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:56,597 INFO:     Epoch: 73
2022-11-28 02:07:57,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41873085845348446, 'Total loss': 0.41873085845348446} | train loss {'Reaction outcome loss': 0.3250396889252741, 'Total loss': 0.3250396889252741}
2022-11-28 02:07:57,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:57,336 INFO:     Epoch: 74
2022-11-28 02:07:58,078 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44684189246144407, 'Total loss': 0.44684189246144407} | train loss {'Reaction outcome loss': 0.30929155913410616, 'Total loss': 0.30929155913410616}
2022-11-28 02:07:58,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:58,079 INFO:     Epoch: 75
2022-11-28 02:07:58,821 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40607496160407397, 'Total loss': 0.40607496160407397} | train loss {'Reaction outcome loss': 0.3172630094846741, 'Total loss': 0.3172630094846741}
2022-11-28 02:07:58,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:58,821 INFO:     Epoch: 76
2022-11-28 02:07:59,568 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40127958391988, 'Total loss': 0.40127958391988} | train loss {'Reaction outcome loss': 0.31547909816269015, 'Total loss': 0.31547909816269015}
2022-11-28 02:07:59,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:07:59,568 INFO:     Epoch: 77
2022-11-28 02:08:00,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.399460406844006, 'Total loss': 0.399460406844006} | train loss {'Reaction outcome loss': 0.323668666275554, 'Total loss': 0.323668666275554}
2022-11-28 02:08:00,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:00,312 INFO:     Epoch: 78
2022-11-28 02:08:01,053 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3915880131860112, 'Total loss': 0.3915880131860112} | train loss {'Reaction outcome loss': 0.31293771309075785, 'Total loss': 0.31293771309075785}
2022-11-28 02:08:01,054 INFO:     Found new best model at epoch 78
2022-11-28 02:08:01,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:01,055 INFO:     Epoch: 79
2022-11-28 02:08:01,797 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44793437178744827, 'Total loss': 0.44793437178744827} | train loss {'Reaction outcome loss': 0.31495165043189877, 'Total loss': 0.31495165043189877}
2022-11-28 02:08:01,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:01,797 INFO:     Epoch: 80
2022-11-28 02:08:02,541 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4231220842447392, 'Total loss': 0.4231220842447392} | train loss {'Reaction outcome loss': 0.30910850337660706, 'Total loss': 0.30910850337660706}
2022-11-28 02:08:02,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:02,541 INFO:     Epoch: 81
2022-11-28 02:08:03,285 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39574811659580056, 'Total loss': 0.39574811659580056} | train loss {'Reaction outcome loss': 0.3147805450239875, 'Total loss': 0.3147805450239875}
2022-11-28 02:08:03,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:03,285 INFO:     Epoch: 82
2022-11-28 02:08:04,028 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45648662711298743, 'Total loss': 0.45648662711298743} | train loss {'Reaction outcome loss': 0.3090227938516707, 'Total loss': 0.3090227938516707}
2022-11-28 02:08:04,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:04,028 INFO:     Epoch: 83
2022-11-28 02:08:04,770 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4051112622715706, 'Total loss': 0.4051112622715706} | train loss {'Reaction outcome loss': 0.32756261371808953, 'Total loss': 0.32756261371808953}
2022-11-28 02:08:04,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:04,770 INFO:     Epoch: 84
2022-11-28 02:08:05,511 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4251020963108817, 'Total loss': 0.4251020963108817} | train loss {'Reaction outcome loss': 0.3126606535716135, 'Total loss': 0.3126606535716135}
2022-11-28 02:08:05,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:05,512 INFO:     Epoch: 85
2022-11-28 02:08:06,253 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40535669028759, 'Total loss': 0.40535669028759} | train loss {'Reaction outcome loss': 0.31633944296446004, 'Total loss': 0.31633944296446004}
2022-11-28 02:08:06,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:06,253 INFO:     Epoch: 86
2022-11-28 02:08:06,995 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3931515636139138, 'Total loss': 0.3931515636139138} | train loss {'Reaction outcome loss': 0.3132147682433734, 'Total loss': 0.3132147682433734}
2022-11-28 02:08:06,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:06,995 INFO:     Epoch: 87
2022-11-28 02:08:07,734 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45235536992549896, 'Total loss': 0.45235536992549896} | train loss {'Reaction outcome loss': 0.3106175275427885, 'Total loss': 0.3106175275427885}
2022-11-28 02:08:07,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:07,734 INFO:     Epoch: 88
2022-11-28 02:08:08,475 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40035766640374826, 'Total loss': 0.40035766640374826} | train loss {'Reaction outcome loss': 0.31163003201001005, 'Total loss': 0.31163003201001005}
2022-11-28 02:08:08,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:08,475 INFO:     Epoch: 89
2022-11-28 02:08:09,217 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41415838619997336, 'Total loss': 0.41415838619997336} | train loss {'Reaction outcome loss': 0.3131307169153798, 'Total loss': 0.3131307169153798}
2022-11-28 02:08:09,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:09,217 INFO:     Epoch: 90
2022-11-28 02:08:09,964 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3878088357836701, 'Total loss': 0.3878088357836701} | train loss {'Reaction outcome loss': 0.3058179629447519, 'Total loss': 0.3058179629447519}
2022-11-28 02:08:09,964 INFO:     Found new best model at epoch 90
2022-11-28 02:08:09,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:09,965 INFO:     Epoch: 91
2022-11-28 02:08:10,709 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39725507657195247, 'Total loss': 0.39725507657195247} | train loss {'Reaction outcome loss': 0.3149694453802754, 'Total loss': 0.3149694453802754}
2022-11-28 02:08:10,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:10,709 INFO:     Epoch: 92
2022-11-28 02:08:11,451 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41430044382117515, 'Total loss': 0.41430044382117515} | train loss {'Reaction outcome loss': 0.31138084318916326, 'Total loss': 0.31138084318916326}
2022-11-28 02:08:11,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:11,452 INFO:     Epoch: 93
2022-11-28 02:08:12,194 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4552190556775692, 'Total loss': 0.4552190556775692} | train loss {'Reaction outcome loss': 0.3099114806238623, 'Total loss': 0.3099114806238623}
2022-11-28 02:08:12,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:12,194 INFO:     Epoch: 94
2022-11-28 02:08:12,936 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43439708927343057, 'Total loss': 0.43439708927343057} | train loss {'Reaction outcome loss': 0.31690666765035663, 'Total loss': 0.31690666765035663}
2022-11-28 02:08:12,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:12,937 INFO:     Epoch: 95
2022-11-28 02:08:13,683 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40153556473033375, 'Total loss': 0.40153556473033375} | train loss {'Reaction outcome loss': 0.31747695852498536, 'Total loss': 0.31747695852498536}
2022-11-28 02:08:13,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:13,684 INFO:     Epoch: 96
2022-11-28 02:08:14,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44504464885523154, 'Total loss': 0.44504464885523154} | train loss {'Reaction outcome loss': 0.32276551199496767, 'Total loss': 0.32276551199496767}
2022-11-28 02:08:14,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:14,429 INFO:     Epoch: 97
2022-11-28 02:08:15,174 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4141299265415169, 'Total loss': 0.4141299265415169} | train loss {'Reaction outcome loss': 0.32336012596172875, 'Total loss': 0.32336012596172875}
2022-11-28 02:08:15,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:15,174 INFO:     Epoch: 98
2022-11-28 02:08:15,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43591575671074, 'Total loss': 0.43591575671074} | train loss {'Reaction outcome loss': 0.3133379588605928, 'Total loss': 0.3133379588605928}
2022-11-28 02:08:15,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:15,919 INFO:     Epoch: 99
2022-11-28 02:08:16,663 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4138123909401339, 'Total loss': 0.4138123909401339} | train loss {'Reaction outcome loss': 0.3096168615290376, 'Total loss': 0.3096168615290376}
2022-11-28 02:08:16,664 INFO:     Best model found after epoch 91 of 100.
2022-11-28 02:08:16,664 INFO:   Done with stage: TRAINING
2022-11-28 02:08:16,664 INFO:   Starting stage: EVALUATION
2022-11-28 02:08:16,801 INFO:   Done with stage: EVALUATION
2022-11-28 02:08:16,801 INFO:   Leaving out SEQ value Fold_1
2022-11-28 02:08:16,814 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:08:16,814 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:08:17,456 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:08:17,456 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:08:17,523 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:08:17,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:08:17,523 INFO:     No hyperparam tuning for this model
2022-11-28 02:08:17,524 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:08:17,524 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:08:17,524 INFO:     None feature selector for col prot
2022-11-28 02:08:17,524 INFO:     None feature selector for col prot
2022-11-28 02:08:17,524 INFO:     None feature selector for col prot
2022-11-28 02:08:17,525 INFO:     None feature selector for col chem
2022-11-28 02:08:17,525 INFO:     None feature selector for col chem
2022-11-28 02:08:17,525 INFO:     None feature selector for col chem
2022-11-28 02:08:17,525 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:08:17,525 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:08:17,527 INFO:     Number of params in model 169741
2022-11-28 02:08:17,530 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:08:17,530 INFO:   Starting stage: TRAINING
2022-11-28 02:08:17,583 INFO:     Val loss before train {'Reaction outcome loss': 0.984164526516741, 'Total loss': 0.984164526516741}
2022-11-28 02:08:17,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:17,583 INFO:     Epoch: 0
2022-11-28 02:08:18,332 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5418931509960782, 'Total loss': 0.5418931509960782} | train loss {'Reaction outcome loss': 0.6454436898231506, 'Total loss': 0.6454436898231506}
2022-11-28 02:08:18,332 INFO:     Found new best model at epoch 0
2022-11-28 02:08:18,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:18,333 INFO:     Epoch: 1
2022-11-28 02:08:19,082 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5161291252483021, 'Total loss': 0.5161291252483021} | train loss {'Reaction outcome loss': 0.5181870647230927, 'Total loss': 0.5181870647230927}
2022-11-28 02:08:19,082 INFO:     Found new best model at epoch 1
2022-11-28 02:08:19,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:19,083 INFO:     Epoch: 2
2022-11-28 02:08:19,826 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5312872407111254, 'Total loss': 0.5312872407111254} | train loss {'Reaction outcome loss': 0.46779282001816497, 'Total loss': 0.46779282001816497}
2022-11-28 02:08:19,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:19,826 INFO:     Epoch: 3
2022-11-28 02:08:20,572 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4643210213292729, 'Total loss': 0.4643210213292729} | train loss {'Reaction outcome loss': 0.4468439461625352, 'Total loss': 0.4468439461625352}
2022-11-28 02:08:20,572 INFO:     Found new best model at epoch 3
2022-11-28 02:08:20,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:20,573 INFO:     Epoch: 4
2022-11-28 02:08:21,320 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4677929200909354, 'Total loss': 0.4677929200909354} | train loss {'Reaction outcome loss': 0.4266919037517236, 'Total loss': 0.4266919037517236}
2022-11-28 02:08:21,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:21,320 INFO:     Epoch: 5
2022-11-28 02:08:22,066 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4372436771677299, 'Total loss': 0.4372436771677299} | train loss {'Reaction outcome loss': 0.4129088328505049, 'Total loss': 0.4129088328505049}
2022-11-28 02:08:22,066 INFO:     Found new best model at epoch 5
2022-11-28 02:08:22,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:22,067 INFO:     Epoch: 6
2022-11-28 02:08:22,815 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4720402143218301, 'Total loss': 0.4720402143218301} | train loss {'Reaction outcome loss': 0.41630587054758655, 'Total loss': 0.41630587054758655}
2022-11-28 02:08:22,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:22,815 INFO:     Epoch: 7
2022-11-28 02:08:23,562 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43738010965965013, 'Total loss': 0.43738010965965013} | train loss {'Reaction outcome loss': 0.3893866552077994, 'Total loss': 0.3893866552077994}
2022-11-28 02:08:23,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:23,563 INFO:     Epoch: 8
2022-11-28 02:08:24,307 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44466441768136894, 'Total loss': 0.44466441768136894} | train loss {'Reaction outcome loss': 0.38773037976756386, 'Total loss': 0.38773037976756386}
2022-11-28 02:08:24,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:24,308 INFO:     Epoch: 9
2022-11-28 02:08:25,056 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42619026672433724, 'Total loss': 0.42619026672433724} | train loss {'Reaction outcome loss': 0.383350629374689, 'Total loss': 0.383350629374689}
2022-11-28 02:08:25,056 INFO:     Found new best model at epoch 9
2022-11-28 02:08:25,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:25,057 INFO:     Epoch: 10
2022-11-28 02:08:25,807 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4633472036908973, 'Total loss': 0.4633472036908973} | train loss {'Reaction outcome loss': 0.373401891090432, 'Total loss': 0.373401891090432}
2022-11-28 02:08:25,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:25,807 INFO:     Epoch: 11
2022-11-28 02:08:26,553 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.424371656707742, 'Total loss': 0.424371656707742} | train loss {'Reaction outcome loss': 0.36715421238724066, 'Total loss': 0.36715421238724066}
2022-11-28 02:08:26,553 INFO:     Found new best model at epoch 11
2022-11-28 02:08:26,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:26,554 INFO:     Epoch: 12
2022-11-28 02:08:27,296 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.442548529329625, 'Total loss': 0.442548529329625} | train loss {'Reaction outcome loss': 0.3706247858246978, 'Total loss': 0.3706247858246978}
2022-11-28 02:08:27,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:27,297 INFO:     Epoch: 13
2022-11-28 02:08:28,042 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42725846950303425, 'Total loss': 0.42725846950303425} | train loss {'Reaction outcome loss': 0.3560039639168856, 'Total loss': 0.3560039639168856}
2022-11-28 02:08:28,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:28,042 INFO:     Epoch: 14
2022-11-28 02:08:28,791 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4192976914346218, 'Total loss': 0.4192976914346218} | train loss {'Reaction outcome loss': 0.3596437025739222, 'Total loss': 0.3596437025739222}
2022-11-28 02:08:28,791 INFO:     Found new best model at epoch 14
2022-11-28 02:08:28,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:28,792 INFO:     Epoch: 15
2022-11-28 02:08:29,540 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44934211705218663, 'Total loss': 0.44934211705218663} | train loss {'Reaction outcome loss': 0.3559846398477652, 'Total loss': 0.3559846398477652}
2022-11-28 02:08:29,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:29,540 INFO:     Epoch: 16
2022-11-28 02:08:30,283 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4513941505415873, 'Total loss': 0.4513941505415873} | train loss {'Reaction outcome loss': 0.3538175688714397, 'Total loss': 0.3538175688714397}
2022-11-28 02:08:30,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:30,283 INFO:     Epoch: 17
2022-11-28 02:08:31,030 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4388253478841348, 'Total loss': 0.4388253478841348} | train loss {'Reaction outcome loss': 0.34371330467413885, 'Total loss': 0.34371330467413885}
2022-11-28 02:08:31,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:31,031 INFO:     Epoch: 18
2022-11-28 02:08:31,774 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4473949721591039, 'Total loss': 0.4473949721591039} | train loss {'Reaction outcome loss': 0.34475296659737215, 'Total loss': 0.34475296659737215}
2022-11-28 02:08:31,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:31,775 INFO:     Epoch: 19
2022-11-28 02:08:32,516 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4113612747327848, 'Total loss': 0.4113612747327848} | train loss {'Reaction outcome loss': 0.35498370485646386, 'Total loss': 0.35498370485646386}
2022-11-28 02:08:32,516 INFO:     Found new best model at epoch 19
2022-11-28 02:08:32,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:32,517 INFO:     Epoch: 20
2022-11-28 02:08:33,265 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41925976306877355, 'Total loss': 0.41925976306877355} | train loss {'Reaction outcome loss': 0.33939341635120157, 'Total loss': 0.33939341635120157}
2022-11-28 02:08:33,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:33,265 INFO:     Epoch: 21
2022-11-28 02:08:34,016 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4031805345280604, 'Total loss': 0.4031805345280604} | train loss {'Reaction outcome loss': 0.3442895166423856, 'Total loss': 0.3442895166423856}
2022-11-28 02:08:34,016 INFO:     Found new best model at epoch 21
2022-11-28 02:08:34,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:34,017 INFO:     Epoch: 22
2022-11-28 02:08:34,763 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41762319139458914, 'Total loss': 0.41762319139458914} | train loss {'Reaction outcome loss': 0.33873771827439875, 'Total loss': 0.33873771827439875}
2022-11-28 02:08:34,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:34,763 INFO:     Epoch: 23
2022-11-28 02:08:35,506 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4089020443233577, 'Total loss': 0.4089020443233577} | train loss {'Reaction outcome loss': 0.3374741268097138, 'Total loss': 0.3374741268097138}
2022-11-28 02:08:35,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:35,507 INFO:     Epoch: 24
2022-11-28 02:08:36,255 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46356770531697705, 'Total loss': 0.46356770531697705} | train loss {'Reaction outcome loss': 0.3384265022922535, 'Total loss': 0.3384265022922535}
2022-11-28 02:08:36,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:36,255 INFO:     Epoch: 25
2022-11-28 02:08:37,001 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42290726507251913, 'Total loss': 0.42290726507251913} | train loss {'Reaction outcome loss': 0.3270992708753566, 'Total loss': 0.3270992708753566}
2022-11-28 02:08:37,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:37,001 INFO:     Epoch: 26
2022-11-28 02:08:37,746 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4297626621343873, 'Total loss': 0.4297626621343873} | train loss {'Reaction outcome loss': 0.3292914055743996, 'Total loss': 0.3292914055743996}
2022-11-28 02:08:37,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:37,747 INFO:     Epoch: 27
2022-11-28 02:08:38,494 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46122234619476576, 'Total loss': 0.46122234619476576} | train loss {'Reaction outcome loss': 0.3296297856435484, 'Total loss': 0.3296297856435484}
2022-11-28 02:08:38,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:38,495 INFO:     Epoch: 28
2022-11-28 02:08:39,242 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40883983684365044, 'Total loss': 0.40883983684365044} | train loss {'Reaction outcome loss': 0.3303224187420339, 'Total loss': 0.3303224187420339}
2022-11-28 02:08:39,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:39,243 INFO:     Epoch: 29
2022-11-28 02:08:39,989 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41716315326365555, 'Total loss': 0.41716315326365555} | train loss {'Reaction outcome loss': 0.3259609376289407, 'Total loss': 0.3259609376289407}
2022-11-28 02:08:39,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:39,990 INFO:     Epoch: 30
2022-11-28 02:08:40,736 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4165500326251442, 'Total loss': 0.4165500326251442} | train loss {'Reaction outcome loss': 0.3277363182634723, 'Total loss': 0.3277363182634723}
2022-11-28 02:08:40,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:40,744 INFO:     Epoch: 31
2022-11-28 02:08:41,491 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4445243975655599, 'Total loss': 0.4445243975655599} | train loss {'Reaction outcome loss': 0.32401054008882874, 'Total loss': 0.32401054008882874}
2022-11-28 02:08:41,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:41,491 INFO:     Epoch: 32
2022-11-28 02:08:42,242 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4158438064835288, 'Total loss': 0.4158438064835288} | train loss {'Reaction outcome loss': 0.3324429751658926, 'Total loss': 0.3324429751658926}
2022-11-28 02:08:42,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:42,243 INFO:     Epoch: 33
2022-11-28 02:08:42,993 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43357608060945163, 'Total loss': 0.43357608060945163} | train loss {'Reaction outcome loss': 0.32556730530091693, 'Total loss': 0.32556730530091693}
2022-11-28 02:08:42,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:42,993 INFO:     Epoch: 34
2022-11-28 02:08:43,747 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3875351317904212, 'Total loss': 0.3875351317904212} | train loss {'Reaction outcome loss': 0.32174176528137555, 'Total loss': 0.32174176528137555}
2022-11-28 02:08:43,748 INFO:     Found new best model at epoch 34
2022-11-28 02:08:43,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:43,749 INFO:     Epoch: 35
2022-11-28 02:08:44,506 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4143888804722916, 'Total loss': 0.4143888804722916} | train loss {'Reaction outcome loss': 0.33128848115400394, 'Total loss': 0.33128848115400394}
2022-11-28 02:08:44,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:44,506 INFO:     Epoch: 36
2022-11-28 02:08:45,258 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40769174457951024, 'Total loss': 0.40769174457951024} | train loss {'Reaction outcome loss': 0.32335677916298106, 'Total loss': 0.32335677916298106}
2022-11-28 02:08:45,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:45,258 INFO:     Epoch: 37
2022-11-28 02:08:46,009 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4350977936251597, 'Total loss': 0.4350977936251597} | train loss {'Reaction outcome loss': 0.31989876247790394, 'Total loss': 0.31989876247790394}
2022-11-28 02:08:46,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:46,009 INFO:     Epoch: 38
2022-11-28 02:08:46,762 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4089733670380982, 'Total loss': 0.4089733670380982} | train loss {'Reaction outcome loss': 0.32349117878748446, 'Total loss': 0.32349117878748446}
2022-11-28 02:08:46,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:46,762 INFO:     Epoch: 39
2022-11-28 02:08:47,516 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4161925884810361, 'Total loss': 0.4161925884810361} | train loss {'Reaction outcome loss': 0.32394845567795694, 'Total loss': 0.32394845567795694}
2022-11-28 02:08:47,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:47,516 INFO:     Epoch: 40
2022-11-28 02:08:48,265 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4309548396955837, 'Total loss': 0.4309548396955837} | train loss {'Reaction outcome loss': 0.3195958288652556, 'Total loss': 0.3195958288652556}
2022-11-28 02:08:48,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:48,265 INFO:     Epoch: 41
2022-11-28 02:08:49,015 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41044471954757517, 'Total loss': 0.41044471954757517} | train loss {'Reaction outcome loss': 0.3145697736770523, 'Total loss': 0.3145697736770523}
2022-11-28 02:08:49,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:49,015 INFO:     Epoch: 42
2022-11-28 02:08:49,765 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45195190235972404, 'Total loss': 0.45195190235972404} | train loss {'Reaction outcome loss': 0.31999601197181915, 'Total loss': 0.31999601197181915}
2022-11-28 02:08:49,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:49,766 INFO:     Epoch: 43
2022-11-28 02:08:50,514 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39344692196358333, 'Total loss': 0.39344692196358333} | train loss {'Reaction outcome loss': 0.32055667021444867, 'Total loss': 0.32055667021444867}
2022-11-28 02:08:50,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:50,514 INFO:     Epoch: 44
2022-11-28 02:08:51,263 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40111135522072966, 'Total loss': 0.40111135522072966} | train loss {'Reaction outcome loss': 0.31337232300821616, 'Total loss': 0.31337232300821616}
2022-11-28 02:08:51,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:51,263 INFO:     Epoch: 45
2022-11-28 02:08:52,013 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43238870765675197, 'Total loss': 0.43238870765675197} | train loss {'Reaction outcome loss': 0.3174644179794253, 'Total loss': 0.3174644179794253}
2022-11-28 02:08:52,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:52,013 INFO:     Epoch: 46
2022-11-28 02:08:52,765 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42887414687059144, 'Total loss': 0.42887414687059144} | train loss {'Reaction outcome loss': 0.31968063450589473, 'Total loss': 0.31968063450589473}
2022-11-28 02:08:52,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:52,765 INFO:     Epoch: 47
2022-11-28 02:08:53,519 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4265804395756938, 'Total loss': 0.4265804395756938} | train loss {'Reaction outcome loss': 0.30761322251388007, 'Total loss': 0.30761322251388007}
2022-11-28 02:08:53,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:53,519 INFO:     Epoch: 48
2022-11-28 02:08:54,267 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4394437420097264, 'Total loss': 0.4394437420097264} | train loss {'Reaction outcome loss': 0.3149287513020087, 'Total loss': 0.3149287513020087}
2022-11-28 02:08:54,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:54,267 INFO:     Epoch: 49
2022-11-28 02:08:55,016 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43846995586698706, 'Total loss': 0.43846995586698706} | train loss {'Reaction outcome loss': 0.3145167825477464, 'Total loss': 0.3145167825477464}
2022-11-28 02:08:55,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:55,016 INFO:     Epoch: 50
2022-11-28 02:08:55,769 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4298024406148629, 'Total loss': 0.4298024406148629} | train loss {'Reaction outcome loss': 0.31393904771123615, 'Total loss': 0.31393904771123615}
2022-11-28 02:08:55,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:55,770 INFO:     Epoch: 51
2022-11-28 02:08:56,520 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41140255094929173, 'Total loss': 0.41140255094929173} | train loss {'Reaction outcome loss': 0.32534444380779654, 'Total loss': 0.32534444380779654}
2022-11-28 02:08:56,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:56,520 INFO:     Epoch: 52
2022-11-28 02:08:57,271 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4410720145837827, 'Total loss': 0.4410720145837827} | train loss {'Reaction outcome loss': 0.3108398218544162, 'Total loss': 0.3108398218544162}
2022-11-28 02:08:57,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:57,271 INFO:     Epoch: 53
2022-11-28 02:08:58,021 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4133003587749871, 'Total loss': 0.4133003587749871} | train loss {'Reaction outcome loss': 0.32340906602995734, 'Total loss': 0.32340906602995734}
2022-11-28 02:08:58,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:58,021 INFO:     Epoch: 54
2022-11-28 02:08:58,771 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4125542478127913, 'Total loss': 0.4125542478127913} | train loss {'Reaction outcome loss': 0.3139225860639494, 'Total loss': 0.3139225860639494}
2022-11-28 02:08:58,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:58,771 INFO:     Epoch: 55
2022-11-28 02:08:59,524 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42904027009552176, 'Total loss': 0.42904027009552176} | train loss {'Reaction outcome loss': 0.31517037104587164, 'Total loss': 0.31517037104587164}
2022-11-28 02:08:59,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:08:59,524 INFO:     Epoch: 56
2022-11-28 02:09:00,274 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45973784815181384, 'Total loss': 0.45973784815181384} | train loss {'Reaction outcome loss': 0.30395890748014254, 'Total loss': 0.30395890748014254}
2022-11-28 02:09:00,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:00,274 INFO:     Epoch: 57
2022-11-28 02:09:01,026 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43488769030029123, 'Total loss': 0.43488769030029123} | train loss {'Reaction outcome loss': 0.31046554105622426, 'Total loss': 0.31046554105622426}
2022-11-28 02:09:01,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:01,026 INFO:     Epoch: 58
2022-11-28 02:09:01,776 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4153987257423895, 'Total loss': 0.4153987257423895} | train loss {'Reaction outcome loss': 0.3062261787908418, 'Total loss': 0.3062261787908418}
2022-11-28 02:09:01,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:01,777 INFO:     Epoch: 59
2022-11-28 02:09:02,524 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43066433376886626, 'Total loss': 0.43066433376886626} | train loss {'Reaction outcome loss': 0.3079914020336404, 'Total loss': 0.3079914020336404}
2022-11-28 02:09:02,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:02,525 INFO:     Epoch: 60
2022-11-28 02:09:03,268 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40600717220116744, 'Total loss': 0.40600717220116744} | train loss {'Reaction outcome loss': 0.3168890289810239, 'Total loss': 0.3168890289810239}
2022-11-28 02:09:03,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:03,268 INFO:     Epoch: 61
2022-11-28 02:09:04,012 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38669458658180456, 'Total loss': 0.38669458658180456} | train loss {'Reaction outcome loss': 0.3077054702201668, 'Total loss': 0.3077054702201668}
2022-11-28 02:09:04,012 INFO:     Found new best model at epoch 61
2022-11-28 02:09:04,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:04,013 INFO:     Epoch: 62
2022-11-28 02:09:04,761 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43138396502895787, 'Total loss': 0.43138396502895787} | train loss {'Reaction outcome loss': 0.3062031600244191, 'Total loss': 0.3062031600244191}
2022-11-28 02:09:04,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:04,761 INFO:     Epoch: 63
2022-11-28 02:09:05,511 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4269633117047223, 'Total loss': 0.4269633117047223} | train loss {'Reaction outcome loss': 0.3178530769384637, 'Total loss': 0.3178530769384637}
2022-11-28 02:09:05,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:05,512 INFO:     Epoch: 64
2022-11-28 02:09:06,265 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42205219343304634, 'Total loss': 0.42205219343304634} | train loss {'Reaction outcome loss': 0.31301230733491936, 'Total loss': 0.31301230733491936}
2022-11-28 02:09:06,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:06,265 INFO:     Epoch: 65
2022-11-28 02:09:07,010 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40714474428783765, 'Total loss': 0.40714474428783765} | train loss {'Reaction outcome loss': 0.2991102655019079, 'Total loss': 0.2991102655019079}
2022-11-28 02:09:07,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:07,010 INFO:     Epoch: 66
2022-11-28 02:09:07,759 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4131448892029849, 'Total loss': 0.4131448892029849} | train loss {'Reaction outcome loss': 0.3091283847938995, 'Total loss': 0.3091283847938995}
2022-11-28 02:09:07,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:07,759 INFO:     Epoch: 67
2022-11-28 02:09:08,504 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41466736082326283, 'Total loss': 0.41466736082326283} | train loss {'Reaction outcome loss': 0.31725809102763936, 'Total loss': 0.31725809102763936}
2022-11-28 02:09:08,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:08,504 INFO:     Epoch: 68
2022-11-28 02:09:09,251 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4222337617115541, 'Total loss': 0.4222337617115541} | train loss {'Reaction outcome loss': 0.2987889814437652, 'Total loss': 0.2987889814437652}
2022-11-28 02:09:09,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:09,252 INFO:     Epoch: 69
2022-11-28 02:09:09,995 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43406378816474567, 'Total loss': 0.43406378816474567} | train loss {'Reaction outcome loss': 0.3062555115441887, 'Total loss': 0.3062555115441887}
2022-11-28 02:09:09,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:09,995 INFO:     Epoch: 70
2022-11-28 02:09:10,741 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4108250459486788, 'Total loss': 0.4108250459486788} | train loss {'Reaction outcome loss': 0.30578088714760177, 'Total loss': 0.30578088714760177}
2022-11-28 02:09:10,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:10,741 INFO:     Epoch: 71
2022-11-28 02:09:11,488 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43098763478073204, 'Total loss': 0.43098763478073204} | train loss {'Reaction outcome loss': 0.30557122729262526, 'Total loss': 0.30557122729262526}
2022-11-28 02:09:11,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:11,488 INFO:     Epoch: 72
2022-11-28 02:09:12,233 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4329404671761123, 'Total loss': 0.4329404671761123} | train loss {'Reaction outcome loss': 0.3125359707949113, 'Total loss': 0.3125359707949113}
2022-11-28 02:09:12,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:12,233 INFO:     Epoch: 73
2022-11-28 02:09:12,979 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4061977636407722, 'Total loss': 0.4061977636407722} | train loss {'Reaction outcome loss': 0.29999894487614537, 'Total loss': 0.29999894487614537}
2022-11-28 02:09:12,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:12,980 INFO:     Epoch: 74
2022-11-28 02:09:13,732 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4336960657753728, 'Total loss': 0.4336960657753728} | train loss {'Reaction outcome loss': 0.30466297661163366, 'Total loss': 0.30466297661163366}
2022-11-28 02:09:13,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:13,732 INFO:     Epoch: 75
2022-11-28 02:09:14,478 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4287756925279444, 'Total loss': 0.4287756925279444} | train loss {'Reaction outcome loss': 0.31054960741680493, 'Total loss': 0.31054960741680493}
2022-11-28 02:09:14,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:14,479 INFO:     Epoch: 76
2022-11-28 02:09:15,226 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4298510104417801, 'Total loss': 0.4298510104417801} | train loss {'Reaction outcome loss': 0.2962608602582192, 'Total loss': 0.2962608602582192}
2022-11-28 02:09:15,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:15,227 INFO:     Epoch: 77
2022-11-28 02:09:15,974 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45418917861851776, 'Total loss': 0.45418917861851776} | train loss {'Reaction outcome loss': 0.29779637702265566, 'Total loss': 0.29779637702265566}
2022-11-28 02:09:15,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:15,974 INFO:     Epoch: 78
2022-11-28 02:09:16,723 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42393642748092214, 'Total loss': 0.42393642748092214} | train loss {'Reaction outcome loss': 0.30406425701720374, 'Total loss': 0.30406425701720374}
2022-11-28 02:09:16,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:16,723 INFO:     Epoch: 79
2022-11-28 02:09:17,474 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42777677151289856, 'Total loss': 0.42777677151289856} | train loss {'Reaction outcome loss': 0.3112156999658565, 'Total loss': 0.3112156999658565}
2022-11-28 02:09:17,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:17,474 INFO:     Epoch: 80
2022-11-28 02:09:18,219 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41439417512579396, 'Total loss': 0.41439417512579396} | train loss {'Reaction outcome loss': 0.3166083426956011, 'Total loss': 0.3166083426956011}
2022-11-28 02:09:18,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:18,219 INFO:     Epoch: 81
2022-11-28 02:09:18,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45236762308261613, 'Total loss': 0.45236762308261613} | train loss {'Reaction outcome loss': 0.30478237151187293, 'Total loss': 0.30478237151187293}
2022-11-28 02:09:18,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:18,961 INFO:     Epoch: 82
2022-11-28 02:09:19,708 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43723995780402963, 'Total loss': 0.43723995780402963} | train loss {'Reaction outcome loss': 0.30587134227460744, 'Total loss': 0.30587134227460744}
2022-11-28 02:09:19,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:19,709 INFO:     Epoch: 83
2022-11-28 02:09:20,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4550406025214629, 'Total loss': 0.4550406025214629} | train loss {'Reaction outcome loss': 0.3090210689573872, 'Total loss': 0.3090210689573872}
2022-11-28 02:09:20,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:20,452 INFO:     Epoch: 84
2022-11-28 02:09:21,198 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3996358188715848, 'Total loss': 0.3996358188715848} | train loss {'Reaction outcome loss': 0.29621016477443735, 'Total loss': 0.29621016477443735}
2022-11-28 02:09:21,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:21,199 INFO:     Epoch: 85
2022-11-28 02:09:21,944 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42672406966713344, 'Total loss': 0.42672406966713344} | train loss {'Reaction outcome loss': 0.3126100338539299, 'Total loss': 0.3126100338539299}
2022-11-28 02:09:21,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:21,944 INFO:     Epoch: 86
2022-11-28 02:09:22,692 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4932531663639979, 'Total loss': 0.4932531663639979} | train loss {'Reaction outcome loss': 0.29894763137004815, 'Total loss': 0.29894763137004815}
2022-11-28 02:09:22,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:22,692 INFO:     Epoch: 87
2022-11-28 02:09:23,435 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43728127228942787, 'Total loss': 0.43728127228942787} | train loss {'Reaction outcome loss': 0.30703069528146665, 'Total loss': 0.30703069528146665}
2022-11-28 02:09:23,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:23,436 INFO:     Epoch: 88
2022-11-28 02:09:24,178 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4067443050444126, 'Total loss': 0.4067443050444126} | train loss {'Reaction outcome loss': 0.30096911642016194, 'Total loss': 0.30096911642016194}
2022-11-28 02:09:24,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:24,178 INFO:     Epoch: 89
2022-11-28 02:09:24,922 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4236294766041366, 'Total loss': 0.4236294766041366} | train loss {'Reaction outcome loss': 0.30688912388013334, 'Total loss': 0.30688912388013334}
2022-11-28 02:09:24,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:24,922 INFO:     Epoch: 90
2022-11-28 02:09:25,668 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4253947792405432, 'Total loss': 0.4253947792405432} | train loss {'Reaction outcome loss': 0.30304526067814047, 'Total loss': 0.30304526067814047}
2022-11-28 02:09:25,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:25,668 INFO:     Epoch: 91
2022-11-28 02:09:26,415 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4391786769371141, 'Total loss': 0.4391786769371141} | train loss {'Reaction outcome loss': 0.30140195595366615, 'Total loss': 0.30140195595366615}
2022-11-28 02:09:26,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:26,415 INFO:     Epoch: 92
2022-11-28 02:09:27,160 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45048440620303154, 'Total loss': 0.45048440620303154} | train loss {'Reaction outcome loss': 0.2909738433908443, 'Total loss': 0.2909738433908443}
2022-11-28 02:09:27,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:27,160 INFO:     Epoch: 93
2022-11-28 02:09:27,902 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4620926437730139, 'Total loss': 0.4620926437730139} | train loss {'Reaction outcome loss': 0.3012222450302572, 'Total loss': 0.3012222450302572}
2022-11-28 02:09:27,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:27,902 INFO:     Epoch: 94
2022-11-28 02:09:28,649 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4392400986768983, 'Total loss': 0.4392400986768983} | train loss {'Reaction outcome loss': 0.30462579035333226, 'Total loss': 0.30462579035333226}
2022-11-28 02:09:28,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:28,650 INFO:     Epoch: 95
2022-11-28 02:09:29,396 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43008242547512054, 'Total loss': 0.43008242547512054} | train loss {'Reaction outcome loss': 0.30065709446765937, 'Total loss': 0.30065709446765937}
2022-11-28 02:09:29,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:29,396 INFO:     Epoch: 96
2022-11-28 02:09:30,144 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4209823316301812, 'Total loss': 0.4209823316301812} | train loss {'Reaction outcome loss': 0.2969518671686552, 'Total loss': 0.2969518671686552}
2022-11-28 02:09:30,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:30,144 INFO:     Epoch: 97
2022-11-28 02:09:30,890 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4278835007412867, 'Total loss': 0.4278835007412867} | train loss {'Reaction outcome loss': 0.2987574934351201, 'Total loss': 0.2987574934351201}
2022-11-28 02:09:30,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:30,890 INFO:     Epoch: 98
2022-11-28 02:09:31,640 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4430317021906376, 'Total loss': 0.4430317021906376} | train loss {'Reaction outcome loss': 0.3025132377993087, 'Total loss': 0.3025132377993087}
2022-11-28 02:09:31,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:31,640 INFO:     Epoch: 99
2022-11-28 02:09:32,387 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43681085685437376, 'Total loss': 0.43681085685437376} | train loss {'Reaction outcome loss': 0.3003565879196537, 'Total loss': 0.3003565879196537}
2022-11-28 02:09:32,388 INFO:     Best model found after epoch 62 of 100.
2022-11-28 02:09:32,388 INFO:   Done with stage: TRAINING
2022-11-28 02:09:32,388 INFO:   Starting stage: EVALUATION
2022-11-28 02:09:32,518 INFO:   Done with stage: EVALUATION
2022-11-28 02:09:32,518 INFO:   Leaving out SEQ value Fold_2
2022-11-28 02:09:32,531 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:09:32,531 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:09:33,183 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:09:33,183 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:09:33,251 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:09:33,252 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:09:33,252 INFO:     No hyperparam tuning for this model
2022-11-28 02:09:33,252 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:09:33,252 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:09:33,253 INFO:     None feature selector for col prot
2022-11-28 02:09:33,253 INFO:     None feature selector for col prot
2022-11-28 02:09:33,253 INFO:     None feature selector for col prot
2022-11-28 02:09:33,254 INFO:     None feature selector for col chem
2022-11-28 02:09:33,254 INFO:     None feature selector for col chem
2022-11-28 02:09:33,254 INFO:     None feature selector for col chem
2022-11-28 02:09:33,254 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:09:33,254 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:09:33,256 INFO:     Number of params in model 169741
2022-11-28 02:09:33,259 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:09:33,259 INFO:   Starting stage: TRAINING
2022-11-28 02:09:33,312 INFO:     Val loss before train {'Reaction outcome loss': 0.9644958778869274, 'Total loss': 0.9644958778869274}
2022-11-28 02:09:33,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:33,312 INFO:     Epoch: 0
2022-11-28 02:09:34,050 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5062403762063314, 'Total loss': 0.5062403762063314} | train loss {'Reaction outcome loss': 0.6390773402374299, 'Total loss': 0.6390773402374299}
2022-11-28 02:09:34,050 INFO:     Found new best model at epoch 0
2022-11-28 02:09:34,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:34,051 INFO:     Epoch: 1
2022-11-28 02:09:34,791 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5213583226120749, 'Total loss': 0.5213583226120749} | train loss {'Reaction outcome loss': 0.49618546310506884, 'Total loss': 0.49618546310506884}
2022-11-28 02:09:34,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:34,792 INFO:     Epoch: 2
2022-11-28 02:09:35,530 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4822351970644884, 'Total loss': 0.4822351970644884} | train loss {'Reaction outcome loss': 0.45975147218244977, 'Total loss': 0.45975147218244977}
2022-11-28 02:09:35,531 INFO:     Found new best model at epoch 2
2022-11-28 02:09:35,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:35,531 INFO:     Epoch: 3
2022-11-28 02:09:36,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45373390095178473, 'Total loss': 0.45373390095178473} | train loss {'Reaction outcome loss': 0.43654640989958265, 'Total loss': 0.43654640989958265}
2022-11-28 02:09:36,270 INFO:     Found new best model at epoch 3
2022-11-28 02:09:36,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:36,271 INFO:     Epoch: 4
2022-11-28 02:09:37,012 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46951850139817525, 'Total loss': 0.46951850139817525} | train loss {'Reaction outcome loss': 0.42353398026135125, 'Total loss': 0.42353398026135125}
2022-11-28 02:09:37,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:37,012 INFO:     Epoch: 5
2022-11-28 02:09:37,753 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43854145185891974, 'Total loss': 0.43854145185891974} | train loss {'Reaction outcome loss': 0.41325914383423135, 'Total loss': 0.41325914383423135}
2022-11-28 02:09:37,753 INFO:     Found new best model at epoch 5
2022-11-28 02:09:37,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:37,754 INFO:     Epoch: 6
2022-11-28 02:09:38,501 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45137429687865943, 'Total loss': 0.45137429687865943} | train loss {'Reaction outcome loss': 0.40749621363814736, 'Total loss': 0.40749621363814736}
2022-11-28 02:09:38,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:38,501 INFO:     Epoch: 7
2022-11-28 02:09:39,240 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43290553935045417, 'Total loss': 0.43290553935045417} | train loss {'Reaction outcome loss': 0.3957893077100887, 'Total loss': 0.3957893077100887}
2022-11-28 02:09:39,240 INFO:     Found new best model at epoch 7
2022-11-28 02:09:39,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:39,241 INFO:     Epoch: 8
2022-11-28 02:09:39,979 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4213016927242279, 'Total loss': 0.4213016927242279} | train loss {'Reaction outcome loss': 0.39671673689831477, 'Total loss': 0.39671673689831477}
2022-11-28 02:09:39,979 INFO:     Found new best model at epoch 8
2022-11-28 02:09:39,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:39,980 INFO:     Epoch: 9
2022-11-28 02:09:40,722 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4376083757988242, 'Total loss': 0.4376083757988242} | train loss {'Reaction outcome loss': 0.38564527166060736, 'Total loss': 0.38564527166060736}
2022-11-28 02:09:40,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:40,723 INFO:     Epoch: 10
2022-11-28 02:09:41,463 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44317540179851445, 'Total loss': 0.44317540179851445} | train loss {'Reaction outcome loss': 0.3758464443390487, 'Total loss': 0.3758464443390487}
2022-11-28 02:09:41,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:41,463 INFO:     Epoch: 11
2022-11-28 02:09:42,203 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41202237578325496, 'Total loss': 0.41202237578325496} | train loss {'Reaction outcome loss': 0.3773839694188266, 'Total loss': 0.3773839694188266}
2022-11-28 02:09:42,203 INFO:     Found new best model at epoch 11
2022-11-28 02:09:42,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:42,204 INFO:     Epoch: 12
2022-11-28 02:09:42,946 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42504843826903854, 'Total loss': 0.42504843826903854} | train loss {'Reaction outcome loss': 0.3710997594428844, 'Total loss': 0.3710997594428844}
2022-11-28 02:09:42,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:42,947 INFO:     Epoch: 13
2022-11-28 02:09:43,689 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4068366715381312, 'Total loss': 0.4068366715381312} | train loss {'Reaction outcome loss': 0.3652407966981657, 'Total loss': 0.3652407966981657}
2022-11-28 02:09:43,690 INFO:     Found new best model at epoch 13
2022-11-28 02:09:43,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:43,691 INFO:     Epoch: 14
2022-11-28 02:09:44,430 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4203376399223195, 'Total loss': 0.4203376399223195} | train loss {'Reaction outcome loss': 0.3623384012550604, 'Total loss': 0.3623384012550604}
2022-11-28 02:09:44,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:44,430 INFO:     Epoch: 15
2022-11-28 02:09:45,170 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4319233835436577, 'Total loss': 0.4319233835436577} | train loss {'Reaction outcome loss': 0.36519207860358427, 'Total loss': 0.36519207860358427}
2022-11-28 02:09:45,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:45,171 INFO:     Epoch: 16
2022-11-28 02:09:45,917 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43737642293752627, 'Total loss': 0.43737642293752627} | train loss {'Reaction outcome loss': 0.3612741655135741, 'Total loss': 0.3612741655135741}
2022-11-28 02:09:45,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:45,918 INFO:     Epoch: 17
2022-11-28 02:09:46,664 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4261401025361793, 'Total loss': 0.4261401025361793} | train loss {'Reaction outcome loss': 0.3537038944234125, 'Total loss': 0.3537038944234125}
2022-11-28 02:09:46,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:46,664 INFO:     Epoch: 18
2022-11-28 02:09:47,403 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42405801630297374, 'Total loss': 0.42405801630297374} | train loss {'Reaction outcome loss': 0.3519691800484892, 'Total loss': 0.3519691800484892}
2022-11-28 02:09:47,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:47,403 INFO:     Epoch: 19
2022-11-28 02:09:48,143 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42181278834509295, 'Total loss': 0.42181278834509295} | train loss {'Reaction outcome loss': 0.34550618899405977, 'Total loss': 0.34550618899405977}
2022-11-28 02:09:48,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:48,144 INFO:     Epoch: 20
2022-11-28 02:09:48,883 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42112090248008105, 'Total loss': 0.42112090248008105} | train loss {'Reaction outcome loss': 0.3482254646932248, 'Total loss': 0.3482254646932248}
2022-11-28 02:09:48,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:48,883 INFO:     Epoch: 21
2022-11-28 02:09:49,622 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42911676265472587, 'Total loss': 0.42911676265472587} | train loss {'Reaction outcome loss': 0.33754390896465936, 'Total loss': 0.33754390896465936}
2022-11-28 02:09:49,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:49,622 INFO:     Epoch: 22
2022-11-28 02:09:50,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43934901024019996, 'Total loss': 0.43934901024019996} | train loss {'Reaction outcome loss': 0.33802606116552825, 'Total loss': 0.33802606116552825}
2022-11-28 02:09:50,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:50,360 INFO:     Epoch: 23
2022-11-28 02:09:51,099 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4225808544907459, 'Total loss': 0.4225808544907459} | train loss {'Reaction outcome loss': 0.3456971886888391, 'Total loss': 0.3456971886888391}
2022-11-28 02:09:51,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:51,099 INFO:     Epoch: 24
2022-11-28 02:09:51,838 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4236707794804906, 'Total loss': 0.4236707794804906} | train loss {'Reaction outcome loss': 0.34590743824106746, 'Total loss': 0.34590743824106746}
2022-11-28 02:09:51,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:51,839 INFO:     Epoch: 25
2022-11-28 02:09:52,581 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41640324544074925, 'Total loss': 0.41640324544074925} | train loss {'Reaction outcome loss': 0.34375454992300175, 'Total loss': 0.34375454992300175}
2022-11-28 02:09:52,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:52,582 INFO:     Epoch: 26
2022-11-28 02:09:53,318 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4179485100646352, 'Total loss': 0.4179485100646352} | train loss {'Reaction outcome loss': 0.3411555621528723, 'Total loss': 0.3411555621528723}
2022-11-28 02:09:53,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:53,318 INFO:     Epoch: 27
2022-11-28 02:09:54,055 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41097950034363323, 'Total loss': 0.41097950034363323} | train loss {'Reaction outcome loss': 0.32827756315714024, 'Total loss': 0.32827756315714024}
2022-11-28 02:09:54,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:54,056 INFO:     Epoch: 28
2022-11-28 02:09:54,800 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4349462604799936, 'Total loss': 0.4349462604799936} | train loss {'Reaction outcome loss': 0.337232859560945, 'Total loss': 0.337232859560945}
2022-11-28 02:09:54,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:54,800 INFO:     Epoch: 29
2022-11-28 02:09:55,546 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44493541052175123, 'Total loss': 0.44493541052175123} | train loss {'Reaction outcome loss': 0.33036975238899713, 'Total loss': 0.33036975238899713}
2022-11-28 02:09:55,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:55,546 INFO:     Epoch: 30
2022-11-28 02:09:56,288 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42552874739779983, 'Total loss': 0.42552874739779983} | train loss {'Reaction outcome loss': 0.33582225335059596, 'Total loss': 0.33582225335059596}
2022-11-28 02:09:56,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:56,288 INFO:     Epoch: 31
2022-11-28 02:09:57,028 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41815753593001254, 'Total loss': 0.41815753593001254} | train loss {'Reaction outcome loss': 0.3304262156674608, 'Total loss': 0.3304262156674608}
2022-11-28 02:09:57,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:57,028 INFO:     Epoch: 32
2022-11-28 02:09:57,767 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4209775429132373, 'Total loss': 0.4209775429132373} | train loss {'Reaction outcome loss': 0.3350215289802825, 'Total loss': 0.3350215289802825}
2022-11-28 02:09:57,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:57,767 INFO:     Epoch: 33
2022-11-28 02:09:58,512 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4060629096835159, 'Total loss': 0.4060629096835159} | train loss {'Reaction outcome loss': 0.32791689035223154, 'Total loss': 0.32791689035223154}
2022-11-28 02:09:58,512 INFO:     Found new best model at epoch 33
2022-11-28 02:09:58,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:58,513 INFO:     Epoch: 34
2022-11-28 02:09:59,255 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42517387381819793, 'Total loss': 0.42517387381819793} | train loss {'Reaction outcome loss': 0.32480709505130034, 'Total loss': 0.32480709505130034}
2022-11-28 02:09:59,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:59,255 INFO:     Epoch: 35
2022-11-28 02:09:59,995 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4357968378205632, 'Total loss': 0.4357968378205632} | train loss {'Reaction outcome loss': 0.3378740611073912, 'Total loss': 0.3378740611073912}
2022-11-28 02:09:59,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:09:59,995 INFO:     Epoch: 36
2022-11-28 02:10:00,734 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42256872009399327, 'Total loss': 0.42256872009399327} | train loss {'Reaction outcome loss': 0.3204250845630638, 'Total loss': 0.3204250845630638}
2022-11-28 02:10:00,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:00,734 INFO:     Epoch: 37
2022-11-28 02:10:01,476 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43421082891697105, 'Total loss': 0.43421082891697105} | train loss {'Reaction outcome loss': 0.32293197888209196, 'Total loss': 0.32293197888209196}
2022-11-28 02:10:01,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:01,476 INFO:     Epoch: 38
2022-11-28 02:10:02,214 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4209776084090388, 'Total loss': 0.4209776084090388} | train loss {'Reaction outcome loss': 0.32573706052098117, 'Total loss': 0.32573706052098117}
2022-11-28 02:10:02,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:02,215 INFO:     Epoch: 39
2022-11-28 02:10:02,953 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4202943960594576, 'Total loss': 0.4202943960594576} | train loss {'Reaction outcome loss': 0.32830517787913804, 'Total loss': 0.32830517787913804}
2022-11-28 02:10:02,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:02,953 INFO:     Epoch: 40
2022-11-28 02:10:03,693 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42227982175211576, 'Total loss': 0.42227982175211576} | train loss {'Reaction outcome loss': 0.32534686445457034, 'Total loss': 0.32534686445457034}
2022-11-28 02:10:03,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:03,693 INFO:     Epoch: 41
2022-11-28 02:10:04,431 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3993583039142365, 'Total loss': 0.3993583039142365} | train loss {'Reaction outcome loss': 0.3225531661424969, 'Total loss': 0.3225531661424969}
2022-11-28 02:10:04,431 INFO:     Found new best model at epoch 41
2022-11-28 02:10:04,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:04,432 INFO:     Epoch: 42
2022-11-28 02:10:05,176 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4620687895736029, 'Total loss': 0.4620687895736029} | train loss {'Reaction outcome loss': 0.3148158000721062, 'Total loss': 0.3148158000721062}
2022-11-28 02:10:05,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:05,176 INFO:     Epoch: 43
2022-11-28 02:10:05,911 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43103119315103045, 'Total loss': 0.43103119315103045} | train loss {'Reaction outcome loss': 0.31988532795402846, 'Total loss': 0.31988532795402846}
2022-11-28 02:10:05,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:05,912 INFO:     Epoch: 44
2022-11-28 02:10:06,647 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3965535532943038, 'Total loss': 0.3965535532943038} | train loss {'Reaction outcome loss': 0.315625172322158, 'Total loss': 0.315625172322158}
2022-11-28 02:10:06,647 INFO:     Found new best model at epoch 44
2022-11-28 02:10:06,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:06,648 INFO:     Epoch: 45
2022-11-28 02:10:07,388 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4476163536310196, 'Total loss': 0.4476163536310196} | train loss {'Reaction outcome loss': 0.31847827683096047, 'Total loss': 0.31847827683096047}
2022-11-28 02:10:07,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:07,388 INFO:     Epoch: 46
2022-11-28 02:10:08,127 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44030224549215896, 'Total loss': 0.44030224549215896} | train loss {'Reaction outcome loss': 0.3207454897890814, 'Total loss': 0.3207454897890814}
2022-11-28 02:10:08,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:08,128 INFO:     Epoch: 47
2022-11-28 02:10:08,869 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43612681675788967, 'Total loss': 0.43612681675788967} | train loss {'Reaction outcome loss': 0.31858959430676015, 'Total loss': 0.31858959430676015}
2022-11-28 02:10:08,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:08,869 INFO:     Epoch: 48
2022-11-28 02:10:09,609 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4356399940889935, 'Total loss': 0.4356399940889935} | train loss {'Reaction outcome loss': 0.31800449816662757, 'Total loss': 0.31800449816662757}
2022-11-28 02:10:09,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:09,609 INFO:     Epoch: 49
2022-11-28 02:10:10,346 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4413670360348945, 'Total loss': 0.4413670360348945} | train loss {'Reaction outcome loss': 0.32222021352805075, 'Total loss': 0.32222021352805075}
2022-11-28 02:10:10,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:10,347 INFO:     Epoch: 50
2022-11-28 02:10:11,086 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4213190180964248, 'Total loss': 0.4213190180964248} | train loss {'Reaction outcome loss': 0.3121687663322101, 'Total loss': 0.3121687663322101}
2022-11-28 02:10:11,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:11,086 INFO:     Epoch: 51
2022-11-28 02:10:11,825 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3942685730235521, 'Total loss': 0.3942685730235521} | train loss {'Reaction outcome loss': 0.33370371401065685, 'Total loss': 0.33370371401065685}
2022-11-28 02:10:11,825 INFO:     Found new best model at epoch 51
2022-11-28 02:10:11,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:11,826 INFO:     Epoch: 52
2022-11-28 02:10:12,568 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4334618719511254, 'Total loss': 0.4334618719511254} | train loss {'Reaction outcome loss': 0.31253761679056236, 'Total loss': 0.31253761679056236}
2022-11-28 02:10:12,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:12,569 INFO:     Epoch: 53
2022-11-28 02:10:13,309 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4136594509662584, 'Total loss': 0.4136594509662584} | train loss {'Reaction outcome loss': 0.3163185713537892, 'Total loss': 0.3163185713537892}
2022-11-28 02:10:13,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:13,309 INFO:     Epoch: 54
2022-11-28 02:10:14,051 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43827945894973225, 'Total loss': 0.43827945894973225} | train loss {'Reaction outcome loss': 0.32391679833536263, 'Total loss': 0.32391679833536263}
2022-11-28 02:10:14,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:14,052 INFO:     Epoch: 55
2022-11-28 02:10:14,794 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44791579766328943, 'Total loss': 0.44791579766328943} | train loss {'Reaction outcome loss': 0.31093244108020285, 'Total loss': 0.31093244108020285}
2022-11-28 02:10:14,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:14,795 INFO:     Epoch: 56
2022-11-28 02:10:15,534 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41345499698505844, 'Total loss': 0.41345499698505844} | train loss {'Reaction outcome loss': 0.31387039939643907, 'Total loss': 0.31387039939643907}
2022-11-28 02:10:15,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:15,534 INFO:     Epoch: 57
2022-11-28 02:10:16,271 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4137509014717368, 'Total loss': 0.4137509014717368} | train loss {'Reaction outcome loss': 0.3148009943943776, 'Total loss': 0.3148009943943776}
2022-11-28 02:10:16,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:16,272 INFO:     Epoch: 58
2022-11-28 02:10:17,015 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4323434056930764, 'Total loss': 0.4323434056930764} | train loss {'Reaction outcome loss': 0.32065449126797624, 'Total loss': 0.32065449126797624}
2022-11-28 02:10:17,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:17,015 INFO:     Epoch: 59
2022-11-28 02:10:17,761 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4324357669020808, 'Total loss': 0.4324357669020808} | train loss {'Reaction outcome loss': 0.3171163343015264, 'Total loss': 0.3171163343015264}
2022-11-28 02:10:17,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:17,761 INFO:     Epoch: 60
2022-11-28 02:10:18,507 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4306445239588272, 'Total loss': 0.4306445239588272} | train loss {'Reaction outcome loss': 0.3245599231850661, 'Total loss': 0.3245599231850661}
2022-11-28 02:10:18,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:18,507 INFO:     Epoch: 61
2022-11-28 02:10:19,247 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40949254292388293, 'Total loss': 0.40949254292388293} | train loss {'Reaction outcome loss': 0.30857881005914484, 'Total loss': 0.30857881005914484}
2022-11-28 02:10:19,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:19,247 INFO:     Epoch: 62
2022-11-28 02:10:19,986 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4456817583982335, 'Total loss': 0.4456817583982335} | train loss {'Reaction outcome loss': 0.3132107169291035, 'Total loss': 0.3132107169291035}
2022-11-28 02:10:19,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:19,986 INFO:     Epoch: 63
2022-11-28 02:10:20,726 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4090201327967089, 'Total loss': 0.4090201327967089} | train loss {'Reaction outcome loss': 0.31548292327244754, 'Total loss': 0.31548292327244754}
2022-11-28 02:10:20,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:20,726 INFO:     Epoch: 64
2022-11-28 02:10:21,469 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4519892253501471, 'Total loss': 0.4519892253501471} | train loss {'Reaction outcome loss': 0.30970170848132644, 'Total loss': 0.30970170848132644}
2022-11-28 02:10:21,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:21,470 INFO:     Epoch: 65
2022-11-28 02:10:22,210 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4687611204247142, 'Total loss': 0.4687611204247142} | train loss {'Reaction outcome loss': 0.32389344742185755, 'Total loss': 0.32389344742185755}
2022-11-28 02:10:22,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:22,210 INFO:     Epoch: 66
2022-11-28 02:10:22,952 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4088848021834396, 'Total loss': 0.4088848021834396} | train loss {'Reaction outcome loss': 0.31424909891163716, 'Total loss': 0.31424909891163716}
2022-11-28 02:10:22,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:22,953 INFO:     Epoch: 67
2022-11-28 02:10:23,692 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4498114471518716, 'Total loss': 0.4498114471518716} | train loss {'Reaction outcome loss': 0.31694285470809114, 'Total loss': 0.31694285470809114}
2022-11-28 02:10:23,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:23,692 INFO:     Epoch: 68
2022-11-28 02:10:24,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4215534026193064, 'Total loss': 0.4215534026193064} | train loss {'Reaction outcome loss': 0.3114819667744832, 'Total loss': 0.3114819667744832}
2022-11-28 02:10:24,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:24,432 INFO:     Epoch: 69
2022-11-28 02:10:25,169 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44358808356662127, 'Total loss': 0.44358808356662127} | train loss {'Reaction outcome loss': 0.30540818866098024, 'Total loss': 0.30540818866098024}
2022-11-28 02:10:25,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:25,170 INFO:     Epoch: 70
2022-11-28 02:10:25,912 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41655344602673555, 'Total loss': 0.41655344602673555} | train loss {'Reaction outcome loss': 0.3165436038961176, 'Total loss': 0.3165436038961176}
2022-11-28 02:10:25,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:25,913 INFO:     Epoch: 71
2022-11-28 02:10:26,651 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43063120405341304, 'Total loss': 0.43063120405341304} | train loss {'Reaction outcome loss': 0.31784981412843605, 'Total loss': 0.31784981412843605}
2022-11-28 02:10:26,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:26,651 INFO:     Epoch: 72
2022-11-28 02:10:27,389 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4187969343606816, 'Total loss': 0.4187969343606816} | train loss {'Reaction outcome loss': 0.3242214535072934, 'Total loss': 0.3242214535072934}
2022-11-28 02:10:27,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:27,389 INFO:     Epoch: 73
2022-11-28 02:10:28,130 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3897504135966301, 'Total loss': 0.3897504135966301} | train loss {'Reaction outcome loss': 0.32087908666886267, 'Total loss': 0.32087908666886267}
2022-11-28 02:10:28,130 INFO:     Found new best model at epoch 73
2022-11-28 02:10:28,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:28,131 INFO:     Epoch: 74
2022-11-28 02:10:28,870 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4129955629969752, 'Total loss': 0.4129955629969752} | train loss {'Reaction outcome loss': 0.3012716542074426, 'Total loss': 0.3012716542074426}
2022-11-28 02:10:28,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:28,871 INFO:     Epoch: 75
2022-11-28 02:10:29,614 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3951505294372869, 'Total loss': 0.3951505294372869} | train loss {'Reaction outcome loss': 0.320251192683812, 'Total loss': 0.320251192683812}
2022-11-28 02:10:29,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:29,614 INFO:     Epoch: 76
2022-11-28 02:10:30,357 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3965049628601518, 'Total loss': 0.3965049628601518} | train loss {'Reaction outcome loss': 0.3033711345957928, 'Total loss': 0.3033711345957928}
2022-11-28 02:10:30,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:30,357 INFO:     Epoch: 77
2022-11-28 02:10:31,099 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42691839711610663, 'Total loss': 0.42691839711610663} | train loss {'Reaction outcome loss': 0.3087410869412735, 'Total loss': 0.3087410869412735}
2022-11-28 02:10:31,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:31,099 INFO:     Epoch: 78
2022-11-28 02:10:31,844 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4433143024527749, 'Total loss': 0.4433143024527749} | train loss {'Reaction outcome loss': 0.31176871155984087, 'Total loss': 0.31176871155984087}
2022-11-28 02:10:31,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:31,844 INFO:     Epoch: 79
2022-11-28 02:10:32,585 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4208422698253809, 'Total loss': 0.4208422698253809} | train loss {'Reaction outcome loss': 0.3102157474113781, 'Total loss': 0.3102157474113781}
2022-11-28 02:10:32,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:32,585 INFO:     Epoch: 80
2022-11-28 02:10:33,323 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42470362609209017, 'Total loss': 0.42470362609209017} | train loss {'Reaction outcome loss': 0.3114862360793059, 'Total loss': 0.3114862360793059}
2022-11-28 02:10:33,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:33,323 INFO:     Epoch: 81
2022-11-28 02:10:34,061 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41497415477453276, 'Total loss': 0.41497415477453276} | train loss {'Reaction outcome loss': 0.3126124122531199, 'Total loss': 0.3126124122531199}
2022-11-28 02:10:34,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:34,061 INFO:     Epoch: 82
2022-11-28 02:10:34,802 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4410065312025159, 'Total loss': 0.4410065312025159} | train loss {'Reaction outcome loss': 0.3175944726853097, 'Total loss': 0.3175944726853097}
2022-11-28 02:10:34,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:34,802 INFO:     Epoch: 83
2022-11-28 02:10:35,537 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4224151854598245, 'Total loss': 0.4224151854598245} | train loss {'Reaction outcome loss': 0.3178394481417586, 'Total loss': 0.3178394481417586}
2022-11-28 02:10:35,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:35,538 INFO:     Epoch: 84
2022-11-28 02:10:36,278 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42220931067023165, 'Total loss': 0.42220931067023165} | train loss {'Reaction outcome loss': 0.31429231789756995, 'Total loss': 0.31429231789756995}
2022-11-28 02:10:36,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:36,279 INFO:     Epoch: 85
2022-11-28 02:10:37,018 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40280554287655407, 'Total loss': 0.40280554287655407} | train loss {'Reaction outcome loss': 0.3158127395894195, 'Total loss': 0.3158127395894195}
2022-11-28 02:10:37,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:37,018 INFO:     Epoch: 86
2022-11-28 02:10:37,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41620484098445537, 'Total loss': 0.41620484098445537} | train loss {'Reaction outcome loss': 0.3063462209261832, 'Total loss': 0.3063462209261832}
2022-11-28 02:10:37,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:37,757 INFO:     Epoch: 87
2022-11-28 02:10:38,501 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41756699112958684, 'Total loss': 0.41756699112958684} | train loss {'Reaction outcome loss': 0.31484653976303145, 'Total loss': 0.31484653976303145}
2022-11-28 02:10:38,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:38,501 INFO:     Epoch: 88
2022-11-28 02:10:39,241 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44337178524150406, 'Total loss': 0.44337178524150406} | train loss {'Reaction outcome loss': 0.32007523180275665, 'Total loss': 0.32007523180275665}
2022-11-28 02:10:39,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:39,241 INFO:     Epoch: 89
2022-11-28 02:10:39,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46102004931416624, 'Total loss': 0.46102004931416624} | train loss {'Reaction outcome loss': 0.3124469467667771, 'Total loss': 0.3124469467667771}
2022-11-28 02:10:39,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:39,984 INFO:     Epoch: 90
2022-11-28 02:10:40,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4237090938313063, 'Total loss': 0.4237090938313063} | train loss {'Reaction outcome loss': 0.31002264888193765, 'Total loss': 0.31002264888193765}
2022-11-28 02:10:40,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:40,724 INFO:     Epoch: 91
2022-11-28 02:10:41,462 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43325028932371806, 'Total loss': 0.43325028932371806} | train loss {'Reaction outcome loss': 0.31341892143436634, 'Total loss': 0.31341892143436634}
2022-11-28 02:10:41,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:41,463 INFO:     Epoch: 92
2022-11-28 02:10:42,199 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43830933976312014, 'Total loss': 0.43830933976312014} | train loss {'Reaction outcome loss': 0.3102113729892451, 'Total loss': 0.3102113729892451}
2022-11-28 02:10:42,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:42,199 INFO:     Epoch: 93
2022-11-28 02:10:42,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4379874559682469, 'Total loss': 0.4379874559682469} | train loss {'Reaction outcome loss': 0.3175836130060622, 'Total loss': 0.3175836130060622}
2022-11-28 02:10:42,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:42,943 INFO:     Epoch: 94
2022-11-28 02:10:43,682 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44612124077109405, 'Total loss': 0.44612124077109405} | train loss {'Reaction outcome loss': 0.3197274458304536, 'Total loss': 0.3197274458304536}
2022-11-28 02:10:43,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:43,682 INFO:     Epoch: 95
2022-11-28 02:10:44,425 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4376000210989353, 'Total loss': 0.4376000210989353} | train loss {'Reaction outcome loss': 0.3136051557652774, 'Total loss': 0.3136051557652774}
2022-11-28 02:10:44,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:44,425 INFO:     Epoch: 96
2022-11-28 02:10:45,162 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41421753930491073, 'Total loss': 0.41421753930491073} | train loss {'Reaction outcome loss': 0.31021079821054076, 'Total loss': 0.31021079821054076}
2022-11-28 02:10:45,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:45,162 INFO:     Epoch: 97
2022-11-28 02:10:45,897 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43248449439226194, 'Total loss': 0.43248449439226194} | train loss {'Reaction outcome loss': 0.30464084104436345, 'Total loss': 0.30464084104436345}
2022-11-28 02:10:45,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:45,898 INFO:     Epoch: 98
2022-11-28 02:10:46,637 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42644184689189113, 'Total loss': 0.42644184689189113} | train loss {'Reaction outcome loss': 0.30982594874489017, 'Total loss': 0.30982594874489017}
2022-11-28 02:10:46,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:46,637 INFO:     Epoch: 99
2022-11-28 02:10:47,379 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4038884501124537, 'Total loss': 0.4038884501124537} | train loss {'Reaction outcome loss': 0.31073308540660827, 'Total loss': 0.31073308540660827}
2022-11-28 02:10:47,380 INFO:     Best model found after epoch 74 of 100.
2022-11-28 02:10:47,380 INFO:   Done with stage: TRAINING
2022-11-28 02:10:47,380 INFO:   Starting stage: EVALUATION
2022-11-28 02:10:47,516 INFO:   Done with stage: EVALUATION
2022-11-28 02:10:47,516 INFO:   Leaving out SEQ value Fold_3
2022-11-28 02:10:47,529 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:10:47,529 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:10:48,169 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:10:48,170 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:10:48,237 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:10:48,237 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:10:48,237 INFO:     No hyperparam tuning for this model
2022-11-28 02:10:48,237 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:10:48,237 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:10:48,238 INFO:     None feature selector for col prot
2022-11-28 02:10:48,238 INFO:     None feature selector for col prot
2022-11-28 02:10:48,238 INFO:     None feature selector for col prot
2022-11-28 02:10:48,239 INFO:     None feature selector for col chem
2022-11-28 02:10:48,239 INFO:     None feature selector for col chem
2022-11-28 02:10:48,239 INFO:     None feature selector for col chem
2022-11-28 02:10:48,239 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:10:48,239 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:10:48,240 INFO:     Number of params in model 169741
2022-11-28 02:10:48,244 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:10:48,244 INFO:   Starting stage: TRAINING
2022-11-28 02:10:48,297 INFO:     Val loss before train {'Reaction outcome loss': 1.0154285044832663, 'Total loss': 1.0154285044832663}
2022-11-28 02:10:48,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:48,297 INFO:     Epoch: 0
2022-11-28 02:10:49,043 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5648351535201073, 'Total loss': 0.5648351535201073} | train loss {'Reaction outcome loss': 0.6462644393346748, 'Total loss': 0.6462644393346748}
2022-11-28 02:10:49,043 INFO:     Found new best model at epoch 0
2022-11-28 02:10:49,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:49,044 INFO:     Epoch: 1
2022-11-28 02:10:49,788 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.508835569024086, 'Total loss': 0.508835569024086} | train loss {'Reaction outcome loss': 0.5022996212754931, 'Total loss': 0.5022996212754931}
2022-11-28 02:10:49,788 INFO:     Found new best model at epoch 1
2022-11-28 02:10:49,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:49,789 INFO:     Epoch: 2
2022-11-28 02:10:50,531 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47383158789439633, 'Total loss': 0.47383158789439633} | train loss {'Reaction outcome loss': 0.46909653793792333, 'Total loss': 0.46909653793792333}
2022-11-28 02:10:50,531 INFO:     Found new best model at epoch 2
2022-11-28 02:10:50,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:50,532 INFO:     Epoch: 3
2022-11-28 02:10:51,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46105748347260733, 'Total loss': 0.46105748347260733} | train loss {'Reaction outcome loss': 0.45165881587534534, 'Total loss': 0.45165881587534534}
2022-11-28 02:10:51,271 INFO:     Found new best model at epoch 3
2022-11-28 02:10:51,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:51,271 INFO:     Epoch: 4
2022-11-28 02:10:52,012 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4878364462744106, 'Total loss': 0.4878364462744106} | train loss {'Reaction outcome loss': 0.44149271219360586, 'Total loss': 0.44149271219360586}
2022-11-28 02:10:52,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:52,012 INFO:     Epoch: 5
2022-11-28 02:10:52,753 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44424907355145976, 'Total loss': 0.44424907355145976} | train loss {'Reaction outcome loss': 0.4160323303572986, 'Total loss': 0.4160323303572986}
2022-11-28 02:10:52,753 INFO:     Found new best model at epoch 5
2022-11-28 02:10:52,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:52,754 INFO:     Epoch: 6
2022-11-28 02:10:53,490 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4450461227785457, 'Total loss': 0.4450461227785457} | train loss {'Reaction outcome loss': 0.4031108032683937, 'Total loss': 0.4031108032683937}
2022-11-28 02:10:53,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:53,491 INFO:     Epoch: 7
2022-11-28 02:10:54,232 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45096847211772745, 'Total loss': 0.45096847211772745} | train loss {'Reaction outcome loss': 0.4013723395612775, 'Total loss': 0.4013723395612775}
2022-11-28 02:10:54,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:54,232 INFO:     Epoch: 8
2022-11-28 02:10:54,973 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4302035892720927, 'Total loss': 0.4302035892720927} | train loss {'Reaction outcome loss': 0.39743135255210255, 'Total loss': 0.39743135255210255}
2022-11-28 02:10:54,973 INFO:     Found new best model at epoch 8
2022-11-28 02:10:54,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:54,974 INFO:     Epoch: 9
2022-11-28 02:10:55,709 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44145532815971156, 'Total loss': 0.44145532815971156} | train loss {'Reaction outcome loss': 0.38352818451061543, 'Total loss': 0.38352818451061543}
2022-11-28 02:10:55,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:55,709 INFO:     Epoch: 10
2022-11-28 02:10:56,446 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4923668612133373, 'Total loss': 0.4923668612133373} | train loss {'Reaction outcome loss': 0.3779058817698031, 'Total loss': 0.3779058817698031}
2022-11-28 02:10:56,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:56,446 INFO:     Epoch: 11
2022-11-28 02:10:57,186 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4468317235058004, 'Total loss': 0.4468317235058004} | train loss {'Reaction outcome loss': 0.37847921737298673, 'Total loss': 0.37847921737298673}
2022-11-28 02:10:57,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:57,187 INFO:     Epoch: 12
2022-11-28 02:10:57,925 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4349981062114239, 'Total loss': 0.4349981062114239} | train loss {'Reaction outcome loss': 0.36309133013900446, 'Total loss': 0.36309133013900446}
2022-11-28 02:10:57,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:57,925 INFO:     Epoch: 13
2022-11-28 02:10:58,663 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43842164460908284, 'Total loss': 0.43842164460908284} | train loss {'Reaction outcome loss': 0.36819246022068725, 'Total loss': 0.36819246022068725}
2022-11-28 02:10:58,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:58,664 INFO:     Epoch: 14
2022-11-28 02:10:59,403 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43686971881172876, 'Total loss': 0.43686971881172876} | train loss {'Reaction outcome loss': 0.3588947029138098, 'Total loss': 0.3588947029138098}
2022-11-28 02:10:59,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:10:59,403 INFO:     Epoch: 15
2022-11-28 02:11:00,144 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4383548579432748, 'Total loss': 0.4383548579432748} | train loss {'Reaction outcome loss': 0.35423891973130556, 'Total loss': 0.35423891973130556}
2022-11-28 02:11:00,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:00,144 INFO:     Epoch: 16
2022-11-28 02:11:00,884 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4046096403829076, 'Total loss': 0.4046096403829076} | train loss {'Reaction outcome loss': 0.38085516356692023, 'Total loss': 0.38085516356692023}
2022-11-28 02:11:00,884 INFO:     Found new best model at epoch 16
2022-11-28 02:11:00,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:00,885 INFO:     Epoch: 17
2022-11-28 02:11:01,623 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4497170187532902, 'Total loss': 0.4497170187532902} | train loss {'Reaction outcome loss': 0.35959638828525736, 'Total loss': 0.35959638828525736}
2022-11-28 02:11:01,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:01,624 INFO:     Epoch: 18
2022-11-28 02:11:02,364 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4335073537447236, 'Total loss': 0.4335073537447236} | train loss {'Reaction outcome loss': 0.35631001178099186, 'Total loss': 0.35631001178099186}
2022-11-28 02:11:02,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:02,364 INFO:     Epoch: 19
2022-11-28 02:11:03,104 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40352505479346623, 'Total loss': 0.40352505479346623} | train loss {'Reaction outcome loss': 0.35126988656666813, 'Total loss': 0.35126988656666813}
2022-11-28 02:11:03,104 INFO:     Found new best model at epoch 19
2022-11-28 02:11:03,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:03,105 INFO:     Epoch: 20
2022-11-28 02:11:03,847 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4227873632176356, 'Total loss': 0.4227873632176356} | train loss {'Reaction outcome loss': 0.3459228683795248, 'Total loss': 0.3459228683795248}
2022-11-28 02:11:03,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:03,847 INFO:     Epoch: 21
2022-11-28 02:11:04,590 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42554855143482034, 'Total loss': 0.42554855143482034} | train loss {'Reaction outcome loss': 0.34184039733847793, 'Total loss': 0.34184039733847793}
2022-11-28 02:11:04,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:04,591 INFO:     Epoch: 22
2022-11-28 02:11:05,332 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4036384482275356, 'Total loss': 0.4036384482275356} | train loss {'Reaction outcome loss': 0.3396182413612093, 'Total loss': 0.3396182413612093}
2022-11-28 02:11:05,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:05,332 INFO:     Epoch: 23
2022-11-28 02:11:06,074 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42648858712478116, 'Total loss': 0.42648858712478116} | train loss {'Reaction outcome loss': 0.3395545052934666, 'Total loss': 0.3395545052934666}
2022-11-28 02:11:06,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:06,075 INFO:     Epoch: 24
2022-11-28 02:11:06,819 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40340812648223207, 'Total loss': 0.40340812648223207} | train loss {'Reaction outcome loss': 0.336284070492399, 'Total loss': 0.336284070492399}
2022-11-28 02:11:06,819 INFO:     Found new best model at epoch 24
2022-11-28 02:11:06,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:06,820 INFO:     Epoch: 25
2022-11-28 02:11:07,565 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4514631127769297, 'Total loss': 0.4514631127769297} | train loss {'Reaction outcome loss': 0.3400302462583902, 'Total loss': 0.3400302462583902}
2022-11-28 02:11:07,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:07,565 INFO:     Epoch: 26
2022-11-28 02:11:08,307 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3839600228450515, 'Total loss': 0.3839600228450515} | train loss {'Reaction outcome loss': 0.3358629520146214, 'Total loss': 0.3358629520146214}
2022-11-28 02:11:08,307 INFO:     Found new best model at epoch 26
2022-11-28 02:11:08,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:08,308 INFO:     Epoch: 27
2022-11-28 02:11:09,047 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40760452359576116, 'Total loss': 0.40760452359576116} | train loss {'Reaction outcome loss': 0.33356122523546217, 'Total loss': 0.33356122523546217}
2022-11-28 02:11:09,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:09,047 INFO:     Epoch: 28
2022-11-28 02:11:09,791 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3991549719463695, 'Total loss': 0.3991549719463695} | train loss {'Reaction outcome loss': 0.3281348984156336, 'Total loss': 0.3281348984156336}
2022-11-28 02:11:09,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:09,791 INFO:     Epoch: 29
2022-11-28 02:11:10,537 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38078590719537303, 'Total loss': 0.38078590719537303} | train loss {'Reaction outcome loss': 0.3330746521451035, 'Total loss': 0.3330746521451035}
2022-11-28 02:11:10,537 INFO:     Found new best model at epoch 29
2022-11-28 02:11:10,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:10,538 INFO:     Epoch: 30
2022-11-28 02:11:11,281 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40972666069865227, 'Total loss': 0.40972666069865227} | train loss {'Reaction outcome loss': 0.3262200004744286, 'Total loss': 0.3262200004744286}
2022-11-28 02:11:11,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:11,281 INFO:     Epoch: 31
2022-11-28 02:11:12,023 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40591866319829767, 'Total loss': 0.40591866319829767} | train loss {'Reaction outcome loss': 0.3308741176767009, 'Total loss': 0.3308741176767009}
2022-11-28 02:11:12,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:12,023 INFO:     Epoch: 32
2022-11-28 02:11:12,764 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4355881078676744, 'Total loss': 0.4355881078676744} | train loss {'Reaction outcome loss': 0.3348616298060028, 'Total loss': 0.3348616298060028}
2022-11-28 02:11:12,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:12,765 INFO:     Epoch: 33
2022-11-28 02:11:13,510 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4442181702364575, 'Total loss': 0.4442181702364575} | train loss {'Reaction outcome loss': 0.3294811091556841, 'Total loss': 0.3294811091556841}
2022-11-28 02:11:13,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:13,511 INFO:     Epoch: 34
2022-11-28 02:11:14,250 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4130410318347541, 'Total loss': 0.4130410318347541} | train loss {'Reaction outcome loss': 0.31661852382275524, 'Total loss': 0.31661852382275524}
2022-11-28 02:11:14,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:14,251 INFO:     Epoch: 35
2022-11-28 02:11:14,989 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38393199376084586, 'Total loss': 0.38393199376084586} | train loss {'Reaction outcome loss': 0.33109711180536117, 'Total loss': 0.33109711180536117}
2022-11-28 02:11:14,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:14,989 INFO:     Epoch: 36
2022-11-28 02:11:15,727 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41224721421233634, 'Total loss': 0.41224721421233634} | train loss {'Reaction outcome loss': 0.31238004705127403, 'Total loss': 0.31238004705127403}
2022-11-28 02:11:15,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:15,727 INFO:     Epoch: 37
2022-11-28 02:11:16,466 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3923170231282711, 'Total loss': 0.3923170231282711} | train loss {'Reaction outcome loss': 0.32183373667755905, 'Total loss': 0.32183373667755905}
2022-11-28 02:11:16,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:16,467 INFO:     Epoch: 38
2022-11-28 02:11:17,205 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4296673116358844, 'Total loss': 0.4296673116358844} | train loss {'Reaction outcome loss': 0.3189957198363786, 'Total loss': 0.3189957198363786}
2022-11-28 02:11:17,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:17,205 INFO:     Epoch: 39
2022-11-28 02:11:17,947 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4292337464337999, 'Total loss': 0.4292337464337999} | train loss {'Reaction outcome loss': 0.3164907470345497, 'Total loss': 0.3164907470345497}
2022-11-28 02:11:17,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:17,947 INFO:     Epoch: 40
2022-11-28 02:11:18,688 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40097636356949806, 'Total loss': 0.40097636356949806} | train loss {'Reaction outcome loss': 0.3288877122256221, 'Total loss': 0.3288877122256221}
2022-11-28 02:11:18,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:18,689 INFO:     Epoch: 41
2022-11-28 02:11:19,429 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4515154446390542, 'Total loss': 0.4515154446390542} | train loss {'Reaction outcome loss': 0.32782166028509335, 'Total loss': 0.32782166028509335}
2022-11-28 02:11:19,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:19,429 INFO:     Epoch: 42
2022-11-28 02:11:20,168 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40074815914373507, 'Total loss': 0.40074815914373507} | train loss {'Reaction outcome loss': 0.3220158824811176, 'Total loss': 0.3220158824811176}
2022-11-28 02:11:20,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:20,168 INFO:     Epoch: 43
2022-11-28 02:11:20,907 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41440668634392996, 'Total loss': 0.41440668634392996} | train loss {'Reaction outcome loss': 0.3202094012985424, 'Total loss': 0.3202094012985424}
2022-11-28 02:11:20,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:20,907 INFO:     Epoch: 44
2022-11-28 02:11:21,650 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41399765759706497, 'Total loss': 0.41399765759706497} | train loss {'Reaction outcome loss': 0.32366936927547263, 'Total loss': 0.32366936927547263}
2022-11-28 02:11:21,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:21,651 INFO:     Epoch: 45
2022-11-28 02:11:22,390 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41798789257353003, 'Total loss': 0.41798789257353003} | train loss {'Reaction outcome loss': 0.307242174400967, 'Total loss': 0.307242174400967}
2022-11-28 02:11:22,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:22,390 INFO:     Epoch: 46
2022-11-28 02:11:23,130 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4705077247186141, 'Total loss': 0.4705077247186141} | train loss {'Reaction outcome loss': 0.31695271383742896, 'Total loss': 0.31695271383742896}
2022-11-28 02:11:23,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:23,130 INFO:     Epoch: 47
2022-11-28 02:11:23,868 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.416406242007559, 'Total loss': 0.416406242007559} | train loss {'Reaction outcome loss': 0.31653563961082576, 'Total loss': 0.31653563961082576}
2022-11-28 02:11:23,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:23,868 INFO:     Epoch: 48
2022-11-28 02:11:24,611 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4402686320245266, 'Total loss': 0.4402686320245266} | train loss {'Reaction outcome loss': 0.3120473927989298, 'Total loss': 0.3120473927989298}
2022-11-28 02:11:24,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:24,611 INFO:     Epoch: 49
2022-11-28 02:11:25,349 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42154995826157654, 'Total loss': 0.42154995826157654} | train loss {'Reaction outcome loss': 0.32323287667668593, 'Total loss': 0.32323287667668593}
2022-11-28 02:11:25,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:25,350 INFO:     Epoch: 50
2022-11-28 02:11:26,085 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41461664133451204, 'Total loss': 0.41461664133451204} | train loss {'Reaction outcome loss': 0.33346864714914437, 'Total loss': 0.33346864714914437}
2022-11-28 02:11:26,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:26,085 INFO:     Epoch: 51
2022-11-28 02:11:26,824 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4458335966549136, 'Total loss': 0.4458335966549136} | train loss {'Reaction outcome loss': 0.3275928090421521, 'Total loss': 0.3275928090421521}
2022-11-28 02:11:26,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:26,824 INFO:     Epoch: 52
2022-11-28 02:11:27,563 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40232216160405765, 'Total loss': 0.40232216160405765} | train loss {'Reaction outcome loss': 0.31563742683858287, 'Total loss': 0.31563742683858287}
2022-11-28 02:11:27,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:27,563 INFO:     Epoch: 53
2022-11-28 02:11:28,302 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4080789905380119, 'Total loss': 0.4080789905380119} | train loss {'Reaction outcome loss': 0.3185294554853926, 'Total loss': 0.3185294554853926}
2022-11-28 02:11:28,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:28,303 INFO:     Epoch: 54
2022-11-28 02:11:29,043 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4304468171163039, 'Total loss': 0.4304468171163039} | train loss {'Reaction outcome loss': 0.323498893088224, 'Total loss': 0.323498893088224}
2022-11-28 02:11:29,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:29,044 INFO:     Epoch: 55
2022-11-28 02:11:29,783 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4213882274925709, 'Total loss': 0.4213882274925709} | train loss {'Reaction outcome loss': 0.31130684529032027, 'Total loss': 0.31130684529032027}
2022-11-28 02:11:29,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:29,783 INFO:     Epoch: 56
2022-11-28 02:11:30,526 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43894864872775297, 'Total loss': 0.43894864872775297} | train loss {'Reaction outcome loss': 0.30847686392312146, 'Total loss': 0.30847686392312146}
2022-11-28 02:11:30,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:30,526 INFO:     Epoch: 57
2022-11-28 02:11:31,271 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4143593202937733, 'Total loss': 0.4143593202937733} | train loss {'Reaction outcome loss': 0.30893498306371725, 'Total loss': 0.30893498306371725}
2022-11-28 02:11:31,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:31,271 INFO:     Epoch: 58
2022-11-28 02:11:32,016 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44125064834952354, 'Total loss': 0.44125064834952354} | train loss {'Reaction outcome loss': 0.3195220913205828, 'Total loss': 0.3195220913205828}
2022-11-28 02:11:32,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:32,016 INFO:     Epoch: 59
2022-11-28 02:11:32,761 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4408403553745963, 'Total loss': 0.4408403553745963} | train loss {'Reaction outcome loss': 0.30913912848550446, 'Total loss': 0.30913912848550446}
2022-11-28 02:11:32,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:32,761 INFO:     Epoch: 60
2022-11-28 02:11:33,499 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.444145045158538, 'Total loss': 0.444145045158538} | train loss {'Reaction outcome loss': 0.3135751341678658, 'Total loss': 0.3135751341678658}
2022-11-28 02:11:33,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:33,499 INFO:     Epoch: 61
2022-11-28 02:11:34,240 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4142931184985421, 'Total loss': 0.4142931184985421} | train loss {'Reaction outcome loss': 0.31523673069112157, 'Total loss': 0.31523673069112157}
2022-11-28 02:11:34,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:34,240 INFO:     Epoch: 62
2022-11-28 02:11:34,983 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43431374633854086, 'Total loss': 0.43431374633854086} | train loss {'Reaction outcome loss': 0.3038569037099274, 'Total loss': 0.3038569037099274}
2022-11-28 02:11:34,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:34,983 INFO:     Epoch: 63
2022-11-28 02:11:35,724 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4091767252168872, 'Total loss': 0.4091767252168872} | train loss {'Reaction outcome loss': 0.31216051551152246, 'Total loss': 0.31216051551152246}
2022-11-28 02:11:35,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:35,724 INFO:     Epoch: 64
2022-11-28 02:11:36,470 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42170309597118333, 'Total loss': 0.42170309597118333} | train loss {'Reaction outcome loss': 0.3110815929819126, 'Total loss': 0.3110815929819126}
2022-11-28 02:11:36,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:36,471 INFO:     Epoch: 65
2022-11-28 02:11:37,209 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40533219785852864, 'Total loss': 0.40533219785852864} | train loss {'Reaction outcome loss': 0.3077281794377736, 'Total loss': 0.3077281794377736}
2022-11-28 02:11:37,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:37,209 INFO:     Epoch: 66
2022-11-28 02:11:37,948 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4216602105985988, 'Total loss': 0.4216602105985988} | train loss {'Reaction outcome loss': 0.31435813374665317, 'Total loss': 0.31435813374665317}
2022-11-28 02:11:37,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:37,949 INFO:     Epoch: 67
2022-11-28 02:11:38,690 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4077987071465362, 'Total loss': 0.4077987071465362} | train loss {'Reaction outcome loss': 0.3060951827131972, 'Total loss': 0.3060951827131972}
2022-11-28 02:11:38,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:38,690 INFO:     Epoch: 68
2022-11-28 02:11:39,431 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44543584978038614, 'Total loss': 0.44543584978038614} | train loss {'Reaction outcome loss': 0.30979267310123054, 'Total loss': 0.30979267310123054}
2022-11-28 02:11:39,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:39,431 INFO:     Epoch: 69
2022-11-28 02:11:40,168 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4015180322934281, 'Total loss': 0.4015180322934281} | train loss {'Reaction outcome loss': 0.31100873501629245, 'Total loss': 0.31100873501629245}
2022-11-28 02:11:40,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:40,168 INFO:     Epoch: 70
2022-11-28 02:11:40,907 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39417807859453285, 'Total loss': 0.39417807859453285} | train loss {'Reaction outcome loss': 0.307584784012668, 'Total loss': 0.307584784012668}
2022-11-28 02:11:40,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:40,908 INFO:     Epoch: 71
2022-11-28 02:11:41,648 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43152345954017207, 'Total loss': 0.43152345954017207} | train loss {'Reaction outcome loss': 0.3110459210313096, 'Total loss': 0.3110459210313096}
2022-11-28 02:11:41,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:41,648 INFO:     Epoch: 72
2022-11-28 02:11:42,389 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43160650388083677, 'Total loss': 0.43160650388083677} | train loss {'Reaction outcome loss': 0.3056119765858261, 'Total loss': 0.3056119765858261}
2022-11-28 02:11:42,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:42,389 INFO:     Epoch: 73
2022-11-28 02:11:43,129 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3952657048675147, 'Total loss': 0.3952657048675147} | train loss {'Reaction outcome loss': 0.31714961647379153, 'Total loss': 0.31714961647379153}
2022-11-28 02:11:43,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:43,129 INFO:     Epoch: 74
2022-11-28 02:11:43,869 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4140300699933009, 'Total loss': 0.4140300699933009} | train loss {'Reaction outcome loss': 0.3016346187767934, 'Total loss': 0.3016346187767934}
2022-11-28 02:11:43,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:43,869 INFO:     Epoch: 75
2022-11-28 02:11:44,606 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40007358755577693, 'Total loss': 0.40007358755577693} | train loss {'Reaction outcome loss': 0.3201803148401027, 'Total loss': 0.3201803148401027}
2022-11-28 02:11:44,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:44,606 INFO:     Epoch: 76
2022-11-28 02:11:45,349 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4149028774012219, 'Total loss': 0.4149028774012219} | train loss {'Reaction outcome loss': 0.3221330464798577, 'Total loss': 0.3221330464798577}
2022-11-28 02:11:45,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:45,350 INFO:     Epoch: 77
2022-11-28 02:11:46,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4133574783124707, 'Total loss': 0.4133574783124707} | train loss {'Reaction outcome loss': 0.30753438180806686, 'Total loss': 0.30753438180806686}
2022-11-28 02:11:46,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:46,089 INFO:     Epoch: 78
2022-11-28 02:11:46,827 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4396900468590585, 'Total loss': 0.4396900468590585} | train loss {'Reaction outcome loss': 0.30650679602914926, 'Total loss': 0.30650679602914926}
2022-11-28 02:11:46,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:46,827 INFO:     Epoch: 79
2022-11-28 02:11:47,566 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4182222317904234, 'Total loss': 0.4182222317904234} | train loss {'Reaction outcome loss': 0.31507584890540763, 'Total loss': 0.31507584890540763}
2022-11-28 02:11:47,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:47,566 INFO:     Epoch: 80
2022-11-28 02:11:48,311 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4484951939772476, 'Total loss': 0.4484951939772476} | train loss {'Reaction outcome loss': 0.30121666652207474, 'Total loss': 0.30121666652207474}
2022-11-28 02:11:48,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:48,311 INFO:     Epoch: 81
2022-11-28 02:11:49,052 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4192832220684398, 'Total loss': 0.4192832220684398} | train loss {'Reaction outcome loss': 0.32224018820086303, 'Total loss': 0.32224018820086303}
2022-11-28 02:11:49,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:49,052 INFO:     Epoch: 82
2022-11-28 02:11:49,793 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4242563552477143, 'Total loss': 0.4242563552477143} | train loss {'Reaction outcome loss': 0.31234934737487713, 'Total loss': 0.31234934737487713}
2022-11-28 02:11:49,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:49,794 INFO:     Epoch: 83
2022-11-28 02:11:50,533 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41357180306857283, 'Total loss': 0.41357180306857283} | train loss {'Reaction outcome loss': 0.32054139494287726, 'Total loss': 0.32054139494287726}
2022-11-28 02:11:50,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:50,534 INFO:     Epoch: 84
2022-11-28 02:11:51,276 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42591562596234406, 'Total loss': 0.42591562596234406} | train loss {'Reaction outcome loss': 0.3066957154292233, 'Total loss': 0.3066957154292233}
2022-11-28 02:11:51,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:51,276 INFO:     Epoch: 85
2022-11-28 02:11:52,018 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3948578478937799, 'Total loss': 0.3948578478937799} | train loss {'Reaction outcome loss': 0.3055834152868816, 'Total loss': 0.3055834152868816}
2022-11-28 02:11:52,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:52,018 INFO:     Epoch: 86
2022-11-28 02:11:52,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3931436903499575, 'Total loss': 0.3931436903499575} | train loss {'Reaction outcome loss': 0.31290564235984064, 'Total loss': 0.31290564235984064}
2022-11-28 02:11:52,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:52,757 INFO:     Epoch: 87
2022-11-28 02:11:53,495 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44797919487411325, 'Total loss': 0.44797919487411325} | train loss {'Reaction outcome loss': 0.29829736966259623, 'Total loss': 0.29829736966259623}
2022-11-28 02:11:53,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:53,495 INFO:     Epoch: 88
2022-11-28 02:11:54,237 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43065926229411905, 'Total loss': 0.43065926229411905} | train loss {'Reaction outcome loss': 0.3109971890035941, 'Total loss': 0.3109971890035941}
2022-11-28 02:11:54,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:54,237 INFO:     Epoch: 89
2022-11-28 02:11:54,978 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41441200571981346, 'Total loss': 0.41441200571981346} | train loss {'Reaction outcome loss': 0.3140565325410999, 'Total loss': 0.3140565325410999}
2022-11-28 02:11:54,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:54,978 INFO:     Epoch: 90
2022-11-28 02:11:55,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3906021728180349, 'Total loss': 0.3906021728180349} | train loss {'Reaction outcome loss': 0.31005203067039955, 'Total loss': 0.31005203067039955}
2022-11-28 02:11:55,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:55,720 INFO:     Epoch: 91
2022-11-28 02:11:56,459 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4250469905408946, 'Total loss': 0.4250469905408946} | train loss {'Reaction outcome loss': 0.30886414671430784, 'Total loss': 0.30886414671430784}
2022-11-28 02:11:56,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:56,460 INFO:     Epoch: 92
2022-11-28 02:11:57,200 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4415156881917607, 'Total loss': 0.4415156881917607} | train loss {'Reaction outcome loss': 0.30555218237699294, 'Total loss': 0.30555218237699294}
2022-11-28 02:11:57,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:57,200 INFO:     Epoch: 93
2022-11-28 02:11:57,940 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4198143577033823, 'Total loss': 0.4198143577033823} | train loss {'Reaction outcome loss': 0.3118150605382968, 'Total loss': 0.3118150605382968}
2022-11-28 02:11:57,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:57,940 INFO:     Epoch: 94
2022-11-28 02:11:58,681 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44789322736588394, 'Total loss': 0.44789322736588394} | train loss {'Reaction outcome loss': 0.29980996567375806, 'Total loss': 0.29980996567375806}
2022-11-28 02:11:58,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:58,682 INFO:     Epoch: 95
2022-11-28 02:11:59,420 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39386761357838457, 'Total loss': 0.39386761357838457} | train loss {'Reaction outcome loss': 0.3144872748730134, 'Total loss': 0.3144872748730134}
2022-11-28 02:11:59,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:11:59,420 INFO:     Epoch: 96
2022-11-28 02:12:00,166 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42111466147682886, 'Total loss': 0.42111466147682886} | train loss {'Reaction outcome loss': 0.3038291396079015, 'Total loss': 0.3038291396079015}
2022-11-28 02:12:00,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:00,166 INFO:     Epoch: 97
2022-11-28 02:12:00,904 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4045246873389591, 'Total loss': 0.4045246873389591} | train loss {'Reaction outcome loss': 0.3030556390176014, 'Total loss': 0.3030556390176014}
2022-11-28 02:12:00,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:00,905 INFO:     Epoch: 98
2022-11-28 02:12:01,647 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44220259819518437, 'Total loss': 0.44220259819518437} | train loss {'Reaction outcome loss': 0.3037929187319717, 'Total loss': 0.3037929187319717}
2022-11-28 02:12:01,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:01,647 INFO:     Epoch: 99
2022-11-28 02:12:02,388 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4466875735670328, 'Total loss': 0.4466875735670328} | train loss {'Reaction outcome loss': 0.3119597477572305, 'Total loss': 0.3119597477572305}
2022-11-28 02:12:02,388 INFO:     Best model found after epoch 30 of 100.
2022-11-28 02:12:02,388 INFO:   Done with stage: TRAINING
2022-11-28 02:12:02,388 INFO:   Starting stage: EVALUATION
2022-11-28 02:12:02,518 INFO:   Done with stage: EVALUATION
2022-11-28 02:12:02,518 INFO:   Leaving out SEQ value Fold_4
2022-11-28 02:12:02,530 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:12:02,531 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:12:03,172 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:12:03,172 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:12:03,240 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:12:03,240 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:12:03,240 INFO:     No hyperparam tuning for this model
2022-11-28 02:12:03,240 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:12:03,240 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:12:03,241 INFO:     None feature selector for col prot
2022-11-28 02:12:03,241 INFO:     None feature selector for col prot
2022-11-28 02:12:03,241 INFO:     None feature selector for col prot
2022-11-28 02:12:03,241 INFO:     None feature selector for col chem
2022-11-28 02:12:03,242 INFO:     None feature selector for col chem
2022-11-28 02:12:03,242 INFO:     None feature selector for col chem
2022-11-28 02:12:03,242 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:12:03,242 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:12:03,243 INFO:     Number of params in model 169741
2022-11-28 02:12:03,246 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:12:03,246 INFO:   Starting stage: TRAINING
2022-11-28 02:12:03,300 INFO:     Val loss before train {'Reaction outcome loss': 0.9707863046364351, 'Total loss': 0.9707863046364351}
2022-11-28 02:12:03,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:03,300 INFO:     Epoch: 0
2022-11-28 02:12:04,043 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5315052548592741, 'Total loss': 0.5315052548592741} | train loss {'Reaction outcome loss': 0.6388359319886215, 'Total loss': 0.6388359319886215}
2022-11-28 02:12:04,043 INFO:     Found new best model at epoch 0
2022-11-28 02:12:04,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:04,044 INFO:     Epoch: 1
2022-11-28 02:12:04,789 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5226928573101759, 'Total loss': 0.5226928573101759} | train loss {'Reaction outcome loss': 0.4962457712091174, 'Total loss': 0.4962457712091174}
2022-11-28 02:12:04,789 INFO:     Found new best model at epoch 1
2022-11-28 02:12:04,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:04,790 INFO:     Epoch: 2
2022-11-28 02:12:05,536 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.504515583880923, 'Total loss': 0.504515583880923} | train loss {'Reaction outcome loss': 0.45474231038016344, 'Total loss': 0.45474231038016344}
2022-11-28 02:12:05,537 INFO:     Found new best model at epoch 2
2022-11-28 02:12:05,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:05,537 INFO:     Epoch: 3
2022-11-28 02:12:06,284 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4775231030176986, 'Total loss': 0.4775231030176986} | train loss {'Reaction outcome loss': 0.4388338660421642, 'Total loss': 0.4388338660421642}
2022-11-28 02:12:06,285 INFO:     Found new best model at epoch 3
2022-11-28 02:12:06,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:06,285 INFO:     Epoch: 4
2022-11-28 02:12:07,036 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47532377392053604, 'Total loss': 0.47532377392053604} | train loss {'Reaction outcome loss': 0.4216096792897956, 'Total loss': 0.4216096792897956}
2022-11-28 02:12:07,036 INFO:     Found new best model at epoch 4
2022-11-28 02:12:07,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:07,037 INFO:     Epoch: 5
2022-11-28 02:12:07,780 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.454195575280623, 'Total loss': 0.454195575280623} | train loss {'Reaction outcome loss': 0.4064687077514073, 'Total loss': 0.4064687077514073}
2022-11-28 02:12:07,780 INFO:     Found new best model at epoch 5
2022-11-28 02:12:07,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:07,781 INFO:     Epoch: 6
2022-11-28 02:12:08,527 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45538215745579114, 'Total loss': 0.45538215745579114} | train loss {'Reaction outcome loss': 0.39915300763932315, 'Total loss': 0.39915300763932315}
2022-11-28 02:12:08,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:08,528 INFO:     Epoch: 7
2022-11-28 02:12:09,271 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45523086596619, 'Total loss': 0.45523086596619} | train loss {'Reaction outcome loss': 0.38866801383275434, 'Total loss': 0.38866801383275434}
2022-11-28 02:12:09,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:09,271 INFO:     Epoch: 8
2022-11-28 02:12:10,016 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46953501823273575, 'Total loss': 0.46953501823273575} | train loss {'Reaction outcome loss': 0.38803150085543814, 'Total loss': 0.38803150085543814}
2022-11-28 02:12:10,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:10,016 INFO:     Epoch: 9
2022-11-28 02:12:10,759 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43818994442170317, 'Total loss': 0.43818994442170317} | train loss {'Reaction outcome loss': 0.38860811775753856, 'Total loss': 0.38860811775753856}
2022-11-28 02:12:10,759 INFO:     Found new best model at epoch 9
2022-11-28 02:12:10,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:10,760 INFO:     Epoch: 10
2022-11-28 02:12:11,504 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4525477723641829, 'Total loss': 0.4525477723641829} | train loss {'Reaction outcome loss': 0.37008405546186424, 'Total loss': 0.37008405546186424}
2022-11-28 02:12:11,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:11,504 INFO:     Epoch: 11
2022-11-28 02:12:12,247 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42603653093630617, 'Total loss': 0.42603653093630617} | train loss {'Reaction outcome loss': 0.3857658347680501, 'Total loss': 0.3857658347680501}
2022-11-28 02:12:12,248 INFO:     Found new best model at epoch 11
2022-11-28 02:12:12,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:12,248 INFO:     Epoch: 12
2022-11-28 02:12:12,996 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4623729203912345, 'Total loss': 0.4623729203912345} | train loss {'Reaction outcome loss': 0.3658825838976061, 'Total loss': 0.3658825838976061}
2022-11-28 02:12:12,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:12,996 INFO:     Epoch: 13
2022-11-28 02:12:13,737 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4920904693955725, 'Total loss': 0.4920904693955725} | train loss {'Reaction outcome loss': 0.3760723791383056, 'Total loss': 0.3760723791383056}
2022-11-28 02:12:13,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:13,737 INFO:     Epoch: 14
2022-11-28 02:12:14,480 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.440945682877844, 'Total loss': 0.440945682877844} | train loss {'Reaction outcome loss': 0.3783596480182308, 'Total loss': 0.3783596480182308}
2022-11-28 02:12:14,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:14,480 INFO:     Epoch: 15
2022-11-28 02:12:15,225 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4580787183208899, 'Total loss': 0.4580787183208899} | train loss {'Reaction outcome loss': 0.3631021771957035, 'Total loss': 0.3631021771957035}
2022-11-28 02:12:15,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:15,225 INFO:     Epoch: 16
2022-11-28 02:12:15,970 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43127299506555905, 'Total loss': 0.43127299506555905} | train loss {'Reaction outcome loss': 0.3576819322369842, 'Total loss': 0.3576819322369842}
2022-11-28 02:12:15,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:15,970 INFO:     Epoch: 17
2022-11-28 02:12:16,715 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46680130809545517, 'Total loss': 0.46680130809545517} | train loss {'Reaction outcome loss': 0.3555402000725028, 'Total loss': 0.3555402000725028}
2022-11-28 02:12:16,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:16,715 INFO:     Epoch: 18
2022-11-28 02:12:17,458 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4383617432957346, 'Total loss': 0.4383617432957346} | train loss {'Reaction outcome loss': 0.3485287295858025, 'Total loss': 0.3485287295858025}
2022-11-28 02:12:17,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:17,458 INFO:     Epoch: 19
2022-11-28 02:12:18,206 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4341761124404994, 'Total loss': 0.4341761124404994} | train loss {'Reaction outcome loss': 0.34843053011155806, 'Total loss': 0.34843053011155806}
2022-11-28 02:12:18,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:18,206 INFO:     Epoch: 20
2022-11-28 02:12:18,952 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46248533339662984, 'Total loss': 0.46248533339662984} | train loss {'Reaction outcome loss': 0.35718024576361845, 'Total loss': 0.35718024576361845}
2022-11-28 02:12:18,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:18,952 INFO:     Epoch: 21
2022-11-28 02:12:19,697 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4758621237494729, 'Total loss': 0.4758621237494729} | train loss {'Reaction outcome loss': 0.3731171853146572, 'Total loss': 0.3731171853146572}
2022-11-28 02:12:19,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:19,698 INFO:     Epoch: 22
2022-11-28 02:12:20,445 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4263835952363231, 'Total loss': 0.4263835952363231} | train loss {'Reaction outcome loss': 0.35660071324119685, 'Total loss': 0.35660071324119685}
2022-11-28 02:12:20,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:20,445 INFO:     Epoch: 23
2022-11-28 02:12:21,189 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43540462716059253, 'Total loss': 0.43540462716059253} | train loss {'Reaction outcome loss': 0.3383358694944787, 'Total loss': 0.3383358694944787}
2022-11-28 02:12:21,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:21,190 INFO:     Epoch: 24
2022-11-28 02:12:21,933 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44104275378313934, 'Total loss': 0.44104275378313934} | train loss {'Reaction outcome loss': 0.34955072467807335, 'Total loss': 0.34955072467807335}
2022-11-28 02:12:21,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:21,934 INFO:     Epoch: 25
2022-11-28 02:12:22,679 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42264794084158813, 'Total loss': 0.42264794084158813} | train loss {'Reaction outcome loss': 0.3351823978450315, 'Total loss': 0.3351823978450315}
2022-11-28 02:12:22,679 INFO:     Found new best model at epoch 25
2022-11-28 02:12:22,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:22,680 INFO:     Epoch: 26
2022-11-28 02:12:23,423 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4070844030515714, 'Total loss': 0.4070844030515714} | train loss {'Reaction outcome loss': 0.3319284308829952, 'Total loss': 0.3319284308829952}
2022-11-28 02:12:23,423 INFO:     Found new best model at epoch 26
2022-11-28 02:12:23,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:23,424 INFO:     Epoch: 27
2022-11-28 02:12:24,169 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4266681886193427, 'Total loss': 0.4266681886193427} | train loss {'Reaction outcome loss': 0.3313908254207387, 'Total loss': 0.3313908254207387}
2022-11-28 02:12:24,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:24,169 INFO:     Epoch: 28
2022-11-28 02:12:24,910 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4175803547894413, 'Total loss': 0.4175803547894413} | train loss {'Reaction outcome loss': 0.357642208878328, 'Total loss': 0.357642208878328}
2022-11-28 02:12:24,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:24,911 INFO:     Epoch: 29
2022-11-28 02:12:25,660 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4239520408551801, 'Total loss': 0.4239520408551801} | train loss {'Reaction outcome loss': 0.34476470170535056, 'Total loss': 0.34476470170535056}
2022-11-28 02:12:25,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:25,660 INFO:     Epoch: 30
2022-11-28 02:12:26,407 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45207192274657165, 'Total loss': 0.45207192274657165} | train loss {'Reaction outcome loss': 0.32935915145314176, 'Total loss': 0.32935915145314176}
2022-11-28 02:12:26,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:26,408 INFO:     Epoch: 31
2022-11-28 02:12:27,152 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40363157472827216, 'Total loss': 0.40363157472827216} | train loss {'Reaction outcome loss': 0.3356348216413004, 'Total loss': 0.3356348216413004}
2022-11-28 02:12:27,153 INFO:     Found new best model at epoch 31
2022-11-28 02:12:27,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:27,153 INFO:     Epoch: 32
2022-11-28 02:12:27,897 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4255876703695817, 'Total loss': 0.4255876703695817} | train loss {'Reaction outcome loss': 0.32799740349836193, 'Total loss': 0.32799740349836193}
2022-11-28 02:12:27,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:27,898 INFO:     Epoch: 33
2022-11-28 02:12:28,644 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42507854307239706, 'Total loss': 0.42507854307239706} | train loss {'Reaction outcome loss': 0.3358474666712738, 'Total loss': 0.3358474666712738}
2022-11-28 02:12:28,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:28,644 INFO:     Epoch: 34
2022-11-28 02:12:29,390 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42429143376648426, 'Total loss': 0.42429143376648426} | train loss {'Reaction outcome loss': 0.3291553110185905, 'Total loss': 0.3291553110185905}
2022-11-28 02:12:29,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:29,390 INFO:     Epoch: 35
2022-11-28 02:12:30,135 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4516292265193029, 'Total loss': 0.4516292265193029} | train loss {'Reaction outcome loss': 0.3364240660856248, 'Total loss': 0.3364240660856248}
2022-11-28 02:12:30,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:30,135 INFO:     Epoch: 36
2022-11-28 02:12:30,882 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4367387989027934, 'Total loss': 0.4367387989027934} | train loss {'Reaction outcome loss': 0.32433466783720954, 'Total loss': 0.32433466783720954}
2022-11-28 02:12:30,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:30,882 INFO:     Epoch: 37
2022-11-28 02:12:31,624 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44344851543957536, 'Total loss': 0.44344851543957536} | train loss {'Reaction outcome loss': 0.3445030625811533, 'Total loss': 0.3445030625811533}
2022-11-28 02:12:31,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:31,624 INFO:     Epoch: 38
2022-11-28 02:12:32,367 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41754251244393265, 'Total loss': 0.41754251244393265} | train loss {'Reaction outcome loss': 0.3238653073726912, 'Total loss': 0.3238653073726912}
2022-11-28 02:12:32,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:32,367 INFO:     Epoch: 39
2022-11-28 02:12:33,111 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4518350782719525, 'Total loss': 0.4518350782719525} | train loss {'Reaction outcome loss': 0.32225446989722095, 'Total loss': 0.32225446989722095}
2022-11-28 02:12:33,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:33,111 INFO:     Epoch: 40
2022-11-28 02:12:33,857 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42130156978964806, 'Total loss': 0.42130156978964806} | train loss {'Reaction outcome loss': 0.3167315383406928, 'Total loss': 0.3167315383406928}
2022-11-28 02:12:33,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:33,857 INFO:     Epoch: 41
2022-11-28 02:12:34,600 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45592732761393895, 'Total loss': 0.45592732761393895} | train loss {'Reaction outcome loss': 0.3403936148232777, 'Total loss': 0.3403936148232777}
2022-11-28 02:12:34,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:34,601 INFO:     Epoch: 42
2022-11-28 02:12:35,346 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40410189398310403, 'Total loss': 0.40410189398310403} | train loss {'Reaction outcome loss': 0.33351456325667106, 'Total loss': 0.33351456325667106}
2022-11-28 02:12:35,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:35,346 INFO:     Epoch: 43
2022-11-28 02:12:36,094 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4320847568186847, 'Total loss': 0.4320847568186847} | train loss {'Reaction outcome loss': 0.3329362705550703, 'Total loss': 0.3329362705550703}
2022-11-28 02:12:36,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:36,094 INFO:     Epoch: 44
2022-11-28 02:12:36,848 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.457689511843703, 'Total loss': 0.457689511843703} | train loss {'Reaction outcome loss': 0.33088004187895703, 'Total loss': 0.33088004187895703}
2022-11-28 02:12:36,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:36,848 INFO:     Epoch: 45
2022-11-28 02:12:37,595 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3957356285642494, 'Total loss': 0.3957356285642494} | train loss {'Reaction outcome loss': 0.33196755631370584, 'Total loss': 0.33196755631370584}
2022-11-28 02:12:37,595 INFO:     Found new best model at epoch 45
2022-11-28 02:12:37,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:37,596 INFO:     Epoch: 46
2022-11-28 02:12:38,339 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4370457164265893, 'Total loss': 0.4370457164265893} | train loss {'Reaction outcome loss': 0.31483346653295313, 'Total loss': 0.31483346653295313}
2022-11-28 02:12:38,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:38,339 INFO:     Epoch: 47
2022-11-28 02:12:39,080 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4341161386533217, 'Total loss': 0.4341161386533217} | train loss {'Reaction outcome loss': 0.325429173555934, 'Total loss': 0.325429173555934}
2022-11-28 02:12:39,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:39,081 INFO:     Epoch: 48
2022-11-28 02:12:39,827 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44496438482945616, 'Total loss': 0.44496438482945616} | train loss {'Reaction outcome loss': 0.31861216315494373, 'Total loss': 0.31861216315494373}
2022-11-28 02:12:39,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:39,827 INFO:     Epoch: 49
2022-11-28 02:12:40,575 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4267291058362885, 'Total loss': 0.4267291058362885} | train loss {'Reaction outcome loss': 0.3311077707149239, 'Total loss': 0.3311077707149239}
2022-11-28 02:12:40,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:40,576 INFO:     Epoch: 50
2022-11-28 02:12:41,322 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42536037347533484, 'Total loss': 0.42536037347533484} | train loss {'Reaction outcome loss': 0.3246199735685399, 'Total loss': 0.3246199735685399}
2022-11-28 02:12:41,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:41,322 INFO:     Epoch: 51
2022-11-28 02:12:42,066 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42220373316244647, 'Total loss': 0.42220373316244647} | train loss {'Reaction outcome loss': 0.3293692135678129, 'Total loss': 0.3293692135678129}
2022-11-28 02:12:42,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:42,066 INFO:     Epoch: 52
2022-11-28 02:12:42,811 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43397640538486565, 'Total loss': 0.43397640538486565} | train loss {'Reaction outcome loss': 0.321397545698442, 'Total loss': 0.321397545698442}
2022-11-28 02:12:42,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:42,811 INFO:     Epoch: 53
2022-11-28 02:12:43,556 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44920641353184526, 'Total loss': 0.44920641353184526} | train loss {'Reaction outcome loss': 0.3213950700243475, 'Total loss': 0.3213950700243475}
2022-11-28 02:12:43,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:43,556 INFO:     Epoch: 54
2022-11-28 02:12:44,301 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4309447624466636, 'Total loss': 0.4309447624466636} | train loss {'Reaction outcome loss': 0.3341623878216999, 'Total loss': 0.3341623878216999}
2022-11-28 02:12:44,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:44,301 INFO:     Epoch: 55
2022-11-28 02:12:45,045 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44800197976556694, 'Total loss': 0.44800197976556694} | train loss {'Reaction outcome loss': 0.3213417934890561, 'Total loss': 0.3213417934890561}
2022-11-28 02:12:45,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:45,045 INFO:     Epoch: 56
2022-11-28 02:12:45,789 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44179403510960663, 'Total loss': 0.44179403510960663} | train loss {'Reaction outcome loss': 0.32886409367385666, 'Total loss': 0.32886409367385666}
2022-11-28 02:12:45,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:45,789 INFO:     Epoch: 57
2022-11-28 02:12:46,537 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4144864707698368, 'Total loss': 0.4144864707698368} | train loss {'Reaction outcome loss': 0.32174850038068015, 'Total loss': 0.32174850038068015}
2022-11-28 02:12:46,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:46,537 INFO:     Epoch: 58
2022-11-28 02:12:47,280 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45052334530787036, 'Total loss': 0.45052334530787036} | train loss {'Reaction outcome loss': 0.3188248814539871, 'Total loss': 0.3188248814539871}
2022-11-28 02:12:47,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:47,280 INFO:     Epoch: 59
2022-11-28 02:12:48,026 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4182536026293581, 'Total loss': 0.4182536026293581} | train loss {'Reaction outcome loss': 0.3245942387202008, 'Total loss': 0.3245942387202008}
2022-11-28 02:12:48,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:48,027 INFO:     Epoch: 60
2022-11-28 02:12:48,770 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4483053477650339, 'Total loss': 0.4483053477650339} | train loss {'Reaction outcome loss': 0.33071073250956307, 'Total loss': 0.33071073250956307}
2022-11-28 02:12:48,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:48,770 INFO:     Epoch: 61
2022-11-28 02:12:49,513 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4357562915168025, 'Total loss': 0.4357562915168025} | train loss {'Reaction outcome loss': 0.3087126113368794, 'Total loss': 0.3087126113368794}
2022-11-28 02:12:49,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:49,513 INFO:     Epoch: 62
2022-11-28 02:12:50,263 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4290080839260058, 'Total loss': 0.4290080839260058} | train loss {'Reaction outcome loss': 0.3106937529406084, 'Total loss': 0.3106937529406084}
2022-11-28 02:12:50,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:50,263 INFO:     Epoch: 63
2022-11-28 02:12:51,012 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41840931569988077, 'Total loss': 0.41840931569988077} | train loss {'Reaction outcome loss': 0.33639897025277016, 'Total loss': 0.33639897025277016}
2022-11-28 02:12:51,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:51,012 INFO:     Epoch: 64
2022-11-28 02:12:51,758 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.431923602453687, 'Total loss': 0.431923602453687} | train loss {'Reaction outcome loss': 0.32458608717914966, 'Total loss': 0.32458608717914966}
2022-11-28 02:12:51,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:51,759 INFO:     Epoch: 65
2022-11-28 02:12:52,505 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4149516113102436, 'Total loss': 0.4149516113102436} | train loss {'Reaction outcome loss': 0.3148303839723534, 'Total loss': 0.3148303839723534}
2022-11-28 02:12:52,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:52,506 INFO:     Epoch: 66
2022-11-28 02:12:53,252 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4112905758348378, 'Total loss': 0.4112905758348378} | train loss {'Reaction outcome loss': 0.3071908125963047, 'Total loss': 0.3071908125963047}
2022-11-28 02:12:53,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:53,252 INFO:     Epoch: 67
2022-11-28 02:12:53,997 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4046571667898785, 'Total loss': 0.4046571667898785} | train loss {'Reaction outcome loss': 0.3141876643576361, 'Total loss': 0.3141876643576361}
2022-11-28 02:12:53,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:53,997 INFO:     Epoch: 68
2022-11-28 02:12:54,741 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4581564851105213, 'Total loss': 0.4581564851105213} | train loss {'Reaction outcome loss': 0.3158749022751081, 'Total loss': 0.3158749022751081}
2022-11-28 02:12:54,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:54,741 INFO:     Epoch: 69
2022-11-28 02:12:55,490 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42750993777405133, 'Total loss': 0.42750993777405133} | train loss {'Reaction outcome loss': 0.31292404757759834, 'Total loss': 0.31292404757759834}
2022-11-28 02:12:55,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:55,490 INFO:     Epoch: 70
2022-11-28 02:12:56,236 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4280374182218855, 'Total loss': 0.4280374182218855} | train loss {'Reaction outcome loss': 0.3138855389858547, 'Total loss': 0.3138855389858547}
2022-11-28 02:12:56,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:56,236 INFO:     Epoch: 71
2022-11-28 02:12:56,986 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4275637436658144, 'Total loss': 0.4275637436658144} | train loss {'Reaction outcome loss': 0.31111046251829577, 'Total loss': 0.31111046251829577}
2022-11-28 02:12:56,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:56,986 INFO:     Epoch: 72
2022-11-28 02:12:57,730 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42075555669990455, 'Total loss': 0.42075555669990455} | train loss {'Reaction outcome loss': 0.3135829266266302, 'Total loss': 0.3135829266266302}
2022-11-28 02:12:57,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:57,731 INFO:     Epoch: 73
2022-11-28 02:12:58,477 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4200905554673888, 'Total loss': 0.4200905554673888} | train loss {'Reaction outcome loss': 0.3476398494283137, 'Total loss': 0.3476398494283137}
2022-11-28 02:12:58,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:58,478 INFO:     Epoch: 74
2022-11-28 02:12:59,227 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41631655903025105, 'Total loss': 0.41631655903025105} | train loss {'Reaction outcome loss': 0.31214421707005635, 'Total loss': 0.31214421707005635}
2022-11-28 02:12:59,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:59,227 INFO:     Epoch: 75
2022-11-28 02:12:59,974 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42165844210169534, 'Total loss': 0.42165844210169534} | train loss {'Reaction outcome loss': 0.3113071062608701, 'Total loss': 0.3113071062608701}
2022-11-28 02:12:59,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:12:59,975 INFO:     Epoch: 76
2022-11-28 02:13:00,720 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4432987245223062, 'Total loss': 0.4432987245223062} | train loss {'Reaction outcome loss': 0.2973378868735874, 'Total loss': 0.2973378868735874}
2022-11-28 02:13:00,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:00,720 INFO:     Epoch: 77
2022-11-28 02:13:01,468 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41214453225786035, 'Total loss': 0.41214453225786035} | train loss {'Reaction outcome loss': 0.30988170487828826, 'Total loss': 0.30988170487828826}
2022-11-28 02:13:01,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:01,469 INFO:     Epoch: 78
2022-11-28 02:13:02,215 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43587657233530824, 'Total loss': 0.43587657233530824} | train loss {'Reaction outcome loss': 0.31351593432397495, 'Total loss': 0.31351593432397495}
2022-11-28 02:13:02,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:02,215 INFO:     Epoch: 79
2022-11-28 02:13:02,960 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4386485550891269, 'Total loss': 0.4386485550891269} | train loss {'Reaction outcome loss': 0.32399706237832543, 'Total loss': 0.32399706237832543}
2022-11-28 02:13:02,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:02,960 INFO:     Epoch: 80
2022-11-28 02:13:03,706 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4222219616852023, 'Total loss': 0.4222219616852023} | train loss {'Reaction outcome loss': 0.36307139444327063, 'Total loss': 0.36307139444327063}
2022-11-28 02:13:03,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:03,706 INFO:     Epoch: 81
2022-11-28 02:13:04,451 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.457474849102172, 'Total loss': 0.457474849102172} | train loss {'Reaction outcome loss': 0.3137375725063718, 'Total loss': 0.3137375725063718}
2022-11-28 02:13:04,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:04,451 INFO:     Epoch: 82
2022-11-28 02:13:05,201 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46856021508574486, 'Total loss': 0.46856021508574486} | train loss {'Reaction outcome loss': 0.30037724982328745, 'Total loss': 0.30037724982328745}
2022-11-28 02:13:05,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:05,201 INFO:     Epoch: 83
2022-11-28 02:13:05,945 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47298033332282846, 'Total loss': 0.47298033332282846} | train loss {'Reaction outcome loss': 0.3109429176549921, 'Total loss': 0.3109429176549921}
2022-11-28 02:13:05,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:05,945 INFO:     Epoch: 84
2022-11-28 02:13:06,693 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4326381873000752, 'Total loss': 0.4326381873000752} | train loss {'Reaction outcome loss': 0.3125973886957294, 'Total loss': 0.3125973886957294}
2022-11-28 02:13:06,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:06,693 INFO:     Epoch: 85
2022-11-28 02:13:07,436 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4175830568102273, 'Total loss': 0.4175830568102273} | train loss {'Reaction outcome loss': 0.31388913410208386, 'Total loss': 0.31388913410208386}
2022-11-28 02:13:07,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:07,436 INFO:     Epoch: 86
2022-11-28 02:13:08,184 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4270095613531091, 'Total loss': 0.4270095613531091} | train loss {'Reaction outcome loss': 0.3107608224035275, 'Total loss': 0.3107608224035275}
2022-11-28 02:13:08,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:08,184 INFO:     Epoch: 87
2022-11-28 02:13:08,932 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4370603696866469, 'Total loss': 0.4370603696866469} | train loss {'Reaction outcome loss': 0.30364088180591825, 'Total loss': 0.30364088180591825}
2022-11-28 02:13:08,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:08,932 INFO:     Epoch: 88
2022-11-28 02:13:09,676 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4488071325150403, 'Total loss': 0.4488071325150403} | train loss {'Reaction outcome loss': 0.3084937737069775, 'Total loss': 0.3084937737069775}
2022-11-28 02:13:09,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:09,676 INFO:     Epoch: 89
2022-11-28 02:13:10,421 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46382717246359045, 'Total loss': 0.46382717246359045} | train loss {'Reaction outcome loss': 0.3007370311962931, 'Total loss': 0.3007370311962931}
2022-11-28 02:13:10,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:10,421 INFO:     Epoch: 90
2022-11-28 02:13:11,166 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47673950039527635, 'Total loss': 0.47673950039527635} | train loss {'Reaction outcome loss': 0.3101594745672142, 'Total loss': 0.3101594745672142}
2022-11-28 02:13:11,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:11,166 INFO:     Epoch: 91
2022-11-28 02:13:11,913 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40833894231102685, 'Total loss': 0.40833894231102685} | train loss {'Reaction outcome loss': 0.31911589847764504, 'Total loss': 0.31911589847764504}
2022-11-28 02:13:11,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:11,914 INFO:     Epoch: 92
2022-11-28 02:13:12,658 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4468916573307731, 'Total loss': 0.4468916573307731} | train loss {'Reaction outcome loss': 0.31286605616945673, 'Total loss': 0.31286605616945673}
2022-11-28 02:13:12,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:12,658 INFO:     Epoch: 93
2022-11-28 02:13:13,401 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44286453097381373, 'Total loss': 0.44286453097381373} | train loss {'Reaction outcome loss': 0.30651633378103194, 'Total loss': 0.30651633378103194}
2022-11-28 02:13:13,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:13,401 INFO:     Epoch: 94
2022-11-28 02:13:14,147 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4424217766658826, 'Total loss': 0.4424217766658826} | train loss {'Reaction outcome loss': 0.3053808629904923, 'Total loss': 0.3053808629904923}
2022-11-28 02:13:14,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:14,147 INFO:     Epoch: 95
2022-11-28 02:13:14,896 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42225122113119473, 'Total loss': 0.42225122113119473} | train loss {'Reaction outcome loss': 0.300938758310515, 'Total loss': 0.300938758310515}
2022-11-28 02:13:14,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:14,896 INFO:     Epoch: 96
2022-11-28 02:13:15,639 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41562393155287614, 'Total loss': 0.41562393155287614} | train loss {'Reaction outcome loss': 0.3033208522176453, 'Total loss': 0.3033208522176453}
2022-11-28 02:13:15,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:15,639 INFO:     Epoch: 97
2022-11-28 02:13:16,387 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42344212904572487, 'Total loss': 0.42344212904572487} | train loss {'Reaction outcome loss': 0.30555174232796134, 'Total loss': 0.30555174232796134}
2022-11-28 02:13:16,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:16,387 INFO:     Epoch: 98
2022-11-28 02:13:17,133 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39559898288412526, 'Total loss': 0.39559898288412526} | train loss {'Reaction outcome loss': 0.30383676049197733, 'Total loss': 0.30383676049197733}
2022-11-28 02:13:17,134 INFO:     Found new best model at epoch 98
2022-11-28 02:13:17,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:17,134 INFO:     Epoch: 99
2022-11-28 02:13:17,885 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.446061101149429, 'Total loss': 0.446061101149429} | train loss {'Reaction outcome loss': 0.3013748460136324, 'Total loss': 0.3013748460136324}
2022-11-28 02:13:17,885 INFO:     Best model found after epoch 99 of 100.
2022-11-28 02:13:17,885 INFO:   Done with stage: TRAINING
2022-11-28 02:13:17,885 INFO:   Starting stage: EVALUATION
2022-11-28 02:13:18,009 INFO:   Done with stage: EVALUATION
2022-11-28 02:13:18,009 INFO:   Leaving out SEQ value Fold_5
2022-11-28 02:13:18,022 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:13:18,022 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:13:18,677 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:13:18,677 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:13:18,746 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:13:18,746 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:13:18,746 INFO:     No hyperparam tuning for this model
2022-11-28 02:13:18,746 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:13:18,746 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:13:18,747 INFO:     None feature selector for col prot
2022-11-28 02:13:18,747 INFO:     None feature selector for col prot
2022-11-28 02:13:18,747 INFO:     None feature selector for col prot
2022-11-28 02:13:18,748 INFO:     None feature selector for col chem
2022-11-28 02:13:18,748 INFO:     None feature selector for col chem
2022-11-28 02:13:18,748 INFO:     None feature selector for col chem
2022-11-28 02:13:18,748 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:13:18,748 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:13:18,749 INFO:     Number of params in model 169741
2022-11-28 02:13:18,753 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:13:18,753 INFO:   Starting stage: TRAINING
2022-11-28 02:13:18,806 INFO:     Val loss before train {'Reaction outcome loss': 0.999444842338562, 'Total loss': 0.999444842338562}
2022-11-28 02:13:18,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:18,807 INFO:     Epoch: 0
2022-11-28 02:13:19,557 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.49441775865852833, 'Total loss': 0.49441775865852833} | train loss {'Reaction outcome loss': 0.6348818821101053, 'Total loss': 0.6348818821101053}
2022-11-28 02:13:19,557 INFO:     Found new best model at epoch 0
2022-11-28 02:13:19,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:19,558 INFO:     Epoch: 1
2022-11-28 02:13:20,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5012479536235332, 'Total loss': 0.5012479536235332} | train loss {'Reaction outcome loss': 0.495975493811644, 'Total loss': 0.495975493811644}
2022-11-28 02:13:20,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:20,304 INFO:     Epoch: 2
2022-11-28 02:13:21,050 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.485076789828864, 'Total loss': 0.485076789828864} | train loss {'Reaction outcome loss': 0.478690098201939, 'Total loss': 0.478690098201939}
2022-11-28 02:13:21,050 INFO:     Found new best model at epoch 2
2022-11-28 02:13:21,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:21,051 INFO:     Epoch: 3
2022-11-28 02:13:21,802 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45425990698012436, 'Total loss': 0.45425990698012436} | train loss {'Reaction outcome loss': 0.44893045727962905, 'Total loss': 0.44893045727962905}
2022-11-28 02:13:21,802 INFO:     Found new best model at epoch 3
2022-11-28 02:13:21,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:21,803 INFO:     Epoch: 4
2022-11-28 02:13:22,555 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4312387796288187, 'Total loss': 0.4312387796288187} | train loss {'Reaction outcome loss': 0.4262629545063746, 'Total loss': 0.4262629545063746}
2022-11-28 02:13:22,555 INFO:     Found new best model at epoch 4
2022-11-28 02:13:22,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:22,556 INFO:     Epoch: 5
2022-11-28 02:13:23,306 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.460263502868739, 'Total loss': 0.460263502868739} | train loss {'Reaction outcome loss': 0.41104456022200797, 'Total loss': 0.41104456022200797}
2022-11-28 02:13:23,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:23,307 INFO:     Epoch: 6
2022-11-28 02:13:24,056 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4220527552745559, 'Total loss': 0.4220527552745559} | train loss {'Reaction outcome loss': 0.410892444839965, 'Total loss': 0.410892444839965}
2022-11-28 02:13:24,056 INFO:     Found new best model at epoch 6
2022-11-28 02:13:24,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:24,057 INFO:     Epoch: 7
2022-11-28 02:13:24,802 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4272346262904731, 'Total loss': 0.4272346262904731} | train loss {'Reaction outcome loss': 0.3928392226487277, 'Total loss': 0.3928392226487277}
2022-11-28 02:13:24,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:24,802 INFO:     Epoch: 8
2022-11-28 02:13:25,550 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44512149725448, 'Total loss': 0.44512149725448} | train loss {'Reaction outcome loss': 0.38369855486791626, 'Total loss': 0.38369855486791626}
2022-11-28 02:13:25,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:25,550 INFO:     Epoch: 9
2022-11-28 02:13:26,295 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4308134358037602, 'Total loss': 0.4308134358037602} | train loss {'Reaction outcome loss': 0.3844498550662628, 'Total loss': 0.3844498550662628}
2022-11-28 02:13:26,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:26,295 INFO:     Epoch: 10
2022-11-28 02:13:27,044 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43494059247049416, 'Total loss': 0.43494059247049416} | train loss {'Reaction outcome loss': 0.37631577935054716, 'Total loss': 0.37631577935054716}
2022-11-28 02:13:27,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:27,045 INFO:     Epoch: 11
2022-11-28 02:13:27,792 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4206866875968196, 'Total loss': 0.4206866875968196} | train loss {'Reaction outcome loss': 0.3680921880460461, 'Total loss': 0.3680921880460461}
2022-11-28 02:13:27,792 INFO:     Found new best model at epoch 11
2022-11-28 02:13:27,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:27,793 INFO:     Epoch: 12
2022-11-28 02:13:28,540 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41330323266712105, 'Total loss': 0.41330323266712105} | train loss {'Reaction outcome loss': 0.3667017627575318, 'Total loss': 0.3667017627575318}
2022-11-28 02:13:28,540 INFO:     Found new best model at epoch 12
2022-11-28 02:13:28,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:28,541 INFO:     Epoch: 13
2022-11-28 02:13:29,292 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4171595735983415, 'Total loss': 0.4171595735983415} | train loss {'Reaction outcome loss': 0.3711610963711372, 'Total loss': 0.3711610963711372}
2022-11-28 02:13:29,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:29,292 INFO:     Epoch: 14
2022-11-28 02:13:30,041 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4282258461144837, 'Total loss': 0.4282258461144837} | train loss {'Reaction outcome loss': 0.41251301891754877, 'Total loss': 0.41251301891754877}
2022-11-28 02:13:30,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:30,042 INFO:     Epoch: 15
2022-11-28 02:13:30,789 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4501747719266198, 'Total loss': 0.4501747719266198} | train loss {'Reaction outcome loss': 0.3546835785874954, 'Total loss': 0.3546835785874954}
2022-11-28 02:13:30,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:30,789 INFO:     Epoch: 16
2022-11-28 02:13:31,535 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4379414360631596, 'Total loss': 0.4379414360631596} | train loss {'Reaction outcome loss': 0.3522885504823465, 'Total loss': 0.3522885504823465}
2022-11-28 02:13:31,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:31,536 INFO:     Epoch: 17
2022-11-28 02:13:32,286 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41257363659414376, 'Total loss': 0.41257363659414376} | train loss {'Reaction outcome loss': 0.35723839803534724, 'Total loss': 0.35723839803534724}
2022-11-28 02:13:32,286 INFO:     Found new best model at epoch 17
2022-11-28 02:13:32,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:32,287 INFO:     Epoch: 18
2022-11-28 02:13:33,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42536868375133385, 'Total loss': 0.42536868375133385} | train loss {'Reaction outcome loss': 0.3395022741756458, 'Total loss': 0.3395022741756458}
2022-11-28 02:13:33,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:33,035 INFO:     Epoch: 19
2022-11-28 02:13:33,784 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40449232506481086, 'Total loss': 0.40449232506481086} | train loss {'Reaction outcome loss': 0.34638368744244763, 'Total loss': 0.34638368744244763}
2022-11-28 02:13:33,785 INFO:     Found new best model at epoch 19
2022-11-28 02:13:33,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:33,785 INFO:     Epoch: 20
2022-11-28 02:13:34,532 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4283417019654404, 'Total loss': 0.4283417019654404} | train loss {'Reaction outcome loss': 0.35035845172791347, 'Total loss': 0.35035845172791347}
2022-11-28 02:13:34,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:34,532 INFO:     Epoch: 21
2022-11-28 02:13:35,279 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4305375059219924, 'Total loss': 0.4305375059219924} | train loss {'Reaction outcome loss': 0.3668418746603736, 'Total loss': 0.3668418746603736}
2022-11-28 02:13:35,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:35,279 INFO:     Epoch: 22
2022-11-28 02:13:36,026 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39147161929444835, 'Total loss': 0.39147161929444835} | train loss {'Reaction outcome loss': 0.342419186071587, 'Total loss': 0.342419186071587}
2022-11-28 02:13:36,026 INFO:     Found new best model at epoch 22
2022-11-28 02:13:36,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:36,027 INFO:     Epoch: 23
2022-11-28 02:13:36,772 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4492594860494137, 'Total loss': 0.4492594860494137} | train loss {'Reaction outcome loss': 0.3417464430153611, 'Total loss': 0.3417464430153611}
2022-11-28 02:13:36,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:36,772 INFO:     Epoch: 24
2022-11-28 02:13:37,521 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40007508071986114, 'Total loss': 0.40007508071986114} | train loss {'Reaction outcome loss': 0.33695425663656187, 'Total loss': 0.33695425663656187}
2022-11-28 02:13:37,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:37,522 INFO:     Epoch: 25
2022-11-28 02:13:38,267 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44637696174058045, 'Total loss': 0.44637696174058045} | train loss {'Reaction outcome loss': 0.33210907571549386, 'Total loss': 0.33210907571549386}
2022-11-28 02:13:38,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:38,267 INFO:     Epoch: 26
2022-11-28 02:13:39,016 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39908703382719646, 'Total loss': 0.39908703382719646} | train loss {'Reaction outcome loss': 0.3310244703884067, 'Total loss': 0.3310244703884067}
2022-11-28 02:13:39,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:39,017 INFO:     Epoch: 27
2022-11-28 02:13:39,768 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38643212701109325, 'Total loss': 0.38643212701109325} | train loss {'Reaction outcome loss': 0.33298042938414857, 'Total loss': 0.33298042938414857}
2022-11-28 02:13:39,768 INFO:     Found new best model at epoch 27
2022-11-28 02:13:39,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:39,769 INFO:     Epoch: 28
2022-11-28 02:13:40,513 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43822965161366895, 'Total loss': 0.43822965161366895} | train loss {'Reaction outcome loss': 0.32765471865140233, 'Total loss': 0.32765471865140233}
2022-11-28 02:13:40,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:40,513 INFO:     Epoch: 29
2022-11-28 02:13:41,260 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4035384275696494, 'Total loss': 0.4035384275696494} | train loss {'Reaction outcome loss': 0.32361765847228435, 'Total loss': 0.32361765847228435}
2022-11-28 02:13:41,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:41,260 INFO:     Epoch: 30
2022-11-28 02:13:42,008 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4057124543257735, 'Total loss': 0.4057124543257735} | train loss {'Reaction outcome loss': 0.3295878151640002, 'Total loss': 0.3295878151640002}
2022-11-28 02:13:42,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:42,008 INFO:     Epoch: 31
2022-11-28 02:13:42,755 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4332464984194799, 'Total loss': 0.4332464984194799} | train loss {'Reaction outcome loss': 0.32890103090750544, 'Total loss': 0.32890103090750544}
2022-11-28 02:13:42,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:42,756 INFO:     Epoch: 32
2022-11-28 02:13:43,501 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3988575840538198, 'Total loss': 0.3988575840538198} | train loss {'Reaction outcome loss': 0.3372329209744082, 'Total loss': 0.3372329209744082}
2022-11-28 02:13:43,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:43,501 INFO:     Epoch: 33
2022-11-28 02:13:44,248 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4014730765060945, 'Total loss': 0.4014730765060945} | train loss {'Reaction outcome loss': 0.3203192686262401, 'Total loss': 0.3203192686262401}
2022-11-28 02:13:44,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:44,248 INFO:     Epoch: 34
2022-11-28 02:13:44,997 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39486423947594385, 'Total loss': 0.39486423947594385} | train loss {'Reaction outcome loss': 0.32338026472129805, 'Total loss': 0.32338026472129805}
2022-11-28 02:13:44,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:44,997 INFO:     Epoch: 35
2022-11-28 02:13:45,747 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40807813304391777, 'Total loss': 0.40807813304391777} | train loss {'Reaction outcome loss': 0.33941761503818063, 'Total loss': 0.33941761503818063}
2022-11-28 02:13:45,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:45,747 INFO:     Epoch: 36
2022-11-28 02:13:46,495 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4164013855836608, 'Total loss': 0.4164013855836608} | train loss {'Reaction outcome loss': 0.32344587768620325, 'Total loss': 0.32344587768620325}
2022-11-28 02:13:46,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:46,496 INFO:     Epoch: 37
2022-11-28 02:13:47,244 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4167052576826377, 'Total loss': 0.4167052576826377} | train loss {'Reaction outcome loss': 0.3255378666073687, 'Total loss': 0.3255378666073687}
2022-11-28 02:13:47,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:47,244 INFO:     Epoch: 38
2022-11-28 02:13:47,990 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40076905488967896, 'Total loss': 0.40076905488967896} | train loss {'Reaction outcome loss': 0.3213693244978484, 'Total loss': 0.3213693244978484}
2022-11-28 02:13:47,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:47,990 INFO:     Epoch: 39
2022-11-28 02:13:48,733 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3980618085373532, 'Total loss': 0.3980618085373532} | train loss {'Reaction outcome loss': 0.32429925117147745, 'Total loss': 0.32429925117147745}
2022-11-28 02:13:48,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:48,734 INFO:     Epoch: 40
2022-11-28 02:13:49,480 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43710190684280614, 'Total loss': 0.43710190684280614} | train loss {'Reaction outcome loss': 0.3096597715552429, 'Total loss': 0.3096597715552429}
2022-11-28 02:13:49,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:49,480 INFO:     Epoch: 41
2022-11-28 02:13:50,225 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38636218062178657, 'Total loss': 0.38636218062178657} | train loss {'Reaction outcome loss': 0.32708633534218134, 'Total loss': 0.32708633534218134}
2022-11-28 02:13:50,225 INFO:     Found new best model at epoch 41
2022-11-28 02:13:50,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:50,226 INFO:     Epoch: 42
2022-11-28 02:13:50,974 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40249543298374524, 'Total loss': 0.40249543298374524} | train loss {'Reaction outcome loss': 0.3376048722790803, 'Total loss': 0.3376048722790803}
2022-11-28 02:13:50,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:50,975 INFO:     Epoch: 43
2022-11-28 02:13:51,728 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4001554325222969, 'Total loss': 0.4001554325222969} | train loss {'Reaction outcome loss': 0.31116505730369315, 'Total loss': 0.31116505730369315}
2022-11-28 02:13:51,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:51,729 INFO:     Epoch: 44
2022-11-28 02:13:52,479 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41305477713996713, 'Total loss': 0.41305477713996713} | train loss {'Reaction outcome loss': 0.30756217398565744, 'Total loss': 0.30756217398565744}
2022-11-28 02:13:52,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:52,479 INFO:     Epoch: 45
2022-11-28 02:13:53,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42003708434375847, 'Total loss': 0.42003708434375847} | train loss {'Reaction outcome loss': 0.3162712545882579, 'Total loss': 0.3162712545882579}
2022-11-28 02:13:53,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:53,228 INFO:     Epoch: 46
2022-11-28 02:13:53,980 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41937679137018596, 'Total loss': 0.41937679137018596} | train loss {'Reaction outcome loss': 0.31567663642076343, 'Total loss': 0.31567663642076343}
2022-11-28 02:13:53,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:53,980 INFO:     Epoch: 47
2022-11-28 02:13:54,733 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46113100478594954, 'Total loss': 0.46113100478594954} | train loss {'Reaction outcome loss': 0.3202156684387792, 'Total loss': 0.3202156684387792}
2022-11-28 02:13:54,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:54,734 INFO:     Epoch: 48
2022-11-28 02:13:55,483 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39780747484077106, 'Total loss': 0.39780747484077106} | train loss {'Reaction outcome loss': 0.32964660878847485, 'Total loss': 0.32964660878847485}
2022-11-28 02:13:55,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:55,484 INFO:     Epoch: 49
2022-11-28 02:13:56,230 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3782767682251605, 'Total loss': 0.3782767682251605} | train loss {'Reaction outcome loss': 0.3149894053311566, 'Total loss': 0.3149894053311566}
2022-11-28 02:13:56,230 INFO:     Found new best model at epoch 49
2022-11-28 02:13:56,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:56,231 INFO:     Epoch: 50
2022-11-28 02:13:56,977 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3834645721045407, 'Total loss': 0.3834645721045407} | train loss {'Reaction outcome loss': 0.29955570128282555, 'Total loss': 0.29955570128282555}
2022-11-28 02:13:56,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:56,977 INFO:     Epoch: 51
2022-11-28 02:13:57,722 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4256835634058172, 'Total loss': 0.4256835634058172} | train loss {'Reaction outcome loss': 0.3128685331658313, 'Total loss': 0.3128685331658313}
2022-11-28 02:13:57,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:57,722 INFO:     Epoch: 52
2022-11-28 02:13:58,468 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38904136046767235, 'Total loss': 0.38904136046767235} | train loss {'Reaction outcome loss': 0.3150407615839315, 'Total loss': 0.3150407615839315}
2022-11-28 02:13:58,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:58,469 INFO:     Epoch: 53
2022-11-28 02:13:59,221 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4115593001585115, 'Total loss': 0.4115593001585115} | train loss {'Reaction outcome loss': 0.3187806920604667, 'Total loss': 0.3187806920604667}
2022-11-28 02:13:59,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:59,221 INFO:     Epoch: 54
2022-11-28 02:13:59,971 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4048501504585147, 'Total loss': 0.4048501504585147} | train loss {'Reaction outcome loss': 0.30869069661066567, 'Total loss': 0.30869069661066567}
2022-11-28 02:13:59,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:13:59,971 INFO:     Epoch: 55
2022-11-28 02:14:00,715 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4112720032307235, 'Total loss': 0.4112720032307235} | train loss {'Reaction outcome loss': 0.30446895896664516, 'Total loss': 0.30446895896664516}
2022-11-28 02:14:00,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:00,715 INFO:     Epoch: 56
2022-11-28 02:14:01,465 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4304482107135383, 'Total loss': 0.4304482107135383} | train loss {'Reaction outcome loss': 0.29703342986975606, 'Total loss': 0.29703342986975606}
2022-11-28 02:14:01,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:01,466 INFO:     Epoch: 57
2022-11-28 02:14:02,216 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4286742948672988, 'Total loss': 0.4286742948672988} | train loss {'Reaction outcome loss': 0.3105986551928375, 'Total loss': 0.3105986551928375}
2022-11-28 02:14:02,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:02,216 INFO:     Epoch: 58
2022-11-28 02:14:02,964 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4166511805220084, 'Total loss': 0.4166511805220084} | train loss {'Reaction outcome loss': 0.3262121110309956, 'Total loss': 0.3262121110309956}
2022-11-28 02:14:02,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:02,964 INFO:     Epoch: 59
2022-11-28 02:14:03,715 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38372657752849837, 'Total loss': 0.38372657752849837} | train loss {'Reaction outcome loss': 0.3196593322734601, 'Total loss': 0.3196593322734601}
2022-11-28 02:14:03,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:03,715 INFO:     Epoch: 60
2022-11-28 02:14:04,462 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4022544988177039, 'Total loss': 0.4022544988177039} | train loss {'Reaction outcome loss': 0.31447099031586395, 'Total loss': 0.31447099031586395}
2022-11-28 02:14:04,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:04,462 INFO:     Epoch: 61
2022-11-28 02:14:05,216 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3832567828622731, 'Total loss': 0.3832567828622731} | train loss {'Reaction outcome loss': 0.33101323990505715, 'Total loss': 0.33101323990505715}
2022-11-28 02:14:05,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:05,216 INFO:     Epoch: 62
2022-11-28 02:14:05,968 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40436249124732887, 'Total loss': 0.40436249124732887} | train loss {'Reaction outcome loss': 0.31923873384713164, 'Total loss': 0.31923873384713164}
2022-11-28 02:14:05,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:05,969 INFO:     Epoch: 63
2022-11-28 02:14:06,719 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40615182590078225, 'Total loss': 0.40615182590078225} | train loss {'Reaction outcome loss': 0.33741952023404814, 'Total loss': 0.33741952023404814}
2022-11-28 02:14:06,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:06,720 INFO:     Epoch: 64
2022-11-28 02:14:07,472 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4136206279085441, 'Total loss': 0.4136206279085441} | train loss {'Reaction outcome loss': 0.3323906083187835, 'Total loss': 0.3323906083187835}
2022-11-28 02:14:07,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:07,472 INFO:     Epoch: 65
2022-11-28 02:14:08,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39679420028220524, 'Total loss': 0.39679420028220524} | train loss {'Reaction outcome loss': 0.3209452428647622, 'Total loss': 0.3209452428647622}
2022-11-28 02:14:08,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:08,223 INFO:     Epoch: 66
2022-11-28 02:14:08,971 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4045551683415066, 'Total loss': 0.4045551683415066} | train loss {'Reaction outcome loss': 0.31050151621221533, 'Total loss': 0.31050151621221533}
2022-11-28 02:14:08,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:08,971 INFO:     Epoch: 67
2022-11-28 02:14:09,719 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3996292840350758, 'Total loss': 0.3996292840350758} | train loss {'Reaction outcome loss': 0.3037566662377674, 'Total loss': 0.3037566662377674}
2022-11-28 02:14:09,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:09,719 INFO:     Epoch: 68
2022-11-28 02:14:10,474 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39565516940572043, 'Total loss': 0.39565516940572043} | train loss {'Reaction outcome loss': 0.31402063676625536, 'Total loss': 0.31402063676625536}
2022-11-28 02:14:10,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:10,474 INFO:     Epoch: 69
2022-11-28 02:14:11,223 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42171608927575027, 'Total loss': 0.42171608927575027} | train loss {'Reaction outcome loss': 0.2999922137119268, 'Total loss': 0.2999922137119268}
2022-11-28 02:14:11,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:11,223 INFO:     Epoch: 70
2022-11-28 02:14:11,974 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40852301635525445, 'Total loss': 0.40852301635525445} | train loss {'Reaction outcome loss': 0.3077966090638628, 'Total loss': 0.3077966090638628}
2022-11-28 02:14:11,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:11,975 INFO:     Epoch: 71
2022-11-28 02:14:12,728 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4012608081102371, 'Total loss': 0.4012608081102371} | train loss {'Reaction outcome loss': 0.3205777015461613, 'Total loss': 0.3205777015461613}
2022-11-28 02:14:12,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:12,728 INFO:     Epoch: 72
2022-11-28 02:14:13,481 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40615811808542773, 'Total loss': 0.40615811808542773} | train loss {'Reaction outcome loss': 0.29750136301102426, 'Total loss': 0.29750136301102426}
2022-11-28 02:14:13,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:13,482 INFO:     Epoch: 73
2022-11-28 02:14:14,233 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41540462455966254, 'Total loss': 0.41540462455966254} | train loss {'Reaction outcome loss': 0.317945114604616, 'Total loss': 0.317945114604616}
2022-11-28 02:14:14,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:14,233 INFO:     Epoch: 74
2022-11-28 02:14:14,982 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41485623676668515, 'Total loss': 0.41485623676668515} | train loss {'Reaction outcome loss': 0.3029414777029381, 'Total loss': 0.3029414777029381}
2022-11-28 02:14:14,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:14,982 INFO:     Epoch: 75
2022-11-28 02:14:15,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4028225852684541, 'Total loss': 0.4028225852684541} | train loss {'Reaction outcome loss': 0.31568179830700455, 'Total loss': 0.31568179830700455}
2022-11-28 02:14:15,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:15,733 INFO:     Epoch: 76
2022-11-28 02:14:16,483 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4338294599543918, 'Total loss': 0.4338294599543918} | train loss {'Reaction outcome loss': 0.29948930167838145, 'Total loss': 0.29948930167838145}
2022-11-28 02:14:16,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:16,483 INFO:     Epoch: 77
2022-11-28 02:14:17,232 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4383810416541316, 'Total loss': 0.4383810416541316} | train loss {'Reaction outcome loss': 0.3200989429978465, 'Total loss': 0.3200989429978465}
2022-11-28 02:14:17,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:17,232 INFO:     Epoch: 78
2022-11-28 02:14:17,983 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3797149322926998, 'Total loss': 0.3797149322926998} | train loss {'Reaction outcome loss': 0.3144572970084092, 'Total loss': 0.3144572970084092}
2022-11-28 02:14:17,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:17,983 INFO:     Epoch: 79
2022-11-28 02:14:18,732 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41550507870587433, 'Total loss': 0.41550507870587433} | train loss {'Reaction outcome loss': 0.30787230690970435, 'Total loss': 0.30787230690970435}
2022-11-28 02:14:18,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:18,732 INFO:     Epoch: 80
2022-11-28 02:14:19,479 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4221808412535624, 'Total loss': 0.4221808412535624} | train loss {'Reaction outcome loss': 0.2948944054936108, 'Total loss': 0.2948944054936108}
2022-11-28 02:14:19,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:19,480 INFO:     Epoch: 81
2022-11-28 02:14:20,226 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4107807522470301, 'Total loss': 0.4107807522470301} | train loss {'Reaction outcome loss': 0.30335608299685873, 'Total loss': 0.30335608299685873}
2022-11-28 02:14:20,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:20,226 INFO:     Epoch: 82
2022-11-28 02:14:20,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39949170500040054, 'Total loss': 0.39949170500040054} | train loss {'Reaction outcome loss': 0.30084110086141364, 'Total loss': 0.30084110086141364}
2022-11-28 02:14:20,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:20,978 INFO:     Epoch: 83
2022-11-28 02:14:21,729 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4001765498383479, 'Total loss': 0.4001765498383479} | train loss {'Reaction outcome loss': 0.30118128310451625, 'Total loss': 0.30118128310451625}
2022-11-28 02:14:21,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:21,729 INFO:     Epoch: 84
2022-11-28 02:14:22,481 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45462018793279474, 'Total loss': 0.45462018793279474} | train loss {'Reaction outcome loss': 0.2999520178597707, 'Total loss': 0.2999520178597707}
2022-11-28 02:14:22,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:22,481 INFO:     Epoch: 85
2022-11-28 02:14:23,231 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4349767010320317, 'Total loss': 0.4349767010320317} | train loss {'Reaction outcome loss': 0.3116331944460811, 'Total loss': 0.3116331944460811}
2022-11-28 02:14:23,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:23,231 INFO:     Epoch: 86
2022-11-28 02:14:23,980 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4055955023928122, 'Total loss': 0.4055955023928122} | train loss {'Reaction outcome loss': 0.300374853179643, 'Total loss': 0.300374853179643}
2022-11-28 02:14:23,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:23,981 INFO:     Epoch: 87
2022-11-28 02:14:24,731 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40839760411869397, 'Total loss': 0.40839760411869397} | train loss {'Reaction outcome loss': 0.31303463553984345, 'Total loss': 0.31303463553984345}
2022-11-28 02:14:24,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:24,731 INFO:     Epoch: 88
2022-11-28 02:14:25,481 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4050391458652236, 'Total loss': 0.4050391458652236} | train loss {'Reaction outcome loss': 0.2929963591972343, 'Total loss': 0.2929963591972343}
2022-11-28 02:14:25,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:25,481 INFO:     Epoch: 89
2022-11-28 02:14:26,229 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4040098735554652, 'Total loss': 0.4040098735554652} | train loss {'Reaction outcome loss': 0.31454114732049737, 'Total loss': 0.31454114732049737}
2022-11-28 02:14:26,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:26,231 INFO:     Epoch: 90
2022-11-28 02:14:26,981 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39324498447504913, 'Total loss': 0.39324498447504913} | train loss {'Reaction outcome loss': 0.30150341769655165, 'Total loss': 0.30150341769655165}
2022-11-28 02:14:26,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:26,981 INFO:     Epoch: 91
2022-11-28 02:14:27,733 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41495954109863803, 'Total loss': 0.41495954109863803} | train loss {'Reaction outcome loss': 0.2968624340076196, 'Total loss': 0.2968624340076196}
2022-11-28 02:14:27,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:27,733 INFO:     Epoch: 92
2022-11-28 02:14:28,481 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43601916798136453, 'Total loss': 0.43601916798136453} | train loss {'Reaction outcome loss': 0.29364608569063155, 'Total loss': 0.29364608569063155}
2022-11-28 02:14:28,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:28,481 INFO:     Epoch: 93
2022-11-28 02:14:29,230 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40640082718296483, 'Total loss': 0.40640082718296483} | train loss {'Reaction outcome loss': 0.30193861035534314, 'Total loss': 0.30193861035534314}
2022-11-28 02:14:29,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:29,231 INFO:     Epoch: 94
2022-11-28 02:14:29,977 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4076244785365733, 'Total loss': 0.4076244785365733} | train loss {'Reaction outcome loss': 0.301083071809536, 'Total loss': 0.301083071809536}
2022-11-28 02:14:29,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:29,977 INFO:     Epoch: 95
2022-11-28 02:14:30,731 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4211641004817052, 'Total loss': 0.4211641004817052} | train loss {'Reaction outcome loss': 0.3037586430745644, 'Total loss': 0.3037586430745644}
2022-11-28 02:14:30,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:30,731 INFO:     Epoch: 96
2022-11-28 02:14:31,482 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38438485681333323, 'Total loss': 0.38438485681333323} | train loss {'Reaction outcome loss': 0.2975606894505169, 'Total loss': 0.2975606894505169}
2022-11-28 02:14:31,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:31,482 INFO:     Epoch: 97
2022-11-28 02:14:32,228 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4086366002871232, 'Total loss': 0.4086366002871232} | train loss {'Reaction outcome loss': 0.3165351002805146, 'Total loss': 0.3165351002805146}
2022-11-28 02:14:32,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:32,229 INFO:     Epoch: 98
2022-11-28 02:14:32,978 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4070119928907264, 'Total loss': 0.4070119928907264} | train loss {'Reaction outcome loss': 0.3248987562863933, 'Total loss': 0.3248987562863933}
2022-11-28 02:14:32,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:32,978 INFO:     Epoch: 99
2022-11-28 02:14:33,723 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41505302116274834, 'Total loss': 0.41505302116274834} | train loss {'Reaction outcome loss': 0.30754745297646713, 'Total loss': 0.30754745297646713}
2022-11-28 02:14:33,723 INFO:     Best model found after epoch 50 of 100.
2022-11-28 02:14:33,723 INFO:   Done with stage: TRAINING
2022-11-28 02:14:33,723 INFO:   Starting stage: EVALUATION
2022-11-28 02:14:33,848 INFO:   Done with stage: EVALUATION
2022-11-28 02:14:33,848 INFO:   Leaving out SEQ value Fold_6
2022-11-28 02:14:33,861 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:14:33,861 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:14:34,504 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:14:34,504 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:14:34,574 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:14:34,574 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:14:34,574 INFO:     No hyperparam tuning for this model
2022-11-28 02:14:34,574 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:14:34,574 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:14:34,575 INFO:     None feature selector for col prot
2022-11-28 02:14:34,575 INFO:     None feature selector for col prot
2022-11-28 02:14:34,575 INFO:     None feature selector for col prot
2022-11-28 02:14:34,576 INFO:     None feature selector for col chem
2022-11-28 02:14:34,576 INFO:     None feature selector for col chem
2022-11-28 02:14:34,576 INFO:     None feature selector for col chem
2022-11-28 02:14:34,576 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:14:34,576 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:14:34,578 INFO:     Number of params in model 169741
2022-11-28 02:14:34,581 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:14:34,581 INFO:   Starting stage: TRAINING
2022-11-28 02:14:34,635 INFO:     Val loss before train {'Reaction outcome loss': 0.9835928190838207, 'Total loss': 0.9835928190838207}
2022-11-28 02:14:34,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:34,635 INFO:     Epoch: 0
2022-11-28 02:14:35,392 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5384712439369072, 'Total loss': 0.5384712439369072} | train loss {'Reaction outcome loss': 0.6270545203118555, 'Total loss': 0.6270545203118555}
2022-11-28 02:14:35,392 INFO:     Found new best model at epoch 0
2022-11-28 02:14:35,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:35,393 INFO:     Epoch: 1
2022-11-28 02:14:36,146 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5021358484571631, 'Total loss': 0.5021358484571631} | train loss {'Reaction outcome loss': 0.49928774288104427, 'Total loss': 0.49928774288104427}
2022-11-28 02:14:36,146 INFO:     Found new best model at epoch 1
2022-11-28 02:14:36,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:36,147 INFO:     Epoch: 2
2022-11-28 02:14:36,897 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49963002414865926, 'Total loss': 0.49963002414865926} | train loss {'Reaction outcome loss': 0.4654089593358578, 'Total loss': 0.4654089593358578}
2022-11-28 02:14:36,897 INFO:     Found new best model at epoch 2
2022-11-28 02:14:36,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:36,898 INFO:     Epoch: 3
2022-11-28 02:14:37,651 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4894234798848629, 'Total loss': 0.4894234798848629} | train loss {'Reaction outcome loss': 0.4428522836176618, 'Total loss': 0.4428522836176618}
2022-11-28 02:14:37,651 INFO:     Found new best model at epoch 3
2022-11-28 02:14:37,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:37,652 INFO:     Epoch: 4
2022-11-28 02:14:38,407 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4789696850559928, 'Total loss': 0.4789696850559928} | train loss {'Reaction outcome loss': 0.4246390045530373, 'Total loss': 0.4246390045530373}
2022-11-28 02:14:38,407 INFO:     Found new best model at epoch 4
2022-11-28 02:14:38,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:38,408 INFO:     Epoch: 5
2022-11-28 02:14:39,160 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47858205708590423, 'Total loss': 0.47858205708590423} | train loss {'Reaction outcome loss': 0.41964569826039577, 'Total loss': 0.41964569826039577}
2022-11-28 02:14:39,160 INFO:     Found new best model at epoch 5
2022-11-28 02:14:39,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:39,161 INFO:     Epoch: 6
2022-11-28 02:14:39,911 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49935823949900543, 'Total loss': 0.49935823949900543} | train loss {'Reaction outcome loss': 0.41397957023113, 'Total loss': 0.41397957023113}
2022-11-28 02:14:39,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:39,911 INFO:     Epoch: 7
2022-11-28 02:14:40,664 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48898953131654044, 'Total loss': 0.48898953131654044} | train loss {'Reaction outcome loss': 0.4012785020975336, 'Total loss': 0.4012785020975336}
2022-11-28 02:14:40,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:40,664 INFO:     Epoch: 8
2022-11-28 02:14:41,419 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4388318918645382, 'Total loss': 0.4388318918645382} | train loss {'Reaction outcome loss': 0.3855591335844609, 'Total loss': 0.3855591335844609}
2022-11-28 02:14:41,419 INFO:     Found new best model at epoch 8
2022-11-28 02:14:41,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:41,420 INFO:     Epoch: 9
2022-11-28 02:14:42,184 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49352340027689934, 'Total loss': 0.49352340027689934} | train loss {'Reaction outcome loss': 0.37944577219745806, 'Total loss': 0.37944577219745806}
2022-11-28 02:14:42,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:42,185 INFO:     Epoch: 10
2022-11-28 02:14:42,944 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4553434344177896, 'Total loss': 0.4553434344177896} | train loss {'Reaction outcome loss': 0.3799651938100015, 'Total loss': 0.3799651938100015}
2022-11-28 02:14:42,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:42,944 INFO:     Epoch: 11
2022-11-28 02:14:43,704 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46901642497290263, 'Total loss': 0.46901642497290263} | train loss {'Reaction outcome loss': 0.37790810322809604, 'Total loss': 0.37790810322809604}
2022-11-28 02:14:43,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:43,704 INFO:     Epoch: 12
2022-11-28 02:14:44,464 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4510955759747462, 'Total loss': 0.4510955759747462} | train loss {'Reaction outcome loss': 0.3585697705857456, 'Total loss': 0.3585697705857456}
2022-11-28 02:14:44,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:44,465 INFO:     Epoch: 13
2022-11-28 02:14:45,221 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4662648005919023, 'Total loss': 0.4662648005919023} | train loss {'Reaction outcome loss': 0.36961935334388285, 'Total loss': 0.36961935334388285}
2022-11-28 02:14:45,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:45,221 INFO:     Epoch: 14
2022-11-28 02:14:45,978 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44001980837095866, 'Total loss': 0.44001980837095866} | train loss {'Reaction outcome loss': 0.36173916352732527, 'Total loss': 0.36173916352732527}
2022-11-28 02:14:45,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:45,978 INFO:     Epoch: 15
2022-11-28 02:14:46,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49725194715640764, 'Total loss': 0.49725194715640764} | train loss {'Reaction outcome loss': 0.3585711078598134, 'Total loss': 0.3585711078598134}
2022-11-28 02:14:46,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:46,746 INFO:     Epoch: 16
2022-11-28 02:14:47,496 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44640131430192426, 'Total loss': 0.44640131430192426} | train loss {'Reaction outcome loss': 0.35840975532248137, 'Total loss': 0.35840975532248137}
2022-11-28 02:14:47,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:47,497 INFO:     Epoch: 17
2022-11-28 02:14:48,248 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.445233668116006, 'Total loss': 0.445233668116006} | train loss {'Reaction outcome loss': 0.34460858982657233, 'Total loss': 0.34460858982657233}
2022-11-28 02:14:48,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:48,248 INFO:     Epoch: 18
2022-11-28 02:14:49,000 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4342265349220146, 'Total loss': 0.4342265349220146} | train loss {'Reaction outcome loss': 0.352721122604224, 'Total loss': 0.352721122604224}
2022-11-28 02:14:49,000 INFO:     Found new best model at epoch 18
2022-11-28 02:14:49,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:49,001 INFO:     Epoch: 19
2022-11-28 02:14:49,755 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43902367827567185, 'Total loss': 0.43902367827567185} | train loss {'Reaction outcome loss': 0.3494547815212319, 'Total loss': 0.3494547815212319}
2022-11-28 02:14:49,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:49,756 INFO:     Epoch: 20
2022-11-28 02:14:50,510 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45843095298517833, 'Total loss': 0.45843095298517833} | train loss {'Reaction outcome loss': 0.3416416491231611, 'Total loss': 0.3416416491231611}
2022-11-28 02:14:50,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:50,511 INFO:     Epoch: 21
2022-11-28 02:14:51,261 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4577519002963196, 'Total loss': 0.4577519002963196} | train loss {'Reaction outcome loss': 0.3448583063999972, 'Total loss': 0.3448583063999972}
2022-11-28 02:14:51,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:51,261 INFO:     Epoch: 22
2022-11-28 02:14:52,013 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4502227093008431, 'Total loss': 0.4502227093008431} | train loss {'Reaction outcome loss': 0.34017347760738864, 'Total loss': 0.34017347760738864}
2022-11-28 02:14:52,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:52,013 INFO:     Epoch: 23
2022-11-28 02:14:52,764 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4430344401096756, 'Total loss': 0.4430344401096756} | train loss {'Reaction outcome loss': 0.3442896482865176, 'Total loss': 0.3442896482865176}
2022-11-28 02:14:52,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:52,765 INFO:     Epoch: 24
2022-11-28 02:14:53,515 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4201328395442529, 'Total loss': 0.4201328395442529} | train loss {'Reaction outcome loss': 0.33856492354384354, 'Total loss': 0.33856492354384354}
2022-11-28 02:14:53,515 INFO:     Found new best model at epoch 24
2022-11-28 02:14:53,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:53,516 INFO:     Epoch: 25
2022-11-28 02:14:54,269 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4290756471455097, 'Total loss': 0.4290756471455097} | train loss {'Reaction outcome loss': 0.33204182986951164, 'Total loss': 0.33204182986951164}
2022-11-28 02:14:54,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:54,269 INFO:     Epoch: 26
2022-11-28 02:14:55,021 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46436013145880267, 'Total loss': 0.46436013145880267} | train loss {'Reaction outcome loss': 0.3369095488301208, 'Total loss': 0.3369095488301208}
2022-11-28 02:14:55,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:55,021 INFO:     Epoch: 27
2022-11-28 02:14:55,776 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4295482872561975, 'Total loss': 0.4295482872561975} | train loss {'Reaction outcome loss': 0.344193157679852, 'Total loss': 0.344193157679852}
2022-11-28 02:14:55,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:55,776 INFO:     Epoch: 28
2022-11-28 02:14:56,529 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4254447633231228, 'Total loss': 0.4254447633231228} | train loss {'Reaction outcome loss': 0.3277644121478642, 'Total loss': 0.3277644121478642}
2022-11-28 02:14:56,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:56,529 INFO:     Epoch: 29
2022-11-28 02:14:57,285 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43677472932772204, 'Total loss': 0.43677472932772204} | train loss {'Reaction outcome loss': 0.33156990842713463, 'Total loss': 0.33156990842713463}
2022-11-28 02:14:57,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:57,287 INFO:     Epoch: 30
2022-11-28 02:14:58,039 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42361636222763493, 'Total loss': 0.42361636222763493} | train loss {'Reaction outcome loss': 0.33174264476063753, 'Total loss': 0.33174264476063753}
2022-11-28 02:14:58,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:58,040 INFO:     Epoch: 31
2022-11-28 02:14:58,796 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46584901823238895, 'Total loss': 0.46584901823238895} | train loss {'Reaction outcome loss': 0.3335782650918249, 'Total loss': 0.3335782650918249}
2022-11-28 02:14:58,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:58,797 INFO:     Epoch: 32
2022-11-28 02:14:59,552 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42592690377072856, 'Total loss': 0.42592690377072856} | train loss {'Reaction outcome loss': 0.3365228476844007, 'Total loss': 0.3365228476844007}
2022-11-28 02:14:59,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:14:59,552 INFO:     Epoch: 33
2022-11-28 02:15:00,302 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4293948273089799, 'Total loss': 0.4293948273089799} | train loss {'Reaction outcome loss': 0.3340060968072184, 'Total loss': 0.3340060968072184}
2022-11-28 02:15:00,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:00,302 INFO:     Epoch: 34
2022-11-28 02:15:01,053 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4361865618689494, 'Total loss': 0.4361865618689494} | train loss {'Reaction outcome loss': 0.3255111697700716, 'Total loss': 0.3255111697700716}
2022-11-28 02:15:01,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:01,053 INFO:     Epoch: 35
2022-11-28 02:15:01,806 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4238161312585527, 'Total loss': 0.4238161312585527} | train loss {'Reaction outcome loss': 0.33958367199727124, 'Total loss': 0.33958367199727124}
2022-11-28 02:15:01,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:01,806 INFO:     Epoch: 36
2022-11-28 02:15:02,558 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44637421654029324, 'Total loss': 0.44637421654029324} | train loss {'Reaction outcome loss': 0.3287271815502355, 'Total loss': 0.3287271815502355}
2022-11-28 02:15:02,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:02,558 INFO:     Epoch: 37
2022-11-28 02:15:03,310 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4598336883566596, 'Total loss': 0.4598336883566596} | train loss {'Reaction outcome loss': 0.32681179091694856, 'Total loss': 0.32681179091694856}
2022-11-28 02:15:03,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:03,311 INFO:     Epoch: 38
2022-11-28 02:15:04,062 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45920443297787145, 'Total loss': 0.45920443297787145} | train loss {'Reaction outcome loss': 0.32514019634935165, 'Total loss': 0.32514019634935165}
2022-11-28 02:15:04,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:04,062 INFO:     Epoch: 39
2022-11-28 02:15:04,816 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4377519522200931, 'Total loss': 0.4377519522200931} | train loss {'Reaction outcome loss': 0.32544479732431714, 'Total loss': 0.32544479732431714}
2022-11-28 02:15:04,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:04,817 INFO:     Epoch: 40
2022-11-28 02:15:05,572 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45172233337705786, 'Total loss': 0.45172233337705786} | train loss {'Reaction outcome loss': 0.33253797750559544, 'Total loss': 0.33253797750559544}
2022-11-28 02:15:05,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:05,572 INFO:     Epoch: 41
2022-11-28 02:15:06,330 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4550951434807344, 'Total loss': 0.4550951434807344} | train loss {'Reaction outcome loss': 0.32721900044670027, 'Total loss': 0.32721900044670027}
2022-11-28 02:15:06,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:06,330 INFO:     Epoch: 42
2022-11-28 02:15:07,082 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.438315001739697, 'Total loss': 0.438315001739697} | train loss {'Reaction outcome loss': 0.3273369322621053, 'Total loss': 0.3273369322621053}
2022-11-28 02:15:07,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:07,083 INFO:     Epoch: 43
2022-11-28 02:15:07,835 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43941638754172757, 'Total loss': 0.43941638754172757} | train loss {'Reaction outcome loss': 0.3215315981257346, 'Total loss': 0.3215315981257346}
2022-11-28 02:15:07,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:07,836 INFO:     Epoch: 44
2022-11-28 02:15:08,588 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46084546230056067, 'Total loss': 0.46084546230056067} | train loss {'Reaction outcome loss': 0.3294286066065392, 'Total loss': 0.3294286066065392}
2022-11-28 02:15:08,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:08,588 INFO:     Epoch: 45
2022-11-28 02:15:09,339 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4485123408111659, 'Total loss': 0.4485123408111659} | train loss {'Reaction outcome loss': 0.3290210508951737, 'Total loss': 0.3290210508951737}
2022-11-28 02:15:09,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:09,339 INFO:     Epoch: 46
2022-11-28 02:15:10,096 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4568425230681896, 'Total loss': 0.4568425230681896} | train loss {'Reaction outcome loss': 0.3293986727273272, 'Total loss': 0.3293986727273272}
2022-11-28 02:15:10,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:10,096 INFO:     Epoch: 47
2022-11-28 02:15:10,853 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46084998886693607, 'Total loss': 0.46084998886693607} | train loss {'Reaction outcome loss': 0.3153888634105603, 'Total loss': 0.3153888634105603}
2022-11-28 02:15:10,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:10,853 INFO:     Epoch: 48
2022-11-28 02:15:11,607 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43929575265131215, 'Total loss': 0.43929575265131215} | train loss {'Reaction outcome loss': 0.3193250768066895, 'Total loss': 0.3193250768066895}
2022-11-28 02:15:11,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:11,608 INFO:     Epoch: 49
2022-11-28 02:15:12,360 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4174442223527215, 'Total loss': 0.4174442223527215} | train loss {'Reaction outcome loss': 0.31034346829138454, 'Total loss': 0.31034346829138454}
2022-11-28 02:15:12,361 INFO:     Found new best model at epoch 49
2022-11-28 02:15:12,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:12,361 INFO:     Epoch: 50
2022-11-28 02:15:13,117 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43297191844745114, 'Total loss': 0.43297191844745114} | train loss {'Reaction outcome loss': 0.3202121076925147, 'Total loss': 0.3202121076925147}
2022-11-28 02:15:13,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:13,117 INFO:     Epoch: 51
2022-11-28 02:15:13,874 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4817404269494794, 'Total loss': 0.4817404269494794} | train loss {'Reaction outcome loss': 0.3201324626082374, 'Total loss': 0.3201324626082374}
2022-11-28 02:15:13,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:13,874 INFO:     Epoch: 52
2022-11-28 02:15:14,630 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4157901592552662, 'Total loss': 0.4157901592552662} | train loss {'Reaction outcome loss': 0.31801429799487513, 'Total loss': 0.31801429799487513}
2022-11-28 02:15:14,630 INFO:     Found new best model at epoch 52
2022-11-28 02:15:14,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:14,631 INFO:     Epoch: 53
2022-11-28 02:15:15,386 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42222590338100086, 'Total loss': 0.42222590338100086} | train loss {'Reaction outcome loss': 0.3141868693393565, 'Total loss': 0.3141868693393565}
2022-11-28 02:15:15,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:15,387 INFO:     Epoch: 54
2022-11-28 02:15:16,141 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42081398923288693, 'Total loss': 0.42081398923288693} | train loss {'Reaction outcome loss': 0.3239364524281794, 'Total loss': 0.3239364524281794}
2022-11-28 02:15:16,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:16,141 INFO:     Epoch: 55
2022-11-28 02:15:16,897 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4526818167756904, 'Total loss': 0.4526818167756904} | train loss {'Reaction outcome loss': 0.3192978975693545, 'Total loss': 0.3192978975693545}
2022-11-28 02:15:16,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:16,897 INFO:     Epoch: 56
2022-11-28 02:15:17,649 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46773690510202537, 'Total loss': 0.46773690510202537} | train loss {'Reaction outcome loss': 0.31539871702871974, 'Total loss': 0.31539871702871974}
2022-11-28 02:15:17,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:17,649 INFO:     Epoch: 57
2022-11-28 02:15:18,404 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43149531937458296, 'Total loss': 0.43149531937458296} | train loss {'Reaction outcome loss': 0.3188069552453535, 'Total loss': 0.3188069552453535}
2022-11-28 02:15:18,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:18,404 INFO:     Epoch: 58
2022-11-28 02:15:19,153 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4235416484827345, 'Total loss': 0.4235416484827345} | train loss {'Reaction outcome loss': 0.32186427577248505, 'Total loss': 0.32186427577248505}
2022-11-28 02:15:19,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:19,154 INFO:     Epoch: 59
2022-11-28 02:15:19,902 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42257229289547965, 'Total loss': 0.42257229289547965} | train loss {'Reaction outcome loss': 0.3082642631244756, 'Total loss': 0.3082642631244756}
2022-11-28 02:15:19,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:19,903 INFO:     Epoch: 60
2022-11-28 02:15:20,652 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4550397399474274, 'Total loss': 0.4550397399474274} | train loss {'Reaction outcome loss': 0.31423798110336065, 'Total loss': 0.31423798110336065}
2022-11-28 02:15:20,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:20,653 INFO:     Epoch: 61
2022-11-28 02:15:21,401 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4544165161522952, 'Total loss': 0.4544165161522952} | train loss {'Reaction outcome loss': 0.3224705276229689, 'Total loss': 0.3224705276229689}
2022-11-28 02:15:21,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:21,401 INFO:     Epoch: 62
2022-11-28 02:15:22,151 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4451859254728664, 'Total loss': 0.4451859254728664} | train loss {'Reaction outcome loss': 0.3182365977836232, 'Total loss': 0.3182365977836232}
2022-11-28 02:15:22,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:22,151 INFO:     Epoch: 63
2022-11-28 02:15:22,902 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4121555032377893, 'Total loss': 0.4121555032377893} | train loss {'Reaction outcome loss': 0.31427569338871586, 'Total loss': 0.31427569338871586}
2022-11-28 02:15:22,902 INFO:     Found new best model at epoch 63
2022-11-28 02:15:22,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:22,903 INFO:     Epoch: 64
2022-11-28 02:15:23,658 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4109058173542673, 'Total loss': 0.4109058173542673} | train loss {'Reaction outcome loss': 0.3094817505728814, 'Total loss': 0.3094817505728814}
2022-11-28 02:15:23,658 INFO:     Found new best model at epoch 64
2022-11-28 02:15:23,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:23,659 INFO:     Epoch: 65
2022-11-28 02:15:24,409 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.434135091914372, 'Total loss': 0.434135091914372} | train loss {'Reaction outcome loss': 0.31355232354854384, 'Total loss': 0.31355232354854384}
2022-11-28 02:15:24,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:24,409 INFO:     Epoch: 66
2022-11-28 02:15:25,162 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45733041350137105, 'Total loss': 0.45733041350137105} | train loss {'Reaction outcome loss': 0.3114636903628707, 'Total loss': 0.3114636903628707}
2022-11-28 02:15:25,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:25,162 INFO:     Epoch: 67
2022-11-28 02:15:25,918 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4483621845191175, 'Total loss': 0.4483621845191175} | train loss {'Reaction outcome loss': 0.3085154045913969, 'Total loss': 0.3085154045913969}
2022-11-28 02:15:25,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:25,918 INFO:     Epoch: 68
2022-11-28 02:15:26,673 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4296231269836426, 'Total loss': 0.4296231269836426} | train loss {'Reaction outcome loss': 0.31138108858478164, 'Total loss': 0.31138108858478164}
2022-11-28 02:15:26,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:26,673 INFO:     Epoch: 69
2022-11-28 02:15:27,427 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43621327888897876, 'Total loss': 0.43621327888897876} | train loss {'Reaction outcome loss': 0.31143461543345646, 'Total loss': 0.31143461543345646}
2022-11-28 02:15:27,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:27,427 INFO:     Epoch: 70
2022-11-28 02:15:28,181 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4281429265710441, 'Total loss': 0.4281429265710441} | train loss {'Reaction outcome loss': 0.31133746979908355, 'Total loss': 0.31133746979908355}
2022-11-28 02:15:28,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:28,182 INFO:     Epoch: 71
2022-11-28 02:15:28,934 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4267098050225865, 'Total loss': 0.4267098050225865} | train loss {'Reaction outcome loss': 0.31961875333781203, 'Total loss': 0.31961875333781203}
2022-11-28 02:15:28,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:28,934 INFO:     Epoch: 72
2022-11-28 02:15:29,691 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42709607122973964, 'Total loss': 0.42709607122973964} | train loss {'Reaction outcome loss': 0.31506694229920545, 'Total loss': 0.31506694229920545}
2022-11-28 02:15:29,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:29,691 INFO:     Epoch: 73
2022-11-28 02:15:30,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44850221564146603, 'Total loss': 0.44850221564146603} | train loss {'Reaction outcome loss': 0.31540359603241086, 'Total loss': 0.31540359603241086}
2022-11-28 02:15:30,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:30,446 INFO:     Epoch: 74
2022-11-28 02:15:31,198 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4270003793591803, 'Total loss': 0.4270003793591803} | train loss {'Reaction outcome loss': 0.31869724050404563, 'Total loss': 0.31869724050404563}
2022-11-28 02:15:31,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:31,198 INFO:     Epoch: 75
2022-11-28 02:15:31,952 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44427263702858577, 'Total loss': 0.44427263702858577} | train loss {'Reaction outcome loss': 0.31547947549411365, 'Total loss': 0.31547947549411365}
2022-11-28 02:15:31,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:31,953 INFO:     Epoch: 76
2022-11-28 02:15:32,704 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4636644527993419, 'Total loss': 0.4636644527993419} | train loss {'Reaction outcome loss': 0.3221243128646165, 'Total loss': 0.3221243128646165}
2022-11-28 02:15:32,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:32,705 INFO:     Epoch: 77
2022-11-28 02:15:33,457 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45379875803535635, 'Total loss': 0.45379875803535635} | train loss {'Reaction outcome loss': 0.3096848050162436, 'Total loss': 0.3096848050162436}
2022-11-28 02:15:33,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:33,457 INFO:     Epoch: 78
2022-11-28 02:15:34,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42921507138420234, 'Total loss': 0.42921507138420234} | train loss {'Reaction outcome loss': 0.32346537338209247, 'Total loss': 0.32346537338209247}
2022-11-28 02:15:34,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:34,212 INFO:     Epoch: 79
2022-11-28 02:15:34,970 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44523580541664903, 'Total loss': 0.44523580541664903} | train loss {'Reaction outcome loss': 0.31508830472105936, 'Total loss': 0.31508830472105936}
2022-11-28 02:15:34,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:34,970 INFO:     Epoch: 80
2022-11-28 02:15:35,722 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4462592632255771, 'Total loss': 0.4462592632255771} | train loss {'Reaction outcome loss': 0.3107277351101079, 'Total loss': 0.3107277351101079}
2022-11-28 02:15:35,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:35,723 INFO:     Epoch: 81
2022-11-28 02:15:36,475 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44070446254177525, 'Total loss': 0.44070446254177525} | train loss {'Reaction outcome loss': 0.31612435839469394, 'Total loss': 0.31612435839469394}
2022-11-28 02:15:36,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:36,475 INFO:     Epoch: 82
2022-11-28 02:15:37,226 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4498092792928219, 'Total loss': 0.4498092792928219} | train loss {'Reaction outcome loss': 0.328018877895609, 'Total loss': 0.328018877895609}
2022-11-28 02:15:37,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:37,226 INFO:     Epoch: 83
2022-11-28 02:15:37,984 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.455466415733099, 'Total loss': 0.455466415733099} | train loss {'Reaction outcome loss': 0.3185442219518365, 'Total loss': 0.3185442219518365}
2022-11-28 02:15:37,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:37,984 INFO:     Epoch: 84
2022-11-28 02:15:38,736 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45074816488406877, 'Total loss': 0.45074816488406877} | train loss {'Reaction outcome loss': 0.30749138123205594, 'Total loss': 0.30749138123205594}
2022-11-28 02:15:38,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:38,736 INFO:     Epoch: 85
2022-11-28 02:15:39,488 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4661039047959176, 'Total loss': 0.4661039047959176} | train loss {'Reaction outcome loss': 0.3189183275455669, 'Total loss': 0.3189183275455669}
2022-11-28 02:15:39,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:39,489 INFO:     Epoch: 86
2022-11-28 02:15:40,242 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42982547967271373, 'Total loss': 0.42982547967271373} | train loss {'Reaction outcome loss': 0.306443827677398, 'Total loss': 0.306443827677398}
2022-11-28 02:15:40,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:40,242 INFO:     Epoch: 87
2022-11-28 02:15:40,991 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45725798386741767, 'Total loss': 0.45725798386741767} | train loss {'Reaction outcome loss': 0.30802032177246386, 'Total loss': 0.30802032177246386}
2022-11-28 02:15:40,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:40,991 INFO:     Epoch: 88
2022-11-28 02:15:41,744 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4412277645685456, 'Total loss': 0.4412277645685456} | train loss {'Reaction outcome loss': 0.30442175579317393, 'Total loss': 0.30442175579317393}
2022-11-28 02:15:41,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:41,744 INFO:     Epoch: 89
2022-11-28 02:15:42,499 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4200708801773461, 'Total loss': 0.4200708801773461} | train loss {'Reaction outcome loss': 0.310297210160042, 'Total loss': 0.310297210160042}
2022-11-28 02:15:42,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:42,499 INFO:     Epoch: 90
2022-11-28 02:15:43,251 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45076915926553984, 'Total loss': 0.45076915926553984} | train loss {'Reaction outcome loss': 0.31075671654675274, 'Total loss': 0.31075671654675274}
2022-11-28 02:15:43,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:43,251 INFO:     Epoch: 91
2022-11-28 02:15:44,000 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4051764400845224, 'Total loss': 0.4051764400845224} | train loss {'Reaction outcome loss': 0.3128786212614467, 'Total loss': 0.3128786212614467}
2022-11-28 02:15:44,000 INFO:     Found new best model at epoch 91
2022-11-28 02:15:44,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:44,001 INFO:     Epoch: 92
2022-11-28 02:15:44,755 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4366591013967991, 'Total loss': 0.4366591013967991} | train loss {'Reaction outcome loss': 0.3064612056308937, 'Total loss': 0.3064612056308937}
2022-11-28 02:15:44,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:44,755 INFO:     Epoch: 93
2022-11-28 02:15:45,507 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4207757755436681, 'Total loss': 0.4207757755436681} | train loss {'Reaction outcome loss': 0.31113758590072393, 'Total loss': 0.31113758590072393}
2022-11-28 02:15:45,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:45,507 INFO:     Epoch: 94
2022-11-28 02:15:46,259 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43248801542954013, 'Total loss': 0.43248801542954013} | train loss {'Reaction outcome loss': 0.31349295652621695, 'Total loss': 0.31349295652621695}
2022-11-28 02:15:46,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:46,259 INFO:     Epoch: 95
2022-11-28 02:15:47,010 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41065876016562636, 'Total loss': 0.41065876016562636} | train loss {'Reaction outcome loss': 0.3033430385553548, 'Total loss': 0.3033430385553548}
2022-11-28 02:15:47,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:47,011 INFO:     Epoch: 96
2022-11-28 02:15:47,763 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4499878937547857, 'Total loss': 0.4499878937547857} | train loss {'Reaction outcome loss': 0.3089687912274272, 'Total loss': 0.3089687912274272}
2022-11-28 02:15:47,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:47,763 INFO:     Epoch: 97
2022-11-28 02:15:48,520 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4286831512369893, 'Total loss': 0.4286831512369893} | train loss {'Reaction outcome loss': 0.30863215500909474, 'Total loss': 0.30863215500909474}
2022-11-28 02:15:48,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:48,520 INFO:     Epoch: 98
2022-11-28 02:15:49,272 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42657329531555827, 'Total loss': 0.42657329531555827} | train loss {'Reaction outcome loss': 0.30720460099438507, 'Total loss': 0.30720460099438507}
2022-11-28 02:15:49,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:49,273 INFO:     Epoch: 99
2022-11-28 02:15:50,033 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45913651246916165, 'Total loss': 0.45913651246916165} | train loss {'Reaction outcome loss': 0.30097345994304747, 'Total loss': 0.30097345994304747}
2022-11-28 02:15:50,033 INFO:     Best model found after epoch 92 of 100.
2022-11-28 02:15:50,033 INFO:   Done with stage: TRAINING
2022-11-28 02:15:50,033 INFO:   Starting stage: EVALUATION
2022-11-28 02:15:50,152 INFO:   Done with stage: EVALUATION
2022-11-28 02:15:50,153 INFO:   Leaving out SEQ value Fold_7
2022-11-28 02:15:50,165 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:15:50,166 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:15:50,811 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:15:50,812 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:15:50,881 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:15:50,881 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:15:50,881 INFO:     No hyperparam tuning for this model
2022-11-28 02:15:50,881 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:15:50,881 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:15:50,882 INFO:     None feature selector for col prot
2022-11-28 02:15:50,882 INFO:     None feature selector for col prot
2022-11-28 02:15:50,882 INFO:     None feature selector for col prot
2022-11-28 02:15:50,883 INFO:     None feature selector for col chem
2022-11-28 02:15:50,883 INFO:     None feature selector for col chem
2022-11-28 02:15:50,883 INFO:     None feature selector for col chem
2022-11-28 02:15:50,883 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:15:50,883 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:15:50,884 INFO:     Number of params in model 169741
2022-11-28 02:15:50,888 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:15:50,888 INFO:   Starting stage: TRAINING
2022-11-28 02:15:50,942 INFO:     Val loss before train {'Reaction outcome loss': 1.0038877820426768, 'Total loss': 1.0038877820426768}
2022-11-28 02:15:50,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:50,942 INFO:     Epoch: 0
2022-11-28 02:15:51,695 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5478001602671363, 'Total loss': 0.5478001602671363} | train loss {'Reaction outcome loss': 0.6427325256048672, 'Total loss': 0.6427325256048672}
2022-11-28 02:15:51,695 INFO:     Found new best model at epoch 0
2022-11-28 02:15:51,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:51,696 INFO:     Epoch: 1
2022-11-28 02:15:52,447 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.523863557387482, 'Total loss': 0.523863557387482} | train loss {'Reaction outcome loss': 0.49924132780682656, 'Total loss': 0.49924132780682656}
2022-11-28 02:15:52,447 INFO:     Found new best model at epoch 1
2022-11-28 02:15:52,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:52,448 INFO:     Epoch: 2
2022-11-28 02:15:53,199 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48390790955586865, 'Total loss': 0.48390790955586865} | train loss {'Reaction outcome loss': 0.45744877539935613, 'Total loss': 0.45744877539935613}
2022-11-28 02:15:53,200 INFO:     Found new best model at epoch 2
2022-11-28 02:15:53,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:53,201 INFO:     Epoch: 3
2022-11-28 02:15:53,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47829222746870736, 'Total loss': 0.47829222746870736} | train loss {'Reaction outcome loss': 0.4360331751165851, 'Total loss': 0.4360331751165851}
2022-11-28 02:15:53,952 INFO:     Found new best model at epoch 3
2022-11-28 02:15:53,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:53,953 INFO:     Epoch: 4
2022-11-28 02:15:54,704 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.507670137015256, 'Total loss': 0.507670137015256} | train loss {'Reaction outcome loss': 0.427237011702551, 'Total loss': 0.427237011702551}
2022-11-28 02:15:54,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:54,704 INFO:     Epoch: 5
2022-11-28 02:15:55,460 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44921078566800465, 'Total loss': 0.44921078566800465} | train loss {'Reaction outcome loss': 0.40873673080556816, 'Total loss': 0.40873673080556816}
2022-11-28 02:15:55,460 INFO:     Found new best model at epoch 5
2022-11-28 02:15:55,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:55,461 INFO:     Epoch: 6
2022-11-28 02:15:56,214 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4451539106667042, 'Total loss': 0.4451539106667042} | train loss {'Reaction outcome loss': 0.40812233165507356, 'Total loss': 0.40812233165507356}
2022-11-28 02:15:56,214 INFO:     Found new best model at epoch 6
2022-11-28 02:15:56,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:56,215 INFO:     Epoch: 7
2022-11-28 02:15:56,968 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4340445930984887, 'Total loss': 0.4340445930984887} | train loss {'Reaction outcome loss': 0.3962480331200265, 'Total loss': 0.3962480331200265}
2022-11-28 02:15:56,968 INFO:     Found new best model at epoch 7
2022-11-28 02:15:56,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:56,969 INFO:     Epoch: 8
2022-11-28 02:15:57,720 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4265950223938985, 'Total loss': 0.4265950223938985} | train loss {'Reaction outcome loss': 0.39381943802319225, 'Total loss': 0.39381943802319225}
2022-11-28 02:15:57,721 INFO:     Found new best model at epoch 8
2022-11-28 02:15:57,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:57,721 INFO:     Epoch: 9
2022-11-28 02:15:58,471 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4631806622174653, 'Total loss': 0.4631806622174653} | train loss {'Reaction outcome loss': 0.3832869119040908, 'Total loss': 0.3832869119040908}
2022-11-28 02:15:58,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:58,471 INFO:     Epoch: 10
2022-11-28 02:15:59,222 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44500352679328486, 'Total loss': 0.44500352679328486} | train loss {'Reaction outcome loss': 0.3820840485934769, 'Total loss': 0.3820840485934769}
2022-11-28 02:15:59,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:59,223 INFO:     Epoch: 11
2022-11-28 02:15:59,977 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.430742194537412, 'Total loss': 0.430742194537412} | train loss {'Reaction outcome loss': 0.36861936603823015, 'Total loss': 0.36861936603823015}
2022-11-28 02:15:59,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:15:59,977 INFO:     Epoch: 12
2022-11-28 02:16:00,728 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42379293218255043, 'Total loss': 0.42379293218255043} | train loss {'Reaction outcome loss': 0.3694344609975815, 'Total loss': 0.3694344609975815}
2022-11-28 02:16:00,728 INFO:     Found new best model at epoch 12
2022-11-28 02:16:00,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:00,729 INFO:     Epoch: 13
2022-11-28 02:16:01,485 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4030885733664036, 'Total loss': 0.4030885733664036} | train loss {'Reaction outcome loss': 0.3598223134815212, 'Total loss': 0.3598223134815212}
2022-11-28 02:16:01,486 INFO:     Found new best model at epoch 13
2022-11-28 02:16:01,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:01,487 INFO:     Epoch: 14
2022-11-28 02:16:02,242 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3995142917741429, 'Total loss': 0.3995142917741429} | train loss {'Reaction outcome loss': 0.35962949353720874, 'Total loss': 0.35962949353720874}
2022-11-28 02:16:02,242 INFO:     Found new best model at epoch 14
2022-11-28 02:16:02,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:02,243 INFO:     Epoch: 15
2022-11-28 02:16:02,994 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4058409170670943, 'Total loss': 0.4058409170670943} | train loss {'Reaction outcome loss': 0.3613696159013817, 'Total loss': 0.3613696159013817}
2022-11-28 02:16:02,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:02,994 INFO:     Epoch: 16
2022-11-28 02:16:03,745 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4276097792793404, 'Total loss': 0.4276097792793404} | train loss {'Reaction outcome loss': 0.36102584336373594, 'Total loss': 0.36102584336373594}
2022-11-28 02:16:03,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:03,746 INFO:     Epoch: 17
2022-11-28 02:16:04,495 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4155243357474154, 'Total loss': 0.4155243357474154} | train loss {'Reaction outcome loss': 0.3630982581826468, 'Total loss': 0.3630982581826468}
2022-11-28 02:16:04,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:04,495 INFO:     Epoch: 18
2022-11-28 02:16:05,247 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4458067373118617, 'Total loss': 0.4458067373118617} | train loss {'Reaction outcome loss': 0.349090592875596, 'Total loss': 0.349090592875596}
2022-11-28 02:16:05,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:05,248 INFO:     Epoch: 19
2022-11-28 02:16:05,998 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44960973344065924, 'Total loss': 0.44960973344065924} | train loss {'Reaction outcome loss': 0.3439983890782441, 'Total loss': 0.3439983890782441}
2022-11-28 02:16:05,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:05,999 INFO:     Epoch: 20
2022-11-28 02:16:06,751 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4135533950545571, 'Total loss': 0.4135533950545571} | train loss {'Reaction outcome loss': 0.34836431857078304, 'Total loss': 0.34836431857078304}
2022-11-28 02:16:06,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:06,751 INFO:     Epoch: 21
2022-11-28 02:16:07,502 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.434206583621827, 'Total loss': 0.434206583621827} | train loss {'Reaction outcome loss': 0.33631243403520317, 'Total loss': 0.33631243403520317}
2022-11-28 02:16:07,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:07,502 INFO:     Epoch: 22
2022-11-28 02:16:08,252 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4478804905983535, 'Total loss': 0.4478804905983535} | train loss {'Reaction outcome loss': 0.3483347665338266, 'Total loss': 0.3483347665338266}
2022-11-28 02:16:08,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:08,252 INFO:     Epoch: 23
2022-11-28 02:16:09,004 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41557651859792794, 'Total loss': 0.41557651859792794} | train loss {'Reaction outcome loss': 0.343830538432925, 'Total loss': 0.343830538432925}
2022-11-28 02:16:09,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:09,004 INFO:     Epoch: 24
2022-11-28 02:16:09,757 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42703552679582074, 'Total loss': 0.42703552679582074} | train loss {'Reaction outcome loss': 0.3456033535842453, 'Total loss': 0.3456033535842453}
2022-11-28 02:16:09,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:09,758 INFO:     Epoch: 25
2022-11-28 02:16:10,511 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40406539833003824, 'Total loss': 0.40406539833003824} | train loss {'Reaction outcome loss': 0.3431550501695564, 'Total loss': 0.3431550501695564}
2022-11-28 02:16:10,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:10,511 INFO:     Epoch: 26
2022-11-28 02:16:11,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4254997464066202, 'Total loss': 0.4254997464066202} | train loss {'Reaction outcome loss': 0.3412210129561924, 'Total loss': 0.3412210129561924}
2022-11-28 02:16:11,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:11,269 INFO:     Epoch: 27
2022-11-28 02:16:12,022 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4191242486915805, 'Total loss': 0.4191242486915805} | train loss {'Reaction outcome loss': 0.3406025381578553, 'Total loss': 0.3406025381578553}
2022-11-28 02:16:12,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:12,022 INFO:     Epoch: 28
2022-11-28 02:16:12,773 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42154560271989217, 'Total loss': 0.42154560271989217} | train loss {'Reaction outcome loss': 0.3314630220373792, 'Total loss': 0.3314630220373792}
2022-11-28 02:16:12,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:12,773 INFO:     Epoch: 29
2022-11-28 02:16:13,531 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42992240766232664, 'Total loss': 0.42992240766232664} | train loss {'Reaction outcome loss': 0.32751011343732955, 'Total loss': 0.32751011343732955}
2022-11-28 02:16:13,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:13,531 INFO:     Epoch: 30
2022-11-28 02:16:14,287 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4265283410522071, 'Total loss': 0.4265283410522071} | train loss {'Reaction outcome loss': 0.33575394515308643, 'Total loss': 0.33575394515308643}
2022-11-28 02:16:14,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:14,287 INFO:     Epoch: 31
2022-11-28 02:16:15,042 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41968529603698035, 'Total loss': 0.41968529603698035} | train loss {'Reaction outcome loss': 0.3319196147663939, 'Total loss': 0.3319196147663939}
2022-11-28 02:16:15,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:15,043 INFO:     Epoch: 32
2022-11-28 02:16:15,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4171845550564202, 'Total loss': 0.4171845550564202} | train loss {'Reaction outcome loss': 0.3303383123129606, 'Total loss': 0.3303383123129606}
2022-11-28 02:16:15,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:15,795 INFO:     Epoch: 33
2022-11-28 02:16:16,548 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4681520407850092, 'Total loss': 0.4681520407850092} | train loss {'Reaction outcome loss': 0.3260366779962374, 'Total loss': 0.3260366779962374}
2022-11-28 02:16:16,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:16,548 INFO:     Epoch: 34
2022-11-28 02:16:17,303 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42735987986353313, 'Total loss': 0.42735987986353313} | train loss {'Reaction outcome loss': 0.3271341438315088, 'Total loss': 0.3271341438315088}
2022-11-28 02:16:17,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:17,304 INFO:     Epoch: 35
2022-11-28 02:16:18,059 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4090409844436429, 'Total loss': 0.4090409844436429} | train loss {'Reaction outcome loss': 0.31885010983434414, 'Total loss': 0.31885010983434414}
2022-11-28 02:16:18,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:18,059 INFO:     Epoch: 36
2022-11-28 02:16:18,814 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4295988076112487, 'Total loss': 0.4295988076112487} | train loss {'Reaction outcome loss': 0.3293728053029026, 'Total loss': 0.3293728053029026}
2022-11-28 02:16:18,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:18,815 INFO:     Epoch: 37
2022-11-28 02:16:19,567 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42888218503106723, 'Total loss': 0.42888218503106723} | train loss {'Reaction outcome loss': 0.32709046689072446, 'Total loss': 0.32709046689072446}
2022-11-28 02:16:19,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:19,568 INFO:     Epoch: 38
2022-11-28 02:16:20,321 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42227136106653645, 'Total loss': 0.42227136106653645} | train loss {'Reaction outcome loss': 0.3220390018316046, 'Total loss': 0.3220390018316046}
2022-11-28 02:16:20,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:20,321 INFO:     Epoch: 39
2022-11-28 02:16:21,074 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44047197462482884, 'Total loss': 0.44047197462482884} | train loss {'Reaction outcome loss': 0.31581248640413245, 'Total loss': 0.31581248640413245}
2022-11-28 02:16:21,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:21,075 INFO:     Epoch: 40
2022-11-28 02:16:21,828 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4109854285012592, 'Total loss': 0.4109854285012592} | train loss {'Reaction outcome loss': 0.3234770005388606, 'Total loss': 0.3234770005388606}
2022-11-28 02:16:21,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:21,828 INFO:     Epoch: 41
2022-11-28 02:16:22,580 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4218387058512731, 'Total loss': 0.4218387058512731} | train loss {'Reaction outcome loss': 0.3259042444068097, 'Total loss': 0.3259042444068097}
2022-11-28 02:16:22,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:22,580 INFO:     Epoch: 42
2022-11-28 02:16:23,334 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4194246039471843, 'Total loss': 0.4194246039471843} | train loss {'Reaction outcome loss': 0.31779939870560364, 'Total loss': 0.31779939870560364}
2022-11-28 02:16:23,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:23,334 INFO:     Epoch: 43
2022-11-28 02:16:24,086 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4222872518002987, 'Total loss': 0.4222872518002987} | train loss {'Reaction outcome loss': 0.32039428709615625, 'Total loss': 0.32039428709615625}
2022-11-28 02:16:24,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:24,087 INFO:     Epoch: 44
2022-11-28 02:16:24,840 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4215396503833207, 'Total loss': 0.4215396503833207} | train loss {'Reaction outcome loss': 0.3091992704017508, 'Total loss': 0.3091992704017508}
2022-11-28 02:16:24,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:24,840 INFO:     Epoch: 45
2022-11-28 02:16:25,597 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4304386126724156, 'Total loss': 0.4304386126724156} | train loss {'Reaction outcome loss': 0.3191130532312297, 'Total loss': 0.3191130532312297}
2022-11-28 02:16:25,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:25,597 INFO:     Epoch: 46
2022-11-28 02:16:26,354 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4531639394435016, 'Total loss': 0.4531639394435016} | train loss {'Reaction outcome loss': 0.32092978264535627, 'Total loss': 0.32092978264535627}
2022-11-28 02:16:26,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:26,354 INFO:     Epoch: 47
2022-11-28 02:16:27,108 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.407852464440194, 'Total loss': 0.407852464440194} | train loss {'Reaction outcome loss': 0.3153177411445687, 'Total loss': 0.3153177411445687}
2022-11-28 02:16:27,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:27,108 INFO:     Epoch: 48
2022-11-28 02:16:27,861 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42860378765247087, 'Total loss': 0.42860378765247087} | train loss {'Reaction outcome loss': 0.319881001697673, 'Total loss': 0.319881001697673}
2022-11-28 02:16:27,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:27,861 INFO:     Epoch: 49
2022-11-28 02:16:28,613 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41610717231577093, 'Total loss': 0.41610717231577093} | train loss {'Reaction outcome loss': 0.30977048361373527, 'Total loss': 0.30977048361373527}
2022-11-28 02:16:28,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:28,613 INFO:     Epoch: 50
2022-11-28 02:16:29,365 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42141478237780655, 'Total loss': 0.42141478237780655} | train loss {'Reaction outcome loss': 0.31990925036370754, 'Total loss': 0.31990925036370754}
2022-11-28 02:16:29,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:29,366 INFO:     Epoch: 51
2022-11-28 02:16:30,120 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41913020983338356, 'Total loss': 0.41913020983338356} | train loss {'Reaction outcome loss': 0.3206372484564781, 'Total loss': 0.3206372484564781}
2022-11-28 02:16:30,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:30,121 INFO:     Epoch: 52
2022-11-28 02:16:30,873 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4494049626995217, 'Total loss': 0.4494049626995217} | train loss {'Reaction outcome loss': 0.314118109403118, 'Total loss': 0.314118109403118}
2022-11-28 02:16:30,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:30,873 INFO:     Epoch: 53
2022-11-28 02:16:31,625 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4028511726382104, 'Total loss': 0.4028511726382104} | train loss {'Reaction outcome loss': 0.3142254489864553, 'Total loss': 0.3142254489864553}
2022-11-28 02:16:31,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:31,625 INFO:     Epoch: 54
2022-11-28 02:16:32,379 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4192354113540866, 'Total loss': 0.4192354113540866} | train loss {'Reaction outcome loss': 0.3067565604353384, 'Total loss': 0.3067565604353384}
2022-11-28 02:16:32,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:32,379 INFO:     Epoch: 55
2022-11-28 02:16:33,128 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4158534888516773, 'Total loss': 0.4158534888516773} | train loss {'Reaction outcome loss': 0.3147379042911193, 'Total loss': 0.3147379042911193}
2022-11-28 02:16:33,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:33,129 INFO:     Epoch: 56
2022-11-28 02:16:33,882 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40973046151074494, 'Total loss': 0.40973046151074494} | train loss {'Reaction outcome loss': 0.3043639439668867, 'Total loss': 0.3043639439668867}
2022-11-28 02:16:33,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:33,883 INFO:     Epoch: 57
2022-11-28 02:16:34,636 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4112410382790999, 'Total loss': 0.4112410382790999} | train loss {'Reaction outcome loss': 0.3174672992599587, 'Total loss': 0.3174672992599587}
2022-11-28 02:16:34,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:34,636 INFO:     Epoch: 58
2022-11-28 02:16:35,386 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4411520947786895, 'Total loss': 0.4411520947786895} | train loss {'Reaction outcome loss': 0.31592084980389523, 'Total loss': 0.31592084980389523}
2022-11-28 02:16:35,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:35,386 INFO:     Epoch: 59
2022-11-28 02:16:36,137 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4147406437180259, 'Total loss': 0.4147406437180259} | train loss {'Reaction outcome loss': 0.30757535837831035, 'Total loss': 0.30757535837831035}
2022-11-28 02:16:36,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:36,138 INFO:     Epoch: 60
2022-11-28 02:16:36,893 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41821823912588035, 'Total loss': 0.41821823912588035} | train loss {'Reaction outcome loss': 0.30430735266136544, 'Total loss': 0.30430735266136544}
2022-11-28 02:16:36,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:36,893 INFO:     Epoch: 61
2022-11-28 02:16:37,645 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.420711362734437, 'Total loss': 0.420711362734437} | train loss {'Reaction outcome loss': 0.31278443111166837, 'Total loss': 0.31278443111166837}
2022-11-28 02:16:37,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:37,645 INFO:     Epoch: 62
2022-11-28 02:16:38,397 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4066127933223139, 'Total loss': 0.4066127933223139} | train loss {'Reaction outcome loss': 0.3125500802491461, 'Total loss': 0.3125500802491461}
2022-11-28 02:16:38,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:38,397 INFO:     Epoch: 63
2022-11-28 02:16:39,147 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4451506009156054, 'Total loss': 0.4451506009156054} | train loss {'Reaction outcome loss': 0.3199526921755845, 'Total loss': 0.3199526921755845}
2022-11-28 02:16:39,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:39,148 INFO:     Epoch: 64
2022-11-28 02:16:39,897 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4088520488955758, 'Total loss': 0.4088520488955758} | train loss {'Reaction outcome loss': 0.3154552990660792, 'Total loss': 0.3154552990660792}
2022-11-28 02:16:39,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:39,897 INFO:     Epoch: 65
2022-11-28 02:16:40,646 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44091536782004614, 'Total loss': 0.44091536782004614} | train loss {'Reaction outcome loss': 0.30523726247972055, 'Total loss': 0.30523726247972055}
2022-11-28 02:16:40,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:40,646 INFO:     Epoch: 66
2022-11-28 02:16:41,395 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44855988499793137, 'Total loss': 0.44855988499793137} | train loss {'Reaction outcome loss': 0.30957800080819475, 'Total loss': 0.30957800080819475}
2022-11-28 02:16:41,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:41,396 INFO:     Epoch: 67
2022-11-28 02:16:42,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4095750789750706, 'Total loss': 0.4095750789750706} | train loss {'Reaction outcome loss': 0.310827461732251, 'Total loss': 0.310827461732251}
2022-11-28 02:16:42,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:42,146 INFO:     Epoch: 68
2022-11-28 02:16:42,896 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3927624902941964, 'Total loss': 0.3927624902941964} | train loss {'Reaction outcome loss': 0.3120683227335253, 'Total loss': 0.3120683227335253}
2022-11-28 02:16:42,896 INFO:     Found new best model at epoch 68
2022-11-28 02:16:42,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:42,897 INFO:     Epoch: 69
2022-11-28 02:16:43,651 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40947305952960794, 'Total loss': 0.40947305952960794} | train loss {'Reaction outcome loss': 0.31198529730881414, 'Total loss': 0.31198529730881414}
2022-11-28 02:16:43,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:43,651 INFO:     Epoch: 70
2022-11-28 02:16:44,406 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4042436834424734, 'Total loss': 0.4042436834424734} | train loss {'Reaction outcome loss': 0.3100565817627695, 'Total loss': 0.3100565817627695}
2022-11-28 02:16:44,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:44,406 INFO:     Epoch: 71
2022-11-28 02:16:45,159 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4260921742428433, 'Total loss': 0.4260921742428433} | train loss {'Reaction outcome loss': 0.29846557917734307, 'Total loss': 0.29846557917734307}
2022-11-28 02:16:45,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:45,160 INFO:     Epoch: 72
2022-11-28 02:16:45,911 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4074903072958643, 'Total loss': 0.4074903072958643} | train loss {'Reaction outcome loss': 0.31545413910381254, 'Total loss': 0.31545413910381254}
2022-11-28 02:16:45,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:45,911 INFO:     Epoch: 73
2022-11-28 02:16:46,662 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40180718763308093, 'Total loss': 0.40180718763308093} | train loss {'Reaction outcome loss': 0.31048393345648245, 'Total loss': 0.31048393345648245}
2022-11-28 02:16:46,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:46,662 INFO:     Epoch: 74
2022-11-28 02:16:47,410 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4284061471169645, 'Total loss': 0.4284061471169645} | train loss {'Reaction outcome loss': 0.31493902721652584, 'Total loss': 0.31493902721652584}
2022-11-28 02:16:47,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:47,411 INFO:     Epoch: 75
2022-11-28 02:16:48,160 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4242338297719305, 'Total loss': 0.4242338297719305} | train loss {'Reaction outcome loss': 0.30123029613206465, 'Total loss': 0.30123029613206465}
2022-11-28 02:16:48,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:48,161 INFO:     Epoch: 76
2022-11-28 02:16:48,912 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41810721362178976, 'Total loss': 0.41810721362178976} | train loss {'Reaction outcome loss': 0.30186233849775407, 'Total loss': 0.30186233849775407}
2022-11-28 02:16:48,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:48,912 INFO:     Epoch: 77
2022-11-28 02:16:49,664 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4288424797017466, 'Total loss': 0.4288424797017466} | train loss {'Reaction outcome loss': 0.31527257437307027, 'Total loss': 0.31527257437307027}
2022-11-28 02:16:49,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:49,665 INFO:     Epoch: 78
2022-11-28 02:16:50,418 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.442319703373042, 'Total loss': 0.442319703373042} | train loss {'Reaction outcome loss': 0.3017143901557692, 'Total loss': 0.3017143901557692}
2022-11-28 02:16:50,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:50,418 INFO:     Epoch: 79
2022-11-28 02:16:51,172 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42160970480604604, 'Total loss': 0.42160970480604604} | train loss {'Reaction outcome loss': 0.3106093252858808, 'Total loss': 0.3106093252858808}
2022-11-28 02:16:51,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:51,172 INFO:     Epoch: 80
2022-11-28 02:16:51,927 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4331804532557726, 'Total loss': 0.4331804532557726} | train loss {'Reaction outcome loss': 0.3028506493316062, 'Total loss': 0.3028506493316062}
2022-11-28 02:16:51,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:51,927 INFO:     Epoch: 81
2022-11-28 02:16:52,680 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41646805100820283, 'Total loss': 0.41646805100820283} | train loss {'Reaction outcome loss': 0.3026564297146134, 'Total loss': 0.3026564297146134}
2022-11-28 02:16:52,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:52,681 INFO:     Epoch: 82
2022-11-28 02:16:53,437 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43584167110649025, 'Total loss': 0.43584167110649025} | train loss {'Reaction outcome loss': 0.30246093989379946, 'Total loss': 0.30246093989379946}
2022-11-28 02:16:53,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:53,437 INFO:     Epoch: 83
2022-11-28 02:16:54,194 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4158618792214177, 'Total loss': 0.4158618792214177} | train loss {'Reaction outcome loss': 0.31227032203347455, 'Total loss': 0.31227032203347455}
2022-11-28 02:16:54,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:54,194 INFO:     Epoch: 84
2022-11-28 02:16:54,945 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41727462343194266, 'Total loss': 0.41727462343194266} | train loss {'Reaction outcome loss': 0.30899386935596984, 'Total loss': 0.30899386935596984}
2022-11-28 02:16:54,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:54,945 INFO:     Epoch: 85
2022-11-28 02:16:55,697 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4252369466491721, 'Total loss': 0.4252369466491721} | train loss {'Reaction outcome loss': 0.30702768683794046, 'Total loss': 0.30702768683794046}
2022-11-28 02:16:55,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:55,697 INFO:     Epoch: 86
2022-11-28 02:16:56,451 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43464901620014146, 'Total loss': 0.43464901620014146} | train loss {'Reaction outcome loss': 0.3057967081455694, 'Total loss': 0.3057967081455694}
2022-11-28 02:16:56,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:56,451 INFO:     Epoch: 87
2022-11-28 02:16:57,202 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.408804658123038, 'Total loss': 0.408804658123038} | train loss {'Reaction outcome loss': 0.29916589070231686, 'Total loss': 0.29916589070231686}
2022-11-28 02:16:57,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:57,202 INFO:     Epoch: 88
2022-11-28 02:16:57,954 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43864966183900833, 'Total loss': 0.43864966183900833} | train loss {'Reaction outcome loss': 0.3064941284396956, 'Total loss': 0.3064941284396956}
2022-11-28 02:16:57,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:57,955 INFO:     Epoch: 89
2022-11-28 02:16:58,709 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4198396551338109, 'Total loss': 0.4198396551338109} | train loss {'Reaction outcome loss': 0.30334399679615615, 'Total loss': 0.30334399679615615}
2022-11-28 02:16:58,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:58,709 INFO:     Epoch: 90
2022-11-28 02:16:59,462 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4163940670815381, 'Total loss': 0.4163940670815381} | train loss {'Reaction outcome loss': 0.30050558605862243, 'Total loss': 0.30050558605862243}
2022-11-28 02:16:59,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:16:59,462 INFO:     Epoch: 91
2022-11-28 02:17:00,213 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4064473917877132, 'Total loss': 0.4064473917877132} | train loss {'Reaction outcome loss': 0.30372355647024607, 'Total loss': 0.30372355647024607}
2022-11-28 02:17:00,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:00,213 INFO:     Epoch: 92
2022-11-28 02:17:00,965 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41894187253307213, 'Total loss': 0.41894187253307213} | train loss {'Reaction outcome loss': 0.3070417260751128, 'Total loss': 0.3070417260751128}
2022-11-28 02:17:00,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:00,966 INFO:     Epoch: 93
2022-11-28 02:17:01,720 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4492102268744599, 'Total loss': 0.4492102268744599} | train loss {'Reaction outcome loss': 0.3023496883050088, 'Total loss': 0.3023496883050088}
2022-11-28 02:17:01,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:01,720 INFO:     Epoch: 94
2022-11-28 02:17:02,470 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43756747736849566, 'Total loss': 0.43756747736849566} | train loss {'Reaction outcome loss': 0.3125121504248631, 'Total loss': 0.3125121504248631}
2022-11-28 02:17:02,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:02,471 INFO:     Epoch: 95
2022-11-28 02:17:03,222 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4576311595737934, 'Total loss': 0.4576311595737934} | train loss {'Reaction outcome loss': 0.3068339159231513, 'Total loss': 0.3068339159231513}
2022-11-28 02:17:03,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:03,223 INFO:     Epoch: 96
2022-11-28 02:17:03,975 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42415619777007535, 'Total loss': 0.42415619777007535} | train loss {'Reaction outcome loss': 0.29609679094245356, 'Total loss': 0.29609679094245356}
2022-11-28 02:17:03,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:03,975 INFO:     Epoch: 97
2022-11-28 02:17:04,729 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41796734116294165, 'Total loss': 0.41796734116294165} | train loss {'Reaction outcome loss': 0.3060799336000796, 'Total loss': 0.3060799336000796}
2022-11-28 02:17:04,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:04,729 INFO:     Epoch: 98
2022-11-28 02:17:05,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42101667008616706, 'Total loss': 0.42101667008616706} | train loss {'Reaction outcome loss': 0.3078080634586513, 'Total loss': 0.3078080634586513}
2022-11-28 02:17:05,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:05,481 INFO:     Epoch: 99
2022-11-28 02:17:06,233 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43479578298601235, 'Total loss': 0.43479578298601235} | train loss {'Reaction outcome loss': 0.30019986258459186, 'Total loss': 0.30019986258459186}
2022-11-28 02:17:06,234 INFO:     Best model found after epoch 69 of 100.
2022-11-28 02:17:06,234 INFO:   Done with stage: TRAINING
2022-11-28 02:17:06,234 INFO:   Starting stage: EVALUATION
2022-11-28 02:17:06,353 INFO:   Done with stage: EVALUATION
2022-11-28 02:17:06,353 INFO:   Leaving out SEQ value Fold_8
2022-11-28 02:17:06,365 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:17:06,366 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:17:07,009 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:17:07,009 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:17:07,078 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:17:07,078 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:17:07,078 INFO:     No hyperparam tuning for this model
2022-11-28 02:17:07,078 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:17:07,078 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:17:07,079 INFO:     None feature selector for col prot
2022-11-28 02:17:07,079 INFO:     None feature selector for col prot
2022-11-28 02:17:07,079 INFO:     None feature selector for col prot
2022-11-28 02:17:07,080 INFO:     None feature selector for col chem
2022-11-28 02:17:07,080 INFO:     None feature selector for col chem
2022-11-28 02:17:07,080 INFO:     None feature selector for col chem
2022-11-28 02:17:07,080 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:17:07,080 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:17:07,082 INFO:     Number of params in model 169741
2022-11-28 02:17:07,085 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:17:07,085 INFO:   Starting stage: TRAINING
2022-11-28 02:17:07,139 INFO:     Val loss before train {'Reaction outcome loss': 0.9776920175010507, 'Total loss': 0.9776920175010507}
2022-11-28 02:17:07,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:07,139 INFO:     Epoch: 0
2022-11-28 02:17:07,888 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5531508231704886, 'Total loss': 0.5531508231704886} | train loss {'Reaction outcome loss': 0.6440737053992287, 'Total loss': 0.6440737053992287}
2022-11-28 02:17:07,888 INFO:     Found new best model at epoch 0
2022-11-28 02:17:07,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:07,889 INFO:     Epoch: 1
2022-11-28 02:17:08,639 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49099262194199994, 'Total loss': 0.49099262194199994} | train loss {'Reaction outcome loss': 0.49998169236125484, 'Total loss': 0.49998169236125484}
2022-11-28 02:17:08,639 INFO:     Found new best model at epoch 1
2022-11-28 02:17:08,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:08,640 INFO:     Epoch: 2
2022-11-28 02:17:09,395 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46264505047689786, 'Total loss': 0.46264505047689786} | train loss {'Reaction outcome loss': 0.4653118706398433, 'Total loss': 0.4653118706398433}
2022-11-28 02:17:09,395 INFO:     Found new best model at epoch 2
2022-11-28 02:17:09,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:09,396 INFO:     Epoch: 3
2022-11-28 02:17:10,150 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49373498829928314, 'Total loss': 0.49373498829928314} | train loss {'Reaction outcome loss': 0.45249134085832105, 'Total loss': 0.45249134085832105}
2022-11-28 02:17:10,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:10,150 INFO:     Epoch: 4
2022-11-28 02:17:10,904 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4604175964539701, 'Total loss': 0.4604175964539701} | train loss {'Reaction outcome loss': 0.4285894760321225, 'Total loss': 0.4285894760321225}
2022-11-28 02:17:10,904 INFO:     Found new best model at epoch 4
2022-11-28 02:17:10,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:10,905 INFO:     Epoch: 5
2022-11-28 02:17:11,654 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44715128297155554, 'Total loss': 0.44715128297155554} | train loss {'Reaction outcome loss': 0.4256641461904491, 'Total loss': 0.4256641461904491}
2022-11-28 02:17:11,654 INFO:     Found new best model at epoch 5
2022-11-28 02:17:11,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:11,655 INFO:     Epoch: 6
2022-11-28 02:17:12,407 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4450804753737016, 'Total loss': 0.4450804753737016} | train loss {'Reaction outcome loss': 0.41568013118399727, 'Total loss': 0.41568013118399727}
2022-11-28 02:17:12,407 INFO:     Found new best model at epoch 6
2022-11-28 02:17:12,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:12,408 INFO:     Epoch: 7
2022-11-28 02:17:13,158 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.415414806116711, 'Total loss': 0.415414806116711} | train loss {'Reaction outcome loss': 0.40177690781532754, 'Total loss': 0.40177690781532754}
2022-11-28 02:17:13,158 INFO:     Found new best model at epoch 7
2022-11-28 02:17:13,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:13,159 INFO:     Epoch: 8
2022-11-28 02:17:13,910 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4389580254527656, 'Total loss': 0.4389580254527656} | train loss {'Reaction outcome loss': 0.4051783376884076, 'Total loss': 0.4051783376884076}
2022-11-28 02:17:13,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:13,911 INFO:     Epoch: 9
2022-11-28 02:17:14,659 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.432457623495297, 'Total loss': 0.432457623495297} | train loss {'Reaction outcome loss': 0.39332608220678184, 'Total loss': 0.39332608220678184}
2022-11-28 02:17:14,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:14,660 INFO:     Epoch: 10
2022-11-28 02:17:15,409 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4195863448760726, 'Total loss': 0.4195863448760726} | train loss {'Reaction outcome loss': 0.3755482382351352, 'Total loss': 0.3755482382351352}
2022-11-28 02:17:15,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:15,409 INFO:     Epoch: 11
2022-11-28 02:17:16,160 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4295959423550151, 'Total loss': 0.4295959423550151} | train loss {'Reaction outcome loss': 0.37929169806621726, 'Total loss': 0.37929169806621726}
2022-11-28 02:17:16,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:16,160 INFO:     Epoch: 12
2022-11-28 02:17:16,912 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.448468761687929, 'Total loss': 0.448468761687929} | train loss {'Reaction outcome loss': 0.3826623235739047, 'Total loss': 0.3826623235739047}
2022-11-28 02:17:16,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:16,913 INFO:     Epoch: 13
2022-11-28 02:17:17,667 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41518130017952487, 'Total loss': 0.41518130017952487} | train loss {'Reaction outcome loss': 0.375600733343632, 'Total loss': 0.375600733343632}
2022-11-28 02:17:17,667 INFO:     Found new best model at epoch 13
2022-11-28 02:17:17,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:17,668 INFO:     Epoch: 14
2022-11-28 02:17:18,421 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4233433475548571, 'Total loss': 0.4233433475548571} | train loss {'Reaction outcome loss': 0.3665235359221697, 'Total loss': 0.3665235359221697}
2022-11-28 02:17:18,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:18,421 INFO:     Epoch: 15
2022-11-28 02:17:19,177 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4166990149427544, 'Total loss': 0.4166990149427544} | train loss {'Reaction outcome loss': 0.36490937091049647, 'Total loss': 0.36490937091049647}
2022-11-28 02:17:19,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:19,178 INFO:     Epoch: 16
2022-11-28 02:17:19,934 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42190094478428364, 'Total loss': 0.42190094478428364} | train loss {'Reaction outcome loss': 0.3681436294629689, 'Total loss': 0.3681436294629689}
2022-11-28 02:17:19,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:19,935 INFO:     Epoch: 17
2022-11-28 02:17:20,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41496669060804625, 'Total loss': 0.41496669060804625} | train loss {'Reaction outcome loss': 0.3567473831015729, 'Total loss': 0.3567473831015729}
2022-11-28 02:17:20,687 INFO:     Found new best model at epoch 17
2022-11-28 02:17:20,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:20,688 INFO:     Epoch: 18
2022-11-28 02:17:21,436 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42149741879918357, 'Total loss': 0.42149741879918357} | train loss {'Reaction outcome loss': 0.35728759814294114, 'Total loss': 0.35728759814294114}
2022-11-28 02:17:21,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:21,437 INFO:     Epoch: 19
2022-11-28 02:17:22,187 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42688512260263617, 'Total loss': 0.42688512260263617} | train loss {'Reaction outcome loss': 0.3541683688639633, 'Total loss': 0.3541683688639633}
2022-11-28 02:17:22,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:22,187 INFO:     Epoch: 20
2022-11-28 02:17:22,939 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4507810713892633, 'Total loss': 0.4507810713892633} | train loss {'Reaction outcome loss': 0.35832956682650313, 'Total loss': 0.35832956682650313}
2022-11-28 02:17:22,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:22,940 INFO:     Epoch: 21
2022-11-28 02:17:23,692 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4020394283262166, 'Total loss': 0.4020394283262166} | train loss {'Reaction outcome loss': 0.35035784527539243, 'Total loss': 0.35035784527539243}
2022-11-28 02:17:23,692 INFO:     Found new best model at epoch 21
2022-11-28 02:17:23,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:23,693 INFO:     Epoch: 22
2022-11-28 02:17:24,444 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41671995005824347, 'Total loss': 0.41671995005824347} | train loss {'Reaction outcome loss': 0.3512637574946688, 'Total loss': 0.3512637574946688}
2022-11-28 02:17:24,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:24,444 INFO:     Epoch: 23
2022-11-28 02:17:25,197 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4095091257583011, 'Total loss': 0.4095091257583011} | train loss {'Reaction outcome loss': 0.3475250942752727, 'Total loss': 0.3475250942752727}
2022-11-28 02:17:25,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:25,197 INFO:     Epoch: 24
2022-11-28 02:17:25,950 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3890863155776804, 'Total loss': 0.3890863155776804} | train loss {'Reaction outcome loss': 0.34882683300923917, 'Total loss': 0.34882683300923917}
2022-11-28 02:17:25,950 INFO:     Found new best model at epoch 24
2022-11-28 02:17:25,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:25,951 INFO:     Epoch: 25
2022-11-28 02:17:26,700 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39855462549762294, 'Total loss': 0.39855462549762294} | train loss {'Reaction outcome loss': 0.34108639111922634, 'Total loss': 0.34108639111922634}
2022-11-28 02:17:26,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:26,701 INFO:     Epoch: 26
2022-11-28 02:17:27,452 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43019023266705597, 'Total loss': 0.43019023266705597} | train loss {'Reaction outcome loss': 0.34691534608963037, 'Total loss': 0.34691534608963037}
2022-11-28 02:17:27,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:27,453 INFO:     Epoch: 27
2022-11-28 02:17:28,202 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42887925932353194, 'Total loss': 0.42887925932353194} | train loss {'Reaction outcome loss': 0.33693857584148645, 'Total loss': 0.33693857584148645}
2022-11-28 02:17:28,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:28,202 INFO:     Epoch: 28
2022-11-28 02:17:28,951 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3919780692085624, 'Total loss': 0.3919780692085624} | train loss {'Reaction outcome loss': 0.3482545555058506, 'Total loss': 0.3482545555058506}
2022-11-28 02:17:28,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:28,951 INFO:     Epoch: 29
2022-11-28 02:17:29,701 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39493767138231883, 'Total loss': 0.39493767138231883} | train loss {'Reaction outcome loss': 0.3389101873692726, 'Total loss': 0.3389101873692726}
2022-11-28 02:17:29,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:29,701 INFO:     Epoch: 30
2022-11-28 02:17:30,452 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.410624353045767, 'Total loss': 0.410624353045767} | train loss {'Reaction outcome loss': 0.34163111628543946, 'Total loss': 0.34163111628543946}
2022-11-28 02:17:30,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:30,452 INFO:     Epoch: 31
2022-11-28 02:17:31,205 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40939153222875163, 'Total loss': 0.40939153222875163} | train loss {'Reaction outcome loss': 0.34535031193386645, 'Total loss': 0.34535031193386645}
2022-11-28 02:17:31,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:31,205 INFO:     Epoch: 32
2022-11-28 02:17:31,954 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3820780668069016, 'Total loss': 0.3820780668069016} | train loss {'Reaction outcome loss': 0.3417962192287368, 'Total loss': 0.3417962192287368}
2022-11-28 02:17:31,955 INFO:     Found new best model at epoch 32
2022-11-28 02:17:31,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:31,956 INFO:     Epoch: 33
2022-11-28 02:17:32,710 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4097737029872157, 'Total loss': 0.4097737029872157} | train loss {'Reaction outcome loss': 0.3364943024972754, 'Total loss': 0.3364943024972754}
2022-11-28 02:17:32,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:32,710 INFO:     Epoch: 34
2022-11-28 02:17:33,463 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4139166274531321, 'Total loss': 0.4139166274531321} | train loss {'Reaction outcome loss': 0.3389923678590886, 'Total loss': 0.3389923678590886}
2022-11-28 02:17:33,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:33,464 INFO:     Epoch: 35
2022-11-28 02:17:34,217 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41275008937174623, 'Total loss': 0.41275008937174623} | train loss {'Reaction outcome loss': 0.33500140866324785, 'Total loss': 0.33500140866324785}
2022-11-28 02:17:34,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:34,217 INFO:     Epoch: 36
2022-11-28 02:17:34,969 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4294589500535618, 'Total loss': 0.4294589500535618} | train loss {'Reaction outcome loss': 0.3283624304758926, 'Total loss': 0.3283624304758926}
2022-11-28 02:17:34,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:34,970 INFO:     Epoch: 37
2022-11-28 02:17:35,718 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4264488071203232, 'Total loss': 0.4264488071203232} | train loss {'Reaction outcome loss': 0.3294033273573845, 'Total loss': 0.3294033273573845}
2022-11-28 02:17:35,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:35,719 INFO:     Epoch: 38
2022-11-28 02:17:36,472 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3983899395574223, 'Total loss': 0.3983899395574223} | train loss {'Reaction outcome loss': 0.3268967377202165, 'Total loss': 0.3268967377202165}
2022-11-28 02:17:36,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:36,472 INFO:     Epoch: 39
2022-11-28 02:17:37,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4194833663376895, 'Total loss': 0.4194833663376895} | train loss {'Reaction outcome loss': 0.32949312749288734, 'Total loss': 0.32949312749288734}
2022-11-28 02:17:37,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:37,225 INFO:     Epoch: 40
2022-11-28 02:17:37,975 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4041397124528885, 'Total loss': 0.4041397124528885} | train loss {'Reaction outcome loss': 0.3260190985015323, 'Total loss': 0.3260190985015323}
2022-11-28 02:17:37,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:37,976 INFO:     Epoch: 41
2022-11-28 02:17:38,725 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40447227301245386, 'Total loss': 0.40447227301245386} | train loss {'Reaction outcome loss': 0.33463889600769164, 'Total loss': 0.33463889600769164}
2022-11-28 02:17:38,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:38,726 INFO:     Epoch: 42
2022-11-28 02:17:39,477 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4131188197908076, 'Total loss': 0.4131188197908076} | train loss {'Reaction outcome loss': 0.32344770784519855, 'Total loss': 0.32344770784519855}
2022-11-28 02:17:39,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:39,477 INFO:     Epoch: 43
2022-11-28 02:17:40,231 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39018086581067607, 'Total loss': 0.39018086581067607} | train loss {'Reaction outcome loss': 0.336447482718335, 'Total loss': 0.336447482718335}
2022-11-28 02:17:40,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:40,231 INFO:     Epoch: 44
2022-11-28 02:17:40,984 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3992623478512872, 'Total loss': 0.3992623478512872} | train loss {'Reaction outcome loss': 0.3240594218875612, 'Total loss': 0.3240594218875612}
2022-11-28 02:17:40,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:40,984 INFO:     Epoch: 45
2022-11-28 02:17:41,735 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4210983054204421, 'Total loss': 0.4210983054204421} | train loss {'Reaction outcome loss': 0.32341708828725163, 'Total loss': 0.32341708828725163}
2022-11-28 02:17:41,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:41,735 INFO:     Epoch: 46
2022-11-28 02:17:42,487 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4016557926820083, 'Total loss': 0.4016557926820083} | train loss {'Reaction outcome loss': 0.3379029383462283, 'Total loss': 0.3379029383462283}
2022-11-28 02:17:42,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:42,487 INFO:     Epoch: 47
2022-11-28 02:17:43,241 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4001869769258933, 'Total loss': 0.4001869769258933} | train loss {'Reaction outcome loss': 0.3301252811065605, 'Total loss': 0.3301252811065605}
2022-11-28 02:17:43,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:43,241 INFO:     Epoch: 48
2022-11-28 02:17:43,991 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41142584349621425, 'Total loss': 0.41142584349621425} | train loss {'Reaction outcome loss': 0.3209589976336687, 'Total loss': 0.3209589976336687}
2022-11-28 02:17:43,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:43,991 INFO:     Epoch: 49
2022-11-28 02:17:44,742 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4142916216091676, 'Total loss': 0.4142916216091676} | train loss {'Reaction outcome loss': 0.32870831442696435, 'Total loss': 0.32870831442696435}
2022-11-28 02:17:44,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:44,743 INFO:     Epoch: 50
2022-11-28 02:17:45,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40201313522729004, 'Total loss': 0.40201313522729004} | train loss {'Reaction outcome loss': 0.32545989199030784, 'Total loss': 0.32545989199030784}
2022-11-28 02:17:45,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:45,495 INFO:     Epoch: 51
2022-11-28 02:17:46,253 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38794230872934515, 'Total loss': 0.38794230872934515} | train loss {'Reaction outcome loss': 0.3289136693722779, 'Total loss': 0.3289136693722779}
2022-11-28 02:17:46,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:46,253 INFO:     Epoch: 52
2022-11-28 02:17:47,008 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3732182275165211, 'Total loss': 0.3732182275165211} | train loss {'Reaction outcome loss': 0.3234164248701305, 'Total loss': 0.3234164248701305}
2022-11-28 02:17:47,008 INFO:     Found new best model at epoch 52
2022-11-28 02:17:47,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:47,009 INFO:     Epoch: 53
2022-11-28 02:17:47,759 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40382668579166586, 'Total loss': 0.40382668579166586} | train loss {'Reaction outcome loss': 0.32197872293932783, 'Total loss': 0.32197872293932783}
2022-11-28 02:17:47,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:47,759 INFO:     Epoch: 54
2022-11-28 02:17:48,518 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38081629980694165, 'Total loss': 0.38081629980694165} | train loss {'Reaction outcome loss': 0.3261124791517373, 'Total loss': 0.3261124791517373}
2022-11-28 02:17:48,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:48,519 INFO:     Epoch: 55
2022-11-28 02:17:49,270 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40343856100331654, 'Total loss': 0.40343856100331654} | train loss {'Reaction outcome loss': 0.3201053129328835, 'Total loss': 0.3201053129328835}
2022-11-28 02:17:49,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:49,270 INFO:     Epoch: 56
2022-11-28 02:17:50,020 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39227534932169045, 'Total loss': 0.39227534932169045} | train loss {'Reaction outcome loss': 0.3259297095599674, 'Total loss': 0.3259297095599674}
2022-11-28 02:17:50,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:50,020 INFO:     Epoch: 57
2022-11-28 02:17:50,772 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36953986808657646, 'Total loss': 0.36953986808657646} | train loss {'Reaction outcome loss': 0.3215524398631627, 'Total loss': 0.3215524398631627}
2022-11-28 02:17:50,772 INFO:     Found new best model at epoch 57
2022-11-28 02:17:50,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:50,773 INFO:     Epoch: 58
2022-11-28 02:17:51,527 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38223071413284, 'Total loss': 0.38223071413284} | train loss {'Reaction outcome loss': 0.3172787707449207, 'Total loss': 0.3172787707449207}
2022-11-28 02:17:51,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:51,527 INFO:     Epoch: 59
2022-11-28 02:17:52,279 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4227341250939803, 'Total loss': 0.4227341250939803} | train loss {'Reaction outcome loss': 0.3236539664888574, 'Total loss': 0.3236539664888574}
2022-11-28 02:17:52,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:52,280 INFO:     Epoch: 60
2022-11-28 02:17:53,031 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4083439281040972, 'Total loss': 0.4083439281040972} | train loss {'Reaction outcome loss': 0.3240437936338206, 'Total loss': 0.3240437936338206}
2022-11-28 02:17:53,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:53,031 INFO:     Epoch: 61
2022-11-28 02:17:53,787 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4136140076443553, 'Total loss': 0.4136140076443553} | train loss {'Reaction outcome loss': 0.32198623733054244, 'Total loss': 0.32198623733054244}
2022-11-28 02:17:53,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:53,787 INFO:     Epoch: 62
2022-11-28 02:17:54,547 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3976728110150857, 'Total loss': 0.3976728110150857} | train loss {'Reaction outcome loss': 0.3284655012070171, 'Total loss': 0.3284655012070171}
2022-11-28 02:17:54,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:54,547 INFO:     Epoch: 63
2022-11-28 02:17:55,304 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4012601605870507, 'Total loss': 0.4012601605870507} | train loss {'Reaction outcome loss': 0.32043980446554, 'Total loss': 0.32043980446554}
2022-11-28 02:17:55,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:55,304 INFO:     Epoch: 64
2022-11-28 02:17:56,056 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4078928790986538, 'Total loss': 0.4078928790986538} | train loss {'Reaction outcome loss': 0.3220882932204873, 'Total loss': 0.3220882932204873}
2022-11-28 02:17:56,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:56,056 INFO:     Epoch: 65
2022-11-28 02:17:56,806 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3908951578831131, 'Total loss': 0.3908951578831131} | train loss {'Reaction outcome loss': 0.32273746723489416, 'Total loss': 0.32273746723489416}
2022-11-28 02:17:56,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:56,806 INFO:     Epoch: 66
2022-11-28 02:17:57,562 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3906757892532782, 'Total loss': 0.3906757892532782} | train loss {'Reaction outcome loss': 0.3182245115599325, 'Total loss': 0.3182245115599325}
2022-11-28 02:17:57,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:57,563 INFO:     Epoch: 67
2022-11-28 02:17:58,316 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39878493784503505, 'Total loss': 0.39878493784503505} | train loss {'Reaction outcome loss': 0.32648974928944824, 'Total loss': 0.32648974928944824}
2022-11-28 02:17:58,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:58,316 INFO:     Epoch: 68
2022-11-28 02:17:59,071 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.415184750137004, 'Total loss': 0.415184750137004} | train loss {'Reaction outcome loss': 0.3249225727312507, 'Total loss': 0.3249225727312507}
2022-11-28 02:17:59,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:59,071 INFO:     Epoch: 69
2022-11-28 02:17:59,826 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3692197965627367, 'Total loss': 0.3692197965627367} | train loss {'Reaction outcome loss': 0.31625368411562615, 'Total loss': 0.31625368411562615}
2022-11-28 02:17:59,826 INFO:     Found new best model at epoch 69
2022-11-28 02:17:59,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:17:59,827 INFO:     Epoch: 70
2022-11-28 02:18:00,577 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41850199990651826, 'Total loss': 0.41850199990651826} | train loss {'Reaction outcome loss': 0.3172571180208075, 'Total loss': 0.3172571180208075}
2022-11-28 02:18:00,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:00,578 INFO:     Epoch: 71
2022-11-28 02:18:01,329 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4043897617269646, 'Total loss': 0.4043897617269646} | train loss {'Reaction outcome loss': 0.31722807975846434, 'Total loss': 0.31722807975846434}
2022-11-28 02:18:01,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:01,329 INFO:     Epoch: 72
2022-11-28 02:18:02,079 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37863892960277473, 'Total loss': 0.37863892960277473} | train loss {'Reaction outcome loss': 0.32000005200144743, 'Total loss': 0.32000005200144743}
2022-11-28 02:18:02,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:02,079 INFO:     Epoch: 73
2022-11-28 02:18:02,830 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37445487115870824, 'Total loss': 0.37445487115870824} | train loss {'Reaction outcome loss': 0.3271316390845083, 'Total loss': 0.3271316390845083}
2022-11-28 02:18:02,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:02,831 INFO:     Epoch: 74
2022-11-28 02:18:03,580 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4006222014061429, 'Total loss': 0.4006222014061429} | train loss {'Reaction outcome loss': 0.3064715814806761, 'Total loss': 0.3064715814806761}
2022-11-28 02:18:03,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:03,580 INFO:     Epoch: 75
2022-11-28 02:18:04,331 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39777004888111894, 'Total loss': 0.39777004888111894} | train loss {'Reaction outcome loss': 0.32354012471173077, 'Total loss': 0.32354012471173077}
2022-11-28 02:18:04,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:04,331 INFO:     Epoch: 76
2022-11-28 02:18:05,082 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37404066358100285, 'Total loss': 0.37404066358100285} | train loss {'Reaction outcome loss': 0.32479503922044267, 'Total loss': 0.32479503922044267}
2022-11-28 02:18:05,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:05,083 INFO:     Epoch: 77
2022-11-28 02:18:05,829 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39942518452351744, 'Total loss': 0.39942518452351744} | train loss {'Reaction outcome loss': 0.3218219006253827, 'Total loss': 0.3218219006253827}
2022-11-28 02:18:05,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:05,829 INFO:     Epoch: 78
2022-11-28 02:18:06,578 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37677696787498216, 'Total loss': 0.37677696787498216} | train loss {'Reaction outcome loss': 0.3234657943248749, 'Total loss': 0.3234657943248749}
2022-11-28 02:18:06,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:06,578 INFO:     Epoch: 79
2022-11-28 02:18:07,326 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37842592664740304, 'Total loss': 0.37842592664740304} | train loss {'Reaction outcome loss': 0.31825133636894243, 'Total loss': 0.31825133636894243}
2022-11-28 02:18:07,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:07,327 INFO:     Epoch: 80
2022-11-28 02:18:08,075 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39999252422289416, 'Total loss': 0.39999252422289416} | train loss {'Reaction outcome loss': 0.31315335382016435, 'Total loss': 0.31315335382016435}
2022-11-28 02:18:08,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:08,075 INFO:     Epoch: 81
2022-11-28 02:18:08,821 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3923503424633633, 'Total loss': 0.3923503424633633} | train loss {'Reaction outcome loss': 0.3230452042433523, 'Total loss': 0.3230452042433523}
2022-11-28 02:18:08,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:08,821 INFO:     Epoch: 82
2022-11-28 02:18:09,568 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39344840801574965, 'Total loss': 0.39344840801574965} | train loss {'Reaction outcome loss': 0.32590586541881483, 'Total loss': 0.32590586541881483}
2022-11-28 02:18:09,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:09,569 INFO:     Epoch: 83
2022-11-28 02:18:10,316 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3954620657658035, 'Total loss': 0.3954620657658035} | train loss {'Reaction outcome loss': 0.32283002226763674, 'Total loss': 0.32283002226763674}
2022-11-28 02:18:10,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:10,316 INFO:     Epoch: 84
2022-11-28 02:18:11,062 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3986738429150798, 'Total loss': 0.3986738429150798} | train loss {'Reaction outcome loss': 0.311191855208768, 'Total loss': 0.311191855208768}
2022-11-28 02:18:11,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:11,063 INFO:     Epoch: 85
2022-11-28 02:18:11,812 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3770022973079573, 'Total loss': 0.3770022973079573} | train loss {'Reaction outcome loss': 0.3160662110294065, 'Total loss': 0.3160662110294065}
2022-11-28 02:18:11,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:11,812 INFO:     Epoch: 86
2022-11-28 02:18:12,559 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4194887744432146, 'Total loss': 0.4194887744432146} | train loss {'Reaction outcome loss': 0.3193465505516337, 'Total loss': 0.3193465505516337}
2022-11-28 02:18:12,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:12,559 INFO:     Epoch: 87
2022-11-28 02:18:13,306 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42113286697051744, 'Total loss': 0.42113286697051744} | train loss {'Reaction outcome loss': 0.3185216426068256, 'Total loss': 0.3185216426068256}
2022-11-28 02:18:13,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:13,306 INFO:     Epoch: 88
2022-11-28 02:18:14,052 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4031791470267556, 'Total loss': 0.4031791470267556} | train loss {'Reaction outcome loss': 0.31684411001662094, 'Total loss': 0.31684411001662094}
2022-11-28 02:18:14,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:14,052 INFO:     Epoch: 89
2022-11-28 02:18:14,798 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3782183949581601, 'Total loss': 0.3782183949581601} | train loss {'Reaction outcome loss': 0.31858805660158396, 'Total loss': 0.31858805660158396}
2022-11-28 02:18:14,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:14,798 INFO:     Epoch: 90
2022-11-28 02:18:15,547 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36327255043116485, 'Total loss': 0.36327255043116485} | train loss {'Reaction outcome loss': 0.32139628656929536, 'Total loss': 0.32139628656929536}
2022-11-28 02:18:15,547 INFO:     Found new best model at epoch 90
2022-11-28 02:18:15,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:15,548 INFO:     Epoch: 91
2022-11-28 02:18:16,296 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4022609859027646, 'Total loss': 0.4022609859027646} | train loss {'Reaction outcome loss': 0.32024635777117744, 'Total loss': 0.32024635777117744}
2022-11-28 02:18:16,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:16,296 INFO:     Epoch: 92
2022-11-28 02:18:17,044 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3877636292441325, 'Total loss': 0.3877636292441325} | train loss {'Reaction outcome loss': 0.32008704257708404, 'Total loss': 0.32008704257708404}
2022-11-28 02:18:17,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:17,044 INFO:     Epoch: 93
2022-11-28 02:18:17,793 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38569188405844296, 'Total loss': 0.38569188405844296} | train loss {'Reaction outcome loss': 0.3122616747334119, 'Total loss': 0.3122616747334119}
2022-11-28 02:18:17,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:17,793 INFO:     Epoch: 94
2022-11-28 02:18:18,542 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4037088221785697, 'Total loss': 0.4037088221785697} | train loss {'Reaction outcome loss': 0.3200157004438581, 'Total loss': 0.3200157004438581}
2022-11-28 02:18:18,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:18,542 INFO:     Epoch: 95
2022-11-28 02:18:19,291 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40908906490288, 'Total loss': 0.40908906490288} | train loss {'Reaction outcome loss': 0.32975611589368314, 'Total loss': 0.32975611589368314}
2022-11-28 02:18:19,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:19,291 INFO:     Epoch: 96
2022-11-28 02:18:20,038 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44092016700993886, 'Total loss': 0.44092016700993886} | train loss {'Reaction outcome loss': 0.3098645918371697, 'Total loss': 0.3098645918371697}
2022-11-28 02:18:20,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:20,038 INFO:     Epoch: 97
2022-11-28 02:18:20,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39376952702348883, 'Total loss': 0.39376952702348883} | train loss {'Reaction outcome loss': 0.31783755877686126, 'Total loss': 0.31783755877686126}
2022-11-28 02:18:20,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:20,789 INFO:     Epoch: 98
2022-11-28 02:18:21,542 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40508078174157575, 'Total loss': 0.40508078174157575} | train loss {'Reaction outcome loss': 0.31741532456550386, 'Total loss': 0.31741532456550386}
2022-11-28 02:18:21,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:21,542 INFO:     Epoch: 99
2022-11-28 02:18:22,296 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37782748246734793, 'Total loss': 0.37782748246734793} | train loss {'Reaction outcome loss': 0.31954940303318924, 'Total loss': 0.31954940303318924}
2022-11-28 02:18:22,297 INFO:     Best model found after epoch 91 of 100.
2022-11-28 02:18:22,297 INFO:   Done with stage: TRAINING
2022-11-28 02:18:22,297 INFO:   Starting stage: EVALUATION
2022-11-28 02:18:22,416 INFO:   Done with stage: EVALUATION
2022-11-28 02:18:22,416 INFO:   Leaving out SEQ value Fold_9
2022-11-28 02:18:22,429 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:18:22,429 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:18:23,064 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:18:23,065 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:18:23,133 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:18:23,134 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:18:23,134 INFO:     No hyperparam tuning for this model
2022-11-28 02:18:23,134 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:18:23,134 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:18:23,135 INFO:     None feature selector for col prot
2022-11-28 02:18:23,135 INFO:     None feature selector for col prot
2022-11-28 02:18:23,135 INFO:     None feature selector for col prot
2022-11-28 02:18:23,135 INFO:     None feature selector for col chem
2022-11-28 02:18:23,135 INFO:     None feature selector for col chem
2022-11-28 02:18:23,135 INFO:     None feature selector for col chem
2022-11-28 02:18:23,136 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:18:23,136 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:18:23,137 INFO:     Number of params in model 169741
2022-11-28 02:18:23,140 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:18:23,140 INFO:   Starting stage: TRAINING
2022-11-28 02:18:23,194 INFO:     Val loss before train {'Reaction outcome loss': 1.029036975719712, 'Total loss': 1.029036975719712}
2022-11-28 02:18:23,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:23,194 INFO:     Epoch: 0
2022-11-28 02:18:23,937 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5150149992921136, 'Total loss': 0.5150149992921136} | train loss {'Reaction outcome loss': 0.627590980578442, 'Total loss': 0.627590980578442}
2022-11-28 02:18:23,937 INFO:     Found new best model at epoch 0
2022-11-28 02:18:23,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:23,938 INFO:     Epoch: 1
2022-11-28 02:18:24,685 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4782931625165723, 'Total loss': 0.4782931625165723} | train loss {'Reaction outcome loss': 0.4832443771921858, 'Total loss': 0.4832443771921858}
2022-11-28 02:18:24,685 INFO:     Found new best model at epoch 1
2022-11-28 02:18:24,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:24,686 INFO:     Epoch: 2
2022-11-28 02:18:25,429 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47482350197705353, 'Total loss': 0.47482350197705353} | train loss {'Reaction outcome loss': 0.44188771016743716, 'Total loss': 0.44188771016743716}
2022-11-28 02:18:25,429 INFO:     Found new best model at epoch 2
2022-11-28 02:18:25,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:25,430 INFO:     Epoch: 3
2022-11-28 02:18:26,170 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4953363737599416, 'Total loss': 0.4953363737599416} | train loss {'Reaction outcome loss': 0.4165815707372159, 'Total loss': 0.4165815707372159}
2022-11-28 02:18:26,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:26,170 INFO:     Epoch: 4
2022-11-28 02:18:26,909 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46970245750112966, 'Total loss': 0.46970245750112966} | train loss {'Reaction outcome loss': 0.40450028129378146, 'Total loss': 0.40450028129378146}
2022-11-28 02:18:26,909 INFO:     Found new best model at epoch 4
2022-11-28 02:18:26,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:26,910 INFO:     Epoch: 5
2022-11-28 02:18:27,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43701406161893497, 'Total loss': 0.43701406161893497} | train loss {'Reaction outcome loss': 0.39938013018394003, 'Total loss': 0.39938013018394003}
2022-11-28 02:18:27,652 INFO:     Found new best model at epoch 5
2022-11-28 02:18:27,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:27,653 INFO:     Epoch: 6
2022-11-28 02:18:28,399 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4789369397542693, 'Total loss': 0.4789369397542693} | train loss {'Reaction outcome loss': 0.3848648942246729, 'Total loss': 0.3848648942246729}
2022-11-28 02:18:28,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:28,399 INFO:     Epoch: 7
2022-11-28 02:18:29,144 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4425687864422798, 'Total loss': 0.4425687864422798} | train loss {'Reaction outcome loss': 0.38094181315023073, 'Total loss': 0.38094181315023073}
2022-11-28 02:18:29,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:29,145 INFO:     Epoch: 8
2022-11-28 02:18:29,891 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42574489434165036, 'Total loss': 0.42574489434165036} | train loss {'Reaction outcome loss': 0.37038946504495585, 'Total loss': 0.37038946504495585}
2022-11-28 02:18:29,891 INFO:     Found new best model at epoch 8
2022-11-28 02:18:29,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:29,892 INFO:     Epoch: 9
2022-11-28 02:18:30,632 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46687688678503036, 'Total loss': 0.46687688678503036} | train loss {'Reaction outcome loss': 0.3675479728348401, 'Total loss': 0.3675479728348401}
2022-11-28 02:18:30,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:30,632 INFO:     Epoch: 10
2022-11-28 02:18:31,377 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4153269349851392, 'Total loss': 0.4153269349851392} | train loss {'Reaction outcome loss': 0.3644376800680647, 'Total loss': 0.3644376800680647}
2022-11-28 02:18:31,377 INFO:     Found new best model at epoch 10
2022-11-28 02:18:31,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:31,378 INFO:     Epoch: 11
2022-11-28 02:18:32,123 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4382441836324605, 'Total loss': 0.4382441836324605} | train loss {'Reaction outcome loss': 0.36328860980515576, 'Total loss': 0.36328860980515576}
2022-11-28 02:18:32,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:32,123 INFO:     Epoch: 12
2022-11-28 02:18:32,868 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45382133701985533, 'Total loss': 0.45382133701985533} | train loss {'Reaction outcome loss': 0.3644321671249915, 'Total loss': 0.3644321671249915}
2022-11-28 02:18:32,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:32,868 INFO:     Epoch: 13
2022-11-28 02:18:33,613 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43217513405463914, 'Total loss': 0.43217513405463914} | train loss {'Reaction outcome loss': 0.35064122871476777, 'Total loss': 0.35064122871476777}
2022-11-28 02:18:33,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:33,614 INFO:     Epoch: 14
2022-11-28 02:18:34,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4316330347210169, 'Total loss': 0.4316330347210169} | train loss {'Reaction outcome loss': 0.34385846354523486, 'Total loss': 0.34385846354523486}
2022-11-28 02:18:34,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:34,360 INFO:     Epoch: 15
2022-11-28 02:18:35,103 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43231437101282855, 'Total loss': 0.43231437101282855} | train loss {'Reaction outcome loss': 0.3438676463706153, 'Total loss': 0.3438676463706153}
2022-11-28 02:18:35,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:35,103 INFO:     Epoch: 16
2022-11-28 02:18:35,844 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4382933127609166, 'Total loss': 0.4382933127609166} | train loss {'Reaction outcome loss': 0.3423226430099838, 'Total loss': 0.3423226430099838}
2022-11-28 02:18:35,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:35,844 INFO:     Epoch: 17
2022-11-28 02:18:36,585 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4419033657759428, 'Total loss': 0.4419033657759428} | train loss {'Reaction outcome loss': 0.3351071921842439, 'Total loss': 0.3351071921842439}
2022-11-28 02:18:36,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:36,586 INFO:     Epoch: 18
2022-11-28 02:18:37,328 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42457475648684934, 'Total loss': 0.42457475648684934} | train loss {'Reaction outcome loss': 0.33928013884899566, 'Total loss': 0.33928013884899566}
2022-11-28 02:18:37,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:37,328 INFO:     Epoch: 19
2022-11-28 02:18:38,069 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49175439012998884, 'Total loss': 0.49175439012998884} | train loss {'Reaction outcome loss': 0.33547032587990466, 'Total loss': 0.33547032587990466}
2022-11-28 02:18:38,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:38,070 INFO:     Epoch: 20
2022-11-28 02:18:38,810 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47708430818536063, 'Total loss': 0.47708430818536063} | train loss {'Reaction outcome loss': 0.3357190778060835, 'Total loss': 0.3357190778060835}
2022-11-28 02:18:38,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:38,810 INFO:     Epoch: 21
2022-11-28 02:18:39,552 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40818024934692815, 'Total loss': 0.40818024934692815} | train loss {'Reaction outcome loss': 0.32639867841285103, 'Total loss': 0.32639867841285103}
2022-11-28 02:18:39,552 INFO:     Found new best model at epoch 21
2022-11-28 02:18:39,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:39,553 INFO:     Epoch: 22
2022-11-28 02:18:40,295 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45512122694741597, 'Total loss': 0.45512122694741597} | train loss {'Reaction outcome loss': 0.32854723740293057, 'Total loss': 0.32854723740293057}
2022-11-28 02:18:40,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:40,296 INFO:     Epoch: 23
2022-11-28 02:18:41,038 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.417018550363454, 'Total loss': 0.417018550363454} | train loss {'Reaction outcome loss': 0.3318481857071117, 'Total loss': 0.3318481857071117}
2022-11-28 02:18:41,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:41,038 INFO:     Epoch: 24
2022-11-28 02:18:41,780 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40651782331141556, 'Total loss': 0.40651782331141556} | train loss {'Reaction outcome loss': 0.3266712518370881, 'Total loss': 0.3266712518370881}
2022-11-28 02:18:41,780 INFO:     Found new best model at epoch 24
2022-11-28 02:18:41,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:41,781 INFO:     Epoch: 25
2022-11-28 02:18:42,525 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4539589299397035, 'Total loss': 0.4539589299397035} | train loss {'Reaction outcome loss': 0.3205488107642349, 'Total loss': 0.3205488107642349}
2022-11-28 02:18:42,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:42,525 INFO:     Epoch: 26
2022-11-28 02:18:43,265 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4332748367027803, 'Total loss': 0.4332748367027803} | train loss {'Reaction outcome loss': 0.328085357011581, 'Total loss': 0.328085357011581}
2022-11-28 02:18:43,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:43,266 INFO:     Epoch: 27
2022-11-28 02:18:44,008 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46124579825184564, 'Total loss': 0.46124579825184564} | train loss {'Reaction outcome loss': 0.3179356717029396, 'Total loss': 0.3179356717029396}
2022-11-28 02:18:44,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:44,008 INFO:     Epoch: 28
2022-11-28 02:18:44,749 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4499570019543171, 'Total loss': 0.4499570019543171} | train loss {'Reaction outcome loss': 0.3151995380009924, 'Total loss': 0.3151995380009924}
2022-11-28 02:18:44,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:44,749 INFO:     Epoch: 29
2022-11-28 02:18:45,494 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.436361507258632, 'Total loss': 0.436361507258632} | train loss {'Reaction outcome loss': 0.32484018328238506, 'Total loss': 0.32484018328238506}
2022-11-28 02:18:45,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:45,495 INFO:     Epoch: 30
2022-11-28 02:18:46,246 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43515285646373575, 'Total loss': 0.43515285646373575} | train loss {'Reaction outcome loss': 0.31465546437063996, 'Total loss': 0.31465546437063996}
2022-11-28 02:18:46,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:46,247 INFO:     Epoch: 31
2022-11-28 02:18:46,994 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.406524968418208, 'Total loss': 0.406524968418208} | train loss {'Reaction outcome loss': 0.3221942530146667, 'Total loss': 0.3221942530146667}
2022-11-28 02:18:46,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:46,994 INFO:     Epoch: 32
2022-11-28 02:18:47,741 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4514937031675469, 'Total loss': 0.4514937031675469} | train loss {'Reaction outcome loss': 0.3135183212404348, 'Total loss': 0.3135183212404348}
2022-11-28 02:18:47,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:47,742 INFO:     Epoch: 33
2022-11-28 02:18:48,486 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42525203796950256, 'Total loss': 0.42525203796950256} | train loss {'Reaction outcome loss': 0.30671042054891584, 'Total loss': 0.30671042054891584}
2022-11-28 02:18:48,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:48,486 INFO:     Epoch: 34
2022-11-28 02:18:49,232 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40134497748857195, 'Total loss': 0.40134497748857195} | train loss {'Reaction outcome loss': 0.31456390891452224, 'Total loss': 0.31456390891452224}
2022-11-28 02:18:49,232 INFO:     Found new best model at epoch 34
2022-11-28 02:18:49,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:49,233 INFO:     Epoch: 35
2022-11-28 02:18:49,983 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4113818850706924, 'Total loss': 0.4113818850706924} | train loss {'Reaction outcome loss': 0.31441719224866554, 'Total loss': 0.31441719224866554}
2022-11-28 02:18:49,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:49,983 INFO:     Epoch: 36
2022-11-28 02:18:50,731 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4048195037652146, 'Total loss': 0.4048195037652146} | train loss {'Reaction outcome loss': 0.30309810206598164, 'Total loss': 0.30309810206598164}
2022-11-28 02:18:50,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:50,731 INFO:     Epoch: 37
2022-11-28 02:18:51,479 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42894937843084335, 'Total loss': 0.42894937843084335} | train loss {'Reaction outcome loss': 0.31025147553609345, 'Total loss': 0.31025147553609345}
2022-11-28 02:18:51,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:51,479 INFO:     Epoch: 38
2022-11-28 02:18:52,230 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43439438194036484, 'Total loss': 0.43439438194036484} | train loss {'Reaction outcome loss': 0.31480090301864, 'Total loss': 0.31480090301864}
2022-11-28 02:18:52,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:52,230 INFO:     Epoch: 39
2022-11-28 02:18:52,981 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4233320270749656, 'Total loss': 0.4233320270749656} | train loss {'Reaction outcome loss': 0.3090754132793874, 'Total loss': 0.3090754132793874}
2022-11-28 02:18:52,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:52,981 INFO:     Epoch: 40
2022-11-28 02:18:53,733 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45198365338993346, 'Total loss': 0.45198365338993346} | train loss {'Reaction outcome loss': 0.30194888601497727, 'Total loss': 0.30194888601497727}
2022-11-28 02:18:53,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:53,733 INFO:     Epoch: 41
2022-11-28 02:18:54,484 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41870778291062877, 'Total loss': 0.41870778291062877} | train loss {'Reaction outcome loss': 0.30637604265796897, 'Total loss': 0.30637604265796897}
2022-11-28 02:18:54,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:54,484 INFO:     Epoch: 42
2022-11-28 02:18:55,233 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4309375765310092, 'Total loss': 0.4309375765310092} | train loss {'Reaction outcome loss': 0.2973714492758926, 'Total loss': 0.2973714492758926}
2022-11-28 02:18:55,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:55,233 INFO:     Epoch: 43
2022-11-28 02:18:55,980 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4313166635957631, 'Total loss': 0.4313166635957631} | train loss {'Reaction outcome loss': 0.3123964505840321, 'Total loss': 0.3123964505840321}
2022-11-28 02:18:55,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:55,980 INFO:     Epoch: 44
2022-11-28 02:18:56,729 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4300066954032941, 'Total loss': 0.4300066954032941} | train loss {'Reaction outcome loss': 0.30311280993782747, 'Total loss': 0.30311280993782747}
2022-11-28 02:18:56,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:56,730 INFO:     Epoch: 45
2022-11-28 02:18:57,475 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42780200425874104, 'Total loss': 0.42780200425874104} | train loss {'Reaction outcome loss': 0.2999109822572494, 'Total loss': 0.2999109822572494}
2022-11-28 02:18:57,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:57,475 INFO:     Epoch: 46
2022-11-28 02:18:58,225 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41367670317942445, 'Total loss': 0.41367670317942445} | train loss {'Reaction outcome loss': 0.30758101959921874, 'Total loss': 0.30758101959921874}
2022-11-28 02:18:58,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:58,225 INFO:     Epoch: 47
2022-11-28 02:18:58,973 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4619267289950089, 'Total loss': 0.4619267289950089} | train loss {'Reaction outcome loss': 0.30818514051486035, 'Total loss': 0.30818514051486035}
2022-11-28 02:18:58,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:58,973 INFO:     Epoch: 48
2022-11-28 02:18:59,719 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43943010981787334, 'Total loss': 0.43943010981787334} | train loss {'Reaction outcome loss': 0.3071728113050364, 'Total loss': 0.3071728113050364}
2022-11-28 02:18:59,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:18:59,719 INFO:     Epoch: 49
2022-11-28 02:19:00,469 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4213279099626975, 'Total loss': 0.4213279099626975} | train loss {'Reaction outcome loss': 0.30257610417142206, 'Total loss': 0.30257610417142206}
2022-11-28 02:19:00,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:00,469 INFO:     Epoch: 50
2022-11-28 02:19:01,212 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41488198800520465, 'Total loss': 0.41488198800520465} | train loss {'Reaction outcome loss': 0.2949197867239008, 'Total loss': 0.2949197867239008}
2022-11-28 02:19:01,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:01,213 INFO:     Epoch: 51
2022-11-28 02:19:01,962 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4313309667631984, 'Total loss': 0.4313309667631984} | train loss {'Reaction outcome loss': 0.30144310876423, 'Total loss': 0.30144310876423}
2022-11-28 02:19:01,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:01,962 INFO:     Epoch: 52
2022-11-28 02:19:02,712 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41960152848200366, 'Total loss': 0.41960152848200366} | train loss {'Reaction outcome loss': 0.3029375014560563, 'Total loss': 0.3029375014560563}
2022-11-28 02:19:02,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:02,712 INFO:     Epoch: 53
2022-11-28 02:19:03,460 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41449016908353026, 'Total loss': 0.41449016908353026} | train loss {'Reaction outcome loss': 0.30755957462349715, 'Total loss': 0.30755957462349715}
2022-11-28 02:19:03,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:03,460 INFO:     Epoch: 54
2022-11-28 02:19:04,207 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4376478090204976, 'Total loss': 0.4376478090204976} | train loss {'Reaction outcome loss': 0.30707905170868854, 'Total loss': 0.30707905170868854}
2022-11-28 02:19:04,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:04,207 INFO:     Epoch: 55
2022-11-28 02:19:04,956 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4125562516803091, 'Total loss': 0.4125562516803091} | train loss {'Reaction outcome loss': 0.29974305746810775, 'Total loss': 0.29974305746810775}
2022-11-28 02:19:04,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:04,957 INFO:     Epoch: 56
2022-11-28 02:19:05,703 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.419175829061053, 'Total loss': 0.419175829061053} | train loss {'Reaction outcome loss': 0.2971229484798957, 'Total loss': 0.2971229484798957}
2022-11-28 02:19:05,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:05,704 INFO:     Epoch: 57
2022-11-28 02:19:06,450 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4666988212953914, 'Total loss': 0.4666988212953914} | train loss {'Reaction outcome loss': 0.30231216758185503, 'Total loss': 0.30231216758185503}
2022-11-28 02:19:06,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:06,450 INFO:     Epoch: 58
2022-11-28 02:19:07,197 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4316020817919211, 'Total loss': 0.4316020817919211} | train loss {'Reaction outcome loss': 0.29525691898805756, 'Total loss': 0.29525691898805756}
2022-11-28 02:19:07,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:07,197 INFO:     Epoch: 59
2022-11-28 02:19:07,943 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4589866521683606, 'Total loss': 0.4589866521683606} | train loss {'Reaction outcome loss': 0.30167036628236577, 'Total loss': 0.30167036628236577}
2022-11-28 02:19:07,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:07,943 INFO:     Epoch: 60
2022-11-28 02:19:08,688 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42333101769062603, 'Total loss': 0.42333101769062603} | train loss {'Reaction outcome loss': 0.2975810463027078, 'Total loss': 0.2975810463027078}
2022-11-28 02:19:08,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:08,688 INFO:     Epoch: 61
2022-11-28 02:19:09,435 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42377797548066487, 'Total loss': 0.42377797548066487} | train loss {'Reaction outcome loss': 0.29623318506138663, 'Total loss': 0.29623318506138663}
2022-11-28 02:19:09,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:09,435 INFO:     Epoch: 62
2022-11-28 02:19:10,180 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.450500834394585, 'Total loss': 0.450500834394585} | train loss {'Reaction outcome loss': 0.2975233656107163, 'Total loss': 0.2975233656107163}
2022-11-28 02:19:10,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:10,180 INFO:     Epoch: 63
2022-11-28 02:19:10,930 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4101187449625947, 'Total loss': 0.4101187449625947} | train loss {'Reaction outcome loss': 0.2966671249087976, 'Total loss': 0.2966671249087976}
2022-11-28 02:19:10,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:10,930 INFO:     Epoch: 64
2022-11-28 02:19:11,679 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4157628533853726, 'Total loss': 0.4157628533853726} | train loss {'Reaction outcome loss': 0.30468171022984447, 'Total loss': 0.30468171022984447}
2022-11-28 02:19:11,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:11,679 INFO:     Epoch: 65
2022-11-28 02:19:12,428 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47057112035426224, 'Total loss': 0.47057112035426224} | train loss {'Reaction outcome loss': 0.2912006727286747, 'Total loss': 0.2912006727286747}
2022-11-28 02:19:12,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:12,428 INFO:     Epoch: 66
2022-11-28 02:19:13,174 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.401876837015152, 'Total loss': 0.401876837015152} | train loss {'Reaction outcome loss': 0.30206026948836384, 'Total loss': 0.30206026948836384}
2022-11-28 02:19:13,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:13,175 INFO:     Epoch: 67
2022-11-28 02:19:13,919 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4227904166010293, 'Total loss': 0.4227904166010293} | train loss {'Reaction outcome loss': 0.2962030601288591, 'Total loss': 0.2962030601288591}
2022-11-28 02:19:13,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:13,919 INFO:     Epoch: 68
2022-11-28 02:19:14,665 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4243822389028289, 'Total loss': 0.4243822389028289} | train loss {'Reaction outcome loss': 0.3033733804615176, 'Total loss': 0.3033733804615176}
2022-11-28 02:19:14,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:14,665 INFO:     Epoch: 69
2022-11-28 02:19:15,411 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4029237480664795, 'Total loss': 0.4029237480664795} | train loss {'Reaction outcome loss': 0.2905833332210171, 'Total loss': 0.2905833332210171}
2022-11-28 02:19:15,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:15,412 INFO:     Epoch: 70
2022-11-28 02:19:16,160 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4326705659147013, 'Total loss': 0.4326705659147013} | train loss {'Reaction outcome loss': 0.2894405867068135, 'Total loss': 0.2894405867068135}
2022-11-28 02:19:16,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:16,160 INFO:     Epoch: 71
2022-11-28 02:19:16,909 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42988879487595777, 'Total loss': 0.42988879487595777} | train loss {'Reaction outcome loss': 0.28894935228994917, 'Total loss': 0.28894935228994917}
2022-11-28 02:19:16,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:16,909 INFO:     Epoch: 72
2022-11-28 02:19:17,654 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44133352414196864, 'Total loss': 0.44133352414196864} | train loss {'Reaction outcome loss': 0.2919519111209986, 'Total loss': 0.2919519111209986}
2022-11-28 02:19:17,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:17,654 INFO:     Epoch: 73
2022-11-28 02:19:18,403 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44076344472440804, 'Total loss': 0.44076344472440804} | train loss {'Reaction outcome loss': 0.30259143383223186, 'Total loss': 0.30259143383223186}
2022-11-28 02:19:18,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:18,403 INFO:     Epoch: 74
2022-11-28 02:19:19,149 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40467041375284846, 'Total loss': 0.40467041375284846} | train loss {'Reaction outcome loss': 0.29429887971099544, 'Total loss': 0.29429887971099544}
2022-11-28 02:19:19,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:19,149 INFO:     Epoch: 75
2022-11-28 02:19:19,897 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4243445596234365, 'Total loss': 0.4243445596234365} | train loss {'Reaction outcome loss': 0.2887884823947537, 'Total loss': 0.2887884823947537}
2022-11-28 02:19:19,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:19,897 INFO:     Epoch: 76
2022-11-28 02:19:20,645 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4150060367855159, 'Total loss': 0.4150060367855159} | train loss {'Reaction outcome loss': 0.3038203854493949, 'Total loss': 0.3038203854493949}
2022-11-28 02:19:20,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:20,645 INFO:     Epoch: 77
2022-11-28 02:19:21,391 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39590996046635235, 'Total loss': 0.39590996046635235} | train loss {'Reaction outcome loss': 0.290221575845261, 'Total loss': 0.290221575845261}
2022-11-28 02:19:21,391 INFO:     Found new best model at epoch 77
2022-11-28 02:19:21,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:21,392 INFO:     Epoch: 78
2022-11-28 02:19:22,134 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4292290434241295, 'Total loss': 0.4292290434241295} | train loss {'Reaction outcome loss': 0.2931337251498991, 'Total loss': 0.2931337251498991}
2022-11-28 02:19:22,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:22,134 INFO:     Epoch: 79
2022-11-28 02:19:22,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43486447716978466, 'Total loss': 0.43486447716978466} | train loss {'Reaction outcome loss': 0.29628139743391346, 'Total loss': 0.29628139743391346}
2022-11-28 02:19:22,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:22,877 INFO:     Epoch: 80
2022-11-28 02:19:23,628 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42032368752089416, 'Total loss': 0.42032368752089416} | train loss {'Reaction outcome loss': 0.292476112684425, 'Total loss': 0.292476112684425}
2022-11-28 02:19:23,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:23,628 INFO:     Epoch: 81
2022-11-28 02:19:24,376 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4574241651730104, 'Total loss': 0.4574241651730104} | train loss {'Reaction outcome loss': 0.29320756770214257, 'Total loss': 0.29320756770214257}
2022-11-28 02:19:24,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:24,377 INFO:     Epoch: 82
2022-11-28 02:19:25,123 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4022251105105335, 'Total loss': 0.4022251105105335} | train loss {'Reaction outcome loss': 0.30044251333694066, 'Total loss': 0.30044251333694066}
2022-11-28 02:19:25,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:25,123 INFO:     Epoch: 83
2022-11-28 02:19:25,868 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43794479593634605, 'Total loss': 0.43794479593634605} | train loss {'Reaction outcome loss': 0.3018338295878196, 'Total loss': 0.3018338295878196}
2022-11-28 02:19:25,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:25,868 INFO:     Epoch: 84
2022-11-28 02:19:26,615 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4209830385040153, 'Total loss': 0.4209830385040153} | train loss {'Reaction outcome loss': 0.2911881582013198, 'Total loss': 0.2911881582013198}
2022-11-28 02:19:26,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:26,615 INFO:     Epoch: 85
2022-11-28 02:19:27,360 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42535941472107713, 'Total loss': 0.42535941472107713} | train loss {'Reaction outcome loss': 0.29766921096918536, 'Total loss': 0.29766921096918536}
2022-11-28 02:19:27,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:27,360 INFO:     Epoch: 86
2022-11-28 02:19:28,106 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4154654189266942, 'Total loss': 0.4154654189266942} | train loss {'Reaction outcome loss': 0.29912963144633237, 'Total loss': 0.29912963144633237}
2022-11-28 02:19:28,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:28,107 INFO:     Epoch: 87
2022-11-28 02:19:28,854 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4483081227676435, 'Total loss': 0.4483081227676435} | train loss {'Reaction outcome loss': 0.29274943331066444, 'Total loss': 0.29274943331066444}
2022-11-28 02:19:28,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:28,854 INFO:     Epoch: 88
2022-11-28 02:19:29,599 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42007756792008877, 'Total loss': 0.42007756792008877} | train loss {'Reaction outcome loss': 0.3043695610396716, 'Total loss': 0.3043695610396716}
2022-11-28 02:19:29,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:29,599 INFO:     Epoch: 89
2022-11-28 02:19:30,344 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4453288387845863, 'Total loss': 0.4453288387845863} | train loss {'Reaction outcome loss': 0.28663530513948327, 'Total loss': 0.28663530513948327}
2022-11-28 02:19:30,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:30,344 INFO:     Epoch: 90
2022-11-28 02:19:31,096 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4104394112205641, 'Total loss': 0.4104394112205641} | train loss {'Reaction outcome loss': 0.2909340380709998, 'Total loss': 0.2909340380709998}
2022-11-28 02:19:31,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:31,096 INFO:     Epoch: 91
2022-11-28 02:19:31,844 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41262926042757253, 'Total loss': 0.41262926042757253} | train loss {'Reaction outcome loss': 0.29071463252208674, 'Total loss': 0.29071463252208674}
2022-11-28 02:19:31,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:31,844 INFO:     Epoch: 92
2022-11-28 02:19:32,589 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4066906144673174, 'Total loss': 0.4066906144673174} | train loss {'Reaction outcome loss': 0.2916606357511209, 'Total loss': 0.2916606357511209}
2022-11-28 02:19:32,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:32,589 INFO:     Epoch: 93
2022-11-28 02:19:33,331 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42133588885719125, 'Total loss': 0.42133588885719125} | train loss {'Reaction outcome loss': 0.28581549081267144, 'Total loss': 0.28581549081267144}
2022-11-28 02:19:33,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:33,331 INFO:     Epoch: 94
2022-11-28 02:19:34,079 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43438981456512754, 'Total loss': 0.43438981456512754} | train loss {'Reaction outcome loss': 0.29512840062379836, 'Total loss': 0.29512840062379836}
2022-11-28 02:19:34,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:34,080 INFO:     Epoch: 95
2022-11-28 02:19:34,825 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4557897658510642, 'Total loss': 0.4557897658510642} | train loss {'Reaction outcome loss': 0.29148934679676075, 'Total loss': 0.29148934679676075}
2022-11-28 02:19:34,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:34,825 INFO:     Epoch: 96
2022-11-28 02:19:35,575 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42457707175476983, 'Total loss': 0.42457707175476983} | train loss {'Reaction outcome loss': 0.29428620732256344, 'Total loss': 0.29428620732256344}
2022-11-28 02:19:35,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:35,575 INFO:     Epoch: 97
2022-11-28 02:19:36,320 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43521343340927904, 'Total loss': 0.43521343340927904} | train loss {'Reaction outcome loss': 0.2880999079164194, 'Total loss': 0.2880999079164194}
2022-11-28 02:19:36,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:36,321 INFO:     Epoch: 98
2022-11-28 02:19:37,071 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4311722605065866, 'Total loss': 0.4311722605065866} | train loss {'Reaction outcome loss': 0.29009945553784466, 'Total loss': 0.29009945553784466}
2022-11-28 02:19:37,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:37,071 INFO:     Epoch: 99
2022-11-28 02:19:37,815 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4387830749831416, 'Total loss': 0.4387830749831416} | train loss {'Reaction outcome loss': 0.2995271931345366, 'Total loss': 0.2995271931345366}
2022-11-28 02:19:37,815 INFO:     Best model found after epoch 78 of 100.
2022-11-28 02:19:37,815 INFO:   Done with stage: TRAINING
2022-11-28 02:19:37,815 INFO:   Starting stage: EVALUATION
2022-11-28 02:19:37,946 INFO:   Done with stage: EVALUATION
2022-11-28 02:19:37,954 INFO:   Leaving out SEQ value Fold_0
2022-11-28 02:19:37,967 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:19:37,967 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:19:38,606 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:19:38,606 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:19:38,674 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:19:38,674 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:19:38,674 INFO:     No hyperparam tuning for this model
2022-11-28 02:19:38,674 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:19:38,674 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:19:38,675 INFO:     None feature selector for col prot
2022-11-28 02:19:38,675 INFO:     None feature selector for col prot
2022-11-28 02:19:38,675 INFO:     None feature selector for col prot
2022-11-28 02:19:38,676 INFO:     None feature selector for col chem
2022-11-28 02:19:38,676 INFO:     None feature selector for col chem
2022-11-28 02:19:38,676 INFO:     None feature selector for col chem
2022-11-28 02:19:38,676 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:19:38,676 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:19:38,677 INFO:     Number of params in model 169741
2022-11-28 02:19:38,681 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:19:38,681 INFO:   Starting stage: TRAINING
2022-11-28 02:19:38,734 INFO:     Val loss before train {'Reaction outcome loss': 0.9587543200362812, 'Total loss': 0.9587543200362812}
2022-11-28 02:19:38,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:38,735 INFO:     Epoch: 0
2022-11-28 02:19:39,478 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5827648466960951, 'Total loss': 0.5827648466960951} | train loss {'Reaction outcome loss': 0.6313851720216322, 'Total loss': 0.6313851720216322}
2022-11-28 02:19:39,479 INFO:     Found new best model at epoch 0
2022-11-28 02:19:39,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:39,479 INFO:     Epoch: 1
2022-11-28 02:19:40,222 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.528064539148049, 'Total loss': 0.528064539148049} | train loss {'Reaction outcome loss': 0.4842024026476607, 'Total loss': 0.4842024026476607}
2022-11-28 02:19:40,222 INFO:     Found new best model at epoch 1
2022-11-28 02:19:40,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:40,223 INFO:     Epoch: 2
2022-11-28 02:19:40,967 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5200099504806779, 'Total loss': 0.5200099504806779} | train loss {'Reaction outcome loss': 0.44945995755949797, 'Total loss': 0.44945995755949797}
2022-11-28 02:19:40,968 INFO:     Found new best model at epoch 2
2022-11-28 02:19:40,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:40,968 INFO:     Epoch: 3
2022-11-28 02:19:41,710 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4522000757808035, 'Total loss': 0.4522000757808035} | train loss {'Reaction outcome loss': 0.4259357664049888, 'Total loss': 0.4259357664049888}
2022-11-28 02:19:41,710 INFO:     Found new best model at epoch 3
2022-11-28 02:19:41,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:41,711 INFO:     Epoch: 4
2022-11-28 02:19:42,455 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.472269649871371, 'Total loss': 0.472269649871371} | train loss {'Reaction outcome loss': 0.3988643727740463, 'Total loss': 0.3988643727740463}
2022-11-28 02:19:42,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:42,455 INFO:     Epoch: 5
2022-11-28 02:19:43,200 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4944182607260617, 'Total loss': 0.4944182607260617} | train loss {'Reaction outcome loss': 0.391983680062148, 'Total loss': 0.391983680062148}
2022-11-28 02:19:43,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:43,200 INFO:     Epoch: 6
2022-11-28 02:19:43,946 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5138791955330155, 'Total loss': 0.5138791955330155} | train loss {'Reaction outcome loss': 0.37478731447944835, 'Total loss': 0.37478731447944835}
2022-11-28 02:19:43,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:43,946 INFO:     Epoch: 7
2022-11-28 02:19:44,695 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47080938501114195, 'Total loss': 0.47080938501114195} | train loss {'Reaction outcome loss': 0.3809676707399135, 'Total loss': 0.3809676707399135}
2022-11-28 02:19:44,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:44,695 INFO:     Epoch: 8
2022-11-28 02:19:45,443 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47330187261104584, 'Total loss': 0.47330187261104584} | train loss {'Reaction outcome loss': 0.3778095590520878, 'Total loss': 0.3778095590520878}
2022-11-28 02:19:45,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:45,443 INFO:     Epoch: 9
2022-11-28 02:19:46,196 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.477371161295609, 'Total loss': 0.477371161295609} | train loss {'Reaction outcome loss': 0.36554242707028684, 'Total loss': 0.36554242707028684}
2022-11-28 02:19:46,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:46,197 INFO:     Epoch: 10
2022-11-28 02:19:46,939 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4604888361963359, 'Total loss': 0.4604888361963359} | train loss {'Reaction outcome loss': 0.3592824837687064, 'Total loss': 0.3592824837687064}
2022-11-28 02:19:46,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:46,939 INFO:     Epoch: 11
2022-11-28 02:19:47,681 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4614668088880452, 'Total loss': 0.4614668088880452} | train loss {'Reaction outcome loss': 0.3630192109516689, 'Total loss': 0.3630192109516689}
2022-11-28 02:19:47,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:47,681 INFO:     Epoch: 12
2022-11-28 02:19:48,421 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4816777682439847, 'Total loss': 0.4816777682439847} | train loss {'Reaction outcome loss': 0.3524244926413711, 'Total loss': 0.3524244926413711}
2022-11-28 02:19:48,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:48,421 INFO:     Epoch: 13
2022-11-28 02:19:49,163 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4590581812133843, 'Total loss': 0.4590581812133843} | train loss {'Reaction outcome loss': 0.34760510851534043, 'Total loss': 0.34760510851534043}
2022-11-28 02:19:49,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:49,164 INFO:     Epoch: 14
2022-11-28 02:19:49,905 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46183166720650415, 'Total loss': 0.46183166720650415} | train loss {'Reaction outcome loss': 0.3453138450882873, 'Total loss': 0.3453138450882873}
2022-11-28 02:19:49,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:49,905 INFO:     Epoch: 15
2022-11-28 02:19:50,651 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43325326490131294, 'Total loss': 0.43325326490131294} | train loss {'Reaction outcome loss': 0.3518065434025258, 'Total loss': 0.3518065434025258}
2022-11-28 02:19:50,652 INFO:     Found new best model at epoch 15
2022-11-28 02:19:50,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:50,652 INFO:     Epoch: 16
2022-11-28 02:19:51,398 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43291086788204586, 'Total loss': 0.43291086788204586} | train loss {'Reaction outcome loss': 0.3384018592080291, 'Total loss': 0.3384018592080291}
2022-11-28 02:19:51,398 INFO:     Found new best model at epoch 16
2022-11-28 02:19:51,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:51,399 INFO:     Epoch: 17
2022-11-28 02:19:52,140 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49769698015668173, 'Total loss': 0.49769698015668173} | train loss {'Reaction outcome loss': 0.3388489850017489, 'Total loss': 0.3388489850017489}
2022-11-28 02:19:52,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:52,140 INFO:     Epoch: 18
2022-11-28 02:19:52,881 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47967942465435376, 'Total loss': 0.47967942465435376} | train loss {'Reaction outcome loss': 0.34383532851934434, 'Total loss': 0.34383532851934434}
2022-11-28 02:19:52,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:52,881 INFO:     Epoch: 19
2022-11-28 02:19:53,626 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4400026158175685, 'Total loss': 0.4400026158175685} | train loss {'Reaction outcome loss': 0.32990239965064183, 'Total loss': 0.32990239965064183}
2022-11-28 02:19:53,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:53,626 INFO:     Epoch: 20
2022-11-28 02:19:54,368 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43802878531542694, 'Total loss': 0.43802878531542694} | train loss {'Reaction outcome loss': 0.3403466985694, 'Total loss': 0.3403466985694}
2022-11-28 02:19:54,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:54,368 INFO:     Epoch: 21
2022-11-28 02:19:55,112 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43643489869480784, 'Total loss': 0.43643489869480784} | train loss {'Reaction outcome loss': 0.3313057875754882, 'Total loss': 0.3313057875754882}
2022-11-28 02:19:55,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:55,113 INFO:     Epoch: 22
2022-11-28 02:19:55,856 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46488706005567854, 'Total loss': 0.46488706005567854} | train loss {'Reaction outcome loss': 0.3331625059247017, 'Total loss': 0.3331625059247017}
2022-11-28 02:19:55,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:55,856 INFO:     Epoch: 23
2022-11-28 02:19:56,601 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45678727328777313, 'Total loss': 0.45678727328777313} | train loss {'Reaction outcome loss': 0.3297597057053021, 'Total loss': 0.3297597057053021}
2022-11-28 02:19:56,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:56,602 INFO:     Epoch: 24
2022-11-28 02:19:57,345 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45255572348833084, 'Total loss': 0.45255572348833084} | train loss {'Reaction outcome loss': 0.32480039447546005, 'Total loss': 0.32480039447546005}
2022-11-28 02:19:57,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:57,345 INFO:     Epoch: 25
2022-11-28 02:19:58,086 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44470166753638873, 'Total loss': 0.44470166753638873} | train loss {'Reaction outcome loss': 0.33024238472690387, 'Total loss': 0.33024238472690387}
2022-11-28 02:19:58,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:58,087 INFO:     Epoch: 26
2022-11-28 02:19:58,828 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4403457130220803, 'Total loss': 0.4403457130220803} | train loss {'Reaction outcome loss': 0.32272968362180554, 'Total loss': 0.32272968362180554}
2022-11-28 02:19:58,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:58,828 INFO:     Epoch: 27
2022-11-28 02:19:59,571 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4479274285787886, 'Total loss': 0.4479274285787886} | train loss {'Reaction outcome loss': 0.3229327573764081, 'Total loss': 0.3229327573764081}
2022-11-28 02:19:59,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:19:59,572 INFO:     Epoch: 28
2022-11-28 02:20:00,315 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4739959013055671, 'Total loss': 0.4739959013055671} | train loss {'Reaction outcome loss': 0.33495877856502726, 'Total loss': 0.33495877856502726}
2022-11-28 02:20:00,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:00,315 INFO:     Epoch: 29
2022-11-28 02:20:01,063 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47709346088496124, 'Total loss': 0.47709346088496124} | train loss {'Reaction outcome loss': 0.3203029119238561, 'Total loss': 0.3203029119238561}
2022-11-28 02:20:01,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:01,064 INFO:     Epoch: 30
2022-11-28 02:20:01,810 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4496304341168566, 'Total loss': 0.4496304341168566} | train loss {'Reaction outcome loss': 0.32673400184329676, 'Total loss': 0.32673400184329676}
2022-11-28 02:20:01,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:01,810 INFO:     Epoch: 31
2022-11-28 02:20:02,552 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.437343384901231, 'Total loss': 0.437343384901231} | train loss {'Reaction outcome loss': 0.3229305880106225, 'Total loss': 0.3229305880106225}
2022-11-28 02:20:02,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:02,553 INFO:     Epoch: 32
2022-11-28 02:20:03,297 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4442501896145669, 'Total loss': 0.4442501896145669} | train loss {'Reaction outcome loss': 0.3209951453671163, 'Total loss': 0.3209951453671163}
2022-11-28 02:20:03,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:03,297 INFO:     Epoch: 33
2022-11-28 02:20:04,041 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43281521275639534, 'Total loss': 0.43281521275639534} | train loss {'Reaction outcome loss': 0.3185561561766936, 'Total loss': 0.3185561561766936}
2022-11-28 02:20:04,041 INFO:     Found new best model at epoch 33
2022-11-28 02:20:04,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:04,042 INFO:     Epoch: 34
2022-11-28 02:20:04,785 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4380157002332536, 'Total loss': 0.4380157002332536} | train loss {'Reaction outcome loss': 0.32973239266750765, 'Total loss': 0.32973239266750765}
2022-11-28 02:20:04,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:04,785 INFO:     Epoch: 35
2022-11-28 02:20:05,527 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4477907425977967, 'Total loss': 0.4477907425977967} | train loss {'Reaction outcome loss': 0.32195318809577395, 'Total loss': 0.32195318809577395}
2022-11-28 02:20:05,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:05,527 INFO:     Epoch: 36
2022-11-28 02:20:06,270 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45388011854480614, 'Total loss': 0.45388011854480614} | train loss {'Reaction outcome loss': 0.31939654785151383, 'Total loss': 0.31939654785151383}
2022-11-28 02:20:06,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:06,271 INFO:     Epoch: 37
2022-11-28 02:20:07,011 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42638686611528764, 'Total loss': 0.42638686611528764} | train loss {'Reaction outcome loss': 0.31552100152689583, 'Total loss': 0.31552100152689583}
2022-11-28 02:20:07,013 INFO:     Found new best model at epoch 37
2022-11-28 02:20:07,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:07,013 INFO:     Epoch: 38
2022-11-28 02:20:07,756 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4826208623972806, 'Total loss': 0.4826208623972806} | train loss {'Reaction outcome loss': 0.30622267379444473, 'Total loss': 0.30622267379444473}
2022-11-28 02:20:07,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:07,756 INFO:     Epoch: 39
2022-11-28 02:20:08,495 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4361125867475163, 'Total loss': 0.4361125867475163} | train loss {'Reaction outcome loss': 0.3287977138040017, 'Total loss': 0.3287977138040017}
2022-11-28 02:20:08,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:08,496 INFO:     Epoch: 40
2022-11-28 02:20:09,240 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44128232525492256, 'Total loss': 0.44128232525492256} | train loss {'Reaction outcome loss': 0.31079392062158, 'Total loss': 0.31079392062158}
2022-11-28 02:20:09,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:09,240 INFO:     Epoch: 41
2022-11-28 02:20:09,981 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44422314620830794, 'Total loss': 0.44422314620830794} | train loss {'Reaction outcome loss': 0.3150680409554316, 'Total loss': 0.3150680409554316}
2022-11-28 02:20:09,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:09,981 INFO:     Epoch: 42
2022-11-28 02:20:10,726 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4571623888120733, 'Total loss': 0.4571623888120733} | train loss {'Reaction outcome loss': 0.30991365278557853, 'Total loss': 0.30991365278557853}
2022-11-28 02:20:10,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:10,726 INFO:     Epoch: 43
2022-11-28 02:20:11,470 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4286145291883837, 'Total loss': 0.4286145291883837} | train loss {'Reaction outcome loss': 0.3157877384475907, 'Total loss': 0.3157877384475907}
2022-11-28 02:20:11,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:11,471 INFO:     Epoch: 44
2022-11-28 02:20:12,214 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4582590880719098, 'Total loss': 0.4582590880719098} | train loss {'Reaction outcome loss': 0.30856476584259346, 'Total loss': 0.30856476584259346}
2022-11-28 02:20:12,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:12,214 INFO:     Epoch: 45
2022-11-28 02:20:12,960 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47324464978142217, 'Total loss': 0.47324464978142217} | train loss {'Reaction outcome loss': 0.31594420717078814, 'Total loss': 0.31594420717078814}
2022-11-28 02:20:12,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:12,960 INFO:     Epoch: 46
2022-11-28 02:20:13,701 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45130684971809387, 'Total loss': 0.45130684971809387} | train loss {'Reaction outcome loss': 0.3091519073564179, 'Total loss': 0.3091519073564179}
2022-11-28 02:20:13,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:13,702 INFO:     Epoch: 47
2022-11-28 02:20:14,443 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4629936065863479, 'Total loss': 0.4629936065863479} | train loss {'Reaction outcome loss': 0.31565224023497834, 'Total loss': 0.31565224023497834}
2022-11-28 02:20:14,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:14,443 INFO:     Epoch: 48
2022-11-28 02:20:15,186 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4616266494108872, 'Total loss': 0.4616266494108872} | train loss {'Reaction outcome loss': 0.3078662064002485, 'Total loss': 0.3078662064002485}
2022-11-28 02:20:15,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:15,186 INFO:     Epoch: 49
2022-11-28 02:20:15,930 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46025480871850794, 'Total loss': 0.46025480871850794} | train loss {'Reaction outcome loss': 0.30743233433791567, 'Total loss': 0.30743233433791567}
2022-11-28 02:20:15,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:15,930 INFO:     Epoch: 50
2022-11-28 02:20:16,670 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45316537063230167, 'Total loss': 0.45316537063230167} | train loss {'Reaction outcome loss': 0.30810641527784116, 'Total loss': 0.30810641527784116}
2022-11-28 02:20:16,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:16,670 INFO:     Epoch: 51
2022-11-28 02:20:17,418 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4622254784811627, 'Total loss': 0.4622254784811627} | train loss {'Reaction outcome loss': 0.3032906668526786, 'Total loss': 0.3032906668526786}
2022-11-28 02:20:17,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:17,418 INFO:     Epoch: 52
2022-11-28 02:20:18,161 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47225492346015846, 'Total loss': 0.47225492346015846} | train loss {'Reaction outcome loss': 0.3064037556550941, 'Total loss': 0.3064037556550941}
2022-11-28 02:20:18,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:18,162 INFO:     Epoch: 53
2022-11-28 02:20:18,902 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43904128433628514, 'Total loss': 0.43904128433628514} | train loss {'Reaction outcome loss': 0.30538436080120046, 'Total loss': 0.30538436080120046}
2022-11-28 02:20:18,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:18,902 INFO:     Epoch: 54
2022-11-28 02:20:19,649 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48078738593242387, 'Total loss': 0.48078738593242387} | train loss {'Reaction outcome loss': 0.30366910346308534, 'Total loss': 0.30366910346308534}
2022-11-28 02:20:19,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:19,649 INFO:     Epoch: 55
2022-11-28 02:20:20,390 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5180193016474898, 'Total loss': 0.5180193016474898} | train loss {'Reaction outcome loss': 0.30465896642025636, 'Total loss': 0.30465896642025636}
2022-11-28 02:20:20,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:20,390 INFO:     Epoch: 56
2022-11-28 02:20:21,134 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4744655029340224, 'Total loss': 0.4744655029340224} | train loss {'Reaction outcome loss': 0.30197041354009085, 'Total loss': 0.30197041354009085}
2022-11-28 02:20:21,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:21,135 INFO:     Epoch: 57
2022-11-28 02:20:21,882 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46343095058744604, 'Total loss': 0.46343095058744604} | train loss {'Reaction outcome loss': 0.304539380678717, 'Total loss': 0.304539380678717}
2022-11-28 02:20:21,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:21,882 INFO:     Epoch: 58
2022-11-28 02:20:22,626 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45451720600778406, 'Total loss': 0.45451720600778406} | train loss {'Reaction outcome loss': 0.3097170957193083, 'Total loss': 0.3097170957193083}
2022-11-28 02:20:22,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:22,627 INFO:     Epoch: 59
2022-11-28 02:20:23,370 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43917129578238184, 'Total loss': 0.43917129578238184} | train loss {'Reaction outcome loss': 0.3020852722987837, 'Total loss': 0.3020852722987837}
2022-11-28 02:20:23,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:23,370 INFO:     Epoch: 60
2022-11-28 02:20:24,115 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45672734860669484, 'Total loss': 0.45672734860669484} | train loss {'Reaction outcome loss': 0.30798475277058934, 'Total loss': 0.30798475277058934}
2022-11-28 02:20:24,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:24,115 INFO:     Epoch: 61
2022-11-28 02:20:24,860 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4431436008334541, 'Total loss': 0.4431436008334541} | train loss {'Reaction outcome loss': 0.2985132888263586, 'Total loss': 0.2985132888263586}
2022-11-28 02:20:24,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:24,860 INFO:     Epoch: 62
2022-11-28 02:20:25,601 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43088552288033743, 'Total loss': 0.43088552288033743} | train loss {'Reaction outcome loss': 0.29840356823132963, 'Total loss': 0.29840356823132963}
2022-11-28 02:20:25,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:25,601 INFO:     Epoch: 63
2022-11-28 02:20:26,347 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43230942873792216, 'Total loss': 0.43230942873792216} | train loss {'Reaction outcome loss': 0.3026820960397623, 'Total loss': 0.3026820960397623}
2022-11-28 02:20:26,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:26,347 INFO:     Epoch: 64
2022-11-28 02:20:27,090 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4535747254267335, 'Total loss': 0.4535747254267335} | train loss {'Reaction outcome loss': 0.3147153496742249, 'Total loss': 0.3147153496742249}
2022-11-28 02:20:27,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:27,090 INFO:     Epoch: 65
2022-11-28 02:20:27,834 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5256952764889733, 'Total loss': 0.5256952764889733} | train loss {'Reaction outcome loss': 0.3035708512882797, 'Total loss': 0.3035708512882797}
2022-11-28 02:20:27,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:27,834 INFO:     Epoch: 66
2022-11-28 02:20:28,576 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4481303170323372, 'Total loss': 0.4481303170323372} | train loss {'Reaction outcome loss': 0.31266171480624044, 'Total loss': 0.31266171480624044}
2022-11-28 02:20:28,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:28,576 INFO:     Epoch: 67
2022-11-28 02:20:29,319 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.439914618703452, 'Total loss': 0.439914618703452} | train loss {'Reaction outcome loss': 0.3017521878438337, 'Total loss': 0.3017521878438337}
2022-11-28 02:20:29,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:29,319 INFO:     Epoch: 68
2022-11-28 02:20:30,062 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46119625798680564, 'Total loss': 0.46119625798680564} | train loss {'Reaction outcome loss': 0.29580761361487057, 'Total loss': 0.29580761361487057}
2022-11-28 02:20:30,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:30,063 INFO:     Epoch: 69
2022-11-28 02:20:30,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46104275875470857, 'Total loss': 0.46104275875470857} | train loss {'Reaction outcome loss': 0.31112956340823855, 'Total loss': 0.31112956340823855}
2022-11-28 02:20:30,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:30,805 INFO:     Epoch: 70
2022-11-28 02:20:31,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45560321787541563, 'Total loss': 0.45560321787541563} | train loss {'Reaction outcome loss': 0.3009457245469093, 'Total loss': 0.3009457245469093}
2022-11-28 02:20:31,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:31,551 INFO:     Epoch: 71
2022-11-28 02:20:32,299 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43589330769397994, 'Total loss': 0.43589330769397994} | train loss {'Reaction outcome loss': 0.30406923811046443, 'Total loss': 0.30406923811046443}
2022-11-28 02:20:32,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:32,299 INFO:     Epoch: 72
2022-11-28 02:20:33,043 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4548882618546486, 'Total loss': 0.4548882618546486} | train loss {'Reaction outcome loss': 0.30214376556021827, 'Total loss': 0.30214376556021827}
2022-11-28 02:20:33,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:33,043 INFO:     Epoch: 73
2022-11-28 02:20:33,785 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4628433453088457, 'Total loss': 0.4628433453088457} | train loss {'Reaction outcome loss': 0.29958952422044716, 'Total loss': 0.29958952422044716}
2022-11-28 02:20:33,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:33,785 INFO:     Epoch: 74
2022-11-28 02:20:34,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46717425977641885, 'Total loss': 0.46717425977641885} | train loss {'Reaction outcome loss': 0.30587691812186824, 'Total loss': 0.30587691812186824}
2022-11-28 02:20:34,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:34,534 INFO:     Epoch: 75
2022-11-28 02:20:35,279 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43021451647986064, 'Total loss': 0.43021451647986064} | train loss {'Reaction outcome loss': 0.3003037042459663, 'Total loss': 0.3003037042459663}
2022-11-28 02:20:35,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:35,279 INFO:     Epoch: 76
2022-11-28 02:20:36,021 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4575432108884508, 'Total loss': 0.4575432108884508} | train loss {'Reaction outcome loss': 0.3034068022455488, 'Total loss': 0.3034068022455488}
2022-11-28 02:20:36,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:36,021 INFO:     Epoch: 77
2022-11-28 02:20:36,769 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45328259451145475, 'Total loss': 0.45328259451145475} | train loss {'Reaction outcome loss': 0.30449784671773716, 'Total loss': 0.30449784671773716}
2022-11-28 02:20:36,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:36,769 INFO:     Epoch: 78
2022-11-28 02:20:37,513 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42563183732669463, 'Total loss': 0.42563183732669463} | train loss {'Reaction outcome loss': 0.3021771531932208, 'Total loss': 0.3021771531932208}
2022-11-28 02:20:37,514 INFO:     Found new best model at epoch 78
2022-11-28 02:20:37,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:37,514 INFO:     Epoch: 79
2022-11-28 02:20:38,258 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43170076877471397, 'Total loss': 0.43170076877471397} | train loss {'Reaction outcome loss': 0.30792986867683275, 'Total loss': 0.30792986867683275}
2022-11-28 02:20:38,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:38,260 INFO:     Epoch: 80
2022-11-28 02:20:39,003 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.462602031163194, 'Total loss': 0.462602031163194} | train loss {'Reaction outcome loss': 0.30114559880932984, 'Total loss': 0.30114559880932984}
2022-11-28 02:20:39,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:39,003 INFO:     Epoch: 81
2022-11-28 02:20:39,742 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.471145728179677, 'Total loss': 0.471145728179677} | train loss {'Reaction outcome loss': 0.306459435334011, 'Total loss': 0.306459435334011}
2022-11-28 02:20:39,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:39,743 INFO:     Epoch: 82
2022-11-28 02:20:40,487 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4686796878549186, 'Total loss': 0.4686796878549186} | train loss {'Reaction outcome loss': 0.3028797660555158, 'Total loss': 0.3028797660555158}
2022-11-28 02:20:40,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:40,487 INFO:     Epoch: 83
2022-11-28 02:20:41,229 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42329039898785675, 'Total loss': 0.42329039898785675} | train loss {'Reaction outcome loss': 0.3021906925251289, 'Total loss': 0.3021906925251289}
2022-11-28 02:20:41,229 INFO:     Found new best model at epoch 83
2022-11-28 02:20:41,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:41,230 INFO:     Epoch: 84
2022-11-28 02:20:41,973 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4228951866653832, 'Total loss': 0.4228951866653832} | train loss {'Reaction outcome loss': 0.29162568887885737, 'Total loss': 0.29162568887885737}
2022-11-28 02:20:41,974 INFO:     Found new best model at epoch 84
2022-11-28 02:20:41,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:41,974 INFO:     Epoch: 85
2022-11-28 02:20:42,717 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4099906837059693, 'Total loss': 0.4099906837059693} | train loss {'Reaction outcome loss': 0.29993112923539417, 'Total loss': 0.29993112923539417}
2022-11-28 02:20:42,717 INFO:     Found new best model at epoch 85
2022-11-28 02:20:42,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:42,718 INFO:     Epoch: 86
2022-11-28 02:20:43,461 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4346509946679527, 'Total loss': 0.4346509946679527} | train loss {'Reaction outcome loss': 0.29439650632593095, 'Total loss': 0.29439650632593095}
2022-11-28 02:20:43,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:43,462 INFO:     Epoch: 87
2022-11-28 02:20:44,208 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5119516216218472, 'Total loss': 0.5119516216218472} | train loss {'Reaction outcome loss': 0.29001656667310366, 'Total loss': 0.29001656667310366}
2022-11-28 02:20:44,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:44,208 INFO:     Epoch: 88
2022-11-28 02:20:44,955 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45324931530789897, 'Total loss': 0.45324931530789897} | train loss {'Reaction outcome loss': 0.3035490390293452, 'Total loss': 0.3035490390293452}
2022-11-28 02:20:44,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:44,955 INFO:     Epoch: 89
2022-11-28 02:20:45,696 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4243828081949191, 'Total loss': 0.4243828081949191} | train loss {'Reaction outcome loss': 0.30155894912931386, 'Total loss': 0.30155894912931386}
2022-11-28 02:20:45,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:45,697 INFO:     Epoch: 90
2022-11-28 02:20:46,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4393378939818252, 'Total loss': 0.4393378939818252} | train loss {'Reaction outcome loss': 0.29699800899442363, 'Total loss': 0.29699800899442363}
2022-11-28 02:20:46,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:46,441 INFO:     Epoch: 91
2022-11-28 02:20:47,184 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4655802275308154, 'Total loss': 0.4655802275308154} | train loss {'Reaction outcome loss': 0.29090546777053755, 'Total loss': 0.29090546777053755}
2022-11-28 02:20:47,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:47,184 INFO:     Epoch: 92
2022-11-28 02:20:47,926 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4520755670964718, 'Total loss': 0.4520755670964718} | train loss {'Reaction outcome loss': 0.3078535690903664, 'Total loss': 0.3078535690903664}
2022-11-28 02:20:47,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:47,926 INFO:     Epoch: 93
2022-11-28 02:20:48,667 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43732115998864174, 'Total loss': 0.43732115998864174} | train loss {'Reaction outcome loss': 0.29577269672739265, 'Total loss': 0.29577269672739265}
2022-11-28 02:20:48,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:48,667 INFO:     Epoch: 94
2022-11-28 02:20:49,409 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5014140521260825, 'Total loss': 0.5014140521260825} | train loss {'Reaction outcome loss': 0.29390515002365014, 'Total loss': 0.29390515002365014}
2022-11-28 02:20:49,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:49,410 INFO:     Epoch: 95
2022-11-28 02:20:50,154 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4404069889675487, 'Total loss': 0.4404069889675487} | train loss {'Reaction outcome loss': 0.29416605485033015, 'Total loss': 0.29416605485033015}
2022-11-28 02:20:50,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:50,154 INFO:     Epoch: 96
2022-11-28 02:20:50,898 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43751814334907313, 'Total loss': 0.43751814334907313} | train loss {'Reaction outcome loss': 0.29901053735188077, 'Total loss': 0.29901053735188077}
2022-11-28 02:20:50,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:50,898 INFO:     Epoch: 97
2022-11-28 02:20:51,643 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46188246086239815, 'Total loss': 0.46188246086239815} | train loss {'Reaction outcome loss': 0.2964300327307107, 'Total loss': 0.2964300327307107}
2022-11-28 02:20:51,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:51,643 INFO:     Epoch: 98
2022-11-28 02:20:52,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4518201862546531, 'Total loss': 0.4518201862546531} | train loss {'Reaction outcome loss': 0.2863818183237193, 'Total loss': 0.2863818183237193}
2022-11-28 02:20:52,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:52,388 INFO:     Epoch: 99
2022-11-28 02:20:53,130 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4836078787391836, 'Total loss': 0.4836078787391836} | train loss {'Reaction outcome loss': 0.29132171358381, 'Total loss': 0.29132171358381}
2022-11-28 02:20:53,130 INFO:     Best model found after epoch 86 of 100.
2022-11-28 02:20:53,131 INFO:   Done with stage: TRAINING
2022-11-28 02:20:53,131 INFO:   Starting stage: EVALUATION
2022-11-28 02:20:53,261 INFO:   Done with stage: EVALUATION
2022-11-28 02:20:53,262 INFO:   Leaving out SEQ value Fold_1
2022-11-28 02:20:53,275 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:20:53,275 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:20:53,920 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:20:53,920 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:20:53,988 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:20:53,988 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:20:53,988 INFO:     No hyperparam tuning for this model
2022-11-28 02:20:53,988 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:20:53,988 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:20:53,989 INFO:     None feature selector for col prot
2022-11-28 02:20:53,989 INFO:     None feature selector for col prot
2022-11-28 02:20:53,989 INFO:     None feature selector for col prot
2022-11-28 02:20:53,990 INFO:     None feature selector for col chem
2022-11-28 02:20:53,990 INFO:     None feature selector for col chem
2022-11-28 02:20:53,990 INFO:     None feature selector for col chem
2022-11-28 02:20:53,990 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:20:53,990 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:20:53,992 INFO:     Number of params in model 169741
2022-11-28 02:20:53,995 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:20:53,995 INFO:   Starting stage: TRAINING
2022-11-28 02:20:54,049 INFO:     Val loss before train {'Reaction outcome loss': 1.016914970495484, 'Total loss': 1.016914970495484}
2022-11-28 02:20:54,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:54,049 INFO:     Epoch: 0
2022-11-28 02:20:54,798 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5733158568089659, 'Total loss': 0.5733158568089659} | train loss {'Reaction outcome loss': 0.639955423772335, 'Total loss': 0.639955423772335}
2022-11-28 02:20:54,798 INFO:     Found new best model at epoch 0
2022-11-28 02:20:54,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:54,799 INFO:     Epoch: 1
2022-11-28 02:20:55,543 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5144455768167973, 'Total loss': 0.5144455768167973} | train loss {'Reaction outcome loss': 0.5116069120192818, 'Total loss': 0.5116069120192818}
2022-11-28 02:20:55,543 INFO:     Found new best model at epoch 1
2022-11-28 02:20:55,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:55,544 INFO:     Epoch: 2
2022-11-28 02:20:56,292 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.481769976968115, 'Total loss': 0.481769976968115} | train loss {'Reaction outcome loss': 0.4718494699430852, 'Total loss': 0.4718494699430852}
2022-11-28 02:20:56,292 INFO:     Found new best model at epoch 2
2022-11-28 02:20:56,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:56,293 INFO:     Epoch: 3
2022-11-28 02:20:57,041 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4893283293667165, 'Total loss': 0.4893283293667165} | train loss {'Reaction outcome loss': 0.4405458091724257, 'Total loss': 0.4405458091724257}
2022-11-28 02:20:57,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:57,042 INFO:     Epoch: 4
2022-11-28 02:20:57,786 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5570783025839112, 'Total loss': 0.5570783025839112} | train loss {'Reaction outcome loss': 0.44203410774228064, 'Total loss': 0.44203410774228064}
2022-11-28 02:20:57,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:57,786 INFO:     Epoch: 5
2022-11-28 02:20:58,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47235890613360837, 'Total loss': 0.47235890613360837} | train loss {'Reaction outcome loss': 0.4187322500866917, 'Total loss': 0.4187322500866917}
2022-11-28 02:20:58,538 INFO:     Found new best model at epoch 5
2022-11-28 02:20:58,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:58,539 INFO:     Epoch: 6
2022-11-28 02:20:59,291 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46400053866884927, 'Total loss': 0.46400053866884927} | train loss {'Reaction outcome loss': 0.4086400239468224, 'Total loss': 0.4086400239468224}
2022-11-28 02:20:59,291 INFO:     Found new best model at epoch 6
2022-11-28 02:20:59,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:20:59,292 INFO:     Epoch: 7
2022-11-28 02:21:00,039 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43828476626764645, 'Total loss': 0.43828476626764645} | train loss {'Reaction outcome loss': 0.3977151231063522, 'Total loss': 0.3977151231063522}
2022-11-28 02:21:00,039 INFO:     Found new best model at epoch 7
2022-11-28 02:21:00,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:00,040 INFO:     Epoch: 8
2022-11-28 02:21:00,788 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.495992950079116, 'Total loss': 0.495992950079116} | train loss {'Reaction outcome loss': 0.3878015895272315, 'Total loss': 0.3878015895272315}
2022-11-28 02:21:00,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:00,788 INFO:     Epoch: 9
2022-11-28 02:21:01,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45874683423475787, 'Total loss': 0.45874683423475787} | train loss {'Reaction outcome loss': 0.38865450778712146, 'Total loss': 0.38865450778712146}
2022-11-28 02:21:01,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:01,534 INFO:     Epoch: 10
2022-11-28 02:21:02,281 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5131923993202773, 'Total loss': 0.5131923993202773} | train loss {'Reaction outcome loss': 0.3897690739678709, 'Total loss': 0.3897690739678709}
2022-11-28 02:21:02,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:02,281 INFO:     Epoch: 11
2022-11-28 02:21:03,029 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4519685147838159, 'Total loss': 0.4519685147838159} | train loss {'Reaction outcome loss': 0.372035695643349, 'Total loss': 0.372035695643349}
2022-11-28 02:21:03,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:03,029 INFO:     Epoch: 12
2022-11-28 02:21:03,773 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45535921915010974, 'Total loss': 0.45535921915010974} | train loss {'Reaction outcome loss': 0.3650760638267405, 'Total loss': 0.3650760638267405}
2022-11-28 02:21:03,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:03,773 INFO:     Epoch: 13
2022-11-28 02:21:04,521 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4240701405162161, 'Total loss': 0.4240701405162161} | train loss {'Reaction outcome loss': 0.367570809205534, 'Total loss': 0.367570809205534}
2022-11-28 02:21:04,521 INFO:     Found new best model at epoch 13
2022-11-28 02:21:04,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:04,522 INFO:     Epoch: 14
2022-11-28 02:21:05,268 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4365126358514482, 'Total loss': 0.4365126358514482} | train loss {'Reaction outcome loss': 0.3659588459592599, 'Total loss': 0.3659588459592599}
2022-11-28 02:21:05,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:05,268 INFO:     Epoch: 15
2022-11-28 02:21:06,015 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4236473630775105, 'Total loss': 0.4236473630775105} | train loss {'Reaction outcome loss': 0.36568503467901514, 'Total loss': 0.36568503467901514}
2022-11-28 02:21:06,015 INFO:     Found new best model at epoch 15
2022-11-28 02:21:06,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:06,016 INFO:     Epoch: 16
2022-11-28 02:21:06,766 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47941721806472, 'Total loss': 0.47941721806472} | train loss {'Reaction outcome loss': 0.3565767306517734, 'Total loss': 0.3565767306517734}
2022-11-28 02:21:06,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:06,766 INFO:     Epoch: 17
2022-11-28 02:21:07,511 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44972252913496713, 'Total loss': 0.44972252913496713} | train loss {'Reaction outcome loss': 0.36067711890709064, 'Total loss': 0.36067711890709064}
2022-11-28 02:21:07,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:07,511 INFO:     Epoch: 18
2022-11-28 02:21:08,259 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4790993678298863, 'Total loss': 0.4790993678298863} | train loss {'Reaction outcome loss': 0.3524986739734165, 'Total loss': 0.3524986739734165}
2022-11-28 02:21:08,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:08,259 INFO:     Epoch: 19
2022-11-28 02:21:09,009 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4240497663955797, 'Total loss': 0.4240497663955797} | train loss {'Reaction outcome loss': 0.3531102996530682, 'Total loss': 0.3531102996530682}
2022-11-28 02:21:09,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:09,010 INFO:     Epoch: 20
2022-11-28 02:21:09,756 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4211608797989108, 'Total loss': 0.4211608797989108} | train loss {'Reaction outcome loss': 0.342788710918745, 'Total loss': 0.342788710918745}
2022-11-28 02:21:09,756 INFO:     Found new best model at epoch 20
2022-11-28 02:21:09,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:09,757 INFO:     Epoch: 21
2022-11-28 02:21:10,502 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40747925300489773, 'Total loss': 0.40747925300489773} | train loss {'Reaction outcome loss': 0.36010075864280283, 'Total loss': 0.36010075864280283}
2022-11-28 02:21:10,503 INFO:     Found new best model at epoch 21
2022-11-28 02:21:10,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:10,503 INFO:     Epoch: 22
2022-11-28 02:21:11,251 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4311087825758891, 'Total loss': 0.4311087825758891} | train loss {'Reaction outcome loss': 0.36067607947568664, 'Total loss': 0.36067607947568664}
2022-11-28 02:21:11,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:11,252 INFO:     Epoch: 23
2022-11-28 02:21:11,996 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4367540390654044, 'Total loss': 0.4367540390654044} | train loss {'Reaction outcome loss': 0.34502835767173967, 'Total loss': 0.34502835767173967}
2022-11-28 02:21:11,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:11,996 INFO:     Epoch: 24
2022-11-28 02:21:12,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45242071795192634, 'Total loss': 0.45242071795192634} | train loss {'Reaction outcome loss': 0.3385372918725074, 'Total loss': 0.3385372918725074}
2022-11-28 02:21:12,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:12,743 INFO:     Epoch: 25
2022-11-28 02:21:13,490 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4761062694544142, 'Total loss': 0.4761062694544142} | train loss {'Reaction outcome loss': 0.34922604419683156, 'Total loss': 0.34922604419683156}
2022-11-28 02:21:13,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:13,490 INFO:     Epoch: 26
2022-11-28 02:21:14,240 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.435700403357094, 'Total loss': 0.435700403357094} | train loss {'Reaction outcome loss': 0.35334744492191295, 'Total loss': 0.35334744492191295}
2022-11-28 02:21:14,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:14,240 INFO:     Epoch: 27
2022-11-28 02:21:14,987 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4520388638431376, 'Total loss': 0.4520388638431376} | train loss {'Reaction outcome loss': 0.33482098500508256, 'Total loss': 0.33482098500508256}
2022-11-28 02:21:14,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:14,987 INFO:     Epoch: 28
2022-11-28 02:21:15,732 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41252450814301317, 'Total loss': 0.41252450814301317} | train loss {'Reaction outcome loss': 0.3452317116533214, 'Total loss': 0.3452317116533214}
2022-11-28 02:21:15,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:15,733 INFO:     Epoch: 29
2022-11-28 02:21:16,480 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41893966563723306, 'Total loss': 0.41893966563723306} | train loss {'Reaction outcome loss': 0.3425997831945417, 'Total loss': 0.3425997831945417}
2022-11-28 02:21:16,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:16,481 INFO:     Epoch: 30
2022-11-28 02:21:17,225 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4426948560232466, 'Total loss': 0.4426948560232466} | train loss {'Reaction outcome loss': 0.32922029683766096, 'Total loss': 0.32922029683766096}
2022-11-28 02:21:17,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:17,225 INFO:     Epoch: 31
2022-11-28 02:21:17,971 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44526171244003554, 'Total loss': 0.44526171244003554} | train loss {'Reaction outcome loss': 0.3416438965194742, 'Total loss': 0.3416438965194742}
2022-11-28 02:21:17,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:17,971 INFO:     Epoch: 32
2022-11-28 02:21:18,717 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4272584044797854, 'Total loss': 0.4272584044797854} | train loss {'Reaction outcome loss': 0.3311296086701817, 'Total loss': 0.3311296086701817}
2022-11-28 02:21:18,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:18,718 INFO:     Epoch: 33
2022-11-28 02:21:19,466 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43890188803726976, 'Total loss': 0.43890188803726976} | train loss {'Reaction outcome loss': 0.33331900210636345, 'Total loss': 0.33331900210636345}
2022-11-28 02:21:19,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:19,466 INFO:     Epoch: 34
2022-11-28 02:21:20,214 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42438060316172516, 'Total loss': 0.42438060316172516} | train loss {'Reaction outcome loss': 0.3507509851745266, 'Total loss': 0.3507509851745266}
2022-11-28 02:21:20,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:20,214 INFO:     Epoch: 35
2022-11-28 02:21:20,963 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40028473700989375, 'Total loss': 0.40028473700989375} | train loss {'Reaction outcome loss': 0.3302222305856012, 'Total loss': 0.3302222305856012}
2022-11-28 02:21:20,963 INFO:     Found new best model at epoch 35
2022-11-28 02:21:20,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:20,964 INFO:     Epoch: 36
2022-11-28 02:21:21,713 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48111407831311226, 'Total loss': 0.48111407831311226} | train loss {'Reaction outcome loss': 0.341082630128513, 'Total loss': 0.341082630128513}
2022-11-28 02:21:21,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:21,713 INFO:     Epoch: 37
2022-11-28 02:21:22,462 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45598886060443794, 'Total loss': 0.45598886060443794} | train loss {'Reaction outcome loss': 0.35560229529253384, 'Total loss': 0.35560229529253384}
2022-11-28 02:21:22,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:22,462 INFO:     Epoch: 38
2022-11-28 02:21:23,209 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4073383469473232, 'Total loss': 0.4073383469473232} | train loss {'Reaction outcome loss': 0.33650513391504405, 'Total loss': 0.33650513391504405}
2022-11-28 02:21:23,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:23,209 INFO:     Epoch: 39
2022-11-28 02:21:23,956 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47844545339996164, 'Total loss': 0.47844545339996164} | train loss {'Reaction outcome loss': 0.32208210000625026, 'Total loss': 0.32208210000625026}
2022-11-28 02:21:23,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:23,957 INFO:     Epoch: 40
2022-11-28 02:21:24,706 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44446231865070085, 'Total loss': 0.44446231865070085} | train loss {'Reaction outcome loss': 0.3397843940598279, 'Total loss': 0.3397843940598279}
2022-11-28 02:21:24,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:24,706 INFO:     Epoch: 41
2022-11-28 02:21:25,457 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4640424554659562, 'Total loss': 0.4640424554659562} | train loss {'Reaction outcome loss': 0.33666772829738223, 'Total loss': 0.33666772829738223}
2022-11-28 02:21:25,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:25,457 INFO:     Epoch: 42
2022-11-28 02:21:26,207 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4425745325332338, 'Total loss': 0.4425745325332338} | train loss {'Reaction outcome loss': 0.3452360701223134, 'Total loss': 0.3452360701223134}
2022-11-28 02:21:26,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:26,207 INFO:     Epoch: 43
2022-11-28 02:21:26,957 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4553892073983496, 'Total loss': 0.4553892073983496} | train loss {'Reaction outcome loss': 0.33538866575773396, 'Total loss': 0.33538866575773396}
2022-11-28 02:21:26,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:26,957 INFO:     Epoch: 44
2022-11-28 02:21:27,701 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43254812908443535, 'Total loss': 0.43254812908443535} | train loss {'Reaction outcome loss': 0.3270221940224787, 'Total loss': 0.3270221940224787}
2022-11-28 02:21:27,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:27,701 INFO:     Epoch: 45
2022-11-28 02:21:28,447 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4431547952646559, 'Total loss': 0.4431547952646559} | train loss {'Reaction outcome loss': 0.3276917838193627, 'Total loss': 0.3276917838193627}
2022-11-28 02:21:28,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:28,448 INFO:     Epoch: 46
2022-11-28 02:21:29,193 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41538677271455526, 'Total loss': 0.41538677271455526} | train loss {'Reaction outcome loss': 0.329891566525549, 'Total loss': 0.329891566525549}
2022-11-28 02:21:29,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:29,194 INFO:     Epoch: 47
2022-11-28 02:21:29,938 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4435563615777276, 'Total loss': 0.4435563615777276} | train loss {'Reaction outcome loss': 0.32043752166242734, 'Total loss': 0.32043752166242734}
2022-11-28 02:21:29,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:29,939 INFO:     Epoch: 48
2022-11-28 02:21:30,686 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41217448528517375, 'Total loss': 0.41217448528517375} | train loss {'Reaction outcome loss': 0.3311118763618865, 'Total loss': 0.3311118763618865}
2022-11-28 02:21:30,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:30,686 INFO:     Epoch: 49
2022-11-28 02:21:31,434 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44716268235986883, 'Total loss': 0.44716268235986883} | train loss {'Reaction outcome loss': 0.3365089584458695, 'Total loss': 0.3365089584458695}
2022-11-28 02:21:31,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:31,434 INFO:     Epoch: 50
2022-11-28 02:21:32,184 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4458120373839682, 'Total loss': 0.4458120373839682} | train loss {'Reaction outcome loss': 0.3381292907377848, 'Total loss': 0.3381292907377848}
2022-11-28 02:21:32,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:32,184 INFO:     Epoch: 51
2022-11-28 02:21:32,934 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4282057148150422, 'Total loss': 0.4282057148150422} | train loss {'Reaction outcome loss': 0.3204169896422312, 'Total loss': 0.3204169896422312}
2022-11-28 02:21:32,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:32,935 INFO:     Epoch: 52
2022-11-28 02:21:33,679 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4320654049515724, 'Total loss': 0.4320654049515724} | train loss {'Reaction outcome loss': 0.3255657103470704, 'Total loss': 0.3255657103470704}
2022-11-28 02:21:33,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:33,680 INFO:     Epoch: 53
2022-11-28 02:21:34,432 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41068120063705876, 'Total loss': 0.41068120063705876} | train loss {'Reaction outcome loss': 0.3337934559252611, 'Total loss': 0.3337934559252611}
2022-11-28 02:21:34,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:34,432 INFO:     Epoch: 54
2022-11-28 02:21:35,183 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44173249263655057, 'Total loss': 0.44173249263655057} | train loss {'Reaction outcome loss': 0.3291220480674191, 'Total loss': 0.3291220480674191}
2022-11-28 02:21:35,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:35,183 INFO:     Epoch: 55
2022-11-28 02:21:35,934 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43302693048661406, 'Total loss': 0.43302693048661406} | train loss {'Reaction outcome loss': 0.340422984878608, 'Total loss': 0.340422984878608}
2022-11-28 02:21:35,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:35,934 INFO:     Epoch: 56
2022-11-28 02:21:36,687 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4161490625278516, 'Total loss': 0.4161490625278516} | train loss {'Reaction outcome loss': 0.3257371681578116, 'Total loss': 0.3257371681578116}
2022-11-28 02:21:36,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:36,687 INFO:     Epoch: 57
2022-11-28 02:21:37,434 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39904412694952707, 'Total loss': 0.39904412694952707} | train loss {'Reaction outcome loss': 0.32924410566566925, 'Total loss': 0.32924410566566925}
2022-11-28 02:21:37,434 INFO:     Found new best model at epoch 57
2022-11-28 02:21:37,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:37,435 INFO:     Epoch: 58
2022-11-28 02:21:38,187 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4680452370508151, 'Total loss': 0.4680452370508151} | train loss {'Reaction outcome loss': 0.3310173978870697, 'Total loss': 0.3310173978870697}
2022-11-28 02:21:38,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:38,187 INFO:     Epoch: 59
2022-11-28 02:21:38,938 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5569424507292834, 'Total loss': 0.5569424507292834} | train loss {'Reaction outcome loss': 0.35362578958634905, 'Total loss': 0.35362578958634905}
2022-11-28 02:21:38,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:38,938 INFO:     Epoch: 60
2022-11-28 02:21:39,688 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39233204400674865, 'Total loss': 0.39233204400674865} | train loss {'Reaction outcome loss': 0.34274224550859167, 'Total loss': 0.34274224550859167}
2022-11-28 02:21:39,689 INFO:     Found new best model at epoch 60
2022-11-28 02:21:39,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:39,690 INFO:     Epoch: 61
2022-11-28 02:21:40,441 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41804834455251694, 'Total loss': 0.41804834455251694} | train loss {'Reaction outcome loss': 0.31878974775855357, 'Total loss': 0.31878974775855357}
2022-11-28 02:21:40,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:40,441 INFO:     Epoch: 62
2022-11-28 02:21:41,189 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4247522164474834, 'Total loss': 0.4247522164474834} | train loss {'Reaction outcome loss': 0.31888771591791015, 'Total loss': 0.31888771591791015}
2022-11-28 02:21:41,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:41,189 INFO:     Epoch: 63
2022-11-28 02:21:41,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4493883785537698, 'Total loss': 0.4493883785537698} | train loss {'Reaction outcome loss': 0.352518578591617, 'Total loss': 0.352518578591617}
2022-11-28 02:21:41,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:41,940 INFO:     Epoch: 64
2022-11-28 02:21:42,688 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4182315692305565, 'Total loss': 0.4182315692305565} | train loss {'Reaction outcome loss': 0.33377670131290055, 'Total loss': 0.33377670131290055}
2022-11-28 02:21:42,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:42,688 INFO:     Epoch: 65
2022-11-28 02:21:43,440 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4933632104234262, 'Total loss': 0.4933632104234262} | train loss {'Reaction outcome loss': 0.3188204945400659, 'Total loss': 0.3188204945400659}
2022-11-28 02:21:43,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:43,440 INFO:     Epoch: 66
2022-11-28 02:21:44,192 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43303078497675335, 'Total loss': 0.43303078497675335} | train loss {'Reaction outcome loss': 0.3590171669415662, 'Total loss': 0.3590171669415662}
2022-11-28 02:21:44,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:44,192 INFO:     Epoch: 67
2022-11-28 02:21:44,939 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4485259161076762, 'Total loss': 0.4485259161076762} | train loss {'Reaction outcome loss': 0.32436990668537163, 'Total loss': 0.32436990668537163}
2022-11-28 02:21:44,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:44,939 INFO:     Epoch: 68
2022-11-28 02:21:45,685 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39750582352280617, 'Total loss': 0.39750582352280617} | train loss {'Reaction outcome loss': 0.32773266788991545, 'Total loss': 0.32773266788991545}
2022-11-28 02:21:45,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:45,685 INFO:     Epoch: 69
2022-11-28 02:21:46,434 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4181464980779724, 'Total loss': 0.4181464980779724} | train loss {'Reaction outcome loss': 0.32226405750575043, 'Total loss': 0.32226405750575043}
2022-11-28 02:21:46,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:46,435 INFO:     Epoch: 70
2022-11-28 02:21:47,181 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43447899784554134, 'Total loss': 0.43447899784554134} | train loss {'Reaction outcome loss': 0.3212676371112164, 'Total loss': 0.3212676371112164}
2022-11-28 02:21:47,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:47,181 INFO:     Epoch: 71
2022-11-28 02:21:47,927 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42980196191505954, 'Total loss': 0.42980196191505954} | train loss {'Reaction outcome loss': 0.326760830380294, 'Total loss': 0.326760830380294}
2022-11-28 02:21:47,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:47,927 INFO:     Epoch: 72
2022-11-28 02:21:48,675 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4663102528588338, 'Total loss': 0.4663102528588338} | train loss {'Reaction outcome loss': 0.3402755742492946, 'Total loss': 0.3402755742492946}
2022-11-28 02:21:48,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:48,675 INFO:     Epoch: 73
2022-11-28 02:21:49,423 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4217607240107926, 'Total loss': 0.4217607240107926} | train loss {'Reaction outcome loss': 0.35017625610476083, 'Total loss': 0.35017625610476083}
2022-11-28 02:21:49,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:49,424 INFO:     Epoch: 74
2022-11-28 02:21:50,168 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43503734638745134, 'Total loss': 0.43503734638745134} | train loss {'Reaction outcome loss': 0.3297555783258276, 'Total loss': 0.3297555783258276}
2022-11-28 02:21:50,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:50,168 INFO:     Epoch: 75
2022-11-28 02:21:50,918 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40803097594868054, 'Total loss': 0.40803097594868054} | train loss {'Reaction outcome loss': 0.32353022018907523, 'Total loss': 0.32353022018907523}
2022-11-28 02:21:50,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:50,918 INFO:     Epoch: 76
2022-11-28 02:21:51,667 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.450253640724854, 'Total loss': 0.450253640724854} | train loss {'Reaction outcome loss': 0.33064035121125246, 'Total loss': 0.33064035121125246}
2022-11-28 02:21:51,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:51,667 INFO:     Epoch: 77
2022-11-28 02:21:52,413 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42523661865429446, 'Total loss': 0.42523661865429446} | train loss {'Reaction outcome loss': 0.32107666685332653, 'Total loss': 0.32107666685332653}
2022-11-28 02:21:52,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:52,414 INFO:     Epoch: 78
2022-11-28 02:21:53,163 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42970751429145987, 'Total loss': 0.42970751429145987} | train loss {'Reaction outcome loss': 0.31278273367996023, 'Total loss': 0.31278273367996023}
2022-11-28 02:21:53,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:53,163 INFO:     Epoch: 79
2022-11-28 02:21:53,910 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40240032090382144, 'Total loss': 0.40240032090382144} | train loss {'Reaction outcome loss': 0.31016370029705254, 'Total loss': 0.31016370029705254}
2022-11-28 02:21:53,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:53,910 INFO:     Epoch: 80
2022-11-28 02:21:54,658 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43434369970451703, 'Total loss': 0.43434369970451703} | train loss {'Reaction outcome loss': 0.3277214467525482, 'Total loss': 0.3277214467525482}
2022-11-28 02:21:54,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:54,659 INFO:     Epoch: 81
2022-11-28 02:21:55,408 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4186660186810927, 'Total loss': 0.4186660186810927} | train loss {'Reaction outcome loss': 0.32118849540157585, 'Total loss': 0.32118849540157585}
2022-11-28 02:21:55,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:55,408 INFO:     Epoch: 82
2022-11-28 02:21:56,153 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4539638774638826, 'Total loss': 0.4539638774638826} | train loss {'Reaction outcome loss': 0.3186496544161789, 'Total loss': 0.3186496544161789}
2022-11-28 02:21:56,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:56,153 INFO:     Epoch: 83
2022-11-28 02:21:56,901 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40535325777124276, 'Total loss': 0.40535325777124276} | train loss {'Reaction outcome loss': 0.3319685212242217, 'Total loss': 0.3319685212242217}
2022-11-28 02:21:56,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:56,901 INFO:     Epoch: 84
2022-11-28 02:21:57,651 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43652115626768634, 'Total loss': 0.43652115626768634} | train loss {'Reaction outcome loss': 0.32567367010452003, 'Total loss': 0.32567367010452003}
2022-11-28 02:21:57,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:57,651 INFO:     Epoch: 85
2022-11-28 02:21:58,396 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4828883024271239, 'Total loss': 0.4828883024271239} | train loss {'Reaction outcome loss': 0.3080099346003069, 'Total loss': 0.3080099346003069}
2022-11-28 02:21:58,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:58,396 INFO:     Epoch: 86
2022-11-28 02:21:59,145 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43408342891118745, 'Total loss': 0.43408342891118745} | train loss {'Reaction outcome loss': 0.3325843337493447, 'Total loss': 0.3325843337493447}
2022-11-28 02:21:59,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:59,146 INFO:     Epoch: 87
2022-11-28 02:21:59,892 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44983000646937976, 'Total loss': 0.44983000646937976} | train loss {'Reaction outcome loss': 0.31794522017964466, 'Total loss': 0.31794522017964466}
2022-11-28 02:21:59,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:21:59,893 INFO:     Epoch: 88
2022-11-28 02:22:00,638 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.450121611695398, 'Total loss': 0.450121611695398} | train loss {'Reaction outcome loss': 0.32089825376040143, 'Total loss': 0.32089825376040143}
2022-11-28 02:22:00,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:00,638 INFO:     Epoch: 89
2022-11-28 02:22:01,384 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4261888096278364, 'Total loss': 0.4261888096278364} | train loss {'Reaction outcome loss': 0.3214467329883699, 'Total loss': 0.3214467329883699}
2022-11-28 02:22:01,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:01,384 INFO:     Epoch: 90
2022-11-28 02:22:02,132 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4559554505077275, 'Total loss': 0.4559554505077275} | train loss {'Reaction outcome loss': 0.31741588864369913, 'Total loss': 0.31741588864369913}
2022-11-28 02:22:02,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:02,132 INFO:     Epoch: 91
2022-11-28 02:22:02,880 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4193766631863334, 'Total loss': 0.4193766631863334} | train loss {'Reaction outcome loss': 0.32823518784301964, 'Total loss': 0.32823518784301964}
2022-11-28 02:22:02,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:02,880 INFO:     Epoch: 92
2022-11-28 02:22:03,629 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4169685166667808, 'Total loss': 0.4169685166667808} | train loss {'Reaction outcome loss': 0.32720051621000174, 'Total loss': 0.32720051621000174}
2022-11-28 02:22:03,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:03,629 INFO:     Epoch: 93
2022-11-28 02:22:04,376 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4207343523475257, 'Total loss': 0.4207343523475257} | train loss {'Reaction outcome loss': 0.30832631614526756, 'Total loss': 0.30832631614526756}
2022-11-28 02:22:04,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:04,376 INFO:     Epoch: 94
2022-11-28 02:22:05,120 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4369246492331678, 'Total loss': 0.4369246492331678} | train loss {'Reaction outcome loss': 0.310921141221697, 'Total loss': 0.310921141221697}
2022-11-28 02:22:05,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:05,120 INFO:     Epoch: 95
2022-11-28 02:22:05,867 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4286803830076348, 'Total loss': 0.4286803830076348} | train loss {'Reaction outcome loss': 0.3211186687774986, 'Total loss': 0.3211186687774986}
2022-11-28 02:22:05,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:05,868 INFO:     Epoch: 96
2022-11-28 02:22:06,616 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4604003094136715, 'Total loss': 0.4604003094136715} | train loss {'Reaction outcome loss': 0.32344144936424757, 'Total loss': 0.32344144936424757}
2022-11-28 02:22:06,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:06,616 INFO:     Epoch: 97
2022-11-28 02:22:07,364 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4164002232930877, 'Total loss': 0.4164002232930877} | train loss {'Reaction outcome loss': 0.3216198325074214, 'Total loss': 0.3216198325074214}
2022-11-28 02:22:07,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:07,364 INFO:     Epoch: 98
2022-11-28 02:22:08,111 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42357269166545436, 'Total loss': 0.42357269166545436} | train loss {'Reaction outcome loss': 0.3133899642207362, 'Total loss': 0.3133899642207362}
2022-11-28 02:22:08,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:08,112 INFO:     Epoch: 99
2022-11-28 02:22:08,858 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4201838658614592, 'Total loss': 0.4201838658614592} | train loss {'Reaction outcome loss': 0.31009367545727295, 'Total loss': 0.31009367545727295}
2022-11-28 02:22:08,858 INFO:     Best model found after epoch 61 of 100.
2022-11-28 02:22:08,858 INFO:   Done with stage: TRAINING
2022-11-28 02:22:08,858 INFO:   Starting stage: EVALUATION
2022-11-28 02:22:08,984 INFO:   Done with stage: EVALUATION
2022-11-28 02:22:08,984 INFO:   Leaving out SEQ value Fold_2
2022-11-28 02:22:08,997 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:22:08,997 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:22:09,642 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:22:09,642 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:22:09,711 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:22:09,711 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:22:09,711 INFO:     No hyperparam tuning for this model
2022-11-28 02:22:09,711 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:22:09,711 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:22:09,712 INFO:     None feature selector for col prot
2022-11-28 02:22:09,712 INFO:     None feature selector for col prot
2022-11-28 02:22:09,712 INFO:     None feature selector for col prot
2022-11-28 02:22:09,713 INFO:     None feature selector for col chem
2022-11-28 02:22:09,713 INFO:     None feature selector for col chem
2022-11-28 02:22:09,713 INFO:     None feature selector for col chem
2022-11-28 02:22:09,713 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:22:09,713 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:22:09,715 INFO:     Number of params in model 169741
2022-11-28 02:22:09,718 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:22:09,718 INFO:   Starting stage: TRAINING
2022-11-28 02:22:09,771 INFO:     Val loss before train {'Reaction outcome loss': 0.9853831150315024, 'Total loss': 0.9853831150315024}
2022-11-28 02:22:09,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:09,772 INFO:     Epoch: 0
2022-11-28 02:22:10,517 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.514284340495413, 'Total loss': 0.514284340495413} | train loss {'Reaction outcome loss': 0.6350090863753338, 'Total loss': 0.6350090863753338}
2022-11-28 02:22:10,518 INFO:     Found new best model at epoch 0
2022-11-28 02:22:10,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:10,519 INFO:     Epoch: 1
2022-11-28 02:22:11,259 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4545850377868522, 'Total loss': 0.4545850377868522} | train loss {'Reaction outcome loss': 0.5024173900180934, 'Total loss': 0.5024173900180934}
2022-11-28 02:22:11,259 INFO:     Found new best model at epoch 1
2022-11-28 02:22:11,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:11,260 INFO:     Epoch: 2
2022-11-28 02:22:12,006 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4434295120564374, 'Total loss': 0.4434295120564374} | train loss {'Reaction outcome loss': 0.46312603366618255, 'Total loss': 0.46312603366618255}
2022-11-28 02:22:12,006 INFO:     Found new best model at epoch 2
2022-11-28 02:22:12,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:12,007 INFO:     Epoch: 3
2022-11-28 02:22:12,752 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4642765928398479, 'Total loss': 0.4642765928398479} | train loss {'Reaction outcome loss': 0.43620454571685013, 'Total loss': 0.43620454571685013}
2022-11-28 02:22:12,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:12,753 INFO:     Epoch: 4
2022-11-28 02:22:13,492 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4197444980117408, 'Total loss': 0.4197444980117408} | train loss {'Reaction outcome loss': 0.4252538192028902, 'Total loss': 0.4252538192028902}
2022-11-28 02:22:13,492 INFO:     Found new best model at epoch 4
2022-11-28 02:22:13,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:13,493 INFO:     Epoch: 5
2022-11-28 02:22:14,234 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4264997992325913, 'Total loss': 0.4264997992325913} | train loss {'Reaction outcome loss': 0.41672130050707834, 'Total loss': 0.41672130050707834}
2022-11-28 02:22:14,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:14,235 INFO:     Epoch: 6
2022-11-28 02:22:14,975 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41716333614154294, 'Total loss': 0.41716333614154294} | train loss {'Reaction outcome loss': 0.3979778958826649, 'Total loss': 0.3979778958826649}
2022-11-28 02:22:14,975 INFO:     Found new best model at epoch 6
2022-11-28 02:22:14,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:14,976 INFO:     Epoch: 7
2022-11-28 02:22:15,718 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42993914437564934, 'Total loss': 0.42993914437564934} | train loss {'Reaction outcome loss': 0.4013910459924717, 'Total loss': 0.4013910459924717}
2022-11-28 02:22:15,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:15,719 INFO:     Epoch: 8
2022-11-28 02:22:16,459 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39726571941917593, 'Total loss': 0.39726571941917593} | train loss {'Reaction outcome loss': 0.3900776956154376, 'Total loss': 0.3900776956154376}
2022-11-28 02:22:16,459 INFO:     Found new best model at epoch 8
2022-11-28 02:22:16,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:16,460 INFO:     Epoch: 9
2022-11-28 02:22:17,203 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40852203711190005, 'Total loss': 0.40852203711190005} | train loss {'Reaction outcome loss': 0.38815612646998193, 'Total loss': 0.38815612646998193}
2022-11-28 02:22:17,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:17,203 INFO:     Epoch: 10
2022-11-28 02:22:17,948 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39003303376111115, 'Total loss': 0.39003303376111115} | train loss {'Reaction outcome loss': 0.37046776971950823, 'Total loss': 0.37046776971950823}
2022-11-28 02:22:17,948 INFO:     Found new best model at epoch 10
2022-11-28 02:22:17,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:17,949 INFO:     Epoch: 11
2022-11-28 02:22:18,694 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4063926041126251, 'Total loss': 0.4063926041126251} | train loss {'Reaction outcome loss': 0.3731109961259122, 'Total loss': 0.3731109961259122}
2022-11-28 02:22:18,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:18,694 INFO:     Epoch: 12
2022-11-28 02:22:19,437 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3932105724445798, 'Total loss': 0.3932105724445798} | train loss {'Reaction outcome loss': 0.36619110502758806, 'Total loss': 0.36619110502758806}
2022-11-28 02:22:19,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:19,438 INFO:     Epoch: 13
2022-11-28 02:22:20,178 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3963775130158121, 'Total loss': 0.3963775130158121} | train loss {'Reaction outcome loss': 0.3768823008452143, 'Total loss': 0.3768823008452143}
2022-11-28 02:22:20,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:20,178 INFO:     Epoch: 14
2022-11-28 02:22:20,918 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4141524552621625, 'Total loss': 0.4141524552621625} | train loss {'Reaction outcome loss': 0.3657265198778133, 'Total loss': 0.3657265198778133}
2022-11-28 02:22:20,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:20,918 INFO:     Epoch: 15
2022-11-28 02:22:21,660 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39266509596597066, 'Total loss': 0.39266509596597066} | train loss {'Reaction outcome loss': 0.3632141587077355, 'Total loss': 0.3632141587077355}
2022-11-28 02:22:21,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:21,660 INFO:     Epoch: 16
2022-11-28 02:22:22,401 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4282359386032278, 'Total loss': 0.4282359386032278} | train loss {'Reaction outcome loss': 0.35158167058716017, 'Total loss': 0.35158167058716017}
2022-11-28 02:22:22,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:22,402 INFO:     Epoch: 17
2022-11-28 02:22:23,144 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3916943489827893, 'Total loss': 0.3916943489827893} | train loss {'Reaction outcome loss': 0.3511904754808971, 'Total loss': 0.3511904754808971}
2022-11-28 02:22:23,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:23,145 INFO:     Epoch: 18
2022-11-28 02:22:23,889 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43440819362347777, 'Total loss': 0.43440819362347777} | train loss {'Reaction outcome loss': 0.3521702524350614, 'Total loss': 0.3521702524350614}
2022-11-28 02:22:23,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:23,889 INFO:     Epoch: 19
2022-11-28 02:22:24,631 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38292183219031856, 'Total loss': 0.38292183219031856} | train loss {'Reaction outcome loss': 0.3464871800371579, 'Total loss': 0.3464871800371579}
2022-11-28 02:22:24,631 INFO:     Found new best model at epoch 19
2022-11-28 02:22:24,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:24,632 INFO:     Epoch: 20
2022-11-28 02:22:25,375 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4253170063549822, 'Total loss': 0.4253170063549822} | train loss {'Reaction outcome loss': 0.34078265449830464, 'Total loss': 0.34078265449830464}
2022-11-28 02:22:25,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:25,375 INFO:     Epoch: 21
2022-11-28 02:22:26,125 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3998871198432012, 'Total loss': 0.3998871198432012} | train loss {'Reaction outcome loss': 0.3459650712657948, 'Total loss': 0.3459650712657948}
2022-11-28 02:22:26,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:26,125 INFO:     Epoch: 22
2022-11-28 02:22:26,872 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39638016847046936, 'Total loss': 0.39638016847046936} | train loss {'Reaction outcome loss': 0.34090908917845514, 'Total loss': 0.34090908917845514}
2022-11-28 02:22:26,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:26,872 INFO:     Epoch: 23
2022-11-28 02:22:27,613 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41841101612557063, 'Total loss': 0.41841101612557063} | train loss {'Reaction outcome loss': 0.33733971718014505, 'Total loss': 0.33733971718014505}
2022-11-28 02:22:27,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:27,613 INFO:     Epoch: 24
2022-11-28 02:22:28,357 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4070670011199333, 'Total loss': 0.4070670011199333} | train loss {'Reaction outcome loss': 0.3478483405952551, 'Total loss': 0.3478483405952551}
2022-11-28 02:22:28,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:28,358 INFO:     Epoch: 25
2022-11-28 02:22:29,102 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4222066927362572, 'Total loss': 0.4222066927362572} | train loss {'Reaction outcome loss': 0.3330721416339582, 'Total loss': 0.3330721416339582}
2022-11-28 02:22:29,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:29,102 INFO:     Epoch: 26
2022-11-28 02:22:29,842 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4091928533532403, 'Total loss': 0.4091928533532403} | train loss {'Reaction outcome loss': 0.333672923184171, 'Total loss': 0.333672923184171}
2022-11-28 02:22:29,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:29,843 INFO:     Epoch: 27
2022-11-28 02:22:30,582 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40765547481450165, 'Total loss': 0.40765547481450165} | train loss {'Reaction outcome loss': 0.33330204912594386, 'Total loss': 0.33330204912594386}
2022-11-28 02:22:30,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:30,583 INFO:     Epoch: 28
2022-11-28 02:22:31,326 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40585504370656883, 'Total loss': 0.40585504370656883} | train loss {'Reaction outcome loss': 0.34101656295207083, 'Total loss': 0.34101656295207083}
2022-11-28 02:22:31,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:31,326 INFO:     Epoch: 29
2022-11-28 02:22:32,068 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38477782092311164, 'Total loss': 0.38477782092311164} | train loss {'Reaction outcome loss': 0.3369237536070298, 'Total loss': 0.3369237536070298}
2022-11-28 02:22:32,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:32,068 INFO:     Epoch: 30
2022-11-28 02:22:32,810 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3781079439954324, 'Total loss': 0.3781079439954324} | train loss {'Reaction outcome loss': 0.33319309365992644, 'Total loss': 0.33319309365992644}
2022-11-28 02:22:32,810 INFO:     Found new best model at epoch 30
2022-11-28 02:22:32,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:32,811 INFO:     Epoch: 31
2022-11-28 02:22:33,559 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4011619065634229, 'Total loss': 0.4011619065634229} | train loss {'Reaction outcome loss': 0.32067049823853433, 'Total loss': 0.32067049823853433}
2022-11-28 02:22:33,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:33,559 INFO:     Epoch: 32
2022-11-28 02:22:34,305 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3941745182329958, 'Total loss': 0.3941745182329958} | train loss {'Reaction outcome loss': 0.32794558144345576, 'Total loss': 0.32794558144345576}
2022-11-28 02:22:34,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:34,306 INFO:     Epoch: 33
2022-11-28 02:22:35,053 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39099557122046297, 'Total loss': 0.39099557122046297} | train loss {'Reaction outcome loss': 0.3344714813694662, 'Total loss': 0.3344714813694662}
2022-11-28 02:22:35,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:35,053 INFO:     Epoch: 34
2022-11-28 02:22:35,797 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4025236332619732, 'Total loss': 0.4025236332619732} | train loss {'Reaction outcome loss': 0.3267680198866494, 'Total loss': 0.3267680198866494}
2022-11-28 02:22:35,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:35,797 INFO:     Epoch: 35
2022-11-28 02:22:36,538 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39037879793481395, 'Total loss': 0.39037879793481395} | train loss {'Reaction outcome loss': 0.3164796000232502, 'Total loss': 0.3164796000232502}
2022-11-28 02:22:36,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:36,538 INFO:     Epoch: 36
2022-11-28 02:22:37,280 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4258755455640229, 'Total loss': 0.4258755455640229} | train loss {'Reaction outcome loss': 0.3279706773101067, 'Total loss': 0.3279706773101067}
2022-11-28 02:22:37,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:37,280 INFO:     Epoch: 37
2022-11-28 02:22:38,021 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40993267365477304, 'Total loss': 0.40993267365477304} | train loss {'Reaction outcome loss': 0.3279480557356562, 'Total loss': 0.3279480557356562}
2022-11-28 02:22:38,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:38,021 INFO:     Epoch: 38
2022-11-28 02:22:38,767 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4076258313249458, 'Total loss': 0.4076258313249458} | train loss {'Reaction outcome loss': 0.32962382563522885, 'Total loss': 0.32962382563522885}
2022-11-28 02:22:38,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:38,767 INFO:     Epoch: 39
2022-11-28 02:22:39,508 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4070458032868125, 'Total loss': 0.4070458032868125} | train loss {'Reaction outcome loss': 0.317496589708085, 'Total loss': 0.317496589708085}
2022-11-28 02:22:39,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:39,508 INFO:     Epoch: 40
2022-11-28 02:22:40,252 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39205778254704043, 'Total loss': 0.39205778254704043} | train loss {'Reaction outcome loss': 0.3244232190810904, 'Total loss': 0.3244232190810904}
2022-11-28 02:22:40,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:40,252 INFO:     Epoch: 41
2022-11-28 02:22:40,997 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39169183136387303, 'Total loss': 0.39169183136387303} | train loss {'Reaction outcome loss': 0.3310222123046311, 'Total loss': 0.3310222123046311}
2022-11-28 02:22:40,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:40,997 INFO:     Epoch: 42
2022-11-28 02:22:41,738 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41713265228000557, 'Total loss': 0.41713265228000557} | train loss {'Reaction outcome loss': 0.317661535527025, 'Total loss': 0.317661535527025}
2022-11-28 02:22:41,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:41,739 INFO:     Epoch: 43
2022-11-28 02:22:42,480 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3951562302695079, 'Total loss': 0.3951562302695079} | train loss {'Reaction outcome loss': 0.32049182312829155, 'Total loss': 0.32049182312829155}
2022-11-28 02:22:42,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:42,481 INFO:     Epoch: 44
2022-11-28 02:22:43,227 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3796283667060462, 'Total loss': 0.3796283667060462} | train loss {'Reaction outcome loss': 0.32273878710610526, 'Total loss': 0.32273878710610526}
2022-11-28 02:22:43,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:43,227 INFO:     Epoch: 45
2022-11-28 02:22:43,973 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39426762475208804, 'Total loss': 0.39426762475208804} | train loss {'Reaction outcome loss': 0.3124890781786977, 'Total loss': 0.3124890781786977}
2022-11-28 02:22:43,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:43,973 INFO:     Epoch: 46
2022-11-28 02:22:44,716 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39342530139467935, 'Total loss': 0.39342530139467935} | train loss {'Reaction outcome loss': 0.3187835742472386, 'Total loss': 0.3187835742472386}
2022-11-28 02:22:44,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:44,716 INFO:     Epoch: 47
2022-11-28 02:22:45,457 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38558591944588855, 'Total loss': 0.38558591944588855} | train loss {'Reaction outcome loss': 0.3165838428906032, 'Total loss': 0.3165838428906032}
2022-11-28 02:22:45,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:45,458 INFO:     Epoch: 48
2022-11-28 02:22:46,201 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38224353294142266, 'Total loss': 0.38224353294142266} | train loss {'Reaction outcome loss': 0.3197154189250907, 'Total loss': 0.3197154189250907}
2022-11-28 02:22:46,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:46,202 INFO:     Epoch: 49
2022-11-28 02:22:46,943 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39725893769751897, 'Total loss': 0.39725893769751897} | train loss {'Reaction outcome loss': 0.31298983677917597, 'Total loss': 0.31298983677917597}
2022-11-28 02:22:46,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:46,943 INFO:     Epoch: 50
2022-11-28 02:22:47,685 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42281893123237585, 'Total loss': 0.42281893123237585} | train loss {'Reaction outcome loss': 0.3138605799906108, 'Total loss': 0.3138605799906108}
2022-11-28 02:22:47,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:47,685 INFO:     Epoch: 51
2022-11-28 02:22:48,430 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4041695127856325, 'Total loss': 0.4041695127856325} | train loss {'Reaction outcome loss': 0.32245699769380143, 'Total loss': 0.32245699769380143}
2022-11-28 02:22:48,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:48,430 INFO:     Epoch: 52
2022-11-28 02:22:49,170 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3749372833831744, 'Total loss': 0.3749372833831744} | train loss {'Reaction outcome loss': 0.3119645633259598, 'Total loss': 0.3119645633259598}
2022-11-28 02:22:49,171 INFO:     Found new best model at epoch 52
2022-11-28 02:22:49,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:49,172 INFO:     Epoch: 53
2022-11-28 02:22:49,919 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3801480643451214, 'Total loss': 0.3801480643451214} | train loss {'Reaction outcome loss': 0.3217089449264565, 'Total loss': 0.3217089449264565}
2022-11-28 02:22:49,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:49,920 INFO:     Epoch: 54
2022-11-28 02:22:50,661 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39103533869439905, 'Total loss': 0.39103533869439905} | train loss {'Reaction outcome loss': 0.31393991979409236, 'Total loss': 0.31393991979409236}
2022-11-28 02:22:50,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:50,662 INFO:     Epoch: 55
2022-11-28 02:22:51,407 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3994063816287301, 'Total loss': 0.3994063816287301} | train loss {'Reaction outcome loss': 0.3130114589418684, 'Total loss': 0.3130114589418684}
2022-11-28 02:22:51,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:51,407 INFO:     Epoch: 56
2022-11-28 02:22:52,153 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3708712180907076, 'Total loss': 0.3708712180907076} | train loss {'Reaction outcome loss': 0.3071648659450667, 'Total loss': 0.3071648659450667}
2022-11-28 02:22:52,154 INFO:     Found new best model at epoch 56
2022-11-28 02:22:52,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:52,154 INFO:     Epoch: 57
2022-11-28 02:22:52,894 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3825556317513639, 'Total loss': 0.3825556317513639} | train loss {'Reaction outcome loss': 0.3092105273385437, 'Total loss': 0.3092105273385437}
2022-11-28 02:22:52,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:52,895 INFO:     Epoch: 58
2022-11-28 02:22:53,646 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40224411931227555, 'Total loss': 0.40224411931227555} | train loss {'Reaction outcome loss': 0.30539208170102566, 'Total loss': 0.30539208170102566}
2022-11-28 02:22:53,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:53,647 INFO:     Epoch: 59
2022-11-28 02:22:54,387 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4140197458592328, 'Total loss': 0.4140197458592328} | train loss {'Reaction outcome loss': 0.31133113317951866, 'Total loss': 0.31133113317951866}
2022-11-28 02:22:54,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:54,387 INFO:     Epoch: 60
2022-11-28 02:22:55,127 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37799468433315103, 'Total loss': 0.37799468433315103} | train loss {'Reaction outcome loss': 0.311775389496161, 'Total loss': 0.311775389496161}
2022-11-28 02:22:55,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:55,127 INFO:     Epoch: 61
2022-11-28 02:22:55,868 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40009490874680603, 'Total loss': 0.40009490874680603} | train loss {'Reaction outcome loss': 0.3162597542818712, 'Total loss': 0.3162597542818712}
2022-11-28 02:22:55,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:55,868 INFO:     Epoch: 62
2022-11-28 02:22:56,613 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39389293505386874, 'Total loss': 0.39389293505386874} | train loss {'Reaction outcome loss': 0.30608954593843346, 'Total loss': 0.30608954593843346}
2022-11-28 02:22:56,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:56,613 INFO:     Epoch: 63
2022-11-28 02:22:57,355 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3990640482780608, 'Total loss': 0.3990640482780608} | train loss {'Reaction outcome loss': 0.307019647986305, 'Total loss': 0.307019647986305}
2022-11-28 02:22:57,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:57,356 INFO:     Epoch: 64
2022-11-28 02:22:58,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3819105278023265, 'Total loss': 0.3819105278023265} | train loss {'Reaction outcome loss': 0.3079846813362472, 'Total loss': 0.3079846813362472}
2022-11-28 02:22:58,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:58,108 INFO:     Epoch: 65
2022-11-28 02:22:58,855 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3873771190304648, 'Total loss': 0.3873771190304648} | train loss {'Reaction outcome loss': 0.31651178601444985, 'Total loss': 0.31651178601444985}
2022-11-28 02:22:58,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:58,855 INFO:     Epoch: 66
2022-11-28 02:22:59,597 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3702757141806863, 'Total loss': 0.3702757141806863} | train loss {'Reaction outcome loss': 0.3077794276481988, 'Total loss': 0.3077794276481988}
2022-11-28 02:22:59,597 INFO:     Found new best model at epoch 66
2022-11-28 02:22:59,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:22:59,598 INFO:     Epoch: 67
2022-11-28 02:23:00,337 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3888996687125076, 'Total loss': 0.3888996687125076} | train loss {'Reaction outcome loss': 0.31707862125975744, 'Total loss': 0.31707862125975744}
2022-11-28 02:23:00,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:00,338 INFO:     Epoch: 68
2022-11-28 02:23:01,082 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3836764190769331, 'Total loss': 0.3836764190769331} | train loss {'Reaction outcome loss': 0.307810852220472, 'Total loss': 0.307810852220472}
2022-11-28 02:23:01,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:01,083 INFO:     Epoch: 69
2022-11-28 02:23:01,828 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39355109039355407, 'Total loss': 0.39355109039355407} | train loss {'Reaction outcome loss': 0.3121375107947661, 'Total loss': 0.3121375107947661}
2022-11-28 02:23:01,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:01,829 INFO:     Epoch: 70
2022-11-28 02:23:02,577 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41904394057664, 'Total loss': 0.41904394057664} | train loss {'Reaction outcome loss': 0.31398202440872486, 'Total loss': 0.31398202440872486}
2022-11-28 02:23:02,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:02,577 INFO:     Epoch: 71
2022-11-28 02:23:03,323 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38952366618270223, 'Total loss': 0.38952366618270223} | train loss {'Reaction outcome loss': 0.3025544383392042, 'Total loss': 0.3025544383392042}
2022-11-28 02:23:03,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:03,324 INFO:     Epoch: 72
2022-11-28 02:23:04,067 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3684301167218523, 'Total loss': 0.3684301167218523} | train loss {'Reaction outcome loss': 0.31423070719655677, 'Total loss': 0.31423070719655677}
2022-11-28 02:23:04,067 INFO:     Found new best model at epoch 72
2022-11-28 02:23:04,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:04,068 INFO:     Epoch: 73
2022-11-28 02:23:04,811 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4125742834400047, 'Total loss': 0.4125742834400047} | train loss {'Reaction outcome loss': 0.31520473935774396, 'Total loss': 0.31520473935774396}
2022-11-28 02:23:04,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:04,811 INFO:     Epoch: 74
2022-11-28 02:23:05,558 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4128263049166311, 'Total loss': 0.4128263049166311} | train loss {'Reaction outcome loss': 0.30430893286758537, 'Total loss': 0.30430893286758537}
2022-11-28 02:23:05,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:05,559 INFO:     Epoch: 75
2022-11-28 02:23:06,300 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3959052421321923, 'Total loss': 0.3959052421321923} | train loss {'Reaction outcome loss': 0.31047465901593774, 'Total loss': 0.31047465901593774}
2022-11-28 02:23:06,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:06,300 INFO:     Epoch: 76
2022-11-28 02:23:07,045 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3895799070596695, 'Total loss': 0.3895799070596695} | train loss {'Reaction outcome loss': 0.30792328079744263, 'Total loss': 0.30792328079744263}
2022-11-28 02:23:07,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:07,045 INFO:     Epoch: 77
2022-11-28 02:23:07,787 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38503425991670653, 'Total loss': 0.38503425991670653} | train loss {'Reaction outcome loss': 0.30882771559515776, 'Total loss': 0.30882771559515776}
2022-11-28 02:23:07,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:07,787 INFO:     Epoch: 78
2022-11-28 02:23:08,529 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.366107716140422, 'Total loss': 0.366107716140422} | train loss {'Reaction outcome loss': 0.3055906847727542, 'Total loss': 0.3055906847727542}
2022-11-28 02:23:08,529 INFO:     Found new best model at epoch 78
2022-11-28 02:23:08,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:08,530 INFO:     Epoch: 79
2022-11-28 02:23:09,273 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40905161608349194, 'Total loss': 0.40905161608349194} | train loss {'Reaction outcome loss': 0.31965490319595047, 'Total loss': 0.31965490319595047}
2022-11-28 02:23:09,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:09,274 INFO:     Epoch: 80
2022-11-28 02:23:10,021 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40018769954754546, 'Total loss': 0.40018769954754546} | train loss {'Reaction outcome loss': 0.31178986734273484, 'Total loss': 0.31178986734273484}
2022-11-28 02:23:10,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:10,022 INFO:     Epoch: 81
2022-11-28 02:23:10,764 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41574456136335025, 'Total loss': 0.41574456136335025} | train loss {'Reaction outcome loss': 0.31466645631863144, 'Total loss': 0.31466645631863144}
2022-11-28 02:23:10,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:10,764 INFO:     Epoch: 82
2022-11-28 02:23:11,505 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40130021067505534, 'Total loss': 0.40130021067505534} | train loss {'Reaction outcome loss': 0.30829011645852306, 'Total loss': 0.30829011645852306}
2022-11-28 02:23:11,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:11,505 INFO:     Epoch: 83
2022-11-28 02:23:12,247 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3762634921480309, 'Total loss': 0.3762634921480309} | train loss {'Reaction outcome loss': 0.30362914897957627, 'Total loss': 0.30362914897957627}
2022-11-28 02:23:12,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:12,247 INFO:     Epoch: 84
2022-11-28 02:23:12,993 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4122833355583928, 'Total loss': 0.4122833355583928} | train loss {'Reaction outcome loss': 0.3135840753587533, 'Total loss': 0.3135840753587533}
2022-11-28 02:23:12,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:12,993 INFO:     Epoch: 85
2022-11-28 02:23:13,740 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39010485854338517, 'Total loss': 0.39010485854338517} | train loss {'Reaction outcome loss': 0.30483915027307007, 'Total loss': 0.30483915027307007}
2022-11-28 02:23:13,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:13,741 INFO:     Epoch: 86
2022-11-28 02:23:14,485 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4022763835435564, 'Total loss': 0.4022763835435564} | train loss {'Reaction outcome loss': 0.3049076116966958, 'Total loss': 0.3049076116966958}
2022-11-28 02:23:14,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:14,485 INFO:     Epoch: 87
2022-11-28 02:23:15,230 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37528549488739704, 'Total loss': 0.37528549488739704} | train loss {'Reaction outcome loss': 0.3118058338001066, 'Total loss': 0.3118058338001066}
2022-11-28 02:23:15,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:15,230 INFO:     Epoch: 88
2022-11-28 02:23:15,974 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4285031618042426, 'Total loss': 0.4285031618042426} | train loss {'Reaction outcome loss': 0.3020063907516246, 'Total loss': 0.3020063907516246}
2022-11-28 02:23:15,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:15,974 INFO:     Epoch: 89
2022-11-28 02:23:16,715 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3890849891203371, 'Total loss': 0.3890849891203371} | train loss {'Reaction outcome loss': 0.3160401221440763, 'Total loss': 0.3160401221440763}
2022-11-28 02:23:16,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:16,715 INFO:     Epoch: 90
2022-11-28 02:23:17,461 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38459127210080624, 'Total loss': 0.38459127210080624} | train loss {'Reaction outcome loss': 0.3137392291457069, 'Total loss': 0.3137392291457069}
2022-11-28 02:23:17,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:17,461 INFO:     Epoch: 91
2022-11-28 02:23:18,207 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3718791660979729, 'Total loss': 0.3718791660979729} | train loss {'Reaction outcome loss': 0.3138183110830735, 'Total loss': 0.3138183110830735}
2022-11-28 02:23:18,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:18,207 INFO:     Epoch: 92
2022-11-28 02:23:18,949 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39098946132104506, 'Total loss': 0.39098946132104506} | train loss {'Reaction outcome loss': 0.3059570389742754, 'Total loss': 0.3059570389742754}
2022-11-28 02:23:18,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:18,950 INFO:     Epoch: 93
2022-11-28 02:23:19,695 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3838379806415601, 'Total loss': 0.3838379806415601} | train loss {'Reaction outcome loss': 0.30507021920413385, 'Total loss': 0.30507021920413385}
2022-11-28 02:23:19,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:19,695 INFO:     Epoch: 94
2022-11-28 02:23:20,436 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4041332577947866, 'Total loss': 0.4041332577947866} | train loss {'Reaction outcome loss': 0.3123062709460453, 'Total loss': 0.3123062709460453}
2022-11-28 02:23:20,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:20,437 INFO:     Epoch: 95
2022-11-28 02:23:21,185 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3723480621860786, 'Total loss': 0.3723480621860786} | train loss {'Reaction outcome loss': 0.30120478445778087, 'Total loss': 0.30120478445778087}
2022-11-28 02:23:21,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:21,185 INFO:     Epoch: 96
2022-11-28 02:23:21,930 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4128663854842836, 'Total loss': 0.4128663854842836} | train loss {'Reaction outcome loss': 0.29899813414228205, 'Total loss': 0.29899813414228205}
2022-11-28 02:23:21,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:21,930 INFO:     Epoch: 97
2022-11-28 02:23:22,672 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38171938430009916, 'Total loss': 0.38171938430009916} | train loss {'Reaction outcome loss': 0.2947329655137597, 'Total loss': 0.2947329655137597}
2022-11-28 02:23:22,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:22,673 INFO:     Epoch: 98
2022-11-28 02:23:23,414 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3699832059950991, 'Total loss': 0.3699832059950991} | train loss {'Reaction outcome loss': 0.31711163770179357, 'Total loss': 0.31711163770179357}
2022-11-28 02:23:23,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:23,414 INFO:     Epoch: 99
2022-11-28 02:23:24,158 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38937595385042106, 'Total loss': 0.38937595385042106} | train loss {'Reaction outcome loss': 0.30363675774056087, 'Total loss': 0.30363675774056087}
2022-11-28 02:23:24,158 INFO:     Best model found after epoch 79 of 100.
2022-11-28 02:23:24,158 INFO:   Done with stage: TRAINING
2022-11-28 02:23:24,158 INFO:   Starting stage: EVALUATION
2022-11-28 02:23:24,288 INFO:   Done with stage: EVALUATION
2022-11-28 02:23:24,288 INFO:   Leaving out SEQ value Fold_3
2022-11-28 02:23:24,301 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:23:24,301 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:23:24,946 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:23:24,946 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:23:25,013 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:23:25,013 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:23:25,013 INFO:     No hyperparam tuning for this model
2022-11-28 02:23:25,013 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:23:25,013 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:23:25,014 INFO:     None feature selector for col prot
2022-11-28 02:23:25,014 INFO:     None feature selector for col prot
2022-11-28 02:23:25,014 INFO:     None feature selector for col prot
2022-11-28 02:23:25,015 INFO:     None feature selector for col chem
2022-11-28 02:23:25,015 INFO:     None feature selector for col chem
2022-11-28 02:23:25,015 INFO:     None feature selector for col chem
2022-11-28 02:23:25,015 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:23:25,015 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:23:25,016 INFO:     Number of params in model 169741
2022-11-28 02:23:25,019 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:23:25,020 INFO:   Starting stage: TRAINING
2022-11-28 02:23:25,072 INFO:     Val loss before train {'Reaction outcome loss': 1.0233473583709363, 'Total loss': 1.0233473583709363}
2022-11-28 02:23:25,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:25,072 INFO:     Epoch: 0
2022-11-28 02:23:25,808 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5669424055620681, 'Total loss': 0.5669424055620681} | train loss {'Reaction outcome loss': 0.6388943635049413, 'Total loss': 0.6388943635049413}
2022-11-28 02:23:25,808 INFO:     Found new best model at epoch 0
2022-11-28 02:23:25,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:25,809 INFO:     Epoch: 1
2022-11-28 02:23:26,550 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5423765383487524, 'Total loss': 0.5423765383487524} | train loss {'Reaction outcome loss': 0.4917293868226106, 'Total loss': 0.4917293868226106}
2022-11-28 02:23:26,550 INFO:     Found new best model at epoch 1
2022-11-28 02:23:26,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:26,551 INFO:     Epoch: 2
2022-11-28 02:23:27,296 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5122099785610686, 'Total loss': 0.5122099785610686} | train loss {'Reaction outcome loss': 0.4532974661007279, 'Total loss': 0.4532974661007279}
2022-11-28 02:23:27,296 INFO:     Found new best model at epoch 2
2022-11-28 02:23:27,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:27,297 INFO:     Epoch: 3
2022-11-28 02:23:28,037 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47798345567182055, 'Total loss': 0.47798345567182055} | train loss {'Reaction outcome loss': 0.43781598635994995, 'Total loss': 0.43781598635994995}
2022-11-28 02:23:28,037 INFO:     Found new best model at epoch 3
2022-11-28 02:23:28,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:28,038 INFO:     Epoch: 4
2022-11-28 02:23:28,774 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4806500804978748, 'Total loss': 0.4806500804978748} | train loss {'Reaction outcome loss': 0.4155817052013561, 'Total loss': 0.4155817052013561}
2022-11-28 02:23:28,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:28,774 INFO:     Epoch: 5
2022-11-28 02:23:29,512 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4882265488768733, 'Total loss': 0.4882265488768733} | train loss {'Reaction outcome loss': 0.409306530214724, 'Total loss': 0.409306530214724}
2022-11-28 02:23:29,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:29,513 INFO:     Epoch: 6
2022-11-28 02:23:30,255 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45066391693991287, 'Total loss': 0.45066391693991287} | train loss {'Reaction outcome loss': 0.4014779152501313, 'Total loss': 0.4014779152501313}
2022-11-28 02:23:30,255 INFO:     Found new best model at epoch 6
2022-11-28 02:23:30,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:30,256 INFO:     Epoch: 7
2022-11-28 02:23:30,996 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4632010634901912, 'Total loss': 0.4632010634901912} | train loss {'Reaction outcome loss': 0.3916198636909, 'Total loss': 0.3916198636909}
2022-11-28 02:23:30,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:30,997 INFO:     Epoch: 8
2022-11-28 02:23:31,733 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4562374280635701, 'Total loss': 0.4562374280635701} | train loss {'Reaction outcome loss': 0.3808405678108579, 'Total loss': 0.3808405678108579}
2022-11-28 02:23:31,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:31,733 INFO:     Epoch: 9
2022-11-28 02:23:32,476 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47232128645098487, 'Total loss': 0.47232128645098487} | train loss {'Reaction outcome loss': 0.38223037166429347, 'Total loss': 0.38223037166429347}
2022-11-28 02:23:32,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:32,477 INFO:     Epoch: 10
2022-11-28 02:23:33,217 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43273217716189316, 'Total loss': 0.43273217716189316} | train loss {'Reaction outcome loss': 0.36968827458312276, 'Total loss': 0.36968827458312276}
2022-11-28 02:23:33,218 INFO:     Found new best model at epoch 10
2022-11-28 02:23:33,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:33,218 INFO:     Epoch: 11
2022-11-28 02:23:33,958 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4264368861913681, 'Total loss': 0.4264368861913681} | train loss {'Reaction outcome loss': 0.36783354369099025, 'Total loss': 0.36783354369099025}
2022-11-28 02:23:33,958 INFO:     Found new best model at epoch 11
2022-11-28 02:23:33,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:33,959 INFO:     Epoch: 12
2022-11-28 02:23:34,694 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45067685461321544, 'Total loss': 0.45067685461321544} | train loss {'Reaction outcome loss': 0.3636635836580249, 'Total loss': 0.3636635836580249}
2022-11-28 02:23:34,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:34,694 INFO:     Epoch: 13
2022-11-28 02:23:35,435 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4424384198216505, 'Total loss': 0.4424384198216505} | train loss {'Reaction outcome loss': 0.36144360915192814, 'Total loss': 0.36144360915192814}
2022-11-28 02:23:35,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:35,435 INFO:     Epoch: 14
2022-11-28 02:23:36,177 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45174743893534636, 'Total loss': 0.45174743893534636} | train loss {'Reaction outcome loss': 0.36110578782734326, 'Total loss': 0.36110578782734326}
2022-11-28 02:23:36,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:36,177 INFO:     Epoch: 15
2022-11-28 02:23:36,916 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4435280783231868, 'Total loss': 0.4435280783231868} | train loss {'Reaction outcome loss': 0.36235741248018427, 'Total loss': 0.36235741248018427}
2022-11-28 02:23:36,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:36,916 INFO:     Epoch: 16
2022-11-28 02:23:37,652 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4484894979138707, 'Total loss': 0.4484894979138707} | train loss {'Reaction outcome loss': 0.3474078958273911, 'Total loss': 0.3474078958273911}
2022-11-28 02:23:37,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:37,652 INFO:     Epoch: 17
2022-11-28 02:23:38,390 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4401561666799839, 'Total loss': 0.4401561666799839} | train loss {'Reaction outcome loss': 0.35098081317226415, 'Total loss': 0.35098081317226415}
2022-11-28 02:23:38,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:38,390 INFO:     Epoch: 18
2022-11-28 02:23:39,130 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45393928850806037, 'Total loss': 0.45393928850806037} | train loss {'Reaction outcome loss': 0.3501947864767958, 'Total loss': 0.3501947864767958}
2022-11-28 02:23:39,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:39,130 INFO:     Epoch: 19
2022-11-28 02:23:39,868 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44591464119595153, 'Total loss': 0.44591464119595153} | train loss {'Reaction outcome loss': 0.3461308024335103, 'Total loss': 0.3461308024335103}
2022-11-28 02:23:39,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:39,868 INFO:     Epoch: 20
2022-11-28 02:23:40,606 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4696031309837519, 'Total loss': 0.4696031309837519} | train loss {'Reaction outcome loss': 0.3405831577103646, 'Total loss': 0.3405831577103646}
2022-11-28 02:23:40,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:40,607 INFO:     Epoch: 21
2022-11-28 02:23:41,342 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4307354816863703, 'Total loss': 0.4307354816863703} | train loss {'Reaction outcome loss': 0.3382366385433029, 'Total loss': 0.3382366385433029}
2022-11-28 02:23:41,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:41,342 INFO:     Epoch: 22
2022-11-28 02:23:42,080 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4488575060007184, 'Total loss': 0.4488575060007184} | train loss {'Reaction outcome loss': 0.33379586523429294, 'Total loss': 0.33379586523429294}
2022-11-28 02:23:42,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:42,080 INFO:     Epoch: 23
2022-11-28 02:23:42,818 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4234500912039779, 'Total loss': 0.4234500912039779} | train loss {'Reaction outcome loss': 0.3377156545881365, 'Total loss': 0.3377156545881365}
2022-11-28 02:23:42,818 INFO:     Found new best model at epoch 23
2022-11-28 02:23:42,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:42,819 INFO:     Epoch: 24
2022-11-28 02:23:43,559 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4387588878703672, 'Total loss': 0.4387588878703672} | train loss {'Reaction outcome loss': 0.3359876427433041, 'Total loss': 0.3359876427433041}
2022-11-28 02:23:43,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:43,559 INFO:     Epoch: 25
2022-11-28 02:23:44,297 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.447696456382441, 'Total loss': 0.447696456382441} | train loss {'Reaction outcome loss': 0.3461089366283573, 'Total loss': 0.3461089366283573}
2022-11-28 02:23:44,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:44,297 INFO:     Epoch: 26
2022-11-28 02:23:45,035 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4355557709932327, 'Total loss': 0.4355557709932327} | train loss {'Reaction outcome loss': 0.33087084243898507, 'Total loss': 0.33087084243898507}
2022-11-28 02:23:45,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:45,036 INFO:     Epoch: 27
2022-11-28 02:23:45,775 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43415315795776455, 'Total loss': 0.43415315795776455} | train loss {'Reaction outcome loss': 0.3317454971495222, 'Total loss': 0.3317454971495222}
2022-11-28 02:23:45,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:45,775 INFO:     Epoch: 28
2022-11-28 02:23:46,514 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4176053966200629, 'Total loss': 0.4176053966200629} | train loss {'Reaction outcome loss': 0.3265473655134928, 'Total loss': 0.3265473655134928}
2022-11-28 02:23:46,514 INFO:     Found new best model at epoch 28
2022-11-28 02:23:46,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:46,515 INFO:     Epoch: 29
2022-11-28 02:23:47,254 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4431351350490437, 'Total loss': 0.4431351350490437} | train loss {'Reaction outcome loss': 0.3284647232074229, 'Total loss': 0.3284647232074229}
2022-11-28 02:23:47,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:47,254 INFO:     Epoch: 30
2022-11-28 02:23:47,996 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46352558912232866, 'Total loss': 0.46352558912232866} | train loss {'Reaction outcome loss': 0.3421182657637801, 'Total loss': 0.3421182657637801}
2022-11-28 02:23:47,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:47,997 INFO:     Epoch: 31
2022-11-28 02:23:48,734 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43599062395650284, 'Total loss': 0.43599062395650284} | train loss {'Reaction outcome loss': 0.3322590731511839, 'Total loss': 0.3322590731511839}
2022-11-28 02:23:48,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:48,735 INFO:     Epoch: 32
2022-11-28 02:23:49,477 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43697190631267635, 'Total loss': 0.43697190631267635} | train loss {'Reaction outcome loss': 0.32968832277616517, 'Total loss': 0.32968832277616517}
2022-11-28 02:23:49,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:49,477 INFO:     Epoch: 33
2022-11-28 02:23:50,214 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44006444444490034, 'Total loss': 0.44006444444490034} | train loss {'Reaction outcome loss': 0.3313089861061241, 'Total loss': 0.3313089861061241}
2022-11-28 02:23:50,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:50,214 INFO:     Epoch: 34
2022-11-28 02:23:50,949 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4438780598169149, 'Total loss': 0.4438780598169149} | train loss {'Reaction outcome loss': 0.3322589690720693, 'Total loss': 0.3322589690720693}
2022-11-28 02:23:50,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:50,949 INFO:     Epoch: 35
2022-11-28 02:23:51,687 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4363985758188159, 'Total loss': 0.4363985758188159} | train loss {'Reaction outcome loss': 0.33035658272441293, 'Total loss': 0.33035658272441293}
2022-11-28 02:23:51,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:51,688 INFO:     Epoch: 36
2022-11-28 02:23:52,426 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4762386024691338, 'Total loss': 0.4762386024691338} | train loss {'Reaction outcome loss': 0.3286802643818445, 'Total loss': 0.3286802643818445}
2022-11-28 02:23:52,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:52,426 INFO:     Epoch: 37
2022-11-28 02:23:53,163 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47724578148403834, 'Total loss': 0.47724578148403834} | train loss {'Reaction outcome loss': 0.3233097593498523, 'Total loss': 0.3233097593498523}
2022-11-28 02:23:53,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:53,164 INFO:     Epoch: 38
2022-11-28 02:23:53,902 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43704593354879423, 'Total loss': 0.43704593354879423} | train loss {'Reaction outcome loss': 0.3375345579669124, 'Total loss': 0.3375345579669124}
2022-11-28 02:23:53,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:53,903 INFO:     Epoch: 39
2022-11-28 02:23:54,639 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44084380497766096, 'Total loss': 0.44084380497766096} | train loss {'Reaction outcome loss': 0.32859930596085357, 'Total loss': 0.32859930596085357}
2022-11-28 02:23:54,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:54,639 INFO:     Epoch: 40
2022-11-28 02:23:55,383 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4487543743710185, 'Total loss': 0.4487543743710185} | train loss {'Reaction outcome loss': 0.3205206855123893, 'Total loss': 0.3205206855123893}
2022-11-28 02:23:55,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:55,383 INFO:     Epoch: 41
2022-11-28 02:23:56,124 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44131784522256184, 'Total loss': 0.44131784522256184} | train loss {'Reaction outcome loss': 0.3244926890999567, 'Total loss': 0.3244926890999567}
2022-11-28 02:23:56,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:56,124 INFO:     Epoch: 42
2022-11-28 02:23:56,863 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4393593987753225, 'Total loss': 0.4393593987753225} | train loss {'Reaction outcome loss': 0.3242918970826708, 'Total loss': 0.3242918970826708}
2022-11-28 02:23:56,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:56,864 INFO:     Epoch: 43
2022-11-28 02:23:57,601 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4494570490232734, 'Total loss': 0.4494570490232734} | train loss {'Reaction outcome loss': 0.32099472468749424, 'Total loss': 0.32099472468749424}
2022-11-28 02:23:57,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:57,601 INFO:     Epoch: 44
2022-11-28 02:23:58,337 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42088563757580383, 'Total loss': 0.42088563757580383} | train loss {'Reaction outcome loss': 0.3291006657737689, 'Total loss': 0.3291006657737689}
2022-11-28 02:23:58,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:58,338 INFO:     Epoch: 45
2022-11-28 02:23:59,075 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4803188675364783, 'Total loss': 0.4803188675364783} | train loss {'Reaction outcome loss': 0.3229337809760062, 'Total loss': 0.3229337809760062}
2022-11-28 02:23:59,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:59,076 INFO:     Epoch: 46
2022-11-28 02:23:59,811 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4164820469396059, 'Total loss': 0.4164820469396059} | train loss {'Reaction outcome loss': 0.31817487926512467, 'Total loss': 0.31817487926512467}
2022-11-28 02:23:59,811 INFO:     Found new best model at epoch 46
2022-11-28 02:23:59,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:23:59,812 INFO:     Epoch: 47
2022-11-28 02:24:00,548 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44140270248401997, 'Total loss': 0.44140270248401997} | train loss {'Reaction outcome loss': 0.32310392649569475, 'Total loss': 0.32310392649569475}
2022-11-28 02:24:00,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:00,549 INFO:     Epoch: 48
2022-11-28 02:24:01,287 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43430985510349274, 'Total loss': 0.43430985510349274} | train loss {'Reaction outcome loss': 0.3089500471155663, 'Total loss': 0.3089500471155663}
2022-11-28 02:24:01,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:01,287 INFO:     Epoch: 49
2022-11-28 02:24:02,024 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45124289150847946, 'Total loss': 0.45124289150847946} | train loss {'Reaction outcome loss': 0.311840934281955, 'Total loss': 0.311840934281955}
2022-11-28 02:24:02,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:02,025 INFO:     Epoch: 50
2022-11-28 02:24:02,762 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41959841306819473, 'Total loss': 0.41959841306819473} | train loss {'Reaction outcome loss': 0.31062336308790034, 'Total loss': 0.31062336308790034}
2022-11-28 02:24:02,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:02,763 INFO:     Epoch: 51
2022-11-28 02:24:03,502 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43323019372169363, 'Total loss': 0.43323019372169363} | train loss {'Reaction outcome loss': 0.31479043931868234, 'Total loss': 0.31479043931868234}
2022-11-28 02:24:03,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:03,502 INFO:     Epoch: 52
2022-11-28 02:24:04,239 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4548442046656165, 'Total loss': 0.4548442046656165} | train loss {'Reaction outcome loss': 0.3113767848365375, 'Total loss': 0.3113767848365375}
2022-11-28 02:24:04,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:04,240 INFO:     Epoch: 53
2022-11-28 02:24:04,977 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43746466068334355, 'Total loss': 0.43746466068334355} | train loss {'Reaction outcome loss': 0.32481281828807024, 'Total loss': 0.32481281828807024}
2022-11-28 02:24:04,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:04,977 INFO:     Epoch: 54
2022-11-28 02:24:05,712 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44859244310578633, 'Total loss': 0.44859244310578633} | train loss {'Reaction outcome loss': 0.31845320669598265, 'Total loss': 0.31845320669598265}
2022-11-28 02:24:05,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:05,712 INFO:     Epoch: 55
2022-11-28 02:24:06,448 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4487745096517164, 'Total loss': 0.4487745096517164} | train loss {'Reaction outcome loss': 0.3092942720920336, 'Total loss': 0.3092942720920336}
2022-11-28 02:24:06,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:06,448 INFO:     Epoch: 56
2022-11-28 02:24:07,187 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4247696794742762, 'Total loss': 0.4247696794742762} | train loss {'Reaction outcome loss': 0.31376940686805327, 'Total loss': 0.31376940686805327}
2022-11-28 02:24:07,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:07,188 INFO:     Epoch: 57
2022-11-28 02:24:07,924 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45157521270042245, 'Total loss': 0.45157521270042245} | train loss {'Reaction outcome loss': 0.32098935254406735, 'Total loss': 0.32098935254406735}
2022-11-28 02:24:07,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:07,925 INFO:     Epoch: 58
2022-11-28 02:24:08,665 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4471535672282064, 'Total loss': 0.4471535672282064} | train loss {'Reaction outcome loss': 0.3079500777616364, 'Total loss': 0.3079500777616364}
2022-11-28 02:24:08,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:08,665 INFO:     Epoch: 59
2022-11-28 02:24:09,405 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4394535165886546, 'Total loss': 0.4394535165886546} | train loss {'Reaction outcome loss': 0.31784939830054026, 'Total loss': 0.31784939830054026}
2022-11-28 02:24:09,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:09,405 INFO:     Epoch: 60
2022-11-28 02:24:10,146 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4454714784095454, 'Total loss': 0.4454714784095454} | train loss {'Reaction outcome loss': 0.3131200968913856, 'Total loss': 0.3131200968913856}
2022-11-28 02:24:10,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:10,146 INFO:     Epoch: 61
2022-11-28 02:24:10,883 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4315971430650977, 'Total loss': 0.4315971430650977} | train loss {'Reaction outcome loss': 0.3136290634875415, 'Total loss': 0.3136290634875415}
2022-11-28 02:24:10,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:10,884 INFO:     Epoch: 62
2022-11-28 02:24:11,623 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42141164042228874, 'Total loss': 0.42141164042228874} | train loss {'Reaction outcome loss': 0.3105560969408663, 'Total loss': 0.3105560969408663}
2022-11-28 02:24:11,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:11,623 INFO:     Epoch: 63
2022-11-28 02:24:12,363 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43589874201042705, 'Total loss': 0.43589874201042705} | train loss {'Reaction outcome loss': 0.3087590399091361, 'Total loss': 0.3087590399091361}
2022-11-28 02:24:12,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:12,363 INFO:     Epoch: 64
2022-11-28 02:24:13,103 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.510623149053995, 'Total loss': 0.510623149053995} | train loss {'Reaction outcome loss': 0.3051014278755813, 'Total loss': 0.3051014278755813}
2022-11-28 02:24:13,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:13,103 INFO:     Epoch: 65
2022-11-28 02:24:13,843 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4310375836699508, 'Total loss': 0.4310375836699508} | train loss {'Reaction outcome loss': 0.3115144456110773, 'Total loss': 0.3115144456110773}
2022-11-28 02:24:13,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:13,843 INFO:     Epoch: 66
2022-11-28 02:24:14,581 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4467427491448646, 'Total loss': 0.4467427491448646} | train loss {'Reaction outcome loss': 0.31942208963217306, 'Total loss': 0.31942208963217306}
2022-11-28 02:24:14,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:14,581 INFO:     Epoch: 67
2022-11-28 02:24:15,321 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4432015848714252, 'Total loss': 0.4432015848714252} | train loss {'Reaction outcome loss': 0.31316065134816484, 'Total loss': 0.31316065134816484}
2022-11-28 02:24:15,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:15,321 INFO:     Epoch: 68
2022-11-28 02:24:16,061 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4289841793997343, 'Total loss': 0.4289841793997343} | train loss {'Reaction outcome loss': 0.3081091989793616, 'Total loss': 0.3081091989793616}
2022-11-28 02:24:16,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:16,062 INFO:     Epoch: 69
2022-11-28 02:24:16,802 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4681072630161463, 'Total loss': 0.4681072630161463} | train loss {'Reaction outcome loss': 0.31503409144209055, 'Total loss': 0.31503409144209055}
2022-11-28 02:24:16,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:16,802 INFO:     Epoch: 70
2022-11-28 02:24:17,545 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4644000104000402, 'Total loss': 0.4644000104000402} | train loss {'Reaction outcome loss': 0.31041439103542784, 'Total loss': 0.31041439103542784}
2022-11-28 02:24:17,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:17,545 INFO:     Epoch: 71
2022-11-28 02:24:18,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4454164647085722, 'Total loss': 0.4454164647085722} | train loss {'Reaction outcome loss': 0.3087548810500102, 'Total loss': 0.3087548810500102}
2022-11-28 02:24:18,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:18,283 INFO:     Epoch: 72
2022-11-28 02:24:19,024 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4422135734280875, 'Total loss': 0.4422135734280875} | train loss {'Reaction outcome loss': 0.3031958968943504, 'Total loss': 0.3031958968943504}
2022-11-28 02:24:19,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:19,024 INFO:     Epoch: 73
2022-11-28 02:24:19,766 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46590094441591307, 'Total loss': 0.46590094441591307} | train loss {'Reaction outcome loss': 0.3091336960797427, 'Total loss': 0.3091336960797427}
2022-11-28 02:24:19,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:19,766 INFO:     Epoch: 74
2022-11-28 02:24:20,504 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4638600089522295, 'Total loss': 0.4638600089522295} | train loss {'Reaction outcome loss': 0.3053067608537977, 'Total loss': 0.3053067608537977}
2022-11-28 02:24:20,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:20,504 INFO:     Epoch: 75
2022-11-28 02:24:21,240 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4400148370931315, 'Total loss': 0.4400148370931315} | train loss {'Reaction outcome loss': 0.3011374043331283, 'Total loss': 0.3011374043331283}
2022-11-28 02:24:21,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:21,240 INFO:     Epoch: 76
2022-11-28 02:24:21,977 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45668577723378356, 'Total loss': 0.45668577723378356} | train loss {'Reaction outcome loss': 0.3044952599209596, 'Total loss': 0.3044952599209596}
2022-11-28 02:24:21,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:21,978 INFO:     Epoch: 77
2022-11-28 02:24:22,715 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4552820265986199, 'Total loss': 0.4552820265986199} | train loss {'Reaction outcome loss': 0.3034607088956677, 'Total loss': 0.3034607088956677}
2022-11-28 02:24:22,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:22,716 INFO:     Epoch: 78
2022-11-28 02:24:23,456 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44915670503017513, 'Total loss': 0.44915670503017513} | train loss {'Reaction outcome loss': 0.30611325082842444, 'Total loss': 0.30611325082842444}
2022-11-28 02:24:23,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:23,457 INFO:     Epoch: 79
2022-11-28 02:24:24,194 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4433785819037016, 'Total loss': 0.4433785819037016} | train loss {'Reaction outcome loss': 0.3042466461994365, 'Total loss': 0.3042466461994365}
2022-11-28 02:24:24,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:24,194 INFO:     Epoch: 80
2022-11-28 02:24:24,931 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46351465374924417, 'Total loss': 0.46351465374924417} | train loss {'Reaction outcome loss': 0.3058190183317075, 'Total loss': 0.3058190183317075}
2022-11-28 02:24:24,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:24,931 INFO:     Epoch: 81
2022-11-28 02:24:25,671 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4285615020713141, 'Total loss': 0.4285615020713141} | train loss {'Reaction outcome loss': 0.3100687458836397, 'Total loss': 0.3100687458836397}
2022-11-28 02:24:25,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:25,671 INFO:     Epoch: 82
2022-11-28 02:24:26,409 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4306427339135214, 'Total loss': 0.4306427339135214} | train loss {'Reaction outcome loss': 0.3041095621273166, 'Total loss': 0.3041095621273166}
2022-11-28 02:24:26,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:26,409 INFO:     Epoch: 83
2022-11-28 02:24:27,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4474241355823916, 'Total loss': 0.4474241355823916} | train loss {'Reaction outcome loss': 0.3111148965163309, 'Total loss': 0.3111148965163309}
2022-11-28 02:24:27,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:27,150 INFO:     Epoch: 84
2022-11-28 02:24:27,888 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4369652777217155, 'Total loss': 0.4369652777217155} | train loss {'Reaction outcome loss': 0.3063126223650379, 'Total loss': 0.3063126223650379}
2022-11-28 02:24:27,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:27,888 INFO:     Epoch: 85
2022-11-28 02:24:28,629 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4424445525158283, 'Total loss': 0.4424445525158283} | train loss {'Reaction outcome loss': 0.29906039168966597, 'Total loss': 0.29906039168966597}
2022-11-28 02:24:28,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:28,629 INFO:     Epoch: 86
2022-11-28 02:24:29,374 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4629725072272988, 'Total loss': 0.4629725072272988} | train loss {'Reaction outcome loss': 0.3019788693636656, 'Total loss': 0.3019788693636656}
2022-11-28 02:24:29,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:29,374 INFO:     Epoch: 87
2022-11-28 02:24:30,112 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42880492640096085, 'Total loss': 0.42880492640096085} | train loss {'Reaction outcome loss': 0.30559255637717053, 'Total loss': 0.30559255637717053}
2022-11-28 02:24:30,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:30,113 INFO:     Epoch: 88
2022-11-28 02:24:30,850 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42979614679203476, 'Total loss': 0.42979614679203476} | train loss {'Reaction outcome loss': 0.3023389295873339, 'Total loss': 0.3023389295873339}
2022-11-28 02:24:30,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:30,850 INFO:     Epoch: 89
2022-11-28 02:24:31,588 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44709597216096036, 'Total loss': 0.44709597216096036} | train loss {'Reaction outcome loss': 0.31636145204061367, 'Total loss': 0.31636145204061367}
2022-11-28 02:24:31,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:31,588 INFO:     Epoch: 90
2022-11-28 02:24:32,324 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4678843776847041, 'Total loss': 0.4678843776847041} | train loss {'Reaction outcome loss': 0.3023854948687138, 'Total loss': 0.3023854948687138}
2022-11-28 02:24:32,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:32,325 INFO:     Epoch: 91
2022-11-28 02:24:33,063 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43306125804435375, 'Total loss': 0.43306125804435375} | train loss {'Reaction outcome loss': 0.3215110464418521, 'Total loss': 0.3215110464418521}
2022-11-28 02:24:33,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:33,064 INFO:     Epoch: 92
2022-11-28 02:24:33,804 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4685588732015255, 'Total loss': 0.4685588732015255} | train loss {'Reaction outcome loss': 0.30417851976989235, 'Total loss': 0.30417851976989235}
2022-11-28 02:24:33,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:33,804 INFO:     Epoch: 93
2022-11-28 02:24:34,540 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4104759573589924, 'Total loss': 0.4104759573589924} | train loss {'Reaction outcome loss': 0.3050404314684575, 'Total loss': 0.3050404314684575}
2022-11-28 02:24:34,540 INFO:     Found new best model at epoch 93
2022-11-28 02:24:34,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:34,541 INFO:     Epoch: 94
2022-11-28 02:24:35,281 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44156069256538566, 'Total loss': 0.44156069256538566} | train loss {'Reaction outcome loss': 0.2994361534470417, 'Total loss': 0.2994361534470417}
2022-11-28 02:24:35,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:35,282 INFO:     Epoch: 95
2022-11-28 02:24:36,017 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41865870807059974, 'Total loss': 0.41865870807059974} | train loss {'Reaction outcome loss': 0.2986431498782801, 'Total loss': 0.2986431498782801}
2022-11-28 02:24:36,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:36,017 INFO:     Epoch: 96
2022-11-28 02:24:36,754 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4264246710511141, 'Total loss': 0.4264246710511141} | train loss {'Reaction outcome loss': 0.30899650517270943, 'Total loss': 0.30899650517270943}
2022-11-28 02:24:36,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:36,754 INFO:     Epoch: 97
2022-11-28 02:24:37,486 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.430181777581226, 'Total loss': 0.430181777581226} | train loss {'Reaction outcome loss': 0.30919600523947205, 'Total loss': 0.30919600523947205}
2022-11-28 02:24:37,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:37,487 INFO:     Epoch: 98
2022-11-28 02:24:38,220 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48619314092536303, 'Total loss': 0.48619314092536303} | train loss {'Reaction outcome loss': 0.30302660881740145, 'Total loss': 0.30302660881740145}
2022-11-28 02:24:38,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:38,220 INFO:     Epoch: 99
2022-11-28 02:24:38,953 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4031828070102736, 'Total loss': 0.4031828070102736} | train loss {'Reaction outcome loss': 0.3034463742228805, 'Total loss': 0.3034463742228805}
2022-11-28 02:24:38,953 INFO:     Found new best model at epoch 99
2022-11-28 02:24:38,954 INFO:     Best model found after epoch 100 of 100.
2022-11-28 02:24:38,954 INFO:   Done with stage: TRAINING
2022-11-28 02:24:38,954 INFO:   Starting stage: EVALUATION
2022-11-28 02:24:39,091 INFO:   Done with stage: EVALUATION
2022-11-28 02:24:39,091 INFO:   Leaving out SEQ value Fold_4
2022-11-28 02:24:39,103 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:24:39,104 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:24:39,742 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:24:39,742 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:24:39,810 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:24:39,810 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:24:39,810 INFO:     No hyperparam tuning for this model
2022-11-28 02:24:39,810 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:24:39,810 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:24:39,811 INFO:     None feature selector for col prot
2022-11-28 02:24:39,811 INFO:     None feature selector for col prot
2022-11-28 02:24:39,811 INFO:     None feature selector for col prot
2022-11-28 02:24:39,812 INFO:     None feature selector for col chem
2022-11-28 02:24:39,812 INFO:     None feature selector for col chem
2022-11-28 02:24:39,812 INFO:     None feature selector for col chem
2022-11-28 02:24:39,812 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:24:39,812 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:24:39,814 INFO:     Number of params in model 169741
2022-11-28 02:24:39,817 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:24:39,817 INFO:   Starting stage: TRAINING
2022-11-28 02:24:39,870 INFO:     Val loss before train {'Reaction outcome loss': 1.075722640210932, 'Total loss': 1.075722640210932}
2022-11-28 02:24:39,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:39,870 INFO:     Epoch: 0
2022-11-28 02:24:40,613 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6027927825396712, 'Total loss': 0.6027927825396712} | train loss {'Reaction outcome loss': 0.6261710898747087, 'Total loss': 0.6261710898747087}
2022-11-28 02:24:40,613 INFO:     Found new best model at epoch 0
2022-11-28 02:24:40,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:40,614 INFO:     Epoch: 1
2022-11-28 02:24:41,361 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5609744350341234, 'Total loss': 0.5609744350341234} | train loss {'Reaction outcome loss': 0.49102301467285464, 'Total loss': 0.49102301467285464}
2022-11-28 02:24:41,361 INFO:     Found new best model at epoch 1
2022-11-28 02:24:41,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:41,362 INFO:     Epoch: 2
2022-11-28 02:24:42,109 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5334587584842335, 'Total loss': 0.5334587584842335} | train loss {'Reaction outcome loss': 0.45520000340726213, 'Total loss': 0.45520000340726213}
2022-11-28 02:24:42,110 INFO:     Found new best model at epoch 2
2022-11-28 02:24:42,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:42,110 INFO:     Epoch: 3
2022-11-28 02:24:42,861 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5140406242148443, 'Total loss': 0.5140406242148443} | train loss {'Reaction outcome loss': 0.42827519949389853, 'Total loss': 0.42827519949389853}
2022-11-28 02:24:42,861 INFO:     Found new best model at epoch 3
2022-11-28 02:24:42,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:42,862 INFO:     Epoch: 4
2022-11-28 02:24:43,609 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5183313990181143, 'Total loss': 0.5183313990181143} | train loss {'Reaction outcome loss': 0.42241541902545976, 'Total loss': 0.42241541902545976}
2022-11-28 02:24:43,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:43,610 INFO:     Epoch: 5
2022-11-28 02:24:44,359 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4970781203698028, 'Total loss': 0.4970781203698028} | train loss {'Reaction outcome loss': 0.40101749953146465, 'Total loss': 0.40101749953146465}
2022-11-28 02:24:44,359 INFO:     Found new best model at epoch 5
2022-11-28 02:24:44,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:44,360 INFO:     Epoch: 6
2022-11-28 02:24:45,107 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4933610778640617, 'Total loss': 0.4933610778640617} | train loss {'Reaction outcome loss': 0.39052667519028644, 'Total loss': 0.39052667519028644}
2022-11-28 02:24:45,107 INFO:     Found new best model at epoch 6
2022-11-28 02:24:45,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:45,108 INFO:     Epoch: 7
2022-11-28 02:24:45,856 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.518225715241649, 'Total loss': 0.518225715241649} | train loss {'Reaction outcome loss': 0.39285575688971197, 'Total loss': 0.39285575688971197}
2022-11-28 02:24:45,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:45,856 INFO:     Epoch: 8
2022-11-28 02:24:46,607 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5118869671767409, 'Total loss': 0.5118869671767409} | train loss {'Reaction outcome loss': 0.40182855260758266, 'Total loss': 0.40182855260758266}
2022-11-28 02:24:46,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:46,608 INFO:     Epoch: 9
2022-11-28 02:24:47,356 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5053394179452549, 'Total loss': 0.5053394179452549} | train loss {'Reaction outcome loss': 0.3855327921297386, 'Total loss': 0.3855327921297386}
2022-11-28 02:24:47,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:47,357 INFO:     Epoch: 10
2022-11-28 02:24:48,105 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5060324919494715, 'Total loss': 0.5060324919494715} | train loss {'Reaction outcome loss': 0.3770628308779315, 'Total loss': 0.3770628308779315}
2022-11-28 02:24:48,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:48,106 INFO:     Epoch: 11
2022-11-28 02:24:48,857 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47352191755040124, 'Total loss': 0.47352191755040124} | train loss {'Reaction outcome loss': 0.3605892572152289, 'Total loss': 0.3605892572152289}
2022-11-28 02:24:48,857 INFO:     Found new best model at epoch 11
2022-11-28 02:24:48,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:48,858 INFO:     Epoch: 12
2022-11-28 02:24:49,609 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4857885573397983, 'Total loss': 0.4857885573397983} | train loss {'Reaction outcome loss': 0.354261592317086, 'Total loss': 0.354261592317086}
2022-11-28 02:24:49,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:49,609 INFO:     Epoch: 13
2022-11-28 02:24:50,358 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5168120796707544, 'Total loss': 0.5168120796707544} | train loss {'Reaction outcome loss': 0.35800820233126884, 'Total loss': 0.35800820233126884}
2022-11-28 02:24:50,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:50,358 INFO:     Epoch: 14
2022-11-28 02:24:51,110 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47321686216376047, 'Total loss': 0.47321686216376047} | train loss {'Reaction outcome loss': 0.3556885532770864, 'Total loss': 0.3556885532770864}
2022-11-28 02:24:51,110 INFO:     Found new best model at epoch 14
2022-11-28 02:24:51,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:51,111 INFO:     Epoch: 15
2022-11-28 02:24:51,860 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.505192218856378, 'Total loss': 0.505192218856378} | train loss {'Reaction outcome loss': 0.3489593408147801, 'Total loss': 0.3489593408147801}
2022-11-28 02:24:51,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:51,860 INFO:     Epoch: 16
2022-11-28 02:24:52,608 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4773693155835975, 'Total loss': 0.4773693155835975} | train loss {'Reaction outcome loss': 0.33948332042648244, 'Total loss': 0.33948332042648244}
2022-11-28 02:24:52,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:52,608 INFO:     Epoch: 17
2022-11-28 02:24:53,355 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4868790917098522, 'Total loss': 0.4868790917098522} | train loss {'Reaction outcome loss': 0.3444242402534132, 'Total loss': 0.3444242402534132}
2022-11-28 02:24:53,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:53,356 INFO:     Epoch: 18
2022-11-28 02:24:54,105 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5340086475692012, 'Total loss': 0.5340086475692012} | train loss {'Reaction outcome loss': 0.34317564425861785, 'Total loss': 0.34317564425861785}
2022-11-28 02:24:54,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:54,105 INFO:     Epoch: 19
2022-11-28 02:24:54,851 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48992900719696825, 'Total loss': 0.48992900719696825} | train loss {'Reaction outcome loss': 0.34728906925028635, 'Total loss': 0.34728906925028635}
2022-11-28 02:24:54,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:54,851 INFO:     Epoch: 20
2022-11-28 02:24:55,598 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4834623722867532, 'Total loss': 0.4834623722867532} | train loss {'Reaction outcome loss': 0.3430498375402771, 'Total loss': 0.3430498375402771}
2022-11-28 02:24:55,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:55,598 INFO:     Epoch: 21
2022-11-28 02:24:56,347 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47160986912521446, 'Total loss': 0.47160986912521446} | train loss {'Reaction outcome loss': 0.3304546705865667, 'Total loss': 0.3304546705865667}
2022-11-28 02:24:56,347 INFO:     Found new best model at epoch 21
2022-11-28 02:24:56,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:56,348 INFO:     Epoch: 22
2022-11-28 02:24:57,096 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46245114132761955, 'Total loss': 0.46245114132761955} | train loss {'Reaction outcome loss': 0.3228896191336124, 'Total loss': 0.3228896191336124}
2022-11-28 02:24:57,096 INFO:     Found new best model at epoch 22
2022-11-28 02:24:57,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:57,097 INFO:     Epoch: 23
2022-11-28 02:24:57,847 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4804735989733176, 'Total loss': 0.4804735989733176} | train loss {'Reaction outcome loss': 0.3356874989414482, 'Total loss': 0.3356874989414482}
2022-11-28 02:24:57,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:57,847 INFO:     Epoch: 24
2022-11-28 02:24:58,594 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4934854876588691, 'Total loss': 0.4934854876588691} | train loss {'Reaction outcome loss': 0.32696624297407356, 'Total loss': 0.32696624297407356}
2022-11-28 02:24:58,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:58,594 INFO:     Epoch: 25
2022-11-28 02:24:59,342 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46534167433326895, 'Total loss': 0.46534167433326895} | train loss {'Reaction outcome loss': 0.3285979657822292, 'Total loss': 0.3285979657822292}
2022-11-28 02:24:59,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:24:59,342 INFO:     Epoch: 26
2022-11-28 02:25:00,089 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4923810559240254, 'Total loss': 0.4923810559240254} | train loss {'Reaction outcome loss': 0.3364637183998278, 'Total loss': 0.3364637183998278}
2022-11-28 02:25:00,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:00,089 INFO:     Epoch: 27
2022-11-28 02:25:00,842 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48785095661878586, 'Total loss': 0.48785095661878586} | train loss {'Reaction outcome loss': 0.33583637731157334, 'Total loss': 0.33583637731157334}
2022-11-28 02:25:00,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:00,842 INFO:     Epoch: 28
2022-11-28 02:25:01,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49564905871044507, 'Total loss': 0.49564905871044507} | train loss {'Reaction outcome loss': 0.32620174743740366, 'Total loss': 0.32620174743740366}
2022-11-28 02:25:01,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:01,589 INFO:     Epoch: 29
2022-11-28 02:25:02,338 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4743880331516266, 'Total loss': 0.4743880331516266} | train loss {'Reaction outcome loss': 0.32381306603166315, 'Total loss': 0.32381306603166315}
2022-11-28 02:25:02,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:02,338 INFO:     Epoch: 30
2022-11-28 02:25:03,087 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47168639268387447, 'Total loss': 0.47168639268387447} | train loss {'Reaction outcome loss': 0.31875559613711923, 'Total loss': 0.31875559613711923}
2022-11-28 02:25:03,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:03,087 INFO:     Epoch: 31
2022-11-28 02:25:03,837 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47116238302127883, 'Total loss': 0.47116238302127883} | train loss {'Reaction outcome loss': 0.33497735435663445, 'Total loss': 0.33497735435663445}
2022-11-28 02:25:03,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:03,837 INFO:     Epoch: 32
2022-11-28 02:25:04,591 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48145804621956567, 'Total loss': 0.48145804621956567} | train loss {'Reaction outcome loss': 0.3281864852075152, 'Total loss': 0.3281864852075152}
2022-11-28 02:25:04,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:04,591 INFO:     Epoch: 33
2022-11-28 02:25:05,343 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5105237994681705, 'Total loss': 0.5105237994681705} | train loss {'Reaction outcome loss': 0.3211475039119663, 'Total loss': 0.3211475039119663}
2022-11-28 02:25:05,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:05,343 INFO:     Epoch: 34
2022-11-28 02:25:06,095 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46806004169312393, 'Total loss': 0.46806004169312393} | train loss {'Reaction outcome loss': 0.34563820519548677, 'Total loss': 0.34563820519548677}
2022-11-28 02:25:06,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:06,096 INFO:     Epoch: 35
2022-11-28 02:25:06,848 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47530498762022366, 'Total loss': 0.47530498762022366} | train loss {'Reaction outcome loss': 0.3441145222950802, 'Total loss': 0.3441145222950802}
2022-11-28 02:25:06,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:06,849 INFO:     Epoch: 36
2022-11-28 02:25:07,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4707979190755974, 'Total loss': 0.4707979190755974} | train loss {'Reaction outcome loss': 0.31878311668149373, 'Total loss': 0.31878311668149373}
2022-11-28 02:25:07,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:07,598 INFO:     Epoch: 37
2022-11-28 02:25:08,355 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4685855819420381, 'Total loss': 0.4685855819420381} | train loss {'Reaction outcome loss': 0.31577448133635616, 'Total loss': 0.31577448133635616}
2022-11-28 02:25:08,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:08,355 INFO:     Epoch: 38
2022-11-28 02:25:09,105 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4691945304247466, 'Total loss': 0.4691945304247466} | train loss {'Reaction outcome loss': 0.3153853689731374, 'Total loss': 0.3153853689731374}
2022-11-28 02:25:09,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:09,105 INFO:     Epoch: 39
2022-11-28 02:25:09,855 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4799843985926021, 'Total loss': 0.4799843985926021} | train loss {'Reaction outcome loss': 0.31185687100986087, 'Total loss': 0.31185687100986087}
2022-11-28 02:25:09,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:09,855 INFO:     Epoch: 40
2022-11-28 02:25:10,605 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45949210158803244, 'Total loss': 0.45949210158803244} | train loss {'Reaction outcome loss': 0.32681929369868057, 'Total loss': 0.32681929369868057}
2022-11-28 02:25:10,605 INFO:     Found new best model at epoch 40
2022-11-28 02:25:10,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:10,606 INFO:     Epoch: 41
2022-11-28 02:25:11,355 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.501164688644084, 'Total loss': 0.501164688644084} | train loss {'Reaction outcome loss': 0.31679518107581234, 'Total loss': 0.31679518107581234}
2022-11-28 02:25:11,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:11,356 INFO:     Epoch: 42
2022-11-28 02:25:12,104 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4968637018041177, 'Total loss': 0.4968637018041177} | train loss {'Reaction outcome loss': 0.3256766705317536, 'Total loss': 0.3256766705317536}
2022-11-28 02:25:12,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:12,104 INFO:     Epoch: 43
2022-11-28 02:25:12,855 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4743072326210412, 'Total loss': 0.4743072326210412} | train loss {'Reaction outcome loss': 0.3342657164945776, 'Total loss': 0.3342657164945776}
2022-11-28 02:25:12,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:12,856 INFO:     Epoch: 44
2022-11-28 02:25:13,603 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4915359677238898, 'Total loss': 0.4915359677238898} | train loss {'Reaction outcome loss': 0.3207656696499118, 'Total loss': 0.3207656696499118}
2022-11-28 02:25:13,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:13,603 INFO:     Epoch: 45
2022-11-28 02:25:14,352 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48716216974637727, 'Total loss': 0.48716216974637727} | train loss {'Reaction outcome loss': 0.32259680795849033, 'Total loss': 0.32259680795849033}
2022-11-28 02:25:14,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:14,353 INFO:     Epoch: 46
2022-11-28 02:25:15,099 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47436416521668434, 'Total loss': 0.47436416521668434} | train loss {'Reaction outcome loss': 0.3097330671075264, 'Total loss': 0.3097330671075264}
2022-11-28 02:25:15,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:15,100 INFO:     Epoch: 47
2022-11-28 02:25:15,852 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4770475162023848, 'Total loss': 0.4770475162023848} | train loss {'Reaction outcome loss': 0.3043839404715776, 'Total loss': 0.3043839404715776}
2022-11-28 02:25:15,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:15,852 INFO:     Epoch: 48
2022-11-28 02:25:16,604 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46388470991091296, 'Total loss': 0.46388470991091296} | train loss {'Reaction outcome loss': 0.3099451376208168, 'Total loss': 0.3099451376208168}
2022-11-28 02:25:16,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:16,604 INFO:     Epoch: 49
2022-11-28 02:25:17,355 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49120161309838295, 'Total loss': 0.49120161309838295} | train loss {'Reaction outcome loss': 0.30031032792692214, 'Total loss': 0.30031032792692214}
2022-11-28 02:25:17,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:17,355 INFO:     Epoch: 50
2022-11-28 02:25:18,105 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4675245044583624, 'Total loss': 0.4675245044583624} | train loss {'Reaction outcome loss': 0.30282277173573824, 'Total loss': 0.30282277173573824}
2022-11-28 02:25:18,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:18,107 INFO:     Epoch: 51
2022-11-28 02:25:18,856 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.501772550019351, 'Total loss': 0.501772550019351} | train loss {'Reaction outcome loss': 0.31179411139203467, 'Total loss': 0.31179411139203467}
2022-11-28 02:25:18,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:18,856 INFO:     Epoch: 52
2022-11-28 02:25:19,608 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4565636424178427, 'Total loss': 0.4565636424178427} | train loss {'Reaction outcome loss': 0.30703761694040377, 'Total loss': 0.30703761694040377}
2022-11-28 02:25:19,608 INFO:     Found new best model at epoch 52
2022-11-28 02:25:19,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:19,609 INFO:     Epoch: 53
2022-11-28 02:25:20,356 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46941422671079636, 'Total loss': 0.46941422671079636} | train loss {'Reaction outcome loss': 0.3200348656066516, 'Total loss': 0.3200348656066516}
2022-11-28 02:25:20,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:20,356 INFO:     Epoch: 54
2022-11-28 02:25:21,102 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47119445489211514, 'Total loss': 0.47119445489211514} | train loss {'Reaction outcome loss': 0.30464281437368046, 'Total loss': 0.30464281437368046}
2022-11-28 02:25:21,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:21,103 INFO:     Epoch: 55
2022-11-28 02:25:21,851 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47024006785994227, 'Total loss': 0.47024006785994227} | train loss {'Reaction outcome loss': 0.30844669333595015, 'Total loss': 0.30844669333595015}
2022-11-28 02:25:21,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:21,851 INFO:     Epoch: 56
2022-11-28 02:25:22,603 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4505846541036259, 'Total loss': 0.4505846541036259} | train loss {'Reaction outcome loss': 0.314133039123505, 'Total loss': 0.314133039123505}
2022-11-28 02:25:22,603 INFO:     Found new best model at epoch 56
2022-11-28 02:25:22,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:22,604 INFO:     Epoch: 57
2022-11-28 02:25:23,355 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47245272723111237, 'Total loss': 0.47245272723111237} | train loss {'Reaction outcome loss': 0.2976098388795428, 'Total loss': 0.2976098388795428}
2022-11-28 02:25:23,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:23,355 INFO:     Epoch: 58
2022-11-28 02:25:24,105 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4856343326920813, 'Total loss': 0.4856343326920813} | train loss {'Reaction outcome loss': 0.30132435390967044, 'Total loss': 0.30132435390967044}
2022-11-28 02:25:24,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:24,106 INFO:     Epoch: 59
2022-11-28 02:25:24,855 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4908783198757605, 'Total loss': 0.4908783198757605} | train loss {'Reaction outcome loss': 0.295354654152806, 'Total loss': 0.295354654152806}
2022-11-28 02:25:24,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:24,856 INFO:     Epoch: 60
2022-11-28 02:25:25,604 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48482734709978104, 'Total loss': 0.48482734709978104} | train loss {'Reaction outcome loss': 0.3068532045291518, 'Total loss': 0.3068532045291518}
2022-11-28 02:25:25,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:25,605 INFO:     Epoch: 61
2022-11-28 02:25:26,355 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47797156328504736, 'Total loss': 0.47797156328504736} | train loss {'Reaction outcome loss': 0.3106576267343301, 'Total loss': 0.3106576267343301}
2022-11-28 02:25:26,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:26,355 INFO:     Epoch: 62
2022-11-28 02:25:27,101 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4691027629781853, 'Total loss': 0.4691027629781853} | train loss {'Reaction outcome loss': 0.31544873100301996, 'Total loss': 0.31544873100301996}
2022-11-28 02:25:27,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:27,101 INFO:     Epoch: 63
2022-11-28 02:25:27,851 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4520368166267872, 'Total loss': 0.4520368166267872} | train loss {'Reaction outcome loss': 0.3128331679066545, 'Total loss': 0.3128331679066545}
2022-11-28 02:25:27,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:27,851 INFO:     Epoch: 64
2022-11-28 02:25:28,603 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4920056384395469, 'Total loss': 0.4920056384395469} | train loss {'Reaction outcome loss': 0.3009188135987834, 'Total loss': 0.3009188135987834}
2022-11-28 02:25:28,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:28,603 INFO:     Epoch: 65
2022-11-28 02:25:29,357 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4608926356516101, 'Total loss': 0.4608926356516101} | train loss {'Reaction outcome loss': 0.3127127171136808, 'Total loss': 0.3127127171136808}
2022-11-28 02:25:29,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:29,357 INFO:     Epoch: 66
2022-11-28 02:25:30,112 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48225282809951087, 'Total loss': 0.48225282809951087} | train loss {'Reaction outcome loss': 0.30456774618461546, 'Total loss': 0.30456774618461546}
2022-11-28 02:25:30,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:30,113 INFO:     Epoch: 67
2022-11-28 02:25:30,865 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4896722442724488, 'Total loss': 0.4896722442724488} | train loss {'Reaction outcome loss': 0.3105302955559361, 'Total loss': 0.3105302955559361}
2022-11-28 02:25:30,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:30,865 INFO:     Epoch: 68
2022-11-28 02:25:31,617 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4567734433168715, 'Total loss': 0.4567734433168715} | train loss {'Reaction outcome loss': 0.30026637507896675, 'Total loss': 0.30026637507896675}
2022-11-28 02:25:31,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:31,617 INFO:     Epoch: 69
2022-11-28 02:25:32,368 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48025181821801444, 'Total loss': 0.48025181821801444} | train loss {'Reaction outcome loss': 0.30275049729005016, 'Total loss': 0.30275049729005016}
2022-11-28 02:25:32,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:32,368 INFO:     Epoch: 70
2022-11-28 02:25:33,117 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4565785158086907, 'Total loss': 0.4565785158086907} | train loss {'Reaction outcome loss': 0.2990378709246031, 'Total loss': 0.2990378709246031}
2022-11-28 02:25:33,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:33,118 INFO:     Epoch: 71
2022-11-28 02:25:33,872 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47129098342900927, 'Total loss': 0.47129098342900927} | train loss {'Reaction outcome loss': 0.3079259926189295, 'Total loss': 0.3079259926189295}
2022-11-28 02:25:33,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:33,872 INFO:     Epoch: 72
2022-11-28 02:25:34,623 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.493903479792855, 'Total loss': 0.493903479792855} | train loss {'Reaction outcome loss': 0.30290394177215424, 'Total loss': 0.30290394177215424}
2022-11-28 02:25:34,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:34,623 INFO:     Epoch: 73
2022-11-28 02:25:35,377 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48532275381413376, 'Total loss': 0.48532275381413376} | train loss {'Reaction outcome loss': 0.29249769129044745, 'Total loss': 0.29249769129044745}
2022-11-28 02:25:35,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:35,377 INFO:     Epoch: 74
2022-11-28 02:25:36,134 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44929336553270166, 'Total loss': 0.44929336553270166} | train loss {'Reaction outcome loss': 0.30768021004583673, 'Total loss': 0.30768021004583673}
2022-11-28 02:25:36,134 INFO:     Found new best model at epoch 74
2022-11-28 02:25:36,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:36,135 INFO:     Epoch: 75
2022-11-28 02:25:36,886 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47437286224554887, 'Total loss': 0.47437286224554887} | train loss {'Reaction outcome loss': 0.29155679084058955, 'Total loss': 0.29155679084058955}
2022-11-28 02:25:36,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:36,887 INFO:     Epoch: 76
2022-11-28 02:25:37,639 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47323697940869763, 'Total loss': 0.47323697940869763} | train loss {'Reaction outcome loss': 0.29467831594824245, 'Total loss': 0.29467831594824245}
2022-11-28 02:25:37,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:37,639 INFO:     Epoch: 77
2022-11-28 02:25:38,392 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4549896496940743, 'Total loss': 0.4549896496940743} | train loss {'Reaction outcome loss': 0.2999512462955447, 'Total loss': 0.2999512462955447}
2022-11-28 02:25:38,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:38,392 INFO:     Epoch: 78
2022-11-28 02:25:39,144 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5640931109135802, 'Total loss': 0.5640931109135802} | train loss {'Reaction outcome loss': 0.3007391479756185, 'Total loss': 0.3007391479756185}
2022-11-28 02:25:39,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:39,144 INFO:     Epoch: 79
2022-11-28 02:25:39,896 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47559216246008873, 'Total loss': 0.47559216246008873} | train loss {'Reaction outcome loss': 0.34908928963457525, 'Total loss': 0.34908928963457525}
2022-11-28 02:25:39,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:39,897 INFO:     Epoch: 80
2022-11-28 02:25:40,648 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4478112337264148, 'Total loss': 0.4478112337264148} | train loss {'Reaction outcome loss': 0.3558705493445821, 'Total loss': 0.3558705493445821}
2022-11-28 02:25:40,648 INFO:     Found new best model at epoch 80
2022-11-28 02:25:40,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:40,649 INFO:     Epoch: 81
2022-11-28 02:25:41,400 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43789621036161075, 'Total loss': 0.43789621036161075} | train loss {'Reaction outcome loss': 0.30522679344483233, 'Total loss': 0.30522679344483233}
2022-11-28 02:25:41,400 INFO:     Found new best model at epoch 81
2022-11-28 02:25:41,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:41,401 INFO:     Epoch: 82
2022-11-28 02:25:42,155 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44591405378146604, 'Total loss': 0.44591405378146604} | train loss {'Reaction outcome loss': 0.29969781540314017, 'Total loss': 0.29969781540314017}
2022-11-28 02:25:42,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:42,156 INFO:     Epoch: 83
2022-11-28 02:25:42,909 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46179011735049164, 'Total loss': 0.46179011735049164} | train loss {'Reaction outcome loss': 0.29905422906643947, 'Total loss': 0.29905422906643947}
2022-11-28 02:25:42,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:42,909 INFO:     Epoch: 84
2022-11-28 02:25:43,662 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43787685138258065, 'Total loss': 0.43787685138258065} | train loss {'Reaction outcome loss': 0.3061055182234237, 'Total loss': 0.3061055182234237}
2022-11-28 02:25:43,662 INFO:     Found new best model at epoch 84
2022-11-28 02:25:43,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:43,663 INFO:     Epoch: 85
2022-11-28 02:25:44,418 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46228371729904955, 'Total loss': 0.46228371729904955} | train loss {'Reaction outcome loss': 0.2910092068828552, 'Total loss': 0.2910092068828552}
2022-11-28 02:25:44,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:44,418 INFO:     Epoch: 86
2022-11-28 02:25:45,167 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.523397219451991, 'Total loss': 0.523397219451991} | train loss {'Reaction outcome loss': 0.3037681190319631, 'Total loss': 0.3037681190319631}
2022-11-28 02:25:45,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:45,167 INFO:     Epoch: 87
2022-11-28 02:25:45,916 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45296827805313195, 'Total loss': 0.45296827805313195} | train loss {'Reaction outcome loss': 0.3167571312020182, 'Total loss': 0.3167571312020182}
2022-11-28 02:25:45,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:45,917 INFO:     Epoch: 88
2022-11-28 02:25:46,666 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4779503419995308, 'Total loss': 0.4779503419995308} | train loss {'Reaction outcome loss': 0.3309168875974373, 'Total loss': 0.3309168875974373}
2022-11-28 02:25:46,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:46,667 INFO:     Epoch: 89
2022-11-28 02:25:47,419 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44914437034590676, 'Total loss': 0.44914437034590676} | train loss {'Reaction outcome loss': 0.2853909180082969, 'Total loss': 0.2853909180082969}
2022-11-28 02:25:47,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:47,419 INFO:     Epoch: 90
2022-11-28 02:25:48,171 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4510720649903471, 'Total loss': 0.4510720649903471} | train loss {'Reaction outcome loss': 0.29480792361835717, 'Total loss': 0.29480792361835717}
2022-11-28 02:25:48,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:48,171 INFO:     Epoch: 91
2022-11-28 02:25:48,923 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45746485787359153, 'Total loss': 0.45746485787359153} | train loss {'Reaction outcome loss': 0.29060509307736526, 'Total loss': 0.29060509307736526}
2022-11-28 02:25:48,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:48,924 INFO:     Epoch: 92
2022-11-28 02:25:49,673 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5184946297244593, 'Total loss': 0.5184946297244593} | train loss {'Reaction outcome loss': 0.2971847836787884, 'Total loss': 0.2971847836787884}
2022-11-28 02:25:49,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:49,673 INFO:     Epoch: 93
2022-11-28 02:25:50,425 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45193659818985243, 'Total loss': 0.45193659818985243} | train loss {'Reaction outcome loss': 0.3313868221664718, 'Total loss': 0.3313868221664718}
2022-11-28 02:25:50,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:50,425 INFO:     Epoch: 94
2022-11-28 02:25:51,174 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4413741434162313, 'Total loss': 0.4413741434162313} | train loss {'Reaction outcome loss': 0.3043388435805616, 'Total loss': 0.3043388435805616}
2022-11-28 02:25:51,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:51,175 INFO:     Epoch: 95
2022-11-28 02:25:51,925 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4732664667747237, 'Total loss': 0.4732664667747237} | train loss {'Reaction outcome loss': 0.2998126103226491, 'Total loss': 0.2998126103226491}
2022-11-28 02:25:51,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:51,926 INFO:     Epoch: 96
2022-11-28 02:25:52,681 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4372067993337458, 'Total loss': 0.4372067993337458} | train loss {'Reaction outcome loss': 0.2899087378792917, 'Total loss': 0.2899087378792917}
2022-11-28 02:25:52,681 INFO:     Found new best model at epoch 96
2022-11-28 02:25:52,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:52,682 INFO:     Epoch: 97
2022-11-28 02:25:53,438 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.477781224318526, 'Total loss': 0.477781224318526} | train loss {'Reaction outcome loss': 0.2886217205449637, 'Total loss': 0.2886217205449637}
2022-11-28 02:25:53,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:53,439 INFO:     Epoch: 98
2022-11-28 02:25:54,192 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48604764975607395, 'Total loss': 0.48604764975607395} | train loss {'Reaction outcome loss': 0.30177243453590014, 'Total loss': 0.30177243453590014}
2022-11-28 02:25:54,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:54,193 INFO:     Epoch: 99
2022-11-28 02:25:54,947 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.450384748083624, 'Total loss': 0.450384748083624} | train loss {'Reaction outcome loss': 0.31355587091402487, 'Total loss': 0.31355587091402487}
2022-11-28 02:25:54,948 INFO:     Best model found after epoch 97 of 100.
2022-11-28 02:25:54,948 INFO:   Done with stage: TRAINING
2022-11-28 02:25:54,948 INFO:   Starting stage: EVALUATION
2022-11-28 02:25:55,072 INFO:   Done with stage: EVALUATION
2022-11-28 02:25:55,073 INFO:   Leaving out SEQ value Fold_5
2022-11-28 02:25:55,085 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:25:55,085 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:25:55,734 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:25:55,734 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:25:55,802 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:25:55,802 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:25:55,802 INFO:     No hyperparam tuning for this model
2022-11-28 02:25:55,802 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:25:55,802 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:25:55,803 INFO:     None feature selector for col prot
2022-11-28 02:25:55,803 INFO:     None feature selector for col prot
2022-11-28 02:25:55,803 INFO:     None feature selector for col prot
2022-11-28 02:25:55,804 INFO:     None feature selector for col chem
2022-11-28 02:25:55,804 INFO:     None feature selector for col chem
2022-11-28 02:25:55,804 INFO:     None feature selector for col chem
2022-11-28 02:25:55,804 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:25:55,804 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:25:55,806 INFO:     Number of params in model 169741
2022-11-28 02:25:55,809 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:25:55,809 INFO:   Starting stage: TRAINING
2022-11-28 02:25:55,863 INFO:     Val loss before train {'Reaction outcome loss': 1.0067621875892987, 'Total loss': 1.0067621875892987}
2022-11-28 02:25:55,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:55,863 INFO:     Epoch: 0
2022-11-28 02:25:56,614 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5120461163195696, 'Total loss': 0.5120461163195696} | train loss {'Reaction outcome loss': 0.6415157693811515, 'Total loss': 0.6415157693811515}
2022-11-28 02:25:56,615 INFO:     Found new best model at epoch 0
2022-11-28 02:25:56,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:56,615 INFO:     Epoch: 1
2022-11-28 02:25:57,368 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44094945083964954, 'Total loss': 0.44094945083964954} | train loss {'Reaction outcome loss': 0.5147346408079992, 'Total loss': 0.5147346408079992}
2022-11-28 02:25:57,368 INFO:     Found new best model at epoch 1
2022-11-28 02:25:57,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:57,369 INFO:     Epoch: 2
2022-11-28 02:25:58,121 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41325074434280396, 'Total loss': 0.41325074434280396} | train loss {'Reaction outcome loss': 0.4721967731470521, 'Total loss': 0.4721967731470521}
2022-11-28 02:25:58,121 INFO:     Found new best model at epoch 2
2022-11-28 02:25:58,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:58,122 INFO:     Epoch: 3
2022-11-28 02:25:58,878 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4062416621229865, 'Total loss': 0.4062416621229865} | train loss {'Reaction outcome loss': 0.445871795885838, 'Total loss': 0.445871795885838}
2022-11-28 02:25:58,878 INFO:     Found new best model at epoch 3
2022-11-28 02:25:58,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:58,879 INFO:     Epoch: 4
2022-11-28 02:25:59,634 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.41803077201951633, 'Total loss': 0.41803077201951633} | train loss {'Reaction outcome loss': 0.42663921717448755, 'Total loss': 0.42663921717448755}
2022-11-28 02:25:59,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:25:59,634 INFO:     Epoch: 5
2022-11-28 02:26:00,386 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42737176472490485, 'Total loss': 0.42737176472490485} | train loss {'Reaction outcome loss': 0.4237580292741297, 'Total loss': 0.4237580292741297}
2022-11-28 02:26:00,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:00,386 INFO:     Epoch: 6
2022-11-28 02:26:01,139 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4156848629089919, 'Total loss': 0.4156848629089919} | train loss {'Reaction outcome loss': 0.41675618523166247, 'Total loss': 0.41675618523166247}
2022-11-28 02:26:01,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:01,140 INFO:     Epoch: 7
2022-11-28 02:26:01,894 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40236544744534924, 'Total loss': 0.40236544744534924} | train loss {'Reaction outcome loss': 0.4047675452379864, 'Total loss': 0.4047675452379864}
2022-11-28 02:26:01,894 INFO:     Found new best model at epoch 7
2022-11-28 02:26:01,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:01,895 INFO:     Epoch: 8
2022-11-28 02:26:02,649 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42358787527138536, 'Total loss': 0.42358787527138536} | train loss {'Reaction outcome loss': 0.3922887688902346, 'Total loss': 0.3922887688902346}
2022-11-28 02:26:02,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:02,649 INFO:     Epoch: 9
2022-11-28 02:26:03,404 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40355882014740596, 'Total loss': 0.40355882014740596} | train loss {'Reaction outcome loss': 0.381677097833229, 'Total loss': 0.381677097833229}
2022-11-28 02:26:03,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:03,404 INFO:     Epoch: 10
2022-11-28 02:26:04,154 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4012725783342665, 'Total loss': 0.4012725783342665} | train loss {'Reaction outcome loss': 0.3885626546465434, 'Total loss': 0.3885626546465434}
2022-11-28 02:26:04,154 INFO:     Found new best model at epoch 10
2022-11-28 02:26:04,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:04,155 INFO:     Epoch: 11
2022-11-28 02:26:04,916 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39555893059481273, 'Total loss': 0.39555893059481273} | train loss {'Reaction outcome loss': 0.3749165636551404, 'Total loss': 0.3749165636551404}
2022-11-28 02:26:04,916 INFO:     Found new best model at epoch 11
2022-11-28 02:26:04,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:04,917 INFO:     Epoch: 12
2022-11-28 02:26:05,689 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36965886198661546, 'Total loss': 0.36965886198661546} | train loss {'Reaction outcome loss': 0.37691267199723827, 'Total loss': 0.37691267199723827}
2022-11-28 02:26:05,689 INFO:     Found new best model at epoch 12
2022-11-28 02:26:05,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:05,690 INFO:     Epoch: 13
2022-11-28 02:26:06,463 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4188506251031702, 'Total loss': 0.4188506251031702} | train loss {'Reaction outcome loss': 0.3744629216644355, 'Total loss': 0.3744629216644355}
2022-11-28 02:26:06,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:06,463 INFO:     Epoch: 14
2022-11-28 02:26:07,234 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4107939440079711, 'Total loss': 0.4107939440079711} | train loss {'Reaction outcome loss': 0.3773905645739212, 'Total loss': 0.3773905645739212}
2022-11-28 02:26:07,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:07,235 INFO:     Epoch: 15
2022-11-28 02:26:08,008 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3765306550670754, 'Total loss': 0.3765306550670754} | train loss {'Reaction outcome loss': 0.3704899534383253, 'Total loss': 0.3704899534383253}
2022-11-28 02:26:08,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:08,008 INFO:     Epoch: 16
2022-11-28 02:26:08,777 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41900218989361415, 'Total loss': 0.41900218989361415} | train loss {'Reaction outcome loss': 0.36217200605251526, 'Total loss': 0.36217200605251526}
2022-11-28 02:26:08,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:08,777 INFO:     Epoch: 17
2022-11-28 02:26:09,548 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38874444348568266, 'Total loss': 0.38874444348568266} | train loss {'Reaction outcome loss': 0.36724166216155296, 'Total loss': 0.36724166216155296}
2022-11-28 02:26:09,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:09,548 INFO:     Epoch: 18
2022-11-28 02:26:10,317 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.433525547046553, 'Total loss': 0.433525547046553} | train loss {'Reaction outcome loss': 0.3631286155055409, 'Total loss': 0.3631286155055409}
2022-11-28 02:26:10,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:10,318 INFO:     Epoch: 19
2022-11-28 02:26:11,090 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3847924860363657, 'Total loss': 0.3847924860363657} | train loss {'Reaction outcome loss': 0.35551158069380323, 'Total loss': 0.35551158069380323}
2022-11-28 02:26:11,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:11,091 INFO:     Epoch: 20
2022-11-28 02:26:11,864 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3956612419675697, 'Total loss': 0.3956612419675697} | train loss {'Reaction outcome loss': 0.36062359568561136, 'Total loss': 0.36062359568561136}
2022-11-28 02:26:11,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:11,864 INFO:     Epoch: 21
2022-11-28 02:26:12,634 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39555477621880447, 'Total loss': 0.39555477621880447} | train loss {'Reaction outcome loss': 0.35987565977883484, 'Total loss': 0.35987565977883484}
2022-11-28 02:26:12,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:12,634 INFO:     Epoch: 22
2022-11-28 02:26:13,404 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40970972612161527, 'Total loss': 0.40970972612161527} | train loss {'Reaction outcome loss': 0.36048975016786017, 'Total loss': 0.36048975016786017}
2022-11-28 02:26:13,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:13,404 INFO:     Epoch: 23
2022-11-28 02:26:14,174 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4644810686057264, 'Total loss': 0.4644810686057264} | train loss {'Reaction outcome loss': 0.3507964778766941, 'Total loss': 0.3507964778766941}
2022-11-28 02:26:14,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:14,175 INFO:     Epoch: 24
2022-11-28 02:26:14,945 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41282201067290525, 'Total loss': 0.41282201067290525} | train loss {'Reaction outcome loss': 0.38867538714939764, 'Total loss': 0.38867538714939764}
2022-11-28 02:26:14,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:14,945 INFO:     Epoch: 25
2022-11-28 02:26:15,715 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38889018954201177, 'Total loss': 0.38889018954201177} | train loss {'Reaction outcome loss': 0.35798556218866395, 'Total loss': 0.35798556218866395}
2022-11-28 02:26:15,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:15,715 INFO:     Epoch: 26
2022-11-28 02:26:16,486 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.393490804867311, 'Total loss': 0.393490804867311} | train loss {'Reaction outcome loss': 0.34635174292425325, 'Total loss': 0.34635174292425325}
2022-11-28 02:26:16,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:16,486 INFO:     Epoch: 27
2022-11-28 02:26:17,255 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39955866286023095, 'Total loss': 0.39955866286023095} | train loss {'Reaction outcome loss': 0.3454294382077962, 'Total loss': 0.3454294382077962}
2022-11-28 02:26:17,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:17,255 INFO:     Epoch: 28
2022-11-28 02:26:18,027 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37931358797306364, 'Total loss': 0.37931358797306364} | train loss {'Reaction outcome loss': 0.3675391362142949, 'Total loss': 0.3675391362142949}
2022-11-28 02:26:18,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:18,027 INFO:     Epoch: 29
2022-11-28 02:26:18,800 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37454368580471387, 'Total loss': 0.37454368580471387} | train loss {'Reaction outcome loss': 0.34777638295039476, 'Total loss': 0.34777638295039476}
2022-11-28 02:26:18,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:18,800 INFO:     Epoch: 30
2022-11-28 02:26:19,573 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3660713857547803, 'Total loss': 0.3660713857547803} | train loss {'Reaction outcome loss': 0.34287716758999265, 'Total loss': 0.34287716758999265}
2022-11-28 02:26:19,574 INFO:     Found new best model at epoch 30
2022-11-28 02:26:19,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:19,574 INFO:     Epoch: 31
2022-11-28 02:26:20,343 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39489560735157947, 'Total loss': 0.39489560735157947} | train loss {'Reaction outcome loss': 0.3505049801850126, 'Total loss': 0.3505049801850126}
2022-11-28 02:26:20,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:20,344 INFO:     Epoch: 32
2022-11-28 02:26:21,117 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38292043351314287, 'Total loss': 0.38292043351314287} | train loss {'Reaction outcome loss': 0.351581945502565, 'Total loss': 0.351581945502565}
2022-11-28 02:26:21,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:21,117 INFO:     Epoch: 33
2022-11-28 02:26:21,889 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3846585594794967, 'Total loss': 0.3846585594794967} | train loss {'Reaction outcome loss': 0.33126884124238, 'Total loss': 0.33126884124238}
2022-11-28 02:26:21,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:21,889 INFO:     Epoch: 34
2022-11-28 02:26:22,661 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38924209773540497, 'Total loss': 0.38924209773540497} | train loss {'Reaction outcome loss': 0.3414820327087935, 'Total loss': 0.3414820327087935}
2022-11-28 02:26:22,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:22,661 INFO:     Epoch: 35
2022-11-28 02:26:23,435 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44223656166683545, 'Total loss': 0.44223656166683545} | train loss {'Reaction outcome loss': 0.33854866358131047, 'Total loss': 0.33854866358131047}
2022-11-28 02:26:23,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:23,436 INFO:     Epoch: 36
2022-11-28 02:26:24,208 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39250913905826484, 'Total loss': 0.39250913905826484} | train loss {'Reaction outcome loss': 0.35107871036418536, 'Total loss': 0.35107871036418536}
2022-11-28 02:26:24,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:24,208 INFO:     Epoch: 37
2022-11-28 02:26:24,979 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4002978334372694, 'Total loss': 0.4002978334372694} | train loss {'Reaction outcome loss': 0.3550283696789008, 'Total loss': 0.3550283696789008}
2022-11-28 02:26:24,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:24,979 INFO:     Epoch: 38
2022-11-28 02:26:25,752 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3902872915972363, 'Total loss': 0.3902872915972363} | train loss {'Reaction outcome loss': 0.3329570203046748, 'Total loss': 0.3329570203046748}
2022-11-28 02:26:25,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:25,752 INFO:     Epoch: 39
2022-11-28 02:26:26,525 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.382233279672536, 'Total loss': 0.382233279672536} | train loss {'Reaction outcome loss': 0.3325485516233965, 'Total loss': 0.3325485516233965}
2022-11-28 02:26:26,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:26,526 INFO:     Epoch: 40
2022-11-28 02:26:27,298 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37655178796161304, 'Total loss': 0.37655178796161304} | train loss {'Reaction outcome loss': 0.3358109295669838, 'Total loss': 0.3358109295669838}
2022-11-28 02:26:27,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:27,299 INFO:     Epoch: 41
2022-11-28 02:26:28,069 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.381302590735934, 'Total loss': 0.381302590735934} | train loss {'Reaction outcome loss': 0.33098260626981135, 'Total loss': 0.33098260626981135}
2022-11-28 02:26:28,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:28,070 INFO:     Epoch: 42
2022-11-28 02:26:28,843 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4145067605105313, 'Total loss': 0.4145067605105313} | train loss {'Reaction outcome loss': 0.3332852756054054, 'Total loss': 0.3332852756054054}
2022-11-28 02:26:28,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:28,844 INFO:     Epoch: 43
2022-11-28 02:26:29,614 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37564811212095345, 'Total loss': 0.37564811212095345} | train loss {'Reaction outcome loss': 0.34097726748660506, 'Total loss': 0.34097726748660506}
2022-11-28 02:26:29,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:29,615 INFO:     Epoch: 44
2022-11-28 02:26:30,388 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39803247356956656, 'Total loss': 0.39803247356956656} | train loss {'Reaction outcome loss': 0.330330044936072, 'Total loss': 0.330330044936072}
2022-11-28 02:26:30,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:30,388 INFO:     Epoch: 45
2022-11-28 02:26:31,160 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3754315068098632, 'Total loss': 0.3754315068098632} | train loss {'Reaction outcome loss': 0.3373284552261414, 'Total loss': 0.3373284552261414}
2022-11-28 02:26:31,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:31,160 INFO:     Epoch: 46
2022-11-28 02:26:31,929 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38248452137817035, 'Total loss': 0.38248452137817035} | train loss {'Reaction outcome loss': 0.3317650352352061, 'Total loss': 0.3317650352352061}
2022-11-28 02:26:31,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:31,930 INFO:     Epoch: 47
2022-11-28 02:26:32,706 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3913841948590495, 'Total loss': 0.3913841948590495} | train loss {'Reaction outcome loss': 0.34401387654184573, 'Total loss': 0.34401387654184573}
2022-11-28 02:26:32,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:32,706 INFO:     Epoch: 48
2022-11-28 02:26:33,478 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3888703638857061, 'Total loss': 0.3888703638857061} | train loss {'Reaction outcome loss': 0.3192495931890088, 'Total loss': 0.3192495931890088}
2022-11-28 02:26:33,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:33,478 INFO:     Epoch: 49
2022-11-28 02:26:34,252 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39647693948989565, 'Total loss': 0.39647693948989565} | train loss {'Reaction outcome loss': 0.33057587620941736, 'Total loss': 0.33057587620941736}
2022-11-28 02:26:34,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:34,252 INFO:     Epoch: 50
2022-11-28 02:26:35,025 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42395357144149864, 'Total loss': 0.42395357144149864} | train loss {'Reaction outcome loss': 0.3488073927097716, 'Total loss': 0.3488073927097716}
2022-11-28 02:26:35,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:35,025 INFO:     Epoch: 51
2022-11-28 02:26:35,797 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49607128311287274, 'Total loss': 0.49607128311287274} | train loss {'Reaction outcome loss': 0.3264669777169401, 'Total loss': 0.3264669777169401}
2022-11-28 02:26:35,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:35,797 INFO:     Epoch: 52
2022-11-28 02:26:36,568 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37821117864752357, 'Total loss': 0.37821117864752357} | train loss {'Reaction outcome loss': 0.3315688497005106, 'Total loss': 0.3315688497005106}
2022-11-28 02:26:36,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:36,568 INFO:     Epoch: 53
2022-11-28 02:26:37,341 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38647605055435136, 'Total loss': 0.38647605055435136} | train loss {'Reaction outcome loss': 0.3281543195126993, 'Total loss': 0.3281543195126993}
2022-11-28 02:26:37,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:37,341 INFO:     Epoch: 54
2022-11-28 02:26:38,113 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4190937995233319, 'Total loss': 0.4190937995233319} | train loss {'Reaction outcome loss': 0.3384811275106994, 'Total loss': 0.3384811275106994}
2022-11-28 02:26:38,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:38,113 INFO:     Epoch: 55
2022-11-28 02:26:38,885 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3776351525024934, 'Total loss': 0.3776351525024934} | train loss {'Reaction outcome loss': 0.33406089098845054, 'Total loss': 0.33406089098845054}
2022-11-28 02:26:38,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:38,886 INFO:     Epoch: 56
2022-11-28 02:26:39,663 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41257410327141936, 'Total loss': 0.41257410327141936} | train loss {'Reaction outcome loss': 0.31826647959257426, 'Total loss': 0.31826647959257426}
2022-11-28 02:26:39,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:39,664 INFO:     Epoch: 57
2022-11-28 02:26:40,436 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4174689388071949, 'Total loss': 0.4174689388071949} | train loss {'Reaction outcome loss': 0.3547932634107497, 'Total loss': 0.3547932634107497}
2022-11-28 02:26:40,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:40,436 INFO:     Epoch: 58
2022-11-28 02:26:41,210 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4511816698041829, 'Total loss': 0.4511816698041829} | train loss {'Reaction outcome loss': 0.35236258313120133, 'Total loss': 0.35236258313120133}
2022-11-28 02:26:41,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:41,210 INFO:     Epoch: 59
2022-11-28 02:26:41,987 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39329151199622586, 'Total loss': 0.39329151199622586} | train loss {'Reaction outcome loss': 0.3405747476980271, 'Total loss': 0.3405747476980271}
2022-11-28 02:26:41,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:41,987 INFO:     Epoch: 60
2022-11-28 02:26:42,758 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3929098610850898, 'Total loss': 0.3929098610850898} | train loss {'Reaction outcome loss': 0.34335515521436566, 'Total loss': 0.34335515521436566}
2022-11-28 02:26:42,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:42,758 INFO:     Epoch: 61
2022-11-28 02:26:43,530 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40330164100636134, 'Total loss': 0.40330164100636134} | train loss {'Reaction outcome loss': 0.33948699520667075, 'Total loss': 0.33948699520667075}
2022-11-28 02:26:43,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:43,530 INFO:     Epoch: 62
2022-11-28 02:26:44,305 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3880328070372343, 'Total loss': 0.3880328070372343} | train loss {'Reaction outcome loss': 0.3335055878615904, 'Total loss': 0.3335055878615904}
2022-11-28 02:26:44,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:44,306 INFO:     Epoch: 63
2022-11-28 02:26:45,080 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3809654482386329, 'Total loss': 0.3809654482386329} | train loss {'Reaction outcome loss': 0.3170747386844478, 'Total loss': 0.3170747386844478}
2022-11-28 02:26:45,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:45,080 INFO:     Epoch: 64
2022-11-28 02:26:45,855 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39858773249116813, 'Total loss': 0.39858773249116813} | train loss {'Reaction outcome loss': 0.3216107456609305, 'Total loss': 0.3216107456609305}
2022-11-28 02:26:45,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:45,855 INFO:     Epoch: 65
2022-11-28 02:26:46,629 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.379186193712733, 'Total loss': 0.379186193712733} | train loss {'Reaction outcome loss': 0.32467024438535635, 'Total loss': 0.32467024438535635}
2022-11-28 02:26:46,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:46,630 INFO:     Epoch: 66
2022-11-28 02:26:47,407 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4103429320860993, 'Total loss': 0.4103429320860993} | train loss {'Reaction outcome loss': 0.3283948420211371, 'Total loss': 0.3283948420211371}
2022-11-28 02:26:47,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:47,407 INFO:     Epoch: 67
2022-11-28 02:26:48,181 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41740768538279965, 'Total loss': 0.41740768538279965} | train loss {'Reaction outcome loss': 0.3369057224950327, 'Total loss': 0.3369057224950327}
2022-11-28 02:26:48,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:48,182 INFO:     Epoch: 68
2022-11-28 02:26:48,956 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36889718049629167, 'Total loss': 0.36889718049629167} | train loss {'Reaction outcome loss': 0.3460666030600124, 'Total loss': 0.3460666030600124}
2022-11-28 02:26:48,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:48,956 INFO:     Epoch: 69
2022-11-28 02:26:49,731 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40340430729768495, 'Total loss': 0.40340430729768495} | train loss {'Reaction outcome loss': 0.3147546625752681, 'Total loss': 0.3147546625752681}
2022-11-28 02:26:49,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:49,731 INFO:     Epoch: 70
2022-11-28 02:26:50,506 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3955574028871276, 'Total loss': 0.3955574028871276} | train loss {'Reaction outcome loss': 0.3215176459809064, 'Total loss': 0.3215176459809064}
2022-11-28 02:26:50,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:50,506 INFO:     Epoch: 71
2022-11-28 02:26:51,280 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42063335566358134, 'Total loss': 0.42063335566358134} | train loss {'Reaction outcome loss': 0.317326331217038, 'Total loss': 0.317326331217038}
2022-11-28 02:26:51,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:51,281 INFO:     Epoch: 72
2022-11-28 02:26:52,055 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4160534336485646, 'Total loss': 0.4160534336485646} | train loss {'Reaction outcome loss': 0.3439748471504764, 'Total loss': 0.3439748471504764}
2022-11-28 02:26:52,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:52,055 INFO:     Epoch: 73
2022-11-28 02:26:52,826 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3690936363894831, 'Total loss': 0.3690936363894831} | train loss {'Reaction outcome loss': 0.3291327051124592, 'Total loss': 0.3291327051124592}
2022-11-28 02:26:52,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:52,826 INFO:     Epoch: 74
2022-11-28 02:26:53,596 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4032234400510788, 'Total loss': 0.4032234400510788} | train loss {'Reaction outcome loss': 0.31339048989671414, 'Total loss': 0.31339048989671414}
2022-11-28 02:26:53,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:53,597 INFO:     Epoch: 75
2022-11-28 02:26:54,366 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4375573264604265, 'Total loss': 0.4375573264604265} | train loss {'Reaction outcome loss': 0.3227027102617683, 'Total loss': 0.3227027102617683}
2022-11-28 02:26:54,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:54,366 INFO:     Epoch: 76
2022-11-28 02:26:55,138 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38768602738326247, 'Total loss': 0.38768602738326247} | train loss {'Reaction outcome loss': 0.3149075004331549, 'Total loss': 0.3149075004331549}
2022-11-28 02:26:55,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:55,138 INFO:     Epoch: 77
2022-11-28 02:26:55,912 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.393235268579288, 'Total loss': 0.393235268579288} | train loss {'Reaction outcome loss': 0.31503957681930983, 'Total loss': 0.31503957681930983}
2022-11-28 02:26:55,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:55,912 INFO:     Epoch: 78
2022-11-28 02:26:56,684 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40125828541137953, 'Total loss': 0.40125828541137953} | train loss {'Reaction outcome loss': 0.3289370885201794, 'Total loss': 0.3289370885201794}
2022-11-28 02:26:56,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:56,685 INFO:     Epoch: 79
2022-11-28 02:26:57,458 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43130291998386383, 'Total loss': 0.43130291998386383} | train loss {'Reaction outcome loss': 0.3188312803489356, 'Total loss': 0.3188312803489356}
2022-11-28 02:26:57,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:57,458 INFO:     Epoch: 80
2022-11-28 02:26:58,228 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4007370431314815, 'Total loss': 0.4007370431314815} | train loss {'Reaction outcome loss': 0.32964760617085315, 'Total loss': 0.32964760617085315}
2022-11-28 02:26:58,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:58,229 INFO:     Epoch: 81
2022-11-28 02:26:59,002 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.393519229170951, 'Total loss': 0.393519229170951} | train loss {'Reaction outcome loss': 0.3296727316702908, 'Total loss': 0.3296727316702908}
2022-11-28 02:26:59,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:59,002 INFO:     Epoch: 82
2022-11-28 02:26:59,774 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3684422773393718, 'Total loss': 0.3684422773393718} | train loss {'Reaction outcome loss': 0.3231648729759672, 'Total loss': 0.3231648729759672}
2022-11-28 02:26:59,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:26:59,774 INFO:     Epoch: 83
2022-11-28 02:27:00,546 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43574765358458867, 'Total loss': 0.43574765358458867} | train loss {'Reaction outcome loss': 0.3173323543930826, 'Total loss': 0.3173323543930826}
2022-11-28 02:27:00,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:00,546 INFO:     Epoch: 84
2022-11-28 02:27:01,321 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3945532434365966, 'Total loss': 0.3945532434365966} | train loss {'Reaction outcome loss': 0.32960401531610534, 'Total loss': 0.32960401531610534}
2022-11-28 02:27:01,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:01,322 INFO:     Epoch: 85
2022-11-28 02:27:02,095 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41795493255962024, 'Total loss': 0.41795493255962024} | train loss {'Reaction outcome loss': 0.31398148478766685, 'Total loss': 0.31398148478766685}
2022-11-28 02:27:02,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:02,096 INFO:     Epoch: 86
2022-11-28 02:27:02,870 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44559109109369194, 'Total loss': 0.44559109109369194} | train loss {'Reaction outcome loss': 0.31986401952531657, 'Total loss': 0.31986401952531657}
2022-11-28 02:27:02,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:02,870 INFO:     Epoch: 87
2022-11-28 02:27:03,641 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40374585444276984, 'Total loss': 0.40374585444276984} | train loss {'Reaction outcome loss': 0.3262981529751046, 'Total loss': 0.3262981529751046}
2022-11-28 02:27:03,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:03,642 INFO:     Epoch: 88
2022-11-28 02:27:04,418 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45025154745036905, 'Total loss': 0.45025154745036905} | train loss {'Reaction outcome loss': 0.3191114741901637, 'Total loss': 0.3191114741901637}
2022-11-28 02:27:04,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:04,418 INFO:     Epoch: 89
2022-11-28 02:27:05,191 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3923810986293988, 'Total loss': 0.3923810986293988} | train loss {'Reaction outcome loss': 0.3349409995351726, 'Total loss': 0.3349409995351726}
2022-11-28 02:27:05,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:05,191 INFO:     Epoch: 90
2022-11-28 02:27:05,966 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40702149509028956, 'Total loss': 0.40702149509028956} | train loss {'Reaction outcome loss': 0.34046727723558906, 'Total loss': 0.34046727723558906}
2022-11-28 02:27:05,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:05,966 INFO:     Epoch: 91
2022-11-28 02:27:06,738 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4028449627486142, 'Total loss': 0.4028449627486142} | train loss {'Reaction outcome loss': 0.3178125437092685, 'Total loss': 0.3178125437092685}
2022-11-28 02:27:06,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:06,738 INFO:     Epoch: 92
2022-11-28 02:27:07,510 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4067934700711207, 'Total loss': 0.4067934700711207} | train loss {'Reaction outcome loss': 0.31552318401487645, 'Total loss': 0.31552318401487645}
2022-11-28 02:27:07,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:07,510 INFO:     Epoch: 93
2022-11-28 02:27:08,284 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3676869706674056, 'Total loss': 0.3676869706674056} | train loss {'Reaction outcome loss': 0.32364643802526993, 'Total loss': 0.32364643802526993}
2022-11-28 02:27:08,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:08,284 INFO:     Epoch: 94
2022-11-28 02:27:09,059 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39500052397224034, 'Total loss': 0.39500052397224034} | train loss {'Reaction outcome loss': 0.32329112783956687, 'Total loss': 0.32329112783956687}
2022-11-28 02:27:09,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:09,059 INFO:     Epoch: 95
2022-11-28 02:27:09,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39995521891184826, 'Total loss': 0.39995521891184826} | train loss {'Reaction outcome loss': 0.3185987531392258, 'Total loss': 0.3185987531392258}
2022-11-28 02:27:09,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:09,830 INFO:     Epoch: 96
2022-11-28 02:27:10,600 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4005434550344944, 'Total loss': 0.4005434550344944} | train loss {'Reaction outcome loss': 0.31693645630730316, 'Total loss': 0.31693645630730316}
2022-11-28 02:27:10,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:10,600 INFO:     Epoch: 97
2022-11-28 02:27:11,376 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3976445584134622, 'Total loss': 0.3976445584134622} | train loss {'Reaction outcome loss': 0.3185472632588645, 'Total loss': 0.3185472632588645}
2022-11-28 02:27:11,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:11,376 INFO:     Epoch: 98
2022-11-28 02:27:12,148 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42385479367592116, 'Total loss': 0.42385479367592116} | train loss {'Reaction outcome loss': 0.3291858553439605, 'Total loss': 0.3291858553439605}
2022-11-28 02:27:12,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:12,148 INFO:     Epoch: 99
2022-11-28 02:27:12,920 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42393198202956806, 'Total loss': 0.42393198202956806} | train loss {'Reaction outcome loss': 0.31714014746347696, 'Total loss': 0.31714014746347696}
2022-11-28 02:27:12,920 INFO:     Best model found after epoch 31 of 100.
2022-11-28 02:27:12,920 INFO:   Done with stage: TRAINING
2022-11-28 02:27:12,920 INFO:   Starting stage: EVALUATION
2022-11-28 02:27:13,045 INFO:   Done with stage: EVALUATION
2022-11-28 02:27:13,045 INFO:   Leaving out SEQ value Fold_6
2022-11-28 02:27:13,058 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:27:13,058 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:27:13,705 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:27:13,705 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:27:13,773 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:27:13,773 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:27:13,773 INFO:     No hyperparam tuning for this model
2022-11-28 02:27:13,773 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:27:13,773 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:27:13,774 INFO:     None feature selector for col prot
2022-11-28 02:27:13,774 INFO:     None feature selector for col prot
2022-11-28 02:27:13,774 INFO:     None feature selector for col prot
2022-11-28 02:27:13,775 INFO:     None feature selector for col chem
2022-11-28 02:27:13,775 INFO:     None feature selector for col chem
2022-11-28 02:27:13,775 INFO:     None feature selector for col chem
2022-11-28 02:27:13,775 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:27:13,775 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:27:13,776 INFO:     Number of params in model 169741
2022-11-28 02:27:13,780 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:27:13,780 INFO:   Starting stage: TRAINING
2022-11-28 02:27:13,834 INFO:     Val loss before train {'Reaction outcome loss': 1.0047070546583696, 'Total loss': 1.0047070546583696}
2022-11-28 02:27:13,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:13,834 INFO:     Epoch: 0
2022-11-28 02:27:14,607 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5291848081079397, 'Total loss': 0.5291848081079397} | train loss {'Reaction outcome loss': 0.6286943678212492, 'Total loss': 0.6286943678212492}
2022-11-28 02:27:14,607 INFO:     Found new best model at epoch 0
2022-11-28 02:27:14,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:14,608 INFO:     Epoch: 1
2022-11-28 02:27:15,378 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5211158658970486, 'Total loss': 0.5211158658970486} | train loss {'Reaction outcome loss': 0.5029397250307717, 'Total loss': 0.5029397250307717}
2022-11-28 02:27:15,378 INFO:     Found new best model at epoch 1
2022-11-28 02:27:15,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:15,379 INFO:     Epoch: 2
2022-11-28 02:27:16,152 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48893660036000336, 'Total loss': 0.48893660036000336} | train loss {'Reaction outcome loss': 0.4631770980970459, 'Total loss': 0.4631770980970459}
2022-11-28 02:27:16,152 INFO:     Found new best model at epoch 2
2022-11-28 02:27:16,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:16,153 INFO:     Epoch: 3
2022-11-28 02:27:16,924 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5219095376404849, 'Total loss': 0.5219095376404849} | train loss {'Reaction outcome loss': 0.44528393099001545, 'Total loss': 0.44528393099001545}
2022-11-28 02:27:16,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:16,925 INFO:     Epoch: 4
2022-11-28 02:27:17,698 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4971051768145778, 'Total loss': 0.4971051768145778} | train loss {'Reaction outcome loss': 0.4376371179515051, 'Total loss': 0.4376371179515051}
2022-11-28 02:27:17,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:17,698 INFO:     Epoch: 5
2022-11-28 02:27:18,473 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.469049773094329, 'Total loss': 0.469049773094329} | train loss {'Reaction outcome loss': 0.4315517877156918, 'Total loss': 0.4315517877156918}
2022-11-28 02:27:18,473 INFO:     Found new best model at epoch 5
2022-11-28 02:27:18,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:18,474 INFO:     Epoch: 6
2022-11-28 02:27:19,247 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45874917710369284, 'Total loss': 0.45874917710369284} | train loss {'Reaction outcome loss': 0.40561797472870786, 'Total loss': 0.40561797472870786}
2022-11-28 02:27:19,247 INFO:     Found new best model at epoch 6
2022-11-28 02:27:19,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:19,248 INFO:     Epoch: 7
2022-11-28 02:27:20,016 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4663563645021482, 'Total loss': 0.4663563645021482} | train loss {'Reaction outcome loss': 0.40525813690322615, 'Total loss': 0.40525813690322615}
2022-11-28 02:27:20,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:20,016 INFO:     Epoch: 8
2022-11-28 02:27:20,786 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5093999274752357, 'Total loss': 0.5093999274752357} | train loss {'Reaction outcome loss': 0.3941615832147569, 'Total loss': 0.3941615832147569}
2022-11-28 02:27:20,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:20,786 INFO:     Epoch: 9
2022-11-28 02:27:21,562 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46176178245381877, 'Total loss': 0.46176178245381877} | train loss {'Reaction outcome loss': 0.3845281587227395, 'Total loss': 0.3845281587227395}
2022-11-28 02:27:21,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:21,562 INFO:     Epoch: 10
2022-11-28 02:27:22,336 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4400238028981469, 'Total loss': 0.4400238028981469} | train loss {'Reaction outcome loss': 0.38568665373783845, 'Total loss': 0.38568665373783845}
2022-11-28 02:27:22,338 INFO:     Found new best model at epoch 10
2022-11-28 02:27:22,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:22,338 INFO:     Epoch: 11
2022-11-28 02:27:23,111 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49126773463054135, 'Total loss': 0.49126773463054135} | train loss {'Reaction outcome loss': 0.3746481498605327, 'Total loss': 0.3746481498605327}
2022-11-28 02:27:23,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:23,111 INFO:     Epoch: 12
2022-11-28 02:27:23,885 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46767602962526406, 'Total loss': 0.46767602962526406} | train loss {'Reaction outcome loss': 0.38008884266622156, 'Total loss': 0.38008884266622156}
2022-11-28 02:27:23,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:23,885 INFO:     Epoch: 13
2022-11-28 02:27:24,659 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49162533980878914, 'Total loss': 0.49162533980878914} | train loss {'Reaction outcome loss': 0.3669011167850089, 'Total loss': 0.3669011167850089}
2022-11-28 02:27:24,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:24,659 INFO:     Epoch: 14
2022-11-28 02:27:25,432 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4967652823437344, 'Total loss': 0.4967652823437344} | train loss {'Reaction outcome loss': 0.35758388525078655, 'Total loss': 0.35758388525078655}
2022-11-28 02:27:25,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:25,432 INFO:     Epoch: 15
2022-11-28 02:27:26,204 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46649970385161316, 'Total loss': 0.46649970385161316} | train loss {'Reaction outcome loss': 0.37200106479800665, 'Total loss': 0.37200106479800665}
2022-11-28 02:27:26,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:26,205 INFO:     Epoch: 16
2022-11-28 02:27:26,976 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46071583472869615, 'Total loss': 0.46071583472869615} | train loss {'Reaction outcome loss': 0.3547920496825144, 'Total loss': 0.3547920496825144}
2022-11-28 02:27:26,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:26,976 INFO:     Epoch: 17
2022-11-28 02:27:27,730 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44969116151332855, 'Total loss': 0.44969116151332855} | train loss {'Reaction outcome loss': 0.3548848032649712, 'Total loss': 0.3548848032649712}
2022-11-28 02:27:27,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:27,731 INFO:     Epoch: 18
2022-11-28 02:27:28,484 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46211162209510803, 'Total loss': 0.46211162209510803} | train loss {'Reaction outcome loss': 0.3932061376359299, 'Total loss': 0.3932061376359299}
2022-11-28 02:27:28,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:28,485 INFO:     Epoch: 19
2022-11-28 02:27:29,238 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4450606205923991, 'Total loss': 0.4450606205923991} | train loss {'Reaction outcome loss': 0.3604294128625499, 'Total loss': 0.3604294128625499}
2022-11-28 02:27:29,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:29,238 INFO:     Epoch: 20
2022-11-28 02:27:29,993 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47308996285904537, 'Total loss': 0.47308996285904537} | train loss {'Reaction outcome loss': 0.3553182073993239, 'Total loss': 0.3553182073993239}
2022-11-28 02:27:29,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:29,993 INFO:     Epoch: 21
2022-11-28 02:27:30,751 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4630908773026683, 'Total loss': 0.4630908773026683} | train loss {'Reaction outcome loss': 0.34513492687692043, 'Total loss': 0.34513492687692043}
2022-11-28 02:27:30,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:30,751 INFO:     Epoch: 22
2022-11-28 02:27:31,506 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49123469164425676, 'Total loss': 0.49123469164425676} | train loss {'Reaction outcome loss': 0.34652164834834304, 'Total loss': 0.34652164834834304}
2022-11-28 02:27:31,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:31,507 INFO:     Epoch: 23
2022-11-28 02:27:32,265 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.484060483222658, 'Total loss': 0.484060483222658} | train loss {'Reaction outcome loss': 0.35035263826158125, 'Total loss': 0.35035263826158125}
2022-11-28 02:27:32,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:32,266 INFO:     Epoch: 24
2022-11-28 02:27:33,021 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4570478273724968, 'Total loss': 0.4570478273724968} | train loss {'Reaction outcome loss': 0.3436461695534015, 'Total loss': 0.3436461695534015}
2022-11-28 02:27:33,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:33,021 INFO:     Epoch: 25
2022-11-28 02:27:33,776 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44833568043329497, 'Total loss': 0.44833568043329497} | train loss {'Reaction outcome loss': 0.3528071658512359, 'Total loss': 0.3528071658512359}
2022-11-28 02:27:33,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:33,776 INFO:     Epoch: 26
2022-11-28 02:27:34,537 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4910152652724223, 'Total loss': 0.4910152652724223} | train loss {'Reaction outcome loss': 0.3395097316035375, 'Total loss': 0.3395097316035375}
2022-11-28 02:27:34,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:34,537 INFO:     Epoch: 27
2022-11-28 02:27:35,292 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4491417543454604, 'Total loss': 0.4491417543454604} | train loss {'Reaction outcome loss': 0.3433867235656692, 'Total loss': 0.3433867235656692}
2022-11-28 02:27:35,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:35,293 INFO:     Epoch: 28
2022-11-28 02:27:36,048 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4551803615282882, 'Total loss': 0.4551803615282882} | train loss {'Reaction outcome loss': 0.33849503515054463, 'Total loss': 0.33849503515054463}
2022-11-28 02:27:36,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:36,048 INFO:     Epoch: 29
2022-11-28 02:27:36,804 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4683686972341754, 'Total loss': 0.4683686972341754} | train loss {'Reaction outcome loss': 0.32491318449596707, 'Total loss': 0.32491318449596707}
2022-11-28 02:27:36,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:36,805 INFO:     Epoch: 30
2022-11-28 02:27:37,559 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4626801357689229, 'Total loss': 0.4626801357689229} | train loss {'Reaction outcome loss': 0.3350711052272062, 'Total loss': 0.3350711052272062}
2022-11-28 02:27:37,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:37,559 INFO:     Epoch: 31
2022-11-28 02:27:38,311 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4660108455202796, 'Total loss': 0.4660108455202796} | train loss {'Reaction outcome loss': 0.33063804509065414, 'Total loss': 0.33063804509065414}
2022-11-28 02:27:38,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:38,312 INFO:     Epoch: 32
2022-11-28 02:27:39,067 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4713072922419418, 'Total loss': 0.4713072922419418} | train loss {'Reaction outcome loss': 0.3302193215863425, 'Total loss': 0.3302193215863425}
2022-11-28 02:27:39,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:39,067 INFO:     Epoch: 33
2022-11-28 02:27:39,826 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47297817891971633, 'Total loss': 0.47297817891971633} | train loss {'Reaction outcome loss': 0.3235880865862495, 'Total loss': 0.3235880865862495}
2022-11-28 02:27:39,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:39,826 INFO:     Epoch: 34
2022-11-28 02:27:40,582 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4527005458419973, 'Total loss': 0.4527005458419973} | train loss {'Reaction outcome loss': 0.32478320568438, 'Total loss': 0.32478320568438}
2022-11-28 02:27:40,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:40,583 INFO:     Epoch: 35
2022-11-28 02:27:41,338 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4514415704391219, 'Total loss': 0.4514415704391219} | train loss {'Reaction outcome loss': 0.32198132996858375, 'Total loss': 0.32198132996858375}
2022-11-28 02:27:41,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:41,338 INFO:     Epoch: 36
2022-11-28 02:27:42,091 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4984323165633462, 'Total loss': 0.4984323165633462} | train loss {'Reaction outcome loss': 0.33541053690408407, 'Total loss': 0.33541053690408407}
2022-11-28 02:27:42,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:42,091 INFO:     Epoch: 37
2022-11-28 02:27:42,848 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47273661890490487, 'Total loss': 0.47273661890490487} | train loss {'Reaction outcome loss': 0.3218107089958331, 'Total loss': 0.3218107089958331}
2022-11-28 02:27:42,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:42,849 INFO:     Epoch: 38
2022-11-28 02:27:43,600 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4495016956193881, 'Total loss': 0.4495016956193881} | train loss {'Reaction outcome loss': 0.3274159453175811, 'Total loss': 0.3274159453175811}
2022-11-28 02:27:43,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:43,600 INFO:     Epoch: 39
2022-11-28 02:27:44,352 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44433412937955424, 'Total loss': 0.44433412937955424} | train loss {'Reaction outcome loss': 0.3227585270427741, 'Total loss': 0.3227585270427741}
2022-11-28 02:27:44,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:44,352 INFO:     Epoch: 40
2022-11-28 02:27:45,105 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4591065885668451, 'Total loss': 0.4591065885668451} | train loss {'Reaction outcome loss': 0.3219746212524019, 'Total loss': 0.3219746212524019}
2022-11-28 02:27:45,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:45,105 INFO:     Epoch: 41
2022-11-28 02:27:45,863 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4653701877052134, 'Total loss': 0.4653701877052134} | train loss {'Reaction outcome loss': 0.3140017907040925, 'Total loss': 0.3140017907040925}
2022-11-28 02:27:45,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:45,864 INFO:     Epoch: 42
2022-11-28 02:27:46,624 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46093091275542974, 'Total loss': 0.46093091275542974} | train loss {'Reaction outcome loss': 0.3191038270062401, 'Total loss': 0.3191038270062401}
2022-11-28 02:27:46,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:46,624 INFO:     Epoch: 43
2022-11-28 02:27:47,379 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4388891722668301, 'Total loss': 0.4388891722668301} | train loss {'Reaction outcome loss': 0.33207192072863523, 'Total loss': 0.33207192072863523}
2022-11-28 02:27:47,379 INFO:     Found new best model at epoch 43
2022-11-28 02:27:47,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:47,380 INFO:     Epoch: 44
2022-11-28 02:27:48,131 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4641611687839031, 'Total loss': 0.4641611687839031} | train loss {'Reaction outcome loss': 0.3233619239068164, 'Total loss': 0.3233619239068164}
2022-11-28 02:27:48,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:48,131 INFO:     Epoch: 45
2022-11-28 02:27:48,884 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45187489451332524, 'Total loss': 0.45187489451332524} | train loss {'Reaction outcome loss': 0.3144496536327277, 'Total loss': 0.3144496536327277}
2022-11-28 02:27:48,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:48,884 INFO:     Epoch: 46
2022-11-28 02:27:49,638 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4452391724017533, 'Total loss': 0.4452391724017533} | train loss {'Reaction outcome loss': 0.3222875677742939, 'Total loss': 0.3222875677742939}
2022-11-28 02:27:49,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:49,638 INFO:     Epoch: 47
2022-11-28 02:27:50,391 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45369009571996605, 'Total loss': 0.45369009571996605} | train loss {'Reaction outcome loss': 0.34207347741770944, 'Total loss': 0.34207347741770944}
2022-11-28 02:27:50,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:50,391 INFO:     Epoch: 48
2022-11-28 02:27:51,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47750000757249916, 'Total loss': 0.47750000757249916} | train loss {'Reaction outcome loss': 0.3197051289577135, 'Total loss': 0.3197051289577135}
2022-11-28 02:27:51,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:51,142 INFO:     Epoch: 49
2022-11-28 02:27:51,896 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4913236471739682, 'Total loss': 0.4913236471739682} | train loss {'Reaction outcome loss': 0.31740185568629486, 'Total loss': 0.31740185568629486}
2022-11-28 02:27:51,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:51,896 INFO:     Epoch: 50
2022-11-28 02:27:52,653 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46061842651529744, 'Total loss': 0.46061842651529744} | train loss {'Reaction outcome loss': 0.323454515872757, 'Total loss': 0.323454515872757}
2022-11-28 02:27:52,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:52,653 INFO:     Epoch: 51
2022-11-28 02:27:53,405 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4337155988270586, 'Total loss': 0.4337155988270586} | train loss {'Reaction outcome loss': 0.3176075132518464, 'Total loss': 0.3176075132518464}
2022-11-28 02:27:53,407 INFO:     Found new best model at epoch 51
2022-11-28 02:27:53,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:53,407 INFO:     Epoch: 52
2022-11-28 02:27:54,159 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4472942298108881, 'Total loss': 0.4472942298108881} | train loss {'Reaction outcome loss': 0.3122470844037424, 'Total loss': 0.3122470844037424}
2022-11-28 02:27:54,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:54,159 INFO:     Epoch: 53
2022-11-28 02:27:54,915 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44866985929283226, 'Total loss': 0.44866985929283226} | train loss {'Reaction outcome loss': 0.3244349336711622, 'Total loss': 0.3244349336711622}
2022-11-28 02:27:54,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:54,915 INFO:     Epoch: 54
2022-11-28 02:27:55,669 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4402303790504282, 'Total loss': 0.4402303790504282} | train loss {'Reaction outcome loss': 0.3250801952080688, 'Total loss': 0.3250801952080688}
2022-11-28 02:27:55,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:55,670 INFO:     Epoch: 55
2022-11-28 02:27:56,426 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4643999355083162, 'Total loss': 0.4643999355083162} | train loss {'Reaction outcome loss': 0.311628498810038, 'Total loss': 0.311628498810038}
2022-11-28 02:27:56,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:56,426 INFO:     Epoch: 56
2022-11-28 02:27:57,180 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45799072544005787, 'Total loss': 0.45799072544005787} | train loss {'Reaction outcome loss': 0.319557747090997, 'Total loss': 0.319557747090997}
2022-11-28 02:27:57,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:57,181 INFO:     Epoch: 57
2022-11-28 02:27:57,933 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48304193568500603, 'Total loss': 0.48304193568500603} | train loss {'Reaction outcome loss': 0.31213934668283233, 'Total loss': 0.31213934668283233}
2022-11-28 02:27:57,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:57,933 INFO:     Epoch: 58
2022-11-28 02:27:58,687 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4587914046238769, 'Total loss': 0.4587914046238769} | train loss {'Reaction outcome loss': 0.31459968956375894, 'Total loss': 0.31459968956375894}
2022-11-28 02:27:58,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:58,687 INFO:     Epoch: 59
2022-11-28 02:27:59,440 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47893422130833974, 'Total loss': 0.47893422130833974} | train loss {'Reaction outcome loss': 0.32113349437713623, 'Total loss': 0.32113349437713623}
2022-11-28 02:27:59,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:27:59,441 INFO:     Epoch: 60
2022-11-28 02:28:00,196 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4966270910067992, 'Total loss': 0.4966270910067992} | train loss {'Reaction outcome loss': 0.3109954977144114, 'Total loss': 0.3109954977144114}
2022-11-28 02:28:00,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:00,197 INFO:     Epoch: 61
2022-11-28 02:28:00,952 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47214896960014646, 'Total loss': 0.47214896960014646} | train loss {'Reaction outcome loss': 0.3194683419487737, 'Total loss': 0.3194683419487737}
2022-11-28 02:28:00,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:00,952 INFO:     Epoch: 62
2022-11-28 02:28:01,714 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5050280260091479, 'Total loss': 0.5050280260091479} | train loss {'Reaction outcome loss': 0.333567460508723, 'Total loss': 0.333567460508723}
2022-11-28 02:28:01,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:01,715 INFO:     Epoch: 63
2022-11-28 02:28:02,470 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.437739086760716, 'Total loss': 0.437739086760716} | train loss {'Reaction outcome loss': 0.31790331334840916, 'Total loss': 0.31790331334840916}
2022-11-28 02:28:02,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:02,471 INFO:     Epoch: 64
2022-11-28 02:28:03,229 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5124486032873392, 'Total loss': 0.5124486032873392} | train loss {'Reaction outcome loss': 0.3047151113087349, 'Total loss': 0.3047151113087349}
2022-11-28 02:28:03,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:03,229 INFO:     Epoch: 65
2022-11-28 02:28:03,987 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46932330693710933, 'Total loss': 0.46932330693710933} | train loss {'Reaction outcome loss': 0.3143693110226891, 'Total loss': 0.3143693110226891}
2022-11-28 02:28:03,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:03,988 INFO:     Epoch: 66
2022-11-28 02:28:04,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49194238741289487, 'Total loss': 0.49194238741289487} | train loss {'Reaction outcome loss': 0.30530011484225994, 'Total loss': 0.30530011484225994}
2022-11-28 02:28:04,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:04,741 INFO:     Epoch: 67
2022-11-28 02:28:05,492 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43754735047167, 'Total loss': 0.43754735047167} | train loss {'Reaction outcome loss': 0.3138393605286293, 'Total loss': 0.3138393605286293}
2022-11-28 02:28:05,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:05,492 INFO:     Epoch: 68
2022-11-28 02:28:06,245 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4505682462318377, 'Total loss': 0.4505682462318377} | train loss {'Reaction outcome loss': 0.3096677410955492, 'Total loss': 0.3096677410955492}
2022-11-28 02:28:06,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:06,245 INFO:     Epoch: 69
2022-11-28 02:28:06,996 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.475869685750116, 'Total loss': 0.475869685750116} | train loss {'Reaction outcome loss': 0.30761136905278874, 'Total loss': 0.30761136905278874}
2022-11-28 02:28:06,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:06,997 INFO:     Epoch: 70
2022-11-28 02:28:07,749 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47366021251813933, 'Total loss': 0.47366021251813933} | train loss {'Reaction outcome loss': 0.30464605303944997, 'Total loss': 0.30464605303944997}
2022-11-28 02:28:07,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:07,749 INFO:     Epoch: 71
2022-11-28 02:28:08,505 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49233616346662695, 'Total loss': 0.49233616346662695} | train loss {'Reaction outcome loss': 0.3056957342905588, 'Total loss': 0.3056957342905588}
2022-11-28 02:28:08,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:08,506 INFO:     Epoch: 72
2022-11-28 02:28:09,262 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47189578312364494, 'Total loss': 0.47189578312364494} | train loss {'Reaction outcome loss': 0.3181729370856333, 'Total loss': 0.3181729370856333}
2022-11-28 02:28:09,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:09,262 INFO:     Epoch: 73
2022-11-28 02:28:10,014 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44265264679085126, 'Total loss': 0.44265264679085126} | train loss {'Reaction outcome loss': 0.31153118560610993, 'Total loss': 0.31153118560610993}
2022-11-28 02:28:10,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:10,014 INFO:     Epoch: 74
2022-11-28 02:28:10,764 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4543454386293888, 'Total loss': 0.4543454386293888} | train loss {'Reaction outcome loss': 0.3284588895647632, 'Total loss': 0.3284588895647632}
2022-11-28 02:28:10,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:10,764 INFO:     Epoch: 75
2022-11-28 02:28:11,518 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.456333420493386, 'Total loss': 0.456333420493386} | train loss {'Reaction outcome loss': 0.320096994324131, 'Total loss': 0.320096994324131}
2022-11-28 02:28:11,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:11,519 INFO:     Epoch: 76
2022-11-28 02:28:12,273 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4503308714113452, 'Total loss': 0.4503308714113452} | train loss {'Reaction outcome loss': 0.3308992509688684, 'Total loss': 0.3308992509688684}
2022-11-28 02:28:12,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:12,273 INFO:     Epoch: 77
2022-11-28 02:28:13,027 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43642133101820946, 'Total loss': 0.43642133101820946} | train loss {'Reaction outcome loss': 0.31386557371480023, 'Total loss': 0.31386557371480023}
2022-11-28 02:28:13,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:13,027 INFO:     Epoch: 78
2022-11-28 02:28:13,780 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46312681517817755, 'Total loss': 0.46312681517817755} | train loss {'Reaction outcome loss': 0.32037165377153315, 'Total loss': 0.32037165377153315}
2022-11-28 02:28:13,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:13,780 INFO:     Epoch: 79
2022-11-28 02:28:14,536 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.482887366278605, 'Total loss': 0.482887366278605} | train loss {'Reaction outcome loss': 0.31225263770775274, 'Total loss': 0.31225263770775274}
2022-11-28 02:28:14,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:14,536 INFO:     Epoch: 80
2022-11-28 02:28:15,289 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4906157079068097, 'Total loss': 0.4906157079068097} | train loss {'Reaction outcome loss': 0.3245816271495723, 'Total loss': 0.3245816271495723}
2022-11-28 02:28:15,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:15,289 INFO:     Epoch: 81
2022-11-28 02:28:16,046 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4311026471920989, 'Total loss': 0.4311026471920989} | train loss {'Reaction outcome loss': 0.31202273640446065, 'Total loss': 0.31202273640446065}
2022-11-28 02:28:16,046 INFO:     Found new best model at epoch 81
2022-11-28 02:28:16,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:16,047 INFO:     Epoch: 82
2022-11-28 02:28:16,803 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47492510910061275, 'Total loss': 0.47492510910061275} | train loss {'Reaction outcome loss': 0.3198774069687163, 'Total loss': 0.3198774069687163}
2022-11-28 02:28:16,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:16,803 INFO:     Epoch: 83
2022-11-28 02:28:17,553 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4569075419144197, 'Total loss': 0.4569075419144197} | train loss {'Reaction outcome loss': 0.317042712525885, 'Total loss': 0.317042712525885}
2022-11-28 02:28:17,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:17,553 INFO:     Epoch: 84
2022-11-28 02:28:18,305 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4374940822070295, 'Total loss': 0.4374940822070295} | train loss {'Reaction outcome loss': 0.3064010882274595, 'Total loss': 0.3064010882274595}
2022-11-28 02:28:18,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:18,305 INFO:     Epoch: 85
2022-11-28 02:28:19,060 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45078320462595334, 'Total loss': 0.45078320462595334} | train loss {'Reaction outcome loss': 0.3138562863851004, 'Total loss': 0.3138562863851004}
2022-11-28 02:28:19,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:19,060 INFO:     Epoch: 86
2022-11-28 02:28:19,810 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4465590014376424, 'Total loss': 0.4465590014376424} | train loss {'Reaction outcome loss': 0.32034743230729573, 'Total loss': 0.32034743230729573}
2022-11-28 02:28:19,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:19,811 INFO:     Epoch: 87
2022-11-28 02:28:20,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43636216155507346, 'Total loss': 0.43636216155507346} | train loss {'Reaction outcome loss': 0.30815165487838236, 'Total loss': 0.30815165487838236}
2022-11-28 02:28:20,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:20,566 INFO:     Epoch: 88
2022-11-28 02:28:21,319 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4533947360786525, 'Total loss': 0.4533947360786525} | train loss {'Reaction outcome loss': 0.30830474816232556, 'Total loss': 0.30830474816232556}
2022-11-28 02:28:21,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:21,319 INFO:     Epoch: 89
2022-11-28 02:28:22,070 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43101561526683246, 'Total loss': 0.43101561526683246} | train loss {'Reaction outcome loss': 0.30617827053374125, 'Total loss': 0.30617827053374125}
2022-11-28 02:28:22,071 INFO:     Found new best model at epoch 89
2022-11-28 02:28:22,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:22,071 INFO:     Epoch: 90
2022-11-28 02:28:22,828 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45010961626063695, 'Total loss': 0.45010961626063695} | train loss {'Reaction outcome loss': 0.30789102689336667, 'Total loss': 0.30789102689336667}
2022-11-28 02:28:22,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:22,828 INFO:     Epoch: 91
2022-11-28 02:28:23,584 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4755531766197898, 'Total loss': 0.4755531766197898} | train loss {'Reaction outcome loss': 0.30824974384385084, 'Total loss': 0.30824974384385084}
2022-11-28 02:28:23,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:23,585 INFO:     Epoch: 92
2022-11-28 02:28:24,337 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4313825521279465, 'Total loss': 0.4313825521279465} | train loss {'Reaction outcome loss': 0.3150419722563825, 'Total loss': 0.3150419722563825}
2022-11-28 02:28:24,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:24,339 INFO:     Epoch: 93
2022-11-28 02:28:25,095 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5278049321337179, 'Total loss': 0.5278049321337179} | train loss {'Reaction outcome loss': 0.32254403175009405, 'Total loss': 0.32254403175009405}
2022-11-28 02:28:25,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:25,095 INFO:     Epoch: 94
2022-11-28 02:28:25,849 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46198252283714036, 'Total loss': 0.46198252283714036} | train loss {'Reaction outcome loss': 0.32100003362309965, 'Total loss': 0.32100003362309965}
2022-11-28 02:28:25,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:25,850 INFO:     Epoch: 95
2022-11-28 02:28:26,601 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48445847122506663, 'Total loss': 0.48445847122506663} | train loss {'Reaction outcome loss': 0.302935464400044, 'Total loss': 0.302935464400044}
2022-11-28 02:28:26,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:26,602 INFO:     Epoch: 96
2022-11-28 02:28:27,353 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.475255085663362, 'Total loss': 0.475255085663362} | train loss {'Reaction outcome loss': 0.314028300857737, 'Total loss': 0.314028300857737}
2022-11-28 02:28:27,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:27,353 INFO:     Epoch: 97
2022-11-28 02:28:28,107 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4486064230176536, 'Total loss': 0.4486064230176536} | train loss {'Reaction outcome loss': 0.31623539817236695, 'Total loss': 0.31623539817236695}
2022-11-28 02:28:28,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:28,108 INFO:     Epoch: 98
2022-11-28 02:28:28,862 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4577914727005092, 'Total loss': 0.4577914727005092} | train loss {'Reaction outcome loss': 0.3122760776264465, 'Total loss': 0.3122760776264465}
2022-11-28 02:28:28,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:28,862 INFO:     Epoch: 99
2022-11-28 02:28:29,612 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4995886219496077, 'Total loss': 0.4995886219496077} | train loss {'Reaction outcome loss': 0.3197795317964515, 'Total loss': 0.3197795317964515}
2022-11-28 02:28:29,613 INFO:     Best model found after epoch 90 of 100.
2022-11-28 02:28:29,613 INFO:   Done with stage: TRAINING
2022-11-28 02:28:29,613 INFO:   Starting stage: EVALUATION
2022-11-28 02:28:29,738 INFO:   Done with stage: EVALUATION
2022-11-28 02:28:29,738 INFO:   Leaving out SEQ value Fold_7
2022-11-28 02:28:29,751 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:28:29,751 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:28:30,397 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:28:30,398 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:28:30,467 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:28:30,467 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:28:30,467 INFO:     No hyperparam tuning for this model
2022-11-28 02:28:30,467 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:28:30,467 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:28:30,468 INFO:     None feature selector for col prot
2022-11-28 02:28:30,468 INFO:     None feature selector for col prot
2022-11-28 02:28:30,468 INFO:     None feature selector for col prot
2022-11-28 02:28:30,468 INFO:     None feature selector for col chem
2022-11-28 02:28:30,468 INFO:     None feature selector for col chem
2022-11-28 02:28:30,469 INFO:     None feature selector for col chem
2022-11-28 02:28:30,469 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:28:30,469 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:28:30,470 INFO:     Number of params in model 169741
2022-11-28 02:28:30,473 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:28:30,473 INFO:   Starting stage: TRAINING
2022-11-28 02:28:30,528 INFO:     Val loss before train {'Reaction outcome loss': 1.0146201334216378, 'Total loss': 1.0146201334216378}
2022-11-28 02:28:30,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:30,528 INFO:     Epoch: 0
2022-11-28 02:28:31,280 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5257402448491617, 'Total loss': 0.5257402448491617} | train loss {'Reaction outcome loss': 0.6304664564949851, 'Total loss': 0.6304664564949851}
2022-11-28 02:28:31,280 INFO:     Found new best model at epoch 0
2022-11-28 02:28:31,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:31,281 INFO:     Epoch: 1
2022-11-28 02:28:32,035 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5007360418411818, 'Total loss': 0.5007360418411818} | train loss {'Reaction outcome loss': 0.5021285184568935, 'Total loss': 0.5021285184568935}
2022-11-28 02:28:32,036 INFO:     Found new best model at epoch 1
2022-11-28 02:28:32,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:32,036 INFO:     Epoch: 2
2022-11-28 02:28:32,793 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5426941571587865, 'Total loss': 0.5426941571587865} | train loss {'Reaction outcome loss': 0.4641452760345513, 'Total loss': 0.4641452760345513}
2022-11-28 02:28:32,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:32,794 INFO:     Epoch: 3
2022-11-28 02:28:33,552 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.474823153831742, 'Total loss': 0.474823153831742} | train loss {'Reaction outcome loss': 0.4379294932549519, 'Total loss': 0.4379294932549519}
2022-11-28 02:28:33,552 INFO:     Found new best model at epoch 3
2022-11-28 02:28:33,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:33,553 INFO:     Epoch: 4
2022-11-28 02:28:34,311 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4739748571406711, 'Total loss': 0.4739748571406711} | train loss {'Reaction outcome loss': 0.42623398579176397, 'Total loss': 0.42623398579176397}
2022-11-28 02:28:34,311 INFO:     Found new best model at epoch 4
2022-11-28 02:28:34,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:34,312 INFO:     Epoch: 5
2022-11-28 02:28:35,068 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4912504672326825, 'Total loss': 0.4912504672326825} | train loss {'Reaction outcome loss': 0.4105367136578406, 'Total loss': 0.4105367136578406}
2022-11-28 02:28:35,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:35,068 INFO:     Epoch: 6
2022-11-28 02:28:35,823 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49264678765426984, 'Total loss': 0.49264678765426984} | train loss {'Reaction outcome loss': 0.3966892306963282, 'Total loss': 0.3966892306963282}
2022-11-28 02:28:35,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:35,824 INFO:     Epoch: 7
2022-11-28 02:28:36,581 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4687495604157448, 'Total loss': 0.4687495604157448} | train loss {'Reaction outcome loss': 0.3966063869696471, 'Total loss': 0.3966063869696471}
2022-11-28 02:28:36,581 INFO:     Found new best model at epoch 7
2022-11-28 02:28:36,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:36,582 INFO:     Epoch: 8
2022-11-28 02:28:37,342 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.441519461910833, 'Total loss': 0.441519461910833} | train loss {'Reaction outcome loss': 0.3858116924642555, 'Total loss': 0.3858116924642555}
2022-11-28 02:28:37,342 INFO:     Found new best model at epoch 8
2022-11-28 02:28:37,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:37,343 INFO:     Epoch: 9
2022-11-28 02:28:38,097 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44992692836306314, 'Total loss': 0.44992692836306314} | train loss {'Reaction outcome loss': 0.3747981596858271, 'Total loss': 0.3747981596858271}
2022-11-28 02:28:38,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:38,098 INFO:     Epoch: 10
2022-11-28 02:28:38,852 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4613395163958723, 'Total loss': 0.4613395163958723} | train loss {'Reaction outcome loss': 0.375749982713211, 'Total loss': 0.375749982713211}
2022-11-28 02:28:38,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:38,852 INFO:     Epoch: 11
2022-11-28 02:28:39,607 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4965793652967973, 'Total loss': 0.4965793652967973} | train loss {'Reaction outcome loss': 0.36283517421613776, 'Total loss': 0.36283517421613776}
2022-11-28 02:28:39,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:39,607 INFO:     Epoch: 12
2022-11-28 02:28:40,361 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4603630917316133, 'Total loss': 0.4603630917316133} | train loss {'Reaction outcome loss': 0.3638314059785297, 'Total loss': 0.3638314059785297}
2022-11-28 02:28:40,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:40,361 INFO:     Epoch: 13
2022-11-28 02:28:41,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4308487129482356, 'Total loss': 0.4308487129482356} | train loss {'Reaction outcome loss': 0.36105378155386253, 'Total loss': 0.36105378155386253}
2022-11-28 02:28:41,117 INFO:     Found new best model at epoch 13
2022-11-28 02:28:41,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:41,118 INFO:     Epoch: 14
2022-11-28 02:28:41,877 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4694374633783644, 'Total loss': 0.4694374633783644} | train loss {'Reaction outcome loss': 0.3652986570171291, 'Total loss': 0.3652986570171291}
2022-11-28 02:28:41,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:41,878 INFO:     Epoch: 15
2022-11-28 02:28:42,635 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4560646414756775, 'Total loss': 0.4560646414756775} | train loss {'Reaction outcome loss': 0.3531797310157168, 'Total loss': 0.3531797310157168}
2022-11-28 02:28:42,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:42,636 INFO:     Epoch: 16
2022-11-28 02:28:43,390 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4475723586299203, 'Total loss': 0.4475723586299203} | train loss {'Reaction outcome loss': 0.3522598811635567, 'Total loss': 0.3522598811635567}
2022-11-28 02:28:43,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:43,390 INFO:     Epoch: 17
2022-11-28 02:28:44,146 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47040496935898607, 'Total loss': 0.47040496935898607} | train loss {'Reaction outcome loss': 0.355699195286199, 'Total loss': 0.355699195286199}
2022-11-28 02:28:44,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:44,146 INFO:     Epoch: 18
2022-11-28 02:28:44,899 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44952841475605965, 'Total loss': 0.44952841475605965} | train loss {'Reaction outcome loss': 0.35078171490421217, 'Total loss': 0.35078171490421217}
2022-11-28 02:28:44,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:44,900 INFO:     Epoch: 19
2022-11-28 02:28:45,654 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4388430067761378, 'Total loss': 0.4388430067761378} | train loss {'Reaction outcome loss': 0.33886430670897805, 'Total loss': 0.33886430670897805}
2022-11-28 02:28:45,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:45,654 INFO:     Epoch: 20
2022-11-28 02:28:46,409 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45369783077727666, 'Total loss': 0.45369783077727666} | train loss {'Reaction outcome loss': 0.3339241126912736, 'Total loss': 0.3339241126912736}
2022-11-28 02:28:46,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:46,410 INFO:     Epoch: 21
2022-11-28 02:28:47,164 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4492868073284626, 'Total loss': 0.4492868073284626} | train loss {'Reaction outcome loss': 0.3396970323256908, 'Total loss': 0.3396970323256908}
2022-11-28 02:28:47,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:47,164 INFO:     Epoch: 22
2022-11-28 02:28:47,919 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45925050940025935, 'Total loss': 0.45925050940025935} | train loss {'Reaction outcome loss': 0.336333773549526, 'Total loss': 0.336333773549526}
2022-11-28 02:28:47,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:47,919 INFO:     Epoch: 23
2022-11-28 02:28:48,670 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4432781626555053, 'Total loss': 0.4432781626555053} | train loss {'Reaction outcome loss': 0.339192234250086, 'Total loss': 0.339192234250086}
2022-11-28 02:28:48,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:48,670 INFO:     Epoch: 24
2022-11-28 02:28:49,425 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.469190852208571, 'Total loss': 0.469190852208571} | train loss {'Reaction outcome loss': 0.33652256062674907, 'Total loss': 0.33652256062674907}
2022-11-28 02:28:49,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:49,425 INFO:     Epoch: 25
2022-11-28 02:28:50,183 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45918565582145343, 'Total loss': 0.45918565582145343} | train loss {'Reaction outcome loss': 0.32583524923651447, 'Total loss': 0.32583524923651447}
2022-11-28 02:28:50,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:50,183 INFO:     Epoch: 26
2022-11-28 02:28:50,936 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44459608840671455, 'Total loss': 0.44459608840671455} | train loss {'Reaction outcome loss': 0.32565633255627846, 'Total loss': 0.32565633255627846}
2022-11-28 02:28:50,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:50,936 INFO:     Epoch: 27
2022-11-28 02:28:51,690 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4888740512119098, 'Total loss': 0.4888740512119098} | train loss {'Reaction outcome loss': 0.3298743752342078, 'Total loss': 0.3298743752342078}
2022-11-28 02:28:51,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:51,691 INFO:     Epoch: 28
2022-11-28 02:28:52,448 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47266538407314906, 'Total loss': 0.47266538407314906} | train loss {'Reaction outcome loss': 0.3310174222945446, 'Total loss': 0.3310174222945446}
2022-11-28 02:28:52,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:52,448 INFO:     Epoch: 29
2022-11-28 02:28:53,206 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.471701612865383, 'Total loss': 0.471701612865383} | train loss {'Reaction outcome loss': 0.342875033406721, 'Total loss': 0.342875033406721}
2022-11-28 02:28:53,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:53,206 INFO:     Epoch: 30
2022-11-28 02:28:53,962 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4300596888431094, 'Total loss': 0.4300596888431094} | train loss {'Reaction outcome loss': 0.3314496237604368, 'Total loss': 0.3314496237604368}
2022-11-28 02:28:53,962 INFO:     Found new best model at epoch 30
2022-11-28 02:28:53,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:53,963 INFO:     Epoch: 31
2022-11-28 02:28:54,719 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4506066306070848, 'Total loss': 0.4506066306070848} | train loss {'Reaction outcome loss': 0.32341086690223986, 'Total loss': 0.32341086690223986}
2022-11-28 02:28:54,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:54,719 INFO:     Epoch: 32
2022-11-28 02:28:55,477 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47995987195860257, 'Total loss': 0.47995987195860257} | train loss {'Reaction outcome loss': 0.3180777347165971, 'Total loss': 0.3180777347165971}
2022-11-28 02:28:55,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:55,478 INFO:     Epoch: 33
2022-11-28 02:28:56,234 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45735653151165356, 'Total loss': 0.45735653151165356} | train loss {'Reaction outcome loss': 0.331286002971953, 'Total loss': 0.331286002971953}
2022-11-28 02:28:56,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:56,234 INFO:     Epoch: 34
2022-11-28 02:28:56,989 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48012976856394246, 'Total loss': 0.48012976856394246} | train loss {'Reaction outcome loss': 0.32524533566808506, 'Total loss': 0.32524533566808506}
2022-11-28 02:28:56,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:56,989 INFO:     Epoch: 35
2022-11-28 02:28:57,754 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4865607294169339, 'Total loss': 0.4865607294169339} | train loss {'Reaction outcome loss': 0.31568468202866856, 'Total loss': 0.31568468202866856}
2022-11-28 02:28:57,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:57,754 INFO:     Epoch: 36
2022-11-28 02:28:58,514 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.466364652257074, 'Total loss': 0.466364652257074} | train loss {'Reaction outcome loss': 0.33135825017046544, 'Total loss': 0.33135825017046544}
2022-11-28 02:28:58,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:58,515 INFO:     Epoch: 37
2022-11-28 02:28:59,273 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44200830364769156, 'Total loss': 0.44200830364769156} | train loss {'Reaction outcome loss': 0.3177250176067314, 'Total loss': 0.3177250176067314}
2022-11-28 02:28:59,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:28:59,274 INFO:     Epoch: 38
2022-11-28 02:29:00,030 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49391475184397265, 'Total loss': 0.49391475184397265} | train loss {'Reaction outcome loss': 0.319208434091941, 'Total loss': 0.319208434091941}
2022-11-28 02:29:00,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:00,030 INFO:     Epoch: 39
2022-11-28 02:29:00,786 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4508776492015882, 'Total loss': 0.4508776492015882} | train loss {'Reaction outcome loss': 0.32678832677042774, 'Total loss': 0.32678832677042774}
2022-11-28 02:29:00,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:00,787 INFO:     Epoch: 40
2022-11-28 02:29:01,544 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47521657530557027, 'Total loss': 0.47521657530557027} | train loss {'Reaction outcome loss': 0.31450519242113634, 'Total loss': 0.31450519242113634}
2022-11-28 02:29:01,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:01,545 INFO:     Epoch: 41
2022-11-28 02:29:02,304 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4559757695956664, 'Total loss': 0.4559757695956664} | train loss {'Reaction outcome loss': 0.32634719620428737, 'Total loss': 0.32634719620428737}
2022-11-28 02:29:02,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:02,304 INFO:     Epoch: 42
2022-11-28 02:29:03,062 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49290331216021016, 'Total loss': 0.49290331216021016} | train loss {'Reaction outcome loss': 0.3221631897613406, 'Total loss': 0.3221631897613406}
2022-11-28 02:29:03,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:03,062 INFO:     Epoch: 43
2022-11-28 02:29:03,826 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46344213086095726, 'Total loss': 0.46344213086095726} | train loss {'Reaction outcome loss': 0.3211153412177678, 'Total loss': 0.3211153412177678}
2022-11-28 02:29:03,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:03,826 INFO:     Epoch: 44
2022-11-28 02:29:04,583 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47301745177669957, 'Total loss': 0.47301745177669957} | train loss {'Reaction outcome loss': 0.31523793118615306, 'Total loss': 0.31523793118615306}
2022-11-28 02:29:04,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:04,584 INFO:     Epoch: 45
2022-11-28 02:29:05,339 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4412543231790716, 'Total loss': 0.4412543231790716} | train loss {'Reaction outcome loss': 0.3164240927585671, 'Total loss': 0.3164240927585671}
2022-11-28 02:29:05,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:05,339 INFO:     Epoch: 46
2022-11-28 02:29:06,094 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45187142355875537, 'Total loss': 0.45187142355875537} | train loss {'Reaction outcome loss': 0.3193672061447174, 'Total loss': 0.3193672061447174}
2022-11-28 02:29:06,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:06,095 INFO:     Epoch: 47
2022-11-28 02:29:06,851 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4495826634493741, 'Total loss': 0.4495826634493741} | train loss {'Reaction outcome loss': 0.3180005578023772, 'Total loss': 0.3180005578023772}
2022-11-28 02:29:06,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:06,852 INFO:     Epoch: 48
2022-11-28 02:29:07,610 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4809657497839494, 'Total loss': 0.4809657497839494} | train loss {'Reaction outcome loss': 0.3225814238370907, 'Total loss': 0.3225814238370907}
2022-11-28 02:29:07,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:07,611 INFO:     Epoch: 49
2022-11-28 02:29:08,367 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46286732043054973, 'Total loss': 0.46286732043054973} | train loss {'Reaction outcome loss': 0.31419889259362416, 'Total loss': 0.31419889259362416}
2022-11-28 02:29:08,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:08,367 INFO:     Epoch: 50
2022-11-28 02:29:09,123 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4396571586416526, 'Total loss': 0.4396571586416526} | train loss {'Reaction outcome loss': 0.3177880078494068, 'Total loss': 0.3177880078494068}
2022-11-28 02:29:09,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:09,123 INFO:     Epoch: 51
2022-11-28 02:29:09,883 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4548112059181387, 'Total loss': 0.4548112059181387} | train loss {'Reaction outcome loss': 0.3120838278123448, 'Total loss': 0.3120838278123448}
2022-11-28 02:29:09,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:09,883 INFO:     Epoch: 52
2022-11-28 02:29:10,640 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44155960834839125, 'Total loss': 0.44155960834839125} | train loss {'Reaction outcome loss': 0.3140928453555511, 'Total loss': 0.3140928453555511}
2022-11-28 02:29:10,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:10,640 INFO:     Epoch: 53
2022-11-28 02:29:11,399 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43500678715380753, 'Total loss': 0.43500678715380753} | train loss {'Reaction outcome loss': 0.31641059350823203, 'Total loss': 0.31641059350823203}
2022-11-28 02:29:11,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:11,399 INFO:     Epoch: 54
2022-11-28 02:29:12,155 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45789550989866257, 'Total loss': 0.45789550989866257} | train loss {'Reaction outcome loss': 0.30864602452023854, 'Total loss': 0.30864602452023854}
2022-11-28 02:29:12,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:12,155 INFO:     Epoch: 55
2022-11-28 02:29:12,912 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48802399465983565, 'Total loss': 0.48802399465983565} | train loss {'Reaction outcome loss': 0.3162154849588631, 'Total loss': 0.3162154849588631}
2022-11-28 02:29:12,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:12,912 INFO:     Epoch: 56
2022-11-28 02:29:13,670 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4694772538813678, 'Total loss': 0.4694772538813678} | train loss {'Reaction outcome loss': 0.3120587766771355, 'Total loss': 0.3120587766771355}
2022-11-28 02:29:13,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:13,671 INFO:     Epoch: 57
2022-11-28 02:29:14,429 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4451702257448977, 'Total loss': 0.4451702257448977} | train loss {'Reaction outcome loss': 0.3139382300658091, 'Total loss': 0.3139382300658091}
2022-11-28 02:29:14,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:14,430 INFO:     Epoch: 58
2022-11-28 02:29:15,188 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4741006461395459, 'Total loss': 0.4741006461395459} | train loss {'Reaction outcome loss': 0.31736865587111923, 'Total loss': 0.31736865587111923}
2022-11-28 02:29:15,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:15,188 INFO:     Epoch: 59
2022-11-28 02:29:15,943 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.437052699144591, 'Total loss': 0.437052699144591} | train loss {'Reaction outcome loss': 0.30620130073399315, 'Total loss': 0.30620130073399315}
2022-11-28 02:29:15,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:15,944 INFO:     Epoch: 60
2022-11-28 02:29:16,699 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45722598853436386, 'Total loss': 0.45722598853436386} | train loss {'Reaction outcome loss': 0.31974920927877387, 'Total loss': 0.31974920927877387}
2022-11-28 02:29:16,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:16,699 INFO:     Epoch: 61
2022-11-28 02:29:17,454 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4802428660067645, 'Total loss': 0.4802428660067645} | train loss {'Reaction outcome loss': 0.3130154159791287, 'Total loss': 0.3130154159791287}
2022-11-28 02:29:17,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:17,454 INFO:     Epoch: 62
2022-11-28 02:29:18,212 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4394260357049378, 'Total loss': 0.4394260357049378} | train loss {'Reaction outcome loss': 0.317570501067225, 'Total loss': 0.317570501067225}
2022-11-28 02:29:18,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:18,212 INFO:     Epoch: 63
2022-11-28 02:29:18,971 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.483353642238812, 'Total loss': 0.483353642238812} | train loss {'Reaction outcome loss': 0.31134066226020934, 'Total loss': 0.31134066226020934}
2022-11-28 02:29:18,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:18,971 INFO:     Epoch: 64
2022-11-28 02:29:19,729 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44254089485515247, 'Total loss': 0.44254089485515247} | train loss {'Reaction outcome loss': 0.3174292919256033, 'Total loss': 0.3174292919256033}
2022-11-28 02:29:19,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:19,729 INFO:     Epoch: 65
2022-11-28 02:29:20,488 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46827973882583057, 'Total loss': 0.46827973882583057} | train loss {'Reaction outcome loss': 0.3067344627192905, 'Total loss': 0.3067344627192905}
2022-11-28 02:29:20,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:20,488 INFO:     Epoch: 66
2022-11-28 02:29:21,248 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4379587932066484, 'Total loss': 0.4379587932066484} | train loss {'Reaction outcome loss': 0.31114158157499566, 'Total loss': 0.31114158157499566}
2022-11-28 02:29:21,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:21,248 INFO:     Epoch: 67
2022-11-28 02:29:22,007 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4326678883622993, 'Total loss': 0.4326678883622993} | train loss {'Reaction outcome loss': 0.30854287506231376, 'Total loss': 0.30854287506231376}
2022-11-28 02:29:22,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:22,007 INFO:     Epoch: 68
2022-11-28 02:29:22,763 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44738101722164586, 'Total loss': 0.44738101722164586} | train loss {'Reaction outcome loss': 0.30711796810670244, 'Total loss': 0.30711796810670244}
2022-11-28 02:29:22,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:22,763 INFO:     Epoch: 69
2022-11-28 02:29:23,523 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4656398682431741, 'Total loss': 0.4656398682431741} | train loss {'Reaction outcome loss': 0.31074220356681653, 'Total loss': 0.31074220356681653}
2022-11-28 02:29:23,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:23,523 INFO:     Epoch: 70
2022-11-28 02:29:24,281 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4485011916946281, 'Total loss': 0.4485011916946281} | train loss {'Reaction outcome loss': 0.30649631936103106, 'Total loss': 0.30649631936103106}
2022-11-28 02:29:24,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:24,281 INFO:     Epoch: 71
2022-11-28 02:29:25,040 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4413190297782421, 'Total loss': 0.4413190297782421} | train loss {'Reaction outcome loss': 0.31198195461183786, 'Total loss': 0.31198195461183786}
2022-11-28 02:29:25,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:25,040 INFO:     Epoch: 72
2022-11-28 02:29:25,798 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45785687829960475, 'Total loss': 0.45785687829960475} | train loss {'Reaction outcome loss': 0.3093263417061779, 'Total loss': 0.3093263417061779}
2022-11-28 02:29:25,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:25,798 INFO:     Epoch: 73
2022-11-28 02:29:26,550 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4693990837443959, 'Total loss': 0.4693990837443959} | train loss {'Reaction outcome loss': 0.30252132261352194, 'Total loss': 0.30252132261352194}
2022-11-28 02:29:26,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:26,551 INFO:     Epoch: 74
2022-11-28 02:29:27,303 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4598229510540312, 'Total loss': 0.4598229510540312} | train loss {'Reaction outcome loss': 0.31095939299332037, 'Total loss': 0.31095939299332037}
2022-11-28 02:29:27,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:27,303 INFO:     Epoch: 75
2022-11-28 02:29:28,055 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4562150805511258, 'Total loss': 0.4562150805511258} | train loss {'Reaction outcome loss': 0.3036447698851266, 'Total loss': 0.3036447698851266}
2022-11-28 02:29:28,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:28,055 INFO:     Epoch: 76
2022-11-28 02:29:28,805 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44981105761094525, 'Total loss': 0.44981105761094525} | train loss {'Reaction outcome loss': 0.3054433782855349, 'Total loss': 0.3054433782855349}
2022-11-28 02:29:28,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:28,805 INFO:     Epoch: 77
2022-11-28 02:29:29,558 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4571283371611075, 'Total loss': 0.4571283371611075} | train loss {'Reaction outcome loss': 0.2967168974479841, 'Total loss': 0.2967168974479841}
2022-11-28 02:29:29,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:29,559 INFO:     Epoch: 78
2022-11-28 02:29:30,311 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42450290478088637, 'Total loss': 0.42450290478088637} | train loss {'Reaction outcome loss': 0.31734058582374164, 'Total loss': 0.31734058582374164}
2022-11-28 02:29:30,311 INFO:     Found new best model at epoch 78
2022-11-28 02:29:30,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:30,312 INFO:     Epoch: 79
2022-11-28 02:29:31,066 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4755306718024341, 'Total loss': 0.4755306718024341} | train loss {'Reaction outcome loss': 0.30328630960936986, 'Total loss': 0.30328630960936986}
2022-11-28 02:29:31,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:31,066 INFO:     Epoch: 80
2022-11-28 02:29:31,822 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45178618417544797, 'Total loss': 0.45178618417544797} | train loss {'Reaction outcome loss': 0.3180840978579175, 'Total loss': 0.3180840978579175}
2022-11-28 02:29:31,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:31,822 INFO:     Epoch: 81
2022-11-28 02:29:32,576 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44724247232079506, 'Total loss': 0.44724247232079506} | train loss {'Reaction outcome loss': 0.3141599039757444, 'Total loss': 0.3141599039757444}
2022-11-28 02:29:32,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:32,577 INFO:     Epoch: 82
2022-11-28 02:29:33,328 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.437910793857141, 'Total loss': 0.437910793857141} | train loss {'Reaction outcome loss': 0.30248288317553457, 'Total loss': 0.30248288317553457}
2022-11-28 02:29:33,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:33,328 INFO:     Epoch: 83
2022-11-28 02:29:34,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45523880726911803, 'Total loss': 0.45523880726911803} | train loss {'Reaction outcome loss': 0.30890255215607826, 'Total loss': 0.30890255215607826}
2022-11-28 02:29:34,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:34,080 INFO:     Epoch: 84
2022-11-28 02:29:34,829 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45535844699902966, 'Total loss': 0.45535844699902966} | train loss {'Reaction outcome loss': 0.31171484883393974, 'Total loss': 0.31171484883393974}
2022-11-28 02:29:34,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:34,829 INFO:     Epoch: 85
2022-11-28 02:29:35,580 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46980487182736397, 'Total loss': 0.46980487182736397} | train loss {'Reaction outcome loss': 0.303838471461448, 'Total loss': 0.303838471461448}
2022-11-28 02:29:35,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:35,581 INFO:     Epoch: 86
2022-11-28 02:29:36,336 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4473657567392696, 'Total loss': 0.4473657567392696} | train loss {'Reaction outcome loss': 0.31030616431587166, 'Total loss': 0.31030616431587166}
2022-11-28 02:29:36,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:36,336 INFO:     Epoch: 87
2022-11-28 02:29:37,088 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45061434906992043, 'Total loss': 0.45061434906992043} | train loss {'Reaction outcome loss': 0.31074899468090267, 'Total loss': 0.31074899468090267}
2022-11-28 02:29:37,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:37,088 INFO:     Epoch: 88
2022-11-28 02:29:37,839 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4849718311293559, 'Total loss': 0.4849718311293559} | train loss {'Reaction outcome loss': 0.3031171568699421, 'Total loss': 0.3031171568699421}
2022-11-28 02:29:37,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:37,839 INFO:     Epoch: 89
2022-11-28 02:29:38,594 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47422559322281316, 'Total loss': 0.47422559322281316} | train loss {'Reaction outcome loss': 0.3180995452097587, 'Total loss': 0.3180995452097587}
2022-11-28 02:29:38,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:38,595 INFO:     Epoch: 90
2022-11-28 02:29:39,346 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4958095716481859, 'Total loss': 0.4958095716481859} | train loss {'Reaction outcome loss': 0.30227767030197766, 'Total loss': 0.30227767030197766}
2022-11-28 02:29:39,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:39,346 INFO:     Epoch: 91
2022-11-28 02:29:40,097 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44315419041297655, 'Total loss': 0.44315419041297655} | train loss {'Reaction outcome loss': 0.3095731264761379, 'Total loss': 0.3095731264761379}
2022-11-28 02:29:40,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:40,097 INFO:     Epoch: 92
2022-11-28 02:29:40,850 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4464303116229447, 'Total loss': 0.4464303116229447} | train loss {'Reaction outcome loss': 0.3004672732805052, 'Total loss': 0.3004672732805052}
2022-11-28 02:29:40,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:40,850 INFO:     Epoch: 93
2022-11-28 02:29:41,602 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43808835643258964, 'Total loss': 0.43808835643258964} | train loss {'Reaction outcome loss': 0.3029338816901849, 'Total loss': 0.3029338816901849}
2022-11-28 02:29:41,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:41,602 INFO:     Epoch: 94
2022-11-28 02:29:42,356 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47273715924132953, 'Total loss': 0.47273715924132953} | train loss {'Reaction outcome loss': 0.303905894318896, 'Total loss': 0.303905894318896}
2022-11-28 02:29:42,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:42,356 INFO:     Epoch: 95
2022-11-28 02:29:43,110 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4580169878900051, 'Total loss': 0.4580169878900051} | train loss {'Reaction outcome loss': 0.30776886122241137, 'Total loss': 0.30776886122241137}
2022-11-28 02:29:43,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:43,111 INFO:     Epoch: 96
2022-11-28 02:29:43,864 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4793073883788152, 'Total loss': 0.4793073883788152} | train loss {'Reaction outcome loss': 0.30895886815062934, 'Total loss': 0.30895886815062934}
2022-11-28 02:29:43,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:43,864 INFO:     Epoch: 97
2022-11-28 02:29:44,616 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4301138479601253, 'Total loss': 0.4301138479601253} | train loss {'Reaction outcome loss': 0.30307489178413827, 'Total loss': 0.30307489178413827}
2022-11-28 02:29:44,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:44,617 INFO:     Epoch: 98
2022-11-28 02:29:45,368 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43243908204815606, 'Total loss': 0.43243908204815606} | train loss {'Reaction outcome loss': 0.30533866536232734, 'Total loss': 0.30533866536232734}
2022-11-28 02:29:45,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:45,368 INFO:     Epoch: 99
2022-11-28 02:29:46,119 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4844976963306015, 'Total loss': 0.4844976963306015} | train loss {'Reaction outcome loss': 0.3049096564251569, 'Total loss': 0.3049096564251569}
2022-11-28 02:29:46,119 INFO:     Best model found after epoch 79 of 100.
2022-11-28 02:29:46,120 INFO:   Done with stage: TRAINING
2022-11-28 02:29:46,120 INFO:   Starting stage: EVALUATION
2022-11-28 02:29:46,239 INFO:   Done with stage: EVALUATION
2022-11-28 02:29:46,239 INFO:   Leaving out SEQ value Fold_8
2022-11-28 02:29:46,252 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:29:46,252 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:29:46,883 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:29:46,884 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:29:46,951 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:29:46,952 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:29:46,952 INFO:     No hyperparam tuning for this model
2022-11-28 02:29:46,952 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:29:46,952 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:29:46,952 INFO:     None feature selector for col prot
2022-11-28 02:29:46,953 INFO:     None feature selector for col prot
2022-11-28 02:29:46,953 INFO:     None feature selector for col prot
2022-11-28 02:29:46,953 INFO:     None feature selector for col chem
2022-11-28 02:29:46,953 INFO:     None feature selector for col chem
2022-11-28 02:29:46,953 INFO:     None feature selector for col chem
2022-11-28 02:29:46,953 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:29:46,953 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:29:46,955 INFO:     Number of params in model 169741
2022-11-28 02:29:46,958 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:29:46,958 INFO:   Starting stage: TRAINING
2022-11-28 02:29:47,012 INFO:     Val loss before train {'Reaction outcome loss': 0.9692471276882083, 'Total loss': 0.9692471276882083}
2022-11-28 02:29:47,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:47,012 INFO:     Epoch: 0
2022-11-28 02:29:47,752 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5043015968660975, 'Total loss': 0.5043015968660975} | train loss {'Reaction outcome loss': 0.6238937391975864, 'Total loss': 0.6238937391975864}
2022-11-28 02:29:47,752 INFO:     Found new best model at epoch 0
2022-11-28 02:29:47,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:47,753 INFO:     Epoch: 1
2022-11-28 02:29:48,490 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48759596084439477, 'Total loss': 0.48759596084439477} | train loss {'Reaction outcome loss': 0.49525292834541834, 'Total loss': 0.49525292834541834}
2022-11-28 02:29:48,490 INFO:     Found new best model at epoch 1
2022-11-28 02:29:48,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:48,491 INFO:     Epoch: 2
2022-11-28 02:29:49,227 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4576224258472753, 'Total loss': 0.4576224258472753} | train loss {'Reaction outcome loss': 0.4600466933162486, 'Total loss': 0.4600466933162486}
2022-11-28 02:29:49,227 INFO:     Found new best model at epoch 2
2022-11-28 02:29:49,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:49,228 INFO:     Epoch: 3
2022-11-28 02:29:49,972 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5977218726346659, 'Total loss': 0.5977218726346659} | train loss {'Reaction outcome loss': 0.43341952953182283, 'Total loss': 0.43341952953182283}
2022-11-28 02:29:49,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:49,972 INFO:     Epoch: 4
2022-11-28 02:29:50,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4730278406032296, 'Total loss': 0.4730278406032296} | train loss {'Reaction outcome loss': 0.43292684446959223, 'Total loss': 0.43292684446959223}
2022-11-28 02:29:50,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:50,710 INFO:     Epoch: 5
2022-11-28 02:29:51,450 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4466129198323849, 'Total loss': 0.4466129198323849} | train loss {'Reaction outcome loss': 0.4049820035207467, 'Total loss': 0.4049820035207467}
2022-11-28 02:29:51,450 INFO:     Found new best model at epoch 5
2022-11-28 02:29:51,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:51,451 INFO:     Epoch: 6
2022-11-28 02:29:52,192 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4292674230974774, 'Total loss': 0.4292674230974774} | train loss {'Reaction outcome loss': 0.4095200664195858, 'Total loss': 0.4095200664195858}
2022-11-28 02:29:52,193 INFO:     Found new best model at epoch 6
2022-11-28 02:29:52,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:52,193 INFO:     Epoch: 7
2022-11-28 02:29:52,932 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4340847654398097, 'Total loss': 0.4340847654398097} | train loss {'Reaction outcome loss': 0.39273714164241413, 'Total loss': 0.39273714164241413}
2022-11-28 02:29:52,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:52,932 INFO:     Epoch: 8
2022-11-28 02:29:53,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43410237895887954, 'Total loss': 0.43410237895887954} | train loss {'Reaction outcome loss': 0.39007767964704115, 'Total loss': 0.39007767964704115}
2022-11-28 02:29:53,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:53,672 INFO:     Epoch: 9
2022-11-28 02:29:54,414 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4393170985371567, 'Total loss': 0.4393170985371567} | train loss {'Reaction outcome loss': 0.37851724953802884, 'Total loss': 0.37851724953802884}
2022-11-28 02:29:54,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:54,415 INFO:     Epoch: 10
2022-11-28 02:29:55,154 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41299916838490686, 'Total loss': 0.41299916838490686} | train loss {'Reaction outcome loss': 0.38132538970132346, 'Total loss': 0.38132538970132346}
2022-11-28 02:29:55,154 INFO:     Found new best model at epoch 10
2022-11-28 02:29:55,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:55,155 INFO:     Epoch: 11
2022-11-28 02:29:55,895 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4478677843892297, 'Total loss': 0.4478677843892297} | train loss {'Reaction outcome loss': 0.3680117512579824, 'Total loss': 0.3680117512579824}
2022-11-28 02:29:55,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:55,895 INFO:     Epoch: 12
2022-11-28 02:29:56,636 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4320858387753021, 'Total loss': 0.4320858387753021} | train loss {'Reaction outcome loss': 0.36634075583615267, 'Total loss': 0.36634075583615267}
2022-11-28 02:29:56,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:56,636 INFO:     Epoch: 13
2022-11-28 02:29:57,377 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4720754775890084, 'Total loss': 0.4720754775890084} | train loss {'Reaction outcome loss': 0.36305022508394524, 'Total loss': 0.36305022508394524}
2022-11-28 02:29:57,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:57,378 INFO:     Epoch: 14
2022-11-28 02:29:58,118 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4149517489727153, 'Total loss': 0.4149517489727153} | train loss {'Reaction outcome loss': 0.36284011272621935, 'Total loss': 0.36284011272621935}
2022-11-28 02:29:58,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:58,118 INFO:     Epoch: 15
2022-11-28 02:29:58,860 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4375171197015186, 'Total loss': 0.4375171197015186} | train loss {'Reaction outcome loss': 0.3598422297261289, 'Total loss': 0.3598422297261289}
2022-11-28 02:29:58,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:58,860 INFO:     Epoch: 16
2022-11-28 02:29:59,599 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41637368049732476, 'Total loss': 0.41637368049732476} | train loss {'Reaction outcome loss': 0.3537306484201404, 'Total loss': 0.3537306484201404}
2022-11-28 02:29:59,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:29:59,599 INFO:     Epoch: 17
2022-11-28 02:30:00,338 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44377887318300646, 'Total loss': 0.44377887318300646} | train loss {'Reaction outcome loss': 0.35040609492752395, 'Total loss': 0.35040609492752395}
2022-11-28 02:30:00,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:00,339 INFO:     Epoch: 18
2022-11-28 02:30:01,082 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43568547693795934, 'Total loss': 0.43568547693795934} | train loss {'Reaction outcome loss': 0.35722933031740733, 'Total loss': 0.35722933031740733}
2022-11-28 02:30:01,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:01,083 INFO:     Epoch: 19
2022-11-28 02:30:01,824 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4274960825609606, 'Total loss': 0.4274960825609606} | train loss {'Reaction outcome loss': 0.3453112913326162, 'Total loss': 0.3453112913326162}
2022-11-28 02:30:01,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:01,824 INFO:     Epoch: 20
2022-11-28 02:30:02,563 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4319275004226108, 'Total loss': 0.4319275004226108} | train loss {'Reaction outcome loss': 0.34515688359187763, 'Total loss': 0.34515688359187763}
2022-11-28 02:30:02,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:02,563 INFO:     Epoch: 21
2022-11-28 02:30:03,303 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43257155113442, 'Total loss': 0.43257155113442} | train loss {'Reaction outcome loss': 0.34624301425379805, 'Total loss': 0.34624301425379805}
2022-11-28 02:30:03,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:03,303 INFO:     Epoch: 22
2022-11-28 02:30:04,043 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40048184055228564, 'Total loss': 0.40048184055228564} | train loss {'Reaction outcome loss': 0.3460799533812726, 'Total loss': 0.3460799533812726}
2022-11-28 02:30:04,044 INFO:     Found new best model at epoch 22
2022-11-28 02:30:04,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:04,045 INFO:     Epoch: 23
2022-11-28 02:30:04,788 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4446442605451096, 'Total loss': 0.4446442605451096} | train loss {'Reaction outcome loss': 0.3382133150809124, 'Total loss': 0.3382133150809124}
2022-11-28 02:30:04,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:04,788 INFO:     Epoch: 24
2022-11-28 02:30:05,526 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40259424163851626, 'Total loss': 0.40259424163851626} | train loss {'Reaction outcome loss': 0.34548582142738044, 'Total loss': 0.34548582142738044}
2022-11-28 02:30:05,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:05,526 INFO:     Epoch: 25
2022-11-28 02:30:06,265 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4466750609666802, 'Total loss': 0.4466750609666802} | train loss {'Reaction outcome loss': 0.33378092294222994, 'Total loss': 0.33378092294222994}
2022-11-28 02:30:06,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:06,265 INFO:     Epoch: 26
2022-11-28 02:30:07,002 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4217213042253672, 'Total loss': 0.4217213042253672} | train loss {'Reaction outcome loss': 0.34011683280228594, 'Total loss': 0.34011683280228594}
2022-11-28 02:30:07,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:07,003 INFO:     Epoch: 27
2022-11-28 02:30:07,742 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4279220353725345, 'Total loss': 0.4279220353725345} | train loss {'Reaction outcome loss': 0.33115322200856245, 'Total loss': 0.33115322200856245}
2022-11-28 02:30:07,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:07,742 INFO:     Epoch: 28
2022-11-28 02:30:08,479 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42814421515132106, 'Total loss': 0.42814421515132106} | train loss {'Reaction outcome loss': 0.33283796303401714, 'Total loss': 0.33283796303401714}
2022-11-28 02:30:08,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:08,479 INFO:     Epoch: 29
2022-11-28 02:30:09,222 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42641449633032774, 'Total loss': 0.42641449633032774} | train loss {'Reaction outcome loss': 0.3251302051281587, 'Total loss': 0.3251302051281587}
2022-11-28 02:30:09,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:09,222 INFO:     Epoch: 30
2022-11-28 02:30:09,964 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4020723638146423, 'Total loss': 0.4020723638146423} | train loss {'Reaction outcome loss': 0.3355373582940121, 'Total loss': 0.3355373582940121}
2022-11-28 02:30:09,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:09,964 INFO:     Epoch: 31
2022-11-28 02:30:10,709 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4198349253382794, 'Total loss': 0.4198349253382794} | train loss {'Reaction outcome loss': 0.32001198321336605, 'Total loss': 0.32001198321336605}
2022-11-28 02:30:10,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:10,709 INFO:     Epoch: 32
2022-11-28 02:30:11,447 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4791115965954093, 'Total loss': 0.4791115965954093} | train loss {'Reaction outcome loss': 0.3228474055248939, 'Total loss': 0.3228474055248939}
2022-11-28 02:30:11,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:11,447 INFO:     Epoch: 33
2022-11-28 02:30:12,189 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4518610961561979, 'Total loss': 0.4518610961561979} | train loss {'Reaction outcome loss': 0.3337803050020679, 'Total loss': 0.3337803050020679}
2022-11-28 02:30:12,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:12,189 INFO:     Epoch: 34
2022-11-28 02:30:12,926 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48340596137351766, 'Total loss': 0.48340596137351766} | train loss {'Reaction outcome loss': 0.3303162955724802, 'Total loss': 0.3303162955724802}
2022-11-28 02:30:12,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:12,927 INFO:     Epoch: 35
2022-11-28 02:30:13,666 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3979863503644633, 'Total loss': 0.3979863503644633} | train loss {'Reaction outcome loss': 0.3244228876027905, 'Total loss': 0.3244228876027905}
2022-11-28 02:30:13,666 INFO:     Found new best model at epoch 35
2022-11-28 02:30:13,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:13,667 INFO:     Epoch: 36
2022-11-28 02:30:14,408 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4209379980037379, 'Total loss': 0.4209379980037379} | train loss {'Reaction outcome loss': 0.3363998478858686, 'Total loss': 0.3363998478858686}
2022-11-28 02:30:14,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:14,408 INFO:     Epoch: 37
2022-11-28 02:30:15,151 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4042865824560786, 'Total loss': 0.4042865824560786} | train loss {'Reaction outcome loss': 0.3265991362697277, 'Total loss': 0.3265991362697277}
2022-11-28 02:30:15,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:15,151 INFO:     Epoch: 38
2022-11-28 02:30:15,889 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4516977061365926, 'Total loss': 0.4516977061365926} | train loss {'Reaction outcome loss': 0.3261159508809692, 'Total loss': 0.3261159508809692}
2022-11-28 02:30:15,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:15,889 INFO:     Epoch: 39
2022-11-28 02:30:16,629 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4049426765982495, 'Total loss': 0.4049426765982495} | train loss {'Reaction outcome loss': 0.3272534603955316, 'Total loss': 0.3272534603955316}
2022-11-28 02:30:16,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:16,630 INFO:     Epoch: 40
2022-11-28 02:30:17,370 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41420568040637085, 'Total loss': 0.41420568040637085} | train loss {'Reaction outcome loss': 0.3152042180147083, 'Total loss': 0.3152042180147083}
2022-11-28 02:30:17,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:17,370 INFO:     Epoch: 41
2022-11-28 02:30:18,109 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4128797061221544, 'Total loss': 0.4128797061221544} | train loss {'Reaction outcome loss': 0.32557946226758055, 'Total loss': 0.32557946226758055}
2022-11-28 02:30:18,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:18,110 INFO:     Epoch: 42
2022-11-28 02:30:18,851 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4313673813675725, 'Total loss': 0.4313673813675725} | train loss {'Reaction outcome loss': 0.3229307339786262, 'Total loss': 0.3229307339786262}
2022-11-28 02:30:18,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:18,851 INFO:     Epoch: 43
2022-11-28 02:30:19,592 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41357610114785126, 'Total loss': 0.41357610114785126} | train loss {'Reaction outcome loss': 0.3193789060364981, 'Total loss': 0.3193789060364981}
2022-11-28 02:30:19,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:19,592 INFO:     Epoch: 44
2022-11-28 02:30:20,332 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4439818852169569, 'Total loss': 0.4439818852169569} | train loss {'Reaction outcome loss': 0.3126529166627614, 'Total loss': 0.3126529166627614}
2022-11-28 02:30:20,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:20,332 INFO:     Epoch: 45
2022-11-28 02:30:21,075 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4291484276222628, 'Total loss': 0.4291484276222628} | train loss {'Reaction outcome loss': 0.3211051018328452, 'Total loss': 0.3211051018328452}
2022-11-28 02:30:21,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:21,075 INFO:     Epoch: 46
2022-11-28 02:30:21,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41739554148773816, 'Total loss': 0.41739554148773816} | train loss {'Reaction outcome loss': 0.3181714236308805, 'Total loss': 0.3181714236308805}
2022-11-28 02:30:21,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:21,817 INFO:     Epoch: 47
2022-11-28 02:30:22,556 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4107449092837267, 'Total loss': 0.4107449092837267} | train loss {'Reaction outcome loss': 0.320189328345119, 'Total loss': 0.320189328345119}
2022-11-28 02:30:22,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:22,556 INFO:     Epoch: 48
2022-11-28 02:30:23,294 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39542480124983675, 'Total loss': 0.39542480124983675} | train loss {'Reaction outcome loss': 0.3116569175369671, 'Total loss': 0.3116569175369671}
2022-11-28 02:30:23,294 INFO:     Found new best model at epoch 48
2022-11-28 02:30:23,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:23,295 INFO:     Epoch: 49
2022-11-28 02:30:24,034 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4027234814887823, 'Total loss': 0.4027234814887823} | train loss {'Reaction outcome loss': 0.31403951322446105, 'Total loss': 0.31403951322446105}
2022-11-28 02:30:24,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:24,034 INFO:     Epoch: 50
2022-11-28 02:30:24,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39682365780652956, 'Total loss': 0.39682365780652956} | train loss {'Reaction outcome loss': 0.31753936121392934, 'Total loss': 0.31753936121392934}
2022-11-28 02:30:24,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:24,774 INFO:     Epoch: 51
2022-11-28 02:30:25,513 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4085439079722693, 'Total loss': 0.4085439079722693} | train loss {'Reaction outcome loss': 0.3183526600726315, 'Total loss': 0.3183526600726315}
2022-11-28 02:30:25,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:25,514 INFO:     Epoch: 52
2022-11-28 02:30:26,253 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4098584454420001, 'Total loss': 0.4098584454420001} | train loss {'Reaction outcome loss': 0.31794410238622645, 'Total loss': 0.31794410238622645}
2022-11-28 02:30:26,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:26,254 INFO:     Epoch: 53
2022-11-28 02:30:26,998 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4285048929064773, 'Total loss': 0.4285048929064773} | train loss {'Reaction outcome loss': 0.3073823059924313, 'Total loss': 0.3073823059924313}
2022-11-28 02:30:26,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:26,998 INFO:     Epoch: 54
2022-11-28 02:30:27,740 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3985244304288265, 'Total loss': 0.3985244304288265} | train loss {'Reaction outcome loss': 0.3191397769193425, 'Total loss': 0.3191397769193425}
2022-11-28 02:30:27,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:27,740 INFO:     Epoch: 55
2022-11-28 02:30:28,480 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39980577833430714, 'Total loss': 0.39980577833430714} | train loss {'Reaction outcome loss': 0.3187502355116313, 'Total loss': 0.3187502355116313}
2022-11-28 02:30:28,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:28,481 INFO:     Epoch: 56
2022-11-28 02:30:29,220 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.399738646523897, 'Total loss': 0.399738646523897} | train loss {'Reaction outcome loss': 0.32107892140868255, 'Total loss': 0.32107892140868255}
2022-11-28 02:30:29,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:29,221 INFO:     Epoch: 57
2022-11-28 02:30:29,960 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41167489300633586, 'Total loss': 0.41167489300633586} | train loss {'Reaction outcome loss': 0.3224786660160686, 'Total loss': 0.3224786660160686}
2022-11-28 02:30:29,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:29,960 INFO:     Epoch: 58
2022-11-28 02:30:30,697 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43394669128018754, 'Total loss': 0.43394669128018754} | train loss {'Reaction outcome loss': 0.3142755605036118, 'Total loss': 0.3142755605036118}
2022-11-28 02:30:30,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:30,697 INFO:     Epoch: 59
2022-11-28 02:30:31,436 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4460043224484421, 'Total loss': 0.4460043224484421} | train loss {'Reaction outcome loss': 0.3156895328190972, 'Total loss': 0.3156895328190972}
2022-11-28 02:30:31,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:31,436 INFO:     Epoch: 60
2022-11-28 02:30:32,174 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42783707657525705, 'Total loss': 0.42783707657525705} | train loss {'Reaction outcome loss': 0.3137996641033497, 'Total loss': 0.3137996641033497}
2022-11-28 02:30:32,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:32,174 INFO:     Epoch: 61
2022-11-28 02:30:32,914 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39803794338259585, 'Total loss': 0.39803794338259585} | train loss {'Reaction outcome loss': 0.31664288175277044, 'Total loss': 0.31664288175277044}
2022-11-28 02:30:32,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:32,915 INFO:     Epoch: 62
2022-11-28 02:30:33,654 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4060071595879488, 'Total loss': 0.4060071595879488} | train loss {'Reaction outcome loss': 0.31254971357154065, 'Total loss': 0.31254971357154065}
2022-11-28 02:30:33,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:33,654 INFO:     Epoch: 63
2022-11-28 02:30:34,393 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43032378582067266, 'Total loss': 0.43032378582067266} | train loss {'Reaction outcome loss': 0.31206323531624236, 'Total loss': 0.31206323531624236}
2022-11-28 02:30:34,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:34,393 INFO:     Epoch: 64
2022-11-28 02:30:35,137 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43166823858438536, 'Total loss': 0.43166823858438536} | train loss {'Reaction outcome loss': 0.3171615479361327, 'Total loss': 0.3171615479361327}
2022-11-28 02:30:35,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:35,138 INFO:     Epoch: 65
2022-11-28 02:30:35,877 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4046656867099363, 'Total loss': 0.4046656867099363} | train loss {'Reaction outcome loss': 0.3153657698545788, 'Total loss': 0.3153657698545788}
2022-11-28 02:30:35,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:35,878 INFO:     Epoch: 66
2022-11-28 02:30:36,617 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43078423343425576, 'Total loss': 0.43078423343425576} | train loss {'Reaction outcome loss': 0.3199374636055016, 'Total loss': 0.3199374636055016}
2022-11-28 02:30:36,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:36,617 INFO:     Epoch: 67
2022-11-28 02:30:37,356 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40982342112896053, 'Total loss': 0.40982342112896053} | train loss {'Reaction outcome loss': 0.3215727875711488, 'Total loss': 0.3215727875711488}
2022-11-28 02:30:37,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:37,356 INFO:     Epoch: 68
2022-11-28 02:30:38,092 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4216438174940819, 'Total loss': 0.4216438174940819} | train loss {'Reaction outcome loss': 0.3139410110831749, 'Total loss': 0.3139410110831749}
2022-11-28 02:30:38,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:38,092 INFO:     Epoch: 69
2022-11-28 02:30:38,832 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4623413517378097, 'Total loss': 0.4623413517378097} | train loss {'Reaction outcome loss': 0.31490902559923345, 'Total loss': 0.31490902559923345}
2022-11-28 02:30:38,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:38,832 INFO:     Epoch: 70
2022-11-28 02:30:39,572 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4117586761713028, 'Total loss': 0.4117586761713028} | train loss {'Reaction outcome loss': 0.31153324976197033, 'Total loss': 0.31153324976197033}
2022-11-28 02:30:39,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:39,573 INFO:     Epoch: 71
2022-11-28 02:30:40,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4213477224111557, 'Total loss': 0.4213477224111557} | train loss {'Reaction outcome loss': 0.31626474428311235, 'Total loss': 0.31626474428311235}
2022-11-28 02:30:40,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:40,310 INFO:     Epoch: 72
2022-11-28 02:30:41,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42972718352495237, 'Total loss': 0.42972718352495237} | train loss {'Reaction outcome loss': 0.3227911842528914, 'Total loss': 0.3227911842528914}
2022-11-28 02:30:41,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:41,046 INFO:     Epoch: 73
2022-11-28 02:30:41,782 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4216282787018044, 'Total loss': 0.4216282787018044} | train loss {'Reaction outcome loss': 0.32278357282830555, 'Total loss': 0.32278357282830555}
2022-11-28 02:30:41,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:41,783 INFO:     Epoch: 74
2022-11-28 02:30:42,521 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40042365073811176, 'Total loss': 0.40042365073811176} | train loss {'Reaction outcome loss': 0.31476545607152046, 'Total loss': 0.31476545607152046}
2022-11-28 02:30:42,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:42,521 INFO:     Epoch: 75
2022-11-28 02:30:43,259 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4123877727015074, 'Total loss': 0.4123877727015074} | train loss {'Reaction outcome loss': 0.31382862206731665, 'Total loss': 0.31382862206731665}
2022-11-28 02:30:43,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:43,259 INFO:     Epoch: 76
2022-11-28 02:30:43,995 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40462165585784027, 'Total loss': 0.40462165585784027} | train loss {'Reaction outcome loss': 0.31014763954721514, 'Total loss': 0.31014763954721514}
2022-11-28 02:30:43,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:43,995 INFO:     Epoch: 77
2022-11-28 02:30:44,732 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41336596324000247, 'Total loss': 0.41336596324000247} | train loss {'Reaction outcome loss': 0.3102180974283179, 'Total loss': 0.3102180974283179}
2022-11-28 02:30:44,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:44,732 INFO:     Epoch: 78
2022-11-28 02:30:45,470 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4210643747518229, 'Total loss': 0.4210643747518229} | train loss {'Reaction outcome loss': 0.31212208074990844, 'Total loss': 0.31212208074990844}
2022-11-28 02:30:45,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:45,471 INFO:     Epoch: 79
2022-11-28 02:30:46,205 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42018802186777426, 'Total loss': 0.42018802186777426} | train loss {'Reaction outcome loss': 0.3188290108667045, 'Total loss': 0.3188290108667045}
2022-11-28 02:30:46,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:46,205 INFO:     Epoch: 80
2022-11-28 02:30:46,942 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4041543256404788, 'Total loss': 0.4041543256404788} | train loss {'Reaction outcome loss': 0.3184548958403165, 'Total loss': 0.3184548958403165}
2022-11-28 02:30:46,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:46,943 INFO:     Epoch: 81
2022-11-28 02:30:47,676 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46616074893363685, 'Total loss': 0.46616074893363685} | train loss {'Reaction outcome loss': 0.31358952411129826, 'Total loss': 0.31358952411129826}
2022-11-28 02:30:47,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:47,677 INFO:     Epoch: 82
2022-11-28 02:30:48,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4149630386815515, 'Total loss': 0.4149630386815515} | train loss {'Reaction outcome loss': 0.31930929599482505, 'Total loss': 0.31930929599482505}
2022-11-28 02:30:48,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:48,418 INFO:     Epoch: 83
2022-11-28 02:30:49,154 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4235034006279568, 'Total loss': 0.4235034006279568} | train loss {'Reaction outcome loss': 0.3164512021009062, 'Total loss': 0.3164512021009062}
2022-11-28 02:30:49,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:49,154 INFO:     Epoch: 84
2022-11-28 02:30:49,892 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4055939510811207, 'Total loss': 0.4055939510811207} | train loss {'Reaction outcome loss': 0.31003588764760337, 'Total loss': 0.31003588764760337}
2022-11-28 02:30:49,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:49,892 INFO:     Epoch: 85
2022-11-28 02:30:50,631 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4276314408973206, 'Total loss': 0.4276314408973206} | train loss {'Reaction outcome loss': 0.3095309732665048, 'Total loss': 0.3095309732665048}
2022-11-28 02:30:50,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:50,632 INFO:     Epoch: 86
2022-11-28 02:30:51,370 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4202424350172974, 'Total loss': 0.4202424350172974} | train loss {'Reaction outcome loss': 0.31668973329370137, 'Total loss': 0.31668973329370137}
2022-11-28 02:30:51,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:51,370 INFO:     Epoch: 87
2022-11-28 02:30:52,109 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4348760240299757, 'Total loss': 0.4348760240299757} | train loss {'Reaction outcome loss': 0.31677808942364866, 'Total loss': 0.31677808942364866}
2022-11-28 02:30:52,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:52,109 INFO:     Epoch: 88
2022-11-28 02:30:52,847 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39727625042893167, 'Total loss': 0.39727625042893167} | train loss {'Reaction outcome loss': 0.3085033612967026, 'Total loss': 0.3085033612967026}
2022-11-28 02:30:52,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:52,847 INFO:     Epoch: 89
2022-11-28 02:30:53,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39900268267753514, 'Total loss': 0.39900268267753514} | train loss {'Reaction outcome loss': 0.3047931015980048, 'Total loss': 0.3047931015980048}
2022-11-28 02:30:53,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:53,583 INFO:     Epoch: 90
2022-11-28 02:30:54,318 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42971201414285704, 'Total loss': 0.42971201414285704} | train loss {'Reaction outcome loss': 0.3172365612976375, 'Total loss': 0.3172365612976375}
2022-11-28 02:30:54,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:54,318 INFO:     Epoch: 91
2022-11-28 02:30:55,053 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4559004440210586, 'Total loss': 0.4559004440210586} | train loss {'Reaction outcome loss': 0.3111075045632534, 'Total loss': 0.3111075045632534}
2022-11-28 02:30:55,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:55,054 INFO:     Epoch: 92
2022-11-28 02:30:55,788 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40529887100984885, 'Total loss': 0.40529887100984885} | train loss {'Reaction outcome loss': 0.31428939736158146, 'Total loss': 0.31428939736158146}
2022-11-28 02:30:55,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:55,788 INFO:     Epoch: 93
2022-11-28 02:30:56,525 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41578167850194975, 'Total loss': 0.41578167850194975} | train loss {'Reaction outcome loss': 0.3119905457267019, 'Total loss': 0.3119905457267019}
2022-11-28 02:30:56,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:56,525 INFO:     Epoch: 94
2022-11-28 02:30:57,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43677533192690027, 'Total loss': 0.43677533192690027} | train loss {'Reaction outcome loss': 0.3052789755470929, 'Total loss': 0.3052789755470929}
2022-11-28 02:30:57,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:57,261 INFO:     Epoch: 95
2022-11-28 02:30:58,001 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.410944421970567, 'Total loss': 0.410944421970567} | train loss {'Reaction outcome loss': 0.3100286064455744, 'Total loss': 0.3100286064455744}
2022-11-28 02:30:58,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:58,001 INFO:     Epoch: 96
2022-11-28 02:30:58,740 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.425682156238445, 'Total loss': 0.425682156238445} | train loss {'Reaction outcome loss': 0.311254348941758, 'Total loss': 0.311254348941758}
2022-11-28 02:30:58,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:58,740 INFO:     Epoch: 97
2022-11-28 02:30:59,476 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4249094915251399, 'Total loss': 0.4249094915251399} | train loss {'Reaction outcome loss': 0.3028178620228513, 'Total loss': 0.3028178620228513}
2022-11-28 02:30:59,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:30:59,477 INFO:     Epoch: 98
2022-11-28 02:31:00,213 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4287082861329234, 'Total loss': 0.4287082861329234} | train loss {'Reaction outcome loss': 0.31005039985184785, 'Total loss': 0.31005039985184785}
2022-11-28 02:31:00,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:00,213 INFO:     Epoch: 99
2022-11-28 02:31:00,949 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4041598496395488, 'Total loss': 0.4041598496395488} | train loss {'Reaction outcome loss': 0.31582084653868536, 'Total loss': 0.31582084653868536}
2022-11-28 02:31:00,949 INFO:     Best model found after epoch 49 of 100.
2022-11-28 02:31:00,949 INFO:   Done with stage: TRAINING
2022-11-28 02:31:00,949 INFO:   Starting stage: EVALUATION
2022-11-28 02:31:01,085 INFO:   Done with stage: EVALUATION
2022-11-28 02:31:01,086 INFO:   Leaving out SEQ value Fold_9
2022-11-28 02:31:01,098 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:31:01,098 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:31:01,738 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:31:01,739 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:31:01,806 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:31:01,806 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:31:01,806 INFO:     No hyperparam tuning for this model
2022-11-28 02:31:01,807 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:31:01,807 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:31:01,807 INFO:     None feature selector for col prot
2022-11-28 02:31:01,807 INFO:     None feature selector for col prot
2022-11-28 02:31:01,807 INFO:     None feature selector for col prot
2022-11-28 02:31:01,808 INFO:     None feature selector for col chem
2022-11-28 02:31:01,808 INFO:     None feature selector for col chem
2022-11-28 02:31:01,808 INFO:     None feature selector for col chem
2022-11-28 02:31:01,808 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:31:01,808 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:31:01,810 INFO:     Number of params in model 169741
2022-11-28 02:31:01,813 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:31:01,813 INFO:   Starting stage: TRAINING
2022-11-28 02:31:01,866 INFO:     Val loss before train {'Reaction outcome loss': 1.0399125814437866, 'Total loss': 1.0399125814437866}
2022-11-28 02:31:01,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:01,867 INFO:     Epoch: 0
2022-11-28 02:31:02,616 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5415593819184736, 'Total loss': 0.5415593819184736} | train loss {'Reaction outcome loss': 0.6517669289342819, 'Total loss': 0.6517669289342819}
2022-11-28 02:31:02,616 INFO:     Found new best model at epoch 0
2022-11-28 02:31:02,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:02,617 INFO:     Epoch: 1
2022-11-28 02:31:03,368 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5332721776582978, 'Total loss': 0.5332721776582978} | train loss {'Reaction outcome loss': 0.5029137568368066, 'Total loss': 0.5029137568368066}
2022-11-28 02:31:03,368 INFO:     Found new best model at epoch 1
2022-11-28 02:31:03,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:03,369 INFO:     Epoch: 2
2022-11-28 02:31:04,119 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49372951076789334, 'Total loss': 0.49372951076789334} | train loss {'Reaction outcome loss': 0.4649660482161468, 'Total loss': 0.4649660482161468}
2022-11-28 02:31:04,119 INFO:     Found new best model at epoch 2
2022-11-28 02:31:04,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:04,120 INFO:     Epoch: 3
2022-11-28 02:31:04,866 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46504571627486835, 'Total loss': 0.46504571627486835} | train loss {'Reaction outcome loss': 0.438136821853057, 'Total loss': 0.438136821853057}
2022-11-28 02:31:04,866 INFO:     Found new best model at epoch 3
2022-11-28 02:31:04,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:04,867 INFO:     Epoch: 4
2022-11-28 02:31:05,618 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4547515714710409, 'Total loss': 0.4547515714710409} | train loss {'Reaction outcome loss': 0.4301783181126079, 'Total loss': 0.4301783181126079}
2022-11-28 02:31:05,619 INFO:     Found new best model at epoch 4
2022-11-28 02:31:05,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:05,620 INFO:     Epoch: 5
2022-11-28 02:31:06,373 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4642917937175794, 'Total loss': 0.4642917937175794} | train loss {'Reaction outcome loss': 0.41468094060978583, 'Total loss': 0.41468094060978583}
2022-11-28 02:31:06,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:06,374 INFO:     Epoch: 6
2022-11-28 02:31:07,124 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46118124117228115, 'Total loss': 0.46118124117228115} | train loss {'Reaction outcome loss': 0.4027175090966686, 'Total loss': 0.4027175090966686}
2022-11-28 02:31:07,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:07,125 INFO:     Epoch: 7
2022-11-28 02:31:07,877 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4379977665164254, 'Total loss': 0.4379977665164254} | train loss {'Reaction outcome loss': 0.39523628861793586, 'Total loss': 0.39523628861793586}
2022-11-28 02:31:07,878 INFO:     Found new best model at epoch 7
2022-11-28 02:31:07,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:07,878 INFO:     Epoch: 8
2022-11-28 02:31:08,628 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4674019803377715, 'Total loss': 0.4674019803377715} | train loss {'Reaction outcome loss': 0.3968610672520534, 'Total loss': 0.3968610672520534}
2022-11-28 02:31:08,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:08,628 INFO:     Epoch: 9
2022-11-28 02:31:09,376 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4715951914814385, 'Total loss': 0.4715951914814385} | train loss {'Reaction outcome loss': 0.3854038166032443, 'Total loss': 0.3854038166032443}
2022-11-28 02:31:09,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:09,376 INFO:     Epoch: 10
2022-11-28 02:31:10,122 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44772065159949387, 'Total loss': 0.44772065159949387} | train loss {'Reaction outcome loss': 0.3782817467205947, 'Total loss': 0.3782817467205947}
2022-11-28 02:31:10,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:10,122 INFO:     Epoch: 11
2022-11-28 02:31:10,868 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4494908499446782, 'Total loss': 0.4494908499446782} | train loss {'Reaction outcome loss': 0.38100813172997966, 'Total loss': 0.38100813172997966}
2022-11-28 02:31:10,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:10,868 INFO:     Epoch: 12
2022-11-28 02:31:11,616 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4302383783188733, 'Total loss': 0.4302383783188733} | train loss {'Reaction outcome loss': 0.37028215894655836, 'Total loss': 0.37028215894655836}
2022-11-28 02:31:11,616 INFO:     Found new best model at epoch 12
2022-11-28 02:31:11,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:11,617 INFO:     Epoch: 13
2022-11-28 02:31:12,368 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4494075504216281, 'Total loss': 0.4494075504216281} | train loss {'Reaction outcome loss': 0.3680705330484817, 'Total loss': 0.3680705330484817}
2022-11-28 02:31:12,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:12,368 INFO:     Epoch: 14
2022-11-28 02:31:13,119 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4591153440150348, 'Total loss': 0.4591153440150348} | train loss {'Reaction outcome loss': 0.367801176639454, 'Total loss': 0.367801176639454}
2022-11-28 02:31:13,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:13,120 INFO:     Epoch: 15
2022-11-28 02:31:13,871 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4299083985388279, 'Total loss': 0.4299083985388279} | train loss {'Reaction outcome loss': 0.3600857065269543, 'Total loss': 0.3600857065269543}
2022-11-28 02:31:13,871 INFO:     Found new best model at epoch 15
2022-11-28 02:31:13,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:13,872 INFO:     Epoch: 16
2022-11-28 02:31:14,620 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44183861396529456, 'Total loss': 0.44183861396529456} | train loss {'Reaction outcome loss': 0.354621822284835, 'Total loss': 0.354621822284835}
2022-11-28 02:31:14,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:14,620 INFO:     Epoch: 17
2022-11-28 02:31:15,368 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4582733728668906, 'Total loss': 0.4582733728668906} | train loss {'Reaction outcome loss': 0.3555057289589557, 'Total loss': 0.3555057289589557}
2022-11-28 02:31:15,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:15,369 INFO:     Epoch: 18
2022-11-28 02:31:16,117 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45155205069617793, 'Total loss': 0.45155205069617793} | train loss {'Reaction outcome loss': 0.35334357006415246, 'Total loss': 0.35334357006415246}
2022-11-28 02:31:16,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:16,117 INFO:     Epoch: 19
2022-11-28 02:31:16,864 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45708993314342067, 'Total loss': 0.45708993314342067} | train loss {'Reaction outcome loss': 0.35227382934141543, 'Total loss': 0.35227382934141543}
2022-11-28 02:31:16,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:16,865 INFO:     Epoch: 20
2022-11-28 02:31:17,617 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4473385712639852, 'Total loss': 0.4473385712639852} | train loss {'Reaction outcome loss': 0.3577152261991174, 'Total loss': 0.3577152261991174}
2022-11-28 02:31:17,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:17,618 INFO:     Epoch: 21
2022-11-28 02:31:18,369 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47371377660469577, 'Total loss': 0.47371377660469577} | train loss {'Reaction outcome loss': 0.3395611608040429, 'Total loss': 0.3395611608040429}
2022-11-28 02:31:18,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:18,370 INFO:     Epoch: 22
2022-11-28 02:31:19,119 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4350426593287425, 'Total loss': 0.4350426593287425} | train loss {'Reaction outcome loss': 0.34756262369093394, 'Total loss': 0.34756262369093394}
2022-11-28 02:31:19,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:19,119 INFO:     Epoch: 23
2022-11-28 02:31:19,869 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45674817433411424, 'Total loss': 0.45674817433411424} | train loss {'Reaction outcome loss': 0.3524257913982916, 'Total loss': 0.3524257913982916}
2022-11-28 02:31:19,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:19,870 INFO:     Epoch: 24
2022-11-28 02:31:20,621 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4561120757663792, 'Total loss': 0.4561120757663792} | train loss {'Reaction outcome loss': 0.3400465589196932, 'Total loss': 0.3400465589196932}
2022-11-28 02:31:20,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:20,621 INFO:     Epoch: 25
2022-11-28 02:31:21,370 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5033762841062113, 'Total loss': 0.5033762841062113} | train loss {'Reaction outcome loss': 0.3413609575119711, 'Total loss': 0.3413609575119711}
2022-11-28 02:31:21,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:21,371 INFO:     Epoch: 26
2022-11-28 02:31:22,117 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41988224028186366, 'Total loss': 0.41988224028186366} | train loss {'Reaction outcome loss': 0.34171540398270855, 'Total loss': 0.34171540398270855}
2022-11-28 02:31:22,118 INFO:     Found new best model at epoch 26
2022-11-28 02:31:22,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:22,119 INFO:     Epoch: 27
2022-11-28 02:31:22,866 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43957413970069453, 'Total loss': 0.43957413970069453} | train loss {'Reaction outcome loss': 0.33719059407350516, 'Total loss': 0.33719059407350516}
2022-11-28 02:31:22,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:22,866 INFO:     Epoch: 28
2022-11-28 02:31:23,614 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43800957839597354, 'Total loss': 0.43800957839597354} | train loss {'Reaction outcome loss': 0.3399471482562442, 'Total loss': 0.3399471482562442}
2022-11-28 02:31:23,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:23,615 INFO:     Epoch: 29
2022-11-28 02:31:24,363 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4527547776021741, 'Total loss': 0.4527547776021741} | train loss {'Reaction outcome loss': 0.3363408682897927, 'Total loss': 0.3363408682897927}
2022-11-28 02:31:24,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:24,363 INFO:     Epoch: 30
2022-11-28 02:31:25,111 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4731562262908979, 'Total loss': 0.4731562262908979} | train loss {'Reaction outcome loss': 0.33818113951072576, 'Total loss': 0.33818113951072576}
2022-11-28 02:31:25,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:25,111 INFO:     Epoch: 31
2022-11-28 02:31:25,858 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4423243376341733, 'Total loss': 0.4423243376341733} | train loss {'Reaction outcome loss': 0.3394146909817092, 'Total loss': 0.3394146909817092}
2022-11-28 02:31:25,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:25,858 INFO:     Epoch: 32
2022-11-28 02:31:26,605 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46810734779997304, 'Total loss': 0.46810734779997304} | train loss {'Reaction outcome loss': 0.3248316521395839, 'Total loss': 0.3248316521395839}
2022-11-28 02:31:26,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:26,605 INFO:     Epoch: 33
2022-11-28 02:31:27,351 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45821617069569504, 'Total loss': 0.45821617069569504} | train loss {'Reaction outcome loss': 0.34628461382441944, 'Total loss': 0.34628461382441944}
2022-11-28 02:31:27,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:27,351 INFO:     Epoch: 34
2022-11-28 02:31:28,100 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4642789866775274, 'Total loss': 0.4642789866775274} | train loss {'Reaction outcome loss': 0.3249689881058951, 'Total loss': 0.3249689881058951}
2022-11-28 02:31:28,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:28,100 INFO:     Epoch: 35
2022-11-28 02:31:28,850 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.448563582517884, 'Total loss': 0.448563582517884} | train loss {'Reaction outcome loss': 0.3258714066037247, 'Total loss': 0.3258714066037247}
2022-11-28 02:31:28,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:28,850 INFO:     Epoch: 36
2022-11-28 02:31:29,599 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.464008356359872, 'Total loss': 0.464008356359872} | train loss {'Reaction outcome loss': 0.32607319281106034, 'Total loss': 0.32607319281106034}
2022-11-28 02:31:29,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:29,599 INFO:     Epoch: 37
2022-11-28 02:31:30,347 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4517055423083631, 'Total loss': 0.4517055423083631} | train loss {'Reaction outcome loss': 0.32801012577669275, 'Total loss': 0.32801012577669275}
2022-11-28 02:31:30,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:30,348 INFO:     Epoch: 38
2022-11-28 02:31:31,098 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4627245403826237, 'Total loss': 0.4627245403826237} | train loss {'Reaction outcome loss': 0.3300369844261196, 'Total loss': 0.3300369844261196}
2022-11-28 02:31:31,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:31,098 INFO:     Epoch: 39
2022-11-28 02:31:31,845 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4586182392456315, 'Total loss': 0.4586182392456315} | train loss {'Reaction outcome loss': 0.3323313991629308, 'Total loss': 0.3323313991629308}
2022-11-28 02:31:31,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:31,845 INFO:     Epoch: 40
2022-11-28 02:31:32,592 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4721354571255771, 'Total loss': 0.4721354571255771} | train loss {'Reaction outcome loss': 0.32642247948435044, 'Total loss': 0.32642247948435044}
2022-11-28 02:31:32,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:32,593 INFO:     Epoch: 41
2022-11-28 02:31:33,339 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4644270505417477, 'Total loss': 0.4644270505417477} | train loss {'Reaction outcome loss': 0.3333028271614063, 'Total loss': 0.3333028271614063}
2022-11-28 02:31:33,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:33,340 INFO:     Epoch: 42
2022-11-28 02:31:34,088 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46486289968544786, 'Total loss': 0.46486289968544786} | train loss {'Reaction outcome loss': 0.32206217414369026, 'Total loss': 0.32206217414369026}
2022-11-28 02:31:34,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:34,088 INFO:     Epoch: 43
2022-11-28 02:31:34,838 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44372462955388153, 'Total loss': 0.44372462955388153} | train loss {'Reaction outcome loss': 0.31902326080167004, 'Total loss': 0.31902326080167004}
2022-11-28 02:31:34,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:34,838 INFO:     Epoch: 44
2022-11-28 02:31:35,584 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4465500485490669, 'Total loss': 0.4465500485490669} | train loss {'Reaction outcome loss': 0.3159025411211675, 'Total loss': 0.3159025411211675}
2022-11-28 02:31:35,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:35,585 INFO:     Epoch: 45
2022-11-28 02:31:36,334 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45058075575665996, 'Total loss': 0.45058075575665996} | train loss {'Reaction outcome loss': 0.3304867102133651, 'Total loss': 0.3304867102133651}
2022-11-28 02:31:36,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:36,334 INFO:     Epoch: 46
2022-11-28 02:31:37,085 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.432368510148742, 'Total loss': 0.432368510148742} | train loss {'Reaction outcome loss': 0.3211378177567836, 'Total loss': 0.3211378177567836}
2022-11-28 02:31:37,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:37,086 INFO:     Epoch: 47
2022-11-28 02:31:37,837 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40332573516802356, 'Total loss': 0.40332573516802356} | train loss {'Reaction outcome loss': 0.32302892359814817, 'Total loss': 0.32302892359814817}
2022-11-28 02:31:37,837 INFO:     Found new best model at epoch 47
2022-11-28 02:31:37,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:37,838 INFO:     Epoch: 48
2022-11-28 02:31:38,585 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42512384937568143, 'Total loss': 0.42512384937568143} | train loss {'Reaction outcome loss': 0.33351538910139955, 'Total loss': 0.33351538910139955}
2022-11-28 02:31:38,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:38,585 INFO:     Epoch: 49
2022-11-28 02:31:39,335 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4517774344845252, 'Total loss': 0.4517774344845252} | train loss {'Reaction outcome loss': 0.3167534067085193, 'Total loss': 0.3167534067085193}
2022-11-28 02:31:39,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:39,335 INFO:     Epoch: 50
2022-11-28 02:31:40,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4716569517146457, 'Total loss': 0.4716569517146457} | train loss {'Reaction outcome loss': 0.31687436156695886, 'Total loss': 0.31687436156695886}
2022-11-28 02:31:40,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:40,082 INFO:     Epoch: 51
2022-11-28 02:31:40,832 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43024874038316985, 'Total loss': 0.43024874038316985} | train loss {'Reaction outcome loss': 0.3236730823052987, 'Total loss': 0.3236730823052987}
2022-11-28 02:31:40,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:40,832 INFO:     Epoch: 52
2022-11-28 02:31:41,582 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.447709453038194, 'Total loss': 0.447709453038194} | train loss {'Reaction outcome loss': 0.32286127839958473, 'Total loss': 0.32286127839958473}
2022-11-28 02:31:41,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:41,582 INFO:     Epoch: 53
2022-11-28 02:31:42,331 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4359894645485011, 'Total loss': 0.4359894645485011} | train loss {'Reaction outcome loss': 0.32163577800196025, 'Total loss': 0.32163577800196025}
2022-11-28 02:31:42,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:42,332 INFO:     Epoch: 54
2022-11-28 02:31:43,080 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45884903418746864, 'Total loss': 0.45884903418746864} | train loss {'Reaction outcome loss': 0.31198266887616727, 'Total loss': 0.31198266887616727}
2022-11-28 02:31:43,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:43,081 INFO:     Epoch: 55
2022-11-28 02:31:43,830 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49007595228877937, 'Total loss': 0.49007595228877937} | train loss {'Reaction outcome loss': 0.32060477092501616, 'Total loss': 0.32060477092501616}
2022-11-28 02:31:43,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:43,830 INFO:     Epoch: 56
2022-11-28 02:31:44,578 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41769908808849077, 'Total loss': 0.41769908808849077} | train loss {'Reaction outcome loss': 0.3302016923234107, 'Total loss': 0.3302016923234107}
2022-11-28 02:31:44,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:44,578 INFO:     Epoch: 57
2022-11-28 02:31:45,327 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4449844126674262, 'Total loss': 0.4449844126674262} | train loss {'Reaction outcome loss': 0.31737047304669697, 'Total loss': 0.31737047304669697}
2022-11-28 02:31:45,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:45,327 INFO:     Epoch: 58
2022-11-28 02:31:46,082 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4431103603406386, 'Total loss': 0.4431103603406386} | train loss {'Reaction outcome loss': 0.3251882724223598, 'Total loss': 0.3251882724223598}
2022-11-28 02:31:46,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:46,082 INFO:     Epoch: 59
2022-11-28 02:31:46,832 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46781956641511485, 'Total loss': 0.46781956641511485} | train loss {'Reaction outcome loss': 0.31432563985788053, 'Total loss': 0.31432563985788053}
2022-11-28 02:31:46,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:46,832 INFO:     Epoch: 60
2022-11-28 02:31:47,584 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43650251372971316, 'Total loss': 0.43650251372971316} | train loss {'Reaction outcome loss': 0.3153726892065137, 'Total loss': 0.3153726892065137}
2022-11-28 02:31:47,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:47,584 INFO:     Epoch: 61
2022-11-28 02:31:48,333 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4487831274216825, 'Total loss': 0.4487831274216825} | train loss {'Reaction outcome loss': 0.31687072093688673, 'Total loss': 0.31687072093688673}
2022-11-28 02:31:48,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:48,333 INFO:     Epoch: 62
2022-11-28 02:31:49,083 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43345494534481654, 'Total loss': 0.43345494534481654} | train loss {'Reaction outcome loss': 0.31533077211990473, 'Total loss': 0.31533077211990473}
2022-11-28 02:31:49,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:49,084 INFO:     Epoch: 63
2022-11-28 02:31:49,837 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43098354390399024, 'Total loss': 0.43098354390399024} | train loss {'Reaction outcome loss': 0.3126122040614005, 'Total loss': 0.3126122040614005}
2022-11-28 02:31:49,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:49,837 INFO:     Epoch: 64
2022-11-28 02:31:50,587 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4447292441671545, 'Total loss': 0.4447292441671545} | train loss {'Reaction outcome loss': 0.30716992046443686, 'Total loss': 0.30716992046443686}
2022-11-28 02:31:50,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:50,587 INFO:     Epoch: 65
2022-11-28 02:31:51,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42797684601762076, 'Total loss': 0.42797684601762076} | train loss {'Reaction outcome loss': 0.30595810902154735, 'Total loss': 0.30595810902154735}
2022-11-28 02:31:51,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:51,336 INFO:     Epoch: 66
2022-11-28 02:31:52,088 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4386661174622449, 'Total loss': 0.4386661174622449} | train loss {'Reaction outcome loss': 0.31641403570651044, 'Total loss': 0.31641403570651044}
2022-11-28 02:31:52,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:52,088 INFO:     Epoch: 67
2022-11-28 02:31:52,841 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5050220516594973, 'Total loss': 0.5050220516594973} | train loss {'Reaction outcome loss': 0.3179808012960899, 'Total loss': 0.3179808012960899}
2022-11-28 02:31:52,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:52,841 INFO:     Epoch: 68
2022-11-28 02:31:53,588 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4514136915518479, 'Total loss': 0.4514136915518479} | train loss {'Reaction outcome loss': 0.31332245409007997, 'Total loss': 0.31332245409007997}
2022-11-28 02:31:53,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:53,589 INFO:     Epoch: 69
2022-11-28 02:31:54,340 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43326224048029294, 'Total loss': 0.43326224048029294} | train loss {'Reaction outcome loss': 0.3085505850913544, 'Total loss': 0.3085505850913544}
2022-11-28 02:31:54,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:54,340 INFO:     Epoch: 70
2022-11-28 02:31:55,090 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42852219549769704, 'Total loss': 0.42852219549769704} | train loss {'Reaction outcome loss': 0.30912660041283213, 'Total loss': 0.30912660041283213}
2022-11-28 02:31:55,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:55,090 INFO:     Epoch: 71
2022-11-28 02:31:55,840 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44704737090928987, 'Total loss': 0.44704737090928987} | train loss {'Reaction outcome loss': 0.31240398761245514, 'Total loss': 0.31240398761245514}
2022-11-28 02:31:55,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:55,841 INFO:     Epoch: 72
2022-11-28 02:31:56,589 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46852508932352066, 'Total loss': 0.46852508932352066} | train loss {'Reaction outcome loss': 0.31344856291769013, 'Total loss': 0.31344856291769013}
2022-11-28 02:31:56,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:56,589 INFO:     Epoch: 73
2022-11-28 02:31:57,338 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4538991546088999, 'Total loss': 0.4538991546088999} | train loss {'Reaction outcome loss': 0.3127653530588554, 'Total loss': 0.3127653530588554}
2022-11-28 02:31:57,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:57,338 INFO:     Epoch: 74
2022-11-28 02:31:58,087 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48411744528196077, 'Total loss': 0.48411744528196077} | train loss {'Reaction outcome loss': 0.30961920073135724, 'Total loss': 0.30961920073135724}
2022-11-28 02:31:58,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:58,087 INFO:     Epoch: 75
2022-11-28 02:31:58,836 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46350381963632326, 'Total loss': 0.46350381963632326} | train loss {'Reaction outcome loss': 0.311335307140384, 'Total loss': 0.311335307140384}
2022-11-28 02:31:58,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:58,836 INFO:     Epoch: 76
2022-11-28 02:31:59,585 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44480646875771607, 'Total loss': 0.44480646875771607} | train loss {'Reaction outcome loss': 0.3118354253651154, 'Total loss': 0.3118354253651154}
2022-11-28 02:31:59,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:31:59,585 INFO:     Epoch: 77
2022-11-28 02:32:00,337 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49659949117763474, 'Total loss': 0.49659949117763474} | train loss {'Reaction outcome loss': 0.31542603923909124, 'Total loss': 0.31542603923909124}
2022-11-28 02:32:00,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:00,338 INFO:     Epoch: 78
2022-11-28 02:32:01,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4151084084402431, 'Total loss': 0.4151084084402431} | train loss {'Reaction outcome loss': 0.31698204802289126, 'Total loss': 0.31698204802289126}
2022-11-28 02:32:01,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:01,089 INFO:     Epoch: 79
2022-11-28 02:32:01,842 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45119295303117146, 'Total loss': 0.45119295303117146} | train loss {'Reaction outcome loss': 0.3056120354411823, 'Total loss': 0.3056120354411823}
2022-11-28 02:32:01,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:01,842 INFO:     Epoch: 80
2022-11-28 02:32:02,594 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.408501431515271, 'Total loss': 0.408501431515271} | train loss {'Reaction outcome loss': 0.30962562308676783, 'Total loss': 0.30962562308676783}
2022-11-28 02:32:02,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:02,594 INFO:     Epoch: 81
2022-11-28 02:32:03,341 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47709622098640964, 'Total loss': 0.47709622098640964} | train loss {'Reaction outcome loss': 0.31955356578973515, 'Total loss': 0.31955356578973515}
2022-11-28 02:32:03,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:03,341 INFO:     Epoch: 82
2022-11-28 02:32:04,091 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42134954644875094, 'Total loss': 0.42134954644875094} | train loss {'Reaction outcome loss': 0.31959420262325194, 'Total loss': 0.31959420262325194}
2022-11-28 02:32:04,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:04,091 INFO:     Epoch: 83
2022-11-28 02:32:04,842 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4628139453178102, 'Total loss': 0.4628139453178102} | train loss {'Reaction outcome loss': 0.307501298796025, 'Total loss': 0.307501298796025}
2022-11-28 02:32:04,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:04,843 INFO:     Epoch: 84
2022-11-28 02:32:05,592 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43264391442591493, 'Total loss': 0.43264391442591493} | train loss {'Reaction outcome loss': 0.3070621787900886, 'Total loss': 0.3070621787900886}
2022-11-28 02:32:05,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:05,592 INFO:     Epoch: 85
2022-11-28 02:32:06,340 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.441617761823264, 'Total loss': 0.441617761823264} | train loss {'Reaction outcome loss': 0.31268477343743845, 'Total loss': 0.31268477343743845}
2022-11-28 02:32:06,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:06,340 INFO:     Epoch: 86
2022-11-28 02:32:07,091 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45875508947805926, 'Total loss': 0.45875508947805926} | train loss {'Reaction outcome loss': 0.31207185875504245, 'Total loss': 0.31207185875504245}
2022-11-28 02:32:07,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:07,092 INFO:     Epoch: 87
2022-11-28 02:32:07,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4370974756099961, 'Total loss': 0.4370974756099961} | train loss {'Reaction outcome loss': 0.30162411062948163, 'Total loss': 0.30162411062948163}
2022-11-28 02:32:07,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:07,842 INFO:     Epoch: 88
2022-11-28 02:32:08,591 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43089625442569907, 'Total loss': 0.43089625442569907} | train loss {'Reaction outcome loss': 0.30937598282170875, 'Total loss': 0.30937598282170875}
2022-11-28 02:32:08,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:08,592 INFO:     Epoch: 89
2022-11-28 02:32:09,341 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43916910073973914, 'Total loss': 0.43916910073973914} | train loss {'Reaction outcome loss': 0.3114983021251617, 'Total loss': 0.3114983021251617}
2022-11-28 02:32:09,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:09,341 INFO:     Epoch: 90
2022-11-28 02:32:10,093 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45586388490416785, 'Total loss': 0.45586388490416785} | train loss {'Reaction outcome loss': 0.32117840614650517, 'Total loss': 0.32117840614650517}
2022-11-28 02:32:10,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:10,093 INFO:     Epoch: 91
2022-11-28 02:32:10,844 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42090301283381204, 'Total loss': 0.42090301283381204} | train loss {'Reaction outcome loss': 0.32171810193047407, 'Total loss': 0.32171810193047407}
2022-11-28 02:32:10,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:10,844 INFO:     Epoch: 92
2022-11-28 02:32:11,595 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40748264877633616, 'Total loss': 0.40748264877633616} | train loss {'Reaction outcome loss': 0.3153328198278623, 'Total loss': 0.3153328198278623}
2022-11-28 02:32:11,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:11,595 INFO:     Epoch: 93
2022-11-28 02:32:12,344 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4558562341738831, 'Total loss': 0.4558562341738831} | train loss {'Reaction outcome loss': 0.3083134109056705, 'Total loss': 0.3083134109056705}
2022-11-28 02:32:12,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:12,344 INFO:     Epoch: 94
2022-11-28 02:32:13,094 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4349745623767376, 'Total loss': 0.4349745623767376} | train loss {'Reaction outcome loss': 0.31030146831706645, 'Total loss': 0.31030146831706645}
2022-11-28 02:32:13,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:13,094 INFO:     Epoch: 95
2022-11-28 02:32:13,844 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42329450391910295, 'Total loss': 0.42329450391910295} | train loss {'Reaction outcome loss': 0.3137647285156192, 'Total loss': 0.3137647285156192}
2022-11-28 02:32:13,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:13,844 INFO:     Epoch: 96
2022-11-28 02:32:14,594 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4453064887361093, 'Total loss': 0.4453064887361093} | train loss {'Reaction outcome loss': 0.30508917912600503, 'Total loss': 0.30508917912600503}
2022-11-28 02:32:14,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:14,594 INFO:     Epoch: 97
2022-11-28 02:32:15,344 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4407504295760935, 'Total loss': 0.4407504295760935} | train loss {'Reaction outcome loss': 0.3121937394682919, 'Total loss': 0.3121937394682919}
2022-11-28 02:32:15,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:15,344 INFO:     Epoch: 98
2022-11-28 02:32:16,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4642137610776858, 'Total loss': 0.4642137610776858} | train loss {'Reaction outcome loss': 0.31418569797589896, 'Total loss': 0.31418569797589896}
2022-11-28 02:32:16,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:16,096 INFO:     Epoch: 99
2022-11-28 02:32:16,845 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42923543974757195, 'Total loss': 0.42923543974757195} | train loss {'Reaction outcome loss': 0.31055084294489316, 'Total loss': 0.31055084294489316}
2022-11-28 02:32:16,845 INFO:     Best model found after epoch 48 of 100.
2022-11-28 02:32:16,845 INFO:   Done with stage: TRAINING
2022-11-28 02:32:16,845 INFO:   Starting stage: EVALUATION
2022-11-28 02:32:16,964 INFO:   Done with stage: EVALUATION
2022-11-28 02:32:16,972 INFO:   Leaving out SEQ value Fold_0
2022-11-28 02:32:16,985 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:32:16,985 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:32:17,638 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:32:17,639 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:32:17,706 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:32:17,706 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:32:17,706 INFO:     No hyperparam tuning for this model
2022-11-28 02:32:17,706 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:32:17,707 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:32:17,707 INFO:     None feature selector for col prot
2022-11-28 02:32:17,707 INFO:     None feature selector for col prot
2022-11-28 02:32:17,708 INFO:     None feature selector for col prot
2022-11-28 02:32:17,708 INFO:     None feature selector for col chem
2022-11-28 02:32:17,708 INFO:     None feature selector for col chem
2022-11-28 02:32:17,708 INFO:     None feature selector for col chem
2022-11-28 02:32:17,708 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:32:17,708 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:32:17,710 INFO:     Number of params in model 169741
2022-11-28 02:32:17,713 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:32:17,713 INFO:   Starting stage: TRAINING
2022-11-28 02:32:17,767 INFO:     Val loss before train {'Reaction outcome loss': 0.968789130449295, 'Total loss': 0.968789130449295}
2022-11-28 02:32:17,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:17,768 INFO:     Epoch: 0
2022-11-28 02:32:18,513 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.525466566736048, 'Total loss': 0.525466566736048} | train loss {'Reaction outcome loss': 0.6314663847207058, 'Total loss': 0.6314663847207058}
2022-11-28 02:32:18,513 INFO:     Found new best model at epoch 0
2022-11-28 02:32:18,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:18,514 INFO:     Epoch: 1
2022-11-28 02:32:19,258 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4910228523341092, 'Total loss': 0.4910228523341092} | train loss {'Reaction outcome loss': 0.5033244754862689, 'Total loss': 0.5033244754862689}
2022-11-28 02:32:19,259 INFO:     Found new best model at epoch 1
2022-11-28 02:32:19,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:19,260 INFO:     Epoch: 2
2022-11-28 02:32:20,004 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4527452472936023, 'Total loss': 0.4527452472936023} | train loss {'Reaction outcome loss': 0.4661158515132873, 'Total loss': 0.4661158515132873}
2022-11-28 02:32:20,004 INFO:     Found new best model at epoch 2
2022-11-28 02:32:20,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:20,005 INFO:     Epoch: 3
2022-11-28 02:32:20,750 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43809945339506323, 'Total loss': 0.43809945339506323} | train loss {'Reaction outcome loss': 0.45474255736540203, 'Total loss': 0.45474255736540203}
2022-11-28 02:32:20,750 INFO:     Found new best model at epoch 3
2022-11-28 02:32:20,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:20,751 INFO:     Epoch: 4
2022-11-28 02:32:21,497 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4739386960864067, 'Total loss': 0.4739386960864067} | train loss {'Reaction outcome loss': 0.43374856765031333, 'Total loss': 0.43374856765031333}
2022-11-28 02:32:21,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:21,498 INFO:     Epoch: 5
2022-11-28 02:32:22,242 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4873466688123616, 'Total loss': 0.4873466688123616} | train loss {'Reaction outcome loss': 0.41314362544521144, 'Total loss': 0.41314362544521144}
2022-11-28 02:32:22,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:22,242 INFO:     Epoch: 6
2022-11-28 02:32:22,990 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44775465300137346, 'Total loss': 0.44775465300137346} | train loss {'Reaction outcome loss': 0.3999454081058502, 'Total loss': 0.3999454081058502}
2022-11-28 02:32:22,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:22,990 INFO:     Epoch: 7
2022-11-28 02:32:23,735 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4568579772656614, 'Total loss': 0.4568579772656614} | train loss {'Reaction outcome loss': 0.3966616336105444, 'Total loss': 0.3966616336105444}
2022-11-28 02:32:23,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:23,735 INFO:     Epoch: 8
2022-11-28 02:32:24,481 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4448620897125114, 'Total loss': 0.4448620897125114} | train loss {'Reaction outcome loss': 0.386437580472062, 'Total loss': 0.386437580472062}
2022-11-28 02:32:24,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:24,481 INFO:     Epoch: 9
2022-11-28 02:32:25,226 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4407040002671155, 'Total loss': 0.4407040002671155} | train loss {'Reaction outcome loss': 0.3896232027454897, 'Total loss': 0.3896232027454897}
2022-11-28 02:32:25,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:25,226 INFO:     Epoch: 10
2022-11-28 02:32:25,970 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4663462889465419, 'Total loss': 0.4663462889465419} | train loss {'Reaction outcome loss': 0.3866121224184268, 'Total loss': 0.3866121224184268}
2022-11-28 02:32:25,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:25,970 INFO:     Epoch: 11
2022-11-28 02:32:26,715 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4472032036970962, 'Total loss': 0.4472032036970962} | train loss {'Reaction outcome loss': 0.3880817317347295, 'Total loss': 0.3880817317347295}
2022-11-28 02:32:26,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:26,715 INFO:     Epoch: 12
2022-11-28 02:32:27,460 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4448191858828068, 'Total loss': 0.4448191858828068} | train loss {'Reaction outcome loss': 0.36774280917668634, 'Total loss': 0.36774280917668634}
2022-11-28 02:32:27,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:27,460 INFO:     Epoch: 13
2022-11-28 02:32:28,210 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42304949496280064, 'Total loss': 0.42304949496280064} | train loss {'Reaction outcome loss': 0.3659205834271937, 'Total loss': 0.3659205834271937}
2022-11-28 02:32:28,210 INFO:     Found new best model at epoch 13
2022-11-28 02:32:28,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:28,211 INFO:     Epoch: 14
2022-11-28 02:32:28,955 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45604796368967404, 'Total loss': 0.45604796368967404} | train loss {'Reaction outcome loss': 0.3687771439612636, 'Total loss': 0.3687771439612636}
2022-11-28 02:32:28,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:28,955 INFO:     Epoch: 15
2022-11-28 02:32:29,701 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4678697914562442, 'Total loss': 0.4678697914562442} | train loss {'Reaction outcome loss': 0.3662588329691636, 'Total loss': 0.3662588329691636}
2022-11-28 02:32:29,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:29,701 INFO:     Epoch: 16
2022-11-28 02:32:30,443 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4426231824538924, 'Total loss': 0.4426231824538924} | train loss {'Reaction outcome loss': 0.3624285282454027, 'Total loss': 0.3624285282454027}
2022-11-28 02:32:30,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:30,443 INFO:     Epoch: 17
2022-11-28 02:32:31,192 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42473504082723096, 'Total loss': 0.42473504082723096} | train loss {'Reaction outcome loss': 0.353056165582014, 'Total loss': 0.353056165582014}
2022-11-28 02:32:31,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:31,192 INFO:     Epoch: 18
2022-11-28 02:32:31,937 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42908891375091945, 'Total loss': 0.42908891375091945} | train loss {'Reaction outcome loss': 0.3566151403554297, 'Total loss': 0.3566151403554297}
2022-11-28 02:32:31,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:31,938 INFO:     Epoch: 19
2022-11-28 02:32:32,685 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.490150682289492, 'Total loss': 0.490150682289492} | train loss {'Reaction outcome loss': 0.37210281691155755, 'Total loss': 0.37210281691155755}
2022-11-28 02:32:32,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:32,686 INFO:     Epoch: 20
2022-11-28 02:32:33,431 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4250789589502595, 'Total loss': 0.4250789589502595} | train loss {'Reaction outcome loss': 0.3570656590012886, 'Total loss': 0.3570656590012886}
2022-11-28 02:32:33,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:33,432 INFO:     Epoch: 21
2022-11-28 02:32:34,176 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4311701958491044, 'Total loss': 0.4311701958491044} | train loss {'Reaction outcome loss': 0.344024203755414, 'Total loss': 0.344024203755414}
2022-11-28 02:32:34,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:34,176 INFO:     Epoch: 22
2022-11-28 02:32:34,920 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43908906998959457, 'Total loss': 0.43908906998959457} | train loss {'Reaction outcome loss': 0.34085445145243093, 'Total loss': 0.34085445145243093}
2022-11-28 02:32:34,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:34,920 INFO:     Epoch: 23
2022-11-28 02:32:35,662 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40501404079523956, 'Total loss': 0.40501404079523956} | train loss {'Reaction outcome loss': 0.34545009851697, 'Total loss': 0.34545009851697}
2022-11-28 02:32:35,662 INFO:     Found new best model at epoch 23
2022-11-28 02:32:35,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:35,663 INFO:     Epoch: 24
2022-11-28 02:32:36,410 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41311035864055157, 'Total loss': 0.41311035864055157} | train loss {'Reaction outcome loss': 0.34994591166253997, 'Total loss': 0.34994591166253997}
2022-11-28 02:32:36,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:36,410 INFO:     Epoch: 25
2022-11-28 02:32:37,156 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42893855476921255, 'Total loss': 0.42893855476921255} | train loss {'Reaction outcome loss': 0.33740179735398, 'Total loss': 0.33740179735398}
2022-11-28 02:32:37,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:37,156 INFO:     Epoch: 26
2022-11-28 02:32:37,902 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3970318741419099, 'Total loss': 0.3970318741419099} | train loss {'Reaction outcome loss': 0.36534262729077205, 'Total loss': 0.36534262729077205}
2022-11-28 02:32:37,903 INFO:     Found new best model at epoch 26
2022-11-28 02:32:37,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:37,903 INFO:     Epoch: 27
2022-11-28 02:32:38,651 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4442628937011415, 'Total loss': 0.4442628937011415} | train loss {'Reaction outcome loss': 0.343563566333143, 'Total loss': 0.343563566333143}
2022-11-28 02:32:38,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:38,652 INFO:     Epoch: 28
2022-11-28 02:32:39,395 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4285867258229039, 'Total loss': 0.4285867258229039} | train loss {'Reaction outcome loss': 0.3295095672280441, 'Total loss': 0.3295095672280441}
2022-11-28 02:32:39,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:39,396 INFO:     Epoch: 29
2022-11-28 02:32:40,141 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41947431049563666, 'Total loss': 0.41947431049563666} | train loss {'Reaction outcome loss': 0.3358355261110192, 'Total loss': 0.3358355261110192}
2022-11-28 02:32:40,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:40,142 INFO:     Epoch: 30
2022-11-28 02:32:40,885 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4542767982929945, 'Total loss': 0.4542767982929945} | train loss {'Reaction outcome loss': 0.3318412494562898, 'Total loss': 0.3318412494562898}
2022-11-28 02:32:40,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:40,885 INFO:     Epoch: 31
2022-11-28 02:32:41,635 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4335289526392113, 'Total loss': 0.4335289526392113} | train loss {'Reaction outcome loss': 0.358013284863972, 'Total loss': 0.358013284863972}
2022-11-28 02:32:41,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:41,635 INFO:     Epoch: 32
2022-11-28 02:32:42,384 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4387364001436667, 'Total loss': 0.4387364001436667} | train loss {'Reaction outcome loss': 0.33881493148074376, 'Total loss': 0.33881493148074376}
2022-11-28 02:32:42,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:42,384 INFO:     Epoch: 33
2022-11-28 02:32:43,132 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4737481407143853, 'Total loss': 0.4737481407143853} | train loss {'Reaction outcome loss': 0.3295982425451761, 'Total loss': 0.3295982425451761}
2022-11-28 02:32:43,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:43,132 INFO:     Epoch: 34
2022-11-28 02:32:43,879 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4113830622624267, 'Total loss': 0.4113830622624267} | train loss {'Reaction outcome loss': 0.32589519399440725, 'Total loss': 0.32589519399440725}
2022-11-28 02:32:43,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:43,879 INFO:     Epoch: 35
2022-11-28 02:32:44,628 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4032704991034486, 'Total loss': 0.4032704991034486} | train loss {'Reaction outcome loss': 0.33121517300605774, 'Total loss': 0.33121517300605774}
2022-11-28 02:32:44,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:44,628 INFO:     Epoch: 36
2022-11-28 02:32:45,378 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4544233192097057, 'Total loss': 0.4544233192097057} | train loss {'Reaction outcome loss': 0.3308223145090134, 'Total loss': 0.3308223145090134}
2022-11-28 02:32:45,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:45,378 INFO:     Epoch: 37
2022-11-28 02:32:46,127 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4430376741696488, 'Total loss': 0.4430376741696488} | train loss {'Reaction outcome loss': 0.3313712625790704, 'Total loss': 0.3313712625790704}
2022-11-28 02:32:46,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:46,127 INFO:     Epoch: 38
2022-11-28 02:32:46,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40313443998721515, 'Total loss': 0.40313443998721515} | train loss {'Reaction outcome loss': 0.337860815257196, 'Total loss': 0.337860815257196}
2022-11-28 02:32:46,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:46,869 INFO:     Epoch: 39
2022-11-28 02:32:47,614 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42495495216412976, 'Total loss': 0.42495495216412976} | train loss {'Reaction outcome loss': 0.3228513243709981, 'Total loss': 0.3228513243709981}
2022-11-28 02:32:47,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:47,614 INFO:     Epoch: 40
2022-11-28 02:32:48,359 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43758889592506667, 'Total loss': 0.43758889592506667} | train loss {'Reaction outcome loss': 0.32751413962619025, 'Total loss': 0.32751413962619025}
2022-11-28 02:32:48,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:48,359 INFO:     Epoch: 41
2022-11-28 02:32:49,105 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.418999701061032, 'Total loss': 0.418999701061032} | train loss {'Reaction outcome loss': 0.326292992709016, 'Total loss': 0.326292992709016}
2022-11-28 02:32:49,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:49,105 INFO:     Epoch: 42
2022-11-28 02:32:49,852 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41681903278963134, 'Total loss': 0.41681903278963134} | train loss {'Reaction outcome loss': 0.3106899200241093, 'Total loss': 0.3106899200241093}
2022-11-28 02:32:49,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:49,852 INFO:     Epoch: 43
2022-11-28 02:32:50,601 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43037281778048386, 'Total loss': 0.43037281778048386} | train loss {'Reaction outcome loss': 0.32716916248142, 'Total loss': 0.32716916248142}
2022-11-28 02:32:50,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:50,601 INFO:     Epoch: 44
2022-11-28 02:32:51,351 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42156800543042744, 'Total loss': 0.42156800543042744} | train loss {'Reaction outcome loss': 0.3377777470600026, 'Total loss': 0.3377777470600026}
2022-11-28 02:32:51,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:51,351 INFO:     Epoch: 45
2022-11-28 02:32:52,107 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4589492925866084, 'Total loss': 0.4589492925866084} | train loss {'Reaction outcome loss': 0.3179080293764575, 'Total loss': 0.3179080293764575}
2022-11-28 02:32:52,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:52,107 INFO:     Epoch: 46
2022-11-28 02:32:52,861 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43398577347397804, 'Total loss': 0.43398577347397804} | train loss {'Reaction outcome loss': 0.31844266193357074, 'Total loss': 0.31844266193357074}
2022-11-28 02:32:52,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:52,861 INFO:     Epoch: 47
2022-11-28 02:32:53,612 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4307038150727749, 'Total loss': 0.4307038150727749} | train loss {'Reaction outcome loss': 0.31362617665879156, 'Total loss': 0.31362617665879156}
2022-11-28 02:32:53,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:53,612 INFO:     Epoch: 48
2022-11-28 02:32:54,365 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4185958008535884, 'Total loss': 0.4185958008535884} | train loss {'Reaction outcome loss': 0.3100533908919284, 'Total loss': 0.3100533908919284}
2022-11-28 02:32:54,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:54,365 INFO:     Epoch: 49
2022-11-28 02:32:55,115 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44242217764258385, 'Total loss': 0.44242217764258385} | train loss {'Reaction outcome loss': 0.33748783460754134, 'Total loss': 0.33748783460754134}
2022-11-28 02:32:55,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:55,115 INFO:     Epoch: 50
2022-11-28 02:32:55,866 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44780827804722567, 'Total loss': 0.44780827804722567} | train loss {'Reaction outcome loss': 0.3413835990578238, 'Total loss': 0.3413835990578238}
2022-11-28 02:32:55,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:55,867 INFO:     Epoch: 51
2022-11-28 02:32:56,618 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3995501387187026, 'Total loss': 0.3995501387187026} | train loss {'Reaction outcome loss': 0.3304706147988798, 'Total loss': 0.3304706147988798}
2022-11-28 02:32:56,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:56,618 INFO:     Epoch: 52
2022-11-28 02:32:57,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4210521639748053, 'Total loss': 0.4210521639748053} | train loss {'Reaction outcome loss': 0.32540706194148245, 'Total loss': 0.32540706194148245}
2022-11-28 02:32:57,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:57,367 INFO:     Epoch: 53
2022-11-28 02:32:58,120 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44647015258669853, 'Total loss': 0.44647015258669853} | train loss {'Reaction outcome loss': 0.312676594143937, 'Total loss': 0.312676594143937}
2022-11-28 02:32:58,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:58,120 INFO:     Epoch: 54
2022-11-28 02:32:58,871 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4101389086043293, 'Total loss': 0.4101389086043293} | train loss {'Reaction outcome loss': 0.32304521319776897, 'Total loss': 0.32304521319776897}
2022-11-28 02:32:58,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:58,871 INFO:     Epoch: 55
2022-11-28 02:32:59,626 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4144919646734541, 'Total loss': 0.4144919646734541} | train loss {'Reaction outcome loss': 0.312924629377073, 'Total loss': 0.312924629377073}
2022-11-28 02:32:59,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:32:59,626 INFO:     Epoch: 56
2022-11-28 02:33:00,379 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4614034281535582, 'Total loss': 0.4614034281535582} | train loss {'Reaction outcome loss': 0.30512088314000413, 'Total loss': 0.30512088314000413}
2022-11-28 02:33:00,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:00,379 INFO:     Epoch: 57
2022-11-28 02:33:01,127 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41526014848866244, 'Total loss': 0.41526014848866244} | train loss {'Reaction outcome loss': 0.3280075749828714, 'Total loss': 0.3280075749828714}
2022-11-28 02:33:01,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:01,127 INFO:     Epoch: 58
2022-11-28 02:33:01,877 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46927345442500984, 'Total loss': 0.46927345442500984} | train loss {'Reaction outcome loss': 0.31455377415425867, 'Total loss': 0.31455377415425867}
2022-11-28 02:33:01,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:01,878 INFO:     Epoch: 59
2022-11-28 02:33:02,627 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43114003471352835, 'Total loss': 0.43114003471352835} | train loss {'Reaction outcome loss': 0.3291427373230035, 'Total loss': 0.3291427373230035}
2022-11-28 02:33:02,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:02,628 INFO:     Epoch: 60
2022-11-28 02:33:03,380 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43170071190053766, 'Total loss': 0.43170071190053766} | train loss {'Reaction outcome loss': 0.31314939451271945, 'Total loss': 0.31314939451271945}
2022-11-28 02:33:03,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:03,381 INFO:     Epoch: 61
2022-11-28 02:33:04,131 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4392322511835532, 'Total loss': 0.4392322511835532} | train loss {'Reaction outcome loss': 0.30970286182127893, 'Total loss': 0.30970286182127893}
2022-11-28 02:33:04,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:04,131 INFO:     Epoch: 62
2022-11-28 02:33:04,882 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44068734923546965, 'Total loss': 0.44068734923546965} | train loss {'Reaction outcome loss': 0.30870994431800197, 'Total loss': 0.30870994431800197}
2022-11-28 02:33:04,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:04,882 INFO:     Epoch: 63
2022-11-28 02:33:05,631 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41588766466487537, 'Total loss': 0.41588766466487537} | train loss {'Reaction outcome loss': 0.31659572450858864, 'Total loss': 0.31659572450858864}
2022-11-28 02:33:05,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:05,631 INFO:     Epoch: 64
2022-11-28 02:33:06,378 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4301418787376447, 'Total loss': 0.4301418787376447} | train loss {'Reaction outcome loss': 0.32914107359251993, 'Total loss': 0.32914107359251993}
2022-11-28 02:33:06,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:06,379 INFO:     Epoch: 65
2022-11-28 02:33:07,125 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4466789283535697, 'Total loss': 0.4466789283535697} | train loss {'Reaction outcome loss': 0.31552555500284624, 'Total loss': 0.31552555500284624}
2022-11-28 02:33:07,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:07,125 INFO:     Epoch: 66
2022-11-28 02:33:07,876 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49241394617340783, 'Total loss': 0.49241394617340783} | train loss {'Reaction outcome loss': 0.30268972347441475, 'Total loss': 0.30268972347441475}
2022-11-28 02:33:07,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:07,877 INFO:     Epoch: 67
2022-11-28 02:33:08,631 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44097032194787805, 'Total loss': 0.44097032194787805} | train loss {'Reaction outcome loss': 0.3240491108976395, 'Total loss': 0.3240491108976395}
2022-11-28 02:33:08,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:08,631 INFO:     Epoch: 68
2022-11-28 02:33:09,377 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.430053342811086, 'Total loss': 0.430053342811086} | train loss {'Reaction outcome loss': 0.3137069025382339, 'Total loss': 0.3137069025382339}
2022-11-28 02:33:09,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:09,377 INFO:     Epoch: 69
2022-11-28 02:33:10,124 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42889937589114363, 'Total loss': 0.42889937589114363} | train loss {'Reaction outcome loss': 0.3233882296634348, 'Total loss': 0.3233882296634348}
2022-11-28 02:33:10,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:10,125 INFO:     Epoch: 70
2022-11-28 02:33:10,873 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44140434078872204, 'Total loss': 0.44140434078872204} | train loss {'Reaction outcome loss': 0.31084989700541804, 'Total loss': 0.31084989700541804}
2022-11-28 02:33:10,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:10,873 INFO:     Epoch: 71
2022-11-28 02:33:11,620 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4312250302596526, 'Total loss': 0.4312250302596526} | train loss {'Reaction outcome loss': 0.30748363509387727, 'Total loss': 0.30748363509387727}
2022-11-28 02:33:11,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:11,621 INFO:     Epoch: 72
2022-11-28 02:33:12,363 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40827384421771223, 'Total loss': 0.40827384421771223} | train loss {'Reaction outcome loss': 0.3074760868059479, 'Total loss': 0.3074760868059479}
2022-11-28 02:33:12,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:12,363 INFO:     Epoch: 73
2022-11-28 02:33:13,110 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.441414166580547, 'Total loss': 0.441414166580547} | train loss {'Reaction outcome loss': 0.3059988070264278, 'Total loss': 0.3059988070264278}
2022-11-28 02:33:13,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:13,110 INFO:     Epoch: 74
2022-11-28 02:33:13,856 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4310636224055832, 'Total loss': 0.4310636224055832} | train loss {'Reaction outcome loss': 0.31650781740061185, 'Total loss': 0.31650781740061185}
2022-11-28 02:33:13,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:13,856 INFO:     Epoch: 75
2022-11-28 02:33:14,602 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4186212220652537, 'Total loss': 0.4186212220652537} | train loss {'Reaction outcome loss': 0.3063978518732646, 'Total loss': 0.3063978518732646}
2022-11-28 02:33:14,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:14,602 INFO:     Epoch: 76
2022-11-28 02:33:15,351 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44879296235740185, 'Total loss': 0.44879296235740185} | train loss {'Reaction outcome loss': 0.32315063009015943, 'Total loss': 0.32315063009015943}
2022-11-28 02:33:15,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:15,351 INFO:     Epoch: 77
2022-11-28 02:33:16,105 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4295659634200009, 'Total loss': 0.4295659634200009} | train loss {'Reaction outcome loss': 0.31293253430428347, 'Total loss': 0.31293253430428347}
2022-11-28 02:33:16,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:16,106 INFO:     Epoch: 78
2022-11-28 02:33:16,862 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4645036303184249, 'Total loss': 0.4645036303184249} | train loss {'Reaction outcome loss': 0.3182670386274334, 'Total loss': 0.3182670386274334}
2022-11-28 02:33:16,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:16,863 INFO:     Epoch: 79
2022-11-28 02:33:17,622 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4098768882792104, 'Total loss': 0.4098768882792104} | train loss {'Reaction outcome loss': 0.3247103263069744, 'Total loss': 0.3247103263069744}
2022-11-28 02:33:17,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:17,622 INFO:     Epoch: 80
2022-11-28 02:33:18,381 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4271722121841528, 'Total loss': 0.4271722121841528} | train loss {'Reaction outcome loss': 0.3113555845461394, 'Total loss': 0.3113555845461394}
2022-11-28 02:33:18,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:18,381 INFO:     Epoch: 81
2022-11-28 02:33:19,141 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41127533550289547, 'Total loss': 0.41127533550289547} | train loss {'Reaction outcome loss': 0.3222706977293076, 'Total loss': 0.3222706977293076}
2022-11-28 02:33:19,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:19,142 INFO:     Epoch: 82
2022-11-28 02:33:19,902 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4296574904160066, 'Total loss': 0.4296574904160066} | train loss {'Reaction outcome loss': 0.3107249704359273, 'Total loss': 0.3107249704359273}
2022-11-28 02:33:19,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:19,902 INFO:     Epoch: 83
2022-11-28 02:33:20,662 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4389408499171788, 'Total loss': 0.4389408499171788} | train loss {'Reaction outcome loss': 0.30592770371510675, 'Total loss': 0.30592770371510675}
2022-11-28 02:33:20,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:20,662 INFO:     Epoch: 84
2022-11-28 02:33:21,425 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46388376368717715, 'Total loss': 0.46388376368717715} | train loss {'Reaction outcome loss': 0.3104142687219357, 'Total loss': 0.3104142687219357}
2022-11-28 02:33:21,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:21,425 INFO:     Epoch: 85
2022-11-28 02:33:22,187 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40886222435669467, 'Total loss': 0.40886222435669467} | train loss {'Reaction outcome loss': 0.3202460759323136, 'Total loss': 0.3202460759323136}
2022-11-28 02:33:22,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:22,188 INFO:     Epoch: 86
2022-11-28 02:33:22,948 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4314135600897399, 'Total loss': 0.4314135600897399} | train loss {'Reaction outcome loss': 0.30663002857010857, 'Total loss': 0.30663002857010857}
2022-11-28 02:33:22,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:22,948 INFO:     Epoch: 87
2022-11-28 02:33:23,709 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4226477447558533, 'Total loss': 0.4226477447558533} | train loss {'Reaction outcome loss': 0.30516449393712075, 'Total loss': 0.30516449393712075}
2022-11-28 02:33:23,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:23,709 INFO:     Epoch: 88
2022-11-28 02:33:24,468 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45389415526931937, 'Total loss': 0.45389415526931937} | train loss {'Reaction outcome loss': 0.30943440997347177, 'Total loss': 0.30943440997347177}
2022-11-28 02:33:24,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:24,468 INFO:     Epoch: 89
2022-11-28 02:33:25,228 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4493051841855049, 'Total loss': 0.4493051841855049} | train loss {'Reaction outcome loss': 0.3239341292378063, 'Total loss': 0.3239341292378063}
2022-11-28 02:33:25,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:25,228 INFO:     Epoch: 90
2022-11-28 02:33:25,991 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4163127680393783, 'Total loss': 0.4163127680393783} | train loss {'Reaction outcome loss': 0.30292051276456006, 'Total loss': 0.30292051276456006}
2022-11-28 02:33:25,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:25,991 INFO:     Epoch: 91
2022-11-28 02:33:26,750 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4319241453300823, 'Total loss': 0.4319241453300823} | train loss {'Reaction outcome loss': 0.3127946593621482, 'Total loss': 0.3127946593621482}
2022-11-28 02:33:26,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:26,750 INFO:     Epoch: 92
2022-11-28 02:33:27,511 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4238036190244285, 'Total loss': 0.4238036190244285} | train loss {'Reaction outcome loss': 0.325685223918936, 'Total loss': 0.325685223918936}
2022-11-28 02:33:27,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:27,511 INFO:     Epoch: 93
2022-11-28 02:33:28,271 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4550155485895547, 'Total loss': 0.4550155485895547} | train loss {'Reaction outcome loss': 0.31236683776383456, 'Total loss': 0.31236683776383456}
2022-11-28 02:33:28,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:28,271 INFO:     Epoch: 94
2022-11-28 02:33:29,031 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4654136071489616, 'Total loss': 0.4654136071489616} | train loss {'Reaction outcome loss': 0.31062347107088034, 'Total loss': 0.31062347107088034}
2022-11-28 02:33:29,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:29,031 INFO:     Epoch: 95
2022-11-28 02:33:29,792 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4413900544697588, 'Total loss': 0.4413900544697588} | train loss {'Reaction outcome loss': 0.31094640171012056, 'Total loss': 0.31094640171012056}
2022-11-28 02:33:29,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:29,792 INFO:     Epoch: 96
2022-11-28 02:33:30,552 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42303049530495296, 'Total loss': 0.42303049530495296} | train loss {'Reaction outcome loss': 0.3002102364529573, 'Total loss': 0.3002102364529573}
2022-11-28 02:33:30,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:30,552 INFO:     Epoch: 97
2022-11-28 02:33:31,311 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46524336629293184, 'Total loss': 0.46524336629293184} | train loss {'Reaction outcome loss': 0.3036745670185564, 'Total loss': 0.3036745670185564}
2022-11-28 02:33:31,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:31,311 INFO:     Epoch: 98
2022-11-28 02:33:32,071 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44086582349105313, 'Total loss': 0.44086582349105313} | train loss {'Reaction outcome loss': 0.3034436291136481, 'Total loss': 0.3034436291136481}
2022-11-28 02:33:32,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:32,071 INFO:     Epoch: 99
2022-11-28 02:33:32,832 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41809794611551543, 'Total loss': 0.41809794611551543} | train loss {'Reaction outcome loss': 0.30871901696223597, 'Total loss': 0.30871901696223597}
2022-11-28 02:33:32,832 INFO:     Best model found after epoch 27 of 100.
2022-11-28 02:33:32,833 INFO:   Done with stage: TRAINING
2022-11-28 02:33:32,833 INFO:   Starting stage: EVALUATION
2022-11-28 02:33:32,957 INFO:   Done with stage: EVALUATION
2022-11-28 02:33:32,958 INFO:   Leaving out SEQ value Fold_1
2022-11-28 02:33:32,970 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 02:33:32,970 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:33:33,599 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:33:33,599 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:33:33,666 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:33:33,666 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:33:33,666 INFO:     No hyperparam tuning for this model
2022-11-28 02:33:33,666 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:33:33,666 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:33:33,667 INFO:     None feature selector for col prot
2022-11-28 02:33:33,667 INFO:     None feature selector for col prot
2022-11-28 02:33:33,667 INFO:     None feature selector for col prot
2022-11-28 02:33:33,667 INFO:     None feature selector for col chem
2022-11-28 02:33:33,667 INFO:     None feature selector for col chem
2022-11-28 02:33:33,668 INFO:     None feature selector for col chem
2022-11-28 02:33:33,668 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:33:33,668 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:33:33,669 INFO:     Number of params in model 169741
2022-11-28 02:33:33,672 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:33:33,672 INFO:   Starting stage: TRAINING
2022-11-28 02:33:33,724 INFO:     Val loss before train {'Reaction outcome loss': 1.0507165872773458, 'Total loss': 1.0507165872773458}
2022-11-28 02:33:33,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:33,725 INFO:     Epoch: 0
2022-11-28 02:33:34,475 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6226230582525564, 'Total loss': 0.6226230582525564} | train loss {'Reaction outcome loss': 0.6390379651338475, 'Total loss': 0.6390379651338475}
2022-11-28 02:33:34,476 INFO:     Found new best model at epoch 0
2022-11-28 02:33:34,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:34,477 INFO:     Epoch: 1
2022-11-28 02:33:35,226 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5177586123693821, 'Total loss': 0.5177586123693821} | train loss {'Reaction outcome loss': 0.4975023270266537, 'Total loss': 0.4975023270266537}
2022-11-28 02:33:35,226 INFO:     Found new best model at epoch 1
2022-11-28 02:33:35,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:35,227 INFO:     Epoch: 2
2022-11-28 02:33:35,974 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4907035113767136, 'Total loss': 0.4907035113767136} | train loss {'Reaction outcome loss': 0.46023067930107747, 'Total loss': 0.46023067930107747}
2022-11-28 02:33:35,974 INFO:     Found new best model at epoch 2
2022-11-28 02:33:35,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:35,975 INFO:     Epoch: 3
2022-11-28 02:33:36,722 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5028210268464199, 'Total loss': 0.5028210268464199} | train loss {'Reaction outcome loss': 0.4357012643980882, 'Total loss': 0.4357012643980882}
2022-11-28 02:33:36,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:36,723 INFO:     Epoch: 4
2022-11-28 02:33:37,472 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48164293932360275, 'Total loss': 0.48164293932360275} | train loss {'Reaction outcome loss': 0.42396819156138493, 'Total loss': 0.42396819156138493}
2022-11-28 02:33:37,472 INFO:     Found new best model at epoch 4
2022-11-28 02:33:37,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:37,473 INFO:     Epoch: 5
2022-11-28 02:33:38,224 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5095068833162618, 'Total loss': 0.5095068833162618} | train loss {'Reaction outcome loss': 0.4077364821370246, 'Total loss': 0.4077364821370246}
2022-11-28 02:33:38,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:38,224 INFO:     Epoch: 6
2022-11-28 02:33:38,975 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46647582636323087, 'Total loss': 0.46647582636323087} | train loss {'Reaction outcome loss': 0.40400991018539595, 'Total loss': 0.40400991018539595}
2022-11-28 02:33:38,975 INFO:     Found new best model at epoch 6
2022-11-28 02:33:38,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:38,976 INFO:     Epoch: 7
2022-11-28 02:33:39,726 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.503904506910679, 'Total loss': 0.503904506910679} | train loss {'Reaction outcome loss': 0.39061895607675545, 'Total loss': 0.39061895607675545}
2022-11-28 02:33:39,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:39,726 INFO:     Epoch: 8
2022-11-28 02:33:40,473 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46183311662008597, 'Total loss': 0.46183311662008597} | train loss {'Reaction outcome loss': 0.39420212707156504, 'Total loss': 0.39420212707156504}
2022-11-28 02:33:40,473 INFO:     Found new best model at epoch 8
2022-11-28 02:33:40,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:40,475 INFO:     Epoch: 9
2022-11-28 02:33:41,224 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47478839581788973, 'Total loss': 0.47478839581788973} | train loss {'Reaction outcome loss': 0.3747513939017131, 'Total loss': 0.3747513939017131}
2022-11-28 02:33:41,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:41,224 INFO:     Epoch: 10
2022-11-28 02:33:41,973 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4375396679307139, 'Total loss': 0.4375396679307139} | train loss {'Reaction outcome loss': 0.3723174435672937, 'Total loss': 0.3723174435672937}
2022-11-28 02:33:41,973 INFO:     Found new best model at epoch 10
2022-11-28 02:33:41,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:41,974 INFO:     Epoch: 11
2022-11-28 02:33:42,721 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4624713323144026, 'Total loss': 0.4624713323144026} | train loss {'Reaction outcome loss': 0.3654925215667413, 'Total loss': 0.3654925215667413}
2022-11-28 02:33:42,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:42,721 INFO:     Epoch: 12
2022-11-28 02:33:43,470 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45494987625022265, 'Total loss': 0.45494987625022265} | train loss {'Reaction outcome loss': 0.368268273617505, 'Total loss': 0.368268273617505}
2022-11-28 02:33:43,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:43,471 INFO:     Epoch: 13
2022-11-28 02:33:44,222 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4505286889020787, 'Total loss': 0.4505286889020787} | train loss {'Reaction outcome loss': 0.36062875776379194, 'Total loss': 0.36062875776379194}
2022-11-28 02:33:44,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:44,223 INFO:     Epoch: 14
2022-11-28 02:33:44,970 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4642110678345658, 'Total loss': 0.4642110678345658} | train loss {'Reaction outcome loss': 0.35514501767393986, 'Total loss': 0.35514501767393986}
2022-11-28 02:33:44,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:44,970 INFO:     Epoch: 15
2022-11-28 02:33:45,719 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44624413012765174, 'Total loss': 0.44624413012765174} | train loss {'Reaction outcome loss': 0.355670186257902, 'Total loss': 0.355670186257902}
2022-11-28 02:33:45,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:45,719 INFO:     Epoch: 16
2022-11-28 02:33:46,468 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45773418109084285, 'Total loss': 0.45773418109084285} | train loss {'Reaction outcome loss': 0.3531848687483113, 'Total loss': 0.3531848687483113}
2022-11-28 02:33:46,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:46,468 INFO:     Epoch: 17
2022-11-28 02:33:47,213 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44285004014192625, 'Total loss': 0.44285004014192625} | train loss {'Reaction outcome loss': 0.3508910133269589, 'Total loss': 0.3508910133269589}
2022-11-28 02:33:47,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:47,213 INFO:     Epoch: 18
2022-11-28 02:33:47,959 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4488799007132996, 'Total loss': 0.4488799007132996} | train loss {'Reaction outcome loss': 0.3487960291957414, 'Total loss': 0.3487960291957414}
2022-11-28 02:33:47,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:47,959 INFO:     Epoch: 19
2022-11-28 02:33:48,705 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.469550606816314, 'Total loss': 0.469550606816314} | train loss {'Reaction outcome loss': 0.3444243610947711, 'Total loss': 0.3444243610947711}
2022-11-28 02:33:48,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:48,705 INFO:     Epoch: 20
2022-11-28 02:33:49,451 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4674926466026971, 'Total loss': 0.4674926466026971} | train loss {'Reaction outcome loss': 0.34688493474520776, 'Total loss': 0.34688493474520776}
2022-11-28 02:33:49,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:49,452 INFO:     Epoch: 21
2022-11-28 02:33:50,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4494874040747798, 'Total loss': 0.4494874040747798} | train loss {'Reaction outcome loss': 0.33750705273798953, 'Total loss': 0.33750705273798953}
2022-11-28 02:33:50,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:50,201 INFO:     Epoch: 22
2022-11-28 02:33:50,947 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44686596961908565, 'Total loss': 0.44686596961908565} | train loss {'Reaction outcome loss': 0.3442715842108177, 'Total loss': 0.3442715842108177}
2022-11-28 02:33:50,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:50,947 INFO:     Epoch: 23
2022-11-28 02:33:51,694 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45014098841090533, 'Total loss': 0.45014098841090533} | train loss {'Reaction outcome loss': 0.34480309431199674, 'Total loss': 0.34480309431199674}
2022-11-28 02:33:51,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:51,694 INFO:     Epoch: 24
2022-11-28 02:33:52,442 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4367930528729461, 'Total loss': 0.4367930528729461} | train loss {'Reaction outcome loss': 0.33741300197417845, 'Total loss': 0.33741300197417845}
2022-11-28 02:33:52,442 INFO:     Found new best model at epoch 24
2022-11-28 02:33:52,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:52,443 INFO:     Epoch: 25
2022-11-28 02:33:53,191 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43837391013322874, 'Total loss': 0.43837391013322874} | train loss {'Reaction outcome loss': 0.33644511964586044, 'Total loss': 0.33644511964586044}
2022-11-28 02:33:53,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:53,192 INFO:     Epoch: 26
2022-11-28 02:33:53,940 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4425706135672192, 'Total loss': 0.4425706135672192} | train loss {'Reaction outcome loss': 0.3421740835156951, 'Total loss': 0.3421740835156951}
2022-11-28 02:33:53,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:53,940 INFO:     Epoch: 27
2022-11-28 02:33:54,687 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4575908485540124, 'Total loss': 0.4575908485540124} | train loss {'Reaction outcome loss': 0.3382597776290811, 'Total loss': 0.3382597776290811}
2022-11-28 02:33:54,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:54,688 INFO:     Epoch: 28
2022-11-28 02:33:55,436 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46896478256513907, 'Total loss': 0.46896478256513907} | train loss {'Reaction outcome loss': 0.3313987993715722, 'Total loss': 0.3313987993715722}
2022-11-28 02:33:55,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:55,437 INFO:     Epoch: 29
2022-11-28 02:33:56,185 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45438338850819787, 'Total loss': 0.45438338850819787} | train loss {'Reaction outcome loss': 0.33345149156978593, 'Total loss': 0.33345149156978593}
2022-11-28 02:33:56,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:56,185 INFO:     Epoch: 30
2022-11-28 02:33:56,934 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4572692873866059, 'Total loss': 0.4572692873866059} | train loss {'Reaction outcome loss': 0.3278242194787465, 'Total loss': 0.3278242194787465}
2022-11-28 02:33:56,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:56,934 INFO:     Epoch: 31
2022-11-28 02:33:57,683 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4456703049498935, 'Total loss': 0.4456703049498935} | train loss {'Reaction outcome loss': 0.33286809160876174, 'Total loss': 0.33286809160876174}
2022-11-28 02:33:57,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:57,684 INFO:     Epoch: 32
2022-11-28 02:33:58,432 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.488289674354154, 'Total loss': 0.488289674354154} | train loss {'Reaction outcome loss': 0.32151875531477203, 'Total loss': 0.32151875531477203}
2022-11-28 02:33:58,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:58,433 INFO:     Epoch: 33
2022-11-28 02:33:59,191 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47241523342077124, 'Total loss': 0.47241523342077124} | train loss {'Reaction outcome loss': 0.3292847815671085, 'Total loss': 0.3292847815671085}
2022-11-28 02:33:59,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:59,191 INFO:     Epoch: 34
2022-11-28 02:33:59,943 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47998228322627934, 'Total loss': 0.47998228322627934} | train loss {'Reaction outcome loss': 0.3345272659090321, 'Total loss': 0.3345272659090321}
2022-11-28 02:33:59,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:33:59,944 INFO:     Epoch: 35
2022-11-28 02:34:00,695 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48075889328191446, 'Total loss': 0.48075889328191446} | train loss {'Reaction outcome loss': 0.31720904647200193, 'Total loss': 0.31720904647200193}
2022-11-28 02:34:00,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:00,695 INFO:     Epoch: 36
2022-11-28 02:34:01,444 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4736262729694677, 'Total loss': 0.4736262729694677} | train loss {'Reaction outcome loss': 0.32815576171494804, 'Total loss': 0.32815576171494804}
2022-11-28 02:34:01,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:01,444 INFO:     Epoch: 37
2022-11-28 02:34:02,190 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4312665951113368, 'Total loss': 0.4312665951113368} | train loss {'Reaction outcome loss': 0.3310445161084089, 'Total loss': 0.3310445161084089}
2022-11-28 02:34:02,190 INFO:     Found new best model at epoch 37
2022-11-28 02:34:02,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:02,191 INFO:     Epoch: 38
2022-11-28 02:34:02,941 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4633066536382187, 'Total loss': 0.4633066536382187} | train loss {'Reaction outcome loss': 0.3257148106095722, 'Total loss': 0.3257148106095722}
2022-11-28 02:34:02,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:02,941 INFO:     Epoch: 39
2022-11-28 02:34:03,692 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4523652126622755, 'Total loss': 0.4523652126622755} | train loss {'Reaction outcome loss': 0.3264705884910415, 'Total loss': 0.3264705884910415}
2022-11-28 02:34:03,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:03,692 INFO:     Epoch: 40
2022-11-28 02:34:04,441 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44943065975987634, 'Total loss': 0.44943065975987634} | train loss {'Reaction outcome loss': 0.31781996686946706, 'Total loss': 0.31781996686946706}
2022-11-28 02:34:04,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:04,441 INFO:     Epoch: 41
2022-11-28 02:34:05,187 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4593617136395255, 'Total loss': 0.4593617136395255} | train loss {'Reaction outcome loss': 0.3139100717265665, 'Total loss': 0.3139100717265665}
2022-11-28 02:34:05,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:05,188 INFO:     Epoch: 42
2022-11-28 02:34:05,938 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46340351395828777, 'Total loss': 0.46340351395828777} | train loss {'Reaction outcome loss': 0.3205148759968732, 'Total loss': 0.3205148759968732}
2022-11-28 02:34:05,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:05,938 INFO:     Epoch: 43
2022-11-28 02:34:06,689 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44930334250594295, 'Total loss': 0.44930334250594295} | train loss {'Reaction outcome loss': 0.3211384679462929, 'Total loss': 0.3211384679462929}
2022-11-28 02:34:06,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:06,689 INFO:     Epoch: 44
2022-11-28 02:34:07,440 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47710136064263275, 'Total loss': 0.47710136064263275} | train loss {'Reaction outcome loss': 0.32600071612331605, 'Total loss': 0.32600071612331605}
2022-11-28 02:34:07,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:07,440 INFO:     Epoch: 45
2022-11-28 02:34:08,187 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48114443899587145, 'Total loss': 0.48114443899587145} | train loss {'Reaction outcome loss': 0.31064065925991585, 'Total loss': 0.31064065925991585}
2022-11-28 02:34:08,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:08,187 INFO:     Epoch: 46
2022-11-28 02:34:08,939 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.475154877055523, 'Total loss': 0.475154877055523} | train loss {'Reaction outcome loss': 0.3176695106880655, 'Total loss': 0.3176695106880655}
2022-11-28 02:34:08,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:08,939 INFO:     Epoch: 47
2022-11-28 02:34:09,687 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4489395933788876, 'Total loss': 0.4489395933788876} | train loss {'Reaction outcome loss': 0.31914846332352836, 'Total loss': 0.31914846332352836}
2022-11-28 02:34:09,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:09,688 INFO:     Epoch: 48
2022-11-28 02:34:10,437 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44074749184209244, 'Total loss': 0.44074749184209244} | train loss {'Reaction outcome loss': 0.3226578313198109, 'Total loss': 0.3226578313198109}
2022-11-28 02:34:10,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:10,437 INFO:     Epoch: 49
2022-11-28 02:34:11,183 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49506681239189104, 'Total loss': 0.49506681239189104} | train loss {'Reaction outcome loss': 0.3209336694989185, 'Total loss': 0.3209336694989185}
2022-11-28 02:34:11,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:11,183 INFO:     Epoch: 50
2022-11-28 02:34:11,929 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4851329077121823, 'Total loss': 0.4851329077121823} | train loss {'Reaction outcome loss': 0.3186681796739131, 'Total loss': 0.3186681796739131}
2022-11-28 02:34:11,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:11,930 INFO:     Epoch: 51
2022-11-28 02:34:12,679 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.456294774316078, 'Total loss': 0.456294774316078} | train loss {'Reaction outcome loss': 0.3137938193670271, 'Total loss': 0.3137938193670271}
2022-11-28 02:34:12,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:12,679 INFO:     Epoch: 52
2022-11-28 02:34:13,429 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4311410107238348, 'Total loss': 0.4311410107238348} | train loss {'Reaction outcome loss': 0.3186216508900678, 'Total loss': 0.3186216508900678}
2022-11-28 02:34:13,429 INFO:     Found new best model at epoch 52
2022-11-28 02:34:13,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:13,430 INFO:     Epoch: 53
2022-11-28 02:34:14,178 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4513372259084569, 'Total loss': 0.4513372259084569} | train loss {'Reaction outcome loss': 0.3177752468903614, 'Total loss': 0.3177752468903614}
2022-11-28 02:34:14,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:14,179 INFO:     Epoch: 54
2022-11-28 02:34:14,932 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4574943533123926, 'Total loss': 0.4574943533123926} | train loss {'Reaction outcome loss': 0.3195719626950629, 'Total loss': 0.3195719626950629}
2022-11-28 02:34:14,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:14,932 INFO:     Epoch: 55
2022-11-28 02:34:15,684 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4331481385716172, 'Total loss': 0.4331481385716172} | train loss {'Reaction outcome loss': 0.31672976903402755, 'Total loss': 0.31672976903402755}
2022-11-28 02:34:15,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:15,684 INFO:     Epoch: 56
2022-11-28 02:34:16,434 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45764295410278233, 'Total loss': 0.45764295410278233} | train loss {'Reaction outcome loss': 0.30792934545641576, 'Total loss': 0.30792934545641576}
2022-11-28 02:34:16,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:16,434 INFO:     Epoch: 57
2022-11-28 02:34:17,183 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4698775012132733, 'Total loss': 0.4698775012132733} | train loss {'Reaction outcome loss': 0.3177593488384176, 'Total loss': 0.3177593488384176}
2022-11-28 02:34:17,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:17,183 INFO:     Epoch: 58
2022-11-28 02:34:17,931 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4539476584556491, 'Total loss': 0.4539476584556491} | train loss {'Reaction outcome loss': 0.31218275568858095, 'Total loss': 0.31218275568858095}
2022-11-28 02:34:17,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:17,932 INFO:     Epoch: 59
2022-11-28 02:34:18,688 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.461664441713067, 'Total loss': 0.461664441713067} | train loss {'Reaction outcome loss': 0.3142734155549434, 'Total loss': 0.3142734155549434}
2022-11-28 02:34:18,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:18,689 INFO:     Epoch: 60
2022-11-28 02:34:19,438 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46015552517979647, 'Total loss': 0.46015552517979647} | train loss {'Reaction outcome loss': 0.3103972614317397, 'Total loss': 0.3103972614317397}
2022-11-28 02:34:19,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:19,438 INFO:     Epoch: 61
2022-11-28 02:34:20,191 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4628776384647502, 'Total loss': 0.4628776384647502} | train loss {'Reaction outcome loss': 0.31045323090604793, 'Total loss': 0.31045323090604793}
2022-11-28 02:34:20,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:20,192 INFO:     Epoch: 62
2022-11-28 02:34:20,941 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47180986854919166, 'Total loss': 0.47180986854919166} | train loss {'Reaction outcome loss': 0.33103635962362643, 'Total loss': 0.33103635962362643}
2022-11-28 02:34:20,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:20,941 INFO:     Epoch: 63
2022-11-28 02:34:21,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48490425164616385, 'Total loss': 0.48490425164616385} | train loss {'Reaction outcome loss': 0.31462852101880334, 'Total loss': 0.31462852101880334}
2022-11-28 02:34:21,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:21,688 INFO:     Epoch: 64
2022-11-28 02:34:22,436 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4518460773451384, 'Total loss': 0.4518460773451384} | train loss {'Reaction outcome loss': 0.3033994076765859, 'Total loss': 0.3033994076765859}
2022-11-28 02:34:22,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:22,436 INFO:     Epoch: 65
2022-11-28 02:34:23,183 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4745558243851329, 'Total loss': 0.4745558243851329} | train loss {'Reaction outcome loss': 0.3072983462501455, 'Total loss': 0.3072983462501455}
2022-11-28 02:34:23,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:23,184 INFO:     Epoch: 66
2022-11-28 02:34:23,931 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4739020012838896, 'Total loss': 0.4739020012838896} | train loss {'Reaction outcome loss': 0.3075635440862228, 'Total loss': 0.3075635440862228}
2022-11-28 02:34:23,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:23,932 INFO:     Epoch: 67
2022-11-28 02:34:24,681 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4628496849259665, 'Total loss': 0.4628496849259665} | train loss {'Reaction outcome loss': 0.31182222856293, 'Total loss': 0.31182222856293}
2022-11-28 02:34:24,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:24,681 INFO:     Epoch: 68
2022-11-28 02:34:25,430 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4610852353101553, 'Total loss': 0.4610852353101553} | train loss {'Reaction outcome loss': 0.314565294839963, 'Total loss': 0.314565294839963}
2022-11-28 02:34:25,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:25,431 INFO:     Epoch: 69
2022-11-28 02:34:26,181 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44559730416120485, 'Total loss': 0.44559730416120485} | train loss {'Reaction outcome loss': 0.3154931871120822, 'Total loss': 0.3154931871120822}
2022-11-28 02:34:26,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:26,181 INFO:     Epoch: 70
2022-11-28 02:34:26,931 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4849447005016859, 'Total loss': 0.4849447005016859} | train loss {'Reaction outcome loss': 0.30017020355588125, 'Total loss': 0.30017020355588125}
2022-11-28 02:34:26,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:26,931 INFO:     Epoch: 71
2022-11-28 02:34:27,678 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4956795181645903, 'Total loss': 0.4956795181645903} | train loss {'Reaction outcome loss': 0.3090749602810836, 'Total loss': 0.3090749602810836}
2022-11-28 02:34:27,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:27,678 INFO:     Epoch: 72
2022-11-28 02:34:28,427 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43853163580561794, 'Total loss': 0.43853163580561794} | train loss {'Reaction outcome loss': 0.31095462280168457, 'Total loss': 0.31095462280168457}
2022-11-28 02:34:28,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:28,427 INFO:     Epoch: 73
2022-11-28 02:34:29,177 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4497895857622457, 'Total loss': 0.4497895857622457} | train loss {'Reaction outcome loss': 0.3022880532813293, 'Total loss': 0.3022880532813293}
2022-11-28 02:34:29,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:29,177 INFO:     Epoch: 74
2022-11-28 02:34:29,926 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45273044878660246, 'Total loss': 0.45273044878660246} | train loss {'Reaction outcome loss': 0.3039340492751863, 'Total loss': 0.3039340492751863}
2022-11-28 02:34:29,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:29,926 INFO:     Epoch: 75
2022-11-28 02:34:30,675 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4376100374515666, 'Total loss': 0.4376100374515666} | train loss {'Reaction outcome loss': 0.30882962159965754, 'Total loss': 0.30882962159965754}
2022-11-28 02:34:30,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:30,676 INFO:     Epoch: 76
2022-11-28 02:34:31,421 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4639898673739544, 'Total loss': 0.4639898673739544} | train loss {'Reaction outcome loss': 0.31241996218392876, 'Total loss': 0.31241996218392876}
2022-11-28 02:34:31,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:31,422 INFO:     Epoch: 77
2022-11-28 02:34:32,168 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4658636436905972, 'Total loss': 0.4658636436905972} | train loss {'Reaction outcome loss': 0.31396370316729133, 'Total loss': 0.31396370316729133}
2022-11-28 02:34:32,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:32,168 INFO:     Epoch: 78
2022-11-28 02:34:32,916 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45614940829055256, 'Total loss': 0.45614940829055256} | train loss {'Reaction outcome loss': 0.3009115708953559, 'Total loss': 0.3009115708953559}
2022-11-28 02:34:32,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:32,917 INFO:     Epoch: 79
2022-11-28 02:34:33,662 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4582791065060815, 'Total loss': 0.4582791065060815} | train loss {'Reaction outcome loss': 0.307919516975497, 'Total loss': 0.307919516975497}
2022-11-28 02:34:33,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:33,662 INFO:     Epoch: 80
2022-11-28 02:34:34,413 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45622075435727144, 'Total loss': 0.45622075435727144} | train loss {'Reaction outcome loss': 0.3119748980420117, 'Total loss': 0.3119748980420117}
2022-11-28 02:34:34,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:34,413 INFO:     Epoch: 81
2022-11-28 02:34:35,162 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44263047811596895, 'Total loss': 0.44263047811596895} | train loss {'Reaction outcome loss': 0.31229263899748216, 'Total loss': 0.31229263899748216}
2022-11-28 02:34:35,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:35,163 INFO:     Epoch: 82
2022-11-28 02:34:35,913 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4660284467214762, 'Total loss': 0.4660284467214762} | train loss {'Reaction outcome loss': 0.3089005699986784, 'Total loss': 0.3089005699986784}
2022-11-28 02:34:35,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:35,915 INFO:     Epoch: 83
2022-11-28 02:34:36,663 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4615612684987312, 'Total loss': 0.4615612684987312} | train loss {'Reaction outcome loss': 0.30253619565762613, 'Total loss': 0.30253619565762613}
2022-11-28 02:34:36,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:36,663 INFO:     Epoch: 84
2022-11-28 02:34:37,411 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44952472108741137, 'Total loss': 0.44952472108741137} | train loss {'Reaction outcome loss': 0.31327700504550227, 'Total loss': 0.31327700504550227}
2022-11-28 02:34:37,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:37,411 INFO:     Epoch: 85
2022-11-28 02:34:38,162 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4253843613835268, 'Total loss': 0.4253843613835268} | train loss {'Reaction outcome loss': 0.3066567155865975, 'Total loss': 0.3066567155865975}
2022-11-28 02:34:38,162 INFO:     Found new best model at epoch 85
2022-11-28 02:34:38,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:38,163 INFO:     Epoch: 86
2022-11-28 02:34:38,911 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44219303633584534, 'Total loss': 0.44219303633584534} | train loss {'Reaction outcome loss': 0.3196663831364471, 'Total loss': 0.3196663831364471}
2022-11-28 02:34:38,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:38,911 INFO:     Epoch: 87
2022-11-28 02:34:39,658 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46220658546270327, 'Total loss': 0.46220658546270327} | train loss {'Reaction outcome loss': 0.30978913028789645, 'Total loss': 0.30978913028789645}
2022-11-28 02:34:39,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:39,658 INFO:     Epoch: 88
2022-11-28 02:34:40,407 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4583399184914522, 'Total loss': 0.4583399184914522} | train loss {'Reaction outcome loss': 0.3112018008413629, 'Total loss': 0.3112018008413629}
2022-11-28 02:34:40,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:40,407 INFO:     Epoch: 89
2022-11-28 02:34:41,156 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4652988477501758, 'Total loss': 0.4652988477501758} | train loss {'Reaction outcome loss': 0.30363842181156203, 'Total loss': 0.30363842181156203}
2022-11-28 02:34:41,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:41,156 INFO:     Epoch: 90
2022-11-28 02:34:41,897 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44690377282541854, 'Total loss': 0.44690377282541854} | train loss {'Reaction outcome loss': 0.3064042466075577, 'Total loss': 0.3064042466075577}
2022-11-28 02:34:41,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:41,897 INFO:     Epoch: 91
2022-11-28 02:34:42,631 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4623775263858396, 'Total loss': 0.4623775263858396} | train loss {'Reaction outcome loss': 0.305187329343317, 'Total loss': 0.305187329343317}
2022-11-28 02:34:42,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:42,631 INFO:     Epoch: 92
2022-11-28 02:34:43,363 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4715728364711584, 'Total loss': 0.4715728364711584} | train loss {'Reaction outcome loss': 0.3056658761261545, 'Total loss': 0.3056658761261545}
2022-11-28 02:34:43,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:43,363 INFO:     Epoch: 93
2022-11-28 02:34:44,095 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47083590578201207, 'Total loss': 0.47083590578201207} | train loss {'Reaction outcome loss': 0.3048821965178835, 'Total loss': 0.3048821965178835}
2022-11-28 02:34:44,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:44,095 INFO:     Epoch: 94
2022-11-28 02:34:44,830 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5151768548544063, 'Total loss': 0.5151768548544063} | train loss {'Reaction outcome loss': 0.307313831530726, 'Total loss': 0.307313831530726}
2022-11-28 02:34:44,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:44,831 INFO:     Epoch: 95
2022-11-28 02:34:45,563 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4591271229261576, 'Total loss': 0.4591271229261576} | train loss {'Reaction outcome loss': 0.3089672987475807, 'Total loss': 0.3089672987475807}
2022-11-28 02:34:45,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:45,563 INFO:     Epoch: 96
2022-11-28 02:34:46,297 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4499532888795054, 'Total loss': 0.4499532888795054} | train loss {'Reaction outcome loss': 0.30665413688852955, 'Total loss': 0.30665413688852955}
2022-11-28 02:34:46,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:46,298 INFO:     Epoch: 97
2022-11-28 02:34:47,040 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.432360774209333, 'Total loss': 0.432360774209333} | train loss {'Reaction outcome loss': 0.3070017611262975, 'Total loss': 0.3070017611262975}
2022-11-28 02:34:47,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:47,040 INFO:     Epoch: 98
2022-11-28 02:34:47,780 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45256839813881145, 'Total loss': 0.45256839813881145} | train loss {'Reaction outcome loss': 0.30064326285580056, 'Total loss': 0.30064326285580056}
2022-11-28 02:34:47,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:47,780 INFO:     Epoch: 99
2022-11-28 02:34:48,519 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47040474154921463, 'Total loss': 0.47040474154921463} | train loss {'Reaction outcome loss': 0.3115387441199503, 'Total loss': 0.3115387441199503}
2022-11-28 02:34:48,519 INFO:     Best model found after epoch 86 of 100.
2022-11-28 02:34:48,520 INFO:   Done with stage: TRAINING
2022-11-28 02:34:48,520 INFO:   Starting stage: EVALUATION
2022-11-28 02:34:48,662 INFO:   Done with stage: EVALUATION
2022-11-28 02:34:48,662 INFO:   Leaving out SEQ value Fold_2
2022-11-28 02:34:48,675 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:34:48,675 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:34:49,325 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:34:49,325 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:34:49,393 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:34:49,393 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:34:49,393 INFO:     No hyperparam tuning for this model
2022-11-28 02:34:49,393 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:34:49,393 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:34:49,394 INFO:     None feature selector for col prot
2022-11-28 02:34:49,394 INFO:     None feature selector for col prot
2022-11-28 02:34:49,394 INFO:     None feature selector for col prot
2022-11-28 02:34:49,394 INFO:     None feature selector for col chem
2022-11-28 02:34:49,394 INFO:     None feature selector for col chem
2022-11-28 02:34:49,395 INFO:     None feature selector for col chem
2022-11-28 02:34:49,395 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:34:49,395 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:34:49,396 INFO:     Number of params in model 169741
2022-11-28 02:34:49,399 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:34:49,399 INFO:   Starting stage: TRAINING
2022-11-28 02:34:49,453 INFO:     Val loss before train {'Reaction outcome loss': 0.9630701704458757, 'Total loss': 0.9630701704458757}
2022-11-28 02:34:49,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:49,453 INFO:     Epoch: 0
2022-11-28 02:34:50,203 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5824881744655696, 'Total loss': 0.5824881744655696} | train loss {'Reaction outcome loss': 0.6633880071494044, 'Total loss': 0.6633880071494044}
2022-11-28 02:34:50,203 INFO:     Found new best model at epoch 0
2022-11-28 02:34:50,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:50,204 INFO:     Epoch: 1
2022-11-28 02:34:50,953 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5014304721897299, 'Total loss': 0.5014304721897299} | train loss {'Reaction outcome loss': 0.5159905149620406, 'Total loss': 0.5159905149620406}
2022-11-28 02:34:50,954 INFO:     Found new best model at epoch 1
2022-11-28 02:34:50,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:50,954 INFO:     Epoch: 2
2022-11-28 02:34:51,699 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48821850154887547, 'Total loss': 0.48821850154887547} | train loss {'Reaction outcome loss': 0.462458788132181, 'Total loss': 0.462458788132181}
2022-11-28 02:34:51,699 INFO:     Found new best model at epoch 2
2022-11-28 02:34:51,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:51,700 INFO:     Epoch: 3
2022-11-28 02:34:52,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5337045771831815, 'Total loss': 0.5337045771831815} | train loss {'Reaction outcome loss': 0.4524361893230555, 'Total loss': 0.4524361893230555}
2022-11-28 02:34:52,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:52,445 INFO:     Epoch: 4
2022-11-28 02:34:53,192 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48628494719212706, 'Total loss': 0.48628494719212706} | train loss {'Reaction outcome loss': 0.43642721428554887, 'Total loss': 0.43642721428554887}
2022-11-28 02:34:53,192 INFO:     Found new best model at epoch 4
2022-11-28 02:34:53,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:53,193 INFO:     Epoch: 5
2022-11-28 02:34:53,940 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46808185656978324, 'Total loss': 0.46808185656978324} | train loss {'Reaction outcome loss': 0.4207864792675388, 'Total loss': 0.4207864792675388}
2022-11-28 02:34:53,941 INFO:     Found new best model at epoch 5
2022-11-28 02:34:53,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:53,941 INFO:     Epoch: 6
2022-11-28 02:34:54,687 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5216349752789194, 'Total loss': 0.5216349752789194} | train loss {'Reaction outcome loss': 0.40989682358138413, 'Total loss': 0.40989682358138413}
2022-11-28 02:34:54,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:54,688 INFO:     Epoch: 7
2022-11-28 02:34:55,432 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4550481984730471, 'Total loss': 0.4550481984730471} | train loss {'Reaction outcome loss': 0.41050706822044997, 'Total loss': 0.41050706822044997}
2022-11-28 02:34:55,432 INFO:     Found new best model at epoch 7
2022-11-28 02:34:55,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:55,433 INFO:     Epoch: 8
2022-11-28 02:34:56,177 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44276782366531814, 'Total loss': 0.44276782366531814} | train loss {'Reaction outcome loss': 0.3983856537512371, 'Total loss': 0.3983856537512371}
2022-11-28 02:34:56,177 INFO:     Found new best model at epoch 8
2022-11-28 02:34:56,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:56,178 INFO:     Epoch: 9
2022-11-28 02:34:56,925 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.461552635173906, 'Total loss': 0.461552635173906} | train loss {'Reaction outcome loss': 0.3838673244933693, 'Total loss': 0.3838673244933693}
2022-11-28 02:34:56,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:56,926 INFO:     Epoch: 10
2022-11-28 02:34:57,672 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4803249981593002, 'Total loss': 0.4803249981593002} | train loss {'Reaction outcome loss': 0.3889034711584753, 'Total loss': 0.3889034711584753}
2022-11-28 02:34:57,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:57,673 INFO:     Epoch: 11
2022-11-28 02:34:58,414 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45727496390992944, 'Total loss': 0.45727496390992944} | train loss {'Reaction outcome loss': 0.38166741266542553, 'Total loss': 0.38166741266542553}
2022-11-28 02:34:58,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:58,414 INFO:     Epoch: 12
2022-11-28 02:34:59,156 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46552118354222993, 'Total loss': 0.46552118354222993} | train loss {'Reaction outcome loss': 0.3777218986530693, 'Total loss': 0.3777218986530693}
2022-11-28 02:34:59,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:59,156 INFO:     Epoch: 13
2022-11-28 02:34:59,897 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5137322202155535, 'Total loss': 0.5137322202155535} | train loss {'Reaction outcome loss': 0.37485213109425136, 'Total loss': 0.37485213109425136}
2022-11-28 02:34:59,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:34:59,897 INFO:     Epoch: 14
2022-11-28 02:35:00,640 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45576904951171443, 'Total loss': 0.45576904951171443} | train loss {'Reaction outcome loss': 0.36416568415505546, 'Total loss': 0.36416568415505546}
2022-11-28 02:35:00,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:00,640 INFO:     Epoch: 15
2022-11-28 02:35:01,382 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45460630411451514, 'Total loss': 0.45460630411451514} | train loss {'Reaction outcome loss': 0.36375885978341105, 'Total loss': 0.36375885978341105}
2022-11-28 02:35:01,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:01,382 INFO:     Epoch: 16
2022-11-28 02:35:02,125 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4792588935656981, 'Total loss': 0.4792588935656981} | train loss {'Reaction outcome loss': 0.3567906872654448, 'Total loss': 0.3567906872654448}
2022-11-28 02:35:02,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:02,125 INFO:     Epoch: 17
2022-11-28 02:35:02,866 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4488882285288789, 'Total loss': 0.4488882285288789} | train loss {'Reaction outcome loss': 0.36825357871700304, 'Total loss': 0.36825357871700304}
2022-11-28 02:35:02,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:02,866 INFO:     Epoch: 18
2022-11-28 02:35:03,610 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43868518383665517, 'Total loss': 0.43868518383665517} | train loss {'Reaction outcome loss': 0.3569209250868583, 'Total loss': 0.3569209250868583}
2022-11-28 02:35:03,610 INFO:     Found new best model at epoch 18
2022-11-28 02:35:03,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:03,611 INFO:     Epoch: 19
2022-11-28 02:35:04,352 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47556176070462575, 'Total loss': 0.47556176070462575} | train loss {'Reaction outcome loss': 0.3652721327330385, 'Total loss': 0.3652721327330385}
2022-11-28 02:35:04,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:04,352 INFO:     Epoch: 20
2022-11-28 02:35:05,091 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44382439282807434, 'Total loss': 0.44382439282807434} | train loss {'Reaction outcome loss': 0.3580782600203339, 'Total loss': 0.3580782600203339}
2022-11-28 02:35:05,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:05,092 INFO:     Epoch: 21
2022-11-28 02:35:05,831 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44086228065531363, 'Total loss': 0.44086228065531363} | train loss {'Reaction outcome loss': 0.3501359615398913, 'Total loss': 0.3501359615398913}
2022-11-28 02:35:05,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:05,832 INFO:     Epoch: 22
2022-11-28 02:35:06,572 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4693813059817661, 'Total loss': 0.4693813059817661} | train loss {'Reaction outcome loss': 0.346373137436351, 'Total loss': 0.346373137436351}
2022-11-28 02:35:06,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:06,572 INFO:     Epoch: 23
2022-11-28 02:35:07,316 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4156491509215398, 'Total loss': 0.4156491509215398} | train loss {'Reaction outcome loss': 0.35323217641942356, 'Total loss': 0.35323217641942356}
2022-11-28 02:35:07,317 INFO:     Found new best model at epoch 23
2022-11-28 02:35:07,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:07,318 INFO:     Epoch: 24
2022-11-28 02:35:08,058 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4571888016706163, 'Total loss': 0.4571888016706163} | train loss {'Reaction outcome loss': 0.34222251572171036, 'Total loss': 0.34222251572171036}
2022-11-28 02:35:08,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:08,058 INFO:     Epoch: 25
2022-11-28 02:35:08,802 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4405900439755483, 'Total loss': 0.4405900439755483} | train loss {'Reaction outcome loss': 0.34495824198333586, 'Total loss': 0.34495824198333586}
2022-11-28 02:35:08,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:08,802 INFO:     Epoch: 26
2022-11-28 02:35:09,545 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46385495974258945, 'Total loss': 0.46385495974258945} | train loss {'Reaction outcome loss': 0.3399915241769382, 'Total loss': 0.3399915241769382}
2022-11-28 02:35:09,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:09,545 INFO:     Epoch: 27
2022-11-28 02:35:10,291 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4289783325723626, 'Total loss': 0.4289783325723626} | train loss {'Reaction outcome loss': 0.33505426484103107, 'Total loss': 0.33505426484103107}
2022-11-28 02:35:10,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:10,291 INFO:     Epoch: 28
2022-11-28 02:35:11,034 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4955435835502364, 'Total loss': 0.4955435835502364} | train loss {'Reaction outcome loss': 0.33484963891761643, 'Total loss': 0.33484963891761643}
2022-11-28 02:35:11,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:11,034 INFO:     Epoch: 29
2022-11-28 02:35:11,781 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4518549465997653, 'Total loss': 0.4518549465997653} | train loss {'Reaction outcome loss': 0.3407740325039747, 'Total loss': 0.3407740325039747}
2022-11-28 02:35:11,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:11,781 INFO:     Epoch: 30
2022-11-28 02:35:12,527 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47008655846796255, 'Total loss': 0.47008655846796255} | train loss {'Reaction outcome loss': 0.3469409805171344, 'Total loss': 0.3469409805171344}
2022-11-28 02:35:12,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:12,528 INFO:     Epoch: 31
2022-11-28 02:35:13,268 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45204355770891363, 'Total loss': 0.45204355770891363} | train loss {'Reaction outcome loss': 0.33536723654489126, 'Total loss': 0.33536723654489126}
2022-11-28 02:35:13,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:13,269 INFO:     Epoch: 32
2022-11-28 02:35:14,011 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44350085576826875, 'Total loss': 0.44350085576826875} | train loss {'Reaction outcome loss': 0.32810162266298215, 'Total loss': 0.32810162266298215}
2022-11-28 02:35:14,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:14,012 INFO:     Epoch: 33
2022-11-28 02:35:14,758 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4632988318123601, 'Total loss': 0.4632988318123601} | train loss {'Reaction outcome loss': 0.3358643044014366, 'Total loss': 0.3358643044014366}
2022-11-28 02:35:14,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:14,758 INFO:     Epoch: 34
2022-11-28 02:35:15,501 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.446881908246062, 'Total loss': 0.446881908246062} | train loss {'Reaction outcome loss': 0.33367318012276476, 'Total loss': 0.33367318012276476}
2022-11-28 02:35:15,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:15,501 INFO:     Epoch: 35
2022-11-28 02:35:16,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4210293003442613, 'Total loss': 0.4210293003442613} | train loss {'Reaction outcome loss': 0.3260040130238144, 'Total loss': 0.3260040130238144}
2022-11-28 02:35:16,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:16,242 INFO:     Epoch: 36
2022-11-28 02:35:16,983 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4623360061510043, 'Total loss': 0.4623360061510043} | train loss {'Reaction outcome loss': 0.33632364248742863, 'Total loss': 0.33632364248742863}
2022-11-28 02:35:16,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:16,984 INFO:     Epoch: 37
2022-11-28 02:35:17,728 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4402212273668159, 'Total loss': 0.4402212273668159} | train loss {'Reaction outcome loss': 0.33045691362753205, 'Total loss': 0.33045691362753205}
2022-11-28 02:35:17,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:17,728 INFO:     Epoch: 38
2022-11-28 02:35:18,470 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4563187330283902, 'Total loss': 0.4563187330283902} | train loss {'Reaction outcome loss': 0.32601175210913835, 'Total loss': 0.32601175210913835}
2022-11-28 02:35:18,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:18,470 INFO:     Epoch: 39
2022-11-28 02:35:19,215 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44313217885792255, 'Total loss': 0.44313217885792255} | train loss {'Reaction outcome loss': 0.3286299868505828, 'Total loss': 0.3286299868505828}
2022-11-28 02:35:19,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:19,215 INFO:     Epoch: 40
2022-11-28 02:35:19,959 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4506696140901609, 'Total loss': 0.4506696140901609} | train loss {'Reaction outcome loss': 0.3297913753712664, 'Total loss': 0.3297913753712664}
2022-11-28 02:35:19,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:19,959 INFO:     Epoch: 41
2022-11-28 02:35:20,700 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4527236418798566, 'Total loss': 0.4527236418798566} | train loss {'Reaction outcome loss': 0.3334477729335123, 'Total loss': 0.3334477729335123}
2022-11-28 02:35:20,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:20,701 INFO:     Epoch: 42
2022-11-28 02:35:21,440 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44908942959525366, 'Total loss': 0.44908942959525366} | train loss {'Reaction outcome loss': 0.329293975538137, 'Total loss': 0.329293975538137}
2022-11-28 02:35:21,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:21,441 INFO:     Epoch: 43
2022-11-28 02:35:22,180 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4315921762450175, 'Total loss': 0.4315921762450175} | train loss {'Reaction outcome loss': 0.32099105536329503, 'Total loss': 0.32099105536329503}
2022-11-28 02:35:22,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:22,180 INFO:     Epoch: 44
2022-11-28 02:35:22,923 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42891036143357103, 'Total loss': 0.42891036143357103} | train loss {'Reaction outcome loss': 0.32935649661385286, 'Total loss': 0.32935649661385286}
2022-11-28 02:35:22,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:22,923 INFO:     Epoch: 45
2022-11-28 02:35:23,668 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4505045283585787, 'Total loss': 0.4505045283585787} | train loss {'Reaction outcome loss': 0.32388770399349076, 'Total loss': 0.32388770399349076}
2022-11-28 02:35:23,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:23,668 INFO:     Epoch: 46
2022-11-28 02:35:24,409 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4235381646589799, 'Total loss': 0.4235381646589799} | train loss {'Reaction outcome loss': 0.32168272095067163, 'Total loss': 0.32168272095067163}
2022-11-28 02:35:24,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:24,410 INFO:     Epoch: 47
2022-11-28 02:35:25,152 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4242309900847348, 'Total loss': 0.4242309900847348} | train loss {'Reaction outcome loss': 0.32368094778182555, 'Total loss': 0.32368094778182555}
2022-11-28 02:35:25,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:25,152 INFO:     Epoch: 48
2022-11-28 02:35:25,893 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4371644329618324, 'Total loss': 0.4371644329618324} | train loss {'Reaction outcome loss': 0.3158590484334498, 'Total loss': 0.3158590484334498}
2022-11-28 02:35:25,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:25,893 INFO:     Epoch: 49
2022-11-28 02:35:26,634 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4473620124838569, 'Total loss': 0.4473620124838569} | train loss {'Reaction outcome loss': 0.327334312699279, 'Total loss': 0.327334312699279}
2022-11-28 02:35:26,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:26,635 INFO:     Epoch: 50
2022-11-28 02:35:27,376 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4476313258478926, 'Total loss': 0.4476313258478926} | train loss {'Reaction outcome loss': 0.32408619662936855, 'Total loss': 0.32408619662936855}
2022-11-28 02:35:27,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:27,376 INFO:     Epoch: 51
2022-11-28 02:35:28,116 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48411948166110297, 'Total loss': 0.48411948166110297} | train loss {'Reaction outcome loss': 0.32356526622054527, 'Total loss': 0.32356526622054527}
2022-11-28 02:35:28,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:28,117 INFO:     Epoch: 52
2022-11-28 02:35:28,859 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4218295644968748, 'Total loss': 0.4218295644968748} | train loss {'Reaction outcome loss': 0.3265064288614964, 'Total loss': 0.3265064288614964}
2022-11-28 02:35:28,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:28,859 INFO:     Epoch: 53
2022-11-28 02:35:29,599 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.450370806184682, 'Total loss': 0.450370806184682} | train loss {'Reaction outcome loss': 0.3304864696702179, 'Total loss': 0.3304864696702179}
2022-11-28 02:35:29,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:29,599 INFO:     Epoch: 54
2022-11-28 02:35:30,340 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44298687407916243, 'Total loss': 0.44298687407916243} | train loss {'Reaction outcome loss': 0.32407553719014537, 'Total loss': 0.32407553719014537}
2022-11-28 02:35:30,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:30,341 INFO:     Epoch: 55
2022-11-28 02:35:31,083 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4533626555719159, 'Total loss': 0.4533626555719159} | train loss {'Reaction outcome loss': 0.32283853931086404, 'Total loss': 0.32283853931086404}
2022-11-28 02:35:31,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:31,083 INFO:     Epoch: 56
2022-11-28 02:35:31,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4664197476072745, 'Total loss': 0.4664197476072745} | train loss {'Reaction outcome loss': 0.3216504573517916, 'Total loss': 0.3216504573517916}
2022-11-28 02:35:31,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:31,823 INFO:     Epoch: 57
2022-11-28 02:35:32,566 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4608945121819323, 'Total loss': 0.4608945121819323} | train loss {'Reaction outcome loss': 0.3063337312365065, 'Total loss': 0.3063337312365065}
2022-11-28 02:35:32,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:32,566 INFO:     Epoch: 58
2022-11-28 02:35:33,306 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4366947588595477, 'Total loss': 0.4366947588595477} | train loss {'Reaction outcome loss': 0.31959802137345683, 'Total loss': 0.31959802137345683}
2022-11-28 02:35:33,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:33,306 INFO:     Epoch: 59
2022-11-28 02:35:34,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4356888064437292, 'Total loss': 0.4356888064437292} | train loss {'Reaction outcome loss': 0.32265934691745407, 'Total loss': 0.32265934691745407}
2022-11-28 02:35:34,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:34,052 INFO:     Epoch: 60
2022-11-28 02:35:34,796 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4470388283106414, 'Total loss': 0.4470388283106414} | train loss {'Reaction outcome loss': 0.31118998007506743, 'Total loss': 0.31118998007506743}
2022-11-28 02:35:34,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:34,796 INFO:     Epoch: 61
2022-11-28 02:35:35,538 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41592990031296556, 'Total loss': 0.41592990031296556} | train loss {'Reaction outcome loss': 0.3155014181927759, 'Total loss': 0.3155014181927759}
2022-11-28 02:35:35,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:35,538 INFO:     Epoch: 62
2022-11-28 02:35:36,279 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4298922357742082, 'Total loss': 0.4298922357742082} | train loss {'Reaction outcome loss': 0.312321290419418, 'Total loss': 0.312321290419418}
2022-11-28 02:35:36,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:36,279 INFO:     Epoch: 63
2022-11-28 02:35:37,023 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44017708267677913, 'Total loss': 0.44017708267677913} | train loss {'Reaction outcome loss': 0.3180043399333954, 'Total loss': 0.3180043399333954}
2022-11-28 02:35:37,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:37,023 INFO:     Epoch: 64
2022-11-28 02:35:37,768 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47593579949303105, 'Total loss': 0.47593579949303105} | train loss {'Reaction outcome loss': 0.3182964087140803, 'Total loss': 0.3182964087140803}
2022-11-28 02:35:37,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:37,769 INFO:     Epoch: 65
2022-11-28 02:35:38,509 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4552364276552742, 'Total loss': 0.4552364276552742} | train loss {'Reaction outcome loss': 0.3213054629308837, 'Total loss': 0.3213054629308837}
2022-11-28 02:35:38,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:38,509 INFO:     Epoch: 66
2022-11-28 02:35:39,250 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44369937919757585, 'Total loss': 0.44369937919757585} | train loss {'Reaction outcome loss': 0.31596769489804094, 'Total loss': 0.31596769489804094}
2022-11-28 02:35:39,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:39,250 INFO:     Epoch: 67
2022-11-28 02:35:39,991 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4416166459294883, 'Total loss': 0.4416166459294883} | train loss {'Reaction outcome loss': 0.31762770294230813, 'Total loss': 0.31762770294230813}
2022-11-28 02:35:39,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:39,991 INFO:     Epoch: 68
2022-11-28 02:35:40,735 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46968090161681175, 'Total loss': 0.46968090161681175} | train loss {'Reaction outcome loss': 0.32374404915133304, 'Total loss': 0.32374404915133304}
2022-11-28 02:35:40,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:40,736 INFO:     Epoch: 69
2022-11-28 02:35:41,483 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4440688948062333, 'Total loss': 0.4440688948062333} | train loss {'Reaction outcome loss': 0.31229390328635975, 'Total loss': 0.31229390328635975}
2022-11-28 02:35:41,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:41,483 INFO:     Epoch: 70
2022-11-28 02:35:42,225 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43923533199863, 'Total loss': 0.43923533199863} | train loss {'Reaction outcome loss': 0.3154911771720769, 'Total loss': 0.3154911771720769}
2022-11-28 02:35:42,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:42,225 INFO:     Epoch: 71
2022-11-28 02:35:42,963 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4603124750270085, 'Total loss': 0.4603124750270085} | train loss {'Reaction outcome loss': 0.30854953545696884, 'Total loss': 0.30854953545696884}
2022-11-28 02:35:42,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:42,964 INFO:     Epoch: 72
2022-11-28 02:35:43,707 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4619267007166689, 'Total loss': 0.4619267007166689} | train loss {'Reaction outcome loss': 0.30893915499351465, 'Total loss': 0.30893915499351465}
2022-11-28 02:35:43,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:43,707 INFO:     Epoch: 73
2022-11-28 02:35:44,451 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46041911603374913, 'Total loss': 0.46041911603374913} | train loss {'Reaction outcome loss': 0.31323099610756855, 'Total loss': 0.31323099610756855}
2022-11-28 02:35:44,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:44,452 INFO:     Epoch: 74
2022-11-28 02:35:45,191 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44407791779799893, 'Total loss': 0.44407791779799893} | train loss {'Reaction outcome loss': 0.309659813253247, 'Total loss': 0.309659813253247}
2022-11-28 02:35:45,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:45,192 INFO:     Epoch: 75
2022-11-28 02:35:45,933 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4518085748634555, 'Total loss': 0.4518085748634555} | train loss {'Reaction outcome loss': 0.31856037062041614, 'Total loss': 0.31856037062041614}
2022-11-28 02:35:45,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:45,933 INFO:     Epoch: 76
2022-11-28 02:35:46,684 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45496331053701317, 'Total loss': 0.45496331053701317} | train loss {'Reaction outcome loss': 0.313770201817459, 'Total loss': 0.313770201817459}
2022-11-28 02:35:46,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:46,684 INFO:     Epoch: 77
2022-11-28 02:35:47,427 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4634250629354607, 'Total loss': 0.4634250629354607} | train loss {'Reaction outcome loss': 0.312035228197976, 'Total loss': 0.312035228197976}
2022-11-28 02:35:47,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:47,427 INFO:     Epoch: 78
2022-11-28 02:35:48,168 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48580662499774585, 'Total loss': 0.48580662499774585} | train loss {'Reaction outcome loss': 0.3111601316503116, 'Total loss': 0.3111601316503116}
2022-11-28 02:35:48,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:48,168 INFO:     Epoch: 79
2022-11-28 02:35:48,913 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44987916912544856, 'Total loss': 0.44987916912544856} | train loss {'Reaction outcome loss': 0.3119671010545322, 'Total loss': 0.3119671010545322}
2022-11-28 02:35:48,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:48,914 INFO:     Epoch: 80
2022-11-28 02:35:49,656 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4445935604585843, 'Total loss': 0.4445935604585843} | train loss {'Reaction outcome loss': 0.3079920807207117, 'Total loss': 0.3079920807207117}
2022-11-28 02:35:49,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:49,656 INFO:     Epoch: 81
2022-11-28 02:35:50,400 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48840530487624084, 'Total loss': 0.48840530487624084} | train loss {'Reaction outcome loss': 0.3074703222634841, 'Total loss': 0.3074703222634841}
2022-11-28 02:35:50,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:50,400 INFO:     Epoch: 82
2022-11-28 02:35:51,145 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46555016308345576, 'Total loss': 0.46555016308345576} | train loss {'Reaction outcome loss': 0.3039188943955363, 'Total loss': 0.3039188943955363}
2022-11-28 02:35:51,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:51,145 INFO:     Epoch: 83
2022-11-28 02:35:51,889 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.455271961633116, 'Total loss': 0.455271961633116} | train loss {'Reaction outcome loss': 0.3071355597249099, 'Total loss': 0.3071355597249099}
2022-11-28 02:35:51,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:51,889 INFO:     Epoch: 84
2022-11-28 02:35:52,632 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45226937159895897, 'Total loss': 0.45226937159895897} | train loss {'Reaction outcome loss': 0.3106495277005799, 'Total loss': 0.3106495277005799}
2022-11-28 02:35:52,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:52,632 INFO:     Epoch: 85
2022-11-28 02:35:53,376 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46038250252604485, 'Total loss': 0.46038250252604485} | train loss {'Reaction outcome loss': 0.3130717375448772, 'Total loss': 0.3130717375448772}
2022-11-28 02:35:53,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:53,376 INFO:     Epoch: 86
2022-11-28 02:35:54,115 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4511531804772941, 'Total loss': 0.4511531804772941} | train loss {'Reaction outcome loss': 0.31684274676502966, 'Total loss': 0.31684274676502966}
2022-11-28 02:35:54,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:54,116 INFO:     Epoch: 87
2022-11-28 02:35:54,855 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43094496395100246, 'Total loss': 0.43094496395100246} | train loss {'Reaction outcome loss': 0.3112596711942128, 'Total loss': 0.3112596711942128}
2022-11-28 02:35:54,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:54,855 INFO:     Epoch: 88
2022-11-28 02:35:55,598 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4407492798160423, 'Total loss': 0.4407492798160423} | train loss {'Reaction outcome loss': 0.3130292348107513, 'Total loss': 0.3130292348107513}
2022-11-28 02:35:55,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:55,598 INFO:     Epoch: 89
2022-11-28 02:35:56,338 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4460170150480487, 'Total loss': 0.4460170150480487} | train loss {'Reaction outcome loss': 0.3074419100369726, 'Total loss': 0.3074419100369726}
2022-11-28 02:35:56,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:56,339 INFO:     Epoch: 90
2022-11-28 02:35:57,078 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4349727299572392, 'Total loss': 0.4349727299572392} | train loss {'Reaction outcome loss': 0.3105267889645635, 'Total loss': 0.3105267889645635}
2022-11-28 02:35:57,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:57,079 INFO:     Epoch: 91
2022-11-28 02:35:57,821 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45101354643702507, 'Total loss': 0.45101354643702507} | train loss {'Reaction outcome loss': 0.2962318671297054, 'Total loss': 0.2962318671297054}
2022-11-28 02:35:57,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:57,822 INFO:     Epoch: 92
2022-11-28 02:35:58,563 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43502842262387276, 'Total loss': 0.43502842262387276} | train loss {'Reaction outcome loss': 0.3128101086434053, 'Total loss': 0.3128101086434053}
2022-11-28 02:35:58,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:58,564 INFO:     Epoch: 93
2022-11-28 02:35:59,305 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4683712961321527, 'Total loss': 0.4683712961321527} | train loss {'Reaction outcome loss': 0.3085231102850972, 'Total loss': 0.3085231102850972}
2022-11-28 02:35:59,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:35:59,305 INFO:     Epoch: 94
2022-11-28 02:36:00,047 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4136119680479169, 'Total loss': 0.4136119680479169} | train loss {'Reaction outcome loss': 0.31333279612721227, 'Total loss': 0.31333279612721227}
2022-11-28 02:36:00,048 INFO:     Found new best model at epoch 94
2022-11-28 02:36:00,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:00,048 INFO:     Epoch: 95
2022-11-28 02:36:00,790 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46507267552343284, 'Total loss': 0.46507267552343284} | train loss {'Reaction outcome loss': 0.3122726664555316, 'Total loss': 0.3122726664555316}
2022-11-28 02:36:00,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:00,790 INFO:     Epoch: 96
2022-11-28 02:36:01,533 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4430556639351628, 'Total loss': 0.4430556639351628} | train loss {'Reaction outcome loss': 0.3089187483702387, 'Total loss': 0.3089187483702387}
2022-11-28 02:36:01,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:01,533 INFO:     Epoch: 97
2022-11-28 02:36:02,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45530461181293835, 'Total loss': 0.45530461181293835} | train loss {'Reaction outcome loss': 0.30005310965435844, 'Total loss': 0.30005310965435844}
2022-11-28 02:36:02,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:02,275 INFO:     Epoch: 98
2022-11-28 02:36:03,023 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4647421900352294, 'Total loss': 0.4647421900352294} | train loss {'Reaction outcome loss': 0.317498021557623, 'Total loss': 0.317498021557623}
2022-11-28 02:36:03,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:03,024 INFO:     Epoch: 99
2022-11-28 02:36:03,768 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44455771994861687, 'Total loss': 0.44455771994861687} | train loss {'Reaction outcome loss': 0.31983149475893197, 'Total loss': 0.31983149475893197}
2022-11-28 02:36:03,768 INFO:     Best model found after epoch 95 of 100.
2022-11-28 02:36:03,768 INFO:   Done with stage: TRAINING
2022-11-28 02:36:03,768 INFO:   Starting stage: EVALUATION
2022-11-28 02:36:03,898 INFO:   Done with stage: EVALUATION
2022-11-28 02:36:03,898 INFO:   Leaving out SEQ value Fold_3
2022-11-28 02:36:03,910 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:36:03,911 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:36:04,546 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:36:04,546 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:36:04,614 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:36:04,615 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:36:04,615 INFO:     No hyperparam tuning for this model
2022-11-28 02:36:04,615 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:36:04,615 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:36:04,616 INFO:     None feature selector for col prot
2022-11-28 02:36:04,616 INFO:     None feature selector for col prot
2022-11-28 02:36:04,616 INFO:     None feature selector for col prot
2022-11-28 02:36:04,616 INFO:     None feature selector for col chem
2022-11-28 02:36:04,616 INFO:     None feature selector for col chem
2022-11-28 02:36:04,616 INFO:     None feature selector for col chem
2022-11-28 02:36:04,617 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:36:04,617 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:36:04,618 INFO:     Number of params in model 169741
2022-11-28 02:36:04,621 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:36:04,622 INFO:   Starting stage: TRAINING
2022-11-28 02:36:04,675 INFO:     Val loss before train {'Reaction outcome loss': 1.0165537202900106, 'Total loss': 1.0165537202900106}
2022-11-28 02:36:04,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:04,676 INFO:     Epoch: 0
2022-11-28 02:36:05,418 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5875363393940709, 'Total loss': 0.5875363393940709} | train loss {'Reaction outcome loss': 0.6414324186286148, 'Total loss': 0.6414324186286148}
2022-11-28 02:36:05,418 INFO:     Found new best model at epoch 0
2022-11-28 02:36:05,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:05,419 INFO:     Epoch: 1
2022-11-28 02:36:06,162 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.508309641006318, 'Total loss': 0.508309641006318} | train loss {'Reaction outcome loss': 0.5028557229406979, 'Total loss': 0.5028557229406979}
2022-11-28 02:36:06,162 INFO:     Found new best model at epoch 1
2022-11-28 02:36:06,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:06,163 INFO:     Epoch: 2
2022-11-28 02:36:06,905 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47016549720005557, 'Total loss': 0.47016549720005557} | train loss {'Reaction outcome loss': 0.45485634530077174, 'Total loss': 0.45485634530077174}
2022-11-28 02:36:06,905 INFO:     Found new best model at epoch 2
2022-11-28 02:36:06,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:06,906 INFO:     Epoch: 3
2022-11-28 02:36:07,650 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47946003756739874, 'Total loss': 0.47946003756739874} | train loss {'Reaction outcome loss': 0.44112894255287793, 'Total loss': 0.44112894255287793}
2022-11-28 02:36:07,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:07,650 INFO:     Epoch: 4
2022-11-28 02:36:08,394 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4616021994840015, 'Total loss': 0.4616021994840015} | train loss {'Reaction outcome loss': 0.42439051033282765, 'Total loss': 0.42439051033282765}
2022-11-28 02:36:08,394 INFO:     Found new best model at epoch 4
2022-11-28 02:36:08,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:08,395 INFO:     Epoch: 5
2022-11-28 02:36:09,143 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4400080554187298, 'Total loss': 0.4400080554187298} | train loss {'Reaction outcome loss': 0.405840959080628, 'Total loss': 0.405840959080628}
2022-11-28 02:36:09,144 INFO:     Found new best model at epoch 5
2022-11-28 02:36:09,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:09,145 INFO:     Epoch: 6
2022-11-28 02:36:09,887 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45798016813668335, 'Total loss': 0.45798016813668335} | train loss {'Reaction outcome loss': 0.4027984555582611, 'Total loss': 0.4027984555582611}
2022-11-28 02:36:09,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:09,887 INFO:     Epoch: 7
2022-11-28 02:36:10,628 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43571608378128573, 'Total loss': 0.43571608378128573} | train loss {'Reaction outcome loss': 0.39172782612090207, 'Total loss': 0.39172782612090207}
2022-11-28 02:36:10,628 INFO:     Found new best model at epoch 7
2022-11-28 02:36:10,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:10,629 INFO:     Epoch: 8
2022-11-28 02:36:11,374 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47744556584141473, 'Total loss': 0.47744556584141473} | train loss {'Reaction outcome loss': 0.37760258350445297, 'Total loss': 0.37760258350445297}
2022-11-28 02:36:11,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:11,375 INFO:     Epoch: 9
2022-11-28 02:36:12,119 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4413743076676672, 'Total loss': 0.4413743076676672} | train loss {'Reaction outcome loss': 0.37866826638275264, 'Total loss': 0.37866826638275264}
2022-11-28 02:36:12,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:12,119 INFO:     Epoch: 10
2022-11-28 02:36:12,863 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43684932724996045, 'Total loss': 0.43684932724996045} | train loss {'Reaction outcome loss': 0.36457397256578716, 'Total loss': 0.36457397256578716}
2022-11-28 02:36:12,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:12,863 INFO:     Epoch: 11
2022-11-28 02:36:13,604 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43877422708002006, 'Total loss': 0.43877422708002006} | train loss {'Reaction outcome loss': 0.3682303089876564, 'Total loss': 0.3682303089876564}
2022-11-28 02:36:13,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:13,604 INFO:     Epoch: 12
2022-11-28 02:36:14,348 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4742872528731823, 'Total loss': 0.4742872528731823} | train loss {'Reaction outcome loss': 0.36721867322921753, 'Total loss': 0.36721867322921753}
2022-11-28 02:36:14,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:14,348 INFO:     Epoch: 13
2022-11-28 02:36:15,084 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45678355307741597, 'Total loss': 0.45678355307741597} | train loss {'Reaction outcome loss': 0.36610454618930816, 'Total loss': 0.36610454618930816}
2022-11-28 02:36:15,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:15,085 INFO:     Epoch: 14
2022-11-28 02:36:15,824 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4654620909555392, 'Total loss': 0.4654620909555392} | train loss {'Reaction outcome loss': 0.34741323459513335, 'Total loss': 0.34741323459513335}
2022-11-28 02:36:15,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:15,825 INFO:     Epoch: 15
2022-11-28 02:36:16,564 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4411785656755621, 'Total loss': 0.4411785656755621} | train loss {'Reaction outcome loss': 0.3540601068765533, 'Total loss': 0.3540601068765533}
2022-11-28 02:36:16,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:16,565 INFO:     Epoch: 16
2022-11-28 02:36:17,304 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45583098246292636, 'Total loss': 0.45583098246292636} | train loss {'Reaction outcome loss': 0.3527288738258031, 'Total loss': 0.3527288738258031}
2022-11-28 02:36:17,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:17,304 INFO:     Epoch: 17
2022-11-28 02:36:18,043 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48855857957493176, 'Total loss': 0.48855857957493176} | train loss {'Reaction outcome loss': 0.34824157065274763, 'Total loss': 0.34824157065274763}
2022-11-28 02:36:18,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:18,043 INFO:     Epoch: 18
2022-11-28 02:36:18,782 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4647922969677232, 'Total loss': 0.4647922969677232} | train loss {'Reaction outcome loss': 0.3399695099312432, 'Total loss': 0.3399695099312432}
2022-11-28 02:36:18,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:18,782 INFO:     Epoch: 19
2022-11-28 02:36:19,520 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4638924385336312, 'Total loss': 0.4638924385336312} | train loss {'Reaction outcome loss': 0.3353433953864234, 'Total loss': 0.3353433953864234}
2022-11-28 02:36:19,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:19,520 INFO:     Epoch: 20
2022-11-28 02:36:20,258 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4646332656477832, 'Total loss': 0.4646332656477832} | train loss {'Reaction outcome loss': 0.33254534772464206, 'Total loss': 0.33254534772464206}
2022-11-28 02:36:20,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:20,258 INFO:     Epoch: 21
2022-11-28 02:36:20,997 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4355251829732548, 'Total loss': 0.4355251829732548} | train loss {'Reaction outcome loss': 0.3400138240687701, 'Total loss': 0.3400138240687701}
2022-11-28 02:36:20,997 INFO:     Found new best model at epoch 21
2022-11-28 02:36:20,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:20,998 INFO:     Epoch: 22
2022-11-28 02:36:21,736 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4625683545388959, 'Total loss': 0.4625683545388959} | train loss {'Reaction outcome loss': 0.3410123772767125, 'Total loss': 0.3410123772767125}
2022-11-28 02:36:21,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:21,736 INFO:     Epoch: 23
2022-11-28 02:36:22,481 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4718543203039603, 'Total loss': 0.4718543203039603} | train loss {'Reaction outcome loss': 0.3297503411769867, 'Total loss': 0.3297503411769867}
2022-11-28 02:36:22,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:22,481 INFO:     Epoch: 24
2022-11-28 02:36:23,223 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4425023717340082, 'Total loss': 0.4425023717340082} | train loss {'Reaction outcome loss': 0.3394636315046525, 'Total loss': 0.3394636315046525}
2022-11-28 02:36:23,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:23,223 INFO:     Epoch: 25
2022-11-28 02:36:23,967 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4811387854543599, 'Total loss': 0.4811387854543599} | train loss {'Reaction outcome loss': 0.32589452584483186, 'Total loss': 0.32589452584483186}
2022-11-28 02:36:23,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:23,967 INFO:     Epoch: 26
2022-11-28 02:36:24,710 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4579549113457853, 'Total loss': 0.4579549113457853} | train loss {'Reaction outcome loss': 0.3324343958983616, 'Total loss': 0.3324343958983616}
2022-11-28 02:36:24,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:24,710 INFO:     Epoch: 27
2022-11-28 02:36:25,452 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.445436213334853, 'Total loss': 0.445436213334853} | train loss {'Reaction outcome loss': 0.33209967518947564, 'Total loss': 0.33209967518947564}
2022-11-28 02:36:25,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:25,452 INFO:     Epoch: 28
2022-11-28 02:36:26,192 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4470098553733392, 'Total loss': 0.4470098553733392} | train loss {'Reaction outcome loss': 0.3219809816808117, 'Total loss': 0.3219809816808117}
2022-11-28 02:36:26,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:26,193 INFO:     Epoch: 29
2022-11-28 02:36:26,931 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4342046725479039, 'Total loss': 0.4342046725479039} | train loss {'Reaction outcome loss': 0.32500844497461706, 'Total loss': 0.32500844497461706}
2022-11-28 02:36:26,932 INFO:     Found new best model at epoch 29
2022-11-28 02:36:26,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:26,932 INFO:     Epoch: 30
2022-11-28 02:36:27,673 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43803341618993064, 'Total loss': 0.43803341618993064} | train loss {'Reaction outcome loss': 0.3302813118817855, 'Total loss': 0.3302813118817855}
2022-11-28 02:36:27,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:27,673 INFO:     Epoch: 31
2022-11-28 02:36:28,411 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45222171023488045, 'Total loss': 0.45222171023488045} | train loss {'Reaction outcome loss': 0.3280829782996859, 'Total loss': 0.3280829782996859}
2022-11-28 02:36:28,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:28,412 INFO:     Epoch: 32
2022-11-28 02:36:29,153 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4294657449830662, 'Total loss': 0.4294657449830662} | train loss {'Reaction outcome loss': 0.3422282982845696, 'Total loss': 0.3422282982845696}
2022-11-28 02:36:29,153 INFO:     Found new best model at epoch 32
2022-11-28 02:36:29,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:29,154 INFO:     Epoch: 33
2022-11-28 02:36:29,893 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4133561294187199, 'Total loss': 0.4133561294187199} | train loss {'Reaction outcome loss': 0.319681925797949, 'Total loss': 0.319681925797949}
2022-11-28 02:36:29,893 INFO:     Found new best model at epoch 33
2022-11-28 02:36:29,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:29,894 INFO:     Epoch: 34
2022-11-28 02:36:30,633 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4470132646912878, 'Total loss': 0.4470132646912878} | train loss {'Reaction outcome loss': 0.32275286523663266, 'Total loss': 0.32275286523663266}
2022-11-28 02:36:30,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:30,634 INFO:     Epoch: 35
2022-11-28 02:36:31,371 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44976247085089033, 'Total loss': 0.44976247085089033} | train loss {'Reaction outcome loss': 0.3260231649997283, 'Total loss': 0.3260231649997283}
2022-11-28 02:36:31,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:31,371 INFO:     Epoch: 36
2022-11-28 02:36:32,111 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4477434198964726, 'Total loss': 0.4477434198964726} | train loss {'Reaction outcome loss': 0.3199604047956515, 'Total loss': 0.3199604047956515}
2022-11-28 02:36:32,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:32,111 INFO:     Epoch: 37
2022-11-28 02:36:32,851 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47809550470926543, 'Total loss': 0.47809550470926543} | train loss {'Reaction outcome loss': 0.3315295857130265, 'Total loss': 0.3315295857130265}
2022-11-28 02:36:32,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:32,851 INFO:     Epoch: 38
2022-11-28 02:36:33,592 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4594420038840987, 'Total loss': 0.4594420038840987} | train loss {'Reaction outcome loss': 0.31939116549126956, 'Total loss': 0.31939116549126956}
2022-11-28 02:36:33,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:33,592 INFO:     Epoch: 39
2022-11-28 02:36:34,332 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4793453589081764, 'Total loss': 0.4793453589081764} | train loss {'Reaction outcome loss': 0.3134846850925562, 'Total loss': 0.3134846850925562}
2022-11-28 02:36:34,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:34,332 INFO:     Epoch: 40
2022-11-28 02:36:35,071 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4376815806396983, 'Total loss': 0.4376815806396983} | train loss {'Reaction outcome loss': 0.3244584741032853, 'Total loss': 0.3244584741032853}
2022-11-28 02:36:35,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:35,071 INFO:     Epoch: 41
2022-11-28 02:36:35,813 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.415875540707599, 'Total loss': 0.415875540707599} | train loss {'Reaction outcome loss': 0.3267589416278868, 'Total loss': 0.3267589416278868}
2022-11-28 02:36:35,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:35,814 INFO:     Epoch: 42
2022-11-28 02:36:36,556 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4589920027012175, 'Total loss': 0.4589920027012175} | train loss {'Reaction outcome loss': 0.3313838953570444, 'Total loss': 0.3313838953570444}
2022-11-28 02:36:36,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:36,557 INFO:     Epoch: 43
2022-11-28 02:36:37,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44431083513931796, 'Total loss': 0.44431083513931796} | train loss {'Reaction outcome loss': 0.3235029774965072, 'Total loss': 0.3235029774965072}
2022-11-28 02:36:37,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:37,297 INFO:     Epoch: 44
2022-11-28 02:36:38,039 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4341080273416909, 'Total loss': 0.4341080273416909} | train loss {'Reaction outcome loss': 0.3171577324672621, 'Total loss': 0.3171577324672621}
2022-11-28 02:36:38,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:38,039 INFO:     Epoch: 45
2022-11-28 02:36:38,777 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4608824910088019, 'Total loss': 0.4608824910088019} | train loss {'Reaction outcome loss': 0.30895063799558853, 'Total loss': 0.30895063799558853}
2022-11-28 02:36:38,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:38,777 INFO:     Epoch: 46
2022-11-28 02:36:39,517 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4502680277959867, 'Total loss': 0.4502680277959867} | train loss {'Reaction outcome loss': 0.31548312279034635, 'Total loss': 0.31548312279034635}
2022-11-28 02:36:39,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:39,517 INFO:     Epoch: 47
2022-11-28 02:36:40,257 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47412742945280945, 'Total loss': 0.47412742945280945} | train loss {'Reaction outcome loss': 0.3148186081526231, 'Total loss': 0.3148186081526231}
2022-11-28 02:36:40,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:40,258 INFO:     Epoch: 48
2022-11-28 02:36:41,000 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44347311928868294, 'Total loss': 0.44347311928868294} | train loss {'Reaction outcome loss': 0.33384312196653715, 'Total loss': 0.33384312196653715}
2022-11-28 02:36:41,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:41,000 INFO:     Epoch: 49
2022-11-28 02:36:41,742 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46121381409466267, 'Total loss': 0.46121381409466267} | train loss {'Reaction outcome loss': 0.3104101032018661, 'Total loss': 0.3104101032018661}
2022-11-28 02:36:41,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:41,743 INFO:     Epoch: 50
2022-11-28 02:36:42,487 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4270393177866936, 'Total loss': 0.4270393177866936} | train loss {'Reaction outcome loss': 0.3124414239610944, 'Total loss': 0.3124414239610944}
2022-11-28 02:36:42,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:42,487 INFO:     Epoch: 51
2022-11-28 02:36:43,229 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4678853428499265, 'Total loss': 0.4678853428499265} | train loss {'Reaction outcome loss': 0.3097530737215159, 'Total loss': 0.3097530737215159}
2022-11-28 02:36:43,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:43,229 INFO:     Epoch: 52
2022-11-28 02:36:43,974 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43554250997575844, 'Total loss': 0.43554250997575844} | train loss {'Reaction outcome loss': 0.32051118514975724, 'Total loss': 0.32051118514975724}
2022-11-28 02:36:43,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:43,974 INFO:     Epoch: 53
2022-11-28 02:36:44,720 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4230020564388145, 'Total loss': 0.4230020564388145} | train loss {'Reaction outcome loss': 0.3185015386160539, 'Total loss': 0.3185015386160539}
2022-11-28 02:36:44,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:44,720 INFO:     Epoch: 54
2022-11-28 02:36:45,465 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4267170158299533, 'Total loss': 0.4267170158299533} | train loss {'Reaction outcome loss': 0.32071261564079595, 'Total loss': 0.32071261564079595}
2022-11-28 02:36:45,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:45,465 INFO:     Epoch: 55
2022-11-28 02:36:46,209 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4304569929160855, 'Total loss': 0.4304569929160855} | train loss {'Reaction outcome loss': 0.3148482648085575, 'Total loss': 0.3148482648085575}
2022-11-28 02:36:46,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:46,210 INFO:     Epoch: 56
2022-11-28 02:36:46,957 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46220540966499934, 'Total loss': 0.46220540966499934} | train loss {'Reaction outcome loss': 0.3107372115461194, 'Total loss': 0.3107372115461194}
2022-11-28 02:36:46,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:46,958 INFO:     Epoch: 57
2022-11-28 02:36:47,706 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4892110761932351, 'Total loss': 0.4892110761932351} | train loss {'Reaction outcome loss': 0.3211736601226184, 'Total loss': 0.3211736601226184}
2022-11-28 02:36:47,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:47,707 INFO:     Epoch: 58
2022-11-28 02:36:48,459 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.433162224394354, 'Total loss': 0.433162224394354} | train loss {'Reaction outcome loss': 0.3039701946992047, 'Total loss': 0.3039701946992047}
2022-11-28 02:36:48,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:48,460 INFO:     Epoch: 59
2022-11-28 02:36:49,207 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42727290060032497, 'Total loss': 0.42727290060032497} | train loss {'Reaction outcome loss': 0.3219341269865328, 'Total loss': 0.3219341269865328}
2022-11-28 02:36:49,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:49,207 INFO:     Epoch: 60
2022-11-28 02:36:49,954 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46639042787931184, 'Total loss': 0.46639042787931184} | train loss {'Reaction outcome loss': 0.3059382317321641, 'Total loss': 0.3059382317321641}
2022-11-28 02:36:49,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:49,954 INFO:     Epoch: 61
2022-11-28 02:36:50,701 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4257036651569334, 'Total loss': 0.4257036651569334} | train loss {'Reaction outcome loss': 0.30465445685751585, 'Total loss': 0.30465445685751585}
2022-11-28 02:36:50,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:50,701 INFO:     Epoch: 62
2022-11-28 02:36:51,448 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4429963363165205, 'Total loss': 0.4429963363165205} | train loss {'Reaction outcome loss': 0.30634572130380844, 'Total loss': 0.30634572130380844}
2022-11-28 02:36:51,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:51,448 INFO:     Epoch: 63
2022-11-28 02:36:52,195 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4403785233470527, 'Total loss': 0.4403785233470527} | train loss {'Reaction outcome loss': 0.3122113141174219, 'Total loss': 0.3122113141174219}
2022-11-28 02:36:52,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:52,196 INFO:     Epoch: 64
2022-11-28 02:36:52,940 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43261375108903105, 'Total loss': 0.43261375108903105} | train loss {'Reaction outcome loss': 0.3078875119892918, 'Total loss': 0.3078875119892918}
2022-11-28 02:36:52,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:52,940 INFO:     Epoch: 65
2022-11-28 02:36:53,686 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40202888914129953, 'Total loss': 0.40202888914129953} | train loss {'Reaction outcome loss': 0.31254571597186886, 'Total loss': 0.31254571597186886}
2022-11-28 02:36:53,686 INFO:     Found new best model at epoch 65
2022-11-28 02:36:53,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:53,687 INFO:     Epoch: 66
2022-11-28 02:36:54,433 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43199075622992084, 'Total loss': 0.43199075622992084} | train loss {'Reaction outcome loss': 0.3047508086477007, 'Total loss': 0.3047508086477007}
2022-11-28 02:36:54,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:54,433 INFO:     Epoch: 67
2022-11-28 02:36:55,181 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41385757499797776, 'Total loss': 0.41385757499797776} | train loss {'Reaction outcome loss': 0.3181168972837682, 'Total loss': 0.3181168972837682}
2022-11-28 02:36:55,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:55,181 INFO:     Epoch: 68
2022-11-28 02:36:55,929 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4674219892106273, 'Total loss': 0.4674219892106273} | train loss {'Reaction outcome loss': 0.3102127029579513, 'Total loss': 0.3102127029579513}
2022-11-28 02:36:55,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:55,929 INFO:     Epoch: 69
2022-11-28 02:36:56,677 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4428705552762205, 'Total loss': 0.4428705552762205} | train loss {'Reaction outcome loss': 0.31085008723395213, 'Total loss': 0.31085008723395213}
2022-11-28 02:36:56,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:56,677 INFO:     Epoch: 70
2022-11-28 02:36:57,419 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4301474267108874, 'Total loss': 0.4301474267108874} | train loss {'Reaction outcome loss': 0.30967982143771894, 'Total loss': 0.30967982143771894}
2022-11-28 02:36:57,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:57,419 INFO:     Epoch: 71
2022-11-28 02:36:58,162 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4551330323923718, 'Total loss': 0.4551330323923718} | train loss {'Reaction outcome loss': 0.30725002246243616, 'Total loss': 0.30725002246243616}
2022-11-28 02:36:58,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:58,163 INFO:     Epoch: 72
2022-11-28 02:36:58,906 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4291055626659231, 'Total loss': 0.4291055626659231} | train loss {'Reaction outcome loss': 0.2984455677775704, 'Total loss': 0.2984455677775704}
2022-11-28 02:36:58,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:58,907 INFO:     Epoch: 73
2022-11-28 02:36:59,655 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45163778655908327, 'Total loss': 0.45163778655908327} | train loss {'Reaction outcome loss': 0.3077641883979038, 'Total loss': 0.3077641883979038}
2022-11-28 02:36:59,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:36:59,656 INFO:     Epoch: 74
2022-11-28 02:37:00,401 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4665475508028811, 'Total loss': 0.4665475508028811} | train loss {'Reaction outcome loss': 0.3020952024630138, 'Total loss': 0.3020952024630138}
2022-11-28 02:37:00,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:00,401 INFO:     Epoch: 75
2022-11-28 02:37:01,154 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44523310695182194, 'Total loss': 0.44523310695182194} | train loss {'Reaction outcome loss': 0.29922482845734577, 'Total loss': 0.29922482845734577}
2022-11-28 02:37:01,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:01,154 INFO:     Epoch: 76
2022-11-28 02:37:01,905 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44480087371035054, 'Total loss': 0.44480087371035054} | train loss {'Reaction outcome loss': 0.3077705868956994, 'Total loss': 0.3077705868956994}
2022-11-28 02:37:01,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:01,906 INFO:     Epoch: 77
2022-11-28 02:37:02,651 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44988144671713765, 'Total loss': 0.44988144671713765} | train loss {'Reaction outcome loss': 0.3014836494867899, 'Total loss': 0.3014836494867899}
2022-11-28 02:37:02,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:02,651 INFO:     Epoch: 78
2022-11-28 02:37:03,397 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5143228464505889, 'Total loss': 0.5143228464505889} | train loss {'Reaction outcome loss': 0.30732017858904237, 'Total loss': 0.30732017858904237}
2022-11-28 02:37:03,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:03,397 INFO:     Epoch: 79
2022-11-28 02:37:04,145 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42825389247048984, 'Total loss': 0.42825389247048984} | train loss {'Reaction outcome loss': 0.3207098725803044, 'Total loss': 0.3207098725803044}
2022-11-28 02:37:04,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:04,145 INFO:     Epoch: 80
2022-11-28 02:37:04,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4200756654820659, 'Total loss': 0.4200756654820659} | train loss {'Reaction outcome loss': 0.30523387176954014, 'Total loss': 0.30523387176954014}
2022-11-28 02:37:04,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:04,893 INFO:     Epoch: 81
2022-11-28 02:37:05,644 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43729864027012477, 'Total loss': 0.43729864027012477} | train loss {'Reaction outcome loss': 0.29935324415564535, 'Total loss': 0.29935324415564535}
2022-11-28 02:37:05,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:05,644 INFO:     Epoch: 82
2022-11-28 02:37:06,393 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4228897494348613, 'Total loss': 0.4228897494348613} | train loss {'Reaction outcome loss': 0.3073513633438519, 'Total loss': 0.3073513633438519}
2022-11-28 02:37:06,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:06,393 INFO:     Epoch: 83
2022-11-28 02:37:07,140 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4953616481613029, 'Total loss': 0.4953616481613029} | train loss {'Reaction outcome loss': 0.30269889597381866, 'Total loss': 0.30269889597381866}
2022-11-28 02:37:07,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:07,140 INFO:     Epoch: 84
2022-11-28 02:37:07,890 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.434330952480774, 'Total loss': 0.434330952480774} | train loss {'Reaction outcome loss': 0.3058424248835262, 'Total loss': 0.3058424248835262}
2022-11-28 02:37:07,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:07,890 INFO:     Epoch: 85
2022-11-28 02:37:08,638 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4390052025291053, 'Total loss': 0.4390052025291053} | train loss {'Reaction outcome loss': 0.3120645793725033, 'Total loss': 0.3120645793725033}
2022-11-28 02:37:08,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:08,638 INFO:     Epoch: 86
2022-11-28 02:37:09,388 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4092747277834199, 'Total loss': 0.4092747277834199} | train loss {'Reaction outcome loss': 0.30701983023662954, 'Total loss': 0.30701983023662954}
2022-11-28 02:37:09,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:09,388 INFO:     Epoch: 87
2022-11-28 02:37:10,133 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43767393922263925, 'Total loss': 0.43767393922263925} | train loss {'Reaction outcome loss': 0.3073324024981382, 'Total loss': 0.3073324024981382}
2022-11-28 02:37:10,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:10,133 INFO:     Epoch: 88
2022-11-28 02:37:10,883 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4390098469501192, 'Total loss': 0.4390098469501192} | train loss {'Reaction outcome loss': 0.31753904110923103, 'Total loss': 0.31753904110923103}
2022-11-28 02:37:10,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:10,883 INFO:     Epoch: 89
2022-11-28 02:37:11,631 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.437092184681784, 'Total loss': 0.437092184681784} | train loss {'Reaction outcome loss': 0.2969431735575199, 'Total loss': 0.2969431735575199}
2022-11-28 02:37:11,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:11,632 INFO:     Epoch: 90
2022-11-28 02:37:12,379 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4271082529290156, 'Total loss': 0.4271082529290156} | train loss {'Reaction outcome loss': 0.3100718984494404, 'Total loss': 0.3100718984494404}
2022-11-28 02:37:12,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:12,379 INFO:     Epoch: 91
2022-11-28 02:37:13,123 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4717649326405742, 'Total loss': 0.4717649326405742} | train loss {'Reaction outcome loss': 0.302017480819201, 'Total loss': 0.302017480819201}
2022-11-28 02:37:13,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:13,123 INFO:     Epoch: 92
2022-11-28 02:37:13,867 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4283054836771705, 'Total loss': 0.4283054836771705} | train loss {'Reaction outcome loss': 0.29763315000704355, 'Total loss': 0.29763315000704355}
2022-11-28 02:37:13,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:13,868 INFO:     Epoch: 93
2022-11-28 02:37:14,612 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.430201237343929, 'Total loss': 0.430201237343929} | train loss {'Reaction outcome loss': 0.30378145171063287, 'Total loss': 0.30378145171063287}
2022-11-28 02:37:14,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:14,613 INFO:     Epoch: 94
2022-11-28 02:37:15,361 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45347779853777453, 'Total loss': 0.45347779853777453} | train loss {'Reaction outcome loss': 0.31697038121673526, 'Total loss': 0.31697038121673526}
2022-11-28 02:37:15,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:15,361 INFO:     Epoch: 95
2022-11-28 02:37:16,107 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42237496037374844, 'Total loss': 0.42237496037374844} | train loss {'Reaction outcome loss': 0.29999963078571823, 'Total loss': 0.29999963078571823}
2022-11-28 02:37:16,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:16,108 INFO:     Epoch: 96
2022-11-28 02:37:16,854 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45568669587373734, 'Total loss': 0.45568669587373734} | train loss {'Reaction outcome loss': 0.29557038840590694, 'Total loss': 0.29557038840590694}
2022-11-28 02:37:16,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:16,854 INFO:     Epoch: 97
2022-11-28 02:37:17,600 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45380585810000246, 'Total loss': 0.45380585810000246} | train loss {'Reaction outcome loss': 0.2952638678556802, 'Total loss': 0.2952638678556802}
2022-11-28 02:37:17,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:17,600 INFO:     Epoch: 98
2022-11-28 02:37:18,346 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44831589880314743, 'Total loss': 0.44831589880314743} | train loss {'Reaction outcome loss': 0.314319080479291, 'Total loss': 0.314319080479291}
2022-11-28 02:37:18,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:18,346 INFO:     Epoch: 99
2022-11-28 02:37:19,093 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4337106306444515, 'Total loss': 0.4337106306444515} | train loss {'Reaction outcome loss': 0.30798572088990894, 'Total loss': 0.30798572088990894}
2022-11-28 02:37:19,093 INFO:     Best model found after epoch 66 of 100.
2022-11-28 02:37:19,093 INFO:   Done with stage: TRAINING
2022-11-28 02:37:19,093 INFO:   Starting stage: EVALUATION
2022-11-28 02:37:19,223 INFO:   Done with stage: EVALUATION
2022-11-28 02:37:19,224 INFO:   Leaving out SEQ value Fold_4
2022-11-28 02:37:19,236 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:37:19,236 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:37:19,886 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:37:19,886 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:37:19,955 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:37:19,955 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:37:19,955 INFO:     No hyperparam tuning for this model
2022-11-28 02:37:19,955 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:37:19,955 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:37:19,956 INFO:     None feature selector for col prot
2022-11-28 02:37:19,956 INFO:     None feature selector for col prot
2022-11-28 02:37:19,956 INFO:     None feature selector for col prot
2022-11-28 02:37:19,957 INFO:     None feature selector for col chem
2022-11-28 02:37:19,957 INFO:     None feature selector for col chem
2022-11-28 02:37:19,957 INFO:     None feature selector for col chem
2022-11-28 02:37:19,957 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:37:19,957 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:37:19,959 INFO:     Number of params in model 169741
2022-11-28 02:37:19,962 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:37:19,962 INFO:   Starting stage: TRAINING
2022-11-28 02:37:20,017 INFO:     Val loss before train {'Reaction outcome loss': 0.9785131730816581, 'Total loss': 0.9785131730816581}
2022-11-28 02:37:20,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:20,017 INFO:     Epoch: 0
2022-11-28 02:37:20,766 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5011924640698866, 'Total loss': 0.5011924640698866} | train loss {'Reaction outcome loss': 0.625081549651227, 'Total loss': 0.625081549651227}
2022-11-28 02:37:20,766 INFO:     Found new best model at epoch 0
2022-11-28 02:37:20,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:20,767 INFO:     Epoch: 1
2022-11-28 02:37:21,518 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5050051699985157, 'Total loss': 0.5050051699985157} | train loss {'Reaction outcome loss': 0.49215152527880573, 'Total loss': 0.49215152527880573}
2022-11-28 02:37:21,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:21,518 INFO:     Epoch: 2
2022-11-28 02:37:22,268 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48366766660050914, 'Total loss': 0.48366766660050914} | train loss {'Reaction outcome loss': 0.4629387712551032, 'Total loss': 0.4629387712551032}
2022-11-28 02:37:22,268 INFO:     Found new best model at epoch 2
2022-11-28 02:37:22,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:22,269 INFO:     Epoch: 3
2022-11-28 02:37:23,020 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4876136522401463, 'Total loss': 0.4876136522401463} | train loss {'Reaction outcome loss': 0.430791489862901, 'Total loss': 0.430791489862901}
2022-11-28 02:37:23,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:23,021 INFO:     Epoch: 4
2022-11-28 02:37:23,772 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45360094579783355, 'Total loss': 0.45360094579783355} | train loss {'Reaction outcome loss': 0.4149092551064395, 'Total loss': 0.4149092551064395}
2022-11-28 02:37:23,772 INFO:     Found new best model at epoch 4
2022-11-28 02:37:23,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:23,773 INFO:     Epoch: 5
2022-11-28 02:37:24,523 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46207918802445586, 'Total loss': 0.46207918802445586} | train loss {'Reaction outcome loss': 0.41193511629635504, 'Total loss': 0.41193511629635504}
2022-11-28 02:37:24,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:24,523 INFO:     Epoch: 6
2022-11-28 02:37:25,271 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44381122054024175, 'Total loss': 0.44381122054024175} | train loss {'Reaction outcome loss': 0.4184420360516199, 'Total loss': 0.4184420360516199}
2022-11-28 02:37:25,271 INFO:     Found new best model at epoch 6
2022-11-28 02:37:25,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:25,272 INFO:     Epoch: 7
2022-11-28 02:37:26,024 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44453242353417655, 'Total loss': 0.44453242353417655} | train loss {'Reaction outcome loss': 0.4010300063169919, 'Total loss': 0.4010300063169919}
2022-11-28 02:37:26,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:26,024 INFO:     Epoch: 8
2022-11-28 02:37:26,777 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43444458954036236, 'Total loss': 0.43444458954036236} | train loss {'Reaction outcome loss': 0.3888127660220451, 'Total loss': 0.3888127660220451}
2022-11-28 02:37:26,777 INFO:     Found new best model at epoch 8
2022-11-28 02:37:26,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:26,778 INFO:     Epoch: 9
2022-11-28 02:37:27,530 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4729397881098769, 'Total loss': 0.4729397881098769} | train loss {'Reaction outcome loss': 0.37394349759648204, 'Total loss': 0.37394349759648204}
2022-11-28 02:37:27,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:27,530 INFO:     Epoch: 10
2022-11-28 02:37:28,282 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4249379546804862, 'Total loss': 0.4249379546804862} | train loss {'Reaction outcome loss': 0.3757068548042342, 'Total loss': 0.3757068548042342}
2022-11-28 02:37:28,282 INFO:     Found new best model at epoch 10
2022-11-28 02:37:28,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:28,283 INFO:     Epoch: 11
2022-11-28 02:37:29,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4497281272302974, 'Total loss': 0.4497281272302974} | train loss {'Reaction outcome loss': 0.3609089061829001, 'Total loss': 0.3609089061829001}
2022-11-28 02:37:29,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:29,036 INFO:     Epoch: 12
2022-11-28 02:37:29,786 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4231562844731591, 'Total loss': 0.4231562844731591} | train loss {'Reaction outcome loss': 0.36380673993212975, 'Total loss': 0.36380673993212975}
2022-11-28 02:37:29,786 INFO:     Found new best model at epoch 12
2022-11-28 02:37:29,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:29,787 INFO:     Epoch: 13
2022-11-28 02:37:30,540 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43558454276485875, 'Total loss': 0.43558454276485875} | train loss {'Reaction outcome loss': 0.35803512280226235, 'Total loss': 0.35803512280226235}
2022-11-28 02:37:30,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:30,541 INFO:     Epoch: 14
2022-11-28 02:37:31,290 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4265257878737016, 'Total loss': 0.4265257878737016} | train loss {'Reaction outcome loss': 0.35439536623988555, 'Total loss': 0.35439536623988555}
2022-11-28 02:37:31,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:31,290 INFO:     Epoch: 15
2022-11-28 02:37:32,038 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4139240404421633, 'Total loss': 0.4139240404421633} | train loss {'Reaction outcome loss': 0.37049913116794847, 'Total loss': 0.37049913116794847}
2022-11-28 02:37:32,038 INFO:     Found new best model at epoch 15
2022-11-28 02:37:32,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:32,039 INFO:     Epoch: 16
2022-11-28 02:37:32,792 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42895864763043146, 'Total loss': 0.42895864763043146} | train loss {'Reaction outcome loss': 0.3590355237817716, 'Total loss': 0.3590355237817716}
2022-11-28 02:37:32,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:32,792 INFO:     Epoch: 17
2022-11-28 02:37:33,541 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4283518980849873, 'Total loss': 0.4283518980849873} | train loss {'Reaction outcome loss': 0.3463351991676126, 'Total loss': 0.3463351991676126}
2022-11-28 02:37:33,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:33,542 INFO:     Epoch: 18
2022-11-28 02:37:34,292 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4372173534198241, 'Total loss': 0.4372173534198241} | train loss {'Reaction outcome loss': 0.34020928308548715, 'Total loss': 0.34020928308548715}
2022-11-28 02:37:34,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:34,292 INFO:     Epoch: 19
2022-11-28 02:37:35,044 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42708079161291773, 'Total loss': 0.42708079161291773} | train loss {'Reaction outcome loss': 0.3362834238812991, 'Total loss': 0.3362834238812991}
2022-11-28 02:37:35,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:35,044 INFO:     Epoch: 20
2022-11-28 02:37:35,795 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48125170374458487, 'Total loss': 0.48125170374458487} | train loss {'Reaction outcome loss': 0.3483936862665632, 'Total loss': 0.3483936862665632}
2022-11-28 02:37:35,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:35,796 INFO:     Epoch: 21
2022-11-28 02:37:36,547 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42585068636319856, 'Total loss': 0.42585068636319856} | train loss {'Reaction outcome loss': 0.3487903910127246, 'Total loss': 0.3487903910127246}
2022-11-28 02:37:36,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:36,547 INFO:     Epoch: 22
2022-11-28 02:37:37,304 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4064170758832585, 'Total loss': 0.4064170758832585} | train loss {'Reaction outcome loss': 0.33753462760192665, 'Total loss': 0.33753462760192665}
2022-11-28 02:37:37,305 INFO:     Found new best model at epoch 22
2022-11-28 02:37:37,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:37,305 INFO:     Epoch: 23
2022-11-28 02:37:38,061 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4155366166748784, 'Total loss': 0.4155366166748784} | train loss {'Reaction outcome loss': 0.343558806820437, 'Total loss': 0.343558806820437}
2022-11-28 02:37:38,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:38,062 INFO:     Epoch: 24
2022-11-28 02:37:38,817 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4345191866159439, 'Total loss': 0.4345191866159439} | train loss {'Reaction outcome loss': 0.34713396963923565, 'Total loss': 0.34713396963923565}
2022-11-28 02:37:38,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:38,817 INFO:     Epoch: 25
2022-11-28 02:37:39,568 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44590428336100146, 'Total loss': 0.44590428336100146} | train loss {'Reaction outcome loss': 0.3554753694468393, 'Total loss': 0.3554753694468393}
2022-11-28 02:37:39,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:39,568 INFO:     Epoch: 26
2022-11-28 02:37:40,323 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4391489452259107, 'Total loss': 0.4391489452259107} | train loss {'Reaction outcome loss': 0.3390046715555403, 'Total loss': 0.3390046715555403}
2022-11-28 02:37:40,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:40,323 INFO:     Epoch: 27
2022-11-28 02:37:41,075 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44486886804754083, 'Total loss': 0.44486886804754083} | train loss {'Reaction outcome loss': 0.32498639692299763, 'Total loss': 0.32498639692299763}
2022-11-28 02:37:41,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:41,076 INFO:     Epoch: 28
2022-11-28 02:37:41,826 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4124020134860819, 'Total loss': 0.4124020134860819} | train loss {'Reaction outcome loss': 0.33439172837536346, 'Total loss': 0.33439172837536346}
2022-11-28 02:37:41,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:41,826 INFO:     Epoch: 29
2022-11-28 02:37:42,578 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4174731485545635, 'Total loss': 0.4174731485545635} | train loss {'Reaction outcome loss': 0.32811748773342203, 'Total loss': 0.32811748773342203}
2022-11-28 02:37:42,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:42,579 INFO:     Epoch: 30
2022-11-28 02:37:43,334 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39414937049150467, 'Total loss': 0.39414937049150467} | train loss {'Reaction outcome loss': 0.3275421888903085, 'Total loss': 0.3275421888903085}
2022-11-28 02:37:43,334 INFO:     Found new best model at epoch 30
2022-11-28 02:37:43,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:43,335 INFO:     Epoch: 31
2022-11-28 02:37:44,090 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42793075706471095, 'Total loss': 0.42793075706471095} | train loss {'Reaction outcome loss': 0.3642889949896558, 'Total loss': 0.3642889949896558}
2022-11-28 02:37:44,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:44,090 INFO:     Epoch: 32
2022-11-28 02:37:44,846 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4148134518076073, 'Total loss': 0.4148134518076073} | train loss {'Reaction outcome loss': 0.3363276725174927, 'Total loss': 0.3363276725174927}
2022-11-28 02:37:44,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:44,846 INFO:     Epoch: 33
2022-11-28 02:37:45,600 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40397335114804184, 'Total loss': 0.40397335114804184} | train loss {'Reaction outcome loss': 0.34439668995196276, 'Total loss': 0.34439668995196276}
2022-11-28 02:37:45,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:45,600 INFO:     Epoch: 34
2022-11-28 02:37:46,354 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4685617265376178, 'Total loss': 0.4685617265376178} | train loss {'Reaction outcome loss': 0.327995023759919, 'Total loss': 0.327995023759919}
2022-11-28 02:37:46,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:46,354 INFO:     Epoch: 35
2022-11-28 02:37:47,108 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42942854118618096, 'Total loss': 0.42942854118618096} | train loss {'Reaction outcome loss': 0.33079873851918984, 'Total loss': 0.33079873851918984}
2022-11-28 02:37:47,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:47,108 INFO:     Epoch: 36
2022-11-28 02:37:47,860 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4242275215008042, 'Total loss': 0.4242275215008042} | train loss {'Reaction outcome loss': 0.3341026453957384, 'Total loss': 0.3341026453957384}
2022-11-28 02:37:47,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:47,860 INFO:     Epoch: 37
2022-11-28 02:37:48,616 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41882218996232207, 'Total loss': 0.41882218996232207} | train loss {'Reaction outcome loss': 0.32796655230314625, 'Total loss': 0.32796655230314625}
2022-11-28 02:37:48,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:48,617 INFO:     Epoch: 38
2022-11-28 02:37:49,370 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4235515702854503, 'Total loss': 0.4235515702854503} | train loss {'Reaction outcome loss': 0.34102718507953983, 'Total loss': 0.34102718507953983}
2022-11-28 02:37:49,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:49,371 INFO:     Epoch: 39
2022-11-28 02:37:50,125 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4154232879253951, 'Total loss': 0.4154232879253951} | train loss {'Reaction outcome loss': 0.33114630119641303, 'Total loss': 0.33114630119641303}
2022-11-28 02:37:50,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:50,126 INFO:     Epoch: 40
2022-11-28 02:37:50,883 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43208069692958484, 'Total loss': 0.43208069692958484} | train loss {'Reaction outcome loss': 0.3252051231651171, 'Total loss': 0.3252051231651171}
2022-11-28 02:37:50,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:50,883 INFO:     Epoch: 41
2022-11-28 02:37:51,641 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4162941822274165, 'Total loss': 0.4162941822274165} | train loss {'Reaction outcome loss': 0.3301963760755081, 'Total loss': 0.3301963760755081}
2022-11-28 02:37:51,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:51,641 INFO:     Epoch: 42
2022-11-28 02:37:52,398 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4155559634620493, 'Total loss': 0.4155559634620493} | train loss {'Reaction outcome loss': 0.3298980031117254, 'Total loss': 0.3298980031117254}
2022-11-28 02:37:52,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:52,398 INFO:     Epoch: 43
2022-11-28 02:37:53,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4112399328838695, 'Total loss': 0.4112399328838695} | train loss {'Reaction outcome loss': 0.31961361992998644, 'Total loss': 0.31961361992998644}
2022-11-28 02:37:53,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:53,154 INFO:     Epoch: 44
2022-11-28 02:37:53,909 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4111626652831381, 'Total loss': 0.4111626652831381} | train loss {'Reaction outcome loss': 0.3218160739492791, 'Total loss': 0.3218160739492791}
2022-11-28 02:37:53,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:53,909 INFO:     Epoch: 45
2022-11-28 02:37:54,661 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4235849952833219, 'Total loss': 0.4235849952833219} | train loss {'Reaction outcome loss': 0.3270308074620571, 'Total loss': 0.3270308074620571}
2022-11-28 02:37:54,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:54,662 INFO:     Epoch: 46
2022-11-28 02:37:55,417 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4475200887430798, 'Total loss': 0.4475200887430798} | train loss {'Reaction outcome loss': 0.32390204364592246, 'Total loss': 0.32390204364592246}
2022-11-28 02:37:55,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:55,417 INFO:     Epoch: 47
2022-11-28 02:37:56,166 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.399266509169882, 'Total loss': 0.399266509169882} | train loss {'Reaction outcome loss': 0.32898271412622593, 'Total loss': 0.32898271412622593}
2022-11-28 02:37:56,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:56,167 INFO:     Epoch: 48
2022-11-28 02:37:56,917 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4300010207701813, 'Total loss': 0.4300010207701813} | train loss {'Reaction outcome loss': 0.31518516612620007, 'Total loss': 0.31518516612620007}
2022-11-28 02:37:56,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:56,917 INFO:     Epoch: 49
2022-11-28 02:37:57,670 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40434242209250276, 'Total loss': 0.40434242209250276} | train loss {'Reaction outcome loss': 0.3317093341517062, 'Total loss': 0.3317093341517062}
2022-11-28 02:37:57,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:57,670 INFO:     Epoch: 50
2022-11-28 02:37:58,419 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4171378065577962, 'Total loss': 0.4171378065577962} | train loss {'Reaction outcome loss': 0.31809764307158195, 'Total loss': 0.31809764307158195}
2022-11-28 02:37:58,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:58,419 INFO:     Epoch: 51
2022-11-28 02:37:59,172 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4262315664779056, 'Total loss': 0.4262315664779056} | train loss {'Reaction outcome loss': 0.31811575555885474, 'Total loss': 0.31811575555885474}
2022-11-28 02:37:59,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:59,172 INFO:     Epoch: 52
2022-11-28 02:37:59,922 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41559740189801564, 'Total loss': 0.41559740189801564} | train loss {'Reaction outcome loss': 0.31748125389188164, 'Total loss': 0.31748125389188164}
2022-11-28 02:37:59,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:37:59,922 INFO:     Epoch: 53
2022-11-28 02:38:00,674 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40715605663982307, 'Total loss': 0.40715605663982307} | train loss {'Reaction outcome loss': 0.3156097123695364, 'Total loss': 0.3156097123695364}
2022-11-28 02:38:00,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:00,675 INFO:     Epoch: 54
2022-11-28 02:38:01,428 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4244445166127248, 'Total loss': 0.4244445166127248} | train loss {'Reaction outcome loss': 0.3107670435629152, 'Total loss': 0.3107670435629152}
2022-11-28 02:38:01,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:01,428 INFO:     Epoch: 55
2022-11-28 02:38:02,182 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4585827788846059, 'Total loss': 0.4585827788846059} | train loss {'Reaction outcome loss': 0.3135670868431026, 'Total loss': 0.3135670868431026}
2022-11-28 02:38:02,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:02,182 INFO:     Epoch: 56
2022-11-28 02:38:02,935 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3968269425359639, 'Total loss': 0.3968269425359639} | train loss {'Reaction outcome loss': 0.3275626750911778, 'Total loss': 0.3275626750911778}
2022-11-28 02:38:02,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:02,935 INFO:     Epoch: 57
2022-11-28 02:38:03,686 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40445186621086165, 'Total loss': 0.40445186621086165} | train loss {'Reaction outcome loss': 0.32205921672529686, 'Total loss': 0.32205921672529686}
2022-11-28 02:38:03,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:03,686 INFO:     Epoch: 58
2022-11-28 02:38:04,440 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40887766636230727, 'Total loss': 0.40887766636230727} | train loss {'Reaction outcome loss': 0.31853768164866986, 'Total loss': 0.31853768164866986}
2022-11-28 02:38:04,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:04,441 INFO:     Epoch: 59
2022-11-28 02:38:05,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4350467117672617, 'Total loss': 0.4350467117672617} | train loss {'Reaction outcome loss': 0.31732751911709667, 'Total loss': 0.31732751911709667}
2022-11-28 02:38:05,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:05,193 INFO:     Epoch: 60
2022-11-28 02:38:05,941 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4301866272633726, 'Total loss': 0.4301866272633726} | train loss {'Reaction outcome loss': 0.31588065102394774, 'Total loss': 0.31588065102394774}
2022-11-28 02:38:05,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:05,941 INFO:     Epoch: 61
2022-11-28 02:38:06,687 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4031149640002034, 'Total loss': 0.4031149640002034} | train loss {'Reaction outcome loss': 0.311506877936091, 'Total loss': 0.311506877936091}
2022-11-28 02:38:06,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:06,688 INFO:     Epoch: 62
2022-11-28 02:38:07,434 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4072104242037643, 'Total loss': 0.4072104242037643} | train loss {'Reaction outcome loss': 0.3064188903521912, 'Total loss': 0.3064188903521912}
2022-11-28 02:38:07,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:07,435 INFO:     Epoch: 63
2022-11-28 02:38:08,185 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4560708918354728, 'Total loss': 0.4560708918354728} | train loss {'Reaction outcome loss': 0.30364689092163133, 'Total loss': 0.30364689092163133}
2022-11-28 02:38:08,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:08,185 INFO:     Epoch: 64
2022-11-28 02:38:08,936 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4115486568347974, 'Total loss': 0.4115486568347974} | train loss {'Reaction outcome loss': 0.31522553227370537, 'Total loss': 0.31522553227370537}
2022-11-28 02:38:08,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:08,936 INFO:     Epoch: 65
2022-11-28 02:38:09,684 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.457987001335079, 'Total loss': 0.457987001335079} | train loss {'Reaction outcome loss': 0.3135246322886181, 'Total loss': 0.3135246322886181}
2022-11-28 02:38:09,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:09,684 INFO:     Epoch: 66
2022-11-28 02:38:10,434 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43953109227798204, 'Total loss': 0.43953109227798204} | train loss {'Reaction outcome loss': 0.3242139827840875, 'Total loss': 0.3242139827840875}
2022-11-28 02:38:10,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:10,434 INFO:     Epoch: 67
2022-11-28 02:38:11,184 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40150606022639707, 'Total loss': 0.40150606022639707} | train loss {'Reaction outcome loss': 0.3079572018793961, 'Total loss': 0.3079572018793961}
2022-11-28 02:38:11,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:11,184 INFO:     Epoch: 68
2022-11-28 02:38:11,930 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.434505624527281, 'Total loss': 0.434505624527281} | train loss {'Reaction outcome loss': 0.3239656412589405, 'Total loss': 0.3239656412589405}
2022-11-28 02:38:11,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:11,931 INFO:     Epoch: 69
2022-11-28 02:38:12,681 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4356089031154459, 'Total loss': 0.4356089031154459} | train loss {'Reaction outcome loss': 0.3184588172054484, 'Total loss': 0.3184588172054484}
2022-11-28 02:38:12,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:12,681 INFO:     Epoch: 70
2022-11-28 02:38:13,428 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4261641500687057, 'Total loss': 0.4261641500687057} | train loss {'Reaction outcome loss': 0.3188092150849852, 'Total loss': 0.3188092150849852}
2022-11-28 02:38:13,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:13,429 INFO:     Epoch: 71
2022-11-28 02:38:14,176 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4268874451518059, 'Total loss': 0.4268874451518059} | train loss {'Reaction outcome loss': 0.31828132507048157, 'Total loss': 0.31828132507048157}
2022-11-28 02:38:14,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:14,176 INFO:     Epoch: 72
2022-11-28 02:38:14,926 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.396186589686708, 'Total loss': 0.396186589686708} | train loss {'Reaction outcome loss': 0.3200436377754578, 'Total loss': 0.3200436377754578}
2022-11-28 02:38:14,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:14,926 INFO:     Epoch: 73
2022-11-28 02:38:15,672 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41485808755863796, 'Total loss': 0.41485808755863796} | train loss {'Reaction outcome loss': 0.319496184828793, 'Total loss': 0.319496184828793}
2022-11-28 02:38:15,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:15,673 INFO:     Epoch: 74
2022-11-28 02:38:16,417 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42581958730112424, 'Total loss': 0.42581958730112424} | train loss {'Reaction outcome loss': 0.31650266345394285, 'Total loss': 0.31650266345394285}
2022-11-28 02:38:16,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:16,417 INFO:     Epoch: 75
2022-11-28 02:38:17,162 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4187800223854455, 'Total loss': 0.4187800223854455} | train loss {'Reaction outcome loss': 0.31078947690666203, 'Total loss': 0.31078947690666203}
2022-11-28 02:38:17,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:17,162 INFO:     Epoch: 76
2022-11-28 02:38:17,912 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41120427271181886, 'Total loss': 0.41120427271181886} | train loss {'Reaction outcome loss': 0.306038245550255, 'Total loss': 0.306038245550255}
2022-11-28 02:38:17,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:17,912 INFO:     Epoch: 77
2022-11-28 02:38:18,662 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43334971232847735, 'Total loss': 0.43334971232847735} | train loss {'Reaction outcome loss': 0.3094066602257099, 'Total loss': 0.3094066602257099}
2022-11-28 02:38:18,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:18,663 INFO:     Epoch: 78
2022-11-28 02:38:19,410 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4156617716970769, 'Total loss': 0.4156617716970769} | train loss {'Reaction outcome loss': 0.31188595352264553, 'Total loss': 0.31188595352264553}
2022-11-28 02:38:19,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:19,410 INFO:     Epoch: 79
2022-11-28 02:38:20,160 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4038946618410674, 'Total loss': 0.4038946618410674} | train loss {'Reaction outcome loss': 0.3226366772915912, 'Total loss': 0.3226366772915912}
2022-11-28 02:38:20,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:20,161 INFO:     Epoch: 80
2022-11-28 02:38:20,910 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3960099169476466, 'Total loss': 0.3960099169476466} | train loss {'Reaction outcome loss': 0.30827946341049817, 'Total loss': 0.30827946341049817}
2022-11-28 02:38:20,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:20,910 INFO:     Epoch: 81
2022-11-28 02:38:21,658 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4116412275894122, 'Total loss': 0.4116412275894122} | train loss {'Reaction outcome loss': 0.3146211108539691, 'Total loss': 0.3146211108539691}
2022-11-28 02:38:21,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:21,659 INFO:     Epoch: 82
2022-11-28 02:38:22,405 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4043473679233681, 'Total loss': 0.4043473679233681} | train loss {'Reaction outcome loss': 0.3091141139892371, 'Total loss': 0.3091141139892371}
2022-11-28 02:38:22,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:22,405 INFO:     Epoch: 83
2022-11-28 02:38:23,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4026235501197251, 'Total loss': 0.4026235501197251} | train loss {'Reaction outcome loss': 0.300972533857201, 'Total loss': 0.300972533857201}
2022-11-28 02:38:23,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:23,151 INFO:     Epoch: 84
2022-11-28 02:38:23,900 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4439097290689295, 'Total loss': 0.4439097290689295} | train loss {'Reaction outcome loss': 0.3096080363882698, 'Total loss': 0.3096080363882698}
2022-11-28 02:38:23,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:23,901 INFO:     Epoch: 85
2022-11-28 02:38:24,650 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4348741874776103, 'Total loss': 0.4348741874776103} | train loss {'Reaction outcome loss': 0.31079449911831847, 'Total loss': 0.31079449911831847}
2022-11-28 02:38:24,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:24,651 INFO:     Epoch: 86
2022-11-28 02:38:25,398 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40270487388426607, 'Total loss': 0.40270487388426607} | train loss {'Reaction outcome loss': 0.3125639638678748, 'Total loss': 0.3125639638678748}
2022-11-28 02:38:25,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:25,398 INFO:     Epoch: 87
2022-11-28 02:38:26,146 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39301204427399417, 'Total loss': 0.39301204427399417} | train loss {'Reaction outcome loss': 0.3058494590816695, 'Total loss': 0.3058494590816695}
2022-11-28 02:38:26,147 INFO:     Found new best model at epoch 87
2022-11-28 02:38:26,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:26,147 INFO:     Epoch: 88
2022-11-28 02:38:26,896 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3813429762693969, 'Total loss': 0.3813429762693969} | train loss {'Reaction outcome loss': 0.3095890016932237, 'Total loss': 0.3095890016932237}
2022-11-28 02:38:26,896 INFO:     Found new best model at epoch 88
2022-11-28 02:38:26,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:26,897 INFO:     Epoch: 89
2022-11-28 02:38:27,644 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39325556565414777, 'Total loss': 0.39325556565414777} | train loss {'Reaction outcome loss': 0.31473454075906926, 'Total loss': 0.31473454075906926}
2022-11-28 02:38:27,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:27,645 INFO:     Epoch: 90
2022-11-28 02:38:28,394 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46433207020163536, 'Total loss': 0.46433207020163536} | train loss {'Reaction outcome loss': 0.30926662309449693, 'Total loss': 0.30926662309449693}
2022-11-28 02:38:28,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:28,395 INFO:     Epoch: 91
2022-11-28 02:38:29,143 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4340748018161817, 'Total loss': 0.4340748018161817} | train loss {'Reaction outcome loss': 0.30543966718401705, 'Total loss': 0.30543966718401705}
2022-11-28 02:38:29,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:29,143 INFO:     Epoch: 92
2022-11-28 02:38:29,893 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42559920115904376, 'Total loss': 0.42559920115904376} | train loss {'Reaction outcome loss': 0.3085786958455074, 'Total loss': 0.3085786958455074}
2022-11-28 02:38:29,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:29,893 INFO:     Epoch: 93
2022-11-28 02:38:30,640 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3849140371788632, 'Total loss': 0.3849140371788632} | train loss {'Reaction outcome loss': 0.3325255567892285, 'Total loss': 0.3325255567892285}
2022-11-28 02:38:30,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:30,640 INFO:     Epoch: 94
2022-11-28 02:38:31,386 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4189340231770819, 'Total loss': 0.4189340231770819} | train loss {'Reaction outcome loss': 0.30615475234624584, 'Total loss': 0.30615475234624584}
2022-11-28 02:38:31,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:31,387 INFO:     Epoch: 95
2022-11-28 02:38:32,134 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4466229567134922, 'Total loss': 0.4466229567134922} | train loss {'Reaction outcome loss': 0.30631598000074617, 'Total loss': 0.30631598000074617}
2022-11-28 02:38:32,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:32,134 INFO:     Epoch: 96
2022-11-28 02:38:32,882 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44715407118201256, 'Total loss': 0.44715407118201256} | train loss {'Reaction outcome loss': 0.3101158437398281, 'Total loss': 0.3101158437398281}
2022-11-28 02:38:32,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:32,883 INFO:     Epoch: 97
2022-11-28 02:38:33,629 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3871172808788039, 'Total loss': 0.3871172808788039} | train loss {'Reaction outcome loss': 0.30608905302850825, 'Total loss': 0.30608905302850825}
2022-11-28 02:38:33,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:33,629 INFO:     Epoch: 98
2022-11-28 02:38:34,379 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40495811301198875, 'Total loss': 0.40495811301198875} | train loss {'Reaction outcome loss': 0.3082924583843845, 'Total loss': 0.3082924583843845}
2022-11-28 02:38:34,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:34,379 INFO:     Epoch: 99
2022-11-28 02:38:35,125 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3962073481895707, 'Total loss': 0.3962073481895707} | train loss {'Reaction outcome loss': 0.30706134812551955, 'Total loss': 0.30706134812551955}
2022-11-28 02:38:35,125 INFO:     Best model found after epoch 89 of 100.
2022-11-28 02:38:35,125 INFO:   Done with stage: TRAINING
2022-11-28 02:38:35,125 INFO:   Starting stage: EVALUATION
2022-11-28 02:38:35,251 INFO:   Done with stage: EVALUATION
2022-11-28 02:38:35,251 INFO:   Leaving out SEQ value Fold_5
2022-11-28 02:38:35,264 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:38:35,264 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:38:35,922 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:38:35,922 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:38:35,990 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:38:35,991 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:38:35,991 INFO:     No hyperparam tuning for this model
2022-11-28 02:38:35,991 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:38:35,991 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:38:35,991 INFO:     None feature selector for col prot
2022-11-28 02:38:35,992 INFO:     None feature selector for col prot
2022-11-28 02:38:35,992 INFO:     None feature selector for col prot
2022-11-28 02:38:35,992 INFO:     None feature selector for col chem
2022-11-28 02:38:35,992 INFO:     None feature selector for col chem
2022-11-28 02:38:35,992 INFO:     None feature selector for col chem
2022-11-28 02:38:35,992 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:38:35,993 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:38:35,994 INFO:     Number of params in model 169741
2022-11-28 02:38:35,997 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:38:35,997 INFO:   Starting stage: TRAINING
2022-11-28 02:38:36,051 INFO:     Val loss before train {'Reaction outcome loss': 0.9758772497827356, 'Total loss': 0.9758772497827356}
2022-11-28 02:38:36,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:36,051 INFO:     Epoch: 0
2022-11-28 02:38:36,801 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5752854509787126, 'Total loss': 0.5752854509787126} | train loss {'Reaction outcome loss': 0.6349138247389947, 'Total loss': 0.6349138247389947}
2022-11-28 02:38:36,801 INFO:     Found new best model at epoch 0
2022-11-28 02:38:36,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:36,802 INFO:     Epoch: 1
2022-11-28 02:38:37,549 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5005315440622243, 'Total loss': 0.5005315440622243} | train loss {'Reaction outcome loss': 0.4947606245236051, 'Total loss': 0.4947606245236051}
2022-11-28 02:38:37,549 INFO:     Found new best model at epoch 1
2022-11-28 02:38:37,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:37,550 INFO:     Epoch: 2
2022-11-28 02:38:38,296 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4815222431312908, 'Total loss': 0.4815222431312908} | train loss {'Reaction outcome loss': 0.4621926604079143, 'Total loss': 0.4621926604079143}
2022-11-28 02:38:38,296 INFO:     Found new best model at epoch 2
2022-11-28 02:38:38,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:38,297 INFO:     Epoch: 3
2022-11-28 02:38:39,047 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4590284512801604, 'Total loss': 0.4590284512801604} | train loss {'Reaction outcome loss': 0.43402837835732966, 'Total loss': 0.43402837835732966}
2022-11-28 02:38:39,047 INFO:     Found new best model at epoch 3
2022-11-28 02:38:39,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:39,048 INFO:     Epoch: 4
2022-11-28 02:38:39,802 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48920081521977077, 'Total loss': 0.48920081521977077} | train loss {'Reaction outcome loss': 0.4220047059559053, 'Total loss': 0.4220047059559053}
2022-11-28 02:38:39,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:39,802 INFO:     Epoch: 5
2022-11-28 02:38:40,551 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.463518581607125, 'Total loss': 0.463518581607125} | train loss {'Reaction outcome loss': 0.4120051709394301, 'Total loss': 0.4120051709394301}
2022-11-28 02:38:40,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:40,551 INFO:     Epoch: 6
2022-11-28 02:38:41,299 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45284501869570126, 'Total loss': 0.45284501869570126} | train loss {'Reaction outcome loss': 0.3980580964876759, 'Total loss': 0.3980580964876759}
2022-11-28 02:38:41,299 INFO:     Found new best model at epoch 6
2022-11-28 02:38:41,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:41,300 INFO:     Epoch: 7
2022-11-28 02:38:42,050 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4530391388318755, 'Total loss': 0.4530391388318755} | train loss {'Reaction outcome loss': 0.3941251094783506, 'Total loss': 0.3941251094783506}
2022-11-28 02:38:42,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:42,050 INFO:     Epoch: 8
2022-11-28 02:38:42,804 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.433531564745036, 'Total loss': 0.433531564745036} | train loss {'Reaction outcome loss': 0.3859306221767779, 'Total loss': 0.3859306221767779}
2022-11-28 02:38:42,804 INFO:     Found new best model at epoch 8
2022-11-28 02:38:42,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:42,805 INFO:     Epoch: 9
2022-11-28 02:38:43,559 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4582174833525311, 'Total loss': 0.4582174833525311} | train loss {'Reaction outcome loss': 0.39749395303548346, 'Total loss': 0.39749395303548346}
2022-11-28 02:38:43,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:43,559 INFO:     Epoch: 10
2022-11-28 02:38:44,311 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44978167421438475, 'Total loss': 0.44978167421438475} | train loss {'Reaction outcome loss': 0.3810248849012198, 'Total loss': 0.3810248849012198}
2022-11-28 02:38:44,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:44,312 INFO:     Epoch: 11
2022-11-28 02:38:45,062 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45755404843525455, 'Total loss': 0.45755404843525455} | train loss {'Reaction outcome loss': 0.3749656302914504, 'Total loss': 0.3749656302914504}
2022-11-28 02:38:45,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:45,062 INFO:     Epoch: 12
2022-11-28 02:38:45,813 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43939497152512724, 'Total loss': 0.43939497152512724} | train loss {'Reaction outcome loss': 0.3742151816165255, 'Total loss': 0.3742151816165255}
2022-11-28 02:38:45,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:45,814 INFO:     Epoch: 13
2022-11-28 02:38:46,567 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43454147028652107, 'Total loss': 0.43454147028652107} | train loss {'Reaction outcome loss': 0.36766081489622593, 'Total loss': 0.36766081489622593}
2022-11-28 02:38:46,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:46,567 INFO:     Epoch: 14
2022-11-28 02:38:47,319 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4476055215028199, 'Total loss': 0.4476055215028199} | train loss {'Reaction outcome loss': 0.36186106824466296, 'Total loss': 0.36186106824466296}
2022-11-28 02:38:47,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:47,319 INFO:     Epoch: 15
2022-11-28 02:38:48,072 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4690503317185424, 'Total loss': 0.4690503317185424} | train loss {'Reaction outcome loss': 0.3579584505529173, 'Total loss': 0.3579584505529173}
2022-11-28 02:38:48,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:48,072 INFO:     Epoch: 16
2022-11-28 02:38:48,824 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4982427856461568, 'Total loss': 0.4982427856461568} | train loss {'Reaction outcome loss': 0.36683421672111555, 'Total loss': 0.36683421672111555}
2022-11-28 02:38:48,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:48,824 INFO:     Epoch: 17
2022-11-28 02:38:49,575 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4556006758727811, 'Total loss': 0.4556006758727811} | train loss {'Reaction outcome loss': 0.35373264438502733, 'Total loss': 0.35373264438502733}
2022-11-28 02:38:49,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:49,576 INFO:     Epoch: 18
2022-11-28 02:38:50,327 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4212979369542815, 'Total loss': 0.4212979369542815} | train loss {'Reaction outcome loss': 0.35692530882454687, 'Total loss': 0.35692530882454687}
2022-11-28 02:38:50,328 INFO:     Found new best model at epoch 18
2022-11-28 02:38:50,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:50,329 INFO:     Epoch: 19
2022-11-28 02:38:51,080 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4543023864653977, 'Total loss': 0.4543023864653977} | train loss {'Reaction outcome loss': 0.36150545398554496, 'Total loss': 0.36150545398554496}
2022-11-28 02:38:51,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:51,080 INFO:     Epoch: 20
2022-11-28 02:38:51,832 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44994844699447806, 'Total loss': 0.44994844699447806} | train loss {'Reaction outcome loss': 0.35353594901220453, 'Total loss': 0.35353594901220453}
2022-11-28 02:38:51,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:51,832 INFO:     Epoch: 21
2022-11-28 02:38:52,581 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45259250835938886, 'Total loss': 0.45259250835938886} | train loss {'Reaction outcome loss': 0.3530197925264797, 'Total loss': 0.3530197925264797}
2022-11-28 02:38:52,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:52,581 INFO:     Epoch: 22
2022-11-28 02:38:53,331 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42747498845512216, 'Total loss': 0.42747498845512216} | train loss {'Reaction outcome loss': 0.349822714684471, 'Total loss': 0.349822714684471}
2022-11-28 02:38:53,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:53,331 INFO:     Epoch: 23
2022-11-28 02:38:54,080 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4495722707360983, 'Total loss': 0.4495722707360983} | train loss {'Reaction outcome loss': 0.34984557994551235, 'Total loss': 0.34984557994551235}
2022-11-28 02:38:54,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:54,081 INFO:     Epoch: 24
2022-11-28 02:38:54,832 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43723913468420506, 'Total loss': 0.43723913468420506} | train loss {'Reaction outcome loss': 0.3504908938681887, 'Total loss': 0.3504908938681887}
2022-11-28 02:38:54,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:54,832 INFO:     Epoch: 25
2022-11-28 02:38:55,582 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46485893292860553, 'Total loss': 0.46485893292860553} | train loss {'Reaction outcome loss': 0.3459613279349381, 'Total loss': 0.3459613279349381}
2022-11-28 02:38:55,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:55,582 INFO:     Epoch: 26
2022-11-28 02:38:56,331 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.440317151221362, 'Total loss': 0.440317151221362} | train loss {'Reaction outcome loss': 0.3474230133898316, 'Total loss': 0.3474230133898316}
2022-11-28 02:38:56,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:56,331 INFO:     Epoch: 27
2022-11-28 02:38:57,083 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4589714231816205, 'Total loss': 0.4589714231816205} | train loss {'Reaction outcome loss': 0.34605507297261107, 'Total loss': 0.34605507297261107}
2022-11-28 02:38:57,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:57,083 INFO:     Epoch: 28
2022-11-28 02:38:57,834 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4723743484778838, 'Total loss': 0.4723743484778838} | train loss {'Reaction outcome loss': 0.34388020385297074, 'Total loss': 0.34388020385297074}
2022-11-28 02:38:57,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:57,835 INFO:     Epoch: 29
2022-11-28 02:38:58,587 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45651726864955644, 'Total loss': 0.45651726864955644} | train loss {'Reaction outcome loss': 0.34296170294645334, 'Total loss': 0.34296170294645334}
2022-11-28 02:38:58,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:58,588 INFO:     Epoch: 30
2022-11-28 02:38:59,339 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4266288351606239, 'Total loss': 0.4266288351606239} | train loss {'Reaction outcome loss': 0.3393225377245295, 'Total loss': 0.3393225377245295}
2022-11-28 02:38:59,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:38:59,340 INFO:     Epoch: 31
2022-11-28 02:39:00,096 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.459711028770967, 'Total loss': 0.459711028770967} | train loss {'Reaction outcome loss': 0.3398718205430815, 'Total loss': 0.3398718205430815}
2022-11-28 02:39:00,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:00,096 INFO:     Epoch: 32
2022-11-28 02:39:00,852 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4235312882810831, 'Total loss': 0.4235312882810831} | train loss {'Reaction outcome loss': 0.3367059577797209, 'Total loss': 0.3367059577797209}
2022-11-28 02:39:00,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:00,853 INFO:     Epoch: 33
2022-11-28 02:39:01,608 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.425230618735606, 'Total loss': 0.425230618735606} | train loss {'Reaction outcome loss': 0.33714904681208635, 'Total loss': 0.33714904681208635}
2022-11-28 02:39:01,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:01,608 INFO:     Epoch: 34
2022-11-28 02:39:02,361 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4617908644405278, 'Total loss': 0.4617908644405278} | train loss {'Reaction outcome loss': 0.33213034817468257, 'Total loss': 0.33213034817468257}
2022-11-28 02:39:02,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:02,361 INFO:     Epoch: 35
2022-11-28 02:39:03,114 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4372746048664505, 'Total loss': 0.4372746048664505} | train loss {'Reaction outcome loss': 0.3282109863996025, 'Total loss': 0.3282109863996025}
2022-11-28 02:39:03,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:03,114 INFO:     Epoch: 36
2022-11-28 02:39:03,866 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4548729918897152, 'Total loss': 0.4548729918897152} | train loss {'Reaction outcome loss': 0.33787099455272956, 'Total loss': 0.33787099455272956}
2022-11-28 02:39:03,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:03,867 INFO:     Epoch: 37
2022-11-28 02:39:04,618 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4746637317267331, 'Total loss': 0.4746637317267331} | train loss {'Reaction outcome loss': 0.33920186021996124, 'Total loss': 0.33920186021996124}
2022-11-28 02:39:04,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:04,619 INFO:     Epoch: 38
2022-11-28 02:39:05,368 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4335401583124291, 'Total loss': 0.4335401583124291} | train loss {'Reaction outcome loss': 0.3348503643947263, 'Total loss': 0.3348503643947263}
2022-11-28 02:39:05,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:05,368 INFO:     Epoch: 39
2022-11-28 02:39:06,123 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44586786458438094, 'Total loss': 0.44586786458438094} | train loss {'Reaction outcome loss': 0.3286450192212097, 'Total loss': 0.3286450192212097}
2022-11-28 02:39:06,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:06,124 INFO:     Epoch: 40
2022-11-28 02:39:06,875 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42874877696687524, 'Total loss': 0.42874877696687524} | train loss {'Reaction outcome loss': 0.33387674712726184, 'Total loss': 0.33387674712726184}
2022-11-28 02:39:06,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:06,876 INFO:     Epoch: 41
2022-11-28 02:39:07,628 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5744739858941599, 'Total loss': 0.5744739858941599} | train loss {'Reaction outcome loss': 0.3309910581447184, 'Total loss': 0.3309910581447184}
2022-11-28 02:39:07,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:07,628 INFO:     Epoch: 42
2022-11-28 02:39:08,382 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4137228307398883, 'Total loss': 0.4137228307398883} | train loss {'Reaction outcome loss': 0.33893906556430364, 'Total loss': 0.33893906556430364}
2022-11-28 02:39:08,382 INFO:     Found new best model at epoch 42
2022-11-28 02:39:08,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:08,383 INFO:     Epoch: 43
2022-11-28 02:39:09,134 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4488147720694542, 'Total loss': 0.4488147720694542} | train loss {'Reaction outcome loss': 0.3333567250219564, 'Total loss': 0.3333567250219564}
2022-11-28 02:39:09,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:09,134 INFO:     Epoch: 44
2022-11-28 02:39:09,882 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4366369995881211, 'Total loss': 0.4366369995881211} | train loss {'Reaction outcome loss': 0.32482603435674984, 'Total loss': 0.32482603435674984}
2022-11-28 02:39:09,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:09,882 INFO:     Epoch: 45
2022-11-28 02:39:10,632 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4327148852700537, 'Total loss': 0.4327148852700537} | train loss {'Reaction outcome loss': 0.32422990066510055, 'Total loss': 0.32422990066510055}
2022-11-28 02:39:10,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:10,632 INFO:     Epoch: 46
2022-11-28 02:39:11,384 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43793715265664185, 'Total loss': 0.43793715265664185} | train loss {'Reaction outcome loss': 0.33057930933371665, 'Total loss': 0.33057930933371665}
2022-11-28 02:39:11,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:11,384 INFO:     Epoch: 47
2022-11-28 02:39:12,135 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42452330684120004, 'Total loss': 0.42452330684120004} | train loss {'Reaction outcome loss': 0.32560063345778373, 'Total loss': 0.32560063345778373}
2022-11-28 02:39:12,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:12,135 INFO:     Epoch: 48
2022-11-28 02:39:12,888 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4187372008507902, 'Total loss': 0.4187372008507902} | train loss {'Reaction outcome loss': 0.32742848479369235, 'Total loss': 0.32742848479369235}
2022-11-28 02:39:12,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:12,888 INFO:     Epoch: 49
2022-11-28 02:39:13,638 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4267119037156755, 'Total loss': 0.4267119037156755} | train loss {'Reaction outcome loss': 0.3197901746588609, 'Total loss': 0.3197901746588609}
2022-11-28 02:39:13,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:13,638 INFO:     Epoch: 50
2022-11-28 02:39:14,387 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4404387372461232, 'Total loss': 0.4404387372461232} | train loss {'Reaction outcome loss': 0.3257264991801593, 'Total loss': 0.3257264991801593}
2022-11-28 02:39:14,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:14,388 INFO:     Epoch: 51
2022-11-28 02:39:15,137 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4024791405959563, 'Total loss': 0.4024791405959563} | train loss {'Reaction outcome loss': 0.33509419621118613, 'Total loss': 0.33509419621118613}
2022-11-28 02:39:15,138 INFO:     Found new best model at epoch 51
2022-11-28 02:39:15,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:15,139 INFO:     Epoch: 52
2022-11-28 02:39:15,889 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45176943188363855, 'Total loss': 0.45176943188363855} | train loss {'Reaction outcome loss': 0.3296020528632066, 'Total loss': 0.3296020528632066}
2022-11-28 02:39:15,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:15,890 INFO:     Epoch: 53
2022-11-28 02:39:16,641 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44759984043511475, 'Total loss': 0.44759984043511475} | train loss {'Reaction outcome loss': 0.3212476700484272, 'Total loss': 0.3212476700484272}
2022-11-28 02:39:16,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:16,641 INFO:     Epoch: 54
2022-11-28 02:39:17,396 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44862250780517404, 'Total loss': 0.44862250780517404} | train loss {'Reaction outcome loss': 0.3150769567207223, 'Total loss': 0.3150769567207223}
2022-11-28 02:39:17,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:17,396 INFO:     Epoch: 55
2022-11-28 02:39:18,150 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4467405385591767, 'Total loss': 0.4467405385591767} | train loss {'Reaction outcome loss': 0.3203104735622483, 'Total loss': 0.3203104735622483}
2022-11-28 02:39:18,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:18,150 INFO:     Epoch: 56
2022-11-28 02:39:18,902 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44579688510434196, 'Total loss': 0.44579688510434196} | train loss {'Reaction outcome loss': 0.31524975567815766, 'Total loss': 0.31524975567815766}
2022-11-28 02:39:18,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:18,903 INFO:     Epoch: 57
2022-11-28 02:39:19,656 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4280471530827609, 'Total loss': 0.4280471530827609} | train loss {'Reaction outcome loss': 0.31946742672833706, 'Total loss': 0.31946742672833706}
2022-11-28 02:39:19,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:19,656 INFO:     Epoch: 58
2022-11-28 02:39:20,410 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4529207189652053, 'Total loss': 0.4529207189652053} | train loss {'Reaction outcome loss': 0.3190113150462088, 'Total loss': 0.3190113150462088}
2022-11-28 02:39:20,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:20,411 INFO:     Epoch: 59
2022-11-28 02:39:21,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4749271087348461, 'Total loss': 0.4749271087348461} | train loss {'Reaction outcome loss': 0.3133179635380305, 'Total loss': 0.3133179635380305}
2022-11-28 02:39:21,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:21,166 INFO:     Epoch: 60
2022-11-28 02:39:21,914 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47384362430735066, 'Total loss': 0.47384362430735066} | train loss {'Reaction outcome loss': 0.3209911192496938, 'Total loss': 0.3209911192496938}
2022-11-28 02:39:21,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:21,914 INFO:     Epoch: 61
2022-11-28 02:39:22,667 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4838851016353477, 'Total loss': 0.4838851016353477} | train loss {'Reaction outcome loss': 0.3246307912387795, 'Total loss': 0.3246307912387795}
2022-11-28 02:39:22,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:22,667 INFO:     Epoch: 62
2022-11-28 02:39:23,420 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45409573885527527, 'Total loss': 0.45409573885527527} | train loss {'Reaction outcome loss': 0.31599246368052497, 'Total loss': 0.31599246368052497}
2022-11-28 02:39:23,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:23,420 INFO:     Epoch: 63
2022-11-28 02:39:24,179 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4350805150514299, 'Total loss': 0.4350805150514299} | train loss {'Reaction outcome loss': 0.32490440265786263, 'Total loss': 0.32490440265786263}
2022-11-28 02:39:24,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:24,180 INFO:     Epoch: 64
2022-11-28 02:39:24,936 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41966914385557175, 'Total loss': 0.41966914385557175} | train loss {'Reaction outcome loss': 0.32359066677670323, 'Total loss': 0.32359066677670323}
2022-11-28 02:39:24,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:24,936 INFO:     Epoch: 65
2022-11-28 02:39:25,688 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44027793542905286, 'Total loss': 0.44027793542905286} | train loss {'Reaction outcome loss': 0.3321876432446222, 'Total loss': 0.3321876432446222}
2022-11-28 02:39:25,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:25,688 INFO:     Epoch: 66
2022-11-28 02:39:26,440 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4558191194453023, 'Total loss': 0.4558191194453023} | train loss {'Reaction outcome loss': 0.31454735360438785, 'Total loss': 0.31454735360438785}
2022-11-28 02:39:26,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:26,440 INFO:     Epoch: 67
2022-11-28 02:39:27,193 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4361660954627124, 'Total loss': 0.4361660954627124} | train loss {'Reaction outcome loss': 0.3204588650635654, 'Total loss': 0.3204588650635654}
2022-11-28 02:39:27,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:27,193 INFO:     Epoch: 68
2022-11-28 02:39:27,947 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4378822791305455, 'Total loss': 0.4378822791305455} | train loss {'Reaction outcome loss': 0.3249103047494446, 'Total loss': 0.3249103047494446}
2022-11-28 02:39:27,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:27,948 INFO:     Epoch: 69
2022-11-28 02:39:28,704 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44498485699296, 'Total loss': 0.44498485699296} | train loss {'Reaction outcome loss': 0.31737376647370474, 'Total loss': 0.31737376647370474}
2022-11-28 02:39:28,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:28,704 INFO:     Epoch: 70
2022-11-28 02:39:29,458 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.433836834335869, 'Total loss': 0.433836834335869} | train loss {'Reaction outcome loss': 0.31917871721088886, 'Total loss': 0.31917871721088886}
2022-11-28 02:39:29,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:29,458 INFO:     Epoch: 71
2022-11-28 02:39:30,222 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45356357910416345, 'Total loss': 0.45356357910416345} | train loss {'Reaction outcome loss': 0.31979676915873445, 'Total loss': 0.31979676915873445}
2022-11-28 02:39:30,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:30,222 INFO:     Epoch: 72
2022-11-28 02:39:30,976 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4546509686518799, 'Total loss': 0.4546509686518799} | train loss {'Reaction outcome loss': 0.31979406552930034, 'Total loss': 0.31979406552930034}
2022-11-28 02:39:30,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:30,976 INFO:     Epoch: 73
2022-11-28 02:39:31,725 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4194823428988457, 'Total loss': 0.4194823428988457} | train loss {'Reaction outcome loss': 0.31975732951034463, 'Total loss': 0.31975732951034463}
2022-11-28 02:39:31,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:31,725 INFO:     Epoch: 74
2022-11-28 02:39:32,474 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44059154763817787, 'Total loss': 0.44059154763817787} | train loss {'Reaction outcome loss': 0.31011140311978036, 'Total loss': 0.31011140311978036}
2022-11-28 02:39:32,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:32,475 INFO:     Epoch: 75
2022-11-28 02:39:33,224 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4403179132125594, 'Total loss': 0.4403179132125594} | train loss {'Reaction outcome loss': 0.3075036563339733, 'Total loss': 0.3075036563339733}
2022-11-28 02:39:33,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:33,225 INFO:     Epoch: 76
2022-11-28 02:39:33,975 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46234326386316255, 'Total loss': 0.46234326386316255} | train loss {'Reaction outcome loss': 0.3208478189884655, 'Total loss': 0.3208478189884655}
2022-11-28 02:39:33,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:33,975 INFO:     Epoch: 77
2022-11-28 02:39:34,730 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4370911023156209, 'Total loss': 0.4370911023156209} | train loss {'Reaction outcome loss': 0.31259994265893776, 'Total loss': 0.31259994265893776}
2022-11-28 02:39:34,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:34,731 INFO:     Epoch: 78
2022-11-28 02:39:35,479 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44612820277159865, 'Total loss': 0.44612820277159865} | train loss {'Reaction outcome loss': 0.32065330382676854, 'Total loss': 0.32065330382676854}
2022-11-28 02:39:35,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:35,480 INFO:     Epoch: 79
2022-11-28 02:39:36,230 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4153479313985868, 'Total loss': 0.4153479313985868} | train loss {'Reaction outcome loss': 0.3163336148155072, 'Total loss': 0.3163336148155072}
2022-11-28 02:39:36,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:36,230 INFO:     Epoch: 80
2022-11-28 02:39:36,981 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4697084877301346, 'Total loss': 0.4697084877301346} | train loss {'Reaction outcome loss': 0.3107577069632469, 'Total loss': 0.3107577069632469}
2022-11-28 02:39:36,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:36,981 INFO:     Epoch: 81
2022-11-28 02:39:37,729 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43336239931258286, 'Total loss': 0.43336239931258286} | train loss {'Reaction outcome loss': 0.3182107717279465, 'Total loss': 0.3182107717279465}
2022-11-28 02:39:37,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:37,729 INFO:     Epoch: 82
2022-11-28 02:39:38,479 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49090569940480316, 'Total loss': 0.49090569940480316} | train loss {'Reaction outcome loss': 0.32468925249357256, 'Total loss': 0.32468925249357256}
2022-11-28 02:39:38,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:38,479 INFO:     Epoch: 83
2022-11-28 02:39:39,236 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42778997936032037, 'Total loss': 0.42778997936032037} | train loss {'Reaction outcome loss': 0.31137583455851964, 'Total loss': 0.31137583455851964}
2022-11-28 02:39:39,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:39,236 INFO:     Epoch: 84
2022-11-28 02:39:39,991 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4412228058684956, 'Total loss': 0.4412228058684956} | train loss {'Reaction outcome loss': 0.3189003543567754, 'Total loss': 0.3189003543567754}
2022-11-28 02:39:39,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:39,991 INFO:     Epoch: 85
2022-11-28 02:39:40,746 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43516551618548954, 'Total loss': 0.43516551618548954} | train loss {'Reaction outcome loss': 0.31992080308977633, 'Total loss': 0.31992080308977633}
2022-11-28 02:39:40,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:40,746 INFO:     Epoch: 86
2022-11-28 02:39:41,490 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.424440707672726, 'Total loss': 0.424440707672726} | train loss {'Reaction outcome loss': 0.3099618056308358, 'Total loss': 0.3099618056308358}
2022-11-28 02:39:41,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:41,491 INFO:     Epoch: 87
2022-11-28 02:39:42,240 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44209431077946315, 'Total loss': 0.44209431077946315} | train loss {'Reaction outcome loss': 0.31854815898282873, 'Total loss': 0.31854815898282873}
2022-11-28 02:39:42,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:42,241 INFO:     Epoch: 88
2022-11-28 02:39:42,989 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4466809836978262, 'Total loss': 0.4466809836978262} | train loss {'Reaction outcome loss': 0.30488960246645636, 'Total loss': 0.30488960246645636}
2022-11-28 02:39:42,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:42,989 INFO:     Epoch: 89
2022-11-28 02:39:43,734 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42981215312399645, 'Total loss': 0.42981215312399645} | train loss {'Reaction outcome loss': 0.31398732994773215, 'Total loss': 0.31398732994773215}
2022-11-28 02:39:43,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:43,735 INFO:     Epoch: 90
2022-11-28 02:39:44,481 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4600698345086791, 'Total loss': 0.4600698345086791} | train loss {'Reaction outcome loss': 0.3187199830107631, 'Total loss': 0.3187199830107631}
2022-11-28 02:39:44,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:44,481 INFO:     Epoch: 91
2022-11-28 02:39:45,224 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43765939568931406, 'Total loss': 0.43765939568931406} | train loss {'Reaction outcome loss': 0.3155108779488552, 'Total loss': 0.3155108779488552}
2022-11-28 02:39:45,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:45,224 INFO:     Epoch: 92
2022-11-28 02:39:45,969 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4297967092557387, 'Total loss': 0.4297967092557387} | train loss {'Reaction outcome loss': 0.31421052385121584, 'Total loss': 0.31421052385121584}
2022-11-28 02:39:45,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:45,970 INFO:     Epoch: 93
2022-11-28 02:39:46,714 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48769241165031085, 'Total loss': 0.48769241165031085} | train loss {'Reaction outcome loss': 0.3164609403559758, 'Total loss': 0.3164609403559758}
2022-11-28 02:39:46,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:46,714 INFO:     Epoch: 94
2022-11-28 02:39:47,457 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4318862103603103, 'Total loss': 0.4318862103603103} | train loss {'Reaction outcome loss': 0.3191885636338303, 'Total loss': 0.3191885636338303}
2022-11-28 02:39:47,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:47,457 INFO:     Epoch: 95
2022-11-28 02:39:48,201 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4401479029858654, 'Total loss': 0.4401479029858654} | train loss {'Reaction outcome loss': 0.3139497212645027, 'Total loss': 0.3139497212645027}
2022-11-28 02:39:48,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:48,201 INFO:     Epoch: 96
2022-11-28 02:39:48,945 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46590185910463333, 'Total loss': 0.46590185910463333} | train loss {'Reaction outcome loss': 0.31124243963389625, 'Total loss': 0.31124243963389625}
2022-11-28 02:39:48,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:48,946 INFO:     Epoch: 97
2022-11-28 02:39:49,694 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43349182876673614, 'Total loss': 0.43349182876673614} | train loss {'Reaction outcome loss': 0.31430117861037293, 'Total loss': 0.31430117861037293}
2022-11-28 02:39:49,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:49,694 INFO:     Epoch: 98
2022-11-28 02:39:50,442 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43980069356885826, 'Total loss': 0.43980069356885826} | train loss {'Reaction outcome loss': 0.3120280084530673, 'Total loss': 0.3120280084530673}
2022-11-28 02:39:50,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:50,443 INFO:     Epoch: 99
2022-11-28 02:39:51,187 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44196016375314107, 'Total loss': 0.44196016375314107} | train loss {'Reaction outcome loss': 0.314184797146628, 'Total loss': 0.314184797146628}
2022-11-28 02:39:51,187 INFO:     Best model found after epoch 52 of 100.
2022-11-28 02:39:51,187 INFO:   Done with stage: TRAINING
2022-11-28 02:39:51,187 INFO:   Starting stage: EVALUATION
2022-11-28 02:39:51,305 INFO:   Done with stage: EVALUATION
2022-11-28 02:39:51,306 INFO:   Leaving out SEQ value Fold_6
2022-11-28 02:39:51,318 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:39:51,318 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:39:51,962 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:39:51,962 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:39:52,031 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:39:52,032 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:39:52,032 INFO:     No hyperparam tuning for this model
2022-11-28 02:39:52,032 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:39:52,032 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:39:52,033 INFO:     None feature selector for col prot
2022-11-28 02:39:52,033 INFO:     None feature selector for col prot
2022-11-28 02:39:52,033 INFO:     None feature selector for col prot
2022-11-28 02:39:52,033 INFO:     None feature selector for col chem
2022-11-28 02:39:52,033 INFO:     None feature selector for col chem
2022-11-28 02:39:52,033 INFO:     None feature selector for col chem
2022-11-28 02:39:52,034 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:39:52,034 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:39:52,035 INFO:     Number of params in model 169741
2022-11-28 02:39:52,038 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:39:52,038 INFO:   Starting stage: TRAINING
2022-11-28 02:39:52,092 INFO:     Val loss before train {'Reaction outcome loss': 0.973478065295653, 'Total loss': 0.973478065295653}
2022-11-28 02:39:52,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:52,092 INFO:     Epoch: 0
2022-11-28 02:39:52,842 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5121601505035703, 'Total loss': 0.5121601505035703} | train loss {'Reaction outcome loss': 0.6392263764094922, 'Total loss': 0.6392263764094922}
2022-11-28 02:39:52,842 INFO:     Found new best model at epoch 0
2022-11-28 02:39:52,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:52,843 INFO:     Epoch: 1
2022-11-28 02:39:53,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47416830333796417, 'Total loss': 0.47416830333796417} | train loss {'Reaction outcome loss': 0.5048835253523242, 'Total loss': 0.5048835253523242}
2022-11-28 02:39:53,590 INFO:     Found new best model at epoch 1
2022-11-28 02:39:53,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:53,591 INFO:     Epoch: 2
2022-11-28 02:39:54,338 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4547430964356119, 'Total loss': 0.4547430964356119} | train loss {'Reaction outcome loss': 0.4538889774271557, 'Total loss': 0.4538889774271557}
2022-11-28 02:39:54,338 INFO:     Found new best model at epoch 2
2022-11-28 02:39:54,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:54,339 INFO:     Epoch: 3
2022-11-28 02:39:55,084 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45644803142005747, 'Total loss': 0.45644803142005747} | train loss {'Reaction outcome loss': 0.4370135219106751, 'Total loss': 0.4370135219106751}
2022-11-28 02:39:55,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:55,084 INFO:     Epoch: 4
2022-11-28 02:39:55,830 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4458646801385013, 'Total loss': 0.4458646801385013} | train loss {'Reaction outcome loss': 0.428422344548087, 'Total loss': 0.428422344548087}
2022-11-28 02:39:55,830 INFO:     Found new best model at epoch 4
2022-11-28 02:39:55,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:55,831 INFO:     Epoch: 5
2022-11-28 02:39:56,578 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4298661838878285, 'Total loss': 0.4298661838878285} | train loss {'Reaction outcome loss': 0.41007695995992227, 'Total loss': 0.41007695995992227}
2022-11-28 02:39:56,578 INFO:     Found new best model at epoch 5
2022-11-28 02:39:56,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:56,579 INFO:     Epoch: 6
2022-11-28 02:39:57,327 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4804719259793108, 'Total loss': 0.4804719259793108} | train loss {'Reaction outcome loss': 0.39983451184666446, 'Total loss': 0.39983451184666446}
2022-11-28 02:39:57,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:57,327 INFO:     Epoch: 7
2022-11-28 02:39:58,073 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4359278333458034, 'Total loss': 0.4359278333458034} | train loss {'Reaction outcome loss': 0.39425315864143834, 'Total loss': 0.39425315864143834}
2022-11-28 02:39:58,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:58,073 INFO:     Epoch: 8
2022-11-28 02:39:58,819 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45773920213634317, 'Total loss': 0.45773920213634317} | train loss {'Reaction outcome loss': 0.3830930454536311, 'Total loss': 0.3830930454536311}
2022-11-28 02:39:58,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:58,819 INFO:     Epoch: 9
2022-11-28 02:39:59,568 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4455766274847768, 'Total loss': 0.4455766274847768} | train loss {'Reaction outcome loss': 0.37964733867275136, 'Total loss': 0.37964733867275136}
2022-11-28 02:39:59,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:39:59,568 INFO:     Epoch: 10
2022-11-28 02:40:00,316 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43776197223500773, 'Total loss': 0.43776197223500773} | train loss {'Reaction outcome loss': 0.3738584260366136, 'Total loss': 0.3738584260366136}
2022-11-28 02:40:00,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:00,316 INFO:     Epoch: 11
2022-11-28 02:40:01,063 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.434665629809553, 'Total loss': 0.434665629809553} | train loss {'Reaction outcome loss': 0.36674409948529735, 'Total loss': 0.36674409948529735}
2022-11-28 02:40:01,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:01,063 INFO:     Epoch: 12
2022-11-28 02:40:01,815 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43349385261535645, 'Total loss': 0.43349385261535645} | train loss {'Reaction outcome loss': 0.36293031022913996, 'Total loss': 0.36293031022913996}
2022-11-28 02:40:01,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:01,815 INFO:     Epoch: 13
2022-11-28 02:40:02,568 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.418613521551544, 'Total loss': 0.418613521551544} | train loss {'Reaction outcome loss': 0.3605972825880012, 'Total loss': 0.3605972825880012}
2022-11-28 02:40:02,569 INFO:     Found new best model at epoch 13
2022-11-28 02:40:02,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:02,569 INFO:     Epoch: 14
2022-11-28 02:40:03,323 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43747346238656476, 'Total loss': 0.43747346238656476} | train loss {'Reaction outcome loss': 0.3562052938336086, 'Total loss': 0.3562052938336086}
2022-11-28 02:40:03,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:03,323 INFO:     Epoch: 15
2022-11-28 02:40:04,076 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42636696926572104, 'Total loss': 0.42636696926572104} | train loss {'Reaction outcome loss': 0.3548905774650554, 'Total loss': 0.3548905774650554}
2022-11-28 02:40:04,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:04,076 INFO:     Epoch: 16
2022-11-28 02:40:04,828 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4640218083831397, 'Total loss': 0.4640218083831397} | train loss {'Reaction outcome loss': 0.34310082424311866, 'Total loss': 0.34310082424311866}
2022-11-28 02:40:04,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:04,828 INFO:     Epoch: 17
2022-11-28 02:40:05,580 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45125644256106834, 'Total loss': 0.45125644256106834} | train loss {'Reaction outcome loss': 0.34762048871526796, 'Total loss': 0.34762048871526796}
2022-11-28 02:40:05,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:05,580 INFO:     Epoch: 18
2022-11-28 02:40:06,332 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43538773025978694, 'Total loss': 0.43538773025978694} | train loss {'Reaction outcome loss': 0.3469876164209939, 'Total loss': 0.3469876164209939}
2022-11-28 02:40:06,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:06,332 INFO:     Epoch: 19
2022-11-28 02:40:07,086 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4222101741893725, 'Total loss': 0.4222101741893725} | train loss {'Reaction outcome loss': 0.34606756675507755, 'Total loss': 0.34606756675507755}
2022-11-28 02:40:07,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:07,087 INFO:     Epoch: 20
2022-11-28 02:40:07,840 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38920446061952546, 'Total loss': 0.38920446061952546} | train loss {'Reaction outcome loss': 0.33697824880120253, 'Total loss': 0.33697824880120253}
2022-11-28 02:40:07,840 INFO:     Found new best model at epoch 20
2022-11-28 02:40:07,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:07,841 INFO:     Epoch: 21
2022-11-28 02:40:08,598 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46666425178674137, 'Total loss': 0.46666425178674137} | train loss {'Reaction outcome loss': 0.33994756512824564, 'Total loss': 0.33994756512824564}
2022-11-28 02:40:08,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:08,598 INFO:     Epoch: 22
2022-11-28 02:40:09,352 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4075720811432058, 'Total loss': 0.4075720811432058} | train loss {'Reaction outcome loss': 0.33462105601304964, 'Total loss': 0.33462105601304964}
2022-11-28 02:40:09,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:09,353 INFO:     Epoch: 23
2022-11-28 02:40:10,107 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4498911459337581, 'Total loss': 0.4498911459337581} | train loss {'Reaction outcome loss': 0.3385444899059592, 'Total loss': 0.3385444899059592}
2022-11-28 02:40:10,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:10,107 INFO:     Epoch: 24
2022-11-28 02:40:10,860 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43084951862692833, 'Total loss': 0.43084951862692833} | train loss {'Reaction outcome loss': 0.3327321112456341, 'Total loss': 0.3327321112456341}
2022-11-28 02:40:10,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:10,860 INFO:     Epoch: 25
2022-11-28 02:40:11,612 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4478661265562881, 'Total loss': 0.4478661265562881} | train loss {'Reaction outcome loss': 0.3284393118153657, 'Total loss': 0.3284393118153657}
2022-11-28 02:40:11,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:11,613 INFO:     Epoch: 26
2022-11-28 02:40:12,364 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4424594427374276, 'Total loss': 0.4424594427374276} | train loss {'Reaction outcome loss': 0.3273564042042821, 'Total loss': 0.3273564042042821}
2022-11-28 02:40:12,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:12,364 INFO:     Epoch: 27
2022-11-28 02:40:13,116 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41254856064915657, 'Total loss': 0.41254856064915657} | train loss {'Reaction outcome loss': 0.332651827244028, 'Total loss': 0.332651827244028}
2022-11-28 02:40:13,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:13,116 INFO:     Epoch: 28
2022-11-28 02:40:13,874 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41493616659532895, 'Total loss': 0.41493616659532895} | train loss {'Reaction outcome loss': 0.3284234068837137, 'Total loss': 0.3284234068837137}
2022-11-28 02:40:13,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:13,874 INFO:     Epoch: 29
2022-11-28 02:40:14,631 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44878545335747977, 'Total loss': 0.44878545335747977} | train loss {'Reaction outcome loss': 0.3290379092157368, 'Total loss': 0.3290379092157368}
2022-11-28 02:40:14,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:14,631 INFO:     Epoch: 30
2022-11-28 02:40:15,388 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45047734169797465, 'Total loss': 0.45047734169797465} | train loss {'Reaction outcome loss': 0.32612571919397, 'Total loss': 0.32612571919397}
2022-11-28 02:40:15,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:15,388 INFO:     Epoch: 31
2022-11-28 02:40:16,144 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4312530095604333, 'Total loss': 0.4312530095604333} | train loss {'Reaction outcome loss': 0.3216232818160807, 'Total loss': 0.3216232818160807}
2022-11-28 02:40:16,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:16,144 INFO:     Epoch: 32
2022-11-28 02:40:16,902 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4263275692408735, 'Total loss': 0.4263275692408735} | train loss {'Reaction outcome loss': 0.3241051905638268, 'Total loss': 0.3241051905638268}
2022-11-28 02:40:16,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:16,903 INFO:     Epoch: 33
2022-11-28 02:40:17,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4020269728181037, 'Total loss': 0.4020269728181037} | train loss {'Reaction outcome loss': 0.33238690965358286, 'Total loss': 0.33238690965358286}
2022-11-28 02:40:17,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:17,660 INFO:     Epoch: 34
2022-11-28 02:40:18,415 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40218169140544807, 'Total loss': 0.40218169140544807} | train loss {'Reaction outcome loss': 0.3217130894021642, 'Total loss': 0.3217130894021642}
2022-11-28 02:40:18,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:18,416 INFO:     Epoch: 35
2022-11-28 02:40:19,173 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42181670428677037, 'Total loss': 0.42181670428677037} | train loss {'Reaction outcome loss': 0.3203093496361567, 'Total loss': 0.3203093496361567}
2022-11-28 02:40:19,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:19,173 INFO:     Epoch: 36
2022-11-28 02:40:19,933 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43715649216689845, 'Total loss': 0.43715649216689845} | train loss {'Reaction outcome loss': 0.3221139587582119, 'Total loss': 0.3221139587582119}
2022-11-28 02:40:19,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:19,934 INFO:     Epoch: 37
2022-11-28 02:40:20,684 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4127388335764408, 'Total loss': 0.4127388335764408} | train loss {'Reaction outcome loss': 0.3206027969117126, 'Total loss': 0.3206027969117126}
2022-11-28 02:40:20,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:20,685 INFO:     Epoch: 38
2022-11-28 02:40:21,443 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40491294352845714, 'Total loss': 0.40491294352845714} | train loss {'Reaction outcome loss': 0.3218768947277098, 'Total loss': 0.3218768947277098}
2022-11-28 02:40:21,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:21,443 INFO:     Epoch: 39
2022-11-28 02:40:22,196 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40528454834764654, 'Total loss': 0.40528454834764654} | train loss {'Reaction outcome loss': 0.3247830535195047, 'Total loss': 0.3247830535195047}
2022-11-28 02:40:22,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:22,196 INFO:     Epoch: 40
2022-11-28 02:40:22,953 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41178125041452324, 'Total loss': 0.41178125041452324} | train loss {'Reaction outcome loss': 0.32008483065592663, 'Total loss': 0.32008483065592663}
2022-11-28 02:40:22,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:22,954 INFO:     Epoch: 41
2022-11-28 02:40:23,710 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41723671555519104, 'Total loss': 0.41723671555519104} | train loss {'Reaction outcome loss': 0.3166912643899841, 'Total loss': 0.3166912643899841}
2022-11-28 02:40:23,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:23,711 INFO:     Epoch: 42
2022-11-28 02:40:24,466 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38617808100852097, 'Total loss': 0.38617808100852097} | train loss {'Reaction outcome loss': 0.3204178838359733, 'Total loss': 0.3204178838359733}
2022-11-28 02:40:24,466 INFO:     Found new best model at epoch 42
2022-11-28 02:40:24,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:24,467 INFO:     Epoch: 43
2022-11-28 02:40:25,219 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43255014903843403, 'Total loss': 0.43255014903843403} | train loss {'Reaction outcome loss': 0.3164974460678716, 'Total loss': 0.3164974460678716}
2022-11-28 02:40:25,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:25,220 INFO:     Epoch: 44
2022-11-28 02:40:25,972 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.420137022537264, 'Total loss': 0.420137022537264} | train loss {'Reaction outcome loss': 0.31914864396375997, 'Total loss': 0.31914864396375997}
2022-11-28 02:40:25,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:25,972 INFO:     Epoch: 45
2022-11-28 02:40:26,730 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43000432747331535, 'Total loss': 0.43000432747331535} | train loss {'Reaction outcome loss': 0.32210883603341156, 'Total loss': 0.32210883603341156}
2022-11-28 02:40:26,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:26,730 INFO:     Epoch: 46
2022-11-28 02:40:27,484 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4009430435570804, 'Total loss': 0.4009430435570804} | train loss {'Reaction outcome loss': 0.319996245821277, 'Total loss': 0.319996245821277}
2022-11-28 02:40:27,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:27,484 INFO:     Epoch: 47
2022-11-28 02:40:28,241 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39536700533194974, 'Total loss': 0.39536700533194974} | train loss {'Reaction outcome loss': 0.3240487498772, 'Total loss': 0.3240487498772}
2022-11-28 02:40:28,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:28,241 INFO:     Epoch: 48
2022-11-28 02:40:28,997 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44272649186578666, 'Total loss': 0.44272649186578666} | train loss {'Reaction outcome loss': 0.305102507403541, 'Total loss': 0.305102507403541}
2022-11-28 02:40:28,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:28,997 INFO:     Epoch: 49
2022-11-28 02:40:29,752 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4070075564086437, 'Total loss': 0.4070075564086437} | train loss {'Reaction outcome loss': 0.3185899675252937, 'Total loss': 0.3185899675252937}
2022-11-28 02:40:29,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:29,752 INFO:     Epoch: 50
2022-11-28 02:40:30,506 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.468305210836909, 'Total loss': 0.468305210836909} | train loss {'Reaction outcome loss': 0.32054726473025735, 'Total loss': 0.32054726473025735}
2022-11-28 02:40:30,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:30,506 INFO:     Epoch: 51
2022-11-28 02:40:31,263 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4263473784720356, 'Total loss': 0.4263473784720356} | train loss {'Reaction outcome loss': 0.31936161496466203, 'Total loss': 0.31936161496466203}
2022-11-28 02:40:31,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:31,264 INFO:     Epoch: 52
2022-11-28 02:40:32,016 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42188409343361855, 'Total loss': 0.42188409343361855} | train loss {'Reaction outcome loss': 0.3086901612940334, 'Total loss': 0.3086901612940334}
2022-11-28 02:40:32,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:32,017 INFO:     Epoch: 53
2022-11-28 02:40:32,769 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4343932582573457, 'Total loss': 0.4343932582573457} | train loss {'Reaction outcome loss': 0.3189314524192483, 'Total loss': 0.3189314524192483}
2022-11-28 02:40:32,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:32,769 INFO:     Epoch: 54
2022-11-28 02:40:33,523 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41193135895512323, 'Total loss': 0.41193135895512323} | train loss {'Reaction outcome loss': 0.3199340157030571, 'Total loss': 0.3199340157030571}
2022-11-28 02:40:33,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:33,524 INFO:     Epoch: 55
2022-11-28 02:40:34,281 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42292191596193746, 'Total loss': 0.42292191596193746} | train loss {'Reaction outcome loss': 0.31448890223738646, 'Total loss': 0.31448890223738646}
2022-11-28 02:40:34,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:34,281 INFO:     Epoch: 56
2022-11-28 02:40:35,034 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4246866002001546, 'Total loss': 0.4246866002001546} | train loss {'Reaction outcome loss': 0.31242880089989594, 'Total loss': 0.31242880089989594}
2022-11-28 02:40:35,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:35,035 INFO:     Epoch: 57
2022-11-28 02:40:35,787 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42383672821928153, 'Total loss': 0.42383672821928153} | train loss {'Reaction outcome loss': 0.31440228262856124, 'Total loss': 0.31440228262856124}
2022-11-28 02:40:35,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:35,787 INFO:     Epoch: 58
2022-11-28 02:40:36,538 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4098901877349073, 'Total loss': 0.4098901877349073} | train loss {'Reaction outcome loss': 0.3157560262949236, 'Total loss': 0.3157560262949236}
2022-11-28 02:40:36,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:36,538 INFO:     Epoch: 59
2022-11-28 02:40:37,292 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4012049544941295, 'Total loss': 0.4012049544941295} | train loss {'Reaction outcome loss': 0.31920145806525985, 'Total loss': 0.31920145806525985}
2022-11-28 02:40:37,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:37,292 INFO:     Epoch: 60
2022-11-28 02:40:38,046 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41261925480582495, 'Total loss': 0.41261925480582495} | train loss {'Reaction outcome loss': 0.3168372413323772, 'Total loss': 0.3168372413323772}
2022-11-28 02:40:38,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:38,046 INFO:     Epoch: 61
2022-11-28 02:40:38,798 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3975331100889228, 'Total loss': 0.3975331100889228} | train loss {'Reaction outcome loss': 0.3124489143731133, 'Total loss': 0.3124489143731133}
2022-11-28 02:40:38,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:38,798 INFO:     Epoch: 62
2022-11-28 02:40:39,548 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42298080094835977, 'Total loss': 0.42298080094835977} | train loss {'Reaction outcome loss': 0.3078028646320285, 'Total loss': 0.3078028646320285}
2022-11-28 02:40:39,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:39,548 INFO:     Epoch: 63
2022-11-28 02:40:40,301 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40737765858119185, 'Total loss': 0.40737765858119185} | train loss {'Reaction outcome loss': 0.318719572718105, 'Total loss': 0.318719572718105}
2022-11-28 02:40:40,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:40,301 INFO:     Epoch: 64
2022-11-28 02:40:41,051 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4225251962515441, 'Total loss': 0.4225251962515441} | train loss {'Reaction outcome loss': 0.30619384919203096, 'Total loss': 0.30619384919203096}
2022-11-28 02:40:41,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:41,051 INFO:     Epoch: 65
2022-11-28 02:40:41,805 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43197468973018904, 'Total loss': 0.43197468973018904} | train loss {'Reaction outcome loss': 0.30423498976855506, 'Total loss': 0.30423498976855506}
2022-11-28 02:40:41,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:41,805 INFO:     Epoch: 66
2022-11-28 02:40:42,557 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4066781984134154, 'Total loss': 0.4066781984134154} | train loss {'Reaction outcome loss': 0.3086209626147343, 'Total loss': 0.3086209626147343}
2022-11-28 02:40:42,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:42,557 INFO:     Epoch: 67
2022-11-28 02:40:43,312 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42201315256004984, 'Total loss': 0.42201315256004984} | train loss {'Reaction outcome loss': 0.31620565270103757, 'Total loss': 0.31620565270103757}
2022-11-28 02:40:43,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:43,312 INFO:     Epoch: 68
2022-11-28 02:40:44,062 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42451629957014864, 'Total loss': 0.42451629957014864} | train loss {'Reaction outcome loss': 0.314201875409532, 'Total loss': 0.314201875409532}
2022-11-28 02:40:44,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:44,063 INFO:     Epoch: 69
2022-11-28 02:40:44,816 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4062866924161261, 'Total loss': 0.4062866924161261} | train loss {'Reaction outcome loss': 0.30491047577872393, 'Total loss': 0.30491047577872393}
2022-11-28 02:40:44,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:44,816 INFO:     Epoch: 70
2022-11-28 02:40:45,571 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.431952543895353, 'Total loss': 0.431952543895353} | train loss {'Reaction outcome loss': 0.31289693794303364, 'Total loss': 0.31289693794303364}
2022-11-28 02:40:45,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:45,571 INFO:     Epoch: 71
2022-11-28 02:40:46,327 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42209145054221153, 'Total loss': 0.42209145054221153} | train loss {'Reaction outcome loss': 0.3199824940172895, 'Total loss': 0.3199824940172895}
2022-11-28 02:40:46,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:46,327 INFO:     Epoch: 72
2022-11-28 02:40:47,082 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4242417834360491, 'Total loss': 0.4242417834360491} | train loss {'Reaction outcome loss': 0.306832465553476, 'Total loss': 0.306832465553476}
2022-11-28 02:40:47,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:47,082 INFO:     Epoch: 73
2022-11-28 02:40:47,838 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42948001013560727, 'Total loss': 0.42948001013560727} | train loss {'Reaction outcome loss': 0.31893382855360547, 'Total loss': 0.31893382855360547}
2022-11-28 02:40:47,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:47,840 INFO:     Epoch: 74
2022-11-28 02:40:48,590 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3974217623472214, 'Total loss': 0.3974217623472214} | train loss {'Reaction outcome loss': 0.311759760663394, 'Total loss': 0.311759760663394}
2022-11-28 02:40:48,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:48,590 INFO:     Epoch: 75
2022-11-28 02:40:49,344 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41578450494191865, 'Total loss': 0.41578450494191865} | train loss {'Reaction outcome loss': 0.3148655112261974, 'Total loss': 0.3148655112261974}
2022-11-28 02:40:49,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:49,344 INFO:     Epoch: 76
2022-11-28 02:40:50,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4237447186288508, 'Total loss': 0.4237447186288508} | train loss {'Reaction outcome loss': 0.3123562215947576, 'Total loss': 0.3123562215947576}
2022-11-28 02:40:50,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:50,098 INFO:     Epoch: 77
2022-11-28 02:40:50,853 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43647796931591903, 'Total loss': 0.43647796931591903} | train loss {'Reaction outcome loss': 0.3132610263062581, 'Total loss': 0.3132610263062581}
2022-11-28 02:40:50,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:50,853 INFO:     Epoch: 78
2022-11-28 02:40:51,608 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4160000673410567, 'Total loss': 0.4160000673410567} | train loss {'Reaction outcome loss': 0.3167603584607282, 'Total loss': 0.3167603584607282}
2022-11-28 02:40:51,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:51,608 INFO:     Epoch: 79
2022-11-28 02:40:52,361 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44030456482009456, 'Total loss': 0.44030456482009456} | train loss {'Reaction outcome loss': 0.3153137831437972, 'Total loss': 0.3153137831437972}
2022-11-28 02:40:52,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:52,361 INFO:     Epoch: 80
2022-11-28 02:40:53,113 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4149128682911396, 'Total loss': 0.4149128682911396} | train loss {'Reaction outcome loss': 0.3108289345738388, 'Total loss': 0.3108289345738388}
2022-11-28 02:40:53,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:53,113 INFO:     Epoch: 81
2022-11-28 02:40:53,866 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4148932925679467, 'Total loss': 0.4148932925679467} | train loss {'Reaction outcome loss': 0.3139561844929572, 'Total loss': 0.3139561844929572}
2022-11-28 02:40:53,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:53,867 INFO:     Epoch: 82
2022-11-28 02:40:54,618 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44970402629538014, 'Total loss': 0.44970402629538014} | train loss {'Reaction outcome loss': 0.31047018668464116, 'Total loss': 0.31047018668464116}
2022-11-28 02:40:54,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:54,618 INFO:     Epoch: 83
2022-11-28 02:40:55,375 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43884148922833527, 'Total loss': 0.43884148922833527} | train loss {'Reaction outcome loss': 0.3039926827674912, 'Total loss': 0.3039926827674912}
2022-11-28 02:40:55,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:55,375 INFO:     Epoch: 84
2022-11-28 02:40:56,133 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4514191077852791, 'Total loss': 0.4514191077852791} | train loss {'Reaction outcome loss': 0.30801256193268683, 'Total loss': 0.30801256193268683}
2022-11-28 02:40:56,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:56,133 INFO:     Epoch: 85
2022-11-28 02:40:56,884 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40470127253369853, 'Total loss': 0.40470127253369853} | train loss {'Reaction outcome loss': 0.3115763566156308, 'Total loss': 0.3115763566156308}
2022-11-28 02:40:56,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:56,884 INFO:     Epoch: 86
2022-11-28 02:40:57,637 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4083028110590848, 'Total loss': 0.4083028110590848} | train loss {'Reaction outcome loss': 0.3145895971045379, 'Total loss': 0.3145895971045379}
2022-11-28 02:40:57,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:57,637 INFO:     Epoch: 87
2022-11-28 02:40:58,391 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39004790816794743, 'Total loss': 0.39004790816794743} | train loss {'Reaction outcome loss': 0.3150758522172128, 'Total loss': 0.3150758522172128}
2022-11-28 02:40:58,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:58,391 INFO:     Epoch: 88
2022-11-28 02:40:59,145 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3945924411104484, 'Total loss': 0.3945924411104484} | train loss {'Reaction outcome loss': 0.30439593312480756, 'Total loss': 0.30439593312480756}
2022-11-28 02:40:59,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:59,145 INFO:     Epoch: 89
2022-11-28 02:40:59,899 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4190109930932522, 'Total loss': 0.4190109930932522} | train loss {'Reaction outcome loss': 0.30491367087609345, 'Total loss': 0.30491367087609345}
2022-11-28 02:40:59,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:40:59,899 INFO:     Epoch: 90
2022-11-28 02:41:00,655 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44189835898578167, 'Total loss': 0.44189835898578167} | train loss {'Reaction outcome loss': 0.30897373609965845, 'Total loss': 0.30897373609965845}
2022-11-28 02:41:00,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:00,656 INFO:     Epoch: 91
2022-11-28 02:41:01,411 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39994774894280866, 'Total loss': 0.39994774894280866} | train loss {'Reaction outcome loss': 0.3071502584122842, 'Total loss': 0.3071502584122842}
2022-11-28 02:41:01,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:01,411 INFO:     Epoch: 92
2022-11-28 02:41:02,166 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4211749830706553, 'Total loss': 0.4211749830706553} | train loss {'Reaction outcome loss': 0.30932960331800485, 'Total loss': 0.30932960331800485}
2022-11-28 02:41:02,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:02,166 INFO:     Epoch: 93
2022-11-28 02:41:02,920 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4726671119305221, 'Total loss': 0.4726671119305221} | train loss {'Reaction outcome loss': 0.3067894452101281, 'Total loss': 0.3067894452101281}
2022-11-28 02:41:02,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:02,920 INFO:     Epoch: 94
2022-11-28 02:41:03,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39867734096267005, 'Total loss': 0.39867734096267005} | train loss {'Reaction outcome loss': 0.31513626765339603, 'Total loss': 0.31513626765339603}
2022-11-28 02:41:03,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:03,677 INFO:     Epoch: 95
2022-11-28 02:41:04,427 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40139404785904015, 'Total loss': 0.40139404785904015} | train loss {'Reaction outcome loss': 0.3070017471008243, 'Total loss': 0.3070017471008243}
2022-11-28 02:41:04,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:04,427 INFO:     Epoch: 96
2022-11-28 02:41:05,175 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41558891111476853, 'Total loss': 0.41558891111476853} | train loss {'Reaction outcome loss': 0.3055252152224702, 'Total loss': 0.3055252152224702}
2022-11-28 02:41:05,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:05,175 INFO:     Epoch: 97
2022-11-28 02:41:05,928 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42055812071670184, 'Total loss': 0.42055812071670184} | train loss {'Reaction outcome loss': 0.30594714831620934, 'Total loss': 0.30594714831620934}
2022-11-28 02:41:05,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:05,929 INFO:     Epoch: 98
2022-11-28 02:41:06,681 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4486953297799284, 'Total loss': 0.4486953297799284} | train loss {'Reaction outcome loss': 0.3049680140890902, 'Total loss': 0.3049680140890902}
2022-11-28 02:41:06,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:06,681 INFO:     Epoch: 99
2022-11-28 02:41:07,435 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40075988695025444, 'Total loss': 0.40075988695025444} | train loss {'Reaction outcome loss': 0.30747780598880303, 'Total loss': 0.30747780598880303}
2022-11-28 02:41:07,436 INFO:     Best model found after epoch 43 of 100.
2022-11-28 02:41:07,436 INFO:   Done with stage: TRAINING
2022-11-28 02:41:07,436 INFO:   Starting stage: EVALUATION
2022-11-28 02:41:07,555 INFO:   Done with stage: EVALUATION
2022-11-28 02:41:07,555 INFO:   Leaving out SEQ value Fold_7
2022-11-28 02:41:07,568 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:41:07,568 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:41:08,211 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:41:08,211 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:41:08,279 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:41:08,279 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:41:08,279 INFO:     No hyperparam tuning for this model
2022-11-28 02:41:08,279 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:41:08,279 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:41:08,280 INFO:     None feature selector for col prot
2022-11-28 02:41:08,280 INFO:     None feature selector for col prot
2022-11-28 02:41:08,280 INFO:     None feature selector for col prot
2022-11-28 02:41:08,281 INFO:     None feature selector for col chem
2022-11-28 02:41:08,281 INFO:     None feature selector for col chem
2022-11-28 02:41:08,281 INFO:     None feature selector for col chem
2022-11-28 02:41:08,281 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:41:08,281 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:41:08,283 INFO:     Number of params in model 169741
2022-11-28 02:41:08,286 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:41:08,287 INFO:   Starting stage: TRAINING
2022-11-28 02:41:08,341 INFO:     Val loss before train {'Reaction outcome loss': 1.02595861797983, 'Total loss': 1.02595861797983}
2022-11-28 02:41:08,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:08,342 INFO:     Epoch: 0
2022-11-28 02:41:09,095 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5683025500991128, 'Total loss': 0.5683025500991128} | train loss {'Reaction outcome loss': 0.6299496173617328, 'Total loss': 0.6299496173617328}
2022-11-28 02:41:09,095 INFO:     Found new best model at epoch 0
2022-11-28 02:41:09,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:09,096 INFO:     Epoch: 1
2022-11-28 02:41:09,848 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5106786990707571, 'Total loss': 0.5106786990707571} | train loss {'Reaction outcome loss': 0.4923644419382458, 'Total loss': 0.4923644419382458}
2022-11-28 02:41:09,848 INFO:     Found new best model at epoch 1
2022-11-28 02:41:09,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:09,849 INFO:     Epoch: 2
2022-11-28 02:41:10,602 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48582286455414514, 'Total loss': 0.48582286455414514} | train loss {'Reaction outcome loss': 0.456085192967161, 'Total loss': 0.456085192967161}
2022-11-28 02:41:10,602 INFO:     Found new best model at epoch 2
2022-11-28 02:41:10,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:10,603 INFO:     Epoch: 3
2022-11-28 02:41:11,356 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4720004184002226, 'Total loss': 0.4720004184002226} | train loss {'Reaction outcome loss': 0.4283586772467926, 'Total loss': 0.4283586772467926}
2022-11-28 02:41:11,356 INFO:     Found new best model at epoch 3
2022-11-28 02:41:11,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:11,357 INFO:     Epoch: 4
2022-11-28 02:41:12,107 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4584495255892927, 'Total loss': 0.4584495255892927} | train loss {'Reaction outcome loss': 0.4320245577618178, 'Total loss': 0.4320245577618178}
2022-11-28 02:41:12,107 INFO:     Found new best model at epoch 4
2022-11-28 02:41:12,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:12,108 INFO:     Epoch: 5
2022-11-28 02:41:12,861 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4660550650547851, 'Total loss': 0.4660550650547851} | train loss {'Reaction outcome loss': 0.42291400717337607, 'Total loss': 0.42291400717337607}
2022-11-28 02:41:12,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:12,861 INFO:     Epoch: 6
2022-11-28 02:41:13,612 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4800099655985832, 'Total loss': 0.4800099655985832} | train loss {'Reaction outcome loss': 0.40829066647337336, 'Total loss': 0.40829066647337336}
2022-11-28 02:41:13,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:13,613 INFO:     Epoch: 7
2022-11-28 02:41:14,369 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4538784623146057, 'Total loss': 0.4538784623146057} | train loss {'Reaction outcome loss': 0.3909768774683176, 'Total loss': 0.3909768774683176}
2022-11-28 02:41:14,370 INFO:     Found new best model at epoch 7
2022-11-28 02:41:14,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:14,371 INFO:     Epoch: 8
2022-11-28 02:41:15,124 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45777917924252426, 'Total loss': 0.45777917924252426} | train loss {'Reaction outcome loss': 0.3923834171900262, 'Total loss': 0.3923834171900262}
2022-11-28 02:41:15,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:15,124 INFO:     Epoch: 9
2022-11-28 02:41:15,877 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4517023102803664, 'Total loss': 0.4517023102803664} | train loss {'Reaction outcome loss': 0.377249000194343, 'Total loss': 0.377249000194343}
2022-11-28 02:41:15,877 INFO:     Found new best model at epoch 9
2022-11-28 02:41:15,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:15,878 INFO:     Epoch: 10
2022-11-28 02:41:16,628 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4300515473904935, 'Total loss': 0.4300515473904935} | train loss {'Reaction outcome loss': 0.37539288422718703, 'Total loss': 0.37539288422718703}
2022-11-28 02:41:16,628 INFO:     Found new best model at epoch 10
2022-11-28 02:41:16,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:16,629 INFO:     Epoch: 11
2022-11-28 02:41:17,379 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45428542691198265, 'Total loss': 0.45428542691198265} | train loss {'Reaction outcome loss': 0.3814299807314448, 'Total loss': 0.3814299807314448}
2022-11-28 02:41:17,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:17,379 INFO:     Epoch: 12
2022-11-28 02:41:18,131 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4371448274363171, 'Total loss': 0.4371448274363171} | train loss {'Reaction outcome loss': 0.36992659738432493, 'Total loss': 0.36992659738432493}
2022-11-28 02:41:18,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:18,131 INFO:     Epoch: 13
2022-11-28 02:41:18,881 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4484117484905503, 'Total loss': 0.4484117484905503} | train loss {'Reaction outcome loss': 0.3579653116010944, 'Total loss': 0.3579653116010944}
2022-11-28 02:41:18,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:18,882 INFO:     Epoch: 14
2022-11-28 02:41:19,640 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43299135548824613, 'Total loss': 0.43299135548824613} | train loss {'Reaction outcome loss': 0.3603143317734272, 'Total loss': 0.3603143317734272}
2022-11-28 02:41:19,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:19,640 INFO:     Epoch: 15
2022-11-28 02:41:20,388 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4462677054107189, 'Total loss': 0.4462677054107189} | train loss {'Reaction outcome loss': 0.3548195438708371, 'Total loss': 0.3548195438708371}
2022-11-28 02:41:20,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:20,388 INFO:     Epoch: 16
2022-11-28 02:41:21,139 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4694017097353935, 'Total loss': 0.4694017097353935} | train loss {'Reaction outcome loss': 0.3496584828927932, 'Total loss': 0.3496584828927932}
2022-11-28 02:41:21,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:21,139 INFO:     Epoch: 17
2022-11-28 02:41:21,887 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4328704987737266, 'Total loss': 0.4328704987737266} | train loss {'Reaction outcome loss': 0.3608667933446193, 'Total loss': 0.3608667933446193}
2022-11-28 02:41:21,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:21,887 INFO:     Epoch: 18
2022-11-28 02:41:22,638 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4357580742375417, 'Total loss': 0.4357580742375417} | train loss {'Reaction outcome loss': 0.35677811781298896, 'Total loss': 0.35677811781298896}
2022-11-28 02:41:22,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:22,638 INFO:     Epoch: 19
2022-11-28 02:41:23,389 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4180834916504947, 'Total loss': 0.4180834916504947} | train loss {'Reaction outcome loss': 0.3429155933712176, 'Total loss': 0.3429155933712176}
2022-11-28 02:41:23,389 INFO:     Found new best model at epoch 19
2022-11-28 02:41:23,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:23,390 INFO:     Epoch: 20
2022-11-28 02:41:24,137 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41426606611772016, 'Total loss': 0.41426606611772016} | train loss {'Reaction outcome loss': 0.33708116822397177, 'Total loss': 0.33708116822397177}
2022-11-28 02:41:24,137 INFO:     Found new best model at epoch 20
2022-11-28 02:41:24,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:24,138 INFO:     Epoch: 21
2022-11-28 02:41:24,890 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43524967608126724, 'Total loss': 0.43524967608126724} | train loss {'Reaction outcome loss': 0.35077342194946187, 'Total loss': 0.35077342194946187}
2022-11-28 02:41:24,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:24,891 INFO:     Epoch: 22
2022-11-28 02:41:25,639 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4440384381874041, 'Total loss': 0.4440384381874041} | train loss {'Reaction outcome loss': 0.3453240295955044, 'Total loss': 0.3453240295955044}
2022-11-28 02:41:25,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:25,639 INFO:     Epoch: 23
2022-11-28 02:41:26,387 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46201056749983266, 'Total loss': 0.46201056749983266} | train loss {'Reaction outcome loss': 0.34969855413625117, 'Total loss': 0.34969855413625117}
2022-11-28 02:41:26,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:26,387 INFO:     Epoch: 24
2022-11-28 02:41:27,138 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42502982304854825, 'Total loss': 0.42502982304854825} | train loss {'Reaction outcome loss': 0.3534469575157412, 'Total loss': 0.3534469575157412}
2022-11-28 02:41:27,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:27,138 INFO:     Epoch: 25
2022-11-28 02:41:27,886 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4318263043056835, 'Total loss': 0.4318263043056835} | train loss {'Reaction outcome loss': 0.34438335274153875, 'Total loss': 0.34438335274153875}
2022-11-28 02:41:27,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:27,886 INFO:     Epoch: 26
2022-11-28 02:41:28,635 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4830969246951016, 'Total loss': 0.4830969246951016} | train loss {'Reaction outcome loss': 0.32919890750274966, 'Total loss': 0.32919890750274966}
2022-11-28 02:41:28,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:28,635 INFO:     Epoch: 27
2022-11-28 02:41:29,384 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4304153255440972, 'Total loss': 0.4304153255440972} | train loss {'Reaction outcome loss': 0.3362700910399845, 'Total loss': 0.3362700910399845}
2022-11-28 02:41:29,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:29,384 INFO:     Epoch: 28
2022-11-28 02:41:30,134 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45744333704086865, 'Total loss': 0.45744333704086865} | train loss {'Reaction outcome loss': 0.33161607520421027, 'Total loss': 0.33161607520421027}
2022-11-28 02:41:30,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:30,134 INFO:     Epoch: 29
2022-11-28 02:41:30,888 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44158901037140325, 'Total loss': 0.44158901037140325} | train loss {'Reaction outcome loss': 0.32497461588095555, 'Total loss': 0.32497461588095555}
2022-11-28 02:41:30,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:30,888 INFO:     Epoch: 30
2022-11-28 02:41:31,639 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4683007831600579, 'Total loss': 0.4683007831600579} | train loss {'Reaction outcome loss': 0.3321256031120113, 'Total loss': 0.3321256031120113}
2022-11-28 02:41:31,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:31,639 INFO:     Epoch: 31
2022-11-28 02:41:32,388 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43658720193938777, 'Total loss': 0.43658720193938777} | train loss {'Reaction outcome loss': 0.3227257998697912, 'Total loss': 0.3227257998697912}
2022-11-28 02:41:32,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:32,388 INFO:     Epoch: 32
2022-11-28 02:41:33,136 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43385496498508885, 'Total loss': 0.43385496498508885} | train loss {'Reaction outcome loss': 0.3319994172058728, 'Total loss': 0.3319994172058728}
2022-11-28 02:41:33,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:33,137 INFO:     Epoch: 33
2022-11-28 02:41:33,884 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4461453685706312, 'Total loss': 0.4461453685706312} | train loss {'Reaction outcome loss': 0.3228537940518244, 'Total loss': 0.3228537940518244}
2022-11-28 02:41:33,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:33,885 INFO:     Epoch: 34
2022-11-28 02:41:34,633 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4686230458319187, 'Total loss': 0.4686230458319187} | train loss {'Reaction outcome loss': 0.3216406932545577, 'Total loss': 0.3216406932545577}
2022-11-28 02:41:34,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:34,633 INFO:     Epoch: 35
2022-11-28 02:41:35,384 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43927023390477354, 'Total loss': 0.43927023390477354} | train loss {'Reaction outcome loss': 0.33292790702902353, 'Total loss': 0.33292790702902353}
2022-11-28 02:41:35,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:35,384 INFO:     Epoch: 36
2022-11-28 02:41:36,134 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42647975784811104, 'Total loss': 0.42647975784811104} | train loss {'Reaction outcome loss': 0.32811668595706345, 'Total loss': 0.32811668595706345}
2022-11-28 02:41:36,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:36,134 INFO:     Epoch: 37
2022-11-28 02:41:36,885 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4441001665863124, 'Total loss': 0.4441001665863124} | train loss {'Reaction outcome loss': 0.3161745513016396, 'Total loss': 0.3161745513016396}
2022-11-28 02:41:36,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:36,885 INFO:     Epoch: 38
2022-11-28 02:41:37,633 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4580633995885199, 'Total loss': 0.4580633995885199} | train loss {'Reaction outcome loss': 0.3237556080496022, 'Total loss': 0.3237556080496022}
2022-11-28 02:41:37,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:37,634 INFO:     Epoch: 39
2022-11-28 02:41:38,385 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4476115662943233, 'Total loss': 0.4476115662943233} | train loss {'Reaction outcome loss': 0.3192167278484777, 'Total loss': 0.3192167278484777}
2022-11-28 02:41:38,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:38,385 INFO:     Epoch: 40
2022-11-28 02:41:39,138 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42359240183776076, 'Total loss': 0.42359240183776076} | train loss {'Reaction outcome loss': 0.3285033577970165, 'Total loss': 0.3285033577970165}
2022-11-28 02:41:39,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:39,138 INFO:     Epoch: 41
2022-11-28 02:41:39,888 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48901124637235294, 'Total loss': 0.48901124637235294} | train loss {'Reaction outcome loss': 0.3212539583071312, 'Total loss': 0.3212539583071312}
2022-11-28 02:41:39,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:39,888 INFO:     Epoch: 42
2022-11-28 02:41:40,641 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5056845430623401, 'Total loss': 0.5056845430623401} | train loss {'Reaction outcome loss': 0.3164494192521823, 'Total loss': 0.3164494192521823}
2022-11-28 02:41:40,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:40,641 INFO:     Epoch: 43
2022-11-28 02:41:41,391 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44103655947202985, 'Total loss': 0.44103655947202985} | train loss {'Reaction outcome loss': 0.3443439363686722, 'Total loss': 0.3443439363686722}
2022-11-28 02:41:41,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:41,391 INFO:     Epoch: 44
2022-11-28 02:41:42,142 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43896276368336246, 'Total loss': 0.43896276368336246} | train loss {'Reaction outcome loss': 0.31726574325021584, 'Total loss': 0.31726574325021584}
2022-11-28 02:41:42,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:42,142 INFO:     Epoch: 45
2022-11-28 02:41:42,895 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44992057979106903, 'Total loss': 0.44992057979106903} | train loss {'Reaction outcome loss': 0.32076556556801566, 'Total loss': 0.32076556556801566}
2022-11-28 02:41:42,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:42,895 INFO:     Epoch: 46
2022-11-28 02:41:43,644 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4394375632771037, 'Total loss': 0.4394375632771037} | train loss {'Reaction outcome loss': 0.33312774531030465, 'Total loss': 0.33312774531030465}
2022-11-28 02:41:43,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:43,644 INFO:     Epoch: 47
2022-11-28 02:41:44,396 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.420185519551689, 'Total loss': 0.420185519551689} | train loss {'Reaction outcome loss': 0.3218104503898003, 'Total loss': 0.3218104503898003}
2022-11-28 02:41:44,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:44,396 INFO:     Epoch: 48
2022-11-28 02:41:45,145 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4204797927628864, 'Total loss': 0.4204797927628864} | train loss {'Reaction outcome loss': 0.308150977486375, 'Total loss': 0.308150977486375}
2022-11-28 02:41:45,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:45,145 INFO:     Epoch: 49
2022-11-28 02:41:45,897 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41936501081694255, 'Total loss': 0.41936501081694255} | train loss {'Reaction outcome loss': 0.30618144936769115, 'Total loss': 0.30618144936769115}
2022-11-28 02:41:45,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:45,897 INFO:     Epoch: 50
2022-11-28 02:41:46,665 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4144969545304775, 'Total loss': 0.4144969545304775} | train loss {'Reaction outcome loss': 0.3204961824211997, 'Total loss': 0.3204961824211997}
2022-11-28 02:41:46,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:46,665 INFO:     Epoch: 51
2022-11-28 02:41:47,414 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4264421418986537, 'Total loss': 0.4264421418986537} | train loss {'Reaction outcome loss': 0.3125539881427987, 'Total loss': 0.3125539881427987}
2022-11-28 02:41:47,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:47,414 INFO:     Epoch: 52
2022-11-28 02:41:48,163 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4825923422520811, 'Total loss': 0.4825923422520811} | train loss {'Reaction outcome loss': 0.3149436942267756, 'Total loss': 0.3149436942267756}
2022-11-28 02:41:48,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:48,163 INFO:     Epoch: 53
2022-11-28 02:41:48,916 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4856180961836468, 'Total loss': 0.4856180961836468} | train loss {'Reaction outcome loss': 0.3145968726560896, 'Total loss': 0.3145968726560896}
2022-11-28 02:41:48,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:48,916 INFO:     Epoch: 54
2022-11-28 02:41:49,667 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4111935989084569, 'Total loss': 0.4111935989084569} | train loss {'Reaction outcome loss': 0.32577822200561823, 'Total loss': 0.32577822200561823}
2022-11-28 02:41:49,668 INFO:     Found new best model at epoch 54
2022-11-28 02:41:49,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:49,669 INFO:     Epoch: 55
2022-11-28 02:41:50,419 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4368737279014154, 'Total loss': 0.4368737279014154} | train loss {'Reaction outcome loss': 0.3424827903810783, 'Total loss': 0.3424827903810783}
2022-11-28 02:41:50,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:50,419 INFO:     Epoch: 56
2022-11-28 02:41:51,173 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45676595311273227, 'Total loss': 0.45676595311273227} | train loss {'Reaction outcome loss': 0.35444234331187446, 'Total loss': 0.35444234331187446}
2022-11-28 02:41:51,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:51,173 INFO:     Epoch: 57
2022-11-28 02:41:51,924 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4181362752887336, 'Total loss': 0.4181362752887336} | train loss {'Reaction outcome loss': 0.328997906828384, 'Total loss': 0.328997906828384}
2022-11-28 02:41:51,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:51,924 INFO:     Epoch: 58
2022-11-28 02:41:52,678 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4383149658414451, 'Total loss': 0.4383149658414451} | train loss {'Reaction outcome loss': 0.3131451525306895, 'Total loss': 0.3131451525306895}
2022-11-28 02:41:52,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:52,678 INFO:     Epoch: 59
2022-11-28 02:41:53,431 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44756990298628807, 'Total loss': 0.44756990298628807} | train loss {'Reaction outcome loss': 0.3137629867685951, 'Total loss': 0.3137629867685951}
2022-11-28 02:41:53,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:53,431 INFO:     Epoch: 60
2022-11-28 02:41:54,181 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4430663622915745, 'Total loss': 0.4430663622915745} | train loss {'Reaction outcome loss': 0.3295661854418183, 'Total loss': 0.3295661854418183}
2022-11-28 02:41:54,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:54,181 INFO:     Epoch: 61
2022-11-28 02:41:54,929 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41659634899009357, 'Total loss': 0.41659634899009357} | train loss {'Reaction outcome loss': 0.32137551345685234, 'Total loss': 0.32137551345685234}
2022-11-28 02:41:54,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:54,929 INFO:     Epoch: 62
2022-11-28 02:41:55,679 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43457629260691727, 'Total loss': 0.43457629260691727} | train loss {'Reaction outcome loss': 0.3271003520108669, 'Total loss': 0.3271003520108669}
2022-11-28 02:41:55,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:55,679 INFO:     Epoch: 63
2022-11-28 02:41:56,428 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44339068030769174, 'Total loss': 0.44339068030769174} | train loss {'Reaction outcome loss': 0.3148042757199843, 'Total loss': 0.3148042757199843}
2022-11-28 02:41:56,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:56,428 INFO:     Epoch: 64
2022-11-28 02:41:57,176 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4521870657124303, 'Total loss': 0.4521870657124303} | train loss {'Reaction outcome loss': 0.300990279145569, 'Total loss': 0.300990279145569}
2022-11-28 02:41:57,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:57,177 INFO:     Epoch: 65
2022-11-28 02:41:57,925 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4278294759040529, 'Total loss': 0.4278294759040529} | train loss {'Reaction outcome loss': 0.3244856929006847, 'Total loss': 0.3244856929006847}
2022-11-28 02:41:57,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:57,925 INFO:     Epoch: 66
2022-11-28 02:41:58,672 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.406270448457111, 'Total loss': 0.406270448457111} | train loss {'Reaction outcome loss': 0.3123801893550857, 'Total loss': 0.3123801893550857}
2022-11-28 02:41:58,673 INFO:     Found new best model at epoch 66
2022-11-28 02:41:58,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:58,673 INFO:     Epoch: 67
2022-11-28 02:41:59,420 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43854784084991977, 'Total loss': 0.43854784084991977} | train loss {'Reaction outcome loss': 0.3135396772882475, 'Total loss': 0.3135396772882475}
2022-11-28 02:41:59,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:41:59,420 INFO:     Epoch: 68
2022-11-28 02:42:00,171 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40513004057786683, 'Total loss': 0.40513004057786683} | train loss {'Reaction outcome loss': 0.32147394844730526, 'Total loss': 0.32147394844730526}
2022-11-28 02:42:00,171 INFO:     Found new best model at epoch 68
2022-11-28 02:42:00,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:00,172 INFO:     Epoch: 69
2022-11-28 02:42:00,918 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42605857508765027, 'Total loss': 0.42605857508765027} | train loss {'Reaction outcome loss': 0.3039797975602541, 'Total loss': 0.3039797975602541}
2022-11-28 02:42:00,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:00,918 INFO:     Epoch: 70
2022-11-28 02:42:01,668 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4334530738944357, 'Total loss': 0.4334530738944357} | train loss {'Reaction outcome loss': 0.3169960626947735, 'Total loss': 0.3169960626947735}
2022-11-28 02:42:01,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:01,668 INFO:     Epoch: 71
2022-11-28 02:42:02,419 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4278891496360302, 'Total loss': 0.4278891496360302} | train loss {'Reaction outcome loss': 0.3294638987283716, 'Total loss': 0.3294638987283716}
2022-11-28 02:42:02,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:02,420 INFO:     Epoch: 72
2022-11-28 02:42:03,167 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4120341437784108, 'Total loss': 0.4120341437784108} | train loss {'Reaction outcome loss': 0.30229720358665174, 'Total loss': 0.30229720358665174}
2022-11-28 02:42:03,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:03,167 INFO:     Epoch: 73
2022-11-28 02:42:03,917 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4228966852480715, 'Total loss': 0.4228966852480715} | train loss {'Reaction outcome loss': 0.3120043825071592, 'Total loss': 0.3120043825071592}
2022-11-28 02:42:03,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:03,917 INFO:     Epoch: 74
2022-11-28 02:42:04,667 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43176737224513834, 'Total loss': 0.43176737224513834} | train loss {'Reaction outcome loss': 0.3327792140877681, 'Total loss': 0.3327792140877681}
2022-11-28 02:42:04,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:04,667 INFO:     Epoch: 75
2022-11-28 02:42:05,416 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41235302591865713, 'Total loss': 0.41235302591865713} | train loss {'Reaction outcome loss': 0.3121540872342432, 'Total loss': 0.3121540872342432}
2022-11-28 02:42:05,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:05,417 INFO:     Epoch: 76
2022-11-28 02:42:06,164 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41408762098713353, 'Total loss': 0.41408762098713353} | train loss {'Reaction outcome loss': 0.3045318872490634, 'Total loss': 0.3045318872490634}
2022-11-28 02:42:06,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:06,164 INFO:     Epoch: 77
2022-11-28 02:42:06,913 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48642976344986394, 'Total loss': 0.48642976344986394} | train loss {'Reaction outcome loss': 0.3108836676518203, 'Total loss': 0.3108836676518203}
2022-11-28 02:42:06,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:06,913 INFO:     Epoch: 78
2022-11-28 02:42:07,661 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4280815748497844, 'Total loss': 0.4280815748497844} | train loss {'Reaction outcome loss': 0.30917644824810053, 'Total loss': 0.30917644824810053}
2022-11-28 02:42:07,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:07,662 INFO:     Epoch: 79
2022-11-28 02:42:08,411 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42323389717123727, 'Total loss': 0.42323389717123727} | train loss {'Reaction outcome loss': 0.30754016395582845, 'Total loss': 0.30754016395582845}
2022-11-28 02:42:08,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:08,412 INFO:     Epoch: 80
2022-11-28 02:42:09,161 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4319018318571828, 'Total loss': 0.4319018318571828} | train loss {'Reaction outcome loss': 0.31845070041625606, 'Total loss': 0.31845070041625606}
2022-11-28 02:42:09,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:09,161 INFO:     Epoch: 81
2022-11-28 02:42:09,909 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4573339288207618, 'Total loss': 0.4573339288207618} | train loss {'Reaction outcome loss': 0.3026461531276162, 'Total loss': 0.3026461531276162}
2022-11-28 02:42:09,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:09,910 INFO:     Epoch: 82
2022-11-28 02:42:10,659 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.442422742870721, 'Total loss': 0.442422742870721} | train loss {'Reaction outcome loss': 0.3103451323111048, 'Total loss': 0.3103451323111048}
2022-11-28 02:42:10,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:10,659 INFO:     Epoch: 83
2022-11-28 02:42:11,408 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.440141585232182, 'Total loss': 0.440141585232182} | train loss {'Reaction outcome loss': 0.31988754226007926, 'Total loss': 0.31988754226007926}
2022-11-28 02:42:11,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:11,408 INFO:     Epoch: 84
2022-11-28 02:42:12,157 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42557837610894983, 'Total loss': 0.42557837610894983} | train loss {'Reaction outcome loss': 0.32296978036763696, 'Total loss': 0.32296978036763696}
2022-11-28 02:42:12,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:12,157 INFO:     Epoch: 85
2022-11-28 02:42:12,903 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4231126084923744, 'Total loss': 0.4231126084923744} | train loss {'Reaction outcome loss': 0.3206054328786217, 'Total loss': 0.3206054328786217}
2022-11-28 02:42:12,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:12,903 INFO:     Epoch: 86
2022-11-28 02:42:13,649 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45140874792229047, 'Total loss': 0.45140874792229047} | train loss {'Reaction outcome loss': 0.3116928832794008, 'Total loss': 0.3116928832794008}
2022-11-28 02:42:13,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:13,649 INFO:     Epoch: 87
2022-11-28 02:42:14,400 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39949610930952156, 'Total loss': 0.39949610930952156} | train loss {'Reaction outcome loss': 0.31211963244657287, 'Total loss': 0.31211963244657287}
2022-11-28 02:42:14,400 INFO:     Found new best model at epoch 87
2022-11-28 02:42:14,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:14,401 INFO:     Epoch: 88
2022-11-28 02:42:15,152 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44991324977441266, 'Total loss': 0.44991324977441266} | train loss {'Reaction outcome loss': 0.3154283875546716, 'Total loss': 0.3154283875546716}
2022-11-28 02:42:15,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:15,152 INFO:     Epoch: 89
2022-11-28 02:42:15,908 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47822227532213385, 'Total loss': 0.47822227532213385} | train loss {'Reaction outcome loss': 0.30259602613415315, 'Total loss': 0.30259602613415315}
2022-11-28 02:42:15,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:15,908 INFO:     Epoch: 90
2022-11-28 02:42:16,662 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4499414629218253, 'Total loss': 0.4499414629218253} | train loss {'Reaction outcome loss': 0.31103811117439617, 'Total loss': 0.31103811117439617}
2022-11-28 02:42:16,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:16,662 INFO:     Epoch: 91
2022-11-28 02:42:17,412 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43890127751298924, 'Total loss': 0.43890127751298924} | train loss {'Reaction outcome loss': 0.32519324442092706, 'Total loss': 0.32519324442092706}
2022-11-28 02:42:17,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:17,413 INFO:     Epoch: 92
2022-11-28 02:42:18,163 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4052312240343202, 'Total loss': 0.4052312240343202} | train loss {'Reaction outcome loss': 0.3073688183990326, 'Total loss': 0.3073688183990326}
2022-11-28 02:42:18,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:18,163 INFO:     Epoch: 93
2022-11-28 02:42:18,921 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41805567575449293, 'Total loss': 0.41805567575449293} | train loss {'Reaction outcome loss': 0.30584213098413066, 'Total loss': 0.30584213098413066}
2022-11-28 02:42:18,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:18,921 INFO:     Epoch: 94
2022-11-28 02:42:19,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44133016534826974, 'Total loss': 0.44133016534826974} | train loss {'Reaction outcome loss': 0.3033947334869912, 'Total loss': 0.3033947334869912}
2022-11-28 02:42:19,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:19,677 INFO:     Epoch: 95
2022-11-28 02:42:20,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43017758191986516, 'Total loss': 0.43017758191986516} | train loss {'Reaction outcome loss': 0.3037467211237939, 'Total loss': 0.3037467211237939}
2022-11-28 02:42:20,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:20,431 INFO:     Epoch: 96
2022-11-28 02:42:21,180 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4598959633572535, 'Total loss': 0.4598959633572535} | train loss {'Reaction outcome loss': 0.3067260054411434, 'Total loss': 0.3067260054411434}
2022-11-28 02:42:21,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:21,181 INFO:     Epoch: 97
2022-11-28 02:42:21,935 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4218440614640713, 'Total loss': 0.4218440614640713} | train loss {'Reaction outcome loss': 0.31305959786058435, 'Total loss': 0.31305959786058435}
2022-11-28 02:42:21,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:21,935 INFO:     Epoch: 98
2022-11-28 02:42:22,687 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4445384107530117, 'Total loss': 0.4445384107530117} | train loss {'Reaction outcome loss': 0.30972882238054567, 'Total loss': 0.30972882238054567}
2022-11-28 02:42:22,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:22,688 INFO:     Epoch: 99
2022-11-28 02:42:23,436 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4225051345472986, 'Total loss': 0.4225051345472986} | train loss {'Reaction outcome loss': 0.32427830540156555, 'Total loss': 0.32427830540156555}
2022-11-28 02:42:23,437 INFO:     Best model found after epoch 88 of 100.
2022-11-28 02:42:23,437 INFO:   Done with stage: TRAINING
2022-11-28 02:42:23,437 INFO:   Starting stage: EVALUATION
2022-11-28 02:42:23,562 INFO:   Done with stage: EVALUATION
2022-11-28 02:42:23,562 INFO:   Leaving out SEQ value Fold_8
2022-11-28 02:42:23,575 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:42:23,575 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:42:24,225 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:42:24,225 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:42:24,293 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:42:24,293 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:42:24,293 INFO:     No hyperparam tuning for this model
2022-11-28 02:42:24,293 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:42:24,293 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:42:24,294 INFO:     None feature selector for col prot
2022-11-28 02:42:24,294 INFO:     None feature selector for col prot
2022-11-28 02:42:24,294 INFO:     None feature selector for col prot
2022-11-28 02:42:24,295 INFO:     None feature selector for col chem
2022-11-28 02:42:24,295 INFO:     None feature selector for col chem
2022-11-28 02:42:24,295 INFO:     None feature selector for col chem
2022-11-28 02:42:24,295 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:42:24,295 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:42:24,297 INFO:     Number of params in model 169741
2022-11-28 02:42:24,300 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:42:24,300 INFO:   Starting stage: TRAINING
2022-11-28 02:42:24,354 INFO:     Val loss before train {'Reaction outcome loss': 0.9603703645142642, 'Total loss': 0.9603703645142642}
2022-11-28 02:42:24,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:24,354 INFO:     Epoch: 0
2022-11-28 02:42:25,100 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5037291839041493, 'Total loss': 0.5037291839041493} | train loss {'Reaction outcome loss': 0.6286034158297947, 'Total loss': 0.6286034158297947}
2022-11-28 02:42:25,100 INFO:     Found new best model at epoch 0
2022-11-28 02:42:25,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:25,101 INFO:     Epoch: 1
2022-11-28 02:42:25,843 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48357630521059036, 'Total loss': 0.48357630521059036} | train loss {'Reaction outcome loss': 0.5077717627797808, 'Total loss': 0.5077717627797808}
2022-11-28 02:42:25,843 INFO:     Found new best model at epoch 1
2022-11-28 02:42:25,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:25,844 INFO:     Epoch: 2
2022-11-28 02:42:26,594 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44764937765218993, 'Total loss': 0.44764937765218993} | train loss {'Reaction outcome loss': 0.45701417740510436, 'Total loss': 0.45701417740510436}
2022-11-28 02:42:26,594 INFO:     Found new best model at epoch 2
2022-11-28 02:42:26,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:26,595 INFO:     Epoch: 3
2022-11-28 02:42:27,341 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44300861995328555, 'Total loss': 0.44300861995328555} | train loss {'Reaction outcome loss': 0.43609909701104066, 'Total loss': 0.43609909701104066}
2022-11-28 02:42:27,342 INFO:     Found new best model at epoch 3
2022-11-28 02:42:27,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:27,343 INFO:     Epoch: 4
2022-11-28 02:42:28,089 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44778182967142627, 'Total loss': 0.44778182967142627} | train loss {'Reaction outcome loss': 0.4265792527064985, 'Total loss': 0.4265792527064985}
2022-11-28 02:42:28,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:28,089 INFO:     Epoch: 5
2022-11-28 02:42:28,836 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4352229657498273, 'Total loss': 0.4352229657498273} | train loss {'Reaction outcome loss': 0.4123907124813722, 'Total loss': 0.4123907124813722}
2022-11-28 02:42:28,836 INFO:     Found new best model at epoch 5
2022-11-28 02:42:28,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:28,837 INFO:     Epoch: 6
2022-11-28 02:42:29,579 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4862790195779367, 'Total loss': 0.4862790195779367} | train loss {'Reaction outcome loss': 0.4024486602265008, 'Total loss': 0.4024486602265008}
2022-11-28 02:42:29,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:29,580 INFO:     Epoch: 7
2022-11-28 02:42:30,323 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4592935575002974, 'Total loss': 0.4592935575002974} | train loss {'Reaction outcome loss': 0.39553326125047644, 'Total loss': 0.39553326125047644}
2022-11-28 02:42:30,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:30,324 INFO:     Epoch: 8
2022-11-28 02:42:31,071 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43245753993026237, 'Total loss': 0.43245753993026237} | train loss {'Reaction outcome loss': 0.3835558825609635, 'Total loss': 0.3835558825609635}
2022-11-28 02:42:31,071 INFO:     Found new best model at epoch 8
2022-11-28 02:42:31,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:31,072 INFO:     Epoch: 9
2022-11-28 02:42:31,817 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42253055999224837, 'Total loss': 0.42253055999224837} | train loss {'Reaction outcome loss': 0.3825238411827963, 'Total loss': 0.3825238411827963}
2022-11-28 02:42:31,817 INFO:     Found new best model at epoch 9
2022-11-28 02:42:31,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:31,818 INFO:     Epoch: 10
2022-11-28 02:42:32,562 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4299994674087925, 'Total loss': 0.4299994674087925} | train loss {'Reaction outcome loss': 0.37942552812853636, 'Total loss': 0.37942552812853636}
2022-11-28 02:42:32,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:32,562 INFO:     Epoch: 11
2022-11-28 02:42:33,307 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45346649431369523, 'Total loss': 0.45346649431369523} | train loss {'Reaction outcome loss': 0.3706472961270079, 'Total loss': 0.3706472961270079}
2022-11-28 02:42:33,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:33,307 INFO:     Epoch: 12
2022-11-28 02:42:34,052 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42654435065659607, 'Total loss': 0.42654435065659607} | train loss {'Reaction outcome loss': 0.37007669773028823, 'Total loss': 0.37007669773028823}
2022-11-28 02:42:34,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:34,052 INFO:     Epoch: 13
2022-11-28 02:42:34,797 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4374665194614367, 'Total loss': 0.4374665194614367} | train loss {'Reaction outcome loss': 0.36420417105665015, 'Total loss': 0.36420417105665015}
2022-11-28 02:42:34,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:34,797 INFO:     Epoch: 14
2022-11-28 02:42:35,540 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4481241496449167, 'Total loss': 0.4481241496449167} | train loss {'Reaction outcome loss': 0.3582138554478178, 'Total loss': 0.3582138554478178}
2022-11-28 02:42:35,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:35,541 INFO:     Epoch: 15
2022-11-28 02:42:36,285 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4255608150904829, 'Total loss': 0.4255608150904829} | train loss {'Reaction outcome loss': 0.35637005619248563, 'Total loss': 0.35637005619248563}
2022-11-28 02:42:36,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:36,285 INFO:     Epoch: 16
2022-11-28 02:42:37,030 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4140065905045379, 'Total loss': 0.4140065905045379} | train loss {'Reaction outcome loss': 0.3580565869808197, 'Total loss': 0.3580565869808197}
2022-11-28 02:42:37,030 INFO:     Found new best model at epoch 16
2022-11-28 02:42:37,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:37,031 INFO:     Epoch: 17
2022-11-28 02:42:37,776 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42866730757734994, 'Total loss': 0.42866730757734994} | train loss {'Reaction outcome loss': 0.3539133195062073, 'Total loss': 0.3539133195062073}
2022-11-28 02:42:37,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:37,777 INFO:     Epoch: 18
2022-11-28 02:42:38,522 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43724809857932007, 'Total loss': 0.43724809857932007} | train loss {'Reaction outcome loss': 0.3475086769583274, 'Total loss': 0.3475086769583274}
2022-11-28 02:42:38,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:38,523 INFO:     Epoch: 19
2022-11-28 02:42:39,269 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.429551227864894, 'Total loss': 0.429551227864894} | train loss {'Reaction outcome loss': 0.35271571631334264, 'Total loss': 0.35271571631334264}
2022-11-28 02:42:39,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:39,270 INFO:     Epoch: 20
2022-11-28 02:42:40,014 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4373600631952286, 'Total loss': 0.4373600631952286} | train loss {'Reaction outcome loss': 0.33821342554019423, 'Total loss': 0.33821342554019423}
2022-11-28 02:42:40,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:40,014 INFO:     Epoch: 21
2022-11-28 02:42:40,761 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41107208214022894, 'Total loss': 0.41107208214022894} | train loss {'Reaction outcome loss': 0.3364974856680753, 'Total loss': 0.3364974856680753}
2022-11-28 02:42:40,761 INFO:     Found new best model at epoch 21
2022-11-28 02:42:40,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:40,762 INFO:     Epoch: 22
2022-11-28 02:42:41,507 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40418839031322434, 'Total loss': 0.40418839031322434} | train loss {'Reaction outcome loss': 0.3329769952868929, 'Total loss': 0.3329769952868929}
2022-11-28 02:42:41,507 INFO:     Found new best model at epoch 22
2022-11-28 02:42:41,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:41,508 INFO:     Epoch: 23
2022-11-28 02:42:42,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43357921459458093, 'Total loss': 0.43357921459458093} | train loss {'Reaction outcome loss': 0.330374344696804, 'Total loss': 0.330374344696804}
2022-11-28 02:42:42,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:42,254 INFO:     Epoch: 24
2022-11-28 02:42:42,997 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4341364135457711, 'Total loss': 0.4341364135457711} | train loss {'Reaction outcome loss': 0.3319843152043771, 'Total loss': 0.3319843152043771}
2022-11-28 02:42:42,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:42,998 INFO:     Epoch: 25
2022-11-28 02:42:43,743 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4272905331612988, 'Total loss': 0.4272905331612988} | train loss {'Reaction outcome loss': 0.335851173863119, 'Total loss': 0.335851173863119}
2022-11-28 02:42:43,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:43,743 INFO:     Epoch: 26
2022-11-28 02:42:44,494 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42581161026927555, 'Total loss': 0.42581161026927555} | train loss {'Reaction outcome loss': 0.33562261015176775, 'Total loss': 0.33562261015176775}
2022-11-28 02:42:44,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:44,494 INFO:     Epoch: 27
2022-11-28 02:42:45,240 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41479275680401106, 'Total loss': 0.41479275680401106} | train loss {'Reaction outcome loss': 0.3228738359650787, 'Total loss': 0.3228738359650787}
2022-11-28 02:42:45,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:45,240 INFO:     Epoch: 28
2022-11-28 02:42:45,988 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4163110445846211, 'Total loss': 0.4163110445846211} | train loss {'Reaction outcome loss': 0.324940526819959, 'Total loss': 0.324940526819959}
2022-11-28 02:42:45,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:45,988 INFO:     Epoch: 29
2022-11-28 02:42:46,732 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4058167338371277, 'Total loss': 0.4058167338371277} | train loss {'Reaction outcome loss': 0.3206887213551268, 'Total loss': 0.3206887213551268}
2022-11-28 02:42:46,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:46,732 INFO:     Epoch: 30
2022-11-28 02:42:47,476 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40823036643930455, 'Total loss': 0.40823036643930455} | train loss {'Reaction outcome loss': 0.315668080488638, 'Total loss': 0.315668080488638}
2022-11-28 02:42:47,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:47,476 INFO:     Epoch: 31
2022-11-28 02:42:48,221 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41779464364729146, 'Total loss': 0.41779464364729146} | train loss {'Reaction outcome loss': 0.3234235246874848, 'Total loss': 0.3234235246874848}
2022-11-28 02:42:48,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:48,221 INFO:     Epoch: 32
2022-11-28 02:42:48,969 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41484611853957176, 'Total loss': 0.41484611853957176} | train loss {'Reaction outcome loss': 0.3264783136090454, 'Total loss': 0.3264783136090454}
2022-11-28 02:42:48,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:48,969 INFO:     Epoch: 33
2022-11-28 02:42:49,717 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3888439011167396, 'Total loss': 0.3888439011167396} | train loss {'Reaction outcome loss': 0.32078973793861815, 'Total loss': 0.32078973793861815}
2022-11-28 02:42:49,717 INFO:     Found new best model at epoch 33
2022-11-28 02:42:49,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:49,718 INFO:     Epoch: 34
2022-11-28 02:42:50,461 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4511143792081963, 'Total loss': 0.4511143792081963} | train loss {'Reaction outcome loss': 0.32604139255625864, 'Total loss': 0.32604139255625864}
2022-11-28 02:42:50,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:50,461 INFO:     Epoch: 35
2022-11-28 02:42:51,209 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40643104301257565, 'Total loss': 0.40643104301257565} | train loss {'Reaction outcome loss': 0.319793098207031, 'Total loss': 0.319793098207031}
2022-11-28 02:42:51,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:51,209 INFO:     Epoch: 36
2022-11-28 02:42:51,956 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4895079799673774, 'Total loss': 0.4895079799673774} | train loss {'Reaction outcome loss': 0.3204963542368947, 'Total loss': 0.3204963542368947}
2022-11-28 02:42:51,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:51,957 INFO:     Epoch: 37
2022-11-28 02:42:52,702 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43494992195205257, 'Total loss': 0.43494992195205257} | train loss {'Reaction outcome loss': 0.31966207066968993, 'Total loss': 0.31966207066968993}
2022-11-28 02:42:52,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:52,703 INFO:     Epoch: 38
2022-11-28 02:42:53,447 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45070801878517325, 'Total loss': 0.45070801878517325} | train loss {'Reaction outcome loss': 0.31438457278572784, 'Total loss': 0.31438457278572784}
2022-11-28 02:42:53,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:53,447 INFO:     Epoch: 39
2022-11-28 02:42:54,192 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42080470818010246, 'Total loss': 0.42080470818010246} | train loss {'Reaction outcome loss': 0.313727213123015, 'Total loss': 0.313727213123015}
2022-11-28 02:42:54,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:54,192 INFO:     Epoch: 40
2022-11-28 02:42:54,938 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42445137817412615, 'Total loss': 0.42445137817412615} | train loss {'Reaction outcome loss': 0.317408124874441, 'Total loss': 0.317408124874441}
2022-11-28 02:42:54,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:54,938 INFO:     Epoch: 41
2022-11-28 02:42:55,683 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43022061545740475, 'Total loss': 0.43022061545740475} | train loss {'Reaction outcome loss': 0.31357191387487915, 'Total loss': 0.31357191387487915}
2022-11-28 02:42:55,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:55,683 INFO:     Epoch: 42
2022-11-28 02:42:56,426 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3987311514263803, 'Total loss': 0.3987311514263803} | train loss {'Reaction outcome loss': 0.32499095031193326, 'Total loss': 0.32499095031193326}
2022-11-28 02:42:56,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:56,426 INFO:     Epoch: 43
2022-11-28 02:42:57,171 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39637714285742154, 'Total loss': 0.39637714285742154} | train loss {'Reaction outcome loss': 0.32520263274105227, 'Total loss': 0.32520263274105227}
2022-11-28 02:42:57,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:57,171 INFO:     Epoch: 44
2022-11-28 02:42:57,917 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41914320398460736, 'Total loss': 0.41914320398460736} | train loss {'Reaction outcome loss': 0.3050268504388478, 'Total loss': 0.3050268504388478}
2022-11-28 02:42:57,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:57,917 INFO:     Epoch: 45
2022-11-28 02:42:58,663 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42642915045673196, 'Total loss': 0.42642915045673196} | train loss {'Reaction outcome loss': 0.31285120461668287, 'Total loss': 0.31285120461668287}
2022-11-28 02:42:58,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:58,663 INFO:     Epoch: 46
2022-11-28 02:42:59,408 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40971286764199083, 'Total loss': 0.40971286764199083} | train loss {'Reaction outcome loss': 0.3154669838900469, 'Total loss': 0.3154669838900469}
2022-11-28 02:42:59,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:42:59,408 INFO:     Epoch: 47
2022-11-28 02:43:00,154 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40561840581622993, 'Total loss': 0.40561840581622993} | train loss {'Reaction outcome loss': 0.31110096345750654, 'Total loss': 0.31110096345750654}
2022-11-28 02:43:00,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:00,155 INFO:     Epoch: 48
2022-11-28 02:43:00,902 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41799297082153236, 'Total loss': 0.41799297082153236} | train loss {'Reaction outcome loss': 0.31365126486943695, 'Total loss': 0.31365126486943695}
2022-11-28 02:43:00,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:00,902 INFO:     Epoch: 49
2022-11-28 02:43:01,647 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4145158522508361, 'Total loss': 0.4145158522508361} | train loss {'Reaction outcome loss': 0.3052909377734272, 'Total loss': 0.3052909377734272}
2022-11-28 02:43:01,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:01,647 INFO:     Epoch: 50
2022-11-28 02:43:02,391 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4407701407643882, 'Total loss': 0.4407701407643882} | train loss {'Reaction outcome loss': 0.3005129038983462, 'Total loss': 0.3005129038983462}
2022-11-28 02:43:02,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:02,391 INFO:     Epoch: 51
2022-11-28 02:43:03,137 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40803448110818863, 'Total loss': 0.40803448110818863} | train loss {'Reaction outcome loss': 0.3175149458707595, 'Total loss': 0.3175149458707595}
2022-11-28 02:43:03,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:03,137 INFO:     Epoch: 52
2022-11-28 02:43:03,880 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43007122894579713, 'Total loss': 0.43007122894579713} | train loss {'Reaction outcome loss': 0.3089452599232294, 'Total loss': 0.3089452599232294}
2022-11-28 02:43:03,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:03,880 INFO:     Epoch: 53
2022-11-28 02:43:04,622 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3923466239463199, 'Total loss': 0.3923466239463199} | train loss {'Reaction outcome loss': 0.32201097969497955, 'Total loss': 0.32201097969497955}
2022-11-28 02:43:04,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:04,622 INFO:     Epoch: 54
2022-11-28 02:43:05,365 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4535847949710759, 'Total loss': 0.4535847949710759} | train loss {'Reaction outcome loss': 0.3120788116388175, 'Total loss': 0.3120788116388175}
2022-11-28 02:43:05,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:05,365 INFO:     Epoch: 55
2022-11-28 02:43:06,111 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4118591682477431, 'Total loss': 0.4118591682477431} | train loss {'Reaction outcome loss': 0.3162565911302761, 'Total loss': 0.3162565911302761}
2022-11-28 02:43:06,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:06,112 INFO:     Epoch: 56
2022-11-28 02:43:06,857 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4195410490713336, 'Total loss': 0.4195410490713336} | train loss {'Reaction outcome loss': 0.3120743000993923, 'Total loss': 0.3120743000993923}
2022-11-28 02:43:06,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:06,857 INFO:     Epoch: 57
2022-11-28 02:43:07,601 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43399900172583084, 'Total loss': 0.43399900172583084} | train loss {'Reaction outcome loss': 0.31831146065069704, 'Total loss': 0.31831146065069704}
2022-11-28 02:43:07,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:07,601 INFO:     Epoch: 58
2022-11-28 02:43:08,346 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3839011580090631, 'Total loss': 0.3839011580090631} | train loss {'Reaction outcome loss': 0.3031211109793916, 'Total loss': 0.3031211109793916}
2022-11-28 02:43:08,347 INFO:     Found new best model at epoch 58
2022-11-28 02:43:08,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:08,347 INFO:     Epoch: 59
2022-11-28 02:43:09,089 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4087783910270611, 'Total loss': 0.4087783910270611} | train loss {'Reaction outcome loss': 0.31738172407661164, 'Total loss': 0.31738172407661164}
2022-11-28 02:43:09,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:09,089 INFO:     Epoch: 60
2022-11-28 02:43:09,833 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3971452597020702, 'Total loss': 0.3971452597020702} | train loss {'Reaction outcome loss': 0.3048996392409412, 'Total loss': 0.3048996392409412}
2022-11-28 02:43:09,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:09,833 INFO:     Epoch: 61
2022-11-28 02:43:10,580 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4129849321801554, 'Total loss': 0.4129849321801554} | train loss {'Reaction outcome loss': 0.3047144816238053, 'Total loss': 0.3047144816238053}
2022-11-28 02:43:10,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:10,580 INFO:     Epoch: 62
2022-11-28 02:43:11,329 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3854997256262736, 'Total loss': 0.3854997256262736} | train loss {'Reaction outcome loss': 0.3127927066720262, 'Total loss': 0.3127927066720262}
2022-11-28 02:43:11,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:11,329 INFO:     Epoch: 63
2022-11-28 02:43:12,075 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4114511219615286, 'Total loss': 0.4114511219615286} | train loss {'Reaction outcome loss': 0.30345145117263406, 'Total loss': 0.30345145117263406}
2022-11-28 02:43:12,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:12,076 INFO:     Epoch: 64
2022-11-28 02:43:12,826 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41025857508859853, 'Total loss': 0.41025857508859853} | train loss {'Reaction outcome loss': 0.31702154371507313, 'Total loss': 0.31702154371507313}
2022-11-28 02:43:12,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:12,826 INFO:     Epoch: 65
2022-11-28 02:43:13,579 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40908676758408546, 'Total loss': 0.40908676758408546} | train loss {'Reaction outcome loss': 0.31100777199073715, 'Total loss': 0.31100777199073715}
2022-11-28 02:43:13,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:13,580 INFO:     Epoch: 66
2022-11-28 02:43:14,334 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4131019347431985, 'Total loss': 0.4131019347431985} | train loss {'Reaction outcome loss': 0.30621720981232975, 'Total loss': 0.30621720981232975}
2022-11-28 02:43:14,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:14,335 INFO:     Epoch: 67
2022-11-28 02:43:15,082 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37747149779038, 'Total loss': 0.37747149779038} | train loss {'Reaction outcome loss': 0.31365571450822205, 'Total loss': 0.31365571450822205}
2022-11-28 02:43:15,082 INFO:     Found new best model at epoch 67
2022-11-28 02:43:15,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:15,083 INFO:     Epoch: 68
2022-11-28 02:43:15,834 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4515393792905591, 'Total loss': 0.4515393792905591} | train loss {'Reaction outcome loss': 0.3067046207128739, 'Total loss': 0.3067046207128739}
2022-11-28 02:43:15,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:15,834 INFO:     Epoch: 69
2022-11-28 02:43:16,583 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.409381201998754, 'Total loss': 0.409381201998754} | train loss {'Reaction outcome loss': 0.30443016597811057, 'Total loss': 0.30443016597811057}
2022-11-28 02:43:16,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:16,583 INFO:     Epoch: 70
2022-11-28 02:43:17,339 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3825907233086499, 'Total loss': 0.3825907233086499} | train loss {'Reaction outcome loss': 0.3050480051004157, 'Total loss': 0.3050480051004157}
2022-11-28 02:43:17,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:17,339 INFO:     Epoch: 71
2022-11-28 02:43:18,088 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40644071564416995, 'Total loss': 0.40644071564416995} | train loss {'Reaction outcome loss': 0.298051991146438, 'Total loss': 0.298051991146438}
2022-11-28 02:43:18,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:18,088 INFO:     Epoch: 72
2022-11-28 02:43:18,835 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3965697842226787, 'Total loss': 0.3965697842226787} | train loss {'Reaction outcome loss': 0.3069521406779484, 'Total loss': 0.3069521406779484}
2022-11-28 02:43:18,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:18,835 INFO:     Epoch: 73
2022-11-28 02:43:19,581 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.406080922619863, 'Total loss': 0.406080922619863} | train loss {'Reaction outcome loss': 0.3162753560409254, 'Total loss': 0.3162753560409254}
2022-11-28 02:43:19,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:19,581 INFO:     Epoch: 74
2022-11-28 02:43:20,326 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3876556330783801, 'Total loss': 0.3876556330783801} | train loss {'Reaction outcome loss': 0.3108408295378393, 'Total loss': 0.3108408295378393}
2022-11-28 02:43:20,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:20,327 INFO:     Epoch: 75
2022-11-28 02:43:21,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3802136033773422, 'Total loss': 0.3802136033773422} | train loss {'Reaction outcome loss': 0.3091152026945231, 'Total loss': 0.3091152026945231}
2022-11-28 02:43:21,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:21,071 INFO:     Epoch: 76
2022-11-28 02:43:21,819 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4317025017331947, 'Total loss': 0.4317025017331947} | train loss {'Reaction outcome loss': 0.3038801884468721, 'Total loss': 0.3038801884468721}
2022-11-28 02:43:21,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:21,819 INFO:     Epoch: 77
2022-11-28 02:43:22,564 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43638669919561257, 'Total loss': 0.43638669919561257} | train loss {'Reaction outcome loss': 0.30817076585122516, 'Total loss': 0.30817076585122516}
2022-11-28 02:43:22,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:22,564 INFO:     Epoch: 78
2022-11-28 02:43:23,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4289176235483451, 'Total loss': 0.4289176235483451} | train loss {'Reaction outcome loss': 0.29892579289723414, 'Total loss': 0.29892579289723414}
2022-11-28 02:43:23,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:23,310 INFO:     Epoch: 79
2022-11-28 02:43:24,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4242865866558118, 'Total loss': 0.4242865866558118} | train loss {'Reaction outcome loss': 0.3136242723890713, 'Total loss': 0.3136242723890713}
2022-11-28 02:43:24,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:24,063 INFO:     Epoch: 80
2022-11-28 02:43:24,814 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42693898928436363, 'Total loss': 0.42693898928436363} | train loss {'Reaction outcome loss': 0.3115228468970377, 'Total loss': 0.3115228468970377}
2022-11-28 02:43:24,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:24,814 INFO:     Epoch: 81
2022-11-28 02:43:25,560 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4098664911633188, 'Total loss': 0.4098664911633188} | train loss {'Reaction outcome loss': 0.30142197668248294, 'Total loss': 0.30142197668248294}
2022-11-28 02:43:25,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:25,560 INFO:     Epoch: 82
2022-11-28 02:43:26,306 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4159828886728395, 'Total loss': 0.4159828886728395} | train loss {'Reaction outcome loss': 0.31785866241065824, 'Total loss': 0.31785866241065824}
2022-11-28 02:43:26,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:26,306 INFO:     Epoch: 83
2022-11-28 02:43:27,050 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42875572192397987, 'Total loss': 0.42875572192397987} | train loss {'Reaction outcome loss': 0.3108310386386453, 'Total loss': 0.3108310386386453}
2022-11-28 02:43:27,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:27,050 INFO:     Epoch: 84
2022-11-28 02:43:27,797 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3919974724763465, 'Total loss': 0.3919974724763465} | train loss {'Reaction outcome loss': 0.3092391750338126, 'Total loss': 0.3092391750338126}
2022-11-28 02:43:27,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:27,797 INFO:     Epoch: 85
2022-11-28 02:43:28,542 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38807976482944057, 'Total loss': 0.38807976482944057} | train loss {'Reaction outcome loss': 0.3089310434703924, 'Total loss': 0.3089310434703924}
2022-11-28 02:43:28,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:28,542 INFO:     Epoch: 86
2022-11-28 02:43:29,290 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4319576744667508, 'Total loss': 0.4319576744667508} | train loss {'Reaction outcome loss': 0.30374483730720014, 'Total loss': 0.30374483730720014}
2022-11-28 02:43:29,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:29,290 INFO:     Epoch: 87
2022-11-28 02:43:30,033 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41466074403036723, 'Total loss': 0.41466074403036723} | train loss {'Reaction outcome loss': 0.3087076269546334, 'Total loss': 0.3087076269546334}
2022-11-28 02:43:30,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:30,033 INFO:     Epoch: 88
2022-11-28 02:43:30,780 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4228342625905167, 'Total loss': 0.4228342625905167} | train loss {'Reaction outcome loss': 0.2995244448434333, 'Total loss': 0.2995244448434333}
2022-11-28 02:43:30,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:30,781 INFO:     Epoch: 89
2022-11-28 02:43:31,525 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4047186103416607, 'Total loss': 0.4047186103416607} | train loss {'Reaction outcome loss': 0.3070116429608695, 'Total loss': 0.3070116429608695}
2022-11-28 02:43:31,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:31,526 INFO:     Epoch: 90
2022-11-28 02:43:32,272 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4256528256969018, 'Total loss': 0.4256528256969018} | train loss {'Reaction outcome loss': 0.2992536079518649, 'Total loss': 0.2992536079518649}
2022-11-28 02:43:32,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:32,273 INFO:     Epoch: 91
2022-11-28 02:43:33,022 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4132986278696494, 'Total loss': 0.4132986278696494} | train loss {'Reaction outcome loss': 0.29893102717338776, 'Total loss': 0.29893102717338776}
2022-11-28 02:43:33,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:33,023 INFO:     Epoch: 92
2022-11-28 02:43:33,766 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42738773741505365, 'Total loss': 0.42738773741505365} | train loss {'Reaction outcome loss': 0.29987479743300655, 'Total loss': 0.29987479743300655}
2022-11-28 02:43:33,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:33,767 INFO:     Epoch: 93
2022-11-28 02:43:34,511 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44160147925669496, 'Total loss': 0.44160147925669496} | train loss {'Reaction outcome loss': 0.3087012246251106, 'Total loss': 0.3087012246251106}
2022-11-28 02:43:34,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:34,512 INFO:     Epoch: 94
2022-11-28 02:43:35,254 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4250919615680521, 'Total loss': 0.4250919615680521} | train loss {'Reaction outcome loss': 0.31243461195607575, 'Total loss': 0.31243461195607575}
2022-11-28 02:43:35,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:35,254 INFO:     Epoch: 95
2022-11-28 02:43:35,998 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4449313394725323, 'Total loss': 0.4449313394725323} | train loss {'Reaction outcome loss': 0.30496314228797444, 'Total loss': 0.30496314228797444}
2022-11-28 02:43:35,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:35,999 INFO:     Epoch: 96
2022-11-28 02:43:36,743 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42423311180689116, 'Total loss': 0.42423311180689116} | train loss {'Reaction outcome loss': 0.30150979331561495, 'Total loss': 0.30150979331561495}
2022-11-28 02:43:36,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:36,744 INFO:     Epoch: 97
2022-11-28 02:43:37,487 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4026796435090629, 'Total loss': 0.4026796435090629} | train loss {'Reaction outcome loss': 0.2999313182672676, 'Total loss': 0.2999313182672676}
2022-11-28 02:43:37,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:37,487 INFO:     Epoch: 98
2022-11-28 02:43:38,236 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4354763379828496, 'Total loss': 0.4354763379828496} | train loss {'Reaction outcome loss': 0.3136341472669524, 'Total loss': 0.3136341472669524}
2022-11-28 02:43:38,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:38,236 INFO:     Epoch: 99
2022-11-28 02:43:38,980 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4029976994815198, 'Total loss': 0.4029976994815198} | train loss {'Reaction outcome loss': 0.30001128592661447, 'Total loss': 0.30001128592661447}
2022-11-28 02:43:38,980 INFO:     Best model found after epoch 68 of 100.
2022-11-28 02:43:38,980 INFO:   Done with stage: TRAINING
2022-11-28 02:43:38,981 INFO:   Starting stage: EVALUATION
2022-11-28 02:43:39,111 INFO:   Done with stage: EVALUATION
2022-11-28 02:43:39,112 INFO:   Leaving out SEQ value Fold_9
2022-11-28 02:43:39,124 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:43:39,124 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:43:39,760 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:43:39,760 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:43:39,828 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:43:39,828 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:43:39,828 INFO:     No hyperparam tuning for this model
2022-11-28 02:43:39,828 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:43:39,828 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:43:39,829 INFO:     None feature selector for col prot
2022-11-28 02:43:39,829 INFO:     None feature selector for col prot
2022-11-28 02:43:39,829 INFO:     None feature selector for col prot
2022-11-28 02:43:39,830 INFO:     None feature selector for col chem
2022-11-28 02:43:39,830 INFO:     None feature selector for col chem
2022-11-28 02:43:39,830 INFO:     None feature selector for col chem
2022-11-28 02:43:39,830 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:43:39,830 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:43:39,832 INFO:     Number of params in model 169741
2022-11-28 02:43:39,835 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:43:39,835 INFO:   Starting stage: TRAINING
2022-11-28 02:43:39,888 INFO:     Val loss before train {'Reaction outcome loss': 0.9896980117667805, 'Total loss': 0.9896980117667805}
2022-11-28 02:43:39,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:39,888 INFO:     Epoch: 0
2022-11-28 02:43:40,635 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6009500893679532, 'Total loss': 0.6009500893679532} | train loss {'Reaction outcome loss': 0.6479604468051239, 'Total loss': 0.6479604468051239}
2022-11-28 02:43:40,635 INFO:     Found new best model at epoch 0
2022-11-28 02:43:40,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:40,636 INFO:     Epoch: 1
2022-11-28 02:43:41,386 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4995374848896807, 'Total loss': 0.4995374848896807} | train loss {'Reaction outcome loss': 0.5079133455087299, 'Total loss': 0.5079133455087299}
2022-11-28 02:43:41,386 INFO:     Found new best model at epoch 1
2022-11-28 02:43:41,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:41,387 INFO:     Epoch: 2
2022-11-28 02:43:42,134 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4938108877024867, 'Total loss': 0.4938108877024867} | train loss {'Reaction outcome loss': 0.45913339560089805, 'Total loss': 0.45913339560089805}
2022-11-28 02:43:42,135 INFO:     Found new best model at epoch 2
2022-11-28 02:43:42,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:42,136 INFO:     Epoch: 3
2022-11-28 02:43:42,887 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4846559925512834, 'Total loss': 0.4846559925512834} | train loss {'Reaction outcome loss': 0.45110269439847844, 'Total loss': 0.45110269439847844}
2022-11-28 02:43:42,887 INFO:     Found new best model at epoch 3
2022-11-28 02:43:42,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:42,888 INFO:     Epoch: 4
2022-11-28 02:43:43,639 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45595776357434015, 'Total loss': 0.45595776357434015} | train loss {'Reaction outcome loss': 0.42443126605951836, 'Total loss': 0.42443126605951836}
2022-11-28 02:43:43,639 INFO:     Found new best model at epoch 4
2022-11-28 02:43:43,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:43,640 INFO:     Epoch: 5
2022-11-28 02:43:44,389 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45027024231173773, 'Total loss': 0.45027024231173773} | train loss {'Reaction outcome loss': 0.4061093235969061, 'Total loss': 0.4061093235969061}
2022-11-28 02:43:44,389 INFO:     Found new best model at epoch 5
2022-11-28 02:43:44,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:44,390 INFO:     Epoch: 6
2022-11-28 02:43:45,138 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4600861861624501, 'Total loss': 0.4600861861624501} | train loss {'Reaction outcome loss': 0.39899177158530424, 'Total loss': 0.39899177158530424}
2022-11-28 02:43:45,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:45,138 INFO:     Epoch: 7
2022-11-28 02:43:45,885 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4621458351612091, 'Total loss': 0.4621458351612091} | train loss {'Reaction outcome loss': 0.3903282097718011, 'Total loss': 0.3903282097718011}
2022-11-28 02:43:45,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:45,885 INFO:     Epoch: 8
2022-11-28 02:43:46,635 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45149353857744823, 'Total loss': 0.45149353857744823} | train loss {'Reaction outcome loss': 0.40228529518794437, 'Total loss': 0.40228529518794437}
2022-11-28 02:43:46,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:46,635 INFO:     Epoch: 9
2022-11-28 02:43:47,384 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44157359342683444, 'Total loss': 0.44157359342683444} | train loss {'Reaction outcome loss': 0.402465372644214, 'Total loss': 0.402465372644214}
2022-11-28 02:43:47,384 INFO:     Found new best model at epoch 9
2022-11-28 02:43:47,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:47,385 INFO:     Epoch: 10
2022-11-28 02:43:48,133 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.451523059471087, 'Total loss': 0.451523059471087} | train loss {'Reaction outcome loss': 0.37299633001237503, 'Total loss': 0.37299633001237503}
2022-11-28 02:43:48,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:48,133 INFO:     Epoch: 11
2022-11-28 02:43:48,884 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45383711091496726, 'Total loss': 0.45383711091496726} | train loss {'Reaction outcome loss': 0.374930565958081, 'Total loss': 0.374930565958081}
2022-11-28 02:43:48,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:48,885 INFO:     Epoch: 12
2022-11-28 02:43:49,635 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43878148445351556, 'Total loss': 0.43878148445351556} | train loss {'Reaction outcome loss': 0.38748319893472105, 'Total loss': 0.38748319893472105}
2022-11-28 02:43:49,635 INFO:     Found new best model at epoch 12
2022-11-28 02:43:49,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:49,636 INFO:     Epoch: 13
2022-11-28 02:43:50,388 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4274029176343571, 'Total loss': 0.4274029176343571} | train loss {'Reaction outcome loss': 0.3627713522157417, 'Total loss': 0.3627713522157417}
2022-11-28 02:43:50,388 INFO:     Found new best model at epoch 13
2022-11-28 02:43:50,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:50,389 INFO:     Epoch: 14
2022-11-28 02:43:51,138 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4749737500467084, 'Total loss': 0.4749737500467084} | train loss {'Reaction outcome loss': 0.3608148174840195, 'Total loss': 0.3608148174840195}
2022-11-28 02:43:51,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:51,138 INFO:     Epoch: 15
2022-11-28 02:43:51,886 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.465194258838892, 'Total loss': 0.465194258838892} | train loss {'Reaction outcome loss': 0.3558232036800037, 'Total loss': 0.3558232036800037}
2022-11-28 02:43:51,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:51,887 INFO:     Epoch: 16
2022-11-28 02:43:52,637 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4259480820460753, 'Total loss': 0.4259480820460753} | train loss {'Reaction outcome loss': 0.36673807753966403, 'Total loss': 0.36673807753966403}
2022-11-28 02:43:52,637 INFO:     Found new best model at epoch 16
2022-11-28 02:43:52,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:52,638 INFO:     Epoch: 17
2022-11-28 02:43:53,393 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42305898463184183, 'Total loss': 0.42305898463184183} | train loss {'Reaction outcome loss': 0.3708539403266149, 'Total loss': 0.3708539403266149}
2022-11-28 02:43:53,393 INFO:     Found new best model at epoch 17
2022-11-28 02:43:53,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:53,394 INFO:     Epoch: 18
2022-11-28 02:43:54,146 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4376850920644673, 'Total loss': 0.4376850920644673} | train loss {'Reaction outcome loss': 0.3427752387306468, 'Total loss': 0.3427752387306468}
2022-11-28 02:43:54,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:54,147 INFO:     Epoch: 19
2022-11-28 02:43:54,895 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47349984672936524, 'Total loss': 0.47349984672936524} | train loss {'Reaction outcome loss': 0.3391066945878118, 'Total loss': 0.3391066945878118}
2022-11-28 02:43:54,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:54,896 INFO:     Epoch: 20
2022-11-28 02:43:55,645 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43612235750664363, 'Total loss': 0.43612235750664363} | train loss {'Reaction outcome loss': 0.34141201703895924, 'Total loss': 0.34141201703895924}
2022-11-28 02:43:55,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:55,646 INFO:     Epoch: 21
2022-11-28 02:43:56,396 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4578728455711495, 'Total loss': 0.4578728455711495} | train loss {'Reaction outcome loss': 0.33859267474910026, 'Total loss': 0.33859267474910026}
2022-11-28 02:43:56,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:56,396 INFO:     Epoch: 22
2022-11-28 02:43:57,149 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4545961432158947, 'Total loss': 0.4545961432158947} | train loss {'Reaction outcome loss': 0.34739178582000346, 'Total loss': 0.34739178582000346}
2022-11-28 02:43:57,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:57,149 INFO:     Epoch: 23
2022-11-28 02:43:57,900 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4199297114868056, 'Total loss': 0.4199297114868056} | train loss {'Reaction outcome loss': 0.35080208763600845, 'Total loss': 0.35080208763600845}
2022-11-28 02:43:57,900 INFO:     Found new best model at epoch 23
2022-11-28 02:43:57,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:57,901 INFO:     Epoch: 24
2022-11-28 02:43:58,653 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.433812360025265, 'Total loss': 0.433812360025265} | train loss {'Reaction outcome loss': 0.3489400624115631, 'Total loss': 0.3489400624115631}
2022-11-28 02:43:58,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:58,653 INFO:     Epoch: 25
2022-11-28 02:43:59,402 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.418149744245139, 'Total loss': 0.418149744245139} | train loss {'Reaction outcome loss': 0.3260637817882908, 'Total loss': 0.3260637817882908}
2022-11-28 02:43:59,402 INFO:     Found new best model at epoch 25
2022-11-28 02:43:59,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:43:59,403 INFO:     Epoch: 26
2022-11-28 02:44:00,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42367987910454924, 'Total loss': 0.42367987910454924} | train loss {'Reaction outcome loss': 0.32646958220765177, 'Total loss': 0.32646958220765177}
2022-11-28 02:44:00,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:00,151 INFO:     Epoch: 27
2022-11-28 02:44:00,902 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44708213819698855, 'Total loss': 0.44708213819698855} | train loss {'Reaction outcome loss': 0.33313724362415825, 'Total loss': 0.33313724362415825}
2022-11-28 02:44:00,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:00,902 INFO:     Epoch: 28
2022-11-28 02:44:01,651 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44904697889631445, 'Total loss': 0.44904697889631445} | train loss {'Reaction outcome loss': 0.3347535845239153, 'Total loss': 0.3347535845239153}
2022-11-28 02:44:01,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:01,651 INFO:     Epoch: 29
2022-11-28 02:44:02,401 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4298831004310738, 'Total loss': 0.4298831004310738} | train loss {'Reaction outcome loss': 0.3240825218348368, 'Total loss': 0.3240825218348368}
2022-11-28 02:44:02,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:02,401 INFO:     Epoch: 30
2022-11-28 02:44:03,153 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4658969153057445, 'Total loss': 0.4658969153057445} | train loss {'Reaction outcome loss': 0.3249129581487613, 'Total loss': 0.3249129581487613}
2022-11-28 02:44:03,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:03,153 INFO:     Epoch: 31
2022-11-28 02:44:03,904 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43628371405330574, 'Total loss': 0.43628371405330574} | train loss {'Reaction outcome loss': 0.3337581680129897, 'Total loss': 0.3337581680129897}
2022-11-28 02:44:03,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:03,904 INFO:     Epoch: 32
2022-11-28 02:44:04,656 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44997856562787836, 'Total loss': 0.44997856562787836} | train loss {'Reaction outcome loss': 0.3174516665428756, 'Total loss': 0.3174516665428756}
2022-11-28 02:44:04,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:04,657 INFO:     Epoch: 33
2022-11-28 02:44:05,403 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42504940181970596, 'Total loss': 0.42504940181970596} | train loss {'Reaction outcome loss': 0.3301945145464378, 'Total loss': 0.3301945145464378}
2022-11-28 02:44:05,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:05,403 INFO:     Epoch: 34
2022-11-28 02:44:06,153 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4343673449686982, 'Total loss': 0.4343673449686982} | train loss {'Reaction outcome loss': 0.3364826298737333, 'Total loss': 0.3364826298737333}
2022-11-28 02:44:06,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:06,154 INFO:     Epoch: 35
2022-11-28 02:44:06,903 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4315959555520253, 'Total loss': 0.4315959555520253} | train loss {'Reaction outcome loss': 0.32258746860480986, 'Total loss': 0.32258746860480986}
2022-11-28 02:44:06,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:06,903 INFO:     Epoch: 36
2022-11-28 02:44:07,653 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4729386879639192, 'Total loss': 0.4729386879639192} | train loss {'Reaction outcome loss': 0.3178959447166577, 'Total loss': 0.3178959447166577}
2022-11-28 02:44:07,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:07,653 INFO:     Epoch: 37
2022-11-28 02:44:08,409 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4014638208530166, 'Total loss': 0.4014638208530166} | train loss {'Reaction outcome loss': 0.32264027092982883, 'Total loss': 0.32264027092982883}
2022-11-28 02:44:08,409 INFO:     Found new best model at epoch 37
2022-11-28 02:44:08,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:08,410 INFO:     Epoch: 38
2022-11-28 02:44:09,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4495015601542863, 'Total loss': 0.4495015601542863} | train loss {'Reaction outcome loss': 0.3379982628661391, 'Total loss': 0.3379982628661391}
2022-11-28 02:44:09,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:09,163 INFO:     Epoch: 39
2022-11-28 02:44:09,913 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4407801861790093, 'Total loss': 0.4407801861790093} | train loss {'Reaction outcome loss': 0.31938937994150013, 'Total loss': 0.31938937994150013}
2022-11-28 02:44:09,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:09,914 INFO:     Epoch: 40
2022-11-28 02:44:10,666 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42916471883654594, 'Total loss': 0.42916471883654594} | train loss {'Reaction outcome loss': 0.33991744050186745, 'Total loss': 0.33991744050186745}
2022-11-28 02:44:10,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:10,666 INFO:     Epoch: 41
2022-11-28 02:44:11,416 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41907518907365476, 'Total loss': 0.41907518907365476} | train loss {'Reaction outcome loss': 0.31606659566161605, 'Total loss': 0.31606659566161605}
2022-11-28 02:44:11,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:11,416 INFO:     Epoch: 42
2022-11-28 02:44:12,162 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.439831943674521, 'Total loss': 0.439831943674521} | train loss {'Reaction outcome loss': 0.31818365305662155, 'Total loss': 0.31818365305662155}
2022-11-28 02:44:12,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:12,163 INFO:     Epoch: 43
2022-11-28 02:44:12,914 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4476318494840102, 'Total loss': 0.4476318494840102} | train loss {'Reaction outcome loss': 0.31507302637811496, 'Total loss': 0.31507302637811496}
2022-11-28 02:44:12,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:12,915 INFO:     Epoch: 44
2022-11-28 02:44:13,668 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.431595210663297, 'Total loss': 0.431595210663297} | train loss {'Reaction outcome loss': 0.3137155914788044, 'Total loss': 0.3137155914788044}
2022-11-28 02:44:13,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:13,668 INFO:     Epoch: 45
2022-11-28 02:44:14,417 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43743905188007787, 'Total loss': 0.43743905188007787} | train loss {'Reaction outcome loss': 0.31201616701809504, 'Total loss': 0.31201616701809504}
2022-11-28 02:44:14,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:14,417 INFO:     Epoch: 46
2022-11-28 02:44:15,172 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4331390476700934, 'Total loss': 0.4331390476700934} | train loss {'Reaction outcome loss': 0.31210358546451034, 'Total loss': 0.31210358546451034}
2022-11-28 02:44:15,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:15,172 INFO:     Epoch: 47
2022-11-28 02:44:15,925 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44058410687880084, 'Total loss': 0.44058410687880084} | train loss {'Reaction outcome loss': 0.3156557442037849, 'Total loss': 0.3156557442037849}
2022-11-28 02:44:15,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:15,926 INFO:     Epoch: 48
2022-11-28 02:44:16,677 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4200799184089357, 'Total loss': 0.4200799184089357} | train loss {'Reaction outcome loss': 0.3167093919838971, 'Total loss': 0.3167093919838971}
2022-11-28 02:44:16,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:16,677 INFO:     Epoch: 49
2022-11-28 02:44:17,427 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46612769754772837, 'Total loss': 0.46612769754772837} | train loss {'Reaction outcome loss': 0.33527823655228867, 'Total loss': 0.33527823655228867}
2022-11-28 02:44:17,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:17,428 INFO:     Epoch: 50
2022-11-28 02:44:18,178 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42431052232330496, 'Total loss': 0.42431052232330496} | train loss {'Reaction outcome loss': 0.3194964318798392, 'Total loss': 0.3194964318798392}
2022-11-28 02:44:18,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:18,178 INFO:     Epoch: 51
2022-11-28 02:44:18,929 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4561391266232187, 'Total loss': 0.4561391266232187} | train loss {'Reaction outcome loss': 0.3078168232431296, 'Total loss': 0.3078168232431296}
2022-11-28 02:44:18,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:18,929 INFO:     Epoch: 52
2022-11-28 02:44:19,677 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41828803887421434, 'Total loss': 0.41828803887421434} | train loss {'Reaction outcome loss': 0.3321316407065884, 'Total loss': 0.3321316407065884}
2022-11-28 02:44:19,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:19,678 INFO:     Epoch: 53
2022-11-28 02:44:20,427 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4746401594443755, 'Total loss': 0.4746401594443755} | train loss {'Reaction outcome loss': 0.3078968465301823, 'Total loss': 0.3078968465301823}
2022-11-28 02:44:20,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:20,427 INFO:     Epoch: 54
2022-11-28 02:44:21,177 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45907136679373006, 'Total loss': 0.45907136679373006} | train loss {'Reaction outcome loss': 0.30925450986816816, 'Total loss': 0.30925450986816816}
2022-11-28 02:44:21,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:21,177 INFO:     Epoch: 55
2022-11-28 02:44:21,930 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4152965565974062, 'Total loss': 0.4152965565974062} | train loss {'Reaction outcome loss': 0.31599483581689686, 'Total loss': 0.31599483581689686}
2022-11-28 02:44:21,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:21,930 INFO:     Epoch: 56
2022-11-28 02:44:22,681 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4158553857017647, 'Total loss': 0.4158553857017647} | train loss {'Reaction outcome loss': 0.3054706984188272, 'Total loss': 0.3054706984188272}
2022-11-28 02:44:22,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:22,681 INFO:     Epoch: 57
2022-11-28 02:44:23,430 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4283286692066626, 'Total loss': 0.4283286692066626} | train loss {'Reaction outcome loss': 0.31216978136240786, 'Total loss': 0.31216978136240786}
2022-11-28 02:44:23,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:23,430 INFO:     Epoch: 58
2022-11-28 02:44:24,178 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4291894974356348, 'Total loss': 0.4291894974356348} | train loss {'Reaction outcome loss': 0.30946197615642296, 'Total loss': 0.30946197615642296}
2022-11-28 02:44:24,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:24,178 INFO:     Epoch: 59
2022-11-28 02:44:24,929 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.437145860357718, 'Total loss': 0.437145860357718} | train loss {'Reaction outcome loss': 0.29972008361681235, 'Total loss': 0.29972008361681235}
2022-11-28 02:44:24,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:24,929 INFO:     Epoch: 60
2022-11-28 02:44:25,678 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42819297923283145, 'Total loss': 0.42819297923283145} | train loss {'Reaction outcome loss': 0.30899227605491636, 'Total loss': 0.30899227605491636}
2022-11-28 02:44:25,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:25,678 INFO:     Epoch: 61
2022-11-28 02:44:26,431 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42578539286147465, 'Total loss': 0.42578539286147465} | train loss {'Reaction outcome loss': 0.30766535019464336, 'Total loss': 0.30766535019464336}
2022-11-28 02:44:26,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:26,432 INFO:     Epoch: 62
2022-11-28 02:44:27,184 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42402564869685605, 'Total loss': 0.42402564869685605} | train loss {'Reaction outcome loss': 0.3094890152987565, 'Total loss': 0.3094890152987565}
2022-11-28 02:44:27,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:27,184 INFO:     Epoch: 63
2022-11-28 02:44:27,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4323419881137935, 'Total loss': 0.4323419881137935} | train loss {'Reaction outcome loss': 0.30222385485283276, 'Total loss': 0.30222385485283276}
2022-11-28 02:44:27,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:27,940 INFO:     Epoch: 64
2022-11-28 02:44:28,697 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45506267554380675, 'Total loss': 0.45506267554380675} | train loss {'Reaction outcome loss': 0.29692938215469733, 'Total loss': 0.29692938215469733}
2022-11-28 02:44:28,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:28,697 INFO:     Epoch: 65
2022-11-28 02:44:29,451 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4584404683925889, 'Total loss': 0.4584404683925889} | train loss {'Reaction outcome loss': 0.3143748526993068, 'Total loss': 0.3143748526993068}
2022-11-28 02:44:29,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:29,451 INFO:     Epoch: 66
2022-11-28 02:44:30,204 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42962893132459035, 'Total loss': 0.42962893132459035} | train loss {'Reaction outcome loss': 0.31017546747860153, 'Total loss': 0.31017546747860153}
2022-11-28 02:44:30,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:30,204 INFO:     Epoch: 67
2022-11-28 02:44:30,959 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4218212714926763, 'Total loss': 0.4218212714926763} | train loss {'Reaction outcome loss': 0.3131982514913748, 'Total loss': 0.3131982514913748}
2022-11-28 02:44:30,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:30,959 INFO:     Epoch: 68
2022-11-28 02:44:31,712 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40513044731183484, 'Total loss': 0.40513044731183484} | train loss {'Reaction outcome loss': 0.3109991769739973, 'Total loss': 0.3109991769739973}
2022-11-28 02:44:31,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:31,712 INFO:     Epoch: 69
2022-11-28 02:44:32,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44872720675034955, 'Total loss': 0.44872720675034955} | train loss {'Reaction outcome loss': 0.2954154328296059, 'Total loss': 0.2954154328296059}
2022-11-28 02:44:32,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:32,470 INFO:     Epoch: 70
2022-11-28 02:44:33,228 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42251249961555004, 'Total loss': 0.42251249961555004} | train loss {'Reaction outcome loss': 0.3117584529736264, 'Total loss': 0.3117584529736264}
2022-11-28 02:44:33,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:33,228 INFO:     Epoch: 71
2022-11-28 02:44:33,983 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42763380452313204, 'Total loss': 0.42763380452313204} | train loss {'Reaction outcome loss': 0.3252979445192013, 'Total loss': 0.3252979445192013}
2022-11-28 02:44:33,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:33,984 INFO:     Epoch: 72
2022-11-28 02:44:34,734 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4144293533807451, 'Total loss': 0.4144293533807451} | train loss {'Reaction outcome loss': 0.3038318548558906, 'Total loss': 0.3038318548558906}
2022-11-28 02:44:34,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:34,735 INFO:     Epoch: 73
2022-11-28 02:44:35,488 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41720298576084053, 'Total loss': 0.41720298576084053} | train loss {'Reaction outcome loss': 0.29019176381485073, 'Total loss': 0.29019176381485073}
2022-11-28 02:44:35,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:35,489 INFO:     Epoch: 74
2022-11-28 02:44:36,243 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4678528369827704, 'Total loss': 0.4678528369827704} | train loss {'Reaction outcome loss': 0.2915736714053733, 'Total loss': 0.2915736714053733}
2022-11-28 02:44:36,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:36,244 INFO:     Epoch: 75
2022-11-28 02:44:36,995 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45499730787493964, 'Total loss': 0.45499730787493964} | train loss {'Reaction outcome loss': 0.30332726731836074, 'Total loss': 0.30332726731836074}
2022-11-28 02:44:36,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:36,996 INFO:     Epoch: 76
2022-11-28 02:44:37,747 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.468841554089026, 'Total loss': 0.468841554089026} | train loss {'Reaction outcome loss': 0.3271489590708061, 'Total loss': 0.3271489590708061}
2022-11-28 02:44:37,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:37,748 INFO:     Epoch: 77
2022-11-28 02:44:38,499 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41259813850576227, 'Total loss': 0.41259813850576227} | train loss {'Reaction outcome loss': 0.3014658317865374, 'Total loss': 0.3014658317865374}
2022-11-28 02:44:38,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:38,499 INFO:     Epoch: 78
2022-11-28 02:44:39,248 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4294984005391598, 'Total loss': 0.4294984005391598} | train loss {'Reaction outcome loss': 0.3012761496580564, 'Total loss': 0.3012761496580564}
2022-11-28 02:44:39,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:39,248 INFO:     Epoch: 79
2022-11-28 02:44:39,996 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4272114966403354, 'Total loss': 0.4272114966403354} | train loss {'Reaction outcome loss': 0.305376705747505, 'Total loss': 0.305376705747505}
2022-11-28 02:44:39,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:39,996 INFO:     Epoch: 80
2022-11-28 02:44:40,749 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42845716225829994, 'Total loss': 0.42845716225829994} | train loss {'Reaction outcome loss': 0.2974426703535111, 'Total loss': 0.2974426703535111}
2022-11-28 02:44:40,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:40,750 INFO:     Epoch: 81
2022-11-28 02:44:41,496 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4202216069468043, 'Total loss': 0.4202216069468043} | train loss {'Reaction outcome loss': 0.30969989369152046, 'Total loss': 0.30969989369152046}
2022-11-28 02:44:41,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:41,497 INFO:     Epoch: 82
2022-11-28 02:44:42,241 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4237247444689274, 'Total loss': 0.4237247444689274} | train loss {'Reaction outcome loss': 0.30388869725823825, 'Total loss': 0.30388869725823825}
2022-11-28 02:44:42,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:42,242 INFO:     Epoch: 83
2022-11-28 02:44:42,990 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44931129095229233, 'Total loss': 0.44931129095229233} | train loss {'Reaction outcome loss': 0.29364947838188427, 'Total loss': 0.29364947838188427}
2022-11-28 02:44:42,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:42,990 INFO:     Epoch: 84
2022-11-28 02:44:43,737 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4655628231438724, 'Total loss': 0.4655628231438724} | train loss {'Reaction outcome loss': 0.2979100863732066, 'Total loss': 0.2979100863732066}
2022-11-28 02:44:43,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:43,737 INFO:     Epoch: 85
2022-11-28 02:44:44,484 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39407049932263116, 'Total loss': 0.39407049932263116} | train loss {'Reaction outcome loss': 0.3158762177776711, 'Total loss': 0.3158762177776711}
2022-11-28 02:44:44,485 INFO:     Found new best model at epoch 85
2022-11-28 02:44:44,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:44,486 INFO:     Epoch: 86
2022-11-28 02:44:45,229 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42091903496872296, 'Total loss': 0.42091903496872296} | train loss {'Reaction outcome loss': 0.3017377224166384, 'Total loss': 0.3017377224166384}
2022-11-28 02:44:45,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:45,229 INFO:     Epoch: 87
2022-11-28 02:44:45,976 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4510167715224353, 'Total loss': 0.4510167715224353} | train loss {'Reaction outcome loss': 0.33931168482491847, 'Total loss': 0.33931168482491847}
2022-11-28 02:44:45,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:45,976 INFO:     Epoch: 88
2022-11-28 02:44:46,725 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4246896529062228, 'Total loss': 0.4246896529062228} | train loss {'Reaction outcome loss': 0.3056582497689224, 'Total loss': 0.3056582497689224}
2022-11-28 02:44:46,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:46,725 INFO:     Epoch: 89
2022-11-28 02:44:47,473 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4321943690831011, 'Total loss': 0.4321943690831011} | train loss {'Reaction outcome loss': 0.2851531807774384, 'Total loss': 0.2851531807774384}
2022-11-28 02:44:47,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:47,473 INFO:     Epoch: 90
2022-11-28 02:44:48,222 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4623841372403232, 'Total loss': 0.4623841372403232} | train loss {'Reaction outcome loss': 0.2988417812506197, 'Total loss': 0.2988417812506197}
2022-11-28 02:44:48,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:48,222 INFO:     Epoch: 91
2022-11-28 02:44:48,973 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4642223028296774, 'Total loss': 0.4642223028296774} | train loss {'Reaction outcome loss': 0.31201893929769153, 'Total loss': 0.31201893929769153}
2022-11-28 02:44:48,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:48,973 INFO:     Epoch: 92
2022-11-28 02:44:49,719 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43125138499520044, 'Total loss': 0.43125138499520044} | train loss {'Reaction outcome loss': 0.32239337635004084, 'Total loss': 0.32239337635004084}
2022-11-28 02:44:49,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:49,719 INFO:     Epoch: 93
2022-11-28 02:44:50,463 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4439027692106637, 'Total loss': 0.4439027692106637} | train loss {'Reaction outcome loss': 0.30231076343218805, 'Total loss': 0.30231076343218805}
2022-11-28 02:44:50,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:50,464 INFO:     Epoch: 94
2022-11-28 02:44:51,208 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4220923515544696, 'Total loss': 0.4220923515544696} | train loss {'Reaction outcome loss': 0.30669468701609715, 'Total loss': 0.30669468701609715}
2022-11-28 02:44:51,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:51,209 INFO:     Epoch: 95
2022-11-28 02:44:51,954 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45649191025983205, 'Total loss': 0.45649191025983205} | train loss {'Reaction outcome loss': 0.2943788506425276, 'Total loss': 0.2943788506425276}
2022-11-28 02:44:51,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:51,954 INFO:     Epoch: 96
2022-11-28 02:44:52,698 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40553192201663146, 'Total loss': 0.40553192201663146} | train loss {'Reaction outcome loss': 0.3026839710153669, 'Total loss': 0.3026839710153669}
2022-11-28 02:44:52,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:52,698 INFO:     Epoch: 97
2022-11-28 02:44:53,444 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4398153180425817, 'Total loss': 0.4398153180425817} | train loss {'Reaction outcome loss': 0.304545830135886, 'Total loss': 0.304545830135886}
2022-11-28 02:44:53,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:53,444 INFO:     Epoch: 98
2022-11-28 02:44:54,193 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4153473883528601, 'Total loss': 0.4153473883528601} | train loss {'Reaction outcome loss': 0.3134604014969065, 'Total loss': 0.3134604014969065}
2022-11-28 02:44:54,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:44:54,193 INFO:     Epoch: 99
2022-11-28 02:44:54,937 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46577313203703274, 'Total loss': 0.46577313203703274} | train loss {'Reaction outcome loss': 0.3043597381908884, 'Total loss': 0.3043597381908884}
2022-11-28 02:44:54,937 INFO:     Best model found after epoch 86 of 100.
2022-11-28 02:44:54,937 INFO:   Done with stage: TRAINING
2022-11-28 02:44:54,937 INFO:   Starting stage: EVALUATION
2022-11-28 02:44:55,062 INFO:   Done with stage: EVALUATION
2022-11-28 02:44:55,062 INFO: Done with stage: RUNNING SPLITS
2022-11-28 02:44:55,062 INFO: Starting stage: COMPUTE METRICS
2022-11-28 02:44:56,235 INFO: Done with stage: COMPUTE METRICS
2022-11-28 02:44:56,235 INFO: Starting stage: EXPORT RESULTS
2022-11-28 02:44:56,252 INFO:   Final results averaged over 50 folds: 
2022-11-28 02:44:56,256 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.171447           NaN  0.305252       NaN
2022-11-28 02:44:57,896 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 02:44:57,902 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 02:44:57,904 DEBUG:   interactive is False
2022-11-28 02:44:57,904 DEBUG:   platform is linux
2022-11-28 02:44:57,904 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 02:44:58,077 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 02:44:58,079 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 02:44:58,521 DEBUG:   Loaded backend agg version unknown.
2022-11-28 02:44:58,523 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,524 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,525 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,526 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,527 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 02:44:58,563 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,564 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,565 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,566 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,566 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 02:44:58,575 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,575 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,576 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 02:44:58,577 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 02:44:58,578 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 02:44:58,578 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 02:44:58,901 INFO: Done with stage: EXPORT RESULTS
2022-11-28 02:44:58,901 INFO: Starting stage: SAVE MODEL
2022-11-28 02:44:58,962 INFO: Done with stage: SAVE MODEL
2022-11-28 02:44:58,962 INFO: Wall time for program:  3798.48 seconds
