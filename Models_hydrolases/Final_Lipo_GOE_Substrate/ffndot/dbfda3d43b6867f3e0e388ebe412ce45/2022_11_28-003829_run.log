2022-11-28 02:45:01,221 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/dbfda3d43b6867f3e0e388ebe412ce45/2022_11_28-003829",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.0015553873022161448,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 02:45:01,228 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 02:45:01,234 INFO:   Creating esm representation model
2022-11-28 02:45:01,234 INFO:   Done esm representation model
2022-11-28 02:45:01,234 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 02:45:01,234 INFO: Starting stage: BUILDING DATASET
2022-11-28 02:45:01,287 INFO: Done with stage: BUILDING DATASET
2022-11-28 02:45:01,287 INFO: Starting stage: FEATURIZING DATA
2022-11-28 02:45:01,287 INFO:   Featurizing proteins
2022-11-28 02:45:01,289 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 02:45:01,309 INFO:   Loaded feature cache of size 204
2022-11-28 02:45:01,310 INFO:   Starting to pool ESM Embeddings
2022-11-28 02:45:01,405 INFO:   Featurizing molecules
2022-11-28 02:45:01,427 INFO: Done with stage: FEATURIZING DATA
2022-11-28 02:45:01,427 INFO: Starting stage: RUNNING SPLITS
2022-11-28 02:45:01,436 INFO:   Leaving out SEQ value Fold_0
2022-11-28 02:45:01,450 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:45:01,450 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:45:02,116 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:45:02,117 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:45:02,183 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:45:02,183 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:45:02,183 INFO:     No hyperparam tuning for this model
2022-11-28 02:45:02,183 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:45:02,184 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:45:02,184 INFO:     None feature selector for col prot
2022-11-28 02:45:02,184 INFO:     None feature selector for col prot
2022-11-28 02:45:02,185 INFO:     None feature selector for col prot
2022-11-28 02:45:02,185 INFO:     None feature selector for col chem
2022-11-28 02:45:02,185 INFO:     None feature selector for col chem
2022-11-28 02:45:02,185 INFO:     None feature selector for col chem
2022-11-28 02:45:02,185 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:45:02,185 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:45:02,187 INFO:     Number of params in model 169741
2022-11-28 02:45:02,187 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:45:02,187 INFO:   Starting stage: TRAINING
2022-11-28 02:45:04,215 INFO:     Val loss before train {'Reaction outcome loss': 1.0567488129748854, 'Total loss': 1.0567488129748854}
2022-11-28 02:45:04,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:04,215 INFO:     Epoch: 0
2022-11-28 02:45:04,952 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5499704268782638, 'Total loss': 0.5499704268782638} | train loss {'Reaction outcome loss': 0.6302739243771209, 'Total loss': 0.6302739243771209}
2022-11-28 02:45:04,953 INFO:     Found new best model at epoch 0
2022-11-28 02:45:04,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:04,953 INFO:     Epoch: 1
2022-11-28 02:45:05,689 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5136622776125752, 'Total loss': 0.5136622776125752} | train loss {'Reaction outcome loss': 0.5018058639691502, 'Total loss': 0.5018058639691502}
2022-11-28 02:45:05,690 INFO:     Found new best model at epoch 1
2022-11-28 02:45:05,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:05,691 INFO:     Epoch: 2
2022-11-28 02:45:06,426 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5320452867552291, 'Total loss': 0.5320452867552291} | train loss {'Reaction outcome loss': 0.46655050097186057, 'Total loss': 0.46655050097186057}
2022-11-28 02:45:06,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:06,427 INFO:     Epoch: 3
2022-11-28 02:45:07,159 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5152509177840033, 'Total loss': 0.5152509177840033} | train loss {'Reaction outcome loss': 0.43825694781224256, 'Total loss': 0.43825694781224256}
2022-11-28 02:45:07,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:07,160 INFO:     Epoch: 4
2022-11-28 02:45:07,900 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4815196637497392, 'Total loss': 0.4815196637497392} | train loss {'Reaction outcome loss': 0.42654051985897, 'Total loss': 0.42654051985897}
2022-11-28 02:45:07,901 INFO:     Found new best model at epoch 4
2022-11-28 02:45:07,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:07,902 INFO:     Epoch: 5
2022-11-28 02:45:08,641 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5081835666368174, 'Total loss': 0.5081835666368174} | train loss {'Reaction outcome loss': 0.411446535807164, 'Total loss': 0.411446535807164}
2022-11-28 02:45:08,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:08,641 INFO:     Epoch: 6
2022-11-28 02:45:09,375 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48142208089662153, 'Total loss': 0.48142208089662153} | train loss {'Reaction outcome loss': 0.4083882812715945, 'Total loss': 0.4083882812715945}
2022-11-28 02:45:09,376 INFO:     Found new best model at epoch 6
2022-11-28 02:45:09,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:09,376 INFO:     Epoch: 7
2022-11-28 02:45:10,112 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46865699422913926, 'Total loss': 0.46865699422913926} | train loss {'Reaction outcome loss': 0.4009970750842915, 'Total loss': 0.4009970750842915}
2022-11-28 02:45:10,112 INFO:     Found new best model at epoch 7
2022-11-28 02:45:10,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:10,113 INFO:     Epoch: 8
2022-11-28 02:45:10,852 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.496689515404923, 'Total loss': 0.496689515404923} | train loss {'Reaction outcome loss': 0.3807916352372678, 'Total loss': 0.3807916352372678}
2022-11-28 02:45:10,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:10,853 INFO:     Epoch: 9
2022-11-28 02:45:11,586 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4759210459021635, 'Total loss': 0.4759210459021635} | train loss {'Reaction outcome loss': 0.3864766902244482, 'Total loss': 0.3864766902244482}
2022-11-28 02:45:11,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:11,586 INFO:     Epoch: 10
2022-11-28 02:45:12,318 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46059124067772267, 'Total loss': 0.46059124067772267} | train loss {'Reaction outcome loss': 0.3769469762862217, 'Total loss': 0.3769469762862217}
2022-11-28 02:45:12,318 INFO:     Found new best model at epoch 10
2022-11-28 02:45:12,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:12,319 INFO:     Epoch: 11
2022-11-28 02:45:13,055 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4595906034458515, 'Total loss': 0.4595906034458515} | train loss {'Reaction outcome loss': 0.38383194333950027, 'Total loss': 0.38383194333950027}
2022-11-28 02:45:13,055 INFO:     Found new best model at epoch 11
2022-11-28 02:45:13,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:13,056 INFO:     Epoch: 12
2022-11-28 02:45:13,789 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.455865828450336, 'Total loss': 0.455865828450336} | train loss {'Reaction outcome loss': 0.3670398641499828, 'Total loss': 0.3670398641499828}
2022-11-28 02:45:13,789 INFO:     Found new best model at epoch 12
2022-11-28 02:45:13,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:13,790 INFO:     Epoch: 13
2022-11-28 02:45:14,536 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4640456205883691, 'Total loss': 0.4640456205883691} | train loss {'Reaction outcome loss': 0.3643381083536832, 'Total loss': 0.3643381083536832}
2022-11-28 02:45:14,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:14,537 INFO:     Epoch: 14
2022-11-28 02:45:15,277 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47420571848403575, 'Total loss': 0.47420571848403575} | train loss {'Reaction outcome loss': 0.36423315999449274, 'Total loss': 0.36423315999449274}
2022-11-28 02:45:15,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:15,277 INFO:     Epoch: 15
2022-11-28 02:45:16,013 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4822480449842852, 'Total loss': 0.4822480449842852} | train loss {'Reaction outcome loss': 0.35051763570699535, 'Total loss': 0.35051763570699535}
2022-11-28 02:45:16,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:16,014 INFO:     Epoch: 16
2022-11-28 02:45:16,752 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49242190947366316, 'Total loss': 0.49242190947366316} | train loss {'Reaction outcome loss': 0.3440739982990456, 'Total loss': 0.3440739982990456}
2022-11-28 02:45:16,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:16,752 INFO:     Epoch: 17
2022-11-28 02:45:17,488 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47528504909471025, 'Total loss': 0.47528504909471025} | train loss {'Reaction outcome loss': 0.34832985934297567, 'Total loss': 0.34832985934297567}
2022-11-28 02:45:17,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:17,488 INFO:     Epoch: 18
2022-11-28 02:45:18,225 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5468048734027285, 'Total loss': 0.5468048734027285} | train loss {'Reaction outcome loss': 0.3564719222791371, 'Total loss': 0.3564719222791371}
2022-11-28 02:45:18,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:18,225 INFO:     Epoch: 19
2022-11-28 02:45:18,959 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45660058842148893, 'Total loss': 0.45660058842148893} | train loss {'Reaction outcome loss': 0.34946936546046226, 'Total loss': 0.34946936546046226}
2022-11-28 02:45:18,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:18,959 INFO:     Epoch: 20
2022-11-28 02:45:19,694 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4478012832791306, 'Total loss': 0.4478012832791306} | train loss {'Reaction outcome loss': 0.338749226885008, 'Total loss': 0.338749226885008}
2022-11-28 02:45:19,694 INFO:     Found new best model at epoch 20
2022-11-28 02:45:19,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:19,695 INFO:     Epoch: 21
2022-11-28 02:45:20,426 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4930105510839196, 'Total loss': 0.4930105510839196} | train loss {'Reaction outcome loss': 0.3402899846617804, 'Total loss': 0.3402899846617804}
2022-11-28 02:45:20,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:20,427 INFO:     Epoch: 22
2022-11-28 02:45:21,165 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47085489783176154, 'Total loss': 0.47085489783176154} | train loss {'Reaction outcome loss': 0.34160294667741314, 'Total loss': 0.34160294667741314}
2022-11-28 02:45:21,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:21,165 INFO:     Epoch: 23
2022-11-28 02:45:21,899 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5018182545900345, 'Total loss': 0.5018182545900345} | train loss {'Reaction outcome loss': 0.3414227261711828, 'Total loss': 0.3414227261711828}
2022-11-28 02:45:21,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:21,899 INFO:     Epoch: 24
2022-11-28 02:45:22,630 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4936963721763256, 'Total loss': 0.4936963721763256} | train loss {'Reaction outcome loss': 0.33618423477059506, 'Total loss': 0.33618423477059506}
2022-11-28 02:45:22,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:22,630 INFO:     Epoch: 25
2022-11-28 02:45:23,366 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4886203075564185, 'Total loss': 0.4886203075564185} | train loss {'Reaction outcome loss': 0.34150859444844917, 'Total loss': 0.34150859444844917}
2022-11-28 02:45:23,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:23,366 INFO:     Epoch: 26
2022-11-28 02:45:24,104 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45246198565460916, 'Total loss': 0.45246198565460916} | train loss {'Reaction outcome loss': 0.3299986809400506, 'Total loss': 0.3299986809400506}
2022-11-28 02:45:24,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:24,104 INFO:     Epoch: 27
2022-11-28 02:45:24,842 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.449905568950398, 'Total loss': 0.449905568950398} | train loss {'Reaction outcome loss': 0.3376179224216059, 'Total loss': 0.3376179224216059}
2022-11-28 02:45:24,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:24,843 INFO:     Epoch: 28
2022-11-28 02:45:25,575 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48133361062338187, 'Total loss': 0.48133361062338187} | train loss {'Reaction outcome loss': 0.33282956957328513, 'Total loss': 0.33282956957328513}
2022-11-28 02:45:25,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:25,576 INFO:     Epoch: 29
2022-11-28 02:45:26,314 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5065313958844473, 'Total loss': 0.5065313958844473} | train loss {'Reaction outcome loss': 0.33833472910108137, 'Total loss': 0.33833472910108137}
2022-11-28 02:45:26,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:26,314 INFO:     Epoch: 30
2022-11-28 02:45:27,059 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4895724910636281, 'Total loss': 0.4895724910636281} | train loss {'Reaction outcome loss': 0.3306861188201631, 'Total loss': 0.3306861188201631}
2022-11-28 02:45:27,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:27,060 INFO:     Epoch: 31
2022-11-28 02:45:27,804 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.508599043932072, 'Total loss': 0.508599043932072} | train loss {'Reaction outcome loss': 0.34092303203632596, 'Total loss': 0.34092303203632596}
2022-11-28 02:45:27,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:27,804 INFO:     Epoch: 32
2022-11-28 02:45:28,545 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.468019045023031, 'Total loss': 0.468019045023031} | train loss {'Reaction outcome loss': 0.3311523140606577, 'Total loss': 0.3311523140606577}
2022-11-28 02:45:28,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:28,545 INFO:     Epoch: 33
2022-11-28 02:45:29,289 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46220252784185634, 'Total loss': 0.46220252784185634} | train loss {'Reaction outcome loss': 0.3287227535467656, 'Total loss': 0.3287227535467656}
2022-11-28 02:45:29,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:29,289 INFO:     Epoch: 34
2022-11-28 02:45:30,033 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4680826953330705, 'Total loss': 0.4680826953330705} | train loss {'Reaction outcome loss': 0.32015867363356176, 'Total loss': 0.32015867363356176}
2022-11-28 02:45:30,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:30,034 INFO:     Epoch: 35
2022-11-28 02:45:30,778 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4746483217838199, 'Total loss': 0.4746483217838199} | train loss {'Reaction outcome loss': 0.31824506260454655, 'Total loss': 0.31824506260454655}
2022-11-28 02:45:30,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:30,778 INFO:     Epoch: 36
2022-11-28 02:45:31,519 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4810786063587943, 'Total loss': 0.4810786063587943} | train loss {'Reaction outcome loss': 0.32790286301589405, 'Total loss': 0.32790286301589405}
2022-11-28 02:45:31,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:31,519 INFO:     Epoch: 37
2022-11-28 02:45:32,262 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4428451113229574, 'Total loss': 0.4428451113229574} | train loss {'Reaction outcome loss': 0.32578294672316216, 'Total loss': 0.32578294672316216}
2022-11-28 02:45:32,262 INFO:     Found new best model at epoch 37
2022-11-28 02:45:32,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:32,263 INFO:     Epoch: 38
2022-11-28 02:45:33,004 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4685911064924196, 'Total loss': 0.4685911064924196} | train loss {'Reaction outcome loss': 0.32274912230548314, 'Total loss': 0.32274912230548314}
2022-11-28 02:45:33,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:33,004 INFO:     Epoch: 39
2022-11-28 02:45:33,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45907832820748173, 'Total loss': 0.45907832820748173} | train loss {'Reaction outcome loss': 0.3274626004677571, 'Total loss': 0.3274626004677571}
2022-11-28 02:45:33,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:33,746 INFO:     Epoch: 40
2022-11-28 02:45:34,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46225755540437474, 'Total loss': 0.46225755540437474} | train loss {'Reaction outcome loss': 0.3259714277247425, 'Total loss': 0.3259714277247425}
2022-11-28 02:45:34,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:34,488 INFO:     Epoch: 41
2022-11-28 02:45:35,233 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4745740100394848, 'Total loss': 0.4745740100394848} | train loss {'Reaction outcome loss': 0.32482640332252277, 'Total loss': 0.32482640332252277}
2022-11-28 02:45:35,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:35,233 INFO:     Epoch: 42
2022-11-28 02:45:35,968 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4541372708802999, 'Total loss': 0.4541372708802999} | train loss {'Reaction outcome loss': 0.3318222455955187, 'Total loss': 0.3318222455955187}
2022-11-28 02:45:35,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:35,968 INFO:     Epoch: 43
2022-11-28 02:45:36,706 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46831860722497454, 'Total loss': 0.46831860722497454} | train loss {'Reaction outcome loss': 0.31607025241876235, 'Total loss': 0.31607025241876235}
2022-11-28 02:45:36,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:36,706 INFO:     Epoch: 44
2022-11-28 02:45:37,443 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4520746670490087, 'Total loss': 0.4520746670490087} | train loss {'Reaction outcome loss': 0.3204714549919132, 'Total loss': 0.3204714549919132}
2022-11-28 02:45:37,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:37,443 INFO:     Epoch: 45
2022-11-28 02:45:38,183 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4576539258624232, 'Total loss': 0.4576539258624232} | train loss {'Reaction outcome loss': 0.32280270798040217, 'Total loss': 0.32280270798040217}
2022-11-28 02:45:38,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:38,184 INFO:     Epoch: 46
2022-11-28 02:45:38,928 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44755813618038975, 'Total loss': 0.44755813618038975} | train loss {'Reaction outcome loss': 0.31411978229880333, 'Total loss': 0.31411978229880333}
2022-11-28 02:45:38,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:38,928 INFO:     Epoch: 47
2022-11-28 02:45:39,666 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46177220760389814, 'Total loss': 0.46177220760389814} | train loss {'Reaction outcome loss': 0.32046808549737343, 'Total loss': 0.32046808549737343}
2022-11-28 02:45:39,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:39,667 INFO:     Epoch: 48
2022-11-28 02:45:40,401 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4623431823281355, 'Total loss': 0.4623431823281355} | train loss {'Reaction outcome loss': 0.31745554308300133, 'Total loss': 0.31745554308300133}
2022-11-28 02:45:40,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:40,402 INFO:     Epoch: 49
2022-11-28 02:45:41,137 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4512581991594891, 'Total loss': 0.4512581991594891} | train loss {'Reaction outcome loss': 0.3141816181481862, 'Total loss': 0.3141816181481862}
2022-11-28 02:45:41,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:41,137 INFO:     Epoch: 50
2022-11-28 02:45:41,877 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4500841467186462, 'Total loss': 0.4500841467186462} | train loss {'Reaction outcome loss': 0.31371358317918463, 'Total loss': 0.31371358317918463}
2022-11-28 02:45:41,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:41,877 INFO:     Epoch: 51
2022-11-28 02:45:42,612 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45419793801252234, 'Total loss': 0.45419793801252234} | train loss {'Reaction outcome loss': 0.32087865398555504, 'Total loss': 0.32087865398555504}
2022-11-28 02:45:42,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:42,613 INFO:     Epoch: 52
2022-11-28 02:45:43,352 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4224560939988425, 'Total loss': 0.4224560939988425} | train loss {'Reaction outcome loss': 0.30819790071395575, 'Total loss': 0.30819790071395575}
2022-11-28 02:45:43,352 INFO:     Found new best model at epoch 52
2022-11-28 02:45:43,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:43,353 INFO:     Epoch: 53
2022-11-28 02:45:44,091 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4911504883405774, 'Total loss': 0.4911504883405774} | train loss {'Reaction outcome loss': 0.30950018430708864, 'Total loss': 0.30950018430708864}
2022-11-28 02:45:44,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:44,091 INFO:     Epoch: 54
2022-11-28 02:45:44,828 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4700055323367895, 'Total loss': 0.4700055323367895} | train loss {'Reaction outcome loss': 0.3116128179321035, 'Total loss': 0.3116128179321035}
2022-11-28 02:45:44,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:44,829 INFO:     Epoch: 55
2022-11-28 02:45:45,568 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44719055710836897, 'Total loss': 0.44719055710836897} | train loss {'Reaction outcome loss': 0.3196713484701563, 'Total loss': 0.3196713484701563}
2022-11-28 02:45:45,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:45,568 INFO:     Epoch: 56
2022-11-28 02:45:46,311 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4485583492489748, 'Total loss': 0.4485583492489748} | train loss {'Reaction outcome loss': 0.31089971176363895, 'Total loss': 0.31089971176363895}
2022-11-28 02:45:46,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:46,311 INFO:     Epoch: 57
2022-11-28 02:45:47,047 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48388883159604185, 'Total loss': 0.48388883159604185} | train loss {'Reaction outcome loss': 0.31035009298290384, 'Total loss': 0.31035009298290384}
2022-11-28 02:45:47,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:47,047 INFO:     Epoch: 58
2022-11-28 02:45:47,785 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.446600548056669, 'Total loss': 0.446600548056669} | train loss {'Reaction outcome loss': 0.3095881053414501, 'Total loss': 0.3095881053414501}
2022-11-28 02:45:47,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:47,785 INFO:     Epoch: 59
2022-11-28 02:45:48,522 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46938552828722224, 'Total loss': 0.46938552828722224} | train loss {'Reaction outcome loss': 0.31919758889030236, 'Total loss': 0.31919758889030236}
2022-11-28 02:45:48,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:48,522 INFO:     Epoch: 60
2022-11-28 02:45:49,256 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46058935758679415, 'Total loss': 0.46058935758679415} | train loss {'Reaction outcome loss': 0.31086846877683383, 'Total loss': 0.31086846877683383}
2022-11-28 02:45:49,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:49,256 INFO:     Epoch: 61
2022-11-28 02:45:49,994 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4849768076525178, 'Total loss': 0.4849768076525178} | train loss {'Reaction outcome loss': 0.30738897125435166, 'Total loss': 0.30738897125435166}
2022-11-28 02:45:49,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:49,994 INFO:     Epoch: 62
2022-11-28 02:45:50,734 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.463252512521522, 'Total loss': 0.463252512521522} | train loss {'Reaction outcome loss': 0.31090438816329985, 'Total loss': 0.31090438816329985}
2022-11-28 02:45:50,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:50,734 INFO:     Epoch: 63
2022-11-28 02:45:51,475 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4581444329300592, 'Total loss': 0.4581444329300592} | train loss {'Reaction outcome loss': 0.30575270533989196, 'Total loss': 0.30575270533989196}
2022-11-28 02:45:51,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:51,475 INFO:     Epoch: 64
2022-11-28 02:45:52,210 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4627699803474338, 'Total loss': 0.4627699803474338} | train loss {'Reaction outcome loss': 0.31254734447012184, 'Total loss': 0.31254734447012184}
2022-11-28 02:45:52,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:52,210 INFO:     Epoch: 65
2022-11-28 02:45:52,943 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46668035796908447, 'Total loss': 0.46668035796908447} | train loss {'Reaction outcome loss': 0.31191541282002067, 'Total loss': 0.31191541282002067}
2022-11-28 02:45:52,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:52,944 INFO:     Epoch: 66
2022-11-28 02:45:53,685 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45426942789277364, 'Total loss': 0.45426942789277364} | train loss {'Reaction outcome loss': 0.31096450566146216, 'Total loss': 0.31096450566146216}
2022-11-28 02:45:53,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:53,685 INFO:     Epoch: 67
2022-11-28 02:45:54,428 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46819647349590476, 'Total loss': 0.46819647349590476} | train loss {'Reaction outcome loss': 0.31115863078319633, 'Total loss': 0.31115863078319633}
2022-11-28 02:45:54,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:54,428 INFO:     Epoch: 68
2022-11-28 02:45:55,168 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4623664950215539, 'Total loss': 0.4623664950215539} | train loss {'Reaction outcome loss': 0.3008180134853379, 'Total loss': 0.3008180134853379}
2022-11-28 02:45:55,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:55,168 INFO:     Epoch: 69
2022-11-28 02:45:55,906 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4710924965004588, 'Total loss': 0.4710924965004588} | train loss {'Reaction outcome loss': 0.3115306928387431, 'Total loss': 0.3115306928387431}
2022-11-28 02:45:55,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:55,906 INFO:     Epoch: 70
2022-11-28 02:45:56,643 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4608816851017087, 'Total loss': 0.4608816851017087} | train loss {'Reaction outcome loss': 0.306405724163671, 'Total loss': 0.306405724163671}
2022-11-28 02:45:56,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:56,643 INFO:     Epoch: 71
2022-11-28 02:45:57,381 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44695478816365086, 'Total loss': 0.44695478816365086} | train loss {'Reaction outcome loss': 0.30588485697498086, 'Total loss': 0.30588485697498086}
2022-11-28 02:45:57,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:57,382 INFO:     Epoch: 72
2022-11-28 02:45:58,119 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45724482868993005, 'Total loss': 0.45724482868993005} | train loss {'Reaction outcome loss': 0.3070148334029268, 'Total loss': 0.3070148334029268}
2022-11-28 02:45:58,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:58,119 INFO:     Epoch: 73
2022-11-28 02:45:58,862 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47449564240699593, 'Total loss': 0.47449564240699593} | train loss {'Reaction outcome loss': 0.305115023856891, 'Total loss': 0.305115023856891}
2022-11-28 02:45:58,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:58,862 INFO:     Epoch: 74
2022-11-28 02:45:59,599 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4880668174388797, 'Total loss': 0.4880668174388797} | train loss {'Reaction outcome loss': 0.3118098764756664, 'Total loss': 0.3118098764756664}
2022-11-28 02:45:59,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:45:59,599 INFO:     Epoch: 75
2022-11-28 02:46:00,334 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47963326337725615, 'Total loss': 0.47963326337725615} | train loss {'Reaction outcome loss': 0.29740005930061225, 'Total loss': 0.29740005930061225}
2022-11-28 02:46:00,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:00,334 INFO:     Epoch: 76
2022-11-28 02:46:01,070 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4754548769357593, 'Total loss': 0.4754548769357593} | train loss {'Reaction outcome loss': 0.3149706260224835, 'Total loss': 0.3149706260224835}
2022-11-28 02:46:01,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:01,071 INFO:     Epoch: 77
2022-11-28 02:46:01,809 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4887792738371117, 'Total loss': 0.4887792738371117} | train loss {'Reaction outcome loss': 0.30871100592442224, 'Total loss': 0.30871100592442224}
2022-11-28 02:46:01,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:01,809 INFO:     Epoch: 78
2022-11-28 02:46:02,545 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4494559768327447, 'Total loss': 0.4494559768327447} | train loss {'Reaction outcome loss': 0.3119870091742668, 'Total loss': 0.3119870091742668}
2022-11-28 02:46:02,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:02,545 INFO:     Epoch: 79
2022-11-28 02:46:03,287 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4881544497817062, 'Total loss': 0.4881544497817062} | train loss {'Reaction outcome loss': 0.29979330444800073, 'Total loss': 0.29979330444800073}
2022-11-28 02:46:03,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:03,288 INFO:     Epoch: 80
2022-11-28 02:46:04,021 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4765268872643626, 'Total loss': 0.4765268872643626} | train loss {'Reaction outcome loss': 0.31436917512509666, 'Total loss': 0.31436917512509666}
2022-11-28 02:46:04,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:04,021 INFO:     Epoch: 81
2022-11-28 02:46:04,758 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4946829184543255, 'Total loss': 0.4946829184543255} | train loss {'Reaction outcome loss': 0.30750909273619537, 'Total loss': 0.30750909273619537}
2022-11-28 02:46:04,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:04,758 INFO:     Epoch: 82
2022-11-28 02:46:05,498 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4671171042461728, 'Total loss': 0.4671171042461728} | train loss {'Reaction outcome loss': 0.30305169745669014, 'Total loss': 0.30305169745669014}
2022-11-28 02:46:05,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:05,498 INFO:     Epoch: 83
2022-11-28 02:46:06,236 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46978272324384646, 'Total loss': 0.46978272324384646} | train loss {'Reaction outcome loss': 0.2993011026047781, 'Total loss': 0.2993011026047781}
2022-11-28 02:46:06,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:06,236 INFO:     Epoch: 84
2022-11-28 02:46:06,974 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44039497125980465, 'Total loss': 0.44039497125980465} | train loss {'Reaction outcome loss': 0.3183125683762988, 'Total loss': 0.3183125683762988}
2022-11-28 02:46:06,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:06,974 INFO:     Epoch: 85
2022-11-28 02:46:07,711 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48602575063705444, 'Total loss': 0.48602575063705444} | train loss {'Reaction outcome loss': 0.30426961801885094, 'Total loss': 0.30426961801885094}
2022-11-28 02:46:07,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:07,712 INFO:     Epoch: 86
2022-11-28 02:46:08,452 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4416372439889021, 'Total loss': 0.4416372439889021} | train loss {'Reaction outcome loss': 0.3010889175195308, 'Total loss': 0.3010889175195308}
2022-11-28 02:46:08,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:08,452 INFO:     Epoch: 87
2022-11-28 02:46:09,192 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4475338391439859, 'Total loss': 0.4475338391439859} | train loss {'Reaction outcome loss': 0.2991411177533083, 'Total loss': 0.2991411177533083}
2022-11-28 02:46:09,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:09,193 INFO:     Epoch: 88
2022-11-28 02:46:09,930 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45931003052134844, 'Total loss': 0.45931003052134844} | train loss {'Reaction outcome loss': 0.30669792711001925, 'Total loss': 0.30669792711001925}
2022-11-28 02:46:09,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:09,930 INFO:     Epoch: 89
2022-11-28 02:46:10,667 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4806565188391264, 'Total loss': 0.4806565188391264} | train loss {'Reaction outcome loss': 0.29916839900075415, 'Total loss': 0.29916839900075415}
2022-11-28 02:46:10,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:10,668 INFO:     Epoch: 90
2022-11-28 02:46:11,405 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4514628908661909, 'Total loss': 0.4514628908661909} | train loss {'Reaction outcome loss': 0.29785086064920074, 'Total loss': 0.29785086064920074}
2022-11-28 02:46:11,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:11,405 INFO:     Epoch: 91
2022-11-28 02:46:12,142 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4877145983452021, 'Total loss': 0.4877145983452021} | train loss {'Reaction outcome loss': 0.30416881039616517, 'Total loss': 0.30416881039616517}
2022-11-28 02:46:12,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:12,142 INFO:     Epoch: 92
2022-11-28 02:46:12,874 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5007136665111365, 'Total loss': 0.5007136665111365} | train loss {'Reaction outcome loss': 0.31376964113384975, 'Total loss': 0.31376964113384975}
2022-11-28 02:46:12,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:12,875 INFO:     Epoch: 93
2022-11-28 02:46:13,611 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4965968707273173, 'Total loss': 0.4965968707273173} | train loss {'Reaction outcome loss': 0.2983152629715986, 'Total loss': 0.2983152629715986}
2022-11-28 02:46:13,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:13,611 INFO:     Epoch: 94
2022-11-28 02:46:14,343 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44938681257325547, 'Total loss': 0.44938681257325547} | train loss {'Reaction outcome loss': 0.3137382057602288, 'Total loss': 0.3137382057602288}
2022-11-28 02:46:14,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:14,344 INFO:     Epoch: 95
2022-11-28 02:46:15,084 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4664638735527216, 'Total loss': 0.4664638735527216} | train loss {'Reaction outcome loss': 0.29718083589047684, 'Total loss': 0.29718083589047684}
2022-11-28 02:46:15,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:15,084 INFO:     Epoch: 96
2022-11-28 02:46:15,821 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4920663947975913, 'Total loss': 0.4920663947975913} | train loss {'Reaction outcome loss': 0.30172862152217844, 'Total loss': 0.30172862152217844}
2022-11-28 02:46:15,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:15,822 INFO:     Epoch: 97
2022-11-28 02:46:16,563 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46640346840370533, 'Total loss': 0.46640346840370533} | train loss {'Reaction outcome loss': 0.3127604329073038, 'Total loss': 0.3127604329073038}
2022-11-28 02:46:16,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:16,564 INFO:     Epoch: 98
2022-11-28 02:46:17,302 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43999337110408515, 'Total loss': 0.43999337110408515} | train loss {'Reaction outcome loss': 0.30039355836686543, 'Total loss': 0.30039355836686543}
2022-11-28 02:46:17,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:17,302 INFO:     Epoch: 99
2022-11-28 02:46:18,036 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5157297541235768, 'Total loss': 0.5157297541235768} | train loss {'Reaction outcome loss': 0.29563405706745677, 'Total loss': 0.29563405706745677}
2022-11-28 02:46:18,037 INFO:     Best model found after epoch 53 of 100.
2022-11-28 02:46:18,037 INFO:   Done with stage: TRAINING
2022-11-28 02:46:18,037 INFO:   Starting stage: EVALUATION
2022-11-28 02:46:18,170 INFO:   Done with stage: EVALUATION
2022-11-28 02:46:18,170 INFO:   Leaving out SEQ value Fold_1
2022-11-28 02:46:18,184 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:46:18,184 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:46:18,834 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:46:18,834 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:46:18,903 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:46:18,903 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:46:18,903 INFO:     No hyperparam tuning for this model
2022-11-28 02:46:18,903 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:46:18,903 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:46:18,904 INFO:     None feature selector for col prot
2022-11-28 02:46:18,904 INFO:     None feature selector for col prot
2022-11-28 02:46:18,904 INFO:     None feature selector for col prot
2022-11-28 02:46:18,905 INFO:     None feature selector for col chem
2022-11-28 02:46:18,905 INFO:     None feature selector for col chem
2022-11-28 02:46:18,905 INFO:     None feature selector for col chem
2022-11-28 02:46:18,905 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:46:18,905 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:46:18,907 INFO:     Number of params in model 169741
2022-11-28 02:46:18,910 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:46:18,910 INFO:   Starting stage: TRAINING
2022-11-28 02:46:18,963 INFO:     Val loss before train {'Reaction outcome loss': 1.0107056545940312, 'Total loss': 1.0107056545940312}
2022-11-28 02:46:18,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:18,964 INFO:     Epoch: 0
2022-11-28 02:46:19,710 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5069006315686486, 'Total loss': 0.5069006315686486} | train loss {'Reaction outcome loss': 0.6514484173192187, 'Total loss': 0.6514484173192187}
2022-11-28 02:46:19,711 INFO:     Found new best model at epoch 0
2022-11-28 02:46:19,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:19,711 INFO:     Epoch: 1
2022-11-28 02:46:20,459 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5078649178824641, 'Total loss': 0.5078649178824641} | train loss {'Reaction outcome loss': 0.5125379739743978, 'Total loss': 0.5125379739743978}
2022-11-28 02:46:20,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:20,459 INFO:     Epoch: 2
2022-11-28 02:46:21,202 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46606412868608127, 'Total loss': 0.46606412868608127} | train loss {'Reaction outcome loss': 0.4743103392814335, 'Total loss': 0.4743103392814335}
2022-11-28 02:46:21,202 INFO:     Found new best model at epoch 2
2022-11-28 02:46:21,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:21,203 INFO:     Epoch: 3
2022-11-28 02:46:21,949 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4918953918597915, 'Total loss': 0.4918953918597915} | train loss {'Reaction outcome loss': 0.45101012500674137, 'Total loss': 0.45101012500674137}
2022-11-28 02:46:21,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:21,949 INFO:     Epoch: 4
2022-11-28 02:46:22,695 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4410366514189677, 'Total loss': 0.4410366514189677} | train loss {'Reaction outcome loss': 0.43226157967378254, 'Total loss': 0.43226157967378254}
2022-11-28 02:46:22,695 INFO:     Found new best model at epoch 4
2022-11-28 02:46:22,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:22,696 INFO:     Epoch: 5
2022-11-28 02:46:23,440 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4301301349293102, 'Total loss': 0.4301301349293102} | train loss {'Reaction outcome loss': 0.41641893777770067, 'Total loss': 0.41641893777770067}
2022-11-28 02:46:23,441 INFO:     Found new best model at epoch 5
2022-11-28 02:46:23,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:23,442 INFO:     Epoch: 6
2022-11-28 02:46:24,189 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4354457191445611, 'Total loss': 0.4354457191445611} | train loss {'Reaction outcome loss': 0.4029082944277327, 'Total loss': 0.4029082944277327}
2022-11-28 02:46:24,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:24,189 INFO:     Epoch: 7
2022-11-28 02:46:24,937 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43257845125415106, 'Total loss': 0.43257845125415106} | train loss {'Reaction outcome loss': 0.4007178616789188, 'Total loss': 0.4007178616789188}
2022-11-28 02:46:24,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:24,938 INFO:     Epoch: 8
2022-11-28 02:46:25,681 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4402399205348708, 'Total loss': 0.4402399205348708} | train loss {'Reaction outcome loss': 0.4027484800772146, 'Total loss': 0.4027484800772146}
2022-11-28 02:46:25,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:25,682 INFO:     Epoch: 9
2022-11-28 02:46:26,432 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4064894125542857, 'Total loss': 0.4064894125542857} | train loss {'Reaction outcome loss': 0.3962442932522249, 'Total loss': 0.3962442932522249}
2022-11-28 02:46:26,432 INFO:     Found new best model at epoch 9
2022-11-28 02:46:26,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:26,433 INFO:     Epoch: 10
2022-11-28 02:46:27,176 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41221794147383084, 'Total loss': 0.41221794147383084} | train loss {'Reaction outcome loss': 0.3946441307301946, 'Total loss': 0.3946441307301946}
2022-11-28 02:46:27,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:27,176 INFO:     Epoch: 11
2022-11-28 02:46:27,922 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4302694601091472, 'Total loss': 0.4302694601091472} | train loss {'Reaction outcome loss': 0.3814103107348929, 'Total loss': 0.3814103107348929}
2022-11-28 02:46:27,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:27,923 INFO:     Epoch: 12
2022-11-28 02:46:28,673 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4380583038384264, 'Total loss': 0.4380583038384264} | train loss {'Reaction outcome loss': 0.367334560887051, 'Total loss': 0.367334560887051}
2022-11-28 02:46:28,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:28,673 INFO:     Epoch: 13
2022-11-28 02:46:29,419 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4183533415198326, 'Total loss': 0.4183533415198326} | train loss {'Reaction outcome loss': 0.37315848321175044, 'Total loss': 0.37315848321175044}
2022-11-28 02:46:29,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:29,419 INFO:     Epoch: 14
2022-11-28 02:46:30,167 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40128125521269714, 'Total loss': 0.40128125521269714} | train loss {'Reaction outcome loss': 0.3629557213063544, 'Total loss': 0.3629557213063544}
2022-11-28 02:46:30,167 INFO:     Found new best model at epoch 14
2022-11-28 02:46:30,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:30,168 INFO:     Epoch: 15
2022-11-28 02:46:30,916 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3949028460139578, 'Total loss': 0.3949028460139578} | train loss {'Reaction outcome loss': 0.35726110091214236, 'Total loss': 0.35726110091214236}
2022-11-28 02:46:30,916 INFO:     Found new best model at epoch 15
2022-11-28 02:46:30,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:30,917 INFO:     Epoch: 16
2022-11-28 02:46:31,662 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42204429988156666, 'Total loss': 0.42204429988156666} | train loss {'Reaction outcome loss': 0.373997183252684, 'Total loss': 0.373997183252684}
2022-11-28 02:46:31,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:31,662 INFO:     Epoch: 17
2022-11-28 02:46:32,407 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40540692244063725, 'Total loss': 0.40540692244063725} | train loss {'Reaction outcome loss': 0.35810363643731064, 'Total loss': 0.35810363643731064}
2022-11-28 02:46:32,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:32,407 INFO:     Epoch: 18
2022-11-28 02:46:33,154 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40259226834909484, 'Total loss': 0.40259226834909484} | train loss {'Reaction outcome loss': 0.3481753339938186, 'Total loss': 0.3481753339938186}
2022-11-28 02:46:33,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:33,154 INFO:     Epoch: 19
2022-11-28 02:46:33,903 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4443910958414728, 'Total loss': 0.4443910958414728} | train loss {'Reaction outcome loss': 0.35315033328919276, 'Total loss': 0.35315033328919276}
2022-11-28 02:46:33,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:33,903 INFO:     Epoch: 20
2022-11-28 02:46:34,646 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.435119406235489, 'Total loss': 0.435119406235489} | train loss {'Reaction outcome loss': 0.37343673739838695, 'Total loss': 0.37343673739838695}
2022-11-28 02:46:34,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:34,647 INFO:     Epoch: 21
2022-11-28 02:46:35,391 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4036657285283912, 'Total loss': 0.4036657285283912} | train loss {'Reaction outcome loss': 0.35420798973334944, 'Total loss': 0.35420798973334944}
2022-11-28 02:46:35,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:35,392 INFO:     Epoch: 22
2022-11-28 02:46:36,138 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3996578925712542, 'Total loss': 0.3996578925712542} | train loss {'Reaction outcome loss': 0.3744093388741316, 'Total loss': 0.3744093388741316}
2022-11-28 02:46:36,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:36,138 INFO:     Epoch: 23
2022-11-28 02:46:36,884 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42037978531284764, 'Total loss': 0.42037978531284764} | train loss {'Reaction outcome loss': 0.35406263258594733, 'Total loss': 0.35406263258594733}
2022-11-28 02:46:36,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:36,884 INFO:     Epoch: 24
2022-11-28 02:46:37,632 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4004830541935834, 'Total loss': 0.4004830541935834} | train loss {'Reaction outcome loss': 0.35215025772208625, 'Total loss': 0.35215025772208625}
2022-11-28 02:46:37,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:37,633 INFO:     Epoch: 25
2022-11-28 02:46:38,382 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4097485173154961, 'Total loss': 0.4097485173154961} | train loss {'Reaction outcome loss': 0.344424638429634, 'Total loss': 0.344424638429634}
2022-11-28 02:46:38,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:38,383 INFO:     Epoch: 26
2022-11-28 02:46:39,127 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.420032298700376, 'Total loss': 0.420032298700376} | train loss {'Reaction outcome loss': 0.3440025118999711, 'Total loss': 0.3440025118999711}
2022-11-28 02:46:39,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:39,127 INFO:     Epoch: 27
2022-11-28 02:46:39,871 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39860554632138123, 'Total loss': 0.39860554632138123} | train loss {'Reaction outcome loss': 0.3397857739556174, 'Total loss': 0.3397857739556174}
2022-11-28 02:46:39,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:39,871 INFO:     Epoch: 28
2022-11-28 02:46:40,621 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40581264143640344, 'Total loss': 0.40581264143640344} | train loss {'Reaction outcome loss': 0.34784820630603475, 'Total loss': 0.34784820630603475}
2022-11-28 02:46:40,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:40,622 INFO:     Epoch: 29
2022-11-28 02:46:41,367 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43488896705887536, 'Total loss': 0.43488896705887536} | train loss {'Reaction outcome loss': 0.39659761103541263, 'Total loss': 0.39659761103541263}
2022-11-28 02:46:41,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:41,368 INFO:     Epoch: 30
2022-11-28 02:46:42,113 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4408735624429854, 'Total loss': 0.4408735624429854} | train loss {'Reaction outcome loss': 0.34939800806132404, 'Total loss': 0.34939800806132404}
2022-11-28 02:46:42,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:42,114 INFO:     Epoch: 31
2022-11-28 02:46:42,861 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5088876431638544, 'Total loss': 0.5088876431638544} | train loss {'Reaction outcome loss': 0.34408016841451405, 'Total loss': 0.34408016841451405}
2022-11-28 02:46:42,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:42,861 INFO:     Epoch: 32
2022-11-28 02:46:43,610 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4053592543033036, 'Total loss': 0.4053592543033036} | train loss {'Reaction outcome loss': 0.3438841809465848, 'Total loss': 0.3438841809465848}
2022-11-28 02:46:43,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:43,610 INFO:     Epoch: 33
2022-11-28 02:46:44,356 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42081690511920233, 'Total loss': 0.42081690511920233} | train loss {'Reaction outcome loss': 0.34424768896539687, 'Total loss': 0.34424768896539687}
2022-11-28 02:46:44,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:44,357 INFO:     Epoch: 34
2022-11-28 02:46:45,100 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41680562089789996, 'Total loss': 0.41680562089789996} | train loss {'Reaction outcome loss': 0.3519801300100092, 'Total loss': 0.3519801300100092}
2022-11-28 02:46:45,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:45,100 INFO:     Epoch: 35
2022-11-28 02:46:45,843 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39175702360543335, 'Total loss': 0.39175702360543335} | train loss {'Reaction outcome loss': 0.3352353283871523, 'Total loss': 0.3352353283871523}
2022-11-28 02:46:45,844 INFO:     Found new best model at epoch 35
2022-11-28 02:46:45,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:45,844 INFO:     Epoch: 36
2022-11-28 02:46:46,591 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4885133982382037, 'Total loss': 0.4885133982382037} | train loss {'Reaction outcome loss': 0.34704098244869763, 'Total loss': 0.34704098244869763}
2022-11-28 02:46:46,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:46,592 INFO:     Epoch: 37
2022-11-28 02:46:47,336 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41742797873236914, 'Total loss': 0.41742797873236914} | train loss {'Reaction outcome loss': 0.3335331136639784, 'Total loss': 0.3335331136639784}
2022-11-28 02:46:47,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:47,337 INFO:     Epoch: 38
2022-11-28 02:46:48,083 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4084828782149337, 'Total loss': 0.4084828782149337} | train loss {'Reaction outcome loss': 0.3325735013554936, 'Total loss': 0.3325735013554936}
2022-11-28 02:46:48,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:48,083 INFO:     Epoch: 39
2022-11-28 02:46:48,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4449093633077361, 'Total loss': 0.4449093633077361} | train loss {'Reaction outcome loss': 0.33628845486322395, 'Total loss': 0.33628845486322395}
2022-11-28 02:46:48,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:48,828 INFO:     Epoch: 40
2022-11-28 02:46:49,575 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4070938835767182, 'Total loss': 0.4070938835767182} | train loss {'Reaction outcome loss': 0.3428262194264152, 'Total loss': 0.3428262194264152}
2022-11-28 02:46:49,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:49,575 INFO:     Epoch: 41
2022-11-28 02:46:50,320 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37756332619623706, 'Total loss': 0.37756332619623706} | train loss {'Reaction outcome loss': 0.3422191953248823, 'Total loss': 0.3422191953248823}
2022-11-28 02:46:50,320 INFO:     Found new best model at epoch 41
2022-11-28 02:46:50,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:50,321 INFO:     Epoch: 42
2022-11-28 02:46:51,069 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41680827059529046, 'Total loss': 0.41680827059529046} | train loss {'Reaction outcome loss': 0.3337947306966009, 'Total loss': 0.3337947306966009}
2022-11-28 02:46:51,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:51,070 INFO:     Epoch: 43
2022-11-28 02:46:51,819 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4128231863406571, 'Total loss': 0.4128231863406571} | train loss {'Reaction outcome loss': 0.3446248156670858, 'Total loss': 0.3446248156670858}
2022-11-28 02:46:51,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:51,819 INFO:     Epoch: 44
2022-11-28 02:46:52,564 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40755249627611856, 'Total loss': 0.40755249627611856} | train loss {'Reaction outcome loss': 0.33762310194945044, 'Total loss': 0.33762310194945044}
2022-11-28 02:46:52,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:52,565 INFO:     Epoch: 45
2022-11-28 02:46:53,310 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3804264644330198, 'Total loss': 0.3804264644330198} | train loss {'Reaction outcome loss': 0.3289708663883378, 'Total loss': 0.3289708663883378}
2022-11-28 02:46:53,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:53,310 INFO:     Epoch: 46
2022-11-28 02:46:54,051 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4105737226253206, 'Total loss': 0.4105737226253206} | train loss {'Reaction outcome loss': 0.3391904746623416, 'Total loss': 0.3391904746623416}
2022-11-28 02:46:54,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:54,051 INFO:     Epoch: 47
2022-11-28 02:46:54,794 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3898574191738259, 'Total loss': 0.3898574191738259} | train loss {'Reaction outcome loss': 0.3387479979680617, 'Total loss': 0.3387479979680617}
2022-11-28 02:46:54,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:54,794 INFO:     Epoch: 48
2022-11-28 02:46:55,542 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.373196867717938, 'Total loss': 0.373196867717938} | train loss {'Reaction outcome loss': 0.3337918523141006, 'Total loss': 0.3337918523141006}
2022-11-28 02:46:55,542 INFO:     Found new best model at epoch 48
2022-11-28 02:46:55,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:55,543 INFO:     Epoch: 49
2022-11-28 02:46:56,290 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3943435045128519, 'Total loss': 0.3943435045128519} | train loss {'Reaction outcome loss': 0.32508720959789356, 'Total loss': 0.32508720959789356}
2022-11-28 02:46:56,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:56,290 INFO:     Epoch: 50
2022-11-28 02:46:57,038 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.392632166093046, 'Total loss': 0.392632166093046} | train loss {'Reaction outcome loss': 0.33829533715208293, 'Total loss': 0.33829533715208293}
2022-11-28 02:46:57,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:57,038 INFO:     Epoch: 51
2022-11-28 02:46:57,784 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3919057490473444, 'Total loss': 0.3919057490473444} | train loss {'Reaction outcome loss': 0.3266508096022162, 'Total loss': 0.3266508096022162}
2022-11-28 02:46:57,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:57,785 INFO:     Epoch: 52
2022-11-28 02:46:58,530 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41933034191077406, 'Total loss': 0.41933034191077406} | train loss {'Reaction outcome loss': 0.3253050167792239, 'Total loss': 0.3253050167792239}
2022-11-28 02:46:58,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:58,530 INFO:     Epoch: 53
2022-11-28 02:46:59,277 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41390848921781237, 'Total loss': 0.41390848921781237} | train loss {'Reaction outcome loss': 0.32805178242053096, 'Total loss': 0.32805178242053096}
2022-11-28 02:46:59,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:46:59,277 INFO:     Epoch: 54
2022-11-28 02:47:00,023 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43491058322516357, 'Total loss': 0.43491058322516357} | train loss {'Reaction outcome loss': 0.3446213937541734, 'Total loss': 0.3446213937541734}
2022-11-28 02:47:00,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:00,024 INFO:     Epoch: 55
2022-11-28 02:47:00,775 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43074733103540813, 'Total loss': 0.43074733103540813} | train loss {'Reaction outcome loss': 0.3259242865811234, 'Total loss': 0.3259242865811234}
2022-11-28 02:47:00,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:00,776 INFO:     Epoch: 56
2022-11-28 02:47:01,523 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3997157801958648, 'Total loss': 0.3997157801958648} | train loss {'Reaction outcome loss': 0.33068655648453515, 'Total loss': 0.33068655648453515}
2022-11-28 02:47:01,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:01,523 INFO:     Epoch: 57
2022-11-28 02:47:02,271 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4058420312675563, 'Total loss': 0.4058420312675563} | train loss {'Reaction outcome loss': 0.3234453732788804, 'Total loss': 0.3234453732788804}
2022-11-28 02:47:02,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:02,271 INFO:     Epoch: 58
2022-11-28 02:47:03,018 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37946830012581567, 'Total loss': 0.37946830012581567} | train loss {'Reaction outcome loss': 0.334485650794163, 'Total loss': 0.334485650794163}
2022-11-28 02:47:03,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:03,019 INFO:     Epoch: 59
2022-11-28 02:47:03,768 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4706708003174175, 'Total loss': 0.4706708003174175} | train loss {'Reaction outcome loss': 0.3293819424473805, 'Total loss': 0.3293819424473805}
2022-11-28 02:47:03,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:03,768 INFO:     Epoch: 60
2022-11-28 02:47:04,514 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43120143054561183, 'Total loss': 0.43120143054561183} | train loss {'Reaction outcome loss': 0.3304231820499849, 'Total loss': 0.3304231820499849}
2022-11-28 02:47:04,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:04,514 INFO:     Epoch: 61
2022-11-28 02:47:05,263 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4121049161661755, 'Total loss': 0.4121049161661755} | train loss {'Reaction outcome loss': 0.3345209207792996, 'Total loss': 0.3345209207792996}
2022-11-28 02:47:05,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:05,263 INFO:     Epoch: 62
2022-11-28 02:47:06,013 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3772385089912198, 'Total loss': 0.3772385089912198} | train loss {'Reaction outcome loss': 0.33171116381255356, 'Total loss': 0.33171116381255356}
2022-11-28 02:47:06,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:06,013 INFO:     Epoch: 63
2022-11-28 02:47:06,764 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3961542739786885, 'Total loss': 0.3961542739786885} | train loss {'Reaction outcome loss': 0.3229461264332779, 'Total loss': 0.3229461264332779}
2022-11-28 02:47:06,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:06,764 INFO:     Epoch: 64
2022-11-28 02:47:07,514 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39275150187313557, 'Total loss': 0.39275150187313557} | train loss {'Reaction outcome loss': 0.319923547507539, 'Total loss': 0.319923547507539}
2022-11-28 02:47:07,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:07,515 INFO:     Epoch: 65
2022-11-28 02:47:08,266 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4554845887151631, 'Total loss': 0.4554845887151631} | train loss {'Reaction outcome loss': 0.3374582752283768, 'Total loss': 0.3374582752283768}
2022-11-28 02:47:08,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:08,266 INFO:     Epoch: 66
2022-11-28 02:47:09,018 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38671664419499313, 'Total loss': 0.38671664419499313} | train loss {'Reaction outcome loss': 0.338570651888606, 'Total loss': 0.338570651888606}
2022-11-28 02:47:09,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:09,018 INFO:     Epoch: 67
2022-11-28 02:47:09,767 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39435953545299446, 'Total loss': 0.39435953545299446} | train loss {'Reaction outcome loss': 0.3247318845166851, 'Total loss': 0.3247318845166851}
2022-11-28 02:47:09,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:09,768 INFO:     Epoch: 68
2022-11-28 02:47:10,516 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39423967457630416, 'Total loss': 0.39423967457630416} | train loss {'Reaction outcome loss': 0.32297978817903805, 'Total loss': 0.32297978817903805}
2022-11-28 02:47:10,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:10,516 INFO:     Epoch: 69
2022-11-28 02:47:11,267 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40861651724712417, 'Total loss': 0.40861651724712417} | train loss {'Reaction outcome loss': 0.32632794998645565, 'Total loss': 0.32632794998645565}
2022-11-28 02:47:11,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:11,267 INFO:     Epoch: 70
2022-11-28 02:47:12,019 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39612605659799144, 'Total loss': 0.39612605659799144} | train loss {'Reaction outcome loss': 0.3266650956531285, 'Total loss': 0.3266650956531285}
2022-11-28 02:47:12,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:12,020 INFO:     Epoch: 71
2022-11-28 02:47:12,769 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4050720680335706, 'Total loss': 0.4050720680335706} | train loss {'Reaction outcome loss': 0.33323471404815674, 'Total loss': 0.33323471404815674}
2022-11-28 02:47:12,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:12,769 INFO:     Epoch: 72
2022-11-28 02:47:13,512 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4087880826131864, 'Total loss': 0.4087880826131864} | train loss {'Reaction outcome loss': 0.31607532719794007, 'Total loss': 0.31607532719794007}
2022-11-28 02:47:13,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:13,512 INFO:     Epoch: 73
2022-11-28 02:47:14,255 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.442799545485865, 'Total loss': 0.442799545485865} | train loss {'Reaction outcome loss': 0.32640547501413447, 'Total loss': 0.32640547501413447}
2022-11-28 02:47:14,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:14,256 INFO:     Epoch: 74
2022-11-28 02:47:15,003 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4090451567687772, 'Total loss': 0.4090451567687772} | train loss {'Reaction outcome loss': 0.32653338396342035, 'Total loss': 0.32653338396342035}
2022-11-28 02:47:15,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:15,003 INFO:     Epoch: 75
2022-11-28 02:47:15,750 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40505087104710663, 'Total loss': 0.40505087104710663} | train loss {'Reaction outcome loss': 0.32662412350778636, 'Total loss': 0.32662412350778636}
2022-11-28 02:47:15,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:15,751 INFO:     Epoch: 76
2022-11-28 02:47:16,495 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3926892453296618, 'Total loss': 0.3926892453296618} | train loss {'Reaction outcome loss': 0.3346584602089425, 'Total loss': 0.3346584602089425}
2022-11-28 02:47:16,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:16,495 INFO:     Epoch: 77
2022-11-28 02:47:17,243 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4023879397321831, 'Total loss': 0.4023879397321831} | train loss {'Reaction outcome loss': 0.31988745310762334, 'Total loss': 0.31988745310762334}
2022-11-28 02:47:17,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:17,243 INFO:     Epoch: 78
2022-11-28 02:47:17,993 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3983575805005702, 'Total loss': 0.3983575805005702} | train loss {'Reaction outcome loss': 0.32222497891559293, 'Total loss': 0.32222497891559293}
2022-11-28 02:47:17,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:17,993 INFO:     Epoch: 79
2022-11-28 02:47:18,739 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40506984530524776, 'Total loss': 0.40506984530524776} | train loss {'Reaction outcome loss': 0.32001925706260115, 'Total loss': 0.32001925706260115}
2022-11-28 02:47:18,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:18,740 INFO:     Epoch: 80
2022-11-28 02:47:19,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4427941670133309, 'Total loss': 0.4427941670133309} | train loss {'Reaction outcome loss': 0.3231753110508566, 'Total loss': 0.3231753110508566}
2022-11-28 02:47:19,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:19,490 INFO:     Epoch: 81
2022-11-28 02:47:20,234 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41406627879901364, 'Total loss': 0.41406627879901364} | train loss {'Reaction outcome loss': 0.31962966871813603, 'Total loss': 0.31962966871813603}
2022-11-28 02:47:20,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:20,235 INFO:     Epoch: 82
2022-11-28 02:47:20,976 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4686060246418823, 'Total loss': 0.4686060246418823} | train loss {'Reaction outcome loss': 0.32267951995552296, 'Total loss': 0.32267951995552296}
2022-11-28 02:47:20,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:20,977 INFO:     Epoch: 83
2022-11-28 02:47:21,720 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38391951234503224, 'Total loss': 0.38391951234503224} | train loss {'Reaction outcome loss': 0.32559564489464043, 'Total loss': 0.32559564489464043}
2022-11-28 02:47:21,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:21,720 INFO:     Epoch: 84
2022-11-28 02:47:22,462 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42787094888362015, 'Total loss': 0.42787094888362015} | train loss {'Reaction outcome loss': 0.3281346196044794, 'Total loss': 0.3281346196044794}
2022-11-28 02:47:22,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:22,463 INFO:     Epoch: 85
2022-11-28 02:47:23,205 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.387639157474041, 'Total loss': 0.387639157474041} | train loss {'Reaction outcome loss': 0.3227335638913367, 'Total loss': 0.3227335638913367}
2022-11-28 02:47:23,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:23,205 INFO:     Epoch: 86
2022-11-28 02:47:23,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39700324477797205, 'Total loss': 0.39700324477797205} | train loss {'Reaction outcome loss': 0.32988014322543435, 'Total loss': 0.32988014322543435}
2022-11-28 02:47:23,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:23,947 INFO:     Epoch: 87
2022-11-28 02:47:24,690 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4164766428822821, 'Total loss': 0.4164766428822821} | train loss {'Reaction outcome loss': 0.3490171590556017, 'Total loss': 0.3490171590556017}
2022-11-28 02:47:24,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:24,690 INFO:     Epoch: 88
2022-11-28 02:47:25,432 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42424407245760615, 'Total loss': 0.42424407245760615} | train loss {'Reaction outcome loss': 0.32243328172204966, 'Total loss': 0.32243328172204966}
2022-11-28 02:47:25,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:25,432 INFO:     Epoch: 89
2022-11-28 02:47:26,170 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3849436024373228, 'Total loss': 0.3849436024373228} | train loss {'Reaction outcome loss': 0.3288779063555619, 'Total loss': 0.3288779063555619}
2022-11-28 02:47:26,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:26,171 INFO:     Epoch: 90
2022-11-28 02:47:26,908 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3942395726388151, 'Total loss': 0.3942395726388151} | train loss {'Reaction outcome loss': 0.31137063233596596, 'Total loss': 0.31137063233596596}
2022-11-28 02:47:26,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:26,908 INFO:     Epoch: 91
2022-11-28 02:47:27,654 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4046684154732661, 'Total loss': 0.4046684154732661} | train loss {'Reaction outcome loss': 0.326839282264111, 'Total loss': 0.326839282264111}
2022-11-28 02:47:27,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:27,654 INFO:     Epoch: 92
2022-11-28 02:47:28,399 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42399111288515007, 'Total loss': 0.42399111288515007} | train loss {'Reaction outcome loss': 0.33675550907729607, 'Total loss': 0.33675550907729607}
2022-11-28 02:47:28,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:28,399 INFO:     Epoch: 93
2022-11-28 02:47:29,143 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4011387208645994, 'Total loss': 0.4011387208645994} | train loss {'Reaction outcome loss': 0.33306561180931016, 'Total loss': 0.33306561180931016}
2022-11-28 02:47:29,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:29,143 INFO:     Epoch: 94
2022-11-28 02:47:29,888 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39127257838845253, 'Total loss': 0.39127257838845253} | train loss {'Reaction outcome loss': 0.3170876118697618, 'Total loss': 0.3170876118697618}
2022-11-28 02:47:29,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:29,888 INFO:     Epoch: 95
2022-11-28 02:47:30,627 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42888164604929363, 'Total loss': 0.42888164604929363} | train loss {'Reaction outcome loss': 0.32489887591798294, 'Total loss': 0.32489887591798294}
2022-11-28 02:47:30,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:30,627 INFO:     Epoch: 96
2022-11-28 02:47:31,368 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38642206957394426, 'Total loss': 0.38642206957394426} | train loss {'Reaction outcome loss': 0.3173104077275948, 'Total loss': 0.3173104077275948}
2022-11-28 02:47:31,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:31,368 INFO:     Epoch: 97
2022-11-28 02:47:32,108 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4227860451421954, 'Total loss': 0.4227860451421954} | train loss {'Reaction outcome loss': 0.3363421077459206, 'Total loss': 0.3363421077459206}
2022-11-28 02:47:32,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:32,109 INFO:     Epoch: 98
2022-11-28 02:47:32,854 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41711663285439665, 'Total loss': 0.41711663285439665} | train loss {'Reaction outcome loss': 0.3288884573137229, 'Total loss': 0.3288884573137229}
2022-11-28 02:47:32,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:32,855 INFO:     Epoch: 99
2022-11-28 02:47:33,597 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.447224616327069, 'Total loss': 0.447224616327069} | train loss {'Reaction outcome loss': 0.31893483440765, 'Total loss': 0.31893483440765}
2022-11-28 02:47:33,597 INFO:     Best model found after epoch 49 of 100.
2022-11-28 02:47:33,597 INFO:   Done with stage: TRAINING
2022-11-28 02:47:33,597 INFO:   Starting stage: EVALUATION
2022-11-28 02:47:33,717 INFO:   Done with stage: EVALUATION
2022-11-28 02:47:33,717 INFO:   Leaving out SEQ value Fold_2
2022-11-28 02:47:33,730 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 02:47:33,730 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:47:34,366 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:47:34,366 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:47:34,435 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:47:34,435 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:47:34,435 INFO:     No hyperparam tuning for this model
2022-11-28 02:47:34,435 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:47:34,436 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:47:34,436 INFO:     None feature selector for col prot
2022-11-28 02:47:34,436 INFO:     None feature selector for col prot
2022-11-28 02:47:34,436 INFO:     None feature selector for col prot
2022-11-28 02:47:34,437 INFO:     None feature selector for col chem
2022-11-28 02:47:34,437 INFO:     None feature selector for col chem
2022-11-28 02:47:34,437 INFO:     None feature selector for col chem
2022-11-28 02:47:34,437 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:47:34,437 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:47:34,439 INFO:     Number of params in model 169741
2022-11-28 02:47:34,442 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:47:34,442 INFO:   Starting stage: TRAINING
2022-11-28 02:47:34,494 INFO:     Val loss before train {'Reaction outcome loss': 0.957724138747814, 'Total loss': 0.957724138747814}
2022-11-28 02:47:34,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:34,495 INFO:     Epoch: 0
2022-11-28 02:47:35,229 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5524949389834737, 'Total loss': 0.5524949389834737} | train loss {'Reaction outcome loss': 0.6385550833627825, 'Total loss': 0.6385550833627825}
2022-11-28 02:47:35,229 INFO:     Found new best model at epoch 0
2022-11-28 02:47:35,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:35,230 INFO:     Epoch: 1
2022-11-28 02:47:35,964 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4597954705011013, 'Total loss': 0.4597954705011013} | train loss {'Reaction outcome loss': 0.5071448242810906, 'Total loss': 0.5071448242810906}
2022-11-28 02:47:35,964 INFO:     Found new best model at epoch 1
2022-11-28 02:47:35,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:35,965 INFO:     Epoch: 2
2022-11-28 02:47:36,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43401816799197085, 'Total loss': 0.43401816799197085} | train loss {'Reaction outcome loss': 0.46981143108645423, 'Total loss': 0.46981143108645423}
2022-11-28 02:47:36,701 INFO:     Found new best model at epoch 2
2022-11-28 02:47:36,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:36,701 INFO:     Epoch: 3
2022-11-28 02:47:37,436 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45188253147657526, 'Total loss': 0.45188253147657526} | train loss {'Reaction outcome loss': 0.4353885789264421, 'Total loss': 0.4353885789264421}
2022-11-28 02:47:37,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:37,436 INFO:     Epoch: 4
2022-11-28 02:47:38,171 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45044976680777793, 'Total loss': 0.45044976680777793} | train loss {'Reaction outcome loss': 0.4234617517680907, 'Total loss': 0.4234617517680907}
2022-11-28 02:47:38,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:38,172 INFO:     Epoch: 5
2022-11-28 02:47:38,905 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4423403469629066, 'Total loss': 0.4423403469629066} | train loss {'Reaction outcome loss': 0.4204153234719253, 'Total loss': 0.4204153234719253}
2022-11-28 02:47:38,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:38,906 INFO:     Epoch: 6
2022-11-28 02:47:39,641 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4344854465750761, 'Total loss': 0.4344854465750761} | train loss {'Reaction outcome loss': 0.40159267645146024, 'Total loss': 0.40159267645146024}
2022-11-28 02:47:39,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:39,642 INFO:     Epoch: 7
2022-11-28 02:47:40,379 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4277695472850356, 'Total loss': 0.4277695472850356} | train loss {'Reaction outcome loss': 0.39368239821499734, 'Total loss': 0.39368239821499734}
2022-11-28 02:47:40,379 INFO:     Found new best model at epoch 7
2022-11-28 02:47:40,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:40,380 INFO:     Epoch: 8
2022-11-28 02:47:41,113 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.417401879679325, 'Total loss': 0.417401879679325} | train loss {'Reaction outcome loss': 0.39148828750628917, 'Total loss': 0.39148828750628917}
2022-11-28 02:47:41,114 INFO:     Found new best model at epoch 8
2022-11-28 02:47:41,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:41,114 INFO:     Epoch: 9
2022-11-28 02:47:41,851 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4143411201793094, 'Total loss': 0.4143411201793094} | train loss {'Reaction outcome loss': 0.384128086116226, 'Total loss': 0.384128086116226}
2022-11-28 02:47:41,851 INFO:     Found new best model at epoch 9
2022-11-28 02:47:41,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:41,852 INFO:     Epoch: 10
2022-11-28 02:47:42,592 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4133764176174652, 'Total loss': 0.4133764176174652} | train loss {'Reaction outcome loss': 0.3794750212462711, 'Total loss': 0.3794750212462711}
2022-11-28 02:47:42,592 INFO:     Found new best model at epoch 10
2022-11-28 02:47:42,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:42,593 INFO:     Epoch: 11
2022-11-28 02:47:43,327 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42483090522677397, 'Total loss': 0.42483090522677397} | train loss {'Reaction outcome loss': 0.3724236968660452, 'Total loss': 0.3724236968660452}
2022-11-28 02:47:43,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:43,328 INFO:     Epoch: 12
2022-11-28 02:47:44,060 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43229929756286534, 'Total loss': 0.43229929756286534} | train loss {'Reaction outcome loss': 0.37883947235455767, 'Total loss': 0.37883947235455767}
2022-11-28 02:47:44,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:44,061 INFO:     Epoch: 13
2022-11-28 02:47:44,795 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43889203667640686, 'Total loss': 0.43889203667640686} | train loss {'Reaction outcome loss': 0.37876647997830737, 'Total loss': 0.37876647997830737}
2022-11-28 02:47:44,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:44,795 INFO:     Epoch: 14
2022-11-28 02:47:45,533 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44029451646777085, 'Total loss': 0.44029451646777085} | train loss {'Reaction outcome loss': 0.35989692675896356, 'Total loss': 0.35989692675896356}
2022-11-28 02:47:45,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:45,534 INFO:     Epoch: 15
2022-11-28 02:47:46,279 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41646932342717813, 'Total loss': 0.41646932342717813} | train loss {'Reaction outcome loss': 0.3583949139555458, 'Total loss': 0.3583949139555458}
2022-11-28 02:47:46,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:46,279 INFO:     Epoch: 16
2022-11-28 02:47:47,016 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4255263455385386, 'Total loss': 0.4255263455385386} | train loss {'Reaction outcome loss': 0.36095821213160384, 'Total loss': 0.36095821213160384}
2022-11-28 02:47:47,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:47,016 INFO:     Epoch: 17
2022-11-28 02:47:47,750 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41152189325454624, 'Total loss': 0.41152189325454624} | train loss {'Reaction outcome loss': 0.353442338951787, 'Total loss': 0.353442338951787}
2022-11-28 02:47:47,750 INFO:     Found new best model at epoch 17
2022-11-28 02:47:47,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:47,751 INFO:     Epoch: 18
2022-11-28 02:47:48,493 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3844958739571793, 'Total loss': 0.3844958739571793} | train loss {'Reaction outcome loss': 0.3613582456820324, 'Total loss': 0.3613582456820324}
2022-11-28 02:47:48,494 INFO:     Found new best model at epoch 18
2022-11-28 02:47:48,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:48,494 INFO:     Epoch: 19
2022-11-28 02:47:49,230 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43636794111063315, 'Total loss': 0.43636794111063315} | train loss {'Reaction outcome loss': 0.3529038209712408, 'Total loss': 0.3529038209712408}
2022-11-28 02:47:49,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:49,231 INFO:     Epoch: 20
2022-11-28 02:47:49,966 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41251379043556924, 'Total loss': 0.41251379043556924} | train loss {'Reaction outcome loss': 0.35111052448265867, 'Total loss': 0.35111052448265867}
2022-11-28 02:47:49,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:49,967 INFO:     Epoch: 21
2022-11-28 02:47:50,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43972950688628265, 'Total loss': 0.43972950688628265} | train loss {'Reaction outcome loss': 0.36125162799583105, 'Total loss': 0.36125162799583105}
2022-11-28 02:47:50,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:50,705 INFO:     Epoch: 22
2022-11-28 02:47:51,441 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43387546407621963, 'Total loss': 0.43387546407621963} | train loss {'Reaction outcome loss': 0.35481368350323106, 'Total loss': 0.35481368350323106}
2022-11-28 02:47:51,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:51,441 INFO:     Epoch: 23
2022-11-28 02:47:52,178 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4283396535834601, 'Total loss': 0.4283396535834601} | train loss {'Reaction outcome loss': 0.33389264965032944, 'Total loss': 0.33389264965032944}
2022-11-28 02:47:52,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:52,178 INFO:     Epoch: 24
2022-11-28 02:47:52,912 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4047547079796015, 'Total loss': 0.4047547079796015} | train loss {'Reaction outcome loss': 0.3434960363035808, 'Total loss': 0.3434960363035808}
2022-11-28 02:47:52,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:52,912 INFO:     Epoch: 25
2022-11-28 02:47:53,649 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43084470303945765, 'Total loss': 0.43084470303945765} | train loss {'Reaction outcome loss': 0.34011873831880873, 'Total loss': 0.34011873831880873}
2022-11-28 02:47:53,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:53,650 INFO:     Epoch: 26
2022-11-28 02:47:54,391 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41495548916417496, 'Total loss': 0.41495548916417496} | train loss {'Reaction outcome loss': 0.34923534956379015, 'Total loss': 0.34923534956379015}
2022-11-28 02:47:54,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:54,391 INFO:     Epoch: 27
2022-11-28 02:47:55,126 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4421046809401623, 'Total loss': 0.4421046809401623} | train loss {'Reaction outcome loss': 0.33731222048890397, 'Total loss': 0.33731222048890397}
2022-11-28 02:47:55,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:55,126 INFO:     Epoch: 28
2022-11-28 02:47:55,862 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4157822489045387, 'Total loss': 0.4157822489045387} | train loss {'Reaction outcome loss': 0.3450424118791936, 'Total loss': 0.3450424118791936}
2022-11-28 02:47:55,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:55,862 INFO:     Epoch: 29
2022-11-28 02:47:56,599 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40456266458644424, 'Total loss': 0.40456266458644424} | train loss {'Reaction outcome loss': 0.3442991661732314, 'Total loss': 0.3442991661732314}
2022-11-28 02:47:56,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:56,599 INFO:     Epoch: 30
2022-11-28 02:47:57,330 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42350167053383453, 'Total loss': 0.42350167053383453} | train loss {'Reaction outcome loss': 0.335645019244708, 'Total loss': 0.335645019244708}
2022-11-28 02:47:57,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:57,331 INFO:     Epoch: 31
2022-11-28 02:47:58,062 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4182349582051122, 'Total loss': 0.4182349582051122} | train loss {'Reaction outcome loss': 0.3418250477216283, 'Total loss': 0.3418250477216283}
2022-11-28 02:47:58,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:58,063 INFO:     Epoch: 32
2022-11-28 02:47:58,800 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45420106448406394, 'Total loss': 0.45420106448406394} | train loss {'Reaction outcome loss': 0.3285631309950449, 'Total loss': 0.3285631309950449}
2022-11-28 02:47:58,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:58,800 INFO:     Epoch: 33
2022-11-28 02:47:59,539 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44958720616129944, 'Total loss': 0.44958720616129944} | train loss {'Reaction outcome loss': 0.3273614620270788, 'Total loss': 0.3273614620270788}
2022-11-28 02:47:59,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:47:59,539 INFO:     Epoch: 34
2022-11-28 02:48:00,275 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4167658296781917, 'Total loss': 0.4167658296781917} | train loss {'Reaction outcome loss': 0.33043463051807687, 'Total loss': 0.33043463051807687}
2022-11-28 02:48:00,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:00,276 INFO:     Epoch: 35
2022-11-28 02:48:01,010 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45336532142273217, 'Total loss': 0.45336532142273217} | train loss {'Reaction outcome loss': 0.3275896414931192, 'Total loss': 0.3275896414931192}
2022-11-28 02:48:01,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:01,011 INFO:     Epoch: 36
2022-11-28 02:48:01,752 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4470337580802829, 'Total loss': 0.4470337580802829} | train loss {'Reaction outcome loss': 0.3328042307899135, 'Total loss': 0.3328042307899135}
2022-11-28 02:48:01,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:01,753 INFO:     Epoch: 37
2022-11-28 02:48:02,489 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4032231891571089, 'Total loss': 0.4032231891571089} | train loss {'Reaction outcome loss': 0.3267880456491572, 'Total loss': 0.3267880456491572}
2022-11-28 02:48:02,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:02,490 INFO:     Epoch: 38
2022-11-28 02:48:03,224 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44328564058902653, 'Total loss': 0.44328564058902653} | train loss {'Reaction outcome loss': 0.3295579352797788, 'Total loss': 0.3295579352797788}
2022-11-28 02:48:03,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:03,225 INFO:     Epoch: 39
2022-11-28 02:48:03,957 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46527176714220714, 'Total loss': 0.46527176714220714} | train loss {'Reaction outcome loss': 0.3357902966806146, 'Total loss': 0.3357902966806146}
2022-11-28 02:48:03,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:03,957 INFO:     Epoch: 40
2022-11-28 02:48:04,695 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3977784138432769, 'Total loss': 0.3977784138432769} | train loss {'Reaction outcome loss': 0.32882534773623356, 'Total loss': 0.32882534773623356}
2022-11-28 02:48:04,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:04,696 INFO:     Epoch: 41
2022-11-28 02:48:05,433 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4492762608583583, 'Total loss': 0.4492762608583583} | train loss {'Reaction outcome loss': 0.32870296801089266, 'Total loss': 0.32870296801089266}
2022-11-28 02:48:05,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:05,433 INFO:     Epoch: 42
2022-11-28 02:48:06,167 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4459597783726315, 'Total loss': 0.4459597783726315} | train loss {'Reaction outcome loss': 0.3157871323103299, 'Total loss': 0.3157871323103299}
2022-11-28 02:48:06,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:06,168 INFO:     Epoch: 43
2022-11-28 02:48:06,905 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.431807677413142, 'Total loss': 0.431807677413142} | train loss {'Reaction outcome loss': 0.32954521171870776, 'Total loss': 0.32954521171870776}
2022-11-28 02:48:06,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:06,905 INFO:     Epoch: 44
2022-11-28 02:48:07,645 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4455415201048518, 'Total loss': 0.4455415201048518} | train loss {'Reaction outcome loss': 0.32829222083091736, 'Total loss': 0.32829222083091736}
2022-11-28 02:48:07,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:07,646 INFO:     Epoch: 45
2022-11-28 02:48:08,385 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4142764328524124, 'Total loss': 0.4142764328524124} | train loss {'Reaction outcome loss': 0.3156828081052079, 'Total loss': 0.3156828081052079}
2022-11-28 02:48:08,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:08,385 INFO:     Epoch: 46
2022-11-28 02:48:09,122 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4075514147447985, 'Total loss': 0.4075514147447985} | train loss {'Reaction outcome loss': 0.31977704836086174, 'Total loss': 0.31977704836086174}
2022-11-28 02:48:09,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:09,122 INFO:     Epoch: 47
2022-11-28 02:48:09,862 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4147687271930451, 'Total loss': 0.4147687271930451} | train loss {'Reaction outcome loss': 0.3351784575669492, 'Total loss': 0.3351784575669492}
2022-11-28 02:48:09,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:09,862 INFO:     Epoch: 48
2022-11-28 02:48:10,601 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4344888485448305, 'Total loss': 0.4344888485448305} | train loss {'Reaction outcome loss': 0.3282793283951087, 'Total loss': 0.3282793283951087}
2022-11-28 02:48:10,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:10,602 INFO:     Epoch: 49
2022-11-28 02:48:11,341 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43372988215712616, 'Total loss': 0.43372988215712616} | train loss {'Reaction outcome loss': 0.32240319568053133, 'Total loss': 0.32240319568053133}
2022-11-28 02:48:11,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:11,341 INFO:     Epoch: 50
2022-11-28 02:48:12,086 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41792754118525705, 'Total loss': 0.41792754118525705} | train loss {'Reaction outcome loss': 0.3302330091351368, 'Total loss': 0.3302330091351368}
2022-11-28 02:48:12,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:12,086 INFO:     Epoch: 51
2022-11-28 02:48:12,827 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.423263942432958, 'Total loss': 0.423263942432958} | train loss {'Reaction outcome loss': 0.3217409219684415, 'Total loss': 0.3217409219684415}
2022-11-28 02:48:12,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:12,827 INFO:     Epoch: 52
2022-11-28 02:48:13,562 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41577359826065774, 'Total loss': 0.41577359826065774} | train loss {'Reaction outcome loss': 0.3317530659928185, 'Total loss': 0.3317530659928185}
2022-11-28 02:48:13,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:13,563 INFO:     Epoch: 53
2022-11-28 02:48:14,300 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43914373426936393, 'Total loss': 0.43914373426936393} | train loss {'Reaction outcome loss': 0.3139781703042691, 'Total loss': 0.3139781703042691}
2022-11-28 02:48:14,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:14,301 INFO:     Epoch: 54
2022-11-28 02:48:15,039 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5122227159350418, 'Total loss': 0.5122227159350418} | train loss {'Reaction outcome loss': 0.3250466514317716, 'Total loss': 0.3250466514317716}
2022-11-28 02:48:15,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:15,040 INFO:     Epoch: 55
2022-11-28 02:48:15,780 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4184898855381234, 'Total loss': 0.4184898855381234} | train loss {'Reaction outcome loss': 0.32333341359970025, 'Total loss': 0.32333341359970025}
2022-11-28 02:48:15,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:15,780 INFO:     Epoch: 56
2022-11-28 02:48:16,519 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4199749529361725, 'Total loss': 0.4199749529361725} | train loss {'Reaction outcome loss': 0.32191727371489415, 'Total loss': 0.32191727371489415}
2022-11-28 02:48:16,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:16,520 INFO:     Epoch: 57
2022-11-28 02:48:17,254 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42976468697536824, 'Total loss': 0.42976468697536824} | train loss {'Reaction outcome loss': 0.31821599764535663, 'Total loss': 0.31821599764535663}
2022-11-28 02:48:17,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:17,254 INFO:     Epoch: 58
2022-11-28 02:48:17,994 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4612676411174064, 'Total loss': 0.4612676411174064} | train loss {'Reaction outcome loss': 0.32168769124956403, 'Total loss': 0.32168769124956403}
2022-11-28 02:48:17,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:17,995 INFO:     Epoch: 59
2022-11-28 02:48:18,736 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4079057546549065, 'Total loss': 0.4079057546549065} | train loss {'Reaction outcome loss': 0.3306526521709366, 'Total loss': 0.3306526521709366}
2022-11-28 02:48:18,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:18,736 INFO:     Epoch: 60
2022-11-28 02:48:19,474 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4393913887960966, 'Total loss': 0.4393913887960966} | train loss {'Reaction outcome loss': 0.32779490388929844, 'Total loss': 0.32779490388929844}
2022-11-28 02:48:19,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:19,474 INFO:     Epoch: 61
2022-11-28 02:48:20,209 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.413725056447262, 'Total loss': 0.413725056447262} | train loss {'Reaction outcome loss': 0.31670660299600145, 'Total loss': 0.31670660299600145}
2022-11-28 02:48:20,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:20,209 INFO:     Epoch: 62
2022-11-28 02:48:20,946 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41457038112851075, 'Total loss': 0.41457038112851075} | train loss {'Reaction outcome loss': 0.32175445526105456, 'Total loss': 0.32175445526105456}
2022-11-28 02:48:20,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:20,947 INFO:     Epoch: 63
2022-11-28 02:48:21,686 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4274880906870199, 'Total loss': 0.4274880906870199} | train loss {'Reaction outcome loss': 0.3162147711473899, 'Total loss': 0.3162147711473899}
2022-11-28 02:48:21,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:21,686 INFO:     Epoch: 64
2022-11-28 02:48:22,426 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43030623052009315, 'Total loss': 0.43030623052009315} | train loss {'Reaction outcome loss': 0.3299442151652985, 'Total loss': 0.3299442151652985}
2022-11-28 02:48:22,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:22,427 INFO:     Epoch: 65
2022-11-28 02:48:23,168 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44055322089860605, 'Total loss': 0.44055322089860605} | train loss {'Reaction outcome loss': 0.3209642920582021, 'Total loss': 0.3209642920582021}
2022-11-28 02:48:23,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:23,168 INFO:     Epoch: 66
2022-11-28 02:48:23,911 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4205532926459645, 'Total loss': 0.4205532926459645} | train loss {'Reaction outcome loss': 0.31653488874740776, 'Total loss': 0.31653488874740776}
2022-11-28 02:48:23,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:23,911 INFO:     Epoch: 67
2022-11-28 02:48:24,649 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40649709521337996, 'Total loss': 0.40649709521337996} | train loss {'Reaction outcome loss': 0.31792081797831373, 'Total loss': 0.31792081797831373}
2022-11-28 02:48:24,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:24,650 INFO:     Epoch: 68
2022-11-28 02:48:25,391 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40121960639953613, 'Total loss': 0.40121960639953613} | train loss {'Reaction outcome loss': 0.3206350227176655, 'Total loss': 0.3206350227176655}
2022-11-28 02:48:25,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:25,391 INFO:     Epoch: 69
2022-11-28 02:48:26,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38996718754602033, 'Total loss': 0.38996718754602033} | train loss {'Reaction outcome loss': 0.3192553805095739, 'Total loss': 0.3192553805095739}
2022-11-28 02:48:26,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:26,128 INFO:     Epoch: 70
2022-11-28 02:48:26,863 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40101905513641445, 'Total loss': 0.40101905513641445} | train loss {'Reaction outcome loss': 0.3184382871526187, 'Total loss': 0.3184382871526187}
2022-11-28 02:48:26,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:26,864 INFO:     Epoch: 71
2022-11-28 02:48:27,600 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41266250956890194, 'Total loss': 0.41266250956890194} | train loss {'Reaction outcome loss': 0.31727631574832516, 'Total loss': 0.31727631574832516}
2022-11-28 02:48:27,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:27,600 INFO:     Epoch: 72
2022-11-28 02:48:28,338 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4630798948712127, 'Total loss': 0.4630798948712127} | train loss {'Reaction outcome loss': 0.3214758994729548, 'Total loss': 0.3214758994729548}
2022-11-28 02:48:28,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:28,338 INFO:     Epoch: 73
2022-11-28 02:48:29,073 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4105249175931825, 'Total loss': 0.4105249175931825} | train loss {'Reaction outcome loss': 0.31444316210805395, 'Total loss': 0.31444316210805395}
2022-11-28 02:48:29,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:29,073 INFO:     Epoch: 74
2022-11-28 02:48:29,810 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41368050249510036, 'Total loss': 0.41368050249510036} | train loss {'Reaction outcome loss': 0.3074812960246059, 'Total loss': 0.3074812960246059}
2022-11-28 02:48:29,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:29,810 INFO:     Epoch: 75
2022-11-28 02:48:30,549 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3969367943530859, 'Total loss': 0.3969367943530859} | train loss {'Reaction outcome loss': 0.32469773011617975, 'Total loss': 0.32469773011617975}
2022-11-28 02:48:30,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:30,549 INFO:     Epoch: 76
2022-11-28 02:48:31,286 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4320242063597191, 'Total loss': 0.4320242063597191} | train loss {'Reaction outcome loss': 0.31496100671222954, 'Total loss': 0.31496100671222954}
2022-11-28 02:48:31,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:31,286 INFO:     Epoch: 77
2022-11-28 02:48:32,026 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41554350943066354, 'Total loss': 0.41554350943066354} | train loss {'Reaction outcome loss': 0.3143624343955126, 'Total loss': 0.3143624343955126}
2022-11-28 02:48:32,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:32,027 INFO:     Epoch: 78
2022-11-28 02:48:32,766 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4111545798043872, 'Total loss': 0.4111545798043872} | train loss {'Reaction outcome loss': 0.31622095986223614, 'Total loss': 0.31622095986223614}
2022-11-28 02:48:32,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:32,766 INFO:     Epoch: 79
2022-11-28 02:48:33,499 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4095249155233073, 'Total loss': 0.4095249155233073} | train loss {'Reaction outcome loss': 0.3182146868317342, 'Total loss': 0.3182146868317342}
2022-11-28 02:48:33,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:33,499 INFO:     Epoch: 80
2022-11-28 02:48:34,239 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41386248032714046, 'Total loss': 0.41386248032714046} | train loss {'Reaction outcome loss': 0.32222258266000475, 'Total loss': 0.32222258266000475}
2022-11-28 02:48:34,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:34,239 INFO:     Epoch: 81
2022-11-28 02:48:34,983 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4347999284780303, 'Total loss': 0.4347999284780303} | train loss {'Reaction outcome loss': 0.31539894527465595, 'Total loss': 0.31539894527465595}
2022-11-28 02:48:34,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:34,983 INFO:     Epoch: 82
2022-11-28 02:48:35,726 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41059944380161373, 'Total loss': 0.41059944380161373} | train loss {'Reaction outcome loss': 0.31944374981351564, 'Total loss': 0.31944374981351564}
2022-11-28 02:48:35,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:35,726 INFO:     Epoch: 83
2022-11-28 02:48:36,463 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4383642871019452, 'Total loss': 0.4383642871019452} | train loss {'Reaction outcome loss': 0.3117054130759884, 'Total loss': 0.3117054130759884}
2022-11-28 02:48:36,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:36,463 INFO:     Epoch: 84
2022-11-28 02:48:37,201 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4046329062345416, 'Total loss': 0.4046329062345416} | train loss {'Reaction outcome loss': 0.32342009365436486, 'Total loss': 0.32342009365436486}
2022-11-28 02:48:37,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:37,201 INFO:     Epoch: 85
2022-11-28 02:48:37,937 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4401659955118978, 'Total loss': 0.4401659955118978} | train loss {'Reaction outcome loss': 0.31637687445236523, 'Total loss': 0.31637687445236523}
2022-11-28 02:48:37,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:37,937 INFO:     Epoch: 86
2022-11-28 02:48:38,671 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41742081281750704, 'Total loss': 0.41742081281750704} | train loss {'Reaction outcome loss': 0.31569738209736153, 'Total loss': 0.31569738209736153}
2022-11-28 02:48:38,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:38,671 INFO:     Epoch: 87
2022-11-28 02:48:39,407 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4177444542563239, 'Total loss': 0.4177444542563239} | train loss {'Reaction outcome loss': 0.31557750529380607, 'Total loss': 0.31557750529380607}
2022-11-28 02:48:39,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:39,407 INFO:     Epoch: 88
2022-11-28 02:48:40,143 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42125169846207594, 'Total loss': 0.42125169846207594} | train loss {'Reaction outcome loss': 0.3068222406274471, 'Total loss': 0.3068222406274471}
2022-11-28 02:48:40,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:40,143 INFO:     Epoch: 89
2022-11-28 02:48:40,885 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40771742087117463, 'Total loss': 0.40771742087117463} | train loss {'Reaction outcome loss': 0.3101954321972415, 'Total loss': 0.3101954321972415}
2022-11-28 02:48:40,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:40,885 INFO:     Epoch: 90
2022-11-28 02:48:41,622 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4291450970394667, 'Total loss': 0.4291450970394667} | train loss {'Reaction outcome loss': 0.3181987059928599, 'Total loss': 0.3181987059928599}
2022-11-28 02:48:41,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:41,623 INFO:     Epoch: 91
2022-11-28 02:48:42,364 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41978060055610744, 'Total loss': 0.41978060055610744} | train loss {'Reaction outcome loss': 0.3111943053539659, 'Total loss': 0.3111943053539659}
2022-11-28 02:48:42,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:42,364 INFO:     Epoch: 92
2022-11-28 02:48:43,104 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4269091680992481, 'Total loss': 0.4269091680992481} | train loss {'Reaction outcome loss': 0.3164659190739765, 'Total loss': 0.3164659190739765}
2022-11-28 02:48:43,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:43,105 INFO:     Epoch: 93
2022-11-28 02:48:43,845 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44700810105301614, 'Total loss': 0.44700810105301614} | train loss {'Reaction outcome loss': 0.31911723447017004, 'Total loss': 0.31911723447017004}
2022-11-28 02:48:43,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:43,845 INFO:     Epoch: 94
2022-11-28 02:48:44,590 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3973144942591357, 'Total loss': 0.3973144942591357} | train loss {'Reaction outcome loss': 0.32449162133099113, 'Total loss': 0.32449162133099113}
2022-11-28 02:48:44,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:44,590 INFO:     Epoch: 95
2022-11-28 02:48:45,329 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4075596464234729, 'Total loss': 0.4075596464234729} | train loss {'Reaction outcome loss': 0.3209284591625948, 'Total loss': 0.3209284591625948}
2022-11-28 02:48:45,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:45,331 INFO:     Epoch: 96
2022-11-28 02:48:46,072 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4384341459981231, 'Total loss': 0.4384341459981231} | train loss {'Reaction outcome loss': 0.31073383354871975, 'Total loss': 0.31073383354871975}
2022-11-28 02:48:46,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:46,072 INFO:     Epoch: 97
2022-11-28 02:48:46,815 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4287734693566034, 'Total loss': 0.4287734693566034} | train loss {'Reaction outcome loss': 0.31783139656801696, 'Total loss': 0.31783139656801696}
2022-11-28 02:48:46,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:46,815 INFO:     Epoch: 98
2022-11-28 02:48:47,550 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41745041241479475, 'Total loss': 0.41745041241479475} | train loss {'Reaction outcome loss': 0.30997157658709856, 'Total loss': 0.30997157658709856}
2022-11-28 02:48:47,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:47,550 INFO:     Epoch: 99
2022-11-28 02:48:48,280 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42890690977490226, 'Total loss': 0.42890690977490226} | train loss {'Reaction outcome loss': 0.31016757556038804, 'Total loss': 0.31016757556038804}
2022-11-28 02:48:48,280 INFO:     Best model found after epoch 19 of 100.
2022-11-28 02:48:48,281 INFO:   Done with stage: TRAINING
2022-11-28 02:48:48,281 INFO:   Starting stage: EVALUATION
2022-11-28 02:48:48,413 INFO:   Done with stage: EVALUATION
2022-11-28 02:48:48,413 INFO:   Leaving out SEQ value Fold_3
2022-11-28 02:48:48,426 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 02:48:48,426 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:48:49,065 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:48:49,065 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:48:49,132 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:48:49,132 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:48:49,133 INFO:     No hyperparam tuning for this model
2022-11-28 02:48:49,133 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:48:49,133 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:48:49,133 INFO:     None feature selector for col prot
2022-11-28 02:48:49,133 INFO:     None feature selector for col prot
2022-11-28 02:48:49,134 INFO:     None feature selector for col prot
2022-11-28 02:48:49,134 INFO:     None feature selector for col chem
2022-11-28 02:48:49,134 INFO:     None feature selector for col chem
2022-11-28 02:48:49,134 INFO:     None feature selector for col chem
2022-11-28 02:48:49,134 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:48:49,134 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:48:49,136 INFO:     Number of params in model 169741
2022-11-28 02:48:49,139 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:48:49,139 INFO:   Starting stage: TRAINING
2022-11-28 02:48:49,192 INFO:     Val loss before train {'Reaction outcome loss': 1.0004954005396642, 'Total loss': 1.0004954005396642}
2022-11-28 02:48:49,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:49,192 INFO:     Epoch: 0
2022-11-28 02:48:49,924 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5022064114725867, 'Total loss': 0.5022064114725867} | train loss {'Reaction outcome loss': 0.6261796816386314, 'Total loss': 0.6261796816386314}
2022-11-28 02:48:49,924 INFO:     Found new best model at epoch 0
2022-11-28 02:48:49,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:49,925 INFO:     Epoch: 1
2022-11-28 02:48:50,657 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4790700043356696, 'Total loss': 0.4790700043356696} | train loss {'Reaction outcome loss': 0.49299797342147356, 'Total loss': 0.49299797342147356}
2022-11-28 02:48:50,657 INFO:     Found new best model at epoch 1
2022-11-28 02:48:50,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:50,658 INFO:     Epoch: 2
2022-11-28 02:48:51,393 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.426200826847276, 'Total loss': 0.426200826847276} | train loss {'Reaction outcome loss': 0.43649406734194773, 'Total loss': 0.43649406734194773}
2022-11-28 02:48:51,394 INFO:     Found new best model at epoch 2
2022-11-28 02:48:51,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:51,395 INFO:     Epoch: 3
2022-11-28 02:48:52,127 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4455131146796914, 'Total loss': 0.4455131146796914} | train loss {'Reaction outcome loss': 0.4267164062815929, 'Total loss': 0.4267164062815929}
2022-11-28 02:48:52,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:52,128 INFO:     Epoch: 4
2022-11-28 02:48:52,860 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4161300449523815, 'Total loss': 0.4161300449523815} | train loss {'Reaction outcome loss': 0.42001821416518326, 'Total loss': 0.42001821416518326}
2022-11-28 02:48:52,860 INFO:     Found new best model at epoch 4
2022-11-28 02:48:52,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:52,861 INFO:     Epoch: 5
2022-11-28 02:48:53,591 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42149394196133283, 'Total loss': 0.42149394196133283} | train loss {'Reaction outcome loss': 0.39723669783568677, 'Total loss': 0.39723669783568677}
2022-11-28 02:48:53,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:53,591 INFO:     Epoch: 6
2022-11-28 02:48:54,324 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.462132221044496, 'Total loss': 0.462132221044496} | train loss {'Reaction outcome loss': 0.38139598890219206, 'Total loss': 0.38139598890219206}
2022-11-28 02:48:54,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:54,324 INFO:     Epoch: 7
2022-11-28 02:48:55,055 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4145266070615414, 'Total loss': 0.4145266070615414} | train loss {'Reaction outcome loss': 0.3832521831057199, 'Total loss': 0.3832521831057199}
2022-11-28 02:48:55,055 INFO:     Found new best model at epoch 7
2022-11-28 02:48:55,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:55,056 INFO:     Epoch: 8
2022-11-28 02:48:55,787 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4217154303955477, 'Total loss': 0.4217154303955477} | train loss {'Reaction outcome loss': 0.3718164504310231, 'Total loss': 0.3718164504310231}
2022-11-28 02:48:55,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:55,787 INFO:     Epoch: 9
2022-11-28 02:48:56,520 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4080190467973088, 'Total loss': 0.4080190467973088} | train loss {'Reaction outcome loss': 0.3643923759031198, 'Total loss': 0.3643923759031198}
2022-11-28 02:48:56,520 INFO:     Found new best model at epoch 9
2022-11-28 02:48:56,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:56,521 INFO:     Epoch: 10
2022-11-28 02:48:57,255 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43290852703327354, 'Total loss': 0.43290852703327354} | train loss {'Reaction outcome loss': 0.3658097528626399, 'Total loss': 0.3658097528626399}
2022-11-28 02:48:57,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:57,255 INFO:     Epoch: 11
2022-11-28 02:48:57,991 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42638080168602077, 'Total loss': 0.42638080168602077} | train loss {'Reaction outcome loss': 0.36464204817029183, 'Total loss': 0.36464204817029183}
2022-11-28 02:48:57,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:57,992 INFO:     Epoch: 12
2022-11-28 02:48:58,725 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4100191111481467, 'Total loss': 0.4100191111481467} | train loss {'Reaction outcome loss': 0.3637106192486031, 'Total loss': 0.3637106192486031}
2022-11-28 02:48:58,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:58,725 INFO:     Epoch: 13
2022-11-28 02:48:59,456 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.396428310940432, 'Total loss': 0.396428310940432} | train loss {'Reaction outcome loss': 0.34946983574349205, 'Total loss': 0.34946983574349205}
2022-11-28 02:48:59,456 INFO:     Found new best model at epoch 13
2022-11-28 02:48:59,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:48:59,457 INFO:     Epoch: 14
2022-11-28 02:49:00,191 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4130244532296824, 'Total loss': 0.4130244532296824} | train loss {'Reaction outcome loss': 0.3458259543825569, 'Total loss': 0.3458259543825569}
2022-11-28 02:49:00,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:00,191 INFO:     Epoch: 15
2022-11-28 02:49:00,926 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39840125448481983, 'Total loss': 0.39840125448481983} | train loss {'Reaction outcome loss': 0.33628473550449184, 'Total loss': 0.33628473550449184}
2022-11-28 02:49:00,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:00,926 INFO:     Epoch: 16
2022-11-28 02:49:01,660 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4594882064780524, 'Total loss': 0.4594882064780524} | train loss {'Reaction outcome loss': 0.3413991423730006, 'Total loss': 0.3413991423730006}
2022-11-28 02:49:01,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:01,660 INFO:     Epoch: 17
2022-11-28 02:49:02,393 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3959765884765359, 'Total loss': 0.3959765884765359} | train loss {'Reaction outcome loss': 0.337704589061531, 'Total loss': 0.337704589061531}
2022-11-28 02:49:02,393 INFO:     Found new best model at epoch 17
2022-11-28 02:49:02,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:02,394 INFO:     Epoch: 18
2022-11-28 02:49:03,127 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42539886055990705, 'Total loss': 0.42539886055990705} | train loss {'Reaction outcome loss': 0.32805997219105315, 'Total loss': 0.32805997219105315}
2022-11-28 02:49:03,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:03,127 INFO:     Epoch: 19
2022-11-28 02:49:03,862 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40318887594134306, 'Total loss': 0.40318887594134306} | train loss {'Reaction outcome loss': 0.3322729653307072, 'Total loss': 0.3322729653307072}
2022-11-28 02:49:03,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:03,863 INFO:     Epoch: 20
2022-11-28 02:49:04,598 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4209696492829988, 'Total loss': 0.4209696492829988} | train loss {'Reaction outcome loss': 0.32940868294410747, 'Total loss': 0.32940868294410747}
2022-11-28 02:49:04,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:04,598 INFO:     Epoch: 21
2022-11-28 02:49:05,333 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45001810858416, 'Total loss': 0.45001810858416} | train loss {'Reaction outcome loss': 0.3316144991681409, 'Total loss': 0.3316144991681409}
2022-11-28 02:49:05,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:05,333 INFO:     Epoch: 22
2022-11-28 02:49:06,068 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41300811012123906, 'Total loss': 0.41300811012123906} | train loss {'Reaction outcome loss': 0.32512723093415485, 'Total loss': 0.32512723093415485}
2022-11-28 02:49:06,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:06,069 INFO:     Epoch: 23
2022-11-28 02:49:06,805 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44751651117274927, 'Total loss': 0.44751651117274927} | train loss {'Reaction outcome loss': 0.3282052485479249, 'Total loss': 0.3282052485479249}
2022-11-28 02:49:06,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:06,805 INFO:     Epoch: 24
2022-11-28 02:49:07,539 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42721203524012896, 'Total loss': 0.42721203524012896} | train loss {'Reaction outcome loss': 0.32152283200879156, 'Total loss': 0.32152283200879156}
2022-11-28 02:49:07,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:07,539 INFO:     Epoch: 25
2022-11-28 02:49:08,271 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3930057304543118, 'Total loss': 0.3930057304543118} | train loss {'Reaction outcome loss': 0.31411219158290343, 'Total loss': 0.31411219158290343}
2022-11-28 02:49:08,271 INFO:     Found new best model at epoch 25
2022-11-28 02:49:08,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:08,272 INFO:     Epoch: 26
2022-11-28 02:49:09,004 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.418032917865487, 'Total loss': 0.418032917865487} | train loss {'Reaction outcome loss': 0.3201822276713917, 'Total loss': 0.3201822276713917}
2022-11-28 02:49:09,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:09,004 INFO:     Epoch: 27
2022-11-28 02:49:09,741 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3897818881411885, 'Total loss': 0.3897818881411885} | train loss {'Reaction outcome loss': 0.31812463026233173, 'Total loss': 0.31812463026233173}
2022-11-28 02:49:09,741 INFO:     Found new best model at epoch 27
2022-11-28 02:49:09,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:09,742 INFO:     Epoch: 28
2022-11-28 02:49:10,478 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3908458359019701, 'Total loss': 0.3908458359019701} | train loss {'Reaction outcome loss': 0.3221358433059214, 'Total loss': 0.3221358433059214}
2022-11-28 02:49:10,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:10,478 INFO:     Epoch: 29
2022-11-28 02:49:11,216 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4336023036130639, 'Total loss': 0.4336023036130639} | train loss {'Reaction outcome loss': 0.3191280411901297, 'Total loss': 0.3191280411901297}
2022-11-28 02:49:11,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:11,217 INFO:     Epoch: 30
2022-11-28 02:49:11,955 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3865455052880354, 'Total loss': 0.3865455052880354} | train loss {'Reaction outcome loss': 0.3179109351931776, 'Total loss': 0.3179109351931776}
2022-11-28 02:49:11,955 INFO:     Found new best model at epoch 30
2022-11-28 02:49:11,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:11,956 INFO:     Epoch: 31
2022-11-28 02:49:12,690 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3987452855636907, 'Total loss': 0.3987452855636907} | train loss {'Reaction outcome loss': 0.32311785834316364, 'Total loss': 0.32311785834316364}
2022-11-28 02:49:12,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:12,691 INFO:     Epoch: 32
2022-11-28 02:49:13,423 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4233701814745748, 'Total loss': 0.4233701814745748} | train loss {'Reaction outcome loss': 0.3179264975550734, 'Total loss': 0.3179264975550734}
2022-11-28 02:49:13,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:13,423 INFO:     Epoch: 33
2022-11-28 02:49:14,162 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4254408530717672, 'Total loss': 0.4254408530717672} | train loss {'Reaction outcome loss': 0.31692669568238435, 'Total loss': 0.31692669568238435}
2022-11-28 02:49:14,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:14,163 INFO:     Epoch: 34
2022-11-28 02:49:14,896 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37888221581314885, 'Total loss': 0.37888221581314885} | train loss {'Reaction outcome loss': 0.320243667427895, 'Total loss': 0.320243667427895}
2022-11-28 02:49:14,896 INFO:     Found new best model at epoch 34
2022-11-28 02:49:14,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:14,897 INFO:     Epoch: 35
2022-11-28 02:49:15,629 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41675182865109556, 'Total loss': 0.41675182865109556} | train loss {'Reaction outcome loss': 0.3124244993268953, 'Total loss': 0.3124244993268953}
2022-11-28 02:49:15,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:15,630 INFO:     Epoch: 36
2022-11-28 02:49:16,361 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37471251155054847, 'Total loss': 0.37471251155054847} | train loss {'Reaction outcome loss': 0.31107745885297106, 'Total loss': 0.31107745885297106}
2022-11-28 02:49:16,362 INFO:     Found new best model at epoch 36
2022-11-28 02:49:16,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:16,363 INFO:     Epoch: 37
2022-11-28 02:49:17,097 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37896216192910837, 'Total loss': 0.37896216192910837} | train loss {'Reaction outcome loss': 0.3043372072126149, 'Total loss': 0.3043372072126149}
2022-11-28 02:49:17,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:17,097 INFO:     Epoch: 38
2022-11-28 02:49:17,831 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4172268877195757, 'Total loss': 0.4172268877195757} | train loss {'Reaction outcome loss': 0.30594012506091545, 'Total loss': 0.30594012506091545}
2022-11-28 02:49:17,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:17,831 INFO:     Epoch: 39
2022-11-28 02:49:18,561 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40181634973647984, 'Total loss': 0.40181634973647984} | train loss {'Reaction outcome loss': 0.3060146509497254, 'Total loss': 0.3060146509497254}
2022-11-28 02:49:18,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:18,561 INFO:     Epoch: 40
2022-11-28 02:49:19,293 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4211519752130952, 'Total loss': 0.4211519752130952} | train loss {'Reaction outcome loss': 0.313403204206086, 'Total loss': 0.313403204206086}
2022-11-28 02:49:19,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:19,293 INFO:     Epoch: 41
2022-11-28 02:49:20,030 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39437516380188076, 'Total loss': 0.39437516380188076} | train loss {'Reaction outcome loss': 0.3054898874872506, 'Total loss': 0.3054898874872506}
2022-11-28 02:49:20,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:20,031 INFO:     Epoch: 42
2022-11-28 02:49:20,762 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4129758361986903, 'Total loss': 0.4129758361986903} | train loss {'Reaction outcome loss': 0.3155315450005571, 'Total loss': 0.3155315450005571}
2022-11-28 02:49:20,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:20,762 INFO:     Epoch: 43
2022-11-28 02:49:21,500 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.402593235983405, 'Total loss': 0.402593235983405} | train loss {'Reaction outcome loss': 0.30745015094064393, 'Total loss': 0.30745015094064393}
2022-11-28 02:49:21,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:21,500 INFO:     Epoch: 44
2022-11-28 02:49:22,240 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41236382376315983, 'Total loss': 0.41236382376315983} | train loss {'Reaction outcome loss': 0.3059559951655168, 'Total loss': 0.3059559951655168}
2022-11-28 02:49:22,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:22,240 INFO:     Epoch: 45
2022-11-28 02:49:22,985 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.413609292618064, 'Total loss': 0.413609292618064} | train loss {'Reaction outcome loss': 0.3004689921506148, 'Total loss': 0.3004689921506148}
2022-11-28 02:49:22,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:22,985 INFO:     Epoch: 46
2022-11-28 02:49:23,732 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39074394072211066, 'Total loss': 0.39074394072211066} | train loss {'Reaction outcome loss': 0.30940806920881625, 'Total loss': 0.30940806920881625}
2022-11-28 02:49:23,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:23,732 INFO:     Epoch: 47
2022-11-28 02:49:24,476 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.427665525917397, 'Total loss': 0.427665525917397} | train loss {'Reaction outcome loss': 0.3012414504716426, 'Total loss': 0.3012414504716426}
2022-11-28 02:49:24,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:24,476 INFO:     Epoch: 48
2022-11-28 02:49:25,217 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4129273756298908, 'Total loss': 0.4129273756298908} | train loss {'Reaction outcome loss': 0.3005262004065906, 'Total loss': 0.3005262004065906}
2022-11-28 02:49:25,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:25,217 INFO:     Epoch: 49
2022-11-28 02:49:25,959 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4101237131412639, 'Total loss': 0.4101237131412639} | train loss {'Reaction outcome loss': 0.3009826952415239, 'Total loss': 0.3009826952415239}
2022-11-28 02:49:25,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:25,959 INFO:     Epoch: 50
2022-11-28 02:49:26,700 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39121451072914654, 'Total loss': 0.39121451072914654} | train loss {'Reaction outcome loss': 0.30351076299638907, 'Total loss': 0.30351076299638907}
2022-11-28 02:49:26,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:26,700 INFO:     Epoch: 51
2022-11-28 02:49:27,444 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4116557022166807, 'Total loss': 0.4116557022166807} | train loss {'Reaction outcome loss': 0.29916940154239474, 'Total loss': 0.29916940154239474}
2022-11-28 02:49:27,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:27,445 INFO:     Epoch: 52
2022-11-28 02:49:28,186 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4298042887172034, 'Total loss': 0.4298042887172034} | train loss {'Reaction outcome loss': 0.29904847018757963, 'Total loss': 0.29904847018757963}
2022-11-28 02:49:28,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:28,187 INFO:     Epoch: 53
2022-11-28 02:49:28,927 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39698674928310307, 'Total loss': 0.39698674928310307} | train loss {'Reaction outcome loss': 0.29908446388112175, 'Total loss': 0.29908446388112175}
2022-11-28 02:49:28,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:28,927 INFO:     Epoch: 54
2022-11-28 02:49:29,667 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40419129888678706, 'Total loss': 0.40419129888678706} | train loss {'Reaction outcome loss': 0.29970485128370333, 'Total loss': 0.29970485128370333}
2022-11-28 02:49:29,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:29,667 INFO:     Epoch: 55
2022-11-28 02:49:30,409 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4115582527809365, 'Total loss': 0.4115582527809365} | train loss {'Reaction outcome loss': 0.29557949893268537, 'Total loss': 0.29557949893268537}
2022-11-28 02:49:30,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:30,409 INFO:     Epoch: 56
2022-11-28 02:49:31,153 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42719569975553556, 'Total loss': 0.42719569975553556} | train loss {'Reaction outcome loss': 0.29487273659664415, 'Total loss': 0.29487273659664415}
2022-11-28 02:49:31,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:31,153 INFO:     Epoch: 57
2022-11-28 02:49:31,894 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3998945055659427, 'Total loss': 0.3998945055659427} | train loss {'Reaction outcome loss': 0.2997365842569512, 'Total loss': 0.2997365842569512}
2022-11-28 02:49:31,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:31,894 INFO:     Epoch: 58
2022-11-28 02:49:32,632 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4084752420353335, 'Total loss': 0.4084752420353335} | train loss {'Reaction outcome loss': 0.2978339189732516, 'Total loss': 0.2978339189732516}
2022-11-28 02:49:32,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:32,632 INFO:     Epoch: 59
2022-11-28 02:49:33,380 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4299042651126551, 'Total loss': 0.4299042651126551} | train loss {'Reaction outcome loss': 0.2946370860002168, 'Total loss': 0.2946370860002168}
2022-11-28 02:49:33,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:33,380 INFO:     Epoch: 60
2022-11-28 02:49:34,126 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40480817473211955, 'Total loss': 0.40480817473211955} | train loss {'Reaction outcome loss': 0.285025260468692, 'Total loss': 0.285025260468692}
2022-11-28 02:49:34,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:34,126 INFO:     Epoch: 61
2022-11-28 02:49:34,863 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4113473223392354, 'Total loss': 0.4113473223392354} | train loss {'Reaction outcome loss': 0.3007915365843125, 'Total loss': 0.3007915365843125}
2022-11-28 02:49:34,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:34,863 INFO:     Epoch: 62
2022-11-28 02:49:35,603 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4072914709185445, 'Total loss': 0.4072914709185445} | train loss {'Reaction outcome loss': 0.3102704808005772, 'Total loss': 0.3102704808005772}
2022-11-28 02:49:35,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:35,604 INFO:     Epoch: 63
2022-11-28 02:49:36,347 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4265181474214376, 'Total loss': 0.4265181474214376} | train loss {'Reaction outcome loss': 0.2902185436445499, 'Total loss': 0.2902185436445499}
2022-11-28 02:49:36,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:36,347 INFO:     Epoch: 64
2022-11-28 02:49:37,088 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37739344114481016, 'Total loss': 0.37739344114481016} | train loss {'Reaction outcome loss': 0.30302577775446965, 'Total loss': 0.30302577775446965}
2022-11-28 02:49:37,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:37,088 INFO:     Epoch: 65
2022-11-28 02:49:37,831 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41119438167228256, 'Total loss': 0.41119438167228256} | train loss {'Reaction outcome loss': 0.29847007812050635, 'Total loss': 0.29847007812050635}
2022-11-28 02:49:37,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:37,831 INFO:     Epoch: 66
2022-11-28 02:49:38,572 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42114596242128416, 'Total loss': 0.42114596242128416} | train loss {'Reaction outcome loss': 0.28933401295432337, 'Total loss': 0.28933401295432337}
2022-11-28 02:49:38,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:38,572 INFO:     Epoch: 67
2022-11-28 02:49:39,319 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3944136860758759, 'Total loss': 0.3944136860758759} | train loss {'Reaction outcome loss': 0.2991967221315751, 'Total loss': 0.2991967221315751}
2022-11-28 02:49:39,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:39,319 INFO:     Epoch: 68
2022-11-28 02:49:40,061 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4138993563693623, 'Total loss': 0.4138993563693623} | train loss {'Reaction outcome loss': 0.3008460830207224, 'Total loss': 0.3008460830207224}
2022-11-28 02:49:40,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:40,061 INFO:     Epoch: 69
2022-11-28 02:49:40,803 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42696978030509725, 'Total loss': 0.42696978030509725} | train loss {'Reaction outcome loss': 0.29933485232385587, 'Total loss': 0.29933485232385587}
2022-11-28 02:49:40,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:40,803 INFO:     Epoch: 70
2022-11-28 02:49:41,543 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40983001766509786, 'Total loss': 0.40983001766509786} | train loss {'Reaction outcome loss': 0.2897741880436493, 'Total loss': 0.2897741880436493}
2022-11-28 02:49:41,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:41,543 INFO:     Epoch: 71
2022-11-28 02:49:42,285 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4415207371808762, 'Total loss': 0.4415207371808762} | train loss {'Reaction outcome loss': 0.2859686471123264, 'Total loss': 0.2859686471123264}
2022-11-28 02:49:42,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:42,286 INFO:     Epoch: 72
2022-11-28 02:49:43,027 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42414144158016803, 'Total loss': 0.42414144158016803} | train loss {'Reaction outcome loss': 0.29188346522457803, 'Total loss': 0.29188346522457803}
2022-11-28 02:49:43,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:43,028 INFO:     Epoch: 73
2022-11-28 02:49:43,771 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3791740349558897, 'Total loss': 0.3791740349558897} | train loss {'Reaction outcome loss': 0.2952220166339673, 'Total loss': 0.2952220166339673}
2022-11-28 02:49:43,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:43,771 INFO:     Epoch: 74
2022-11-28 02:49:44,515 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.404067846578221, 'Total loss': 0.404067846578221} | train loss {'Reaction outcome loss': 0.286598173985756, 'Total loss': 0.286598173985756}
2022-11-28 02:49:44,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:44,515 INFO:     Epoch: 75
2022-11-28 02:49:45,259 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37307661113350893, 'Total loss': 0.37307661113350893} | train loss {'Reaction outcome loss': 0.28573947752454154, 'Total loss': 0.28573947752454154}
2022-11-28 02:49:45,259 INFO:     Found new best model at epoch 75
2022-11-28 02:49:45,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:45,260 INFO:     Epoch: 76
2022-11-28 02:49:46,004 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40076128202815386, 'Total loss': 0.40076128202815386} | train loss {'Reaction outcome loss': 0.2912924951210679, 'Total loss': 0.2912924951210679}
2022-11-28 02:49:46,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:46,004 INFO:     Epoch: 77
2022-11-28 02:49:46,746 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41552018911339517, 'Total loss': 0.41552018911339517} | train loss {'Reaction outcome loss': 0.28690922913360006, 'Total loss': 0.28690922913360006}
2022-11-28 02:49:46,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:46,746 INFO:     Epoch: 78
2022-11-28 02:49:47,488 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41260447665009387, 'Total loss': 0.41260447665009387} | train loss {'Reaction outcome loss': 0.28997031416851304, 'Total loss': 0.28997031416851304}
2022-11-28 02:49:47,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:47,490 INFO:     Epoch: 79
2022-11-28 02:49:48,231 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40102632932884746, 'Total loss': 0.40102632932884746} | train loss {'Reaction outcome loss': 0.2985371353235019, 'Total loss': 0.2985371353235019}
2022-11-28 02:49:48,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:48,231 INFO:     Epoch: 80
2022-11-28 02:49:48,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4117934892690459, 'Total loss': 0.4117934892690459} | train loss {'Reaction outcome loss': 0.2968396470410588, 'Total loss': 0.2968396470410588}
2022-11-28 02:49:48,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:48,973 INFO:     Epoch: 81
2022-11-28 02:49:49,718 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40011360548263375, 'Total loss': 0.40011360548263375} | train loss {'Reaction outcome loss': 0.292076496828976, 'Total loss': 0.292076496828976}
2022-11-28 02:49:49,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:49,719 INFO:     Epoch: 82
2022-11-28 02:49:50,461 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3841360516326372, 'Total loss': 0.3841360516326372} | train loss {'Reaction outcome loss': 0.2990861021196891, 'Total loss': 0.2990861021196891}
2022-11-28 02:49:50,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:50,461 INFO:     Epoch: 83
2022-11-28 02:49:51,204 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4108085358558699, 'Total loss': 0.4108085358558699} | train loss {'Reaction outcome loss': 0.29162310830359595, 'Total loss': 0.29162310830359595}
2022-11-28 02:49:51,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:51,205 INFO:     Epoch: 84
2022-11-28 02:49:51,947 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4278962840867597, 'Total loss': 0.4278962840867597} | train loss {'Reaction outcome loss': 0.2978967160844999, 'Total loss': 0.2978967160844999}
2022-11-28 02:49:51,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:51,947 INFO:     Epoch: 85
2022-11-28 02:49:52,688 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4172574999027474, 'Total loss': 0.4172574999027474} | train loss {'Reaction outcome loss': 0.30539811713766657, 'Total loss': 0.30539811713766657}
2022-11-28 02:49:52,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:52,688 INFO:     Epoch: 86
2022-11-28 02:49:53,432 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4131017264931701, 'Total loss': 0.4131017264931701} | train loss {'Reaction outcome loss': 0.2928558155403706, 'Total loss': 0.2928558155403706}
2022-11-28 02:49:53,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:53,432 INFO:     Epoch: 87
2022-11-28 02:49:54,177 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39296927181787267, 'Total loss': 0.39296927181787267} | train loss {'Reaction outcome loss': 0.29157343474619185, 'Total loss': 0.29157343474619185}
2022-11-28 02:49:54,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:54,178 INFO:     Epoch: 88
2022-11-28 02:49:54,923 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4164659876463025, 'Total loss': 0.4164659876463025} | train loss {'Reaction outcome loss': 0.29685210736292134, 'Total loss': 0.29685210736292134}
2022-11-28 02:49:54,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:54,923 INFO:     Epoch: 89
2022-11-28 02:49:55,665 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4032122011101523, 'Total loss': 0.4032122011101523} | train loss {'Reaction outcome loss': 0.2934616157486115, 'Total loss': 0.2934616157486115}
2022-11-28 02:49:55,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:55,665 INFO:     Epoch: 90
2022-11-28 02:49:56,407 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4103503885657288, 'Total loss': 0.4103503885657288} | train loss {'Reaction outcome loss': 0.2882038992772132, 'Total loss': 0.2882038992772132}
2022-11-28 02:49:56,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:56,407 INFO:     Epoch: 91
2022-11-28 02:49:57,154 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44630674099506334, 'Total loss': 0.44630674099506334} | train loss {'Reaction outcome loss': 0.29629837986802365, 'Total loss': 0.29629837986802365}
2022-11-28 02:49:57,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:57,154 INFO:     Epoch: 92
2022-11-28 02:49:57,898 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42613432989564054, 'Total loss': 0.42613432989564054} | train loss {'Reaction outcome loss': 0.29179697588024806, 'Total loss': 0.29179697588024806}
2022-11-28 02:49:57,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:57,898 INFO:     Epoch: 93
2022-11-28 02:49:58,642 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3966718357662822, 'Total loss': 0.3966718357662822} | train loss {'Reaction outcome loss': 0.28909651801725966, 'Total loss': 0.28909651801725966}
2022-11-28 02:49:58,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:58,643 INFO:     Epoch: 94
2022-11-28 02:49:59,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3917548464134682, 'Total loss': 0.3917548464134682} | train loss {'Reaction outcome loss': 0.28680303389275513, 'Total loss': 0.28680303389275513}
2022-11-28 02:49:59,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:49:59,387 INFO:     Epoch: 95
2022-11-28 02:50:00,134 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41826634143674096, 'Total loss': 0.41826634143674096} | train loss {'Reaction outcome loss': 0.2876032071625009, 'Total loss': 0.2876032071625009}
2022-11-28 02:50:00,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:00,134 INFO:     Epoch: 96
2022-11-28 02:50:00,879 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39051528292339904, 'Total loss': 0.39051528292339904} | train loss {'Reaction outcome loss': 0.2964048385773421, 'Total loss': 0.2964048385773421}
2022-11-28 02:50:00,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:00,879 INFO:     Epoch: 97
2022-11-28 02:50:01,630 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41453018264715064, 'Total loss': 0.41453018264715064} | train loss {'Reaction outcome loss': 0.29220388064720504, 'Total loss': 0.29220388064720504}
2022-11-28 02:50:01,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:01,630 INFO:     Epoch: 98
2022-11-28 02:50:02,375 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4155433923006058, 'Total loss': 0.4155433923006058} | train loss {'Reaction outcome loss': 0.29359773696695335, 'Total loss': 0.29359773696695335}
2022-11-28 02:50:02,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:02,375 INFO:     Epoch: 99
2022-11-28 02:50:03,120 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4035055717063505, 'Total loss': 0.4035055717063505} | train loss {'Reaction outcome loss': 0.29320666985011395, 'Total loss': 0.29320666985011395}
2022-11-28 02:50:03,120 INFO:     Best model found after epoch 76 of 100.
2022-11-28 02:50:03,120 INFO:   Done with stage: TRAINING
2022-11-28 02:50:03,120 INFO:   Starting stage: EVALUATION
2022-11-28 02:50:03,258 INFO:   Done with stage: EVALUATION
2022-11-28 02:50:03,259 INFO:   Leaving out SEQ value Fold_4
2022-11-28 02:50:03,272 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:50:03,272 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:50:03,919 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:50:03,919 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:50:03,988 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:50:03,988 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:50:03,988 INFO:     No hyperparam tuning for this model
2022-11-28 02:50:03,988 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:50:03,988 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:50:03,989 INFO:     None feature selector for col prot
2022-11-28 02:50:03,989 INFO:     None feature selector for col prot
2022-11-28 02:50:03,989 INFO:     None feature selector for col prot
2022-11-28 02:50:03,990 INFO:     None feature selector for col chem
2022-11-28 02:50:03,990 INFO:     None feature selector for col chem
2022-11-28 02:50:03,990 INFO:     None feature selector for col chem
2022-11-28 02:50:03,990 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:50:03,990 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:50:03,991 INFO:     Number of params in model 169741
2022-11-28 02:50:03,994 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:50:03,994 INFO:   Starting stage: TRAINING
2022-11-28 02:50:04,048 INFO:     Val loss before train {'Reaction outcome loss': 1.005058392882347, 'Total loss': 1.005058392882347}
2022-11-28 02:50:04,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:04,048 INFO:     Epoch: 0
2022-11-28 02:50:04,801 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5306547805666924, 'Total loss': 0.5306547805666924} | train loss {'Reaction outcome loss': 0.6411013111984922, 'Total loss': 0.6411013111984922}
2022-11-28 02:50:04,801 INFO:     Found new best model at epoch 0
2022-11-28 02:50:04,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:04,802 INFO:     Epoch: 1
2022-11-28 02:50:05,554 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4724760204553604, 'Total loss': 0.4724760204553604} | train loss {'Reaction outcome loss': 0.5085953854416546, 'Total loss': 0.5085953854416546}
2022-11-28 02:50:05,554 INFO:     Found new best model at epoch 1
2022-11-28 02:50:05,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:05,555 INFO:     Epoch: 2
2022-11-28 02:50:06,313 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47122217816385353, 'Total loss': 0.47122217816385353} | train loss {'Reaction outcome loss': 0.4725927220665009, 'Total loss': 0.4725927220665009}
2022-11-28 02:50:06,314 INFO:     Found new best model at epoch 2
2022-11-28 02:50:06,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:06,315 INFO:     Epoch: 3
2022-11-28 02:50:07,070 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45369217883456836, 'Total loss': 0.45369217883456836} | train loss {'Reaction outcome loss': 0.45141817207037194, 'Total loss': 0.45141817207037194}
2022-11-28 02:50:07,070 INFO:     Found new best model at epoch 3
2022-11-28 02:50:07,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:07,071 INFO:     Epoch: 4
2022-11-28 02:50:07,829 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4362631348723715, 'Total loss': 0.4362631348723715} | train loss {'Reaction outcome loss': 0.4350728462582175, 'Total loss': 0.4350728462582175}
2022-11-28 02:50:07,829 INFO:     Found new best model at epoch 4
2022-11-28 02:50:07,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:07,830 INFO:     Epoch: 5
2022-11-28 02:50:08,586 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41693048111417075, 'Total loss': 0.41693048111417075} | train loss {'Reaction outcome loss': 0.426761908026842, 'Total loss': 0.426761908026842}
2022-11-28 02:50:08,586 INFO:     Found new best model at epoch 5
2022-11-28 02:50:08,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:08,587 INFO:     Epoch: 6
2022-11-28 02:50:09,345 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4220374802296812, 'Total loss': 0.4220374802296812} | train loss {'Reaction outcome loss': 0.42041464867862127, 'Total loss': 0.42041464867862127}
2022-11-28 02:50:09,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:09,345 INFO:     Epoch: 7
2022-11-28 02:50:10,103 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4526347555220127, 'Total loss': 0.4526347555220127} | train loss {'Reaction outcome loss': 0.40772908781221523, 'Total loss': 0.40772908781221523}
2022-11-28 02:50:10,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:10,103 INFO:     Epoch: 8
2022-11-28 02:50:10,860 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4767066484147852, 'Total loss': 0.4767066484147852} | train loss {'Reaction outcome loss': 0.41909148010165104, 'Total loss': 0.41909148010165104}
2022-11-28 02:50:10,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:10,860 INFO:     Epoch: 9
2022-11-28 02:50:11,615 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43791626156731084, 'Total loss': 0.43791626156731084} | train loss {'Reaction outcome loss': 0.3992364468120853, 'Total loss': 0.3992364468120853}
2022-11-28 02:50:11,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:11,616 INFO:     Epoch: 10
2022-11-28 02:50:12,370 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4107342023741115, 'Total loss': 0.4107342023741115} | train loss {'Reaction outcome loss': 0.3966638634682667, 'Total loss': 0.3966638634682667}
2022-11-28 02:50:12,371 INFO:     Found new best model at epoch 10
2022-11-28 02:50:12,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:12,372 INFO:     Epoch: 11
2022-11-28 02:50:13,127 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4248767847364599, 'Total loss': 0.4248767847364599} | train loss {'Reaction outcome loss': 0.380630438021848, 'Total loss': 0.380630438021848}
2022-11-28 02:50:13,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:13,127 INFO:     Epoch: 12
2022-11-28 02:50:13,885 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3871018541130153, 'Total loss': 0.3871018541130153} | train loss {'Reaction outcome loss': 0.37808162818553476, 'Total loss': 0.37808162818553476}
2022-11-28 02:50:13,885 INFO:     Found new best model at epoch 12
2022-11-28 02:50:13,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:13,886 INFO:     Epoch: 13
2022-11-28 02:50:14,645 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4297248517925089, 'Total loss': 0.4297248517925089} | train loss {'Reaction outcome loss': 0.3796433263160439, 'Total loss': 0.3796433263160439}
2022-11-28 02:50:14,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:14,645 INFO:     Epoch: 14
2022-11-28 02:50:15,399 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3902048519389196, 'Total loss': 0.3902048519389196} | train loss {'Reaction outcome loss': 0.37851814777865583, 'Total loss': 0.37851814777865583}
2022-11-28 02:50:15,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:15,400 INFO:     Epoch: 15
2022-11-28 02:50:16,152 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42708219384605234, 'Total loss': 0.42708219384605234} | train loss {'Reaction outcome loss': 0.37328966764303356, 'Total loss': 0.37328966764303356}
2022-11-28 02:50:16,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:16,153 INFO:     Epoch: 16
2022-11-28 02:50:16,907 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41456164521249855, 'Total loss': 0.41456164521249855} | train loss {'Reaction outcome loss': 0.3733539640722487, 'Total loss': 0.3733539640722487}
2022-11-28 02:50:16,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:16,908 INFO:     Epoch: 17
2022-11-28 02:50:17,659 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3984446738931266, 'Total loss': 0.3984446738931266} | train loss {'Reaction outcome loss': 0.37500972907070207, 'Total loss': 0.37500972907070207}
2022-11-28 02:50:17,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:17,660 INFO:     Epoch: 18
2022-11-28 02:50:18,416 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41082998703826556, 'Total loss': 0.41082998703826556} | train loss {'Reaction outcome loss': 0.3708321890126356, 'Total loss': 0.3708321890126356}
2022-11-28 02:50:18,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:18,417 INFO:     Epoch: 19
2022-11-28 02:50:19,176 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.430178048258478, 'Total loss': 0.430178048258478} | train loss {'Reaction outcome loss': 0.36128716246198544, 'Total loss': 0.36128716246198544}
2022-11-28 02:50:19,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:19,176 INFO:     Epoch: 20
2022-11-28 02:50:19,932 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44410653463141486, 'Total loss': 0.44410653463141486} | train loss {'Reaction outcome loss': 0.35517486978156365, 'Total loss': 0.35517486978156365}
2022-11-28 02:50:19,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:19,932 INFO:     Epoch: 21
2022-11-28 02:50:20,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41368607126853685, 'Total loss': 0.41368607126853685} | train loss {'Reaction outcome loss': 0.3602281285201007, 'Total loss': 0.3602281285201007}
2022-11-28 02:50:20,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:20,685 INFO:     Epoch: 22
2022-11-28 02:50:21,440 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38449662551283836, 'Total loss': 0.38449662551283836} | train loss {'Reaction outcome loss': 0.38499345786507555, 'Total loss': 0.38499345786507555}
2022-11-28 02:50:21,440 INFO:     Found new best model at epoch 22
2022-11-28 02:50:21,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:21,441 INFO:     Epoch: 23
2022-11-28 02:50:22,195 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4096908455883915, 'Total loss': 0.4096908455883915} | train loss {'Reaction outcome loss': 0.34765378615596454, 'Total loss': 0.34765378615596454}
2022-11-28 02:50:22,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:22,195 INFO:     Epoch: 24
2022-11-28 02:50:22,950 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3929522262716835, 'Total loss': 0.3929522262716835} | train loss {'Reaction outcome loss': 0.3599177034579308, 'Total loss': 0.3599177034579308}
2022-11-28 02:50:22,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:22,951 INFO:     Epoch: 25
2022-11-28 02:50:23,705 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44151241569356486, 'Total loss': 0.44151241569356486} | train loss {'Reaction outcome loss': 0.36056634750564087, 'Total loss': 0.36056634750564087}
2022-11-28 02:50:23,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:23,705 INFO:     Epoch: 26
2022-11-28 02:50:24,459 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.407001949169419, 'Total loss': 0.407001949169419} | train loss {'Reaction outcome loss': 0.3588648887298368, 'Total loss': 0.3588648887298368}
2022-11-28 02:50:24,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:24,460 INFO:     Epoch: 27
2022-11-28 02:50:25,210 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3750619961118156, 'Total loss': 0.3750619961118156} | train loss {'Reaction outcome loss': 0.3474310957770116, 'Total loss': 0.3474310957770116}
2022-11-28 02:50:25,210 INFO:     Found new best model at epoch 27
2022-11-28 02:50:25,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:25,211 INFO:     Epoch: 28
2022-11-28 02:50:25,966 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4617565633221106, 'Total loss': 0.4617565633221106} | train loss {'Reaction outcome loss': 0.34618853059736826, 'Total loss': 0.34618853059736826}
2022-11-28 02:50:25,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:25,966 INFO:     Epoch: 29
2022-11-28 02:50:26,722 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39473062415014615, 'Total loss': 0.39473062415014615} | train loss {'Reaction outcome loss': 0.3659910454682493, 'Total loss': 0.3659910454682493}
2022-11-28 02:50:26,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:26,722 INFO:     Epoch: 30
2022-11-28 02:50:27,481 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4248412825505842, 'Total loss': 0.4248412825505842} | train loss {'Reaction outcome loss': 0.35048670872012794, 'Total loss': 0.35048670872012794}
2022-11-28 02:50:27,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:27,481 INFO:     Epoch: 31
2022-11-28 02:50:28,237 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3977494310926307, 'Total loss': 0.3977494310926307} | train loss {'Reaction outcome loss': 0.34034991388016866, 'Total loss': 0.34034991388016866}
2022-11-28 02:50:28,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:28,238 INFO:     Epoch: 32
2022-11-28 02:50:28,989 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3988823894072663, 'Total loss': 0.3988823894072663} | train loss {'Reaction outcome loss': 0.342938892452823, 'Total loss': 0.342938892452823}
2022-11-28 02:50:28,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:28,989 INFO:     Epoch: 33
2022-11-28 02:50:29,748 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4027523516931317, 'Total loss': 0.4027523516931317} | train loss {'Reaction outcome loss': 0.3484782348820555, 'Total loss': 0.3484782348820555}
2022-11-28 02:50:29,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:29,749 INFO:     Epoch: 34
2022-11-28 02:50:30,508 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3876696835187348, 'Total loss': 0.3876696835187348} | train loss {'Reaction outcome loss': 0.3512120323202871, 'Total loss': 0.3512120323202871}
2022-11-28 02:50:30,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:30,508 INFO:     Epoch: 35
2022-11-28 02:50:31,264 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3916771510107951, 'Total loss': 0.3916771510107951} | train loss {'Reaction outcome loss': 0.34217405993668626, 'Total loss': 0.34217405993668626}
2022-11-28 02:50:31,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:31,265 INFO:     Epoch: 36
2022-11-28 02:50:32,019 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3828130669214509, 'Total loss': 0.3828130669214509} | train loss {'Reaction outcome loss': 0.33413831630216434, 'Total loss': 0.33413831630216434}
2022-11-28 02:50:32,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:32,020 INFO:     Epoch: 37
2022-11-28 02:50:32,772 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38755977069112385, 'Total loss': 0.38755977069112385} | train loss {'Reaction outcome loss': 0.35691379932950623, 'Total loss': 0.35691379932950623}
2022-11-28 02:50:32,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:32,772 INFO:     Epoch: 38
2022-11-28 02:50:33,529 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3907486095347188, 'Total loss': 0.3907486095347188} | train loss {'Reaction outcome loss': 0.33979197763479674, 'Total loss': 0.33979197763479674}
2022-11-28 02:50:33,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:33,529 INFO:     Epoch: 39
2022-11-28 02:50:34,284 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3978767063130032, 'Total loss': 0.3978767063130032} | train loss {'Reaction outcome loss': 0.35069238439745265, 'Total loss': 0.35069238439745265}
2022-11-28 02:50:34,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:34,284 INFO:     Epoch: 40
2022-11-28 02:50:35,036 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36612230505455623, 'Total loss': 0.36612230505455623} | train loss {'Reaction outcome loss': 0.3384998103204044, 'Total loss': 0.3384998103204044}
2022-11-28 02:50:35,036 INFO:     Found new best model at epoch 40
2022-11-28 02:50:35,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:35,037 INFO:     Epoch: 41
2022-11-28 02:50:35,789 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40775701335885306, 'Total loss': 0.40775701335885306} | train loss {'Reaction outcome loss': 0.34175943939188713, 'Total loss': 0.34175943939188713}
2022-11-28 02:50:35,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:35,789 INFO:     Epoch: 42
2022-11-28 02:50:36,542 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4067543978718194, 'Total loss': 0.4067543978718194} | train loss {'Reaction outcome loss': 0.35134527503478863, 'Total loss': 0.35134527503478863}
2022-11-28 02:50:36,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:36,543 INFO:     Epoch: 43
2022-11-28 02:50:37,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4418093308129094, 'Total loss': 0.4418093308129094} | train loss {'Reaction outcome loss': 0.33925459228516347, 'Total loss': 0.33925459228516347}
2022-11-28 02:50:37,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:37,297 INFO:     Epoch: 44
2022-11-28 02:50:38,053 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43019985644654796, 'Total loss': 0.43019985644654796} | train loss {'Reaction outcome loss': 0.3554663335384145, 'Total loss': 0.3554663335384145}
2022-11-28 02:50:38,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:38,053 INFO:     Epoch: 45
2022-11-28 02:50:38,805 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.410605516623367, 'Total loss': 0.410605516623367} | train loss {'Reaction outcome loss': 0.38709216405022967, 'Total loss': 0.38709216405022967}
2022-11-28 02:50:38,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:38,805 INFO:     Epoch: 46
2022-11-28 02:50:39,558 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4011928486553105, 'Total loss': 0.4011928486553105} | train loss {'Reaction outcome loss': 0.35867747324914767, 'Total loss': 0.35867747324914767}
2022-11-28 02:50:39,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:39,558 INFO:     Epoch: 47
2022-11-28 02:50:40,315 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40292277661236847, 'Total loss': 0.40292277661236847} | train loss {'Reaction outcome loss': 0.3294173949492364, 'Total loss': 0.3294173949492364}
2022-11-28 02:50:40,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:40,315 INFO:     Epoch: 48
2022-11-28 02:50:41,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38314051350409334, 'Total loss': 0.38314051350409334} | train loss {'Reaction outcome loss': 0.36219127608938256, 'Total loss': 0.36219127608938256}
2022-11-28 02:50:41,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:41,072 INFO:     Epoch: 49
2022-11-28 02:50:41,828 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39224074907939543, 'Total loss': 0.39224074907939543} | train loss {'Reaction outcome loss': 0.34892738830705405, 'Total loss': 0.34892738830705405}
2022-11-28 02:50:41,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:41,828 INFO:     Epoch: 50
2022-11-28 02:50:42,586 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4213139929554679, 'Total loss': 0.4213139929554679} | train loss {'Reaction outcome loss': 0.33041855943227105, 'Total loss': 0.33041855943227105}
2022-11-28 02:50:42,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:42,586 INFO:     Epoch: 51
2022-11-28 02:50:43,344 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4181087772277268, 'Total loss': 0.4181087772277268} | train loss {'Reaction outcome loss': 0.3586094520556239, 'Total loss': 0.3586094520556239}
2022-11-28 02:50:43,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:43,344 INFO:     Epoch: 52
2022-11-28 02:50:44,098 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4096657845445655, 'Total loss': 0.4096657845445655} | train loss {'Reaction outcome loss': 0.34631999027029226, 'Total loss': 0.34631999027029226}
2022-11-28 02:50:44,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:44,099 INFO:     Epoch: 53
2022-11-28 02:50:44,853 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4071488908746026, 'Total loss': 0.4071488908746026} | train loss {'Reaction outcome loss': 0.3395122386937441, 'Total loss': 0.3395122386937441}
2022-11-28 02:50:44,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:44,853 INFO:     Epoch: 54
2022-11-28 02:50:45,611 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3740797181698409, 'Total loss': 0.3740797181698409} | train loss {'Reaction outcome loss': 0.34245648343674084, 'Total loss': 0.34245648343674084}
2022-11-28 02:50:45,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:45,612 INFO:     Epoch: 55
2022-11-28 02:50:46,373 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4074813091958111, 'Total loss': 0.4074813091958111} | train loss {'Reaction outcome loss': 0.3365835309978801, 'Total loss': 0.3365835309978801}
2022-11-28 02:50:46,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:46,374 INFO:     Epoch: 56
2022-11-28 02:50:47,129 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4181913167915561, 'Total loss': 0.4181913167915561} | train loss {'Reaction outcome loss': 0.3249084887694311, 'Total loss': 0.3249084887694311}
2022-11-28 02:50:47,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:47,129 INFO:     Epoch: 57
2022-11-28 02:50:47,884 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4226170199161226, 'Total loss': 0.4226170199161226} | train loss {'Reaction outcome loss': 0.3325991164817501, 'Total loss': 0.3325991164817501}
2022-11-28 02:50:47,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:47,884 INFO:     Epoch: 58
2022-11-28 02:50:48,646 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41806528852744534, 'Total loss': 0.41806528852744534} | train loss {'Reaction outcome loss': 0.3497459052907311, 'Total loss': 0.3497459052907311}
2022-11-28 02:50:48,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:48,646 INFO:     Epoch: 59
2022-11-28 02:50:49,405 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4237437956035137, 'Total loss': 0.4237437956035137} | train loss {'Reaction outcome loss': 0.3425605266622686, 'Total loss': 0.3425605266622686}
2022-11-28 02:50:49,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:49,406 INFO:     Epoch: 60
2022-11-28 02:50:50,163 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39229118722406303, 'Total loss': 0.39229118722406303} | train loss {'Reaction outcome loss': 0.33040485793521046, 'Total loss': 0.33040485793521046}
2022-11-28 02:50:50,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:50,163 INFO:     Epoch: 61
2022-11-28 02:50:50,923 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40665607391433284, 'Total loss': 0.40665607391433284} | train loss {'Reaction outcome loss': 0.3305941384586389, 'Total loss': 0.3305941384586389}
2022-11-28 02:50:50,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:50,923 INFO:     Epoch: 62
2022-11-28 02:50:51,679 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3979008157144893, 'Total loss': 0.3979008157144893} | train loss {'Reaction outcome loss': 0.33295210613774867, 'Total loss': 0.33295210613774867}
2022-11-28 02:50:51,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:51,680 INFO:     Epoch: 63
2022-11-28 02:50:52,436 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39092438464814966, 'Total loss': 0.39092438464814966} | train loss {'Reaction outcome loss': 0.33362945853939907, 'Total loss': 0.33362945853939907}
2022-11-28 02:50:52,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:52,436 INFO:     Epoch: 64
2022-11-28 02:50:53,191 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40357363782823086, 'Total loss': 0.40357363782823086} | train loss {'Reaction outcome loss': 0.33163552283335795, 'Total loss': 0.33163552283335795}
2022-11-28 02:50:53,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:53,191 INFO:     Epoch: 65
2022-11-28 02:50:53,944 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38807885196398606, 'Total loss': 0.38807885196398606} | train loss {'Reaction outcome loss': 0.33237878019216394, 'Total loss': 0.33237878019216394}
2022-11-28 02:50:53,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:53,944 INFO:     Epoch: 66
2022-11-28 02:50:54,700 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4272763197394935, 'Total loss': 0.4272763197394935} | train loss {'Reaction outcome loss': 0.327698229084372, 'Total loss': 0.327698229084372}
2022-11-28 02:50:54,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:54,700 INFO:     Epoch: 67
2022-11-28 02:50:55,454 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3802887758409435, 'Total loss': 0.3802887758409435} | train loss {'Reaction outcome loss': 0.3284547373290487, 'Total loss': 0.3284547373290487}
2022-11-28 02:50:55,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:55,455 INFO:     Epoch: 68
2022-11-28 02:50:56,208 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42706721140579745, 'Total loss': 0.42706721140579745} | train loss {'Reaction outcome loss': 0.3305029015731715, 'Total loss': 0.3305029015731715}
2022-11-28 02:50:56,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:56,208 INFO:     Epoch: 69
2022-11-28 02:50:56,963 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40468399125066673, 'Total loss': 0.40468399125066673} | train loss {'Reaction outcome loss': 0.3436578495299768, 'Total loss': 0.3436578495299768}
2022-11-28 02:50:56,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:56,963 INFO:     Epoch: 70
2022-11-28 02:50:57,718 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3876580604436723, 'Total loss': 0.3876580604436723} | train loss {'Reaction outcome loss': 0.3681412117201307, 'Total loss': 0.3681412117201307}
2022-11-28 02:50:57,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:57,718 INFO:     Epoch: 71
2022-11-28 02:50:58,473 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3958078839562156, 'Total loss': 0.3958078839562156} | train loss {'Reaction outcome loss': 0.32213555020421575, 'Total loss': 0.32213555020421575}
2022-11-28 02:50:58,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:58,473 INFO:     Epoch: 72
2022-11-28 02:50:59,235 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4150507196106694, 'Total loss': 0.4150507196106694} | train loss {'Reaction outcome loss': 0.32032331978871115, 'Total loss': 0.32032331978871115}
2022-11-28 02:50:59,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:59,235 INFO:     Epoch: 73
2022-11-28 02:50:59,987 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39774304696104745, 'Total loss': 0.39774304696104745} | train loss {'Reaction outcome loss': 0.3230829940098319, 'Total loss': 0.3230829940098319}
2022-11-28 02:50:59,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:50:59,987 INFO:     Epoch: 74
2022-11-28 02:51:00,741 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4098507518118078, 'Total loss': 0.4098507518118078} | train loss {'Reaction outcome loss': 0.3194184209482164, 'Total loss': 0.3194184209482164}
2022-11-28 02:51:00,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:00,742 INFO:     Epoch: 75
2022-11-28 02:51:01,499 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42601174827326427, 'Total loss': 0.42601174827326427} | train loss {'Reaction outcome loss': 0.3211488321664845, 'Total loss': 0.3211488321664845}
2022-11-28 02:51:01,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:01,500 INFO:     Epoch: 76
2022-11-28 02:51:02,253 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39411829750646243, 'Total loss': 0.39411829750646243} | train loss {'Reaction outcome loss': 0.3374264350967851, 'Total loss': 0.3374264350967851}
2022-11-28 02:51:02,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:02,253 INFO:     Epoch: 77
2022-11-28 02:51:03,010 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39309443228624086, 'Total loss': 0.39309443228624086} | train loss {'Reaction outcome loss': 0.32755649469883336, 'Total loss': 0.32755649469883336}
2022-11-28 02:51:03,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:03,010 INFO:     Epoch: 78
2022-11-28 02:51:03,762 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39414939656853676, 'Total loss': 0.39414939656853676} | train loss {'Reaction outcome loss': 0.3287305238426697, 'Total loss': 0.3287305238426697}
2022-11-28 02:51:03,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:03,762 INFO:     Epoch: 79
2022-11-28 02:51:04,518 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3927347771823406, 'Total loss': 0.3927347771823406} | train loss {'Reaction outcome loss': 0.3464554215249745, 'Total loss': 0.3464554215249745}
2022-11-28 02:51:04,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:04,519 INFO:     Epoch: 80
2022-11-28 02:51:05,276 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38861565359614114, 'Total loss': 0.38861565359614114} | train loss {'Reaction outcome loss': 0.3398094000860385, 'Total loss': 0.3398094000860385}
2022-11-28 02:51:05,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:05,276 INFO:     Epoch: 81
2022-11-28 02:51:06,029 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4030006822537292, 'Total loss': 0.4030006822537292} | train loss {'Reaction outcome loss': 0.32706223610743335, 'Total loss': 0.32706223610743335}
2022-11-28 02:51:06,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:06,030 INFO:     Epoch: 82
2022-11-28 02:51:06,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3818920495157892, 'Total loss': 0.3818920495157892} | train loss {'Reaction outcome loss': 0.31891068045487286, 'Total loss': 0.31891068045487286}
2022-11-28 02:51:06,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:06,785 INFO:     Epoch: 83
2022-11-28 02:51:07,544 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38491384414109314, 'Total loss': 0.38491384414109314} | train loss {'Reaction outcome loss': 0.31869776108064635, 'Total loss': 0.31869776108064635}
2022-11-28 02:51:07,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:07,545 INFO:     Epoch: 84
2022-11-28 02:51:08,307 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4046151524578983, 'Total loss': 0.4046151524578983} | train loss {'Reaction outcome loss': 0.3297228079877402, 'Total loss': 0.3297228079877402}
2022-11-28 02:51:08,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:08,307 INFO:     Epoch: 85
2022-11-28 02:51:09,059 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4022519202394919, 'Total loss': 0.4022519202394919} | train loss {'Reaction outcome loss': 0.32164920663021823, 'Total loss': 0.32164920663021823}
2022-11-28 02:51:09,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:09,059 INFO:     Epoch: 86
2022-11-28 02:51:09,811 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4017747813327746, 'Total loss': 0.4017747813327746} | train loss {'Reaction outcome loss': 0.31612852725920526, 'Total loss': 0.31612852725920526}
2022-11-28 02:51:09,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:09,811 INFO:     Epoch: 87
2022-11-28 02:51:10,564 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3991909860209985, 'Total loss': 0.3991909860209985} | train loss {'Reaction outcome loss': 0.3202470852899165, 'Total loss': 0.3202470852899165}
2022-11-28 02:51:10,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:10,564 INFO:     Epoch: 88
2022-11-28 02:51:11,317 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4032291343266314, 'Total loss': 0.4032291343266314} | train loss {'Reaction outcome loss': 0.3284608712683805, 'Total loss': 0.3284608712683805}
2022-11-28 02:51:11,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:11,317 INFO:     Epoch: 89
2022-11-28 02:51:12,069 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3980594991960309, 'Total loss': 0.3980594991960309} | train loss {'Reaction outcome loss': 0.343389876217012, 'Total loss': 0.343389876217012}
2022-11-28 02:51:12,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:12,070 INFO:     Epoch: 90
2022-11-28 02:51:12,824 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38484398428012023, 'Total loss': 0.38484398428012023} | train loss {'Reaction outcome loss': 0.3198574294490732, 'Total loss': 0.3198574294490732}
2022-11-28 02:51:12,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:12,825 INFO:     Epoch: 91
2022-11-28 02:51:13,580 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39625308831984346, 'Total loss': 0.39625308831984346} | train loss {'Reaction outcome loss': 0.31992193680965464, 'Total loss': 0.31992193680965464}
2022-11-28 02:51:13,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:13,580 INFO:     Epoch: 92
2022-11-28 02:51:14,334 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4081464790823785, 'Total loss': 0.4081464790823785} | train loss {'Reaction outcome loss': 0.32330626192519646, 'Total loss': 0.32330626192519646}
2022-11-28 02:51:14,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:14,334 INFO:     Epoch: 93
2022-11-28 02:51:15,088 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38639686188914557, 'Total loss': 0.38639686188914557} | train loss {'Reaction outcome loss': 0.3199379192627514, 'Total loss': 0.3199379192627514}
2022-11-28 02:51:15,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:15,088 INFO:     Epoch: 94
2022-11-28 02:51:15,839 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3907599610022523, 'Total loss': 0.3907599610022523} | train loss {'Reaction outcome loss': 0.3189788479885833, 'Total loss': 0.3189788479885833}
2022-11-28 02:51:15,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:15,839 INFO:     Epoch: 95
2022-11-28 02:51:16,593 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4231524081392722, 'Total loss': 0.4231524081392722} | train loss {'Reaction outcome loss': 0.31552881204526917, 'Total loss': 0.31552881204526917}
2022-11-28 02:51:16,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:16,593 INFO:     Epoch: 96
2022-11-28 02:51:17,349 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39616923101923684, 'Total loss': 0.39616923101923684} | train loss {'Reaction outcome loss': 0.32489166115052426, 'Total loss': 0.32489166115052426}
2022-11-28 02:51:17,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:17,349 INFO:     Epoch: 97
2022-11-28 02:51:18,101 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39167995886369184, 'Total loss': 0.39167995886369184} | train loss {'Reaction outcome loss': 0.3241489134759073, 'Total loss': 0.3241489134759073}
2022-11-28 02:51:18,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:18,101 INFO:     Epoch: 98
2022-11-28 02:51:18,853 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4006760943342339, 'Total loss': 0.4006760943342339} | train loss {'Reaction outcome loss': 0.32894398012624576, 'Total loss': 0.32894398012624576}
2022-11-28 02:51:18,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:18,854 INFO:     Epoch: 99
2022-11-28 02:51:19,610 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38078257712450897, 'Total loss': 0.38078257712450897} | train loss {'Reaction outcome loss': 0.31615884083244, 'Total loss': 0.31615884083244}
2022-11-28 02:51:19,610 INFO:     Best model found after epoch 41 of 100.
2022-11-28 02:51:19,610 INFO:   Done with stage: TRAINING
2022-11-28 02:51:19,610 INFO:   Starting stage: EVALUATION
2022-11-28 02:51:19,731 INFO:   Done with stage: EVALUATION
2022-11-28 02:51:19,731 INFO:   Leaving out SEQ value Fold_5
2022-11-28 02:51:19,744 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:51:19,744 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:51:20,394 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:51:20,395 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:51:20,464 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:51:20,464 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:51:20,464 INFO:     No hyperparam tuning for this model
2022-11-28 02:51:20,464 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:51:20,464 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:51:20,465 INFO:     None feature selector for col prot
2022-11-28 02:51:20,465 INFO:     None feature selector for col prot
2022-11-28 02:51:20,465 INFO:     None feature selector for col prot
2022-11-28 02:51:20,465 INFO:     None feature selector for col chem
2022-11-28 02:51:20,465 INFO:     None feature selector for col chem
2022-11-28 02:51:20,465 INFO:     None feature selector for col chem
2022-11-28 02:51:20,466 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:51:20,466 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:51:20,467 INFO:     Number of params in model 169741
2022-11-28 02:51:20,470 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:51:20,470 INFO:   Starting stage: TRAINING
2022-11-28 02:51:20,524 INFO:     Val loss before train {'Reaction outcome loss': 0.9905693260106173, 'Total loss': 0.9905693260106173}
2022-11-28 02:51:20,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:20,525 INFO:     Epoch: 0
2022-11-28 02:51:21,277 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6150994510813192, 'Total loss': 0.6150994510813192} | train loss {'Reaction outcome loss': 0.648440078866144, 'Total loss': 0.648440078866144}
2022-11-28 02:51:21,277 INFO:     Found new best model at epoch 0
2022-11-28 02:51:21,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:21,278 INFO:     Epoch: 1
2022-11-28 02:51:22,032 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5076519206843593, 'Total loss': 0.5076519206843593} | train loss {'Reaction outcome loss': 0.5134652999308911, 'Total loss': 0.5134652999308911}
2022-11-28 02:51:22,032 INFO:     Found new best model at epoch 1
2022-11-28 02:51:22,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:22,033 INFO:     Epoch: 2
2022-11-28 02:51:22,793 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5148839422247626, 'Total loss': 0.5148839422247626} | train loss {'Reaction outcome loss': 0.4639111344630902, 'Total loss': 0.4639111344630902}
2022-11-28 02:51:22,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:22,793 INFO:     Epoch: 3
2022-11-28 02:51:23,552 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49212810363281856, 'Total loss': 0.49212810363281856} | train loss {'Reaction outcome loss': 0.45682754666216463, 'Total loss': 0.45682754666216463}
2022-11-28 02:51:23,552 INFO:     Found new best model at epoch 3
2022-11-28 02:51:23,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:23,553 INFO:     Epoch: 4
2022-11-28 02:51:24,308 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4888860813596032, 'Total loss': 0.4888860813596032} | train loss {'Reaction outcome loss': 0.4328026900950231, 'Total loss': 0.4328026900950231}
2022-11-28 02:51:24,308 INFO:     Found new best model at epoch 4
2022-11-28 02:51:24,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:24,309 INFO:     Epoch: 5
2022-11-28 02:51:25,064 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4903127899901433, 'Total loss': 0.4903127899901433} | train loss {'Reaction outcome loss': 0.42362211439532305, 'Total loss': 0.42362211439532305}
2022-11-28 02:51:25,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:25,065 INFO:     Epoch: 6
2022-11-28 02:51:25,817 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4732503877444701, 'Total loss': 0.4732503877444701} | train loss {'Reaction outcome loss': 0.4218380885568225, 'Total loss': 0.4218380885568225}
2022-11-28 02:51:25,817 INFO:     Found new best model at epoch 6
2022-11-28 02:51:25,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:25,818 INFO:     Epoch: 7
2022-11-28 02:51:26,570 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49822715432806447, 'Total loss': 0.49822715432806447} | train loss {'Reaction outcome loss': 0.4103975721940338, 'Total loss': 0.4103975721940338}
2022-11-28 02:51:26,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:26,571 INFO:     Epoch: 8
2022-11-28 02:51:27,325 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4698885716497898, 'Total loss': 0.4698885716497898} | train loss {'Reaction outcome loss': 0.40527415081014034, 'Total loss': 0.40527415081014034}
2022-11-28 02:51:27,326 INFO:     Found new best model at epoch 8
2022-11-28 02:51:27,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:27,326 INFO:     Epoch: 9
2022-11-28 02:51:28,078 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4622867794876749, 'Total loss': 0.4622867794876749} | train loss {'Reaction outcome loss': 0.3948696949161016, 'Total loss': 0.3948696949161016}
2022-11-28 02:51:28,078 INFO:     Found new best model at epoch 9
2022-11-28 02:51:28,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:28,079 INFO:     Epoch: 10
2022-11-28 02:51:28,832 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43416192450306634, 'Total loss': 0.43416192450306634} | train loss {'Reaction outcome loss': 0.38601983006787205, 'Total loss': 0.38601983006787205}
2022-11-28 02:51:28,832 INFO:     Found new best model at epoch 10
2022-11-28 02:51:28,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:28,833 INFO:     Epoch: 11
2022-11-28 02:51:29,587 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4579690293493596, 'Total loss': 0.4579690293493596} | train loss {'Reaction outcome loss': 0.38034211943748025, 'Total loss': 0.38034211943748025}
2022-11-28 02:51:29,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:29,587 INFO:     Epoch: 12
2022-11-28 02:51:30,342 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47601301155307074, 'Total loss': 0.47601301155307074} | train loss {'Reaction outcome loss': 0.39672706484311987, 'Total loss': 0.39672706484311987}
2022-11-28 02:51:30,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:30,342 INFO:     Epoch: 13
2022-11-28 02:51:31,096 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4602228311652487, 'Total loss': 0.4602228311652487} | train loss {'Reaction outcome loss': 0.3786032780220634, 'Total loss': 0.3786032780220634}
2022-11-28 02:51:31,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:31,096 INFO:     Epoch: 14
2022-11-28 02:51:31,849 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48187481781298463, 'Total loss': 0.48187481781298463} | train loss {'Reaction outcome loss': 0.3747482448005634, 'Total loss': 0.3747482448005634}
2022-11-28 02:51:31,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:31,850 INFO:     Epoch: 15
2022-11-28 02:51:32,600 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4695291309194131, 'Total loss': 0.4695291309194131} | train loss {'Reaction outcome loss': 0.3672017232186881, 'Total loss': 0.3672017232186881}
2022-11-28 02:51:32,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:32,600 INFO:     Epoch: 16
2022-11-28 02:51:33,354 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44842894053594634, 'Total loss': 0.44842894053594634} | train loss {'Reaction outcome loss': 0.3701790633351214, 'Total loss': 0.3701790633351214}
2022-11-28 02:51:33,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:33,354 INFO:     Epoch: 17
2022-11-28 02:51:34,106 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4550489317625761, 'Total loss': 0.4550489317625761} | train loss {'Reaction outcome loss': 0.4001650864537428, 'Total loss': 0.4001650864537428}
2022-11-28 02:51:34,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:34,107 INFO:     Epoch: 18
2022-11-28 02:51:34,864 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4580492820929397, 'Total loss': 0.4580492820929397} | train loss {'Reaction outcome loss': 0.37144651662120937, 'Total loss': 0.37144651662120937}
2022-11-28 02:51:34,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:34,864 INFO:     Epoch: 19
2022-11-28 02:51:35,617 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44689849560911005, 'Total loss': 0.44689849560911005} | train loss {'Reaction outcome loss': 0.35774831427826814, 'Total loss': 0.35774831427826814}
2022-11-28 02:51:35,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:35,617 INFO:     Epoch: 20
2022-11-28 02:51:36,371 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46558222479440947, 'Total loss': 0.46558222479440947} | train loss {'Reaction outcome loss': 0.3551083135339413, 'Total loss': 0.3551083135339413}
2022-11-28 02:51:36,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:36,371 INFO:     Epoch: 21
2022-11-28 02:51:37,126 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4334504736418074, 'Total loss': 0.4334504736418074} | train loss {'Reaction outcome loss': 0.3624583211565307, 'Total loss': 0.3624583211565307}
2022-11-28 02:51:37,126 INFO:     Found new best model at epoch 21
2022-11-28 02:51:37,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:37,127 INFO:     Epoch: 22
2022-11-28 02:51:37,877 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44671324200250884, 'Total loss': 0.44671324200250884} | train loss {'Reaction outcome loss': 0.3754558229313688, 'Total loss': 0.3754558229313688}
2022-11-28 02:51:37,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:37,878 INFO:     Epoch: 23
2022-11-28 02:51:38,630 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4649604359133677, 'Total loss': 0.4649604359133677} | train loss {'Reaction outcome loss': 0.35527561807171687, 'Total loss': 0.35527561807171687}
2022-11-28 02:51:38,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:38,630 INFO:     Epoch: 24
2022-11-28 02:51:39,384 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4642541879280047, 'Total loss': 0.4642541879280047} | train loss {'Reaction outcome loss': 0.34183260815233174, 'Total loss': 0.34183260815233174}
2022-11-28 02:51:39,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:39,384 INFO:     Epoch: 25
2022-11-28 02:51:40,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5088813108476725, 'Total loss': 0.5088813108476725} | train loss {'Reaction outcome loss': 0.3411631040003618, 'Total loss': 0.3411631040003618}
2022-11-28 02:51:40,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:40,140 INFO:     Epoch: 26
2022-11-28 02:51:40,893 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4281251034276052, 'Total loss': 0.4281251034276052} | train loss {'Reaction outcome loss': 0.35264441288012244, 'Total loss': 0.35264441288012244}
2022-11-28 02:51:40,893 INFO:     Found new best model at epoch 26
2022-11-28 02:51:40,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:40,894 INFO:     Epoch: 27
2022-11-28 02:51:41,650 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41838129914619704, 'Total loss': 0.41838129914619704} | train loss {'Reaction outcome loss': 0.3481221200890277, 'Total loss': 0.3481221200890277}
2022-11-28 02:51:41,650 INFO:     Found new best model at epoch 27
2022-11-28 02:51:41,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:41,651 INFO:     Epoch: 28
2022-11-28 02:51:42,402 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44627755660225044, 'Total loss': 0.44627755660225044} | train loss {'Reaction outcome loss': 0.34283547284390764, 'Total loss': 0.34283547284390764}
2022-11-28 02:51:42,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:42,403 INFO:     Epoch: 29
2022-11-28 02:51:43,158 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46163989535786887, 'Total loss': 0.46163989535786887} | train loss {'Reaction outcome loss': 0.35409411474278096, 'Total loss': 0.35409411474278096}
2022-11-28 02:51:43,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:43,158 INFO:     Epoch: 30
2022-11-28 02:51:43,907 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46340297670526936, 'Total loss': 0.46340297670526936} | train loss {'Reaction outcome loss': 0.36104927830367917, 'Total loss': 0.36104927830367917}
2022-11-28 02:51:43,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:43,908 INFO:     Epoch: 31
2022-11-28 02:51:44,663 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4499866149642251, 'Total loss': 0.4499866149642251} | train loss {'Reaction outcome loss': 0.3408030443164984, 'Total loss': 0.3408030443164984}
2022-11-28 02:51:44,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:44,663 INFO:     Epoch: 32
2022-11-28 02:51:45,419 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4906017671931874, 'Total loss': 0.4906017671931874} | train loss {'Reaction outcome loss': 0.3483471163069671, 'Total loss': 0.3483471163069671}
2022-11-28 02:51:45,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:45,419 INFO:     Epoch: 33
2022-11-28 02:51:46,174 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4610127241096713, 'Total loss': 0.4610127241096713} | train loss {'Reaction outcome loss': 0.35068904588409977, 'Total loss': 0.35068904588409977}
2022-11-28 02:51:46,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:46,174 INFO:     Epoch: 34
2022-11-28 02:51:46,925 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.442484030330723, 'Total loss': 0.442484030330723} | train loss {'Reaction outcome loss': 0.32921470164770056, 'Total loss': 0.32921470164770056}
2022-11-28 02:51:46,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:46,925 INFO:     Epoch: 35
2022-11-28 02:51:47,681 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49742331491275266, 'Total loss': 0.49742331491275266} | train loss {'Reaction outcome loss': 0.3398278181852117, 'Total loss': 0.3398278181852117}
2022-11-28 02:51:47,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:47,681 INFO:     Epoch: 36
2022-11-28 02:51:48,435 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4576985278928822, 'Total loss': 0.4576985278928822} | train loss {'Reaction outcome loss': 0.34068227067650086, 'Total loss': 0.34068227067650086}
2022-11-28 02:51:48,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:48,435 INFO:     Epoch: 37
2022-11-28 02:51:49,187 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44491372122005984, 'Total loss': 0.44491372122005984} | train loss {'Reaction outcome loss': 0.34563332891868437, 'Total loss': 0.34563332891868437}
2022-11-28 02:51:49,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:49,188 INFO:     Epoch: 38
2022-11-28 02:51:49,941 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4978603439574892, 'Total loss': 0.4978603439574892} | train loss {'Reaction outcome loss': 0.3349695389068531, 'Total loss': 0.3349695389068531}
2022-11-28 02:51:49,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:49,941 INFO:     Epoch: 39
2022-11-28 02:51:50,693 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4790527698668567, 'Total loss': 0.4790527698668567} | train loss {'Reaction outcome loss': 0.3339861453876563, 'Total loss': 0.3339861453876563}
2022-11-28 02:51:50,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:50,693 INFO:     Epoch: 40
2022-11-28 02:51:51,449 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4489162980832837, 'Total loss': 0.4489162980832837} | train loss {'Reaction outcome loss': 0.33914326861319755, 'Total loss': 0.33914326861319755}
2022-11-28 02:51:51,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:51,450 INFO:     Epoch: 41
2022-11-28 02:51:52,206 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4469097154214978, 'Total loss': 0.4469097154214978} | train loss {'Reaction outcome loss': 0.3402531583480507, 'Total loss': 0.3402531583480507}
2022-11-28 02:51:52,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:52,206 INFO:     Epoch: 42
2022-11-28 02:51:52,961 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4632074839689515, 'Total loss': 0.4632074839689515} | train loss {'Reaction outcome loss': 0.34421364926857506, 'Total loss': 0.34421364926857506}
2022-11-28 02:51:52,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:52,961 INFO:     Epoch: 43
2022-11-28 02:51:53,717 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4459441476924853, 'Total loss': 0.4459441476924853} | train loss {'Reaction outcome loss': 0.3513153290700333, 'Total loss': 0.3513153290700333}
2022-11-28 02:51:53,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:53,717 INFO:     Epoch: 44
2022-11-28 02:51:54,473 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46153902634978294, 'Total loss': 0.46153902634978294} | train loss {'Reaction outcome loss': 0.33798574418091565, 'Total loss': 0.33798574418091565}
2022-11-28 02:51:54,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:54,473 INFO:     Epoch: 45
2022-11-28 02:51:55,230 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4374074566770684, 'Total loss': 0.4374074566770684} | train loss {'Reaction outcome loss': 0.3207645892657656, 'Total loss': 0.3207645892657656}
2022-11-28 02:51:55,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:55,230 INFO:     Epoch: 46
2022-11-28 02:51:55,988 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4462742730975151, 'Total loss': 0.4462742730975151} | train loss {'Reaction outcome loss': 0.3240052725260074, 'Total loss': 0.3240052725260074}
2022-11-28 02:51:55,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:55,988 INFO:     Epoch: 47
2022-11-28 02:51:56,744 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4233685206960548, 'Total loss': 0.4233685206960548} | train loss {'Reaction outcome loss': 0.32423682958415523, 'Total loss': 0.32423682958415523}
2022-11-28 02:51:56,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:56,744 INFO:     Epoch: 48
2022-11-28 02:51:57,499 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45794635198333045, 'Total loss': 0.45794635198333045} | train loss {'Reaction outcome loss': 0.3287492330442465, 'Total loss': 0.3287492330442465}
2022-11-28 02:51:57,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:57,499 INFO:     Epoch: 49
2022-11-28 02:51:58,253 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4846810791641474, 'Total loss': 0.4846810791641474} | train loss {'Reaction outcome loss': 0.32456916618926324, 'Total loss': 0.32456916618926324}
2022-11-28 02:51:58,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:58,253 INFO:     Epoch: 50
2022-11-28 02:51:59,007 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4490837522528388, 'Total loss': 0.4490837522528388} | train loss {'Reaction outcome loss': 0.32986239105583687, 'Total loss': 0.32986239105583687}
2022-11-28 02:51:59,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:59,007 INFO:     Epoch: 51
2022-11-28 02:51:59,763 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4807679707353765, 'Total loss': 0.4807679707353765} | train loss {'Reaction outcome loss': 0.32956329586082383, 'Total loss': 0.32956329586082383}
2022-11-28 02:51:59,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:51:59,763 INFO:     Epoch: 52
2022-11-28 02:52:00,517 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44878396222537215, 'Total loss': 0.44878396222537215} | train loss {'Reaction outcome loss': 0.3160198405568831, 'Total loss': 0.3160198405568831}
2022-11-28 02:52:00,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:00,517 INFO:     Epoch: 53
2022-11-28 02:52:01,272 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48016462881456723, 'Total loss': 0.48016462881456723} | train loss {'Reaction outcome loss': 0.3238728216242211, 'Total loss': 0.3238728216242211}
2022-11-28 02:52:01,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:01,273 INFO:     Epoch: 54
2022-11-28 02:52:02,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4539353241297332, 'Total loss': 0.4539353241297332} | train loss {'Reaction outcome loss': 0.33006655556047976, 'Total loss': 0.33006655556047976}
2022-11-28 02:52:02,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:02,028 INFO:     Epoch: 55
2022-11-28 02:52:02,782 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46117970144206827, 'Total loss': 0.46117970144206827} | train loss {'Reaction outcome loss': 0.32707357525623776, 'Total loss': 0.32707357525623776}
2022-11-28 02:52:02,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:02,783 INFO:     Epoch: 56
2022-11-28 02:52:03,538 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45776892317966983, 'Total loss': 0.45776892317966983} | train loss {'Reaction outcome loss': 0.3238651076188454, 'Total loss': 0.3238651076188454}
2022-11-28 02:52:03,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:03,538 INFO:     Epoch: 57
2022-11-28 02:52:04,292 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4469183480197733, 'Total loss': 0.4469183480197733} | train loss {'Reaction outcome loss': 0.3223212620899504, 'Total loss': 0.3223212620899504}
2022-11-28 02:52:04,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:04,293 INFO:     Epoch: 58
2022-11-28 02:52:05,047 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4606799708509987, 'Total loss': 0.4606799708509987} | train loss {'Reaction outcome loss': 0.32436447681365194, 'Total loss': 0.32436447681365194}
2022-11-28 02:52:05,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:05,047 INFO:     Epoch: 59
2022-11-28 02:52:05,803 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4534160081635822, 'Total loss': 0.4534160081635822} | train loss {'Reaction outcome loss': 0.3315722975141825, 'Total loss': 0.3315722975141825}
2022-11-28 02:52:05,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:05,803 INFO:     Epoch: 60
2022-11-28 02:52:06,564 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49760445105758583, 'Total loss': 0.49760445105758583} | train loss {'Reaction outcome loss': 0.3249708572892766, 'Total loss': 0.3249708572892766}
2022-11-28 02:52:06,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:06,564 INFO:     Epoch: 61
2022-11-28 02:52:07,322 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47045593945817515, 'Total loss': 0.47045593945817515} | train loss {'Reaction outcome loss': 0.3286561154070412, 'Total loss': 0.3286561154070412}
2022-11-28 02:52:07,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:07,322 INFO:     Epoch: 62
2022-11-28 02:52:08,076 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43825474940240383, 'Total loss': 0.43825474940240383} | train loss {'Reaction outcome loss': 0.3276288651744364, 'Total loss': 0.3276288651744364}
2022-11-28 02:52:08,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:08,076 INFO:     Epoch: 63
2022-11-28 02:52:08,833 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46878016875548795, 'Total loss': 0.46878016875548795} | train loss {'Reaction outcome loss': 0.31974222986894824, 'Total loss': 0.31974222986894824}
2022-11-28 02:52:08,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:08,833 INFO:     Epoch: 64
2022-11-28 02:52:09,586 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47365534576502716, 'Total loss': 0.47365534576502716} | train loss {'Reaction outcome loss': 0.32379904776992585, 'Total loss': 0.32379904776992585}
2022-11-28 02:52:09,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:09,587 INFO:     Epoch: 65
2022-11-28 02:52:10,339 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4523335068740628, 'Total loss': 0.4523335068740628} | train loss {'Reaction outcome loss': 0.3303418933199002, 'Total loss': 0.3303418933199002}
2022-11-28 02:52:10,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:10,339 INFO:     Epoch: 66
2022-11-28 02:52:11,096 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45602199164303864, 'Total loss': 0.45602199164303864} | train loss {'Reaction outcome loss': 0.32854043553594636, 'Total loss': 0.32854043553594636}
2022-11-28 02:52:11,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:11,096 INFO:     Epoch: 67
2022-11-28 02:52:11,855 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45914517986503517, 'Total loss': 0.45914517986503517} | train loss {'Reaction outcome loss': 0.31587837536928626, 'Total loss': 0.31587837536928626}
2022-11-28 02:52:11,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:11,855 INFO:     Epoch: 68
2022-11-28 02:52:12,609 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4741259095343677, 'Total loss': 0.4741259095343677} | train loss {'Reaction outcome loss': 0.32574431242247825, 'Total loss': 0.32574431242247825}
2022-11-28 02:52:12,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:12,610 INFO:     Epoch: 69
2022-11-28 02:52:13,363 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47495594586838374, 'Total loss': 0.47495594586838374} | train loss {'Reaction outcome loss': 0.32426776617825753, 'Total loss': 0.32426776617825753}
2022-11-28 02:52:13,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:13,363 INFO:     Epoch: 70
2022-11-28 02:52:14,117 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5245353738692674, 'Total loss': 0.5245353738692674} | train loss {'Reaction outcome loss': 0.3221976418191424, 'Total loss': 0.3221976418191424}
2022-11-28 02:52:14,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:14,118 INFO:     Epoch: 71
2022-11-28 02:52:14,869 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4743412597612901, 'Total loss': 0.4743412597612901} | train loss {'Reaction outcome loss': 0.31649857540973103, 'Total loss': 0.31649857540973103}
2022-11-28 02:52:14,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:14,870 INFO:     Epoch: 72
2022-11-28 02:52:15,625 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4739512604745952, 'Total loss': 0.4739512604745952} | train loss {'Reaction outcome loss': 0.3155901354213475, 'Total loss': 0.3155901354213475}
2022-11-28 02:52:15,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:15,625 INFO:     Epoch: 73
2022-11-28 02:52:16,379 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4536666382442821, 'Total loss': 0.4536666382442821} | train loss {'Reaction outcome loss': 0.3216860553754969, 'Total loss': 0.3216860553754969}
2022-11-28 02:52:16,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:16,379 INFO:     Epoch: 74
2022-11-28 02:52:17,137 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4584095992825248, 'Total loss': 0.4584095992825248} | train loss {'Reaction outcome loss': 0.3306622161616681, 'Total loss': 0.3306622161616681}
2022-11-28 02:52:17,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:17,137 INFO:     Epoch: 75
2022-11-28 02:52:17,892 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4563497213477438, 'Total loss': 0.4563497213477438} | train loss {'Reaction outcome loss': 0.31598329242424444, 'Total loss': 0.31598329242424444}
2022-11-28 02:52:17,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:17,892 INFO:     Epoch: 76
2022-11-28 02:52:18,649 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45221173246814445, 'Total loss': 0.45221173246814445} | train loss {'Reaction outcome loss': 0.3175194590740841, 'Total loss': 0.3175194590740841}
2022-11-28 02:52:18,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:18,649 INFO:     Epoch: 77
2022-11-28 02:52:19,406 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44858149583028123, 'Total loss': 0.44858149583028123} | train loss {'Reaction outcome loss': 0.3269787321568501, 'Total loss': 0.3269787321568501}
2022-11-28 02:52:19,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:19,406 INFO:     Epoch: 78
2022-11-28 02:52:20,164 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4482300112193281, 'Total loss': 0.4482300112193281} | train loss {'Reaction outcome loss': 0.31408406859984894, 'Total loss': 0.31408406859984894}
2022-11-28 02:52:20,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:20,164 INFO:     Epoch: 79
2022-11-28 02:52:20,918 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4891345731236718, 'Total loss': 0.4891345731236718} | train loss {'Reaction outcome loss': 0.3177226275914473, 'Total loss': 0.3177226275914473}
2022-11-28 02:52:20,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:20,918 INFO:     Epoch: 80
2022-11-28 02:52:21,676 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4459167779846625, 'Total loss': 0.4459167779846625} | train loss {'Reaction outcome loss': 0.3206753811840466, 'Total loss': 0.3206753811840466}
2022-11-28 02:52:21,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:21,676 INFO:     Epoch: 81
2022-11-28 02:52:22,431 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4712958335876465, 'Total loss': 0.4712958335876465} | train loss {'Reaction outcome loss': 0.3081621200992511, 'Total loss': 0.3081621200992511}
2022-11-28 02:52:22,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:22,432 INFO:     Epoch: 82
2022-11-28 02:52:23,189 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44499461962418124, 'Total loss': 0.44499461962418124} | train loss {'Reaction outcome loss': 0.3312094637799842, 'Total loss': 0.3312094637799842}
2022-11-28 02:52:23,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:23,190 INFO:     Epoch: 83
2022-11-28 02:52:23,944 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45889136974107136, 'Total loss': 0.45889136974107136} | train loss {'Reaction outcome loss': 0.31007527445936917, 'Total loss': 0.31007527445936917}
2022-11-28 02:52:23,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:23,944 INFO:     Epoch: 84
2022-11-28 02:52:24,702 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46228804100643506, 'Total loss': 0.46228804100643506} | train loss {'Reaction outcome loss': 0.3203858421202975, 'Total loss': 0.3203858421202975}
2022-11-28 02:52:24,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:24,702 INFO:     Epoch: 85
2022-11-28 02:52:25,456 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4403308548710563, 'Total loss': 0.4403308548710563} | train loss {'Reaction outcome loss': 0.31734976324494096, 'Total loss': 0.31734976324494096}
2022-11-28 02:52:25,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:25,456 INFO:     Epoch: 86
2022-11-28 02:52:26,208 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.455206130377271, 'Total loss': 0.455206130377271} | train loss {'Reaction outcome loss': 0.32479835174947613, 'Total loss': 0.32479835174947613}
2022-11-28 02:52:26,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:26,209 INFO:     Epoch: 87
2022-11-28 02:52:26,963 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4240791841664098, 'Total loss': 0.4240791841664098} | train loss {'Reaction outcome loss': 0.3231773571929468, 'Total loss': 0.3231773571929468}
2022-11-28 02:52:26,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:26,964 INFO:     Epoch: 88
2022-11-28 02:52:27,720 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4739997817034071, 'Total loss': 0.4739997817034071} | train loss {'Reaction outcome loss': 0.3167335277325229, 'Total loss': 0.3167335277325229}
2022-11-28 02:52:27,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:27,720 INFO:     Epoch: 89
2022-11-28 02:52:28,477 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4404896142130548, 'Total loss': 0.4404896142130548} | train loss {'Reaction outcome loss': 0.33358995284628773, 'Total loss': 0.33358995284628773}
2022-11-28 02:52:28,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:28,478 INFO:     Epoch: 90
2022-11-28 02:52:29,237 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47003823349421675, 'Total loss': 0.47003823349421675} | train loss {'Reaction outcome loss': 0.32010818566176813, 'Total loss': 0.32010818566176813}
2022-11-28 02:52:29,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:29,237 INFO:     Epoch: 91
2022-11-28 02:52:29,994 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45371968536214397, 'Total loss': 0.45371968536214397} | train loss {'Reaction outcome loss': 0.32361628459050107, 'Total loss': 0.32361628459050107}
2022-11-28 02:52:29,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:29,994 INFO:     Epoch: 92
2022-11-28 02:52:30,749 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4721943439746445, 'Total loss': 0.4721943439746445} | train loss {'Reaction outcome loss': 0.33729753079202013, 'Total loss': 0.33729753079202013}
2022-11-28 02:52:30,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:30,749 INFO:     Epoch: 93
2022-11-28 02:52:31,507 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4579728956926953, 'Total loss': 0.4579728956926953} | train loss {'Reaction outcome loss': 0.3284524289310461, 'Total loss': 0.3284524289310461}
2022-11-28 02:52:31,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:31,507 INFO:     Epoch: 94
2022-11-28 02:52:32,269 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4616953232748942, 'Total loss': 0.4616953232748942} | train loss {'Reaction outcome loss': 0.31653871671918793, 'Total loss': 0.31653871671918793}
2022-11-28 02:52:32,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:32,269 INFO:     Epoch: 95
2022-11-28 02:52:33,027 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4265125569972125, 'Total loss': 0.4265125569972125} | train loss {'Reaction outcome loss': 0.31659116511523483, 'Total loss': 0.31659116511523483}
2022-11-28 02:52:33,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:33,027 INFO:     Epoch: 96
2022-11-28 02:52:33,783 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4341343441470103, 'Total loss': 0.4341343441470103} | train loss {'Reaction outcome loss': 0.31714843385494673, 'Total loss': 0.31714843385494673}
2022-11-28 02:52:33,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:33,783 INFO:     Epoch: 97
2022-11-28 02:52:34,534 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4490948502313007, 'Total loss': 0.4490948502313007} | train loss {'Reaction outcome loss': 0.3207732978105349, 'Total loss': 0.3207732978105349}
2022-11-28 02:52:34,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:34,534 INFO:     Epoch: 98
2022-11-28 02:52:35,293 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4596154767681252, 'Total loss': 0.4596154767681252} | train loss {'Reaction outcome loss': 0.3041259856653769, 'Total loss': 0.3041259856653769}
2022-11-28 02:52:35,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:35,293 INFO:     Epoch: 99
2022-11-28 02:52:36,048 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4757433174685998, 'Total loss': 0.4757433174685998} | train loss {'Reaction outcome loss': 0.32204152381251216, 'Total loss': 0.32204152381251216}
2022-11-28 02:52:36,048 INFO:     Best model found after epoch 28 of 100.
2022-11-28 02:52:36,048 INFO:   Done with stage: TRAINING
2022-11-28 02:52:36,048 INFO:   Starting stage: EVALUATION
2022-11-28 02:52:36,170 INFO:   Done with stage: EVALUATION
2022-11-28 02:52:36,171 INFO:   Leaving out SEQ value Fold_6
2022-11-28 02:52:36,184 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:52:36,184 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:52:36,836 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:52:36,836 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:52:36,905 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:52:36,905 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:52:36,905 INFO:     No hyperparam tuning for this model
2022-11-28 02:52:36,905 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:52:36,905 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:52:36,906 INFO:     None feature selector for col prot
2022-11-28 02:52:36,906 INFO:     None feature selector for col prot
2022-11-28 02:52:36,906 INFO:     None feature selector for col prot
2022-11-28 02:52:36,907 INFO:     None feature selector for col chem
2022-11-28 02:52:36,907 INFO:     None feature selector for col chem
2022-11-28 02:52:36,907 INFO:     None feature selector for col chem
2022-11-28 02:52:36,907 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:52:36,907 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:52:36,908 INFO:     Number of params in model 169741
2022-11-28 02:52:36,912 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:52:36,912 INFO:   Starting stage: TRAINING
2022-11-28 02:52:36,966 INFO:     Val loss before train {'Reaction outcome loss': 1.0218600847504355, 'Total loss': 1.0218600847504355}
2022-11-28 02:52:36,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:36,966 INFO:     Epoch: 0
2022-11-28 02:52:37,727 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5790930539369583, 'Total loss': 0.5790930539369583} | train loss {'Reaction outcome loss': 0.6420006430557659, 'Total loss': 0.6420006430557659}
2022-11-28 02:52:37,727 INFO:     Found new best model at epoch 0
2022-11-28 02:52:37,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:37,728 INFO:     Epoch: 1
2022-11-28 02:52:38,492 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49479127235033293, 'Total loss': 0.49479127235033293} | train loss {'Reaction outcome loss': 0.5153212967298685, 'Total loss': 0.5153212967298685}
2022-11-28 02:52:38,492 INFO:     Found new best model at epoch 1
2022-11-28 02:52:38,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:38,493 INFO:     Epoch: 2
2022-11-28 02:52:39,253 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4829416237771511, 'Total loss': 0.4829416237771511} | train loss {'Reaction outcome loss': 0.47484355633177106, 'Total loss': 0.47484355633177106}
2022-11-28 02:52:39,254 INFO:     Found new best model at epoch 2
2022-11-28 02:52:39,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:39,255 INFO:     Epoch: 3
2022-11-28 02:52:40,013 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5026067627424543, 'Total loss': 0.5026067627424543} | train loss {'Reaction outcome loss': 0.44905945171992623, 'Total loss': 0.44905945171992623}
2022-11-28 02:52:40,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:40,013 INFO:     Epoch: 4
2022-11-28 02:52:40,782 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4940058839592067, 'Total loss': 0.4940058839592067} | train loss {'Reaction outcome loss': 0.449243527446543, 'Total loss': 0.449243527446543}
2022-11-28 02:52:40,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:40,783 INFO:     Epoch: 5
2022-11-28 02:52:41,549 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45563604445620015, 'Total loss': 0.45563604445620015} | train loss {'Reaction outcome loss': 0.4187426008884945, 'Total loss': 0.4187426008884945}
2022-11-28 02:52:41,549 INFO:     Found new best model at epoch 5
2022-11-28 02:52:41,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:41,550 INFO:     Epoch: 6
2022-11-28 02:52:42,316 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5175256729125977, 'Total loss': 0.5175256729125977} | train loss {'Reaction outcome loss': 0.41299599613393506, 'Total loss': 0.41299599613393506}
2022-11-28 02:52:42,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:42,316 INFO:     Epoch: 7
2022-11-28 02:52:43,085 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43364595486359164, 'Total loss': 0.43364595486359164} | train loss {'Reaction outcome loss': 0.41627288198158624, 'Total loss': 0.41627288198158624}
2022-11-28 02:52:43,085 INFO:     Found new best model at epoch 7
2022-11-28 02:52:43,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:43,086 INFO:     Epoch: 8
2022-11-28 02:52:43,850 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4205623749982227, 'Total loss': 0.4205623749982227} | train loss {'Reaction outcome loss': 0.4048587184159025, 'Total loss': 0.4048587184159025}
2022-11-28 02:52:43,851 INFO:     Found new best model at epoch 8
2022-11-28 02:52:43,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:43,851 INFO:     Epoch: 9
2022-11-28 02:52:44,614 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4298452108421109, 'Total loss': 0.4298452108421109} | train loss {'Reaction outcome loss': 0.3975909667450093, 'Total loss': 0.3975909667450093}
2022-11-28 02:52:44,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:44,614 INFO:     Epoch: 10
2022-11-28 02:52:45,376 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42645972628485074, 'Total loss': 0.42645972628485074} | train loss {'Reaction outcome loss': 0.3894199813085218, 'Total loss': 0.3894199813085218}
2022-11-28 02:52:45,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:45,376 INFO:     Epoch: 11
2022-11-28 02:52:46,143 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4538052569736134, 'Total loss': 0.4538052569736134} | train loss {'Reaction outcome loss': 0.3826816683154433, 'Total loss': 0.3826816683154433}
2022-11-28 02:52:46,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:46,143 INFO:     Epoch: 12
2022-11-28 02:52:46,909 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4116587384857915, 'Total loss': 0.4116587384857915} | train loss {'Reaction outcome loss': 0.3788257359917606, 'Total loss': 0.3788257359917606}
2022-11-28 02:52:46,909 INFO:     Found new best model at epoch 12
2022-11-28 02:52:46,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:46,910 INFO:     Epoch: 13
2022-11-28 02:52:47,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42881920595060696, 'Total loss': 0.42881920595060696} | train loss {'Reaction outcome loss': 0.37250296398997307, 'Total loss': 0.37250296398997307}
2022-11-28 02:52:47,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:47,676 INFO:     Epoch: 14
2022-11-28 02:52:48,440 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48375306176868355, 'Total loss': 0.48375306176868355} | train loss {'Reaction outcome loss': 0.37333028628340653, 'Total loss': 0.37333028628340653}
2022-11-28 02:52:48,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:48,440 INFO:     Epoch: 15
2022-11-28 02:52:49,200 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4356959739869291, 'Total loss': 0.4356959739869291} | train loss {'Reaction outcome loss': 0.36799462133597943, 'Total loss': 0.36799462133597943}
2022-11-28 02:52:49,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:49,201 INFO:     Epoch: 16
2022-11-28 02:52:49,960 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44320330633358523, 'Total loss': 0.44320330633358523} | train loss {'Reaction outcome loss': 0.3605280138191677, 'Total loss': 0.3605280138191677}
2022-11-28 02:52:49,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:49,961 INFO:     Epoch: 17
2022-11-28 02:52:50,720 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4478432231328704, 'Total loss': 0.4478432231328704} | train loss {'Reaction outcome loss': 0.36605228645907295, 'Total loss': 0.36605228645907295}
2022-11-28 02:52:50,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:50,721 INFO:     Epoch: 18
2022-11-28 02:52:51,481 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4671228804032911, 'Total loss': 0.4671228804032911} | train loss {'Reaction outcome loss': 0.36119238779159085, 'Total loss': 0.36119238779159085}
2022-11-28 02:52:51,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:51,481 INFO:     Epoch: 19
2022-11-28 02:52:52,243 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4262067489326, 'Total loss': 0.4262067489326} | train loss {'Reaction outcome loss': 0.357079784205604, 'Total loss': 0.357079784205604}
2022-11-28 02:52:52,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:52,243 INFO:     Epoch: 20
2022-11-28 02:52:53,004 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4588687931272117, 'Total loss': 0.4588687931272117} | train loss {'Reaction outcome loss': 0.35657958884633356, 'Total loss': 0.35657958884633356}
2022-11-28 02:52:53,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:53,004 INFO:     Epoch: 21
2022-11-28 02:52:53,763 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4201543073762547, 'Total loss': 0.4201543073762547} | train loss {'Reaction outcome loss': 0.35966491960589925, 'Total loss': 0.35966491960589925}
2022-11-28 02:52:53,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:53,764 INFO:     Epoch: 22
2022-11-28 02:52:54,523 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4437086626209996, 'Total loss': 0.4437086626209996} | train loss {'Reaction outcome loss': 0.3543550833879459, 'Total loss': 0.3543550833879459}
2022-11-28 02:52:54,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:54,523 INFO:     Epoch: 23
2022-11-28 02:52:55,284 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41128144616430456, 'Total loss': 0.41128144616430456} | train loss {'Reaction outcome loss': 0.34834170882259646, 'Total loss': 0.34834170882259646}
2022-11-28 02:52:55,284 INFO:     Found new best model at epoch 23
2022-11-28 02:52:55,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:55,285 INFO:     Epoch: 24
2022-11-28 02:52:56,042 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4519341252744198, 'Total loss': 0.4519341252744198} | train loss {'Reaction outcome loss': 0.3465176314235695, 'Total loss': 0.3465176314235695}
2022-11-28 02:52:56,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:56,042 INFO:     Epoch: 25
2022-11-28 02:52:56,800 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4503567208620635, 'Total loss': 0.4503567208620635} | train loss {'Reaction outcome loss': 0.34673028520398563, 'Total loss': 0.34673028520398563}
2022-11-28 02:52:56,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:56,800 INFO:     Epoch: 26
2022-11-28 02:52:57,561 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4054309817200357, 'Total loss': 0.4054309817200357} | train loss {'Reaction outcome loss': 0.3506768988445401, 'Total loss': 0.3506768988445401}
2022-11-28 02:52:57,561 INFO:     Found new best model at epoch 26
2022-11-28 02:52:57,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:57,562 INFO:     Epoch: 27
2022-11-28 02:52:58,320 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42317811569029634, 'Total loss': 0.42317811569029634} | train loss {'Reaction outcome loss': 0.34667550682300524, 'Total loss': 0.34667550682300524}
2022-11-28 02:52:58,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:58,321 INFO:     Epoch: 28
2022-11-28 02:52:59,078 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40387487750161777, 'Total loss': 0.40387487750161777} | train loss {'Reaction outcome loss': 0.3493410696485831, 'Total loss': 0.3493410696485831}
2022-11-28 02:52:59,078 INFO:     Found new best model at epoch 28
2022-11-28 02:52:59,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:59,079 INFO:     Epoch: 29
2022-11-28 02:52:59,841 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43801647661761806, 'Total loss': 0.43801647661761806} | train loss {'Reaction outcome loss': 0.3409912916381032, 'Total loss': 0.3409912916381032}
2022-11-28 02:52:59,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:52:59,842 INFO:     Epoch: 30
2022-11-28 02:53:00,600 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4387973519888791, 'Total loss': 0.4387973519888791} | train loss {'Reaction outcome loss': 0.3376146538723861, 'Total loss': 0.3376146538723861}
2022-11-28 02:53:00,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:00,600 INFO:     Epoch: 31
2022-11-28 02:53:01,359 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44037326594645326, 'Total loss': 0.44037326594645326} | train loss {'Reaction outcome loss': 0.3421981401380993, 'Total loss': 0.3421981401380993}
2022-11-28 02:53:01,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:01,360 INFO:     Epoch: 32
2022-11-28 02:53:02,119 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39965058270503173, 'Total loss': 0.39965058270503173} | train loss {'Reaction outcome loss': 0.33543122980383133, 'Total loss': 0.33543122980383133}
2022-11-28 02:53:02,119 INFO:     Found new best model at epoch 32
2022-11-28 02:53:02,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:02,120 INFO:     Epoch: 33
2022-11-28 02:53:02,882 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43953384865414014, 'Total loss': 0.43953384865414014} | train loss {'Reaction outcome loss': 0.328902400639509, 'Total loss': 0.328902400639509}
2022-11-28 02:53:02,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:02,882 INFO:     Epoch: 34
2022-11-28 02:53:03,644 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4404436827383258, 'Total loss': 0.4404436827383258} | train loss {'Reaction outcome loss': 0.3470779459082311, 'Total loss': 0.3470779459082311}
2022-11-28 02:53:03,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:03,644 INFO:     Epoch: 35
2022-11-28 02:53:04,406 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46856849640607834, 'Total loss': 0.46856849640607834} | train loss {'Reaction outcome loss': 0.3326615426208704, 'Total loss': 0.3326615426208704}
2022-11-28 02:53:04,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:04,406 INFO:     Epoch: 36
2022-11-28 02:53:05,164 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4195167953995141, 'Total loss': 0.4195167953995141} | train loss {'Reaction outcome loss': 0.33150551762552033, 'Total loss': 0.33150551762552033}
2022-11-28 02:53:05,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:05,165 INFO:     Epoch: 37
2022-11-28 02:53:05,923 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44215112924575806, 'Total loss': 0.44215112924575806} | train loss {'Reaction outcome loss': 0.3414531605498445, 'Total loss': 0.3414531605498445}
2022-11-28 02:53:05,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:05,924 INFO:     Epoch: 38
2022-11-28 02:53:06,682 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4736764376813715, 'Total loss': 0.4736764376813715} | train loss {'Reaction outcome loss': 0.3240037190637762, 'Total loss': 0.3240037190637762}
2022-11-28 02:53:06,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:06,682 INFO:     Epoch: 39
2022-11-28 02:53:07,440 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4172232068059119, 'Total loss': 0.4172232068059119} | train loss {'Reaction outcome loss': 0.326612931766337, 'Total loss': 0.326612931766337}
2022-11-28 02:53:07,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:07,441 INFO:     Epoch: 40
2022-11-28 02:53:08,200 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47727411545135756, 'Total loss': 0.47727411545135756} | train loss {'Reaction outcome loss': 0.3272858475139665, 'Total loss': 0.3272858475139665}
2022-11-28 02:53:08,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:08,200 INFO:     Epoch: 41
2022-11-28 02:53:08,955 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4422457539899783, 'Total loss': 0.4422457539899783} | train loss {'Reaction outcome loss': 0.3338924918564097, 'Total loss': 0.3338924918564097}
2022-11-28 02:53:08,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:08,955 INFO:     Epoch: 42
2022-11-28 02:53:09,712 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4296213195405223, 'Total loss': 0.4296213195405223} | train loss {'Reaction outcome loss': 0.3299600930223542, 'Total loss': 0.3299600930223542}
2022-11-28 02:53:09,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:09,713 INFO:     Epoch: 43
2022-11-28 02:53:10,474 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4133565149862658, 'Total loss': 0.4133565149862658} | train loss {'Reaction outcome loss': 0.322357265188569, 'Total loss': 0.322357265188569}
2022-11-28 02:53:10,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:10,474 INFO:     Epoch: 44
2022-11-28 02:53:11,235 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45277862589467655, 'Total loss': 0.45277862589467655} | train loss {'Reaction outcome loss': 0.326502037084391, 'Total loss': 0.326502037084391}
2022-11-28 02:53:11,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:11,235 INFO:     Epoch: 45
2022-11-28 02:53:11,997 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42834843356500973, 'Total loss': 0.42834843356500973} | train loss {'Reaction outcome loss': 0.33636395507041483, 'Total loss': 0.33636395507041483}
2022-11-28 02:53:11,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:11,998 INFO:     Epoch: 46
2022-11-28 02:53:12,761 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4209595031358979, 'Total loss': 0.4209595031358979} | train loss {'Reaction outcome loss': 0.32875481347042707, 'Total loss': 0.32875481347042707}
2022-11-28 02:53:12,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:12,761 INFO:     Epoch: 47
2022-11-28 02:53:13,518 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41999560086564586, 'Total loss': 0.41999560086564586} | train loss {'Reaction outcome loss': 0.32222692832170474, 'Total loss': 0.32222692832170474}
2022-11-28 02:53:13,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:13,518 INFO:     Epoch: 48
2022-11-28 02:53:14,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42530336332592095, 'Total loss': 0.42530336332592095} | train loss {'Reaction outcome loss': 0.32090544219939937, 'Total loss': 0.32090544219939937}
2022-11-28 02:53:14,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:14,280 INFO:     Epoch: 49
2022-11-28 02:53:15,040 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4170964627780698, 'Total loss': 0.4170964627780698} | train loss {'Reaction outcome loss': 0.3222391124694578, 'Total loss': 0.3222391124694578}
2022-11-28 02:53:15,041 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:15,041 INFO:     Epoch: 50
2022-11-28 02:53:15,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.400371136313135, 'Total loss': 0.400371136313135} | train loss {'Reaction outcome loss': 0.3274225263646053, 'Total loss': 0.3274225263646053}
2022-11-28 02:53:15,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:15,802 INFO:     Epoch: 51
2022-11-28 02:53:16,563 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39975502028722654, 'Total loss': 0.39975502028722654} | train loss {'Reaction outcome loss': 0.32325183579157435, 'Total loss': 0.32325183579157435}
2022-11-28 02:53:16,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:16,564 INFO:     Epoch: 52
2022-11-28 02:53:17,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45879828625104646, 'Total loss': 0.45879828625104646} | train loss {'Reaction outcome loss': 0.32448959335564603, 'Total loss': 0.32448959335564603}
2022-11-28 02:53:17,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:17,319 INFO:     Epoch: 53
2022-11-28 02:53:18,080 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.397099168124524, 'Total loss': 0.397099168124524} | train loss {'Reaction outcome loss': 0.3225023009543938, 'Total loss': 0.3225023009543938}
2022-11-28 02:53:18,080 INFO:     Found new best model at epoch 53
2022-11-28 02:53:18,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:18,081 INFO:     Epoch: 54
2022-11-28 02:53:18,839 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4316465509208766, 'Total loss': 0.4316465509208766} | train loss {'Reaction outcome loss': 0.32277807178756884, 'Total loss': 0.32277807178756884}
2022-11-28 02:53:18,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:18,839 INFO:     Epoch: 55
2022-11-28 02:53:19,596 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4269050261513753, 'Total loss': 0.4269050261513753} | train loss {'Reaction outcome loss': 0.3269757876893686, 'Total loss': 0.3269757876893686}
2022-11-28 02:53:19,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:19,596 INFO:     Epoch: 56
2022-11-28 02:53:20,353 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43045585771853273, 'Total loss': 0.43045585771853273} | train loss {'Reaction outcome loss': 0.3243631539085219, 'Total loss': 0.3243631539085219}
2022-11-28 02:53:20,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:20,353 INFO:     Epoch: 57
2022-11-28 02:53:21,113 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4113123711537231, 'Total loss': 0.4113123711537231} | train loss {'Reaction outcome loss': 0.32441306507755674, 'Total loss': 0.32441306507755674}
2022-11-28 02:53:21,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:21,113 INFO:     Epoch: 58
2022-11-28 02:53:21,874 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4365955472669818, 'Total loss': 0.4365955472669818} | train loss {'Reaction outcome loss': 0.31832368750004997, 'Total loss': 0.31832368750004997}
2022-11-28 02:53:21,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:21,874 INFO:     Epoch: 59
2022-11-28 02:53:22,634 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4232477847148072, 'Total loss': 0.4232477847148072} | train loss {'Reaction outcome loss': 0.3221097189422336, 'Total loss': 0.3221097189422336}
2022-11-28 02:53:22,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:22,635 INFO:     Epoch: 60
2022-11-28 02:53:23,393 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4258461262692105, 'Total loss': 0.4258461262692105} | train loss {'Reaction outcome loss': 0.3182589218561207, 'Total loss': 0.3182589218561207}
2022-11-28 02:53:23,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:23,393 INFO:     Epoch: 61
2022-11-28 02:53:24,149 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44795323603532533, 'Total loss': 0.44795323603532533} | train loss {'Reaction outcome loss': 0.324105289975001, 'Total loss': 0.324105289975001}
2022-11-28 02:53:24,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:24,149 INFO:     Epoch: 62
2022-11-28 02:53:24,905 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43900718743150885, 'Total loss': 0.43900718743150885} | train loss {'Reaction outcome loss': 0.30406186636537313, 'Total loss': 0.30406186636537313}
2022-11-28 02:53:24,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:24,906 INFO:     Epoch: 63
2022-11-28 02:53:25,665 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4460989907383919, 'Total loss': 0.4460989907383919} | train loss {'Reaction outcome loss': 0.32180510485364544, 'Total loss': 0.32180510485364544}
2022-11-28 02:53:25,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:25,666 INFO:     Epoch: 64
2022-11-28 02:53:26,427 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42595789446072146, 'Total loss': 0.42595789446072146} | train loss {'Reaction outcome loss': 0.3140056399748691, 'Total loss': 0.3140056399748691}
2022-11-28 02:53:26,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:26,427 INFO:     Epoch: 65
2022-11-28 02:53:27,187 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4152687266469002, 'Total loss': 0.4152687266469002} | train loss {'Reaction outcome loss': 0.3207815802325645, 'Total loss': 0.3207815802325645}
2022-11-28 02:53:27,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:27,187 INFO:     Epoch: 66
2022-11-28 02:53:27,946 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4569057480178096, 'Total loss': 0.4569057480178096} | train loss {'Reaction outcome loss': 0.31961166885711495, 'Total loss': 0.31961166885711495}
2022-11-28 02:53:27,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:27,947 INFO:     Epoch: 67
2022-11-28 02:53:28,704 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4228215559639714, 'Total loss': 0.4228215559639714} | train loss {'Reaction outcome loss': 0.31928524574745565, 'Total loss': 0.31928524574745565}
2022-11-28 02:53:28,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:28,704 INFO:     Epoch: 68
2022-11-28 02:53:29,464 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44402091442184016, 'Total loss': 0.44402091442184016} | train loss {'Reaction outcome loss': 0.31988834151096884, 'Total loss': 0.31988834151096884}
2022-11-28 02:53:29,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:29,464 INFO:     Epoch: 69
2022-11-28 02:53:30,222 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4228092548860745, 'Total loss': 0.4228092548860745} | train loss {'Reaction outcome loss': 0.3278261737357224, 'Total loss': 0.3278261737357224}
2022-11-28 02:53:30,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:30,222 INFO:     Epoch: 70
2022-11-28 02:53:30,980 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4144215698946606, 'Total loss': 0.4144215698946606} | train loss {'Reaction outcome loss': 0.3135463086467597, 'Total loss': 0.3135463086467597}
2022-11-28 02:53:30,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:30,981 INFO:     Epoch: 71
2022-11-28 02:53:31,738 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4141597957773642, 'Total loss': 0.4141597957773642} | train loss {'Reaction outcome loss': 0.3139277273007939, 'Total loss': 0.3139277273007939}
2022-11-28 02:53:31,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:31,738 INFO:     Epoch: 72
2022-11-28 02:53:32,494 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42108735120431945, 'Total loss': 0.42108735120431945} | train loss {'Reaction outcome loss': 0.3135985063629285, 'Total loss': 0.3135985063629285}
2022-11-28 02:53:32,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:32,495 INFO:     Epoch: 73
2022-11-28 02:53:33,254 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4355888000943444, 'Total loss': 0.4355888000943444} | train loss {'Reaction outcome loss': 0.31475030949279187, 'Total loss': 0.31475030949279187}
2022-11-28 02:53:33,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:33,254 INFO:     Epoch: 74
2022-11-28 02:53:34,013 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.421779045665806, 'Total loss': 0.421779045665806} | train loss {'Reaction outcome loss': 0.3214225627842449, 'Total loss': 0.3214225627842449}
2022-11-28 02:53:34,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:34,013 INFO:     Epoch: 75
2022-11-28 02:53:34,771 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41924922134388576, 'Total loss': 0.41924922134388576} | train loss {'Reaction outcome loss': 0.3215755610876987, 'Total loss': 0.3215755610876987}
2022-11-28 02:53:34,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:34,771 INFO:     Epoch: 76
2022-11-28 02:53:35,525 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4207815080881119, 'Total loss': 0.4207815080881119} | train loss {'Reaction outcome loss': 0.31331890115454314, 'Total loss': 0.31331890115454314}
2022-11-28 02:53:35,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:35,525 INFO:     Epoch: 77
2022-11-28 02:53:36,281 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43450275097380986, 'Total loss': 0.43450275097380986} | train loss {'Reaction outcome loss': 0.31181959285130423, 'Total loss': 0.31181959285130423}
2022-11-28 02:53:36,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:36,281 INFO:     Epoch: 78
2022-11-28 02:53:37,039 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4307615679096092, 'Total loss': 0.4307615679096092} | train loss {'Reaction outcome loss': 0.3222782053053379, 'Total loss': 0.3222782053053379}
2022-11-28 02:53:37,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:37,040 INFO:     Epoch: 79
2022-11-28 02:53:37,798 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4189056134359403, 'Total loss': 0.4189056134359403} | train loss {'Reaction outcome loss': 0.306555011429854, 'Total loss': 0.306555011429854}
2022-11-28 02:53:37,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:37,798 INFO:     Epoch: 80
2022-11-28 02:53:38,558 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43351149338890205, 'Total loss': 0.43351149338890205} | train loss {'Reaction outcome loss': 0.311298503119859, 'Total loss': 0.311298503119859}
2022-11-28 02:53:38,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:38,559 INFO:     Epoch: 81
2022-11-28 02:53:39,315 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44487173008647835, 'Total loss': 0.44487173008647835} | train loss {'Reaction outcome loss': 0.31235263523675744, 'Total loss': 0.31235263523675744}
2022-11-28 02:53:39,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:39,316 INFO:     Epoch: 82
2022-11-28 02:53:40,071 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42284859818491066, 'Total loss': 0.42284859818491066} | train loss {'Reaction outcome loss': 0.3182150538289739, 'Total loss': 0.3182150538289739}
2022-11-28 02:53:40,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:40,071 INFO:     Epoch: 83
2022-11-28 02:53:40,833 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4145132194865834, 'Total loss': 0.4145132194865834} | train loss {'Reaction outcome loss': 0.32397258900586634, 'Total loss': 0.32397258900586634}
2022-11-28 02:53:40,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:40,833 INFO:     Epoch: 84
2022-11-28 02:53:41,592 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41308171810074285, 'Total loss': 0.41308171810074285} | train loss {'Reaction outcome loss': 0.3131346559572604, 'Total loss': 0.3131346559572604}
2022-11-28 02:53:41,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:41,592 INFO:     Epoch: 85
2022-11-28 02:53:42,348 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40898696570233867, 'Total loss': 0.40898696570233867} | train loss {'Reaction outcome loss': 0.306496670800111, 'Total loss': 0.306496670800111}
2022-11-28 02:53:42,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:42,349 INFO:     Epoch: 86
2022-11-28 02:53:43,106 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41684699939055875, 'Total loss': 0.41684699939055875} | train loss {'Reaction outcome loss': 0.3231741664330325, 'Total loss': 0.3231741664330325}
2022-11-28 02:53:43,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:43,107 INFO:     Epoch: 87
2022-11-28 02:53:43,864 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4662883918393742, 'Total loss': 0.4662883918393742} | train loss {'Reaction outcome loss': 0.31410498400368997, 'Total loss': 0.31410498400368997}
2022-11-28 02:53:43,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:43,865 INFO:     Epoch: 88
2022-11-28 02:53:44,621 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4319637504152276, 'Total loss': 0.4319637504152276} | train loss {'Reaction outcome loss': 0.3219793023421399, 'Total loss': 0.3219793023421399}
2022-11-28 02:53:44,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:44,621 INFO:     Epoch: 89
2022-11-28 02:53:45,374 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41818348927931354, 'Total loss': 0.41818348927931354} | train loss {'Reaction outcome loss': 0.31613161453917143, 'Total loss': 0.31613161453917143}
2022-11-28 02:53:45,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:45,374 INFO:     Epoch: 90
2022-11-28 02:53:46,131 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4016515846279534, 'Total loss': 0.4016515846279534} | train loss {'Reaction outcome loss': 0.3106119860744765, 'Total loss': 0.3106119860744765}
2022-11-28 02:53:46,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:46,132 INFO:     Epoch: 91
2022-11-28 02:53:46,892 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.450671743770892, 'Total loss': 0.450671743770892} | train loss {'Reaction outcome loss': 0.3098668271014767, 'Total loss': 0.3098668271014767}
2022-11-28 02:53:46,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:46,892 INFO:     Epoch: 92
2022-11-28 02:53:47,655 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4278184368529103, 'Total loss': 0.4278184368529103} | train loss {'Reaction outcome loss': 0.31747677429549154, 'Total loss': 0.31747677429549154}
2022-11-28 02:53:47,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:47,656 INFO:     Epoch: 93
2022-11-28 02:53:48,414 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4271948503499681, 'Total loss': 0.4271948503499681} | train loss {'Reaction outcome loss': 0.3088684502628542, 'Total loss': 0.3088684502628542}
2022-11-28 02:53:48,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:48,414 INFO:     Epoch: 94
2022-11-28 02:53:49,175 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41817673024806107, 'Total loss': 0.41817673024806107} | train loss {'Reaction outcome loss': 0.31482171672847004, 'Total loss': 0.31482171672847004}
2022-11-28 02:53:49,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:49,175 INFO:     Epoch: 95
2022-11-28 02:53:49,935 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4314261356537992, 'Total loss': 0.4314261356537992} | train loss {'Reaction outcome loss': 0.3073257995438912, 'Total loss': 0.3073257995438912}
2022-11-28 02:53:49,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:49,935 INFO:     Epoch: 96
2022-11-28 02:53:50,691 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4443973069163886, 'Total loss': 0.4443973069163886} | train loss {'Reaction outcome loss': 0.31369345115437625, 'Total loss': 0.31369345115437625}
2022-11-28 02:53:50,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:50,692 INFO:     Epoch: 97
2022-11-28 02:53:51,451 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43133168667554855, 'Total loss': 0.43133168667554855} | train loss {'Reaction outcome loss': 0.3142475953565971, 'Total loss': 0.3142475953565971}
2022-11-28 02:53:51,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:51,451 INFO:     Epoch: 98
2022-11-28 02:53:52,209 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40642882815816184, 'Total loss': 0.40642882815816184} | train loss {'Reaction outcome loss': 0.307133135325726, 'Total loss': 0.307133135325726}
2022-11-28 02:53:52,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:52,210 INFO:     Epoch: 99
2022-11-28 02:53:52,966 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4125539457256144, 'Total loss': 0.4125539457256144} | train loss {'Reaction outcome loss': 0.30813988984652585, 'Total loss': 0.30813988984652585}
2022-11-28 02:53:52,966 INFO:     Best model found after epoch 54 of 100.
2022-11-28 02:53:52,967 INFO:   Done with stage: TRAINING
2022-11-28 02:53:52,967 INFO:   Starting stage: EVALUATION
2022-11-28 02:53:53,083 INFO:   Done with stage: EVALUATION
2022-11-28 02:53:53,083 INFO:   Leaving out SEQ value Fold_7
2022-11-28 02:53:53,096 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 02:53:53,096 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:53:53,746 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:53:53,746 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:53:53,814 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:53:53,814 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:53:53,815 INFO:     No hyperparam tuning for this model
2022-11-28 02:53:53,815 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:53:53,815 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:53:53,815 INFO:     None feature selector for col prot
2022-11-28 02:53:53,815 INFO:     None feature selector for col prot
2022-11-28 02:53:53,816 INFO:     None feature selector for col prot
2022-11-28 02:53:53,816 INFO:     None feature selector for col chem
2022-11-28 02:53:53,816 INFO:     None feature selector for col chem
2022-11-28 02:53:53,816 INFO:     None feature selector for col chem
2022-11-28 02:53:53,816 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:53:53,816 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:53:53,818 INFO:     Number of params in model 169741
2022-11-28 02:53:53,821 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:53:53,821 INFO:   Starting stage: TRAINING
2022-11-28 02:53:53,875 INFO:     Val loss before train {'Reaction outcome loss': 1.0393770282918757, 'Total loss': 1.0393770282918757}
2022-11-28 02:53:53,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:53,875 INFO:     Epoch: 0
2022-11-28 02:53:54,628 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5344839746301825, 'Total loss': 0.5344839746301825} | train loss {'Reaction outcome loss': 0.6201687981958995, 'Total loss': 0.6201687981958995}
2022-11-28 02:53:54,629 INFO:     Found new best model at epoch 0
2022-11-28 02:53:54,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:54,629 INFO:     Epoch: 1
2022-11-28 02:53:55,376 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4824695773422718, 'Total loss': 0.4824695773422718} | train loss {'Reaction outcome loss': 0.4880633948574423, 'Total loss': 0.4880633948574423}
2022-11-28 02:53:55,376 INFO:     Found new best model at epoch 1
2022-11-28 02:53:55,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:55,377 INFO:     Epoch: 2
2022-11-28 02:53:56,118 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47291687063195487, 'Total loss': 0.47291687063195487} | train loss {'Reaction outcome loss': 0.46080138851032565, 'Total loss': 0.46080138851032565}
2022-11-28 02:53:56,119 INFO:     Found new best model at epoch 2
2022-11-28 02:53:56,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:56,120 INFO:     Epoch: 3
2022-11-28 02:53:56,870 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.474289265207269, 'Total loss': 0.474289265207269} | train loss {'Reaction outcome loss': 0.44612458426701396, 'Total loss': 0.44612458426701396}
2022-11-28 02:53:56,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:56,870 INFO:     Epoch: 4
2022-11-28 02:53:57,613 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4556551138785752, 'Total loss': 0.4556551138785752} | train loss {'Reaction outcome loss': 0.4396087070286033, 'Total loss': 0.4396087070286033}
2022-11-28 02:53:57,614 INFO:     Found new best model at epoch 4
2022-11-28 02:53:57,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:57,614 INFO:     Epoch: 5
2022-11-28 02:53:58,358 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5143371258269657, 'Total loss': 0.5143371258269657} | train loss {'Reaction outcome loss': 0.41774472901936965, 'Total loss': 0.41774472901936965}
2022-11-28 02:53:58,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:58,358 INFO:     Epoch: 6
2022-11-28 02:53:59,102 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4458204939622771, 'Total loss': 0.4458204939622771} | train loss {'Reaction outcome loss': 0.416697965516343, 'Total loss': 0.416697965516343}
2022-11-28 02:53:59,102 INFO:     Found new best model at epoch 6
2022-11-28 02:53:59,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:59,103 INFO:     Epoch: 7
2022-11-28 02:53:59,850 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47450602833520283, 'Total loss': 0.47450602833520283} | train loss {'Reaction outcome loss': 0.398631122521302, 'Total loss': 0.398631122521302}
2022-11-28 02:53:59,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:53:59,850 INFO:     Epoch: 8
2022-11-28 02:54:00,598 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4782322570681572, 'Total loss': 0.4782322570681572} | train loss {'Reaction outcome loss': 0.395281223452043, 'Total loss': 0.395281223452043}
2022-11-28 02:54:00,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:00,598 INFO:     Epoch: 9
2022-11-28 02:54:01,344 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4642911787060174, 'Total loss': 0.4642911787060174} | train loss {'Reaction outcome loss': 0.3946767951312818, 'Total loss': 0.3946767951312818}
2022-11-28 02:54:01,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:01,345 INFO:     Epoch: 10
2022-11-28 02:54:02,089 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47762811285528267, 'Total loss': 0.47762811285528267} | train loss {'Reaction outcome loss': 0.3951507395638628, 'Total loss': 0.3951507395638628}
2022-11-28 02:54:02,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:02,089 INFO:     Epoch: 11
2022-11-28 02:54:02,832 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44577877528288146, 'Total loss': 0.44577877528288146} | train loss {'Reaction outcome loss': 0.3878719388594029, 'Total loss': 0.3878719388594029}
2022-11-28 02:54:02,832 INFO:     Found new best model at epoch 11
2022-11-28 02:54:02,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:02,833 INFO:     Epoch: 12
2022-11-28 02:54:03,575 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47241955453699286, 'Total loss': 0.47241955453699286} | train loss {'Reaction outcome loss': 0.3744394216037955, 'Total loss': 0.3744394216037955}
2022-11-28 02:54:03,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:03,576 INFO:     Epoch: 13
2022-11-28 02:54:04,318 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45648748021234165, 'Total loss': 0.45648748021234165} | train loss {'Reaction outcome loss': 0.3655468146448676, 'Total loss': 0.3655468146448676}
2022-11-28 02:54:04,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:04,319 INFO:     Epoch: 14
2022-11-28 02:54:05,063 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49957621876489033, 'Total loss': 0.49957621876489033} | train loss {'Reaction outcome loss': 0.369228789831704, 'Total loss': 0.369228789831704}
2022-11-28 02:54:05,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:05,063 INFO:     Epoch: 15
2022-11-28 02:54:05,806 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45214061506769876, 'Total loss': 0.45214061506769876} | train loss {'Reaction outcome loss': 0.3811931460492524, 'Total loss': 0.3811931460492524}
2022-11-28 02:54:05,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:05,807 INFO:     Epoch: 16
2022-11-28 02:54:06,555 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49108629809184506, 'Total loss': 0.49108629809184506} | train loss {'Reaction outcome loss': 0.36855529922886415, 'Total loss': 0.36855529922886415}
2022-11-28 02:54:06,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:06,555 INFO:     Epoch: 17
2022-11-28 02:54:07,302 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46895017237825826, 'Total loss': 0.46895017237825826} | train loss {'Reaction outcome loss': 0.35091118405946353, 'Total loss': 0.35091118405946353}
2022-11-28 02:54:07,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:07,302 INFO:     Epoch: 18
2022-11-28 02:54:08,045 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46557687189091335, 'Total loss': 0.46557687189091335} | train loss {'Reaction outcome loss': 0.3524876298149105, 'Total loss': 0.3524876298149105}
2022-11-28 02:54:08,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:08,046 INFO:     Epoch: 19
2022-11-28 02:54:08,790 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44837553054094315, 'Total loss': 0.44837553054094315} | train loss {'Reaction outcome loss': 0.3459357561191039, 'Total loss': 0.3459357561191039}
2022-11-28 02:54:08,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:08,790 INFO:     Epoch: 20
2022-11-28 02:54:09,537 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45183941755782475, 'Total loss': 0.45183941755782475} | train loss {'Reaction outcome loss': 0.3392040021415905, 'Total loss': 0.3392040021415905}
2022-11-28 02:54:09,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:09,537 INFO:     Epoch: 21
2022-11-28 02:54:10,281 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4574893834916028, 'Total loss': 0.4574893834916028} | train loss {'Reaction outcome loss': 0.33587713519239476, 'Total loss': 0.33587713519239476}
2022-11-28 02:54:10,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:10,281 INFO:     Epoch: 22
2022-11-28 02:54:11,029 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47358045320619235, 'Total loss': 0.47358045320619235} | train loss {'Reaction outcome loss': 0.33944993140364466, 'Total loss': 0.33944993140364466}
2022-11-28 02:54:11,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:11,029 INFO:     Epoch: 23
2022-11-28 02:54:11,776 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4760619696568359, 'Total loss': 0.4760619696568359} | train loss {'Reaction outcome loss': 0.34050299587701016, 'Total loss': 0.34050299587701016}
2022-11-28 02:54:11,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:11,776 INFO:     Epoch: 24
2022-11-28 02:54:12,522 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4376589550890706, 'Total loss': 0.4376589550890706} | train loss {'Reaction outcome loss': 0.33776610711144534, 'Total loss': 0.33776610711144534}
2022-11-28 02:54:12,522 INFO:     Found new best model at epoch 24
2022-11-28 02:54:12,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:12,523 INFO:     Epoch: 25
2022-11-28 02:54:13,267 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4542445062913678, 'Total loss': 0.4542445062913678} | train loss {'Reaction outcome loss': 0.33544939436651916, 'Total loss': 0.33544939436651916}
2022-11-28 02:54:13,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:13,268 INFO:     Epoch: 26
2022-11-28 02:54:14,010 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4505336017093875, 'Total loss': 0.4505336017093875} | train loss {'Reaction outcome loss': 0.3381388659969817, 'Total loss': 0.3381388659969817}
2022-11-28 02:54:14,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:14,010 INFO:     Epoch: 27
2022-11-28 02:54:14,755 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4853860830718821, 'Total loss': 0.4853860830718821} | train loss {'Reaction outcome loss': 0.3291807541782074, 'Total loss': 0.3291807541782074}
2022-11-28 02:54:14,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:14,755 INFO:     Epoch: 28
2022-11-28 02:54:15,501 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44954760846766556, 'Total loss': 0.44954760846766556} | train loss {'Reaction outcome loss': 0.3338228469311075, 'Total loss': 0.3338228469311075}
2022-11-28 02:54:15,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:15,502 INFO:     Epoch: 29
2022-11-28 02:54:16,251 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5280379751189188, 'Total loss': 0.5280379751189188} | train loss {'Reaction outcome loss': 0.3328867051524189, 'Total loss': 0.3328867051524189}
2022-11-28 02:54:16,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:16,252 INFO:     Epoch: 30
2022-11-28 02:54:16,995 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4148177452046763, 'Total loss': 0.4148177452046763} | train loss {'Reaction outcome loss': 0.3455125092244085, 'Total loss': 0.3455125092244085}
2022-11-28 02:54:16,995 INFO:     Found new best model at epoch 30
2022-11-28 02:54:16,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:16,996 INFO:     Epoch: 31
2022-11-28 02:54:17,742 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45835094289346173, 'Total loss': 0.45835094289346173} | train loss {'Reaction outcome loss': 0.3316454612572799, 'Total loss': 0.3316454612572799}
2022-11-28 02:54:17,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:17,742 INFO:     Epoch: 32
2022-11-28 02:54:18,485 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4531345872039145, 'Total loss': 0.4531345872039145} | train loss {'Reaction outcome loss': 0.32029722220743234, 'Total loss': 0.32029722220743234}
2022-11-28 02:54:18,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:18,485 INFO:     Epoch: 33
2022-11-28 02:54:19,230 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45286689495498483, 'Total loss': 0.45286689495498483} | train loss {'Reaction outcome loss': 0.33677084639909777, 'Total loss': 0.33677084639909777}
2022-11-28 02:54:19,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:19,230 INFO:     Epoch: 34
2022-11-28 02:54:19,984 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45611110803755844, 'Total loss': 0.45611110803755844} | train loss {'Reaction outcome loss': 0.3379672433924579, 'Total loss': 0.3379672433924579}
2022-11-28 02:54:19,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:19,984 INFO:     Epoch: 35
2022-11-28 02:54:20,732 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44508962417868053, 'Total loss': 0.44508962417868053} | train loss {'Reaction outcome loss': 0.3318747364350798, 'Total loss': 0.3318747364350798}
2022-11-28 02:54:20,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:20,732 INFO:     Epoch: 36
2022-11-28 02:54:21,478 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46517425030469894, 'Total loss': 0.46517425030469894} | train loss {'Reaction outcome loss': 0.3182524319904053, 'Total loss': 0.3182524319904053}
2022-11-28 02:54:21,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:21,478 INFO:     Epoch: 37
2022-11-28 02:54:22,224 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4412145347080447, 'Total loss': 0.4412145347080447} | train loss {'Reaction outcome loss': 0.33109625971872314, 'Total loss': 0.33109625971872314}
2022-11-28 02:54:22,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:22,224 INFO:     Epoch: 38
2022-11-28 02:54:22,965 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46006451394747605, 'Total loss': 0.46006451394747605} | train loss {'Reaction outcome loss': 0.3258510620487846, 'Total loss': 0.3258510620487846}
2022-11-28 02:54:22,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:22,965 INFO:     Epoch: 39
2022-11-28 02:54:23,709 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4628013863482259, 'Total loss': 0.4628013863482259} | train loss {'Reaction outcome loss': 0.3226433058951789, 'Total loss': 0.3226433058951789}
2022-11-28 02:54:23,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:23,710 INFO:     Epoch: 40
2022-11-28 02:54:24,457 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5084489075974985, 'Total loss': 0.5084489075974985} | train loss {'Reaction outcome loss': 0.3215978873312956, 'Total loss': 0.3215978873312956}
2022-11-28 02:54:24,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:24,457 INFO:     Epoch: 41
2022-11-28 02:54:25,206 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4365328773856163, 'Total loss': 0.4365328773856163} | train loss {'Reaction outcome loss': 0.320594084664033, 'Total loss': 0.320594084664033}
2022-11-28 02:54:25,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:25,206 INFO:     Epoch: 42
2022-11-28 02:54:25,955 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47017405690117314, 'Total loss': 0.47017405690117314} | train loss {'Reaction outcome loss': 0.3297967273395071, 'Total loss': 0.3297967273395071}
2022-11-28 02:54:25,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:25,955 INFO:     Epoch: 43
2022-11-28 02:54:26,701 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4501131156628782, 'Total loss': 0.4501131156628782} | train loss {'Reaction outcome loss': 0.3193740049746596, 'Total loss': 0.3193740049746596}
2022-11-28 02:54:26,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:26,701 INFO:     Epoch: 44
2022-11-28 02:54:27,443 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4593177285384048, 'Total loss': 0.4593177285384048} | train loss {'Reaction outcome loss': 0.33392937240089, 'Total loss': 0.33392937240089}
2022-11-28 02:54:27,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:27,445 INFO:     Epoch: 45
2022-11-28 02:54:28,190 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.466594549742612, 'Total loss': 0.466594549742612} | train loss {'Reaction outcome loss': 0.31977978237124105, 'Total loss': 0.31977978237124105}
2022-11-28 02:54:28,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:28,190 INFO:     Epoch: 46
2022-11-28 02:54:28,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4470941116186706, 'Total loss': 0.4470941116186706} | train loss {'Reaction outcome loss': 0.32331899047154283, 'Total loss': 0.32331899047154283}
2022-11-28 02:54:28,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:28,937 INFO:     Epoch: 47
2022-11-28 02:54:29,686 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4558473845774477, 'Total loss': 0.4558473845774477} | train loss {'Reaction outcome loss': 0.3159424225811051, 'Total loss': 0.3159424225811051}
2022-11-28 02:54:29,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:29,686 INFO:     Epoch: 48
2022-11-28 02:54:30,435 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44149622456593945, 'Total loss': 0.44149622456593945} | train loss {'Reaction outcome loss': 0.3186475326295806, 'Total loss': 0.3186475326295806}
2022-11-28 02:54:30,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:30,435 INFO:     Epoch: 49
2022-11-28 02:54:31,177 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46192707256837323, 'Total loss': 0.46192707256837323} | train loss {'Reaction outcome loss': 0.32273917274310054, 'Total loss': 0.32273917274310054}
2022-11-28 02:54:31,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:31,177 INFO:     Epoch: 50
2022-11-28 02:54:31,922 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46574563736265356, 'Total loss': 0.46574563736265356} | train loss {'Reaction outcome loss': 0.3170057012725938, 'Total loss': 0.3170057012725938}
2022-11-28 02:54:31,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:31,923 INFO:     Epoch: 51
2022-11-28 02:54:32,668 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4486310465092009, 'Total loss': 0.4486310465092009} | train loss {'Reaction outcome loss': 0.3292426860887512, 'Total loss': 0.3292426860887512}
2022-11-28 02:54:32,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:32,668 INFO:     Epoch: 52
2022-11-28 02:54:33,411 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4437688345258886, 'Total loss': 0.4437688345258886} | train loss {'Reaction outcome loss': 0.32008687604354463, 'Total loss': 0.32008687604354463}
2022-11-28 02:54:33,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:33,411 INFO:     Epoch: 53
2022-11-28 02:54:34,158 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46433746408332477, 'Total loss': 0.46433746408332477} | train loss {'Reaction outcome loss': 0.31141082514152835, 'Total loss': 0.31141082514152835}
2022-11-28 02:54:34,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:34,159 INFO:     Epoch: 54
2022-11-28 02:54:34,903 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.488007958301089, 'Total loss': 0.488007958301089} | train loss {'Reaction outcome loss': 0.31802622328403024, 'Total loss': 0.31802622328403024}
2022-11-28 02:54:34,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:34,903 INFO:     Epoch: 55
2022-11-28 02:54:35,649 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4666556272317063, 'Total loss': 0.4666556272317063} | train loss {'Reaction outcome loss': 0.3333185969998962, 'Total loss': 0.3333185969998962}
2022-11-28 02:54:35,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:35,649 INFO:     Epoch: 56
2022-11-28 02:54:36,396 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48896007375283673, 'Total loss': 0.48896007375283673} | train loss {'Reaction outcome loss': 0.32437307101029617, 'Total loss': 0.32437307101029617}
2022-11-28 02:54:36,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:36,396 INFO:     Epoch: 57
2022-11-28 02:54:37,140 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4377797913144935, 'Total loss': 0.4377797913144935} | train loss {'Reaction outcome loss': 0.3166815121299945, 'Total loss': 0.3166815121299945}
2022-11-28 02:54:37,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:37,140 INFO:     Epoch: 58
2022-11-28 02:54:37,886 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4450450988317078, 'Total loss': 0.4450450988317078} | train loss {'Reaction outcome loss': 0.32415485876774497, 'Total loss': 0.32415485876774497}
2022-11-28 02:54:37,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:37,886 INFO:     Epoch: 59
2022-11-28 02:54:38,628 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45094287260012195, 'Total loss': 0.45094287260012195} | train loss {'Reaction outcome loss': 0.3141420388390189, 'Total loss': 0.3141420388390189}
2022-11-28 02:54:38,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:38,629 INFO:     Epoch: 60
2022-11-28 02:54:39,372 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45377555692737753, 'Total loss': 0.45377555692737753} | train loss {'Reaction outcome loss': 0.31348310875506535, 'Total loss': 0.31348310875506535}
2022-11-28 02:54:39,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:39,372 INFO:     Epoch: 61
2022-11-28 02:54:40,115 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4193814220753583, 'Total loss': 0.4193814220753583} | train loss {'Reaction outcome loss': 0.3328353926553089, 'Total loss': 0.3328353926553089}
2022-11-28 02:54:40,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:40,115 INFO:     Epoch: 62
2022-11-28 02:54:40,859 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45805132016539574, 'Total loss': 0.45805132016539574} | train loss {'Reaction outcome loss': 0.3191160345789392, 'Total loss': 0.3191160345789392}
2022-11-28 02:54:40,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:40,859 INFO:     Epoch: 63
2022-11-28 02:54:41,603 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45661388693208044, 'Total loss': 0.45661388693208044} | train loss {'Reaction outcome loss': 0.31376747825552487, 'Total loss': 0.31376747825552487}
2022-11-28 02:54:41,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:41,603 INFO:     Epoch: 64
2022-11-28 02:54:42,350 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4612206860699437, 'Total loss': 0.4612206860699437} | train loss {'Reaction outcome loss': 0.3179630692972828, 'Total loss': 0.3179630692972828}
2022-11-28 02:54:42,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:42,350 INFO:     Epoch: 65
2022-11-28 02:54:43,099 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44557341797785327, 'Total loss': 0.44557341797785327} | train loss {'Reaction outcome loss': 0.30744496316682957, 'Total loss': 0.30744496316682957}
2022-11-28 02:54:43,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:43,099 INFO:     Epoch: 66
2022-11-28 02:54:43,846 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46596675061366777, 'Total loss': 0.46596675061366777} | train loss {'Reaction outcome loss': 0.32569238338393236, 'Total loss': 0.32569238338393236}
2022-11-28 02:54:43,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:43,846 INFO:     Epoch: 67
2022-11-28 02:54:44,591 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4338951876217669, 'Total loss': 0.4338951876217669} | train loss {'Reaction outcome loss': 0.322485615276856, 'Total loss': 0.322485615276856}
2022-11-28 02:54:44,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:44,591 INFO:     Epoch: 68
2022-11-28 02:54:45,338 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46386943029409106, 'Total loss': 0.46386943029409106} | train loss {'Reaction outcome loss': 0.3169904148059064, 'Total loss': 0.3169904148059064}
2022-11-28 02:54:45,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:45,338 INFO:     Epoch: 69
2022-11-28 02:54:46,088 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43641786311160435, 'Total loss': 0.43641786311160435} | train loss {'Reaction outcome loss': 0.3137534445053653, 'Total loss': 0.3137534445053653}
2022-11-28 02:54:46,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:46,089 INFO:     Epoch: 70
2022-11-28 02:54:46,836 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4353308118879795, 'Total loss': 0.4353308118879795} | train loss {'Reaction outcome loss': 0.3197928883044826, 'Total loss': 0.3197928883044826}
2022-11-28 02:54:46,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:46,836 INFO:     Epoch: 71
2022-11-28 02:54:47,583 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44835786013440654, 'Total loss': 0.44835786013440654} | train loss {'Reaction outcome loss': 0.32033362149188827, 'Total loss': 0.32033362149188827}
2022-11-28 02:54:47,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:47,583 INFO:     Epoch: 72
2022-11-28 02:54:48,330 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45077572898431256, 'Total loss': 0.45077572898431256} | train loss {'Reaction outcome loss': 0.30422367493392, 'Total loss': 0.30422367493392}
2022-11-28 02:54:48,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:48,330 INFO:     Epoch: 73
2022-11-28 02:54:49,071 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4953277087347074, 'Total loss': 0.4953277087347074} | train loss {'Reaction outcome loss': 0.3213028683655175, 'Total loss': 0.3213028683655175}
2022-11-28 02:54:49,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:49,071 INFO:     Epoch: 74
2022-11-28 02:54:49,810 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4552458675408905, 'Total loss': 0.4552458675408905} | train loss {'Reaction outcome loss': 0.3032068311414014, 'Total loss': 0.3032068311414014}
2022-11-28 02:54:49,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:49,810 INFO:     Epoch: 75
2022-11-28 02:54:50,555 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41895999217575247, 'Total loss': 0.41895999217575247} | train loss {'Reaction outcome loss': 0.307202102684299, 'Total loss': 0.307202102684299}
2022-11-28 02:54:50,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:50,555 INFO:     Epoch: 76
2022-11-28 02:54:51,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45053608935665, 'Total loss': 0.45053608935665} | train loss {'Reaction outcome loss': 0.33960185043875746, 'Total loss': 0.33960185043875746}
2022-11-28 02:54:51,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:51,299 INFO:     Epoch: 77
2022-11-28 02:54:52,046 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4389921602877704, 'Total loss': 0.4389921602877704} | train loss {'Reaction outcome loss': 0.31121248027935683, 'Total loss': 0.31121248027935683}
2022-11-28 02:54:52,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:52,046 INFO:     Epoch: 78
2022-11-28 02:54:52,793 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4685770012438297, 'Total loss': 0.4685770012438297} | train loss {'Reaction outcome loss': 0.30471380014526434, 'Total loss': 0.30471380014526434}
2022-11-28 02:54:52,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:52,794 INFO:     Epoch: 79
2022-11-28 02:54:53,542 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45248811454935506, 'Total loss': 0.45248811454935506} | train loss {'Reaction outcome loss': 0.3060565082487596, 'Total loss': 0.3060565082487596}
2022-11-28 02:54:53,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:53,543 INFO:     Epoch: 80
2022-11-28 02:54:54,287 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4299999942833727, 'Total loss': 0.4299999942833727} | train loss {'Reaction outcome loss': 0.3037991579395798, 'Total loss': 0.3037991579395798}
2022-11-28 02:54:54,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:54,288 INFO:     Epoch: 81
2022-11-28 02:54:55,031 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44020386243408377, 'Total loss': 0.44020386243408377} | train loss {'Reaction outcome loss': 0.3123173009951105, 'Total loss': 0.3123173009951105}
2022-11-28 02:54:55,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:55,031 INFO:     Epoch: 82
2022-11-28 02:54:55,775 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44671880589290097, 'Total loss': 0.44671880589290097} | train loss {'Reaction outcome loss': 0.30940451370439065, 'Total loss': 0.30940451370439065}
2022-11-28 02:54:55,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:55,775 INFO:     Epoch: 83
2022-11-28 02:54:56,523 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4557339511811733, 'Total loss': 0.4557339511811733} | train loss {'Reaction outcome loss': 0.30984694849598876, 'Total loss': 0.30984694849598876}
2022-11-28 02:54:56,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:56,524 INFO:     Epoch: 84
2022-11-28 02:54:57,265 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47973985360427335, 'Total loss': 0.47973985360427335} | train loss {'Reaction outcome loss': 0.31129985679740363, 'Total loss': 0.31129985679740363}
2022-11-28 02:54:57,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:57,266 INFO:     Epoch: 85
2022-11-28 02:54:58,012 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4497695450078357, 'Total loss': 0.4497695450078357} | train loss {'Reaction outcome loss': 0.3107754146672695, 'Total loss': 0.3107754146672695}
2022-11-28 02:54:58,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:58,012 INFO:     Epoch: 86
2022-11-28 02:54:58,756 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4375877983190797, 'Total loss': 0.4375877983190797} | train loss {'Reaction outcome loss': 0.30910845358784383, 'Total loss': 0.30910845358784383}
2022-11-28 02:54:58,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:58,757 INFO:     Epoch: 87
2022-11-28 02:54:59,501 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45380300080234354, 'Total loss': 0.45380300080234354} | train loss {'Reaction outcome loss': 0.30650861553757297, 'Total loss': 0.30650861553757297}
2022-11-28 02:54:59,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:54:59,501 INFO:     Epoch: 88
2022-11-28 02:55:00,246 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4426500406116247, 'Total loss': 0.4426500406116247} | train loss {'Reaction outcome loss': 0.30258138666329115, 'Total loss': 0.30258138666329115}
2022-11-28 02:55:00,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:00,247 INFO:     Epoch: 89
2022-11-28 02:55:00,991 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4378561076115478, 'Total loss': 0.4378561076115478} | train loss {'Reaction outcome loss': 0.3034221356591353, 'Total loss': 0.3034221356591353}
2022-11-28 02:55:00,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:00,991 INFO:     Epoch: 90
2022-11-28 02:55:01,735 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4373925870115107, 'Total loss': 0.4373925870115107} | train loss {'Reaction outcome loss': 0.3022100076546915, 'Total loss': 0.3022100076546915}
2022-11-28 02:55:01,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:01,735 INFO:     Epoch: 91
2022-11-28 02:55:02,481 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44756008650768886, 'Total loss': 0.44756008650768886} | train loss {'Reaction outcome loss': 0.3024774687251581, 'Total loss': 0.3024774687251581}
2022-11-28 02:55:02,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:02,481 INFO:     Epoch: 92
2022-11-28 02:55:03,224 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4619799132712863, 'Total loss': 0.4619799132712863} | train loss {'Reaction outcome loss': 0.304527271757664, 'Total loss': 0.304527271757664}
2022-11-28 02:55:03,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:03,224 INFO:     Epoch: 93
2022-11-28 02:55:03,970 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42921657487750053, 'Total loss': 0.42921657487750053} | train loss {'Reaction outcome loss': 0.3048289392081274, 'Total loss': 0.3048289392081274}
2022-11-28 02:55:03,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:03,971 INFO:     Epoch: 94
2022-11-28 02:55:04,716 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47222910669039597, 'Total loss': 0.47222910669039597} | train loss {'Reaction outcome loss': 0.2953616122334351, 'Total loss': 0.2953616122334351}
2022-11-28 02:55:04,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:04,716 INFO:     Epoch: 95
2022-11-28 02:55:05,461 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43674948709932243, 'Total loss': 0.43674948709932243} | train loss {'Reaction outcome loss': 0.3002415737099493, 'Total loss': 0.3002415737099493}
2022-11-28 02:55:05,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:05,462 INFO:     Epoch: 96
2022-11-28 02:55:06,212 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4259722249751741, 'Total loss': 0.4259722249751741} | train loss {'Reaction outcome loss': 0.3070611310934248, 'Total loss': 0.3070611310934248}
2022-11-28 02:55:06,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:06,212 INFO:     Epoch: 97
2022-11-28 02:55:06,961 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45180907947095955, 'Total loss': 0.45180907947095955} | train loss {'Reaction outcome loss': 0.31385938566826616, 'Total loss': 0.31385938566826616}
2022-11-28 02:55:06,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:06,962 INFO:     Epoch: 98
2022-11-28 02:55:07,706 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4350829381834377, 'Total loss': 0.4350829381834377} | train loss {'Reaction outcome loss': 0.3025375517002243, 'Total loss': 0.3025375517002243}
2022-11-28 02:55:07,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:07,706 INFO:     Epoch: 99
2022-11-28 02:55:08,453 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46541148254817183, 'Total loss': 0.46541148254817183} | train loss {'Reaction outcome loss': 0.30390085837980996, 'Total loss': 0.30390085837980996}
2022-11-28 02:55:08,453 INFO:     Best model found after epoch 31 of 100.
2022-11-28 02:55:08,454 INFO:   Done with stage: TRAINING
2022-11-28 02:55:08,454 INFO:   Starting stage: EVALUATION
2022-11-28 02:55:08,574 INFO:   Done with stage: EVALUATION
2022-11-28 02:55:08,575 INFO:   Leaving out SEQ value Fold_8
2022-11-28 02:55:08,588 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:55:08,588 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:55:09,227 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:55:09,228 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:55:09,296 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:55:09,296 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:55:09,296 INFO:     No hyperparam tuning for this model
2022-11-28 02:55:09,296 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:55:09,296 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:55:09,297 INFO:     None feature selector for col prot
2022-11-28 02:55:09,297 INFO:     None feature selector for col prot
2022-11-28 02:55:09,297 INFO:     None feature selector for col prot
2022-11-28 02:55:09,298 INFO:     None feature selector for col chem
2022-11-28 02:55:09,298 INFO:     None feature selector for col chem
2022-11-28 02:55:09,298 INFO:     None feature selector for col chem
2022-11-28 02:55:09,298 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:55:09,298 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:55:09,299 INFO:     Number of params in model 169741
2022-11-28 02:55:09,302 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:55:09,303 INFO:   Starting stage: TRAINING
2022-11-28 02:55:09,356 INFO:     Val loss before train {'Reaction outcome loss': 1.0000813102180308, 'Total loss': 1.0000813102180308}
2022-11-28 02:55:09,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:09,356 INFO:     Epoch: 0
2022-11-28 02:55:10,103 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5829899209466848, 'Total loss': 0.5829899209466848} | train loss {'Reaction outcome loss': 0.6252959731725916, 'Total loss': 0.6252959731725916}
2022-11-28 02:55:10,103 INFO:     Found new best model at epoch 0
2022-11-28 02:55:10,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:10,104 INFO:     Epoch: 1
2022-11-28 02:55:10,854 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5486453839323737, 'Total loss': 0.5486453839323737} | train loss {'Reaction outcome loss': 0.48455252113842195, 'Total loss': 0.48455252113842195}
2022-11-28 02:55:10,854 INFO:     Found new best model at epoch 1
2022-11-28 02:55:10,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:10,855 INFO:     Epoch: 2
2022-11-28 02:55:11,604 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.494741733439944, 'Total loss': 0.494741733439944} | train loss {'Reaction outcome loss': 0.45793259264, 'Total loss': 0.45793259264}
2022-11-28 02:55:11,604 INFO:     Found new best model at epoch 2
2022-11-28 02:55:11,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:11,605 INFO:     Epoch: 3
2022-11-28 02:55:12,352 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49324346028945665, 'Total loss': 0.49324346028945665} | train loss {'Reaction outcome loss': 0.42900702780893735, 'Total loss': 0.42900702780893735}
2022-11-28 02:55:12,352 INFO:     Found new best model at epoch 3
2022-11-28 02:55:12,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:12,353 INFO:     Epoch: 4
2022-11-28 02:55:13,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48853700709613884, 'Total loss': 0.48853700709613884} | train loss {'Reaction outcome loss': 0.4128292565864901, 'Total loss': 0.4128292565864901}
2022-11-28 02:55:13,101 INFO:     Found new best model at epoch 4
2022-11-28 02:55:13,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:13,101 INFO:     Epoch: 5
2022-11-28 02:55:13,848 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46781755408102815, 'Total loss': 0.46781755408102815} | train loss {'Reaction outcome loss': 0.40320248463221137, 'Total loss': 0.40320248463221137}
2022-11-28 02:55:13,848 INFO:     Found new best model at epoch 5
2022-11-28 02:55:13,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:13,849 INFO:     Epoch: 6
2022-11-28 02:55:14,598 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46461203965273773, 'Total loss': 0.46461203965273773} | train loss {'Reaction outcome loss': 0.3996909548858962, 'Total loss': 0.3996909548858962}
2022-11-28 02:55:14,598 INFO:     Found new best model at epoch 6
2022-11-28 02:55:14,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:14,599 INFO:     Epoch: 7
2022-11-28 02:55:15,354 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47189207205718214, 'Total loss': 0.47189207205718214} | train loss {'Reaction outcome loss': 0.38774559400495023, 'Total loss': 0.38774559400495023}
2022-11-28 02:55:15,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:15,354 INFO:     Epoch: 8
2022-11-28 02:55:16,101 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47339995442466304, 'Total loss': 0.47339995442466304} | train loss {'Reaction outcome loss': 0.39240616382730586, 'Total loss': 0.39240616382730586}
2022-11-28 02:55:16,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:16,101 INFO:     Epoch: 9
2022-11-28 02:55:16,852 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47914962233467534, 'Total loss': 0.47914962233467534} | train loss {'Reaction outcome loss': 0.3719933632490856, 'Total loss': 0.3719933632490856}
2022-11-28 02:55:16,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:16,852 INFO:     Epoch: 10
2022-11-28 02:55:17,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4693440920249982, 'Total loss': 0.4693440920249982} | train loss {'Reaction outcome loss': 0.3704610809143032, 'Total loss': 0.3704610809143032}
2022-11-28 02:55:17,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:17,604 INFO:     Epoch: 11
2022-11-28 02:55:18,353 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44184923273595894, 'Total loss': 0.44184923273595894} | train loss {'Reaction outcome loss': 0.36448930011641595, 'Total loss': 0.36448930011641595}
2022-11-28 02:55:18,353 INFO:     Found new best model at epoch 11
2022-11-28 02:55:18,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:18,354 INFO:     Epoch: 12
2022-11-28 02:55:19,104 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46210239455103874, 'Total loss': 0.46210239455103874} | train loss {'Reaction outcome loss': 0.3591120966199425, 'Total loss': 0.3591120966199425}
2022-11-28 02:55:19,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:19,104 INFO:     Epoch: 13
2022-11-28 02:55:19,854 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48263965343887155, 'Total loss': 0.48263965343887155} | train loss {'Reaction outcome loss': 0.3619902990908632, 'Total loss': 0.3619902990908632}
2022-11-28 02:55:19,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:19,854 INFO:     Epoch: 14
2022-11-28 02:55:20,604 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.513186857781627, 'Total loss': 0.513186857781627} | train loss {'Reaction outcome loss': 0.36020153736875904, 'Total loss': 0.36020153736875904}
2022-11-28 02:55:20,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:20,604 INFO:     Epoch: 15
2022-11-28 02:55:21,353 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42552805895155127, 'Total loss': 0.42552805895155127} | train loss {'Reaction outcome loss': 0.36001870324534757, 'Total loss': 0.36001870324534757}
2022-11-28 02:55:21,353 INFO:     Found new best model at epoch 15
2022-11-28 02:55:21,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:21,354 INFO:     Epoch: 16
2022-11-28 02:55:22,097 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4438464912501248, 'Total loss': 0.4438464912501248} | train loss {'Reaction outcome loss': 0.34825643338263035, 'Total loss': 0.34825643338263035}
2022-11-28 02:55:22,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:22,098 INFO:     Epoch: 17
2022-11-28 02:55:22,848 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4690230410884727, 'Total loss': 0.4690230410884727} | train loss {'Reaction outcome loss': 0.3510684918071474, 'Total loss': 0.3510684918071474}
2022-11-28 02:55:22,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:22,848 INFO:     Epoch: 18
2022-11-28 02:55:23,601 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5152744969183748, 'Total loss': 0.5152744969183748} | train loss {'Reaction outcome loss': 0.34694417139455197, 'Total loss': 0.34694417139455197}
2022-11-28 02:55:23,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:23,601 INFO:     Epoch: 19
2022-11-28 02:55:24,353 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44534356384114787, 'Total loss': 0.44534356384114787} | train loss {'Reaction outcome loss': 0.34462127978763274, 'Total loss': 0.34462127978763274}
2022-11-28 02:55:24,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:24,354 INFO:     Epoch: 20
2022-11-28 02:55:25,106 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4590343321588906, 'Total loss': 0.4590343321588906} | train loss {'Reaction outcome loss': 0.3418780060244664, 'Total loss': 0.3418780060244664}
2022-11-28 02:55:25,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:25,107 INFO:     Epoch: 21
2022-11-28 02:55:25,860 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4565037973225117, 'Total loss': 0.4565037973225117} | train loss {'Reaction outcome loss': 0.3353854053082966, 'Total loss': 0.3353854053082966}
2022-11-28 02:55:25,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:25,860 INFO:     Epoch: 22
2022-11-28 02:55:26,616 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4537582343274897, 'Total loss': 0.4537582343274897} | train loss {'Reaction outcome loss': 0.34303035992648334, 'Total loss': 0.34303035992648334}
2022-11-28 02:55:26,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:26,617 INFO:     Epoch: 23
2022-11-28 02:55:27,371 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4341192672198469, 'Total loss': 0.4341192672198469} | train loss {'Reaction outcome loss': 0.3371134097087047, 'Total loss': 0.3371134097087047}
2022-11-28 02:55:27,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:27,371 INFO:     Epoch: 24
2022-11-28 02:55:28,126 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4610639461739497, 'Total loss': 0.4610639461739497} | train loss {'Reaction outcome loss': 0.339226697181021, 'Total loss': 0.339226697181021}
2022-11-28 02:55:28,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:28,126 INFO:     Epoch: 25
2022-11-28 02:55:28,884 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43238821744241496, 'Total loss': 0.43238821744241496} | train loss {'Reaction outcome loss': 0.3360176678266256, 'Total loss': 0.3360176678266256}
2022-11-28 02:55:28,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:28,884 INFO:     Epoch: 26
2022-11-28 02:55:29,637 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43818437917666003, 'Total loss': 0.43818437917666003} | train loss {'Reaction outcome loss': 0.3352489635468491, 'Total loss': 0.3352489635468491}
2022-11-28 02:55:29,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:29,638 INFO:     Epoch: 27
2022-11-28 02:55:30,397 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4337708276103843, 'Total loss': 0.4337708276103843} | train loss {'Reaction outcome loss': 0.3358529038096388, 'Total loss': 0.3358529038096388}
2022-11-28 02:55:30,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:30,397 INFO:     Epoch: 28
2022-11-28 02:55:31,152 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45433116534894163, 'Total loss': 0.45433116534894163} | train loss {'Reaction outcome loss': 0.330382700378616, 'Total loss': 0.330382700378616}
2022-11-28 02:55:31,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:31,152 INFO:     Epoch: 29
2022-11-28 02:55:31,906 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43174839222973044, 'Total loss': 0.43174839222973044} | train loss {'Reaction outcome loss': 0.3340137723773237, 'Total loss': 0.3340137723773237}
2022-11-28 02:55:31,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:31,906 INFO:     Epoch: 30
2022-11-28 02:55:32,661 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45838451656428253, 'Total loss': 0.45838451656428253} | train loss {'Reaction outcome loss': 0.3358616363858023, 'Total loss': 0.3358616363858023}
2022-11-28 02:55:32,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:32,662 INFO:     Epoch: 31
2022-11-28 02:55:33,415 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47048637677322735, 'Total loss': 0.47048637677322735} | train loss {'Reaction outcome loss': 0.32344371965155005, 'Total loss': 0.32344371965155005}
2022-11-28 02:55:33,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:33,415 INFO:     Epoch: 32
2022-11-28 02:55:34,170 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4623433104292913, 'Total loss': 0.4623433104292913} | train loss {'Reaction outcome loss': 0.33217933049966253, 'Total loss': 0.33217933049966253}
2022-11-28 02:55:34,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:34,171 INFO:     Epoch: 33
2022-11-28 02:55:34,927 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44976994869383896, 'Total loss': 0.44976994869383896} | train loss {'Reaction outcome loss': 0.32186125519294895, 'Total loss': 0.32186125519294895}
2022-11-28 02:55:34,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:34,928 INFO:     Epoch: 34
2022-11-28 02:55:35,683 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4317467405714772, 'Total loss': 0.4317467405714772} | train loss {'Reaction outcome loss': 0.33544163775419994, 'Total loss': 0.33544163775419994}
2022-11-28 02:55:35,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:35,684 INFO:     Epoch: 35
2022-11-28 02:55:36,440 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.447618942707777, 'Total loss': 0.447618942707777} | train loss {'Reaction outcome loss': 0.3220852770572228, 'Total loss': 0.3220852770572228}
2022-11-28 02:55:36,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:36,440 INFO:     Epoch: 36
2022-11-28 02:55:37,197 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47504970769990573, 'Total loss': 0.47504970769990573} | train loss {'Reaction outcome loss': 0.3256606617041172, 'Total loss': 0.3256606617041172}
2022-11-28 02:55:37,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:37,197 INFO:     Epoch: 37
2022-11-28 02:55:37,954 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4447709667411717, 'Total loss': 0.4447709667411717} | train loss {'Reaction outcome loss': 0.33033047056186104, 'Total loss': 0.33033047056186104}
2022-11-28 02:55:37,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:37,954 INFO:     Epoch: 38
2022-11-28 02:55:38,712 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4579796228896488, 'Total loss': 0.4579796228896488} | train loss {'Reaction outcome loss': 0.32041498130908413, 'Total loss': 0.32041498130908413}
2022-11-28 02:55:38,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:38,712 INFO:     Epoch: 39
2022-11-28 02:55:39,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43763988702134654, 'Total loss': 0.43763988702134654} | train loss {'Reaction outcome loss': 0.31923962859136445, 'Total loss': 0.31923962859136445}
2022-11-28 02:55:39,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:39,466 INFO:     Epoch: 40
2022-11-28 02:55:40,222 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44760088554837485, 'Total loss': 0.44760088554837485} | train loss {'Reaction outcome loss': 0.32182451834781994, 'Total loss': 0.32182451834781994}
2022-11-28 02:55:40,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:40,222 INFO:     Epoch: 41
2022-11-28 02:55:40,978 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43001494014805014, 'Total loss': 0.43001494014805014} | train loss {'Reaction outcome loss': 0.3181615651194607, 'Total loss': 0.3181615651194607}
2022-11-28 02:55:40,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:40,978 INFO:     Epoch: 42
2022-11-28 02:55:41,739 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4263797553086823, 'Total loss': 0.4263797553086823} | train loss {'Reaction outcome loss': 0.31806044092762376, 'Total loss': 0.31806044092762376}
2022-11-28 02:55:41,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:41,739 INFO:     Epoch: 43
2022-11-28 02:55:42,495 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42548552189360966, 'Total loss': 0.42548552189360966} | train loss {'Reaction outcome loss': 0.31502135057422903, 'Total loss': 0.31502135057422903}
2022-11-28 02:55:42,495 INFO:     Found new best model at epoch 43
2022-11-28 02:55:42,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:42,496 INFO:     Epoch: 44
2022-11-28 02:55:43,250 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4574748914350163, 'Total loss': 0.4574748914350163} | train loss {'Reaction outcome loss': 0.31735935444462926, 'Total loss': 0.31735935444462926}
2022-11-28 02:55:43,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:43,250 INFO:     Epoch: 45
2022-11-28 02:55:44,011 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3896221044388684, 'Total loss': 0.3896221044388684} | train loss {'Reaction outcome loss': 0.31280045959377484, 'Total loss': 0.31280045959377484}
2022-11-28 02:55:44,011 INFO:     Found new best model at epoch 45
2022-11-28 02:55:44,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:44,012 INFO:     Epoch: 46
2022-11-28 02:55:44,773 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45709132233803923, 'Total loss': 0.45709132233803923} | train loss {'Reaction outcome loss': 0.31379976637300944, 'Total loss': 0.31379976637300944}
2022-11-28 02:55:44,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:44,774 INFO:     Epoch: 47
2022-11-28 02:55:45,529 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43131436373699794, 'Total loss': 0.43131436373699794} | train loss {'Reaction outcome loss': 0.3197017800844004, 'Total loss': 0.3197017800844004}
2022-11-28 02:55:45,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:45,529 INFO:     Epoch: 48
2022-11-28 02:55:46,286 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4277992756529288, 'Total loss': 0.4277992756529288} | train loss {'Reaction outcome loss': 0.3104177132369049, 'Total loss': 0.3104177132369049}
2022-11-28 02:55:46,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:46,286 INFO:     Epoch: 49
2022-11-28 02:55:47,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44963971627029503, 'Total loss': 0.44963971627029503} | train loss {'Reaction outcome loss': 0.3095626105974999, 'Total loss': 0.3095626105974999}
2022-11-28 02:55:47,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:47,039 INFO:     Epoch: 50
2022-11-28 02:55:47,791 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.447693235156211, 'Total loss': 0.447693235156211} | train loss {'Reaction outcome loss': 0.31727980828333285, 'Total loss': 0.31727980828333285}
2022-11-28 02:55:47,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:47,792 INFO:     Epoch: 51
2022-11-28 02:55:48,545 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4321171709082343, 'Total loss': 0.4321171709082343} | train loss {'Reaction outcome loss': 0.30576125823802525, 'Total loss': 0.30576125823802525}
2022-11-28 02:55:48,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:48,545 INFO:     Epoch: 52
2022-11-28 02:55:49,304 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42670453983274376, 'Total loss': 0.42670453983274376} | train loss {'Reaction outcome loss': 0.31097810042481266, 'Total loss': 0.31097810042481266}
2022-11-28 02:55:49,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:49,304 INFO:     Epoch: 53
2022-11-28 02:55:50,060 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47397908161986957, 'Total loss': 0.47397908161986957} | train loss {'Reaction outcome loss': 0.3173474334180355, 'Total loss': 0.3173474334180355}
2022-11-28 02:55:50,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:50,061 INFO:     Epoch: 54
2022-11-28 02:55:50,814 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45583623224361375, 'Total loss': 0.45583623224361375} | train loss {'Reaction outcome loss': 0.30315280008700585, 'Total loss': 0.30315280008700585}
2022-11-28 02:55:50,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:50,814 INFO:     Epoch: 55
2022-11-28 02:55:51,568 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41619572043418884, 'Total loss': 0.41619572043418884} | train loss {'Reaction outcome loss': 0.312771953311899, 'Total loss': 0.312771953311899}
2022-11-28 02:55:51,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:51,569 INFO:     Epoch: 56
2022-11-28 02:55:52,321 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4561804184182124, 'Total loss': 0.4561804184182124} | train loss {'Reaction outcome loss': 0.31237831297180346, 'Total loss': 0.31237831297180346}
2022-11-28 02:55:52,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:52,321 INFO:     Epoch: 57
2022-11-28 02:55:53,078 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44329004125161603, 'Total loss': 0.44329004125161603} | train loss {'Reaction outcome loss': 0.3115350100842695, 'Total loss': 0.3115350100842695}
2022-11-28 02:55:53,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:53,078 INFO:     Epoch: 58
2022-11-28 02:55:53,837 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42909878526221623, 'Total loss': 0.42909878526221623} | train loss {'Reaction outcome loss': 0.30138425676212194, 'Total loss': 0.30138425676212194}
2022-11-28 02:55:53,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:53,837 INFO:     Epoch: 59
2022-11-28 02:55:54,592 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4430896152149547, 'Total loss': 0.4430896152149547} | train loss {'Reaction outcome loss': 0.3187389743604487, 'Total loss': 0.3187389743604487}
2022-11-28 02:55:54,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:54,592 INFO:     Epoch: 60
2022-11-28 02:55:55,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4413398914039135, 'Total loss': 0.4413398914039135} | train loss {'Reaction outcome loss': 0.3045299971596368, 'Total loss': 0.3045299971596368}
2022-11-28 02:55:55,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:55,345 INFO:     Epoch: 61
2022-11-28 02:55:56,100 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4091618592766198, 'Total loss': 0.4091618592766198} | train loss {'Reaction outcome loss': 0.31939392586448984, 'Total loss': 0.31939392586448984}
2022-11-28 02:55:56,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:56,100 INFO:     Epoch: 62
2022-11-28 02:55:56,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4437002773312005, 'Total loss': 0.4437002773312005} | train loss {'Reaction outcome loss': 0.30492430195332537, 'Total loss': 0.30492430195332537}
2022-11-28 02:55:56,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:56,856 INFO:     Epoch: 63
2022-11-28 02:55:57,613 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43868079578334634, 'Total loss': 0.43868079578334634} | train loss {'Reaction outcome loss': 0.3084161562484599, 'Total loss': 0.3084161562484599}
2022-11-28 02:55:57,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:57,614 INFO:     Epoch: 64
2022-11-28 02:55:58,383 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43492255529219453, 'Total loss': 0.43492255529219453} | train loss {'Reaction outcome loss': 0.30260607371887854, 'Total loss': 0.30260607371887854}
2022-11-28 02:55:58,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:58,383 INFO:     Epoch: 65
2022-11-28 02:55:59,155 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42490932176058943, 'Total loss': 0.42490932176058943} | train loss {'Reaction outcome loss': 0.30801032501603326, 'Total loss': 0.30801032501603326}
2022-11-28 02:55:59,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:59,156 INFO:     Epoch: 66
2022-11-28 02:55:59,927 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4340196864848787, 'Total loss': 0.4340196864848787} | train loss {'Reaction outcome loss': 0.30733103371195253, 'Total loss': 0.30733103371195253}
2022-11-28 02:55:59,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:55:59,928 INFO:     Epoch: 67
2022-11-28 02:56:00,699 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.461786901070313, 'Total loss': 0.461786901070313} | train loss {'Reaction outcome loss': 0.30959848605937534, 'Total loss': 0.30959848605937534}
2022-11-28 02:56:00,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:00,700 INFO:     Epoch: 68
2022-11-28 02:56:01,471 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42614613845944405, 'Total loss': 0.42614613845944405} | train loss {'Reaction outcome loss': 0.3128593930854432, 'Total loss': 0.3128593930854432}
2022-11-28 02:56:01,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:01,471 INFO:     Epoch: 69
2022-11-28 02:56:02,242 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43982517008077016, 'Total loss': 0.43982517008077016} | train loss {'Reaction outcome loss': 0.29753776020821066, 'Total loss': 0.29753776020821066}
2022-11-28 02:56:02,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:02,242 INFO:     Epoch: 70
2022-11-28 02:56:03,012 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42870430140332744, 'Total loss': 0.42870430140332744} | train loss {'Reaction outcome loss': 0.3036078277434553, 'Total loss': 0.3036078277434553}
2022-11-28 02:56:03,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:03,012 INFO:     Epoch: 71
2022-11-28 02:56:03,781 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43512061712416733, 'Total loss': 0.43512061712416733} | train loss {'Reaction outcome loss': 0.31070187123071763, 'Total loss': 0.31070187123071763}
2022-11-28 02:56:03,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:03,781 INFO:     Epoch: 72
2022-11-28 02:56:04,545 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4585600368339907, 'Total loss': 0.4585600368339907} | train loss {'Reaction outcome loss': 0.2998122093267739, 'Total loss': 0.2998122093267739}
2022-11-28 02:56:04,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:04,545 INFO:     Epoch: 73
2022-11-28 02:56:05,297 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4297830618240617, 'Total loss': 0.4297830618240617} | train loss {'Reaction outcome loss': 0.3105019802347787, 'Total loss': 0.3105019802347787}
2022-11-28 02:56:05,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:05,298 INFO:     Epoch: 74
2022-11-28 02:56:06,047 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4193210100585764, 'Total loss': 0.4193210100585764} | train loss {'Reaction outcome loss': 0.3049697498941133, 'Total loss': 0.3049697498941133}
2022-11-28 02:56:06,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:06,047 INFO:     Epoch: 75
2022-11-28 02:56:06,796 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43883021057329397, 'Total loss': 0.43883021057329397} | train loss {'Reaction outcome loss': 0.2974563176413217, 'Total loss': 0.2974563176413217}
2022-11-28 02:56:06,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:06,796 INFO:     Epoch: 76
2022-11-28 02:56:07,548 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44023566591468727, 'Total loss': 0.44023566591468727} | train loss {'Reaction outcome loss': 0.30600372107038576, 'Total loss': 0.30600372107038576}
2022-11-28 02:56:07,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:07,549 INFO:     Epoch: 77
2022-11-28 02:56:08,299 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45242492973127146, 'Total loss': 0.45242492973127146} | train loss {'Reaction outcome loss': 0.30444656721045893, 'Total loss': 0.30444656721045893}
2022-11-28 02:56:08,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:08,299 INFO:     Epoch: 78
2022-11-28 02:56:09,051 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4255490716208111, 'Total loss': 0.4255490716208111} | train loss {'Reaction outcome loss': 0.30950170708820224, 'Total loss': 0.30950170708820224}
2022-11-28 02:56:09,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:09,051 INFO:     Epoch: 79
2022-11-28 02:56:09,802 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43532929163087497, 'Total loss': 0.43532929163087497} | train loss {'Reaction outcome loss': 0.2963833764135357, 'Total loss': 0.2963833764135357}
2022-11-28 02:56:09,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:09,802 INFO:     Epoch: 80
2022-11-28 02:56:10,553 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45408719134601677, 'Total loss': 0.45408719134601677} | train loss {'Reaction outcome loss': 0.3022363973901637, 'Total loss': 0.3022363973901637}
2022-11-28 02:56:10,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:10,553 INFO:     Epoch: 81
2022-11-28 02:56:11,299 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4402290311726657, 'Total loss': 0.4402290311726657} | train loss {'Reaction outcome loss': 0.3145196744871716, 'Total loss': 0.3145196744871716}
2022-11-28 02:56:11,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:11,300 INFO:     Epoch: 82
2022-11-28 02:56:12,048 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43687814101576805, 'Total loss': 0.43687814101576805} | train loss {'Reaction outcome loss': 0.31243996783309885, 'Total loss': 0.31243996783309885}
2022-11-28 02:56:12,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:12,049 INFO:     Epoch: 83
2022-11-28 02:56:12,806 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44120649180629035, 'Total loss': 0.44120649180629035} | train loss {'Reaction outcome loss': 0.311234196482767, 'Total loss': 0.311234196482767}
2022-11-28 02:56:12,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:12,806 INFO:     Epoch: 84
2022-11-28 02:56:13,559 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4410949789664962, 'Total loss': 0.4410949789664962} | train loss {'Reaction outcome loss': 0.30269475149050834, 'Total loss': 0.30269475149050834}
2022-11-28 02:56:13,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:13,559 INFO:     Epoch: 85
2022-11-28 02:56:14,309 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43585145236416295, 'Total loss': 0.43585145236416295} | train loss {'Reaction outcome loss': 0.29765838898357844, 'Total loss': 0.29765838898357844}
2022-11-28 02:56:14,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:14,309 INFO:     Epoch: 86
2022-11-28 02:56:15,060 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4173851983452385, 'Total loss': 0.4173851983452385} | train loss {'Reaction outcome loss': 0.30275776210210975, 'Total loss': 0.30275776210210975}
2022-11-28 02:56:15,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:15,060 INFO:     Epoch: 87
2022-11-28 02:56:15,813 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42082731527361, 'Total loss': 0.42082731527361} | train loss {'Reaction outcome loss': 0.2972729297715329, 'Total loss': 0.2972729297715329}
2022-11-28 02:56:15,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:15,814 INFO:     Epoch: 88
2022-11-28 02:56:16,566 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48366400734944776, 'Total loss': 0.48366400734944776} | train loss {'Reaction outcome loss': 0.3017747247246124, 'Total loss': 0.3017747247246124}
2022-11-28 02:56:16,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:16,566 INFO:     Epoch: 89
2022-11-28 02:56:17,314 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45895365811884403, 'Total loss': 0.45895365811884403} | train loss {'Reaction outcome loss': 0.2957963249646127, 'Total loss': 0.2957963249646127}
2022-11-28 02:56:17,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:17,314 INFO:     Epoch: 90
2022-11-28 02:56:18,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4485446824268861, 'Total loss': 0.4485446824268861} | train loss {'Reaction outcome loss': 0.3121037686904592, 'Total loss': 0.3121037686904592}
2022-11-28 02:56:18,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:18,064 INFO:     Epoch: 91
2022-11-28 02:56:18,811 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44283944029699673, 'Total loss': 0.44283944029699673} | train loss {'Reaction outcome loss': 0.2997431240435089, 'Total loss': 0.2997431240435089}
2022-11-28 02:56:18,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:18,812 INFO:     Epoch: 92
2022-11-28 02:56:19,561 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41693392260508105, 'Total loss': 0.41693392260508105} | train loss {'Reaction outcome loss': 0.30398454448027956, 'Total loss': 0.30398454448027956}
2022-11-28 02:56:19,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:19,562 INFO:     Epoch: 93
2022-11-28 02:56:20,311 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43772305751388724, 'Total loss': 0.43772305751388724} | train loss {'Reaction outcome loss': 0.29574269939574505, 'Total loss': 0.29574269939574505}
2022-11-28 02:56:20,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:20,312 INFO:     Epoch: 94
2022-11-28 02:56:21,060 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48061674562367523, 'Total loss': 0.48061674562367523} | train loss {'Reaction outcome loss': 0.29733213881451276, 'Total loss': 0.29733213881451276}
2022-11-28 02:56:21,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:21,060 INFO:     Epoch: 95
2022-11-28 02:56:21,808 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4475428174165162, 'Total loss': 0.4475428174165162} | train loss {'Reaction outcome loss': 0.2988495728331468, 'Total loss': 0.2988495728331468}
2022-11-28 02:56:21,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:21,809 INFO:     Epoch: 96
2022-11-28 02:56:22,555 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4302568144418977, 'Total loss': 0.4302568144418977} | train loss {'Reaction outcome loss': 0.30769109140120204, 'Total loss': 0.30769109140120204}
2022-11-28 02:56:22,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:22,556 INFO:     Epoch: 97
2022-11-28 02:56:23,299 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.441597273403948, 'Total loss': 0.441597273403948} | train loss {'Reaction outcome loss': 0.30103553672351185, 'Total loss': 0.30103553672351185}
2022-11-28 02:56:23,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:23,300 INFO:     Epoch: 98
2022-11-28 02:56:24,048 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42833609879016876, 'Total loss': 0.42833609879016876} | train loss {'Reaction outcome loss': 0.30464806146318874, 'Total loss': 0.30464806146318874}
2022-11-28 02:56:24,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:24,048 INFO:     Epoch: 99
2022-11-28 02:56:24,799 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45000534504652023, 'Total loss': 0.45000534504652023} | train loss {'Reaction outcome loss': 0.3013162060130027, 'Total loss': 0.3013162060130027}
2022-11-28 02:56:24,799 INFO:     Best model found after epoch 46 of 100.
2022-11-28 02:56:24,799 INFO:   Done with stage: TRAINING
2022-11-28 02:56:24,799 INFO:   Starting stage: EVALUATION
2022-11-28 02:56:24,914 INFO:   Done with stage: EVALUATION
2022-11-28 02:56:24,914 INFO:   Leaving out SEQ value Fold_9
2022-11-28 02:56:24,927 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 02:56:24,927 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:56:25,567 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:56:25,567 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:56:25,636 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:56:25,637 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:56:25,637 INFO:     No hyperparam tuning for this model
2022-11-28 02:56:25,637 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:56:25,637 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:56:25,638 INFO:     None feature selector for col prot
2022-11-28 02:56:25,638 INFO:     None feature selector for col prot
2022-11-28 02:56:25,638 INFO:     None feature selector for col prot
2022-11-28 02:56:25,638 INFO:     None feature selector for col chem
2022-11-28 02:56:25,638 INFO:     None feature selector for col chem
2022-11-28 02:56:25,638 INFO:     None feature selector for col chem
2022-11-28 02:56:25,639 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:56:25,639 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:56:25,640 INFO:     Number of params in model 169741
2022-11-28 02:56:25,643 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:56:25,643 INFO:   Starting stage: TRAINING
2022-11-28 02:56:25,697 INFO:     Val loss before train {'Reaction outcome loss': 0.9016020846637812, 'Total loss': 0.9016020846637812}
2022-11-28 02:56:25,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:25,697 INFO:     Epoch: 0
2022-11-28 02:56:26,444 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.46596140549941495, 'Total loss': 0.46596140549941495} | train loss {'Reaction outcome loss': 0.6469472352295152, 'Total loss': 0.6469472352295152}
2022-11-28 02:56:26,445 INFO:     Found new best model at epoch 0
2022-11-28 02:56:26,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:26,445 INFO:     Epoch: 1
2022-11-28 02:56:27,198 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45205008509484207, 'Total loss': 0.45205008509484207} | train loss {'Reaction outcome loss': 0.5052042320490845, 'Total loss': 0.5052042320490845}
2022-11-28 02:56:27,198 INFO:     Found new best model at epoch 1
2022-11-28 02:56:27,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:27,199 INFO:     Epoch: 2
2022-11-28 02:56:27,952 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4322107569737868, 'Total loss': 0.4322107569737868} | train loss {'Reaction outcome loss': 0.47905098003966196, 'Total loss': 0.47905098003966196}
2022-11-28 02:56:27,952 INFO:     Found new best model at epoch 2
2022-11-28 02:56:27,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:27,953 INFO:     Epoch: 3
2022-11-28 02:56:28,703 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44060991602865135, 'Total loss': 0.44060991602865135} | train loss {'Reaction outcome loss': 0.4407769076886677, 'Total loss': 0.4407769076886677}
2022-11-28 02:56:28,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:28,704 INFO:     Epoch: 4
2022-11-28 02:56:29,453 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4307727458124811, 'Total loss': 0.4307727458124811} | train loss {'Reaction outcome loss': 0.4283309246022855, 'Total loss': 0.4283309246022855}
2022-11-28 02:56:29,453 INFO:     Found new best model at epoch 4
2022-11-28 02:56:29,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:29,454 INFO:     Epoch: 5
2022-11-28 02:56:30,205 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38731085509061813, 'Total loss': 0.38731085509061813} | train loss {'Reaction outcome loss': 0.41779828366012345, 'Total loss': 0.41779828366012345}
2022-11-28 02:56:30,205 INFO:     Found new best model at epoch 5
2022-11-28 02:56:30,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:30,206 INFO:     Epoch: 6
2022-11-28 02:56:30,958 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4032264697280797, 'Total loss': 0.4032264697280797} | train loss {'Reaction outcome loss': 0.4056252843490051, 'Total loss': 0.4056252843490051}
2022-11-28 02:56:30,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:30,958 INFO:     Epoch: 7
2022-11-28 02:56:31,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4239509164948355, 'Total loss': 0.4239509164948355} | train loss {'Reaction outcome loss': 0.40247687405996746, 'Total loss': 0.40247687405996746}
2022-11-28 02:56:31,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:31,709 INFO:     Epoch: 8
2022-11-28 02:56:32,460 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4013946943662383, 'Total loss': 0.4013946943662383} | train loss {'Reaction outcome loss': 0.39880099291763, 'Total loss': 0.39880099291763}
2022-11-28 02:56:32,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:32,461 INFO:     Epoch: 9
2022-11-28 02:56:33,211 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40788606012409384, 'Total loss': 0.40788606012409384} | train loss {'Reaction outcome loss': 0.3913546650400085, 'Total loss': 0.3913546650400085}
2022-11-28 02:56:33,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:33,211 INFO:     Epoch: 10
2022-11-28 02:56:33,968 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4023161025887186, 'Total loss': 0.4023161025887186} | train loss {'Reaction outcome loss': 0.3821098680998529, 'Total loss': 0.3821098680998529}
2022-11-28 02:56:33,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:33,968 INFO:     Epoch: 11
2022-11-28 02:56:34,721 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4015713542361151, 'Total loss': 0.4015713542361151} | train loss {'Reaction outcome loss': 0.3745328926391179, 'Total loss': 0.3745328926391179}
2022-11-28 02:56:34,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:34,721 INFO:     Epoch: 12
2022-11-28 02:56:35,471 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46293988620693033, 'Total loss': 0.46293988620693033} | train loss {'Reaction outcome loss': 0.3723513843611844, 'Total loss': 0.3723513843611844}
2022-11-28 02:56:35,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:35,471 INFO:     Epoch: 13
2022-11-28 02:56:36,221 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41160196133635263, 'Total loss': 0.41160196133635263} | train loss {'Reaction outcome loss': 0.3723769435478795, 'Total loss': 0.3723769435478795}
2022-11-28 02:56:36,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:36,221 INFO:     Epoch: 14
2022-11-28 02:56:36,973 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40951843542808836, 'Total loss': 0.40951843542808836} | train loss {'Reaction outcome loss': 0.362856813225775, 'Total loss': 0.362856813225775}
2022-11-28 02:56:36,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:36,973 INFO:     Epoch: 15
2022-11-28 02:56:37,728 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39359260875393043, 'Total loss': 0.39359260875393043} | train loss {'Reaction outcome loss': 0.3607936725621262, 'Total loss': 0.3607936725621262}
2022-11-28 02:56:37,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:37,729 INFO:     Epoch: 16
2022-11-28 02:56:38,483 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4071106460284103, 'Total loss': 0.4071106460284103} | train loss {'Reaction outcome loss': 0.3605467142657407, 'Total loss': 0.3605467142657407}
2022-11-28 02:56:38,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:38,484 INFO:     Epoch: 17
2022-11-28 02:56:39,235 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44017501395534386, 'Total loss': 0.44017501395534386} | train loss {'Reaction outcome loss': 0.34934367125313126, 'Total loss': 0.34934367125313126}
2022-11-28 02:56:39,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:39,235 INFO:     Epoch: 18
2022-11-28 02:56:39,987 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40839692967181856, 'Total loss': 0.40839692967181856} | train loss {'Reaction outcome loss': 0.3545309924971192, 'Total loss': 0.3545309924971192}
2022-11-28 02:56:39,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:39,987 INFO:     Epoch: 19
2022-11-28 02:56:40,737 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3997438397597183, 'Total loss': 0.3997438397597183} | train loss {'Reaction outcome loss': 0.34766330636076387, 'Total loss': 0.34766330636076387}
2022-11-28 02:56:40,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:40,737 INFO:     Epoch: 20
2022-11-28 02:56:41,483 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4148159684105353, 'Total loss': 0.4148159684105353} | train loss {'Reaction outcome loss': 0.33426328177653974, 'Total loss': 0.33426328177653974}
2022-11-28 02:56:41,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:41,483 INFO:     Epoch: 21
2022-11-28 02:56:42,233 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4271109535951506, 'Total loss': 0.4271109535951506} | train loss {'Reaction outcome loss': 0.34356365851577253, 'Total loss': 0.34356365851577253}
2022-11-28 02:56:42,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:42,233 INFO:     Epoch: 22
2022-11-28 02:56:42,981 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38297676938501274, 'Total loss': 0.38297676938501274} | train loss {'Reaction outcome loss': 0.34972353501906317, 'Total loss': 0.34972353501906317}
2022-11-28 02:56:42,981 INFO:     Found new best model at epoch 22
2022-11-28 02:56:42,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:42,982 INFO:     Epoch: 23
2022-11-28 02:56:43,732 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3876802477646958, 'Total loss': 0.3876802477646958} | train loss {'Reaction outcome loss': 0.33575612622042816, 'Total loss': 0.33575612622042816}
2022-11-28 02:56:43,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:43,732 INFO:     Epoch: 24
2022-11-28 02:56:44,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4082098569382321, 'Total loss': 0.4082098569382321} | train loss {'Reaction outcome loss': 0.3450773865765622, 'Total loss': 0.3450773865765622}
2022-11-28 02:56:44,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:44,477 INFO:     Epoch: 25
2022-11-28 02:56:45,223 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45159435204484244, 'Total loss': 0.45159435204484244} | train loss {'Reaction outcome loss': 0.33377459660292635, 'Total loss': 0.33377459660292635}
2022-11-28 02:56:45,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:45,223 INFO:     Epoch: 26
2022-11-28 02:56:45,972 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39101309566335246, 'Total loss': 0.39101309566335246} | train loss {'Reaction outcome loss': 0.34264077609705346, 'Total loss': 0.34264077609705346}
2022-11-28 02:56:45,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:45,972 INFO:     Epoch: 27
2022-11-28 02:56:46,725 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43350422145290807, 'Total loss': 0.43350422145290807} | train loss {'Reaction outcome loss': 0.3367335837364437, 'Total loss': 0.3367335837364437}
2022-11-28 02:56:46,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:46,725 INFO:     Epoch: 28
2022-11-28 02:56:47,475 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4114719785072587, 'Total loss': 0.4114719785072587} | train loss {'Reaction outcome loss': 0.33397567010815105, 'Total loss': 0.33397567010815105}
2022-11-28 02:56:47,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:47,476 INFO:     Epoch: 29
2022-11-28 02:56:48,224 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4070081311193379, 'Total loss': 0.4070081311193379} | train loss {'Reaction outcome loss': 0.32236560202023434, 'Total loss': 0.32236560202023434}
2022-11-28 02:56:48,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:48,224 INFO:     Epoch: 30
2022-11-28 02:56:48,974 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39908769506622443, 'Total loss': 0.39908769506622443} | train loss {'Reaction outcome loss': 0.33126977056024537, 'Total loss': 0.33126977056024537}
2022-11-28 02:56:48,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:48,974 INFO:     Epoch: 31
2022-11-28 02:56:49,729 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38942565938288515, 'Total loss': 0.38942565938288515} | train loss {'Reaction outcome loss': 0.3271161261945963, 'Total loss': 0.3271161261945963}
2022-11-28 02:56:49,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:49,730 INFO:     Epoch: 32
2022-11-28 02:56:50,487 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40313895453106274, 'Total loss': 0.40313895453106274} | train loss {'Reaction outcome loss': 0.324187355401415, 'Total loss': 0.324187355401415}
2022-11-28 02:56:50,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:50,487 INFO:     Epoch: 33
2022-11-28 02:56:51,238 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4006298008290204, 'Total loss': 0.4006298008290204} | train loss {'Reaction outcome loss': 0.3211686738105791, 'Total loss': 0.3211686738105791}
2022-11-28 02:56:51,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:51,238 INFO:     Epoch: 34
2022-11-28 02:56:51,989 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4240205254067074, 'Total loss': 0.4240205254067074} | train loss {'Reaction outcome loss': 0.3206806520540868, 'Total loss': 0.3206806520540868}
2022-11-28 02:56:51,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:51,989 INFO:     Epoch: 35
2022-11-28 02:56:52,743 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38758357682011346, 'Total loss': 0.38758357682011346} | train loss {'Reaction outcome loss': 0.3254321530581482, 'Total loss': 0.3254321530581482}
2022-11-28 02:56:52,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:52,743 INFO:     Epoch: 36
2022-11-28 02:56:53,493 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4077864008193666, 'Total loss': 0.4077864008193666} | train loss {'Reaction outcome loss': 0.31792452195358856, 'Total loss': 0.31792452195358856}
2022-11-28 02:56:53,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:53,493 INFO:     Epoch: 37
2022-11-28 02:56:54,245 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4127955892207948, 'Total loss': 0.4127955892207948} | train loss {'Reaction outcome loss': 0.3186219258819737, 'Total loss': 0.3186219258819737}
2022-11-28 02:56:54,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:54,246 INFO:     Epoch: 38
2022-11-28 02:56:54,995 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38352378186854447, 'Total loss': 0.38352378186854447} | train loss {'Reaction outcome loss': 0.322146688107281, 'Total loss': 0.322146688107281}
2022-11-28 02:56:54,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:54,995 INFO:     Epoch: 39
2022-11-28 02:56:55,739 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38868772983551025, 'Total loss': 0.38868772983551025} | train loss {'Reaction outcome loss': 0.3130684312012407, 'Total loss': 0.3130684312012407}
2022-11-28 02:56:55,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:55,740 INFO:     Epoch: 40
2022-11-28 02:56:56,494 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3987041711807251, 'Total loss': 0.3987041711807251} | train loss {'Reaction outcome loss': 0.3202618897682236, 'Total loss': 0.3202618897682236}
2022-11-28 02:56:56,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:56,495 INFO:     Epoch: 41
2022-11-28 02:56:57,247 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4211872932924466, 'Total loss': 0.4211872932924466} | train loss {'Reaction outcome loss': 0.3169916558469976, 'Total loss': 0.3169916558469976}
2022-11-28 02:56:57,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:57,247 INFO:     Epoch: 42
2022-11-28 02:56:57,997 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37209184535525064, 'Total loss': 0.37209184535525064} | train loss {'Reaction outcome loss': 0.31683496977653236, 'Total loss': 0.31683496977653236}
2022-11-28 02:56:57,997 INFO:     Found new best model at epoch 42
2022-11-28 02:56:57,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:57,997 INFO:     Epoch: 43
2022-11-28 02:56:58,745 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3840422499924898, 'Total loss': 0.3840422499924898} | train loss {'Reaction outcome loss': 0.3211729896645392, 'Total loss': 0.3211729896645392}
2022-11-28 02:56:58,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:58,745 INFO:     Epoch: 44
2022-11-28 02:56:59,490 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37477407909252425, 'Total loss': 0.37477407909252425} | train loss {'Reaction outcome loss': 0.32305136070616786, 'Total loss': 0.32305136070616786}
2022-11-28 02:56:59,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:56:59,491 INFO:     Epoch: 45
2022-11-28 02:57:00,239 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38919547911394725, 'Total loss': 0.38919547911394725} | train loss {'Reaction outcome loss': 0.3103110765918128, 'Total loss': 0.3103110765918128}
2022-11-28 02:57:00,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:00,239 INFO:     Epoch: 46
2022-11-28 02:57:00,988 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4109633605588566, 'Total loss': 0.4109633605588566} | train loss {'Reaction outcome loss': 0.3070560221770598, 'Total loss': 0.3070560221770598}
2022-11-28 02:57:00,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:00,988 INFO:     Epoch: 47
2022-11-28 02:57:01,740 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37857791578227823, 'Total loss': 0.37857791578227823} | train loss {'Reaction outcome loss': 0.31207947197911, 'Total loss': 0.31207947197911}
2022-11-28 02:57:01,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:01,740 INFO:     Epoch: 48
2022-11-28 02:57:02,491 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4081766852601008, 'Total loss': 0.4081766852601008} | train loss {'Reaction outcome loss': 0.30750596982937667, 'Total loss': 0.30750596982937667}
2022-11-28 02:57:02,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:02,492 INFO:     Epoch: 49
2022-11-28 02:57:03,246 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3775942003862424, 'Total loss': 0.3775942003862424} | train loss {'Reaction outcome loss': 0.3143320916701228, 'Total loss': 0.3143320916701228}
2022-11-28 02:57:03,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:03,246 INFO:     Epoch: 50
2022-11-28 02:57:04,000 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39432467079975386, 'Total loss': 0.39432467079975386} | train loss {'Reaction outcome loss': 0.31602878958707853, 'Total loss': 0.31602878958707853}
2022-11-28 02:57:04,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:04,000 INFO:     Epoch: 51
2022-11-28 02:57:04,750 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4141263331879269, 'Total loss': 0.4141263331879269} | train loss {'Reaction outcome loss': 0.3171300139398344, 'Total loss': 0.3171300139398344}
2022-11-28 02:57:04,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:04,751 INFO:     Epoch: 52
2022-11-28 02:57:05,504 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3800229755314914, 'Total loss': 0.3800229755314914} | train loss {'Reaction outcome loss': 0.31167404930437764, 'Total loss': 0.31167404930437764}
2022-11-28 02:57:05,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:05,504 INFO:     Epoch: 53
2022-11-28 02:57:06,254 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3938361849974502, 'Total loss': 0.3938361849974502} | train loss {'Reaction outcome loss': 0.3125387884736542, 'Total loss': 0.3125387884736542}
2022-11-28 02:57:06,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:06,254 INFO:     Epoch: 54
2022-11-28 02:57:07,004 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38797055320306256, 'Total loss': 0.38797055320306256} | train loss {'Reaction outcome loss': 0.322256283263766, 'Total loss': 0.322256283263766}
2022-11-28 02:57:07,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:07,004 INFO:     Epoch: 55
2022-11-28 02:57:07,755 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37377518381584773, 'Total loss': 0.37377518381584773} | train loss {'Reaction outcome loss': 0.30962484535731133, 'Total loss': 0.30962484535731133}
2022-11-28 02:57:07,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:07,756 INFO:     Epoch: 56
2022-11-28 02:57:08,507 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.385716331445358, 'Total loss': 0.385716331445358} | train loss {'Reaction outcome loss': 0.3087887543463899, 'Total loss': 0.3087887543463899}
2022-11-28 02:57:08,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:08,508 INFO:     Epoch: 57
2022-11-28 02:57:09,254 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4059854271737012, 'Total loss': 0.4059854271737012} | train loss {'Reaction outcome loss': 0.31171973965941896, 'Total loss': 0.31171973965941896}
2022-11-28 02:57:09,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:09,254 INFO:     Epoch: 58
2022-11-28 02:57:10,006 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4127851093018597, 'Total loss': 0.4127851093018597} | train loss {'Reaction outcome loss': 0.3213220465207292, 'Total loss': 0.3213220465207292}
2022-11-28 02:57:10,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:10,007 INFO:     Epoch: 59
2022-11-28 02:57:10,755 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39050774699585006, 'Total loss': 0.39050774699585006} | train loss {'Reaction outcome loss': 0.31311930975906793, 'Total loss': 0.31311930975906793}
2022-11-28 02:57:10,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:10,755 INFO:     Epoch: 60
2022-11-28 02:57:11,506 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37711679325862363, 'Total loss': 0.37711679325862363} | train loss {'Reaction outcome loss': 0.3119312032696701, 'Total loss': 0.3119312032696701}
2022-11-28 02:57:11,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:11,507 INFO:     Epoch: 61
2022-11-28 02:57:12,258 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3808534693988887, 'Total loss': 0.3808534693988887} | train loss {'Reaction outcome loss': 0.29867005937041774, 'Total loss': 0.29867005937041774}
2022-11-28 02:57:12,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:12,259 INFO:     Epoch: 62
2022-11-28 02:57:13,011 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37937065450982616, 'Total loss': 0.37937065450982616} | train loss {'Reaction outcome loss': 0.3043990743556811, 'Total loss': 0.3043990743556811}
2022-11-28 02:57:13,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:13,012 INFO:     Epoch: 63
2022-11-28 02:57:13,761 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42436939681118185, 'Total loss': 0.42436939681118185} | train loss {'Reaction outcome loss': 0.3028318796817574, 'Total loss': 0.3028318796817574}
2022-11-28 02:57:13,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:13,761 INFO:     Epoch: 64
2022-11-28 02:57:14,516 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40312946045940573, 'Total loss': 0.40312946045940573} | train loss {'Reaction outcome loss': 0.312616060578054, 'Total loss': 0.312616060578054}
2022-11-28 02:57:14,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:14,516 INFO:     Epoch: 65
2022-11-28 02:57:15,267 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3919856319711967, 'Total loss': 0.3919856319711967} | train loss {'Reaction outcome loss': 0.3087719924327347, 'Total loss': 0.3087719924327347}
2022-11-28 02:57:15,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:15,268 INFO:     Epoch: 66
2022-11-28 02:57:16,018 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38566567808051, 'Total loss': 0.38566567808051} | train loss {'Reaction outcome loss': 0.30070041387432045, 'Total loss': 0.30070041387432045}
2022-11-28 02:57:16,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:16,018 INFO:     Epoch: 67
2022-11-28 02:57:16,774 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4123719950968569, 'Total loss': 0.4123719950968569} | train loss {'Reaction outcome loss': 0.2927275702297207, 'Total loss': 0.2927275702297207}
2022-11-28 02:57:16,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:16,774 INFO:     Epoch: 68
2022-11-28 02:57:17,525 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3921842859549956, 'Total loss': 0.3921842859549956} | train loss {'Reaction outcome loss': 0.318790964872366, 'Total loss': 0.318790964872366}
2022-11-28 02:57:17,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:17,526 INFO:     Epoch: 69
2022-11-28 02:57:18,275 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3839186541736126, 'Total loss': 0.3839186541736126} | train loss {'Reaction outcome loss': 0.3107384621436077, 'Total loss': 0.3107384621436077}
2022-11-28 02:57:18,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:18,275 INFO:     Epoch: 70
2022-11-28 02:57:19,025 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40785872902382503, 'Total loss': 0.40785872902382503} | train loss {'Reaction outcome loss': 0.3010826325344463, 'Total loss': 0.3010826325344463}
2022-11-28 02:57:19,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:19,025 INFO:     Epoch: 71
2022-11-28 02:57:19,772 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4173707819797776, 'Total loss': 0.4173707819797776} | train loss {'Reaction outcome loss': 0.30594998625137154, 'Total loss': 0.30594998625137154}
2022-11-28 02:57:19,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:19,772 INFO:     Epoch: 72
2022-11-28 02:57:20,521 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37291173975576053, 'Total loss': 0.37291173975576053} | train loss {'Reaction outcome loss': 0.3107638076969212, 'Total loss': 0.3107638076969212}
2022-11-28 02:57:20,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:20,522 INFO:     Epoch: 73
2022-11-28 02:57:21,273 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4097782823849808, 'Total loss': 0.4097782823849808} | train loss {'Reaction outcome loss': 0.30450432749104595, 'Total loss': 0.30450432749104595}
2022-11-28 02:57:21,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:21,274 INFO:     Epoch: 74
2022-11-28 02:57:22,024 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3752273424443873, 'Total loss': 0.3752273424443873} | train loss {'Reaction outcome loss': 0.3076590275872619, 'Total loss': 0.3076590275872619}
2022-11-28 02:57:22,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:22,025 INFO:     Epoch: 75
2022-11-28 02:57:22,774 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3904114866798574, 'Total loss': 0.3904114866798574} | train loss {'Reaction outcome loss': 0.3019999888755621, 'Total loss': 0.3019999888755621}
2022-11-28 02:57:22,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:22,774 INFO:     Epoch: 76
2022-11-28 02:57:23,524 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41553646834059194, 'Total loss': 0.41553646834059194} | train loss {'Reaction outcome loss': 0.30913166359307304, 'Total loss': 0.30913166359307304}
2022-11-28 02:57:23,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:23,524 INFO:     Epoch: 77
2022-11-28 02:57:24,276 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3855823129415512, 'Total loss': 0.3855823129415512} | train loss {'Reaction outcome loss': 0.3076309509004556, 'Total loss': 0.3076309509004556}
2022-11-28 02:57:24,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:24,276 INFO:     Epoch: 78
2022-11-28 02:57:25,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3800462301481854, 'Total loss': 0.3800462301481854} | train loss {'Reaction outcome loss': 0.31245525223353215, 'Total loss': 0.31245525223353215}
2022-11-28 02:57:25,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:25,027 INFO:     Epoch: 79
2022-11-28 02:57:25,773 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3848881325261159, 'Total loss': 0.3848881325261159} | train loss {'Reaction outcome loss': 0.3051355654794362, 'Total loss': 0.3051355654794362}
2022-11-28 02:57:25,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:25,774 INFO:     Epoch: 80
2022-11-28 02:57:26,526 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40048998238688166, 'Total loss': 0.40048998238688166} | train loss {'Reaction outcome loss': 0.3136619787903563, 'Total loss': 0.3136619787903563}
2022-11-28 02:57:26,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:26,526 INFO:     Epoch: 81
2022-11-28 02:57:27,282 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41672098060900514, 'Total loss': 0.41672098060900514} | train loss {'Reaction outcome loss': 0.29705958011289757, 'Total loss': 0.29705958011289757}
2022-11-28 02:57:27,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:27,283 INFO:     Epoch: 82
2022-11-28 02:57:28,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3743318227881735, 'Total loss': 0.3743318227881735} | train loss {'Reaction outcome loss': 0.3116802289000442, 'Total loss': 0.3116802289000442}
2022-11-28 02:57:28,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:28,036 INFO:     Epoch: 83
2022-11-28 02:57:28,787 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3993458040058613, 'Total loss': 0.3993458040058613} | train loss {'Reaction outcome loss': 0.30146459408945614, 'Total loss': 0.30146459408945614}
2022-11-28 02:57:28,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:28,787 INFO:     Epoch: 84
2022-11-28 02:57:29,534 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37648422575809737, 'Total loss': 0.37648422575809737} | train loss {'Reaction outcome loss': 0.306181003489802, 'Total loss': 0.306181003489802}
2022-11-28 02:57:29,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:29,534 INFO:     Epoch: 85
2022-11-28 02:57:30,280 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3947848206893964, 'Total loss': 0.3947848206893964} | train loss {'Reaction outcome loss': 0.30734856087233753, 'Total loss': 0.30734856087233753}
2022-11-28 02:57:30,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:30,280 INFO:     Epoch: 86
2022-11-28 02:57:31,032 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35664900934154337, 'Total loss': 0.35664900934154337} | train loss {'Reaction outcome loss': 0.30774804934739103, 'Total loss': 0.30774804934739103}
2022-11-28 02:57:31,032 INFO:     Found new best model at epoch 86
2022-11-28 02:57:31,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:31,033 INFO:     Epoch: 87
2022-11-28 02:57:31,781 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36438789641992614, 'Total loss': 0.36438789641992614} | train loss {'Reaction outcome loss': 0.3009913846129371, 'Total loss': 0.3009913846129371}
2022-11-28 02:57:31,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:31,781 INFO:     Epoch: 88
2022-11-28 02:57:32,531 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3700986755165187, 'Total loss': 0.3700986755165187} | train loss {'Reaction outcome loss': 0.30223204703220435, 'Total loss': 0.30223204703220435}
2022-11-28 02:57:32,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:32,531 INFO:     Epoch: 89
2022-11-28 02:57:33,281 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4126543714241548, 'Total loss': 0.4126543714241548} | train loss {'Reaction outcome loss': 0.3020285678005988, 'Total loss': 0.3020285678005988}
2022-11-28 02:57:33,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:33,282 INFO:     Epoch: 90
2022-11-28 02:57:34,033 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37840294651687145, 'Total loss': 0.37840294651687145} | train loss {'Reaction outcome loss': 0.3024180554183981, 'Total loss': 0.3024180554183981}
2022-11-28 02:57:34,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:34,033 INFO:     Epoch: 91
2022-11-28 02:57:34,781 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40550498935309326, 'Total loss': 0.40550498935309326} | train loss {'Reaction outcome loss': 0.3067972490624074, 'Total loss': 0.3067972490624074}
2022-11-28 02:57:34,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:34,781 INFO:     Epoch: 92
2022-11-28 02:57:35,530 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37826580249450426, 'Total loss': 0.37826580249450426} | train loss {'Reaction outcome loss': 0.31140738362146003, 'Total loss': 0.31140738362146003}
2022-11-28 02:57:35,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:35,530 INFO:     Epoch: 93
2022-11-28 02:57:36,283 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3744825453243472, 'Total loss': 0.3744825453243472} | train loss {'Reaction outcome loss': 0.30327910465759134, 'Total loss': 0.30327910465759134}
2022-11-28 02:57:36,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:36,283 INFO:     Epoch: 94
2022-11-28 02:57:37,036 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37975146452134306, 'Total loss': 0.37975146452134306} | train loss {'Reaction outcome loss': 0.30170737924955543, 'Total loss': 0.30170737924955543}
2022-11-28 02:57:37,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:37,036 INFO:     Epoch: 95
2022-11-28 02:57:37,791 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3764091791077094, 'Total loss': 0.3764091791077094} | train loss {'Reaction outcome loss': 0.29712033226725554, 'Total loss': 0.29712033226725554}
2022-11-28 02:57:37,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:37,791 INFO:     Epoch: 96
2022-11-28 02:57:38,544 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38717904551462695, 'Total loss': 0.38717904551462695} | train loss {'Reaction outcome loss': 0.3043643781735051, 'Total loss': 0.3043643781735051}
2022-11-28 02:57:38,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:38,545 INFO:     Epoch: 97
2022-11-28 02:57:39,296 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3674647276374427, 'Total loss': 0.3674647276374427} | train loss {'Reaction outcome loss': 0.29530102405096254, 'Total loss': 0.29530102405096254}
2022-11-28 02:57:39,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:39,297 INFO:     Epoch: 98
2022-11-28 02:57:40,047 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3914050456475128, 'Total loss': 0.3914050456475128} | train loss {'Reaction outcome loss': 0.30609572126019385, 'Total loss': 0.30609572126019385}
2022-11-28 02:57:40,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:40,047 INFO:     Epoch: 99
2022-11-28 02:57:40,798 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3878385776823217, 'Total loss': 0.3878385776823217} | train loss {'Reaction outcome loss': 0.3090320030347474, 'Total loss': 0.3090320030347474}
2022-11-28 02:57:40,798 INFO:     Best model found after epoch 87 of 100.
2022-11-28 02:57:40,798 INFO:   Done with stage: TRAINING
2022-11-28 02:57:40,798 INFO:   Starting stage: EVALUATION
2022-11-28 02:57:40,914 INFO:   Done with stage: EVALUATION
2022-11-28 02:57:40,922 INFO:   Leaving out SEQ value Fold_0
2022-11-28 02:57:40,935 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:57:40,935 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:57:41,567 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:57:41,567 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:57:41,635 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:57:41,635 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:57:41,635 INFO:     No hyperparam tuning for this model
2022-11-28 02:57:41,635 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:57:41,635 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:57:41,636 INFO:     None feature selector for col prot
2022-11-28 02:57:41,636 INFO:     None feature selector for col prot
2022-11-28 02:57:41,636 INFO:     None feature selector for col prot
2022-11-28 02:57:41,637 INFO:     None feature selector for col chem
2022-11-28 02:57:41,637 INFO:     None feature selector for col chem
2022-11-28 02:57:41,637 INFO:     None feature selector for col chem
2022-11-28 02:57:41,637 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:57:41,637 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:57:41,639 INFO:     Number of params in model 169741
2022-11-28 02:57:41,641 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:57:41,641 INFO:   Starting stage: TRAINING
2022-11-28 02:57:41,694 INFO:     Val loss before train {'Reaction outcome loss': 0.972131379626014, 'Total loss': 0.972131379626014}
2022-11-28 02:57:41,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:41,695 INFO:     Epoch: 0
2022-11-28 02:57:42,438 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5115429311990738, 'Total loss': 0.5115429311990738} | train loss {'Reaction outcome loss': 0.623894861522986, 'Total loss': 0.623894861522986}
2022-11-28 02:57:42,438 INFO:     Found new best model at epoch 0
2022-11-28 02:57:42,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:42,439 INFO:     Epoch: 1
2022-11-28 02:57:43,187 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4831157909198241, 'Total loss': 0.4831157909198241} | train loss {'Reaction outcome loss': 0.49913183067526135, 'Total loss': 0.49913183067526135}
2022-11-28 02:57:43,187 INFO:     Found new best model at epoch 1
2022-11-28 02:57:43,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:43,188 INFO:     Epoch: 2
2022-11-28 02:57:43,932 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46172465485605324, 'Total loss': 0.46172465485605324} | train loss {'Reaction outcome loss': 0.45817352369123576, 'Total loss': 0.45817352369123576}
2022-11-28 02:57:43,932 INFO:     Found new best model at epoch 2
2022-11-28 02:57:43,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:43,933 INFO:     Epoch: 3
2022-11-28 02:57:44,674 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44021504812619905, 'Total loss': 0.44021504812619905} | train loss {'Reaction outcome loss': 0.4366096045289721, 'Total loss': 0.4366096045289721}
2022-11-28 02:57:44,674 INFO:     Found new best model at epoch 3
2022-11-28 02:57:44,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:44,675 INFO:     Epoch: 4
2022-11-28 02:57:45,420 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4428557435219938, 'Total loss': 0.4428557435219938} | train loss {'Reaction outcome loss': 0.42340148349805756, 'Total loss': 0.42340148349805756}
2022-11-28 02:57:45,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:45,420 INFO:     Epoch: 5
2022-11-28 02:57:46,166 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42284652523019095, 'Total loss': 0.42284652523019095} | train loss {'Reaction outcome loss': 0.40384598660225773, 'Total loss': 0.40384598660225773}
2022-11-28 02:57:46,166 INFO:     Found new best model at epoch 5
2022-11-28 02:57:46,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:46,167 INFO:     Epoch: 6
2022-11-28 02:57:46,912 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43459822508421814, 'Total loss': 0.43459822508421814} | train loss {'Reaction outcome loss': 0.39743778182535755, 'Total loss': 0.39743778182535755}
2022-11-28 02:57:46,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:46,912 INFO:     Epoch: 7
2022-11-28 02:57:47,649 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4428020925684409, 'Total loss': 0.4428020925684409} | train loss {'Reaction outcome loss': 0.386135341591981, 'Total loss': 0.386135341591981}
2022-11-28 02:57:47,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:47,649 INFO:     Epoch: 8
2022-11-28 02:57:48,390 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4481060989201069, 'Total loss': 0.4481060989201069} | train loss {'Reaction outcome loss': 0.3838892049327189, 'Total loss': 0.3838892049327189}
2022-11-28 02:57:48,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:48,390 INFO:     Epoch: 9
2022-11-28 02:57:49,129 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40163811668753624, 'Total loss': 0.40163811668753624} | train loss {'Reaction outcome loss': 0.37482439583661603, 'Total loss': 0.37482439583661603}
2022-11-28 02:57:49,129 INFO:     Found new best model at epoch 9
2022-11-28 02:57:49,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:49,130 INFO:     Epoch: 10
2022-11-28 02:57:49,867 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.408067139712247, 'Total loss': 0.408067139712247} | train loss {'Reaction outcome loss': 0.3752773198850301, 'Total loss': 0.3752773198850301}
2022-11-28 02:57:49,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:49,867 INFO:     Epoch: 11
2022-11-28 02:57:50,607 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4276099624958905, 'Total loss': 0.4276099624958905} | train loss {'Reaction outcome loss': 0.36403773171561105, 'Total loss': 0.36403773171561105}
2022-11-28 02:57:50,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:50,607 INFO:     Epoch: 12
2022-11-28 02:57:51,349 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4254363612695174, 'Total loss': 0.4254363612695174} | train loss {'Reaction outcome loss': 0.3607437158117489, 'Total loss': 0.3607437158117489}
2022-11-28 02:57:51,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:51,350 INFO:     Epoch: 13
2022-11-28 02:57:52,092 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43983104350891983, 'Total loss': 0.43983104350891983} | train loss {'Reaction outcome loss': 0.3619875689550322, 'Total loss': 0.3619875689550322}
2022-11-28 02:57:52,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:52,092 INFO:     Epoch: 14
2022-11-28 02:57:52,836 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46242598444223404, 'Total loss': 0.46242598444223404} | train loss {'Reaction outcome loss': 0.3619444201795422, 'Total loss': 0.3619444201795422}
2022-11-28 02:57:52,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:52,836 INFO:     Epoch: 15
2022-11-28 02:57:53,575 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4179480936039578, 'Total loss': 0.4179480936039578} | train loss {'Reaction outcome loss': 0.35575939222257963, 'Total loss': 0.35575939222257963}
2022-11-28 02:57:53,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:53,575 INFO:     Epoch: 16
2022-11-28 02:57:54,317 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4385629943148656, 'Total loss': 0.4385629943148656} | train loss {'Reaction outcome loss': 0.34656471479303985, 'Total loss': 0.34656471479303985}
2022-11-28 02:57:54,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:54,317 INFO:     Epoch: 17
2022-11-28 02:57:55,061 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42445934834805404, 'Total loss': 0.42445934834805404} | train loss {'Reaction outcome loss': 0.35239926138702704, 'Total loss': 0.35239926138702704}
2022-11-28 02:57:55,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:55,062 INFO:     Epoch: 18
2022-11-28 02:57:55,803 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4245378579944372, 'Total loss': 0.4245378579944372} | train loss {'Reaction outcome loss': 0.3553147441878611, 'Total loss': 0.3553147441878611}
2022-11-28 02:57:55,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:55,803 INFO:     Epoch: 19
2022-11-28 02:57:56,542 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4319193329323422, 'Total loss': 0.4319193329323422} | train loss {'Reaction outcome loss': 0.33875234969416446, 'Total loss': 0.33875234969416446}
2022-11-28 02:57:56,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:56,542 INFO:     Epoch: 20
2022-11-28 02:57:57,285 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42449463971636514, 'Total loss': 0.42449463971636514} | train loss {'Reaction outcome loss': 0.34589571466251295, 'Total loss': 0.34589571466251295}
2022-11-28 02:57:57,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:57,285 INFO:     Epoch: 21
2022-11-28 02:57:58,025 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41216999461705034, 'Total loss': 0.41216999461705034} | train loss {'Reaction outcome loss': 0.3402239731988128, 'Total loss': 0.3402239731988128}
2022-11-28 02:57:58,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:58,025 INFO:     Epoch: 22
2022-11-28 02:57:58,769 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41386913000182673, 'Total loss': 0.41386913000182673} | train loss {'Reaction outcome loss': 0.3431303339345115, 'Total loss': 0.3431303339345115}
2022-11-28 02:57:58,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:58,770 INFO:     Epoch: 23
2022-11-28 02:57:59,511 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4068760308013721, 'Total loss': 0.4068760308013721} | train loss {'Reaction outcome loss': 0.3446709000638553, 'Total loss': 0.3446709000638553}
2022-11-28 02:57:59,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:57:59,511 INFO:     Epoch: 24
2022-11-28 02:58:00,254 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4613548517227173, 'Total loss': 0.4613548517227173} | train loss {'Reaction outcome loss': 0.3369488512222864, 'Total loss': 0.3369488512222864}
2022-11-28 02:58:00,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:00,254 INFO:     Epoch: 25
2022-11-28 02:58:00,996 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4174584126607938, 'Total loss': 0.4174584126607938} | train loss {'Reaction outcome loss': 0.333979695001427, 'Total loss': 0.333979695001427}
2022-11-28 02:58:00,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:00,996 INFO:     Epoch: 26
2022-11-28 02:58:01,737 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4209889021109451, 'Total loss': 0.4209889021109451} | train loss {'Reaction outcome loss': 0.32847297948842147, 'Total loss': 0.32847297948842147}
2022-11-28 02:58:01,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:01,738 INFO:     Epoch: 27
2022-11-28 02:58:02,478 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.421368653124029, 'Total loss': 0.421368653124029} | train loss {'Reaction outcome loss': 0.3324616337461131, 'Total loss': 0.3324616337461131}
2022-11-28 02:58:02,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:02,478 INFO:     Epoch: 28
2022-11-28 02:58:03,220 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4350733435289426, 'Total loss': 0.4350733435289426} | train loss {'Reaction outcome loss': 0.3293968388620688, 'Total loss': 0.3293968388620688}
2022-11-28 02:58:03,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:03,220 INFO:     Epoch: 29
2022-11-28 02:58:03,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41947298869490623, 'Total loss': 0.41947298869490623} | train loss {'Reaction outcome loss': 0.3358567826449871, 'Total loss': 0.3358567826449871}
2022-11-28 02:58:03,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:03,964 INFO:     Epoch: 30
2022-11-28 02:58:04,705 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4415786638855934, 'Total loss': 0.4415786638855934} | train loss {'Reaction outcome loss': 0.3236143964589859, 'Total loss': 0.3236143964589859}
2022-11-28 02:58:04,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:04,707 INFO:     Epoch: 31
2022-11-28 02:58:05,450 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43330843645063316, 'Total loss': 0.43330843645063316} | train loss {'Reaction outcome loss': 0.3285586892646186, 'Total loss': 0.3285586892646186}
2022-11-28 02:58:05,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:05,450 INFO:     Epoch: 32
2022-11-28 02:58:06,193 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43905234573916957, 'Total loss': 0.43905234573916957} | train loss {'Reaction outcome loss': 0.33074640193764043, 'Total loss': 0.33074640193764043}
2022-11-28 02:58:06,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:06,193 INFO:     Epoch: 33
2022-11-28 02:58:06,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38928080892021005, 'Total loss': 0.38928080892021005} | train loss {'Reaction outcome loss': 0.3283888652008407, 'Total loss': 0.3283888652008407}
2022-11-28 02:58:06,934 INFO:     Found new best model at epoch 33
2022-11-28 02:58:06,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:06,935 INFO:     Epoch: 34
2022-11-28 02:58:07,672 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43632993203672493, 'Total loss': 0.43632993203672493} | train loss {'Reaction outcome loss': 0.32156493552789395, 'Total loss': 0.32156493552789395}
2022-11-28 02:58:07,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:07,672 INFO:     Epoch: 35
2022-11-28 02:58:08,413 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4108494564213536, 'Total loss': 0.4108494564213536} | train loss {'Reaction outcome loss': 0.3261441640403806, 'Total loss': 0.3261441640403806}
2022-11-28 02:58:08,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:08,414 INFO:     Epoch: 36
2022-11-28 02:58:09,152 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3991426613859155, 'Total loss': 0.3991426613859155} | train loss {'Reaction outcome loss': 0.3193425735952903, 'Total loss': 0.3193425735952903}
2022-11-28 02:58:09,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:09,153 INFO:     Epoch: 37
2022-11-28 02:58:09,891 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39829048074104567, 'Total loss': 0.39829048074104567} | train loss {'Reaction outcome loss': 0.32261113822460175, 'Total loss': 0.32261113822460175}
2022-11-28 02:58:09,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:09,892 INFO:     Epoch: 38
2022-11-28 02:58:10,636 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42953022637150506, 'Total loss': 0.42953022637150506} | train loss {'Reaction outcome loss': 0.32848490528306185, 'Total loss': 0.32848490528306185}
2022-11-28 02:58:10,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:10,636 INFO:     Epoch: 39
2022-11-28 02:58:11,377 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42525074664842, 'Total loss': 0.42525074664842} | train loss {'Reaction outcome loss': 0.32030389135589404, 'Total loss': 0.32030389135589404}
2022-11-28 02:58:11,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:11,377 INFO:     Epoch: 40
2022-11-28 02:58:12,118 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4430387630550699, 'Total loss': 0.4430387630550699} | train loss {'Reaction outcome loss': 0.33084835653402367, 'Total loss': 0.33084835653402367}
2022-11-28 02:58:12,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:12,118 INFO:     Epoch: 41
2022-11-28 02:58:12,861 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43426913547922263, 'Total loss': 0.43426913547922263} | train loss {'Reaction outcome loss': 0.3250735478437677, 'Total loss': 0.3250735478437677}
2022-11-28 02:58:12,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:12,861 INFO:     Epoch: 42
2022-11-28 02:58:13,606 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4373656286096031, 'Total loss': 0.4373656286096031} | train loss {'Reaction outcome loss': 0.3170852908978657, 'Total loss': 0.3170852908978657}
2022-11-28 02:58:13,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:13,606 INFO:     Epoch: 43
2022-11-28 02:58:14,355 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43602037108079955, 'Total loss': 0.43602037108079955} | train loss {'Reaction outcome loss': 0.3171082536176759, 'Total loss': 0.3171082536176759}
2022-11-28 02:58:14,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:14,355 INFO:     Epoch: 44
2022-11-28 02:58:15,097 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41094732589342375, 'Total loss': 0.41094732589342375} | train loss {'Reaction outcome loss': 0.3184874065372409, 'Total loss': 0.3184874065372409}
2022-11-28 02:58:15,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:15,098 INFO:     Epoch: 45
2022-11-28 02:58:15,843 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4422111223367127, 'Total loss': 0.4422111223367127} | train loss {'Reaction outcome loss': 0.3188063012702124, 'Total loss': 0.3188063012702124}
2022-11-28 02:58:15,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:15,843 INFO:     Epoch: 46
2022-11-28 02:58:16,586 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4186283266171813, 'Total loss': 0.4186283266171813} | train loss {'Reaction outcome loss': 0.3171852412576578, 'Total loss': 0.3171852412576578}
2022-11-28 02:58:16,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:16,586 INFO:     Epoch: 47
2022-11-28 02:58:17,329 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43090290474620735, 'Total loss': 0.43090290474620735} | train loss {'Reaction outcome loss': 0.32152163714778664, 'Total loss': 0.32152163714778664}
2022-11-28 02:58:17,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:17,329 INFO:     Epoch: 48
2022-11-28 02:58:18,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40211416814814915, 'Total loss': 0.40211416814814915} | train loss {'Reaction outcome loss': 0.31197004523508404, 'Total loss': 0.31197004523508404}
2022-11-28 02:58:18,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:18,072 INFO:     Epoch: 49
2022-11-28 02:58:18,812 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.433591693978418, 'Total loss': 0.433591693978418} | train loss {'Reaction outcome loss': 0.3170624939762816, 'Total loss': 0.3170624939762816}
2022-11-28 02:58:18,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:18,812 INFO:     Epoch: 50
2022-11-28 02:58:19,556 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45583483949303627, 'Total loss': 0.45583483949303627} | train loss {'Reaction outcome loss': 0.303799191421392, 'Total loss': 0.303799191421392}
2022-11-28 02:58:19,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:19,557 INFO:     Epoch: 51
2022-11-28 02:58:20,303 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4384131602604281, 'Total loss': 0.4384131602604281} | train loss {'Reaction outcome loss': 0.32472129372917874, 'Total loss': 0.32472129372917874}
2022-11-28 02:58:20,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:20,303 INFO:     Epoch: 52
2022-11-28 02:58:21,046 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4249994277276776, 'Total loss': 0.4249994277276776} | train loss {'Reaction outcome loss': 0.318233561394166, 'Total loss': 0.318233561394166}
2022-11-28 02:58:21,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:21,046 INFO:     Epoch: 53
2022-11-28 02:58:21,787 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43428410826758906, 'Total loss': 0.43428410826758906} | train loss {'Reaction outcome loss': 0.3213636700596128, 'Total loss': 0.3213636700596128}
2022-11-28 02:58:21,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:21,788 INFO:     Epoch: 54
2022-11-28 02:58:22,526 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.429545192217285, 'Total loss': 0.429545192217285} | train loss {'Reaction outcome loss': 0.3177130617353381, 'Total loss': 0.3177130617353381}
2022-11-28 02:58:22,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:22,526 INFO:     Epoch: 55
2022-11-28 02:58:23,267 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4177139795475258, 'Total loss': 0.4177139795475258} | train loss {'Reaction outcome loss': 0.31663547361991845, 'Total loss': 0.31663547361991845}
2022-11-28 02:58:23,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:23,267 INFO:     Epoch: 56
2022-11-28 02:58:24,006 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41569178991697053, 'Total loss': 0.41569178991697053} | train loss {'Reaction outcome loss': 0.32240554807441574, 'Total loss': 0.32240554807441574}
2022-11-28 02:58:24,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:24,007 INFO:     Epoch: 57
2022-11-28 02:58:24,744 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4079129113392396, 'Total loss': 0.4079129113392396} | train loss {'Reaction outcome loss': 0.3163551409329687, 'Total loss': 0.3163551409329687}
2022-11-28 02:58:24,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:24,744 INFO:     Epoch: 58
2022-11-28 02:58:25,493 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40697698447514663, 'Total loss': 0.40697698447514663} | train loss {'Reaction outcome loss': 0.3058957905489571, 'Total loss': 0.3058957905489571}
2022-11-28 02:58:25,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:25,493 INFO:     Epoch: 59
2022-11-28 02:58:26,234 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41380601342428813, 'Total loss': 0.41380601342428813} | train loss {'Reaction outcome loss': 0.3129095047408221, 'Total loss': 0.3129095047408221}
2022-11-28 02:58:26,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:26,234 INFO:     Epoch: 60
2022-11-28 02:58:26,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4208877548914064, 'Total loss': 0.4208877548914064} | train loss {'Reaction outcome loss': 0.31016640562792214, 'Total loss': 0.31016640562792214}
2022-11-28 02:58:26,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:26,978 INFO:     Epoch: 61
2022-11-28 02:58:27,720 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4741295145993883, 'Total loss': 0.4741295145993883} | train loss {'Reaction outcome loss': 0.3069477164927794, 'Total loss': 0.3069477164927794}
2022-11-28 02:58:27,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:27,720 INFO:     Epoch: 62
2022-11-28 02:58:28,462 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3906069602817297, 'Total loss': 0.3906069602817297} | train loss {'Reaction outcome loss': 0.32183921057350784, 'Total loss': 0.32183921057350784}
2022-11-28 02:58:28,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:28,463 INFO:     Epoch: 63
2022-11-28 02:58:29,204 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41053963147781114, 'Total loss': 0.41053963147781114} | train loss {'Reaction outcome loss': 0.3084237114659378, 'Total loss': 0.3084237114659378}
2022-11-28 02:58:29,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:29,205 INFO:     Epoch: 64
2022-11-28 02:58:29,945 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4083224253898317, 'Total loss': 0.4083224253898317} | train loss {'Reaction outcome loss': 0.314693573451772, 'Total loss': 0.314693573451772}
2022-11-28 02:58:29,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:29,946 INFO:     Epoch: 65
2022-11-28 02:58:30,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42490539056333626, 'Total loss': 0.42490539056333626} | train loss {'Reaction outcome loss': 0.31441122098844876, 'Total loss': 0.31441122098844876}
2022-11-28 02:58:30,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:30,690 INFO:     Epoch: 66
2022-11-28 02:58:31,432 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43810645965012635, 'Total loss': 0.43810645965012635} | train loss {'Reaction outcome loss': 0.3193068125266202, 'Total loss': 0.3193068125266202}
2022-11-28 02:58:31,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:31,432 INFO:     Epoch: 67
2022-11-28 02:58:32,170 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4275662565434521, 'Total loss': 0.4275662565434521} | train loss {'Reaction outcome loss': 0.3181845723670356, 'Total loss': 0.3181845723670356}
2022-11-28 02:58:32,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:32,170 INFO:     Epoch: 68
2022-11-28 02:58:32,911 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4205142965709621, 'Total loss': 0.4205142965709621} | train loss {'Reaction outcome loss': 0.31047377899593237, 'Total loss': 0.31047377899593237}
2022-11-28 02:58:32,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:32,911 INFO:     Epoch: 69
2022-11-28 02:58:33,652 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42944353649562056, 'Total loss': 0.42944353649562056} | train loss {'Reaction outcome loss': 0.2935462921857834, 'Total loss': 0.2935462921857834}
2022-11-28 02:58:33,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:33,653 INFO:     Epoch: 70
2022-11-28 02:58:34,392 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44209404509853234, 'Total loss': 0.44209404509853234} | train loss {'Reaction outcome loss': 0.30537691063114575, 'Total loss': 0.30537691063114575}
2022-11-28 02:58:34,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:34,392 INFO:     Epoch: 71
2022-11-28 02:58:35,134 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41811237687414343, 'Total loss': 0.41811237687414343} | train loss {'Reaction outcome loss': 0.31940249633424134, 'Total loss': 0.31940249633424134}
2022-11-28 02:58:35,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:35,135 INFO:     Epoch: 72
2022-11-28 02:58:35,874 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4095694044266235, 'Total loss': 0.4095694044266235} | train loss {'Reaction outcome loss': 0.3145212091353475, 'Total loss': 0.3145212091353475}
2022-11-28 02:58:35,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:35,876 INFO:     Epoch: 73
2022-11-28 02:58:36,618 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44354231587865134, 'Total loss': 0.44354231587865134} | train loss {'Reaction outcome loss': 0.3153022132509825, 'Total loss': 0.3153022132509825}
2022-11-28 02:58:36,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:36,618 INFO:     Epoch: 74
2022-11-28 02:58:37,359 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4001528766344894, 'Total loss': 0.4001528766344894} | train loss {'Reaction outcome loss': 0.32163885445619117, 'Total loss': 0.32163885445619117}
2022-11-28 02:58:37,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:37,360 INFO:     Epoch: 75
2022-11-28 02:58:38,102 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3912060557102615, 'Total loss': 0.3912060557102615} | train loss {'Reaction outcome loss': 0.31076840959033186, 'Total loss': 0.31076840959033186}
2022-11-28 02:58:38,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:38,103 INFO:     Epoch: 76
2022-11-28 02:58:38,850 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3897418458496263, 'Total loss': 0.3897418458496263} | train loss {'Reaction outcome loss': 0.30581666209868025, 'Total loss': 0.30581666209868025}
2022-11-28 02:58:38,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:38,850 INFO:     Epoch: 77
2022-11-28 02:58:39,606 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4179912636225874, 'Total loss': 0.4179912636225874} | train loss {'Reaction outcome loss': 0.3117289216846836, 'Total loss': 0.3117289216846836}
2022-11-28 02:58:39,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:39,606 INFO:     Epoch: 78
2022-11-28 02:58:40,361 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4286150431091135, 'Total loss': 0.4286150431091135} | train loss {'Reaction outcome loss': 0.3095803564908553, 'Total loss': 0.3095803564908553}
2022-11-28 02:58:40,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:40,361 INFO:     Epoch: 79
2022-11-28 02:58:41,116 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4149684486064044, 'Total loss': 0.4149684486064044} | train loss {'Reaction outcome loss': 0.30883840184886846, 'Total loss': 0.30883840184886846}
2022-11-28 02:58:41,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:41,116 INFO:     Epoch: 80
2022-11-28 02:58:41,864 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4025490561669523, 'Total loss': 0.4025490561669523} | train loss {'Reaction outcome loss': 0.3109240987775277, 'Total loss': 0.3109240987775277}
2022-11-28 02:58:41,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:41,865 INFO:     Epoch: 81
2022-11-28 02:58:42,605 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4026312568986958, 'Total loss': 0.4026312568986958} | train loss {'Reaction outcome loss': 0.32319200586299507, 'Total loss': 0.32319200586299507}
2022-11-28 02:58:42,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:42,606 INFO:     Epoch: 82
2022-11-28 02:58:43,343 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3923146914881231, 'Total loss': 0.3923146914881231} | train loss {'Reaction outcome loss': 0.3092377810453882, 'Total loss': 0.3092377810453882}
2022-11-28 02:58:43,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:43,343 INFO:     Epoch: 83
2022-11-28 02:58:44,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4421317025341771, 'Total loss': 0.4421317025341771} | train loss {'Reaction outcome loss': 0.30453983378045413, 'Total loss': 0.30453983378045413}
2022-11-28 02:58:44,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:44,079 INFO:     Epoch: 84
2022-11-28 02:58:44,815 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41733128543604503, 'Total loss': 0.41733128543604503} | train loss {'Reaction outcome loss': 0.3111723505416695, 'Total loss': 0.3111723505416695}
2022-11-28 02:58:44,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:44,815 INFO:     Epoch: 85
2022-11-28 02:58:45,551 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4385113279250535, 'Total loss': 0.4385113279250535} | train loss {'Reaction outcome loss': 0.3084302719454376, 'Total loss': 0.3084302719454376}
2022-11-28 02:58:45,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:45,552 INFO:     Epoch: 86
2022-11-28 02:58:46,293 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4260637645017017, 'Total loss': 0.4260637645017017} | train loss {'Reaction outcome loss': 0.3061373813419926, 'Total loss': 0.3061373813419926}
2022-11-28 02:58:46,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:46,293 INFO:     Epoch: 87
2022-11-28 02:58:47,029 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4069079634818164, 'Total loss': 0.4069079634818164} | train loss {'Reaction outcome loss': 0.30933718401558546, 'Total loss': 0.30933718401558546}
2022-11-28 02:58:47,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:47,029 INFO:     Epoch: 88
2022-11-28 02:58:47,768 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39021198341453617, 'Total loss': 0.39021198341453617} | train loss {'Reaction outcome loss': 0.3073686553507435, 'Total loss': 0.3073686553507435}
2022-11-28 02:58:47,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:47,768 INFO:     Epoch: 89
2022-11-28 02:58:48,503 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42986517772078514, 'Total loss': 0.42986517772078514} | train loss {'Reaction outcome loss': 0.31013396069103355, 'Total loss': 0.31013396069103355}
2022-11-28 02:58:48,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:48,503 INFO:     Epoch: 90
2022-11-28 02:58:49,242 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4258249656043269, 'Total loss': 0.4258249656043269} | train loss {'Reaction outcome loss': 0.31258521782500404, 'Total loss': 0.31258521782500404}
2022-11-28 02:58:49,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:49,242 INFO:     Epoch: 91
2022-11-28 02:58:49,978 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4055642847987739, 'Total loss': 0.4055642847987739} | train loss {'Reaction outcome loss': 0.3107044236696496, 'Total loss': 0.3107044236696496}
2022-11-28 02:58:49,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:49,978 INFO:     Epoch: 92
2022-11-28 02:58:50,718 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4187480865723707, 'Total loss': 0.4187480865723707} | train loss {'Reaction outcome loss': 0.30861554559396237, 'Total loss': 0.30861554559396237}
2022-11-28 02:58:50,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:50,719 INFO:     Epoch: 93
2022-11-28 02:58:51,461 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39895825782282784, 'Total loss': 0.39895825782282784} | train loss {'Reaction outcome loss': 0.30833987581486605, 'Total loss': 0.30833987581486605}
2022-11-28 02:58:51,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:51,461 INFO:     Epoch: 94
2022-11-28 02:58:52,202 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3871794366701083, 'Total loss': 0.3871794366701083} | train loss {'Reaction outcome loss': 0.3150206996622134, 'Total loss': 0.3150206996622134}
2022-11-28 02:58:52,202 INFO:     Found new best model at epoch 94
2022-11-28 02:58:52,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:52,203 INFO:     Epoch: 95
2022-11-28 02:58:52,940 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43033761327916925, 'Total loss': 0.43033761327916925} | train loss {'Reaction outcome loss': 0.3132016446517438, 'Total loss': 0.3132016446517438}
2022-11-28 02:58:52,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:52,940 INFO:     Epoch: 96
2022-11-28 02:58:53,677 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39824726711958647, 'Total loss': 0.39824726711958647} | train loss {'Reaction outcome loss': 0.3055594276712865, 'Total loss': 0.3055594276712865}
2022-11-28 02:58:53,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:53,677 INFO:     Epoch: 97
2022-11-28 02:58:54,415 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39819245298647066, 'Total loss': 0.39819245298647066} | train loss {'Reaction outcome loss': 0.31125833007450004, 'Total loss': 0.31125833007450004}
2022-11-28 02:58:54,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:54,415 INFO:     Epoch: 98
2022-11-28 02:58:55,156 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4134802640500394, 'Total loss': 0.4134802640500394} | train loss {'Reaction outcome loss': 0.30749663947796335, 'Total loss': 0.30749663947796335}
2022-11-28 02:58:55,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:55,157 INFO:     Epoch: 99
2022-11-28 02:58:55,895 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4497918879443949, 'Total loss': 0.4497918879443949} | train loss {'Reaction outcome loss': 0.31365953851111084, 'Total loss': 0.31365953851111084}
2022-11-28 02:58:55,895 INFO:     Best model found after epoch 95 of 100.
2022-11-28 02:58:55,895 INFO:   Done with stage: TRAINING
2022-11-28 02:58:55,895 INFO:   Starting stage: EVALUATION
2022-11-28 02:58:56,022 INFO:   Done with stage: EVALUATION
2022-11-28 02:58:56,022 INFO:   Leaving out SEQ value Fold_1
2022-11-28 02:58:56,035 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 02:58:56,035 INFO:   Starting stage: FEATURE SCALING
2022-11-28 02:58:56,663 INFO:   Done with stage: FEATURE SCALING
2022-11-28 02:58:56,663 INFO:   Starting stage: SCALING TARGETS
2022-11-28 02:58:56,730 INFO:   Done with stage: SCALING TARGETS
2022-11-28 02:58:56,730 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:58:56,731 INFO:     No hyperparam tuning for this model
2022-11-28 02:58:56,731 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 02:58:56,731 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 02:58:56,731 INFO:     None feature selector for col prot
2022-11-28 02:58:56,731 INFO:     None feature selector for col prot
2022-11-28 02:58:56,732 INFO:     None feature selector for col prot
2022-11-28 02:58:56,732 INFO:     None feature selector for col chem
2022-11-28 02:58:56,732 INFO:     None feature selector for col chem
2022-11-28 02:58:56,732 INFO:     None feature selector for col chem
2022-11-28 02:58:56,732 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 02:58:56,732 INFO:   Starting stage: BUILD MODEL
2022-11-28 02:58:56,734 INFO:     Number of params in model 169741
2022-11-28 02:58:56,737 INFO:   Done with stage: BUILD MODEL
2022-11-28 02:58:56,737 INFO:   Starting stage: TRAINING
2022-11-28 02:58:56,790 INFO:     Val loss before train {'Reaction outcome loss': 1.0210524689067493, 'Total loss': 1.0210524689067493}
2022-11-28 02:58:56,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:56,790 INFO:     Epoch: 0
2022-11-28 02:58:57,529 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.559366637332873, 'Total loss': 0.559366637332873} | train loss {'Reaction outcome loss': 0.6389715215381311, 'Total loss': 0.6389715215381311}
2022-11-28 02:58:57,530 INFO:     Found new best model at epoch 0
2022-11-28 02:58:57,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:57,531 INFO:     Epoch: 1
2022-11-28 02:58:58,269 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4944737302986058, 'Total loss': 0.4944737302986058} | train loss {'Reaction outcome loss': 0.5001100788311083, 'Total loss': 0.5001100788311083}
2022-11-28 02:58:58,269 INFO:     Found new best model at epoch 1
2022-11-28 02:58:58,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:58,270 INFO:     Epoch: 2
2022-11-28 02:58:59,010 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4907639284025539, 'Total loss': 0.4907639284025539} | train loss {'Reaction outcome loss': 0.47074676806829413, 'Total loss': 0.47074676806829413}
2022-11-28 02:58:59,010 INFO:     Found new best model at epoch 2
2022-11-28 02:58:59,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:59,011 INFO:     Epoch: 3
2022-11-28 02:58:59,748 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4839772250164639, 'Total loss': 0.4839772250164639} | train loss {'Reaction outcome loss': 0.4367472168134183, 'Total loss': 0.4367472168134183}
2022-11-28 02:58:59,748 INFO:     Found new best model at epoch 3
2022-11-28 02:58:59,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:58:59,749 INFO:     Epoch: 4
2022-11-28 02:59:00,490 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46041315726258536, 'Total loss': 0.46041315726258536} | train loss {'Reaction outcome loss': 0.42520694677927057, 'Total loss': 0.42520694677927057}
2022-11-28 02:59:00,491 INFO:     Found new best model at epoch 4
2022-11-28 02:59:00,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:00,491 INFO:     Epoch: 5
2022-11-28 02:59:01,229 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4635823184454983, 'Total loss': 0.4635823184454983} | train loss {'Reaction outcome loss': 0.4154366082074691, 'Total loss': 0.4154366082074691}
2022-11-28 02:59:01,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:01,229 INFO:     Epoch: 6
2022-11-28 02:59:01,963 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47680797190828755, 'Total loss': 0.47680797190828755} | train loss {'Reaction outcome loss': 0.40632713917566804, 'Total loss': 0.40632713917566804}
2022-11-28 02:59:01,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:01,964 INFO:     Epoch: 7
2022-11-28 02:59:02,699 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4990541142496196, 'Total loss': 0.4990541142496196} | train loss {'Reaction outcome loss': 0.3968705973454884, 'Total loss': 0.3968705973454884}
2022-11-28 02:59:02,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:02,700 INFO:     Epoch: 8
2022-11-28 02:59:03,435 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4596288637681441, 'Total loss': 0.4596288637681441} | train loss {'Reaction outcome loss': 0.39299287415888845, 'Total loss': 0.39299287415888845}
2022-11-28 02:59:03,435 INFO:     Found new best model at epoch 8
2022-11-28 02:59:03,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:03,436 INFO:     Epoch: 9
2022-11-28 02:59:04,175 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48906082795424893, 'Total loss': 0.48906082795424893} | train loss {'Reaction outcome loss': 0.38021875996978916, 'Total loss': 0.38021875996978916}
2022-11-28 02:59:04,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:04,175 INFO:     Epoch: 10
2022-11-28 02:59:04,913 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4680647806010463, 'Total loss': 0.4680647806010463} | train loss {'Reaction outcome loss': 0.3791144533424961, 'Total loss': 0.3791144533424961}
2022-11-28 02:59:04,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:04,914 INFO:     Epoch: 11
2022-11-28 02:59:05,652 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43500144068490376, 'Total loss': 0.43500144068490376} | train loss {'Reaction outcome loss': 0.3741535422145104, 'Total loss': 0.3741535422145104}
2022-11-28 02:59:05,652 INFO:     Found new best model at epoch 11
2022-11-28 02:59:05,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:05,653 INFO:     Epoch: 12
2022-11-28 02:59:06,392 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48960464244539087, 'Total loss': 0.48960464244539087} | train loss {'Reaction outcome loss': 0.3662484887911349, 'Total loss': 0.3662484887911349}
2022-11-28 02:59:06,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:06,392 INFO:     Epoch: 13
2022-11-28 02:59:07,132 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43236662447452545, 'Total loss': 0.43236662447452545} | train loss {'Reaction outcome loss': 0.36012372146455607, 'Total loss': 0.36012372146455607}
2022-11-28 02:59:07,133 INFO:     Found new best model at epoch 13
2022-11-28 02:59:07,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:07,134 INFO:     Epoch: 14
2022-11-28 02:59:07,876 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.442306739193472, 'Total loss': 0.442306739193472} | train loss {'Reaction outcome loss': 0.3664216946582405, 'Total loss': 0.3664216946582405}
2022-11-28 02:59:07,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:07,876 INFO:     Epoch: 15
2022-11-28 02:59:08,614 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.469418409534476, 'Total loss': 0.469418409534476} | train loss {'Reaction outcome loss': 0.3585469454222796, 'Total loss': 0.3585469454222796}
2022-11-28 02:59:08,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:08,614 INFO:     Epoch: 16
2022-11-28 02:59:09,357 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47973136942495, 'Total loss': 0.47973136942495} | train loss {'Reaction outcome loss': 0.34873509248908685, 'Total loss': 0.34873509248908685}
2022-11-28 02:59:09,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:09,357 INFO:     Epoch: 17
2022-11-28 02:59:10,098 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45461176335811615, 'Total loss': 0.45461176335811615} | train loss {'Reaction outcome loss': 0.35814427310714914, 'Total loss': 0.35814427310714914}
2022-11-28 02:59:10,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:10,099 INFO:     Epoch: 18
2022-11-28 02:59:10,835 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39905911057510157, 'Total loss': 0.39905911057510157} | train loss {'Reaction outcome loss': 0.34658404889763617, 'Total loss': 0.34658404889763617}
2022-11-28 02:59:10,835 INFO:     Found new best model at epoch 18
2022-11-28 02:59:10,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:10,836 INFO:     Epoch: 19
2022-11-28 02:59:11,573 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44823583655736665, 'Total loss': 0.44823583655736665} | train loss {'Reaction outcome loss': 0.3535160322882691, 'Total loss': 0.3535160322882691}
2022-11-28 02:59:11,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:11,573 INFO:     Epoch: 20
2022-11-28 02:59:12,318 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42954236319796607, 'Total loss': 0.42954236319796607} | train loss {'Reaction outcome loss': 0.3430748015338061, 'Total loss': 0.3430748015338061}
2022-11-28 02:59:12,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:12,318 INFO:     Epoch: 21
2022-11-28 02:59:13,055 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45806165649132297, 'Total loss': 0.45806165649132297} | train loss {'Reaction outcome loss': 0.34921574522646104, 'Total loss': 0.34921574522646104}
2022-11-28 02:59:13,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:13,055 INFO:     Epoch: 22
2022-11-28 02:59:13,797 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43083902380683203, 'Total loss': 0.43083902380683203} | train loss {'Reaction outcome loss': 0.3480667997075587, 'Total loss': 0.3480667997075587}
2022-11-28 02:59:13,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:13,798 INFO:     Epoch: 23
2022-11-28 02:59:14,535 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44461137225682085, 'Total loss': 0.44461137225682085} | train loss {'Reaction outcome loss': 0.34840839815383057, 'Total loss': 0.34840839815383057}
2022-11-28 02:59:14,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:14,536 INFO:     Epoch: 24
2022-11-28 02:59:15,273 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47387964210726996, 'Total loss': 0.47387964210726996} | train loss {'Reaction outcome loss': 0.34796320075283244, 'Total loss': 0.34796320075283244}
2022-11-28 02:59:15,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:15,273 INFO:     Epoch: 25
2022-11-28 02:59:16,014 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4591681452637369, 'Total loss': 0.4591681452637369} | train loss {'Reaction outcome loss': 0.338188489967463, 'Total loss': 0.338188489967463}
2022-11-28 02:59:16,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:16,015 INFO:     Epoch: 26
2022-11-28 02:59:16,757 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.6086448935622518, 'Total loss': 0.6086448935622518} | train loss {'Reaction outcome loss': 0.33356587783414493, 'Total loss': 0.33356587783414493}
2022-11-28 02:59:16,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:16,757 INFO:     Epoch: 27
2022-11-28 02:59:17,499 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44529407166621904, 'Total loss': 0.44529407166621904} | train loss {'Reaction outcome loss': 0.3473683371227615, 'Total loss': 0.3473683371227615}
2022-11-28 02:59:17,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:17,500 INFO:     Epoch: 28
2022-11-28 02:59:18,240 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43643693846057763, 'Total loss': 0.43643693846057763} | train loss {'Reaction outcome loss': 0.3369527318191772, 'Total loss': 0.3369527318191772}
2022-11-28 02:59:18,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:18,241 INFO:     Epoch: 29
2022-11-28 02:59:18,976 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4336588125337254, 'Total loss': 0.4336588125337254} | train loss {'Reaction outcome loss': 0.33517715605546017, 'Total loss': 0.33517715605546017}
2022-11-28 02:59:18,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:18,977 INFO:     Epoch: 30
2022-11-28 02:59:19,714 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4359934875233607, 'Total loss': 0.4359934875233607} | train loss {'Reaction outcome loss': 0.3342199414968491, 'Total loss': 0.3342199414968491}
2022-11-28 02:59:19,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:19,714 INFO:     Epoch: 31
2022-11-28 02:59:20,454 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4369972392239354, 'Total loss': 0.4369972392239354} | train loss {'Reaction outcome loss': 0.3331538687251052, 'Total loss': 0.3331538687251052}
2022-11-28 02:59:20,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:20,454 INFO:     Epoch: 32
2022-11-28 02:59:21,190 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4532540580892766, 'Total loss': 0.4532540580892766} | train loss {'Reaction outcome loss': 0.333857544648404, 'Total loss': 0.333857544648404}
2022-11-28 02:59:21,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:21,191 INFO:     Epoch: 33
2022-11-28 02:59:21,933 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43627811900594016, 'Total loss': 0.43627811900594016} | train loss {'Reaction outcome loss': 0.3405414087735877, 'Total loss': 0.3405414087735877}
2022-11-28 02:59:21,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:21,933 INFO:     Epoch: 34
2022-11-28 02:59:22,670 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.421954313123768, 'Total loss': 0.421954313123768} | train loss {'Reaction outcome loss': 0.3355314881825934, 'Total loss': 0.3355314881825934}
2022-11-28 02:59:22,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:22,670 INFO:     Epoch: 35
2022-11-28 02:59:23,416 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4502212737094272, 'Total loss': 0.4502212737094272} | train loss {'Reaction outcome loss': 0.3277213979740532, 'Total loss': 0.3277213979740532}
2022-11-28 02:59:23,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:23,416 INFO:     Epoch: 36
2022-11-28 02:59:24,155 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45015580850568687, 'Total loss': 0.45015580850568687} | train loss {'Reaction outcome loss': 0.33971343159067385, 'Total loss': 0.33971343159067385}
2022-11-28 02:59:24,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:24,155 INFO:     Epoch: 37
2022-11-28 02:59:24,893 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4653101841157133, 'Total loss': 0.4653101841157133} | train loss {'Reaction outcome loss': 0.33054795575385193, 'Total loss': 0.33054795575385193}
2022-11-28 02:59:24,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:24,893 INFO:     Epoch: 38
2022-11-28 02:59:25,632 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4383060061796145, 'Total loss': 0.4383060061796145} | train loss {'Reaction outcome loss': 0.33478948829733596, 'Total loss': 0.33478948829733596}
2022-11-28 02:59:25,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:25,633 INFO:     Epoch: 39
2022-11-28 02:59:26,378 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4669444357806986, 'Total loss': 0.4669444357806986} | train loss {'Reaction outcome loss': 0.32364249709917575, 'Total loss': 0.32364249709917575}
2022-11-28 02:59:26,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:26,379 INFO:     Epoch: 40
2022-11-28 02:59:27,120 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4426106239923022, 'Total loss': 0.4426106239923022} | train loss {'Reaction outcome loss': 0.3284952216458564, 'Total loss': 0.3284952216458564}
2022-11-28 02:59:27,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:27,120 INFO:     Epoch: 41
2022-11-28 02:59:27,862 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.438302429900928, 'Total loss': 0.438302429900928} | train loss {'Reaction outcome loss': 0.3278784646823698, 'Total loss': 0.3278784646823698}
2022-11-28 02:59:27,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:27,862 INFO:     Epoch: 42
2022-11-28 02:59:28,604 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4439243772490458, 'Total loss': 0.4439243772490458} | train loss {'Reaction outcome loss': 0.32293561064467136, 'Total loss': 0.32293561064467136}
2022-11-28 02:59:28,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:28,604 INFO:     Epoch: 43
2022-11-28 02:59:29,342 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45335684378038754, 'Total loss': 0.45335684378038754} | train loss {'Reaction outcome loss': 0.3204665183716891, 'Total loss': 0.3204665183716891}
2022-11-28 02:59:29,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:29,342 INFO:     Epoch: 44
2022-11-28 02:59:30,079 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4627454246986996, 'Total loss': 0.4627454246986996} | train loss {'Reaction outcome loss': 0.32809056104445944, 'Total loss': 0.32809056104445944}
2022-11-28 02:59:30,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:30,079 INFO:     Epoch: 45
2022-11-28 02:59:30,821 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4753553830087185, 'Total loss': 0.4753553830087185} | train loss {'Reaction outcome loss': 0.32012126664726104, 'Total loss': 0.32012126664726104}
2022-11-28 02:59:30,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:30,822 INFO:     Epoch: 46
2022-11-28 02:59:31,557 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4358683120543984, 'Total loss': 0.4358683120543984} | train loss {'Reaction outcome loss': 0.32784889507658627, 'Total loss': 0.32784889507658627}
2022-11-28 02:59:31,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:31,557 INFO:     Epoch: 47
2022-11-28 02:59:32,295 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45015802065079863, 'Total loss': 0.45015802065079863} | train loss {'Reaction outcome loss': 0.32730344208527584, 'Total loss': 0.32730344208527584}
2022-11-28 02:59:32,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:32,295 INFO:     Epoch: 48
2022-11-28 02:59:33,036 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44873576712879265, 'Total loss': 0.44873576712879265} | train loss {'Reaction outcome loss': 0.3152243038525387, 'Total loss': 0.3152243038525387}
2022-11-28 02:59:33,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:33,037 INFO:     Epoch: 49
2022-11-28 02:59:33,777 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42816552181135525, 'Total loss': 0.42816552181135525} | train loss {'Reaction outcome loss': 0.32847825465153674, 'Total loss': 0.32847825465153674}
2022-11-28 02:59:33,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:33,777 INFO:     Epoch: 50
2022-11-28 02:59:34,521 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4662990895184604, 'Total loss': 0.4662990895184604} | train loss {'Reaction outcome loss': 0.3146235261036425, 'Total loss': 0.3146235261036425}
2022-11-28 02:59:34,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:34,521 INFO:     Epoch: 51
2022-11-28 02:59:35,260 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42950997298414056, 'Total loss': 0.42950997298414056} | train loss {'Reaction outcome loss': 0.32464018575086884, 'Total loss': 0.32464018575086884}
2022-11-28 02:59:35,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:35,260 INFO:     Epoch: 52
2022-11-28 02:59:35,997 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47400571846149187, 'Total loss': 0.47400571846149187} | train loss {'Reaction outcome loss': 0.3189193644998025, 'Total loss': 0.3189193644998025}
2022-11-28 02:59:35,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:35,998 INFO:     Epoch: 53
2022-11-28 02:59:36,737 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44995406981218944, 'Total loss': 0.44995406981218944} | train loss {'Reaction outcome loss': 0.3250190040590812, 'Total loss': 0.3250190040590812}
2022-11-28 02:59:36,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:36,737 INFO:     Epoch: 54
2022-11-28 02:59:37,474 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4313726120374419, 'Total loss': 0.4313726120374419} | train loss {'Reaction outcome loss': 0.31726744092848835, 'Total loss': 0.31726744092848835}
2022-11-28 02:59:37,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:37,474 INFO:     Epoch: 55
2022-11-28 02:59:38,216 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4263602288609201, 'Total loss': 0.4263602288609201} | train loss {'Reaction outcome loss': 0.32817709065821704, 'Total loss': 0.32817709065821704}
2022-11-28 02:59:38,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:38,217 INFO:     Epoch: 56
2022-11-28 02:59:38,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42342955008445476, 'Total loss': 0.42342955008445476} | train loss {'Reaction outcome loss': 0.3177605735708256, 'Total loss': 0.3177605735708256}
2022-11-28 02:59:38,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:38,959 INFO:     Epoch: 57
2022-11-28 02:59:39,700 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4310650901699608, 'Total loss': 0.4310650901699608} | train loss {'Reaction outcome loss': 0.31334709911322106, 'Total loss': 0.31334709911322106}
2022-11-28 02:59:39,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:39,700 INFO:     Epoch: 58
2022-11-28 02:59:40,443 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44006724791093305, 'Total loss': 0.44006724791093305} | train loss {'Reaction outcome loss': 0.3178718736889411, 'Total loss': 0.3178718736889411}
2022-11-28 02:59:40,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:40,443 INFO:     Epoch: 59
2022-11-28 02:59:41,183 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4344821311533451, 'Total loss': 0.4344821311533451} | train loss {'Reaction outcome loss': 0.3194503284838735, 'Total loss': 0.3194503284838735}
2022-11-28 02:59:41,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:41,183 INFO:     Epoch: 60
2022-11-28 02:59:41,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42676974697546527, 'Total loss': 0.42676974697546527} | train loss {'Reaction outcome loss': 0.3233793802711428, 'Total loss': 0.3233793802711428}
2022-11-28 02:59:41,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:41,921 INFO:     Epoch: 61
2022-11-28 02:59:42,660 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4566740295426412, 'Total loss': 0.4566740295426412} | train loss {'Reaction outcome loss': 0.31451679078900086, 'Total loss': 0.31451679078900086}
2022-11-28 02:59:42,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:42,661 INFO:     Epoch: 62
2022-11-28 02:59:43,401 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44108311855234206, 'Total loss': 0.44108311855234206} | train loss {'Reaction outcome loss': 0.3220064805478466, 'Total loss': 0.3220064805478466}
2022-11-28 02:59:43,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:43,401 INFO:     Epoch: 63
2022-11-28 02:59:44,141 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45564441064330324, 'Total loss': 0.45564441064330324} | train loss {'Reaction outcome loss': 0.32436895543823435, 'Total loss': 0.32436895543823435}
2022-11-28 02:59:44,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:44,142 INFO:     Epoch: 64
2022-11-28 02:59:44,879 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45026303082704544, 'Total loss': 0.45026303082704544} | train loss {'Reaction outcome loss': 0.3117152622463752, 'Total loss': 0.3117152622463752}
2022-11-28 02:59:44,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:44,880 INFO:     Epoch: 65
2022-11-28 02:59:45,621 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4415501478043469, 'Total loss': 0.4415501478043469} | train loss {'Reaction outcome loss': 0.3198688452949329, 'Total loss': 0.3198688452949329}
2022-11-28 02:59:45,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:45,621 INFO:     Epoch: 66
2022-11-28 02:59:46,363 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4623612212863835, 'Total loss': 0.4623612212863835} | train loss {'Reaction outcome loss': 0.3246564410778941, 'Total loss': 0.3246564410778941}
2022-11-28 02:59:46,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:46,363 INFO:     Epoch: 67
2022-11-28 02:59:47,103 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4538447613065893, 'Total loss': 0.4538447613065893} | train loss {'Reaction outcome loss': 0.30549405174595967, 'Total loss': 0.30549405174595967}
2022-11-28 02:59:47,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:47,103 INFO:     Epoch: 68
2022-11-28 02:59:47,845 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45464796640656213, 'Total loss': 0.45464796640656213} | train loss {'Reaction outcome loss': 0.3165743788894342, 'Total loss': 0.3165743788894342}
2022-11-28 02:59:47,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:47,845 INFO:     Epoch: 69
2022-11-28 02:59:48,584 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45289113304831763, 'Total loss': 0.45289113304831763} | train loss {'Reaction outcome loss': 0.3243811417903219, 'Total loss': 0.3243811417903219}
2022-11-28 02:59:48,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:48,585 INFO:     Epoch: 70
2022-11-28 02:59:49,323 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4593042175878178, 'Total loss': 0.4593042175878178} | train loss {'Reaction outcome loss': 0.31056782536360683, 'Total loss': 0.31056782536360683}
2022-11-28 02:59:49,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:49,324 INFO:     Epoch: 71
2022-11-28 02:59:50,063 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4524962194263935, 'Total loss': 0.4524962194263935} | train loss {'Reaction outcome loss': 0.3248934188667609, 'Total loss': 0.3248934188667609}
2022-11-28 02:59:50,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:50,063 INFO:     Epoch: 72
2022-11-28 02:59:50,803 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42355998436158354, 'Total loss': 0.42355998436158354} | train loss {'Reaction outcome loss': 0.3159947441548717, 'Total loss': 0.3159947441548717}
2022-11-28 02:59:50,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:50,803 INFO:     Epoch: 73
2022-11-28 02:59:51,545 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4571804024956443, 'Total loss': 0.4571804024956443} | train loss {'Reaction outcome loss': 0.30995353435983464, 'Total loss': 0.30995353435983464}
2022-11-28 02:59:51,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:51,545 INFO:     Epoch: 74
2022-11-28 02:59:52,285 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45703567056493327, 'Total loss': 0.45703567056493327} | train loss {'Reaction outcome loss': 0.317971576324531, 'Total loss': 0.317971576324531}
2022-11-28 02:59:52,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:52,286 INFO:     Epoch: 75
2022-11-28 02:59:53,026 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4823955703865398, 'Total loss': 0.4823955703865398} | train loss {'Reaction outcome loss': 0.3142370039711193, 'Total loss': 0.3142370039711193}
2022-11-28 02:59:53,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:53,026 INFO:     Epoch: 76
2022-11-28 02:59:53,768 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4401181526482105, 'Total loss': 0.4401181526482105} | train loss {'Reaction outcome loss': 0.3147849519642032, 'Total loss': 0.3147849519642032}
2022-11-28 02:59:53,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:53,769 INFO:     Epoch: 77
2022-11-28 02:59:54,509 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42949008907784114, 'Total loss': 0.42949008907784114} | train loss {'Reaction outcome loss': 0.31833177984369043, 'Total loss': 0.31833177984369043}
2022-11-28 02:59:54,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:54,510 INFO:     Epoch: 78
2022-11-28 02:59:55,254 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4476955285803838, 'Total loss': 0.4476955285803838} | train loss {'Reaction outcome loss': 0.3124829438267922, 'Total loss': 0.3124829438267922}
2022-11-28 02:59:55,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:55,254 INFO:     Epoch: 79
2022-11-28 02:59:55,996 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44928007843819534, 'Total loss': 0.44928007843819534} | train loss {'Reaction outcome loss': 0.3131696668206429, 'Total loss': 0.3131696668206429}
2022-11-28 02:59:55,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:55,996 INFO:     Epoch: 80
2022-11-28 02:59:56,737 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4339693994684653, 'Total loss': 0.4339693994684653} | train loss {'Reaction outcome loss': 0.3110643624042978, 'Total loss': 0.3110643624042978}
2022-11-28 02:59:56,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:56,737 INFO:     Epoch: 81
2022-11-28 02:59:57,477 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5079694923690774, 'Total loss': 0.5079694923690774} | train loss {'Reaction outcome loss': 0.31176013350486753, 'Total loss': 0.31176013350486753}
2022-11-28 02:59:57,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:57,478 INFO:     Epoch: 82
2022-11-28 02:59:58,219 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4834040708162568, 'Total loss': 0.4834040708162568} | train loss {'Reaction outcome loss': 0.314055894041548, 'Total loss': 0.314055894041548}
2022-11-28 02:59:58,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:58,219 INFO:     Epoch: 83
2022-11-28 02:59:58,960 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4386988128112121, 'Total loss': 0.4386988128112121} | train loss {'Reaction outcome loss': 0.32155298386909525, 'Total loss': 0.32155298386909525}
2022-11-28 02:59:58,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:58,960 INFO:     Epoch: 84
2022-11-28 02:59:59,698 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4360933151434768, 'Total loss': 0.4360933151434768} | train loss {'Reaction outcome loss': 0.3211883147760313, 'Total loss': 0.3211883147760313}
2022-11-28 02:59:59,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 02:59:59,698 INFO:     Epoch: 85
2022-11-28 03:00:00,438 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4313741307705641, 'Total loss': 0.4313741307705641} | train loss {'Reaction outcome loss': 0.3071151350681879, 'Total loss': 0.3071151350681879}
2022-11-28 03:00:00,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:00,438 INFO:     Epoch: 86
2022-11-28 03:00:01,180 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4385090091011741, 'Total loss': 0.4385090091011741} | train loss {'Reaction outcome loss': 0.32074832989245045, 'Total loss': 0.32074832989245045}
2022-11-28 03:00:01,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:01,180 INFO:     Epoch: 87
2022-11-28 03:00:01,920 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4260945086452094, 'Total loss': 0.4260945086452094} | train loss {'Reaction outcome loss': 0.2973728477346654, 'Total loss': 0.2973728477346654}
2022-11-28 03:00:01,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:01,920 INFO:     Epoch: 88
2022-11-28 03:00:02,656 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4769758944484321, 'Total loss': 0.4769758944484321} | train loss {'Reaction outcome loss': 0.3059103994649284, 'Total loss': 0.3059103994649284}
2022-11-28 03:00:02,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:02,657 INFO:     Epoch: 89
2022-11-28 03:00:03,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4460390327413651, 'Total loss': 0.4460390327413651} | train loss {'Reaction outcome loss': 0.31000120022467204, 'Total loss': 0.31000120022467204}
2022-11-28 03:00:03,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:03,394 INFO:     Epoch: 90
2022-11-28 03:00:04,130 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43194799599322403, 'Total loss': 0.43194799599322403} | train loss {'Reaction outcome loss': 0.308757401637885, 'Total loss': 0.308757401637885}
2022-11-28 03:00:04,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:04,130 INFO:     Epoch: 91
2022-11-28 03:00:04,867 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4517117054624991, 'Total loss': 0.4517117054624991} | train loss {'Reaction outcome loss': 0.3094460372718013, 'Total loss': 0.3094460372718013}
2022-11-28 03:00:04,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:04,868 INFO:     Epoch: 92
2022-11-28 03:00:05,609 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43508398363536055, 'Total loss': 0.43508398363536055} | train loss {'Reaction outcome loss': 0.3158096932026805, 'Total loss': 0.3158096932026805}
2022-11-28 03:00:05,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:05,609 INFO:     Epoch: 93
2022-11-28 03:00:06,347 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4515181769701568, 'Total loss': 0.4515181769701568} | train loss {'Reaction outcome loss': 0.3175007113084501, 'Total loss': 0.3175007113084501}
2022-11-28 03:00:06,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:06,348 INFO:     Epoch: 94
2022-11-28 03:00:07,088 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45487511733716185, 'Total loss': 0.45487511733716185} | train loss {'Reaction outcome loss': 0.30139223209449223, 'Total loss': 0.30139223209449223}
2022-11-28 03:00:07,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:07,088 INFO:     Epoch: 95
2022-11-28 03:00:07,825 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44333215498111467, 'Total loss': 0.44333215498111467} | train loss {'Reaction outcome loss': 0.30236623775289984, 'Total loss': 0.30236623775289984}
2022-11-28 03:00:07,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:07,826 INFO:     Epoch: 96
2022-11-28 03:00:08,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4276009957221421, 'Total loss': 0.4276009957221421} | train loss {'Reaction outcome loss': 0.3120722328217662, 'Total loss': 0.3120722328217662}
2022-11-28 03:00:08,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:08,570 INFO:     Epoch: 97
2022-11-28 03:00:09,313 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49843911454081535, 'Total loss': 0.49843911454081535} | train loss {'Reaction outcome loss': 0.3104220307299069, 'Total loss': 0.3104220307299069}
2022-11-28 03:00:09,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:09,314 INFO:     Epoch: 98
2022-11-28 03:00:10,056 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45704578913070937, 'Total loss': 0.45704578913070937} | train loss {'Reaction outcome loss': 0.30291409963855936, 'Total loss': 0.30291409963855936}
2022-11-28 03:00:10,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:10,056 INFO:     Epoch: 99
2022-11-28 03:00:10,799 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4309899353168227, 'Total loss': 0.4309899353168227} | train loss {'Reaction outcome loss': 0.31886352984880917, 'Total loss': 0.31886352984880917}
2022-11-28 03:00:10,799 INFO:     Best model found after epoch 19 of 100.
2022-11-28 03:00:10,799 INFO:   Done with stage: TRAINING
2022-11-28 03:00:10,799 INFO:   Starting stage: EVALUATION
2022-11-28 03:00:10,925 INFO:   Done with stage: EVALUATION
2022-11-28 03:00:10,925 INFO:   Leaving out SEQ value Fold_2
2022-11-28 03:00:10,938 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 03:00:10,939 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:00:11,582 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:00:11,583 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:00:11,649 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:00:11,649 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:00:11,649 INFO:     No hyperparam tuning for this model
2022-11-28 03:00:11,650 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:00:11,650 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:00:11,650 INFO:     None feature selector for col prot
2022-11-28 03:00:11,650 INFO:     None feature selector for col prot
2022-11-28 03:00:11,650 INFO:     None feature selector for col prot
2022-11-28 03:00:11,651 INFO:     None feature selector for col chem
2022-11-28 03:00:11,651 INFO:     None feature selector for col chem
2022-11-28 03:00:11,651 INFO:     None feature selector for col chem
2022-11-28 03:00:11,651 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:00:11,651 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:00:11,653 INFO:     Number of params in model 169741
2022-11-28 03:00:11,656 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:00:11,656 INFO:   Starting stage: TRAINING
2022-11-28 03:00:11,708 INFO:     Val loss before train {'Reaction outcome loss': 0.968809959500335, 'Total loss': 0.968809959500335}
2022-11-28 03:00:11,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:11,708 INFO:     Epoch: 0
2022-11-28 03:00:12,444 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5552983443404353, 'Total loss': 0.5552983443404353} | train loss {'Reaction outcome loss': 0.6456099481123393, 'Total loss': 0.6456099481123393}
2022-11-28 03:00:12,444 INFO:     Found new best model at epoch 0
2022-11-28 03:00:12,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:12,445 INFO:     Epoch: 1
2022-11-28 03:00:13,179 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5203281571698744, 'Total loss': 0.5203281571698744} | train loss {'Reaction outcome loss': 0.5007367775943435, 'Total loss': 0.5007367775943435}
2022-11-28 03:00:13,180 INFO:     Found new best model at epoch 1
2022-11-28 03:00:13,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:13,180 INFO:     Epoch: 2
2022-11-28 03:00:13,922 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4999212137488432, 'Total loss': 0.4999212137488432} | train loss {'Reaction outcome loss': 0.46298365942278846, 'Total loss': 0.46298365942278846}
2022-11-28 03:00:13,923 INFO:     Found new best model at epoch 2
2022-11-28 03:00:13,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:13,923 INFO:     Epoch: 3
2022-11-28 03:00:14,657 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48474424869515176, 'Total loss': 0.48474424869515176} | train loss {'Reaction outcome loss': 0.44324200093501903, 'Total loss': 0.44324200093501903}
2022-11-28 03:00:14,657 INFO:     Found new best model at epoch 3
2022-11-28 03:00:14,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:14,658 INFO:     Epoch: 4
2022-11-28 03:00:15,401 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4814384371735329, 'Total loss': 0.4814384371735329} | train loss {'Reaction outcome loss': 0.4240983023506696, 'Total loss': 0.4240983023506696}
2022-11-28 03:00:15,402 INFO:     Found new best model at epoch 4
2022-11-28 03:00:15,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:15,402 INFO:     Epoch: 5
2022-11-28 03:00:16,137 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4555827663388363, 'Total loss': 0.4555827663388363} | train loss {'Reaction outcome loss': 0.41203695007401414, 'Total loss': 0.41203695007401414}
2022-11-28 03:00:16,137 INFO:     Found new best model at epoch 5
2022-11-28 03:00:16,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:16,138 INFO:     Epoch: 6
2022-11-28 03:00:16,872 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4689911919277768, 'Total loss': 0.4689911919277768} | train loss {'Reaction outcome loss': 0.4024415870853623, 'Total loss': 0.4024415870853623}
2022-11-28 03:00:16,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:16,872 INFO:     Epoch: 7
2022-11-28 03:00:17,613 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4653204059184984, 'Total loss': 0.4653204059184984} | train loss {'Reaction outcome loss': 0.3921441598566341, 'Total loss': 0.3921441598566341}
2022-11-28 03:00:17,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:17,613 INFO:     Epoch: 8
2022-11-28 03:00:18,351 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46890084168245627, 'Total loss': 0.46890084168245627} | train loss {'Reaction outcome loss': 0.38777423045430026, 'Total loss': 0.38777423045430026}
2022-11-28 03:00:18,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:18,352 INFO:     Epoch: 9
2022-11-28 03:00:19,087 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45919396918873456, 'Total loss': 0.45919396918873456} | train loss {'Reaction outcome loss': 0.3807298751456327, 'Total loss': 0.3807298751456327}
2022-11-28 03:00:19,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:19,087 INFO:     Epoch: 10
2022-11-28 03:00:19,822 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4535369907700738, 'Total loss': 0.4535369907700738} | train loss {'Reaction outcome loss': 0.3805595529189364, 'Total loss': 0.3805595529189364}
2022-11-28 03:00:19,822 INFO:     Found new best model at epoch 10
2022-11-28 03:00:19,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:19,823 INFO:     Epoch: 11
2022-11-28 03:00:20,557 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4554162590309631, 'Total loss': 0.4554162590309631} | train loss {'Reaction outcome loss': 0.3723085928158682, 'Total loss': 0.3723085928158682}
2022-11-28 03:00:20,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:20,557 INFO:     Epoch: 12
2022-11-28 03:00:21,292 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45102760611578474, 'Total loss': 0.45102760611578474} | train loss {'Reaction outcome loss': 0.3633121039535179, 'Total loss': 0.3633121039535179}
2022-11-28 03:00:21,292 INFO:     Found new best model at epoch 12
2022-11-28 03:00:21,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:21,293 INFO:     Epoch: 13
2022-11-28 03:00:22,025 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46024583349394244, 'Total loss': 0.46024583349394244} | train loss {'Reaction outcome loss': 0.3646780212455597, 'Total loss': 0.3646780212455597}
2022-11-28 03:00:22,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:22,025 INFO:     Epoch: 14
2022-11-28 03:00:22,756 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4735845919958381, 'Total loss': 0.4735845919958381} | train loss {'Reaction outcome loss': 0.3634196907648298, 'Total loss': 0.3634196907648298}
2022-11-28 03:00:22,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:22,756 INFO:     Epoch: 15
2022-11-28 03:00:23,490 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45180164450822874, 'Total loss': 0.45180164450822874} | train loss {'Reaction outcome loss': 0.3619331644206751, 'Total loss': 0.3619331644206751}
2022-11-28 03:00:23,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:23,490 INFO:     Epoch: 16
2022-11-28 03:00:24,226 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4364298336034597, 'Total loss': 0.4364298336034597} | train loss {'Reaction outcome loss': 0.36206321216753273, 'Total loss': 0.36206321216753273}
2022-11-28 03:00:24,227 INFO:     Found new best model at epoch 16
2022-11-28 03:00:24,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:24,227 INFO:     Epoch: 17
2022-11-28 03:00:24,962 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45290737789730695, 'Total loss': 0.45290737789730695} | train loss {'Reaction outcome loss': 0.35797190770018295, 'Total loss': 0.35797190770018295}
2022-11-28 03:00:24,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:24,962 INFO:     Epoch: 18
2022-11-28 03:00:25,700 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45092340333517206, 'Total loss': 0.45092340333517206} | train loss {'Reaction outcome loss': 0.3552252366283878, 'Total loss': 0.3552252366283878}
2022-11-28 03:00:25,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:25,700 INFO:     Epoch: 19
2022-11-28 03:00:26,438 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4512880149968835, 'Total loss': 0.4512880149968835} | train loss {'Reaction outcome loss': 0.35173407026001663, 'Total loss': 0.35173407026001663}
2022-11-28 03:00:26,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:26,439 INFO:     Epoch: 20
2022-11-28 03:00:27,173 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42838685249173364, 'Total loss': 0.42838685249173364} | train loss {'Reaction outcome loss': 0.352884641466815, 'Total loss': 0.352884641466815}
2022-11-28 03:00:27,173 INFO:     Found new best model at epoch 20
2022-11-28 03:00:27,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:27,174 INFO:     Epoch: 21
2022-11-28 03:00:27,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43454505641793095, 'Total loss': 0.43454505641793095} | train loss {'Reaction outcome loss': 0.35702279784151764, 'Total loss': 0.35702279784151764}
2022-11-28 03:00:27,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:27,910 INFO:     Epoch: 22
2022-11-28 03:00:28,648 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4423098699298016, 'Total loss': 0.4423098699298016} | train loss {'Reaction outcome loss': 0.3457634372972563, 'Total loss': 0.3457634372972563}
2022-11-28 03:00:28,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:28,649 INFO:     Epoch: 23
2022-11-28 03:00:29,385 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4644816542087599, 'Total loss': 0.4644816542087599} | train loss {'Reaction outcome loss': 0.3531912674241867, 'Total loss': 0.3531912674241867}
2022-11-28 03:00:29,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:29,385 INFO:     Epoch: 24
2022-11-28 03:00:30,121 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4624014523660028, 'Total loss': 0.4624014523660028} | train loss {'Reaction outcome loss': 0.34691801438199693, 'Total loss': 0.34691801438199693}
2022-11-28 03:00:30,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:30,122 INFO:     Epoch: 25
2022-11-28 03:00:30,859 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4377353530983592, 'Total loss': 0.4377353530983592} | train loss {'Reaction outcome loss': 0.34227844138370184, 'Total loss': 0.34227844138370184}
2022-11-28 03:00:30,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:30,859 INFO:     Epoch: 26
2022-11-28 03:00:31,597 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46354012884372886, 'Total loss': 0.46354012884372886} | train loss {'Reaction outcome loss': 0.34188661348746446, 'Total loss': 0.34188661348746446}
2022-11-28 03:00:31,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:31,597 INFO:     Epoch: 27
2022-11-28 03:00:32,332 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4475370479184528, 'Total loss': 0.4475370479184528} | train loss {'Reaction outcome loss': 0.33771875900689696, 'Total loss': 0.33771875900689696}
2022-11-28 03:00:32,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:32,332 INFO:     Epoch: 28
2022-11-28 03:00:33,071 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4424329850562783, 'Total loss': 0.4424329850562783} | train loss {'Reaction outcome loss': 0.3359839471026522, 'Total loss': 0.3359839471026522}
2022-11-28 03:00:33,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:33,072 INFO:     Epoch: 29
2022-11-28 03:00:33,810 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4704299988441689, 'Total loss': 0.4704299988441689} | train loss {'Reaction outcome loss': 0.3406789012436495, 'Total loss': 0.3406789012436495}
2022-11-28 03:00:33,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:33,810 INFO:     Epoch: 30
2022-11-28 03:00:34,548 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43618571758270264, 'Total loss': 0.43618571758270264} | train loss {'Reaction outcome loss': 0.34229661890717805, 'Total loss': 0.34229661890717805}
2022-11-28 03:00:34,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:34,548 INFO:     Epoch: 31
2022-11-28 03:00:35,280 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4564703973226769, 'Total loss': 0.4564703973226769} | train loss {'Reaction outcome loss': 0.33976312546578585, 'Total loss': 0.33976312546578585}
2022-11-28 03:00:35,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:35,280 INFO:     Epoch: 32
2022-11-28 03:00:36,013 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4447259840577148, 'Total loss': 0.4447259840577148} | train loss {'Reaction outcome loss': 0.33113370838834616, 'Total loss': 0.33113370838834616}
2022-11-28 03:00:36,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:36,014 INFO:     Epoch: 33
2022-11-28 03:00:36,746 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44777496748192364, 'Total loss': 0.44777496748192364} | train loss {'Reaction outcome loss': 0.3310624052633028, 'Total loss': 0.3310624052633028}
2022-11-28 03:00:36,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:36,746 INFO:     Epoch: 34
2022-11-28 03:00:37,480 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46853640952775644, 'Total loss': 0.46853640952775644} | train loss {'Reaction outcome loss': 0.3330374442224131, 'Total loss': 0.3330374442224131}
2022-11-28 03:00:37,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:37,480 INFO:     Epoch: 35
2022-11-28 03:00:38,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4235957504011864, 'Total loss': 0.4235957504011864} | train loss {'Reaction outcome loss': 0.3277530546956619, 'Total loss': 0.3277530546956619}
2022-11-28 03:00:38,214 INFO:     Found new best model at epoch 35
2022-11-28 03:00:38,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:38,215 INFO:     Epoch: 36
2022-11-28 03:00:38,947 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44829166108785673, 'Total loss': 0.44829166108785673} | train loss {'Reaction outcome loss': 0.32235371397777657, 'Total loss': 0.32235371397777657}
2022-11-28 03:00:38,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:38,947 INFO:     Epoch: 37
2022-11-28 03:00:39,681 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43399162729119145, 'Total loss': 0.43399162729119145} | train loss {'Reaction outcome loss': 0.3342035489431659, 'Total loss': 0.3342035489431659}
2022-11-28 03:00:39,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:39,682 INFO:     Epoch: 38
2022-11-28 03:00:40,417 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42988967479661455, 'Total loss': 0.42988967479661455} | train loss {'Reaction outcome loss': 0.32439168023525694, 'Total loss': 0.32439168023525694}
2022-11-28 03:00:40,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:40,418 INFO:     Epoch: 39
2022-11-28 03:00:41,157 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42281356419241706, 'Total loss': 0.42281356419241706} | train loss {'Reaction outcome loss': 0.32396972011469427, 'Total loss': 0.32396972011469427}
2022-11-28 03:00:41,157 INFO:     Found new best model at epoch 39
2022-11-28 03:00:41,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:41,158 INFO:     Epoch: 40
2022-11-28 03:00:41,896 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44879032948682474, 'Total loss': 0.44879032948682474} | train loss {'Reaction outcome loss': 0.3346078821503725, 'Total loss': 0.3346078821503725}
2022-11-28 03:00:41,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:41,896 INFO:     Epoch: 41
2022-11-28 03:00:42,632 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4435974356046943, 'Total loss': 0.4435974356046943} | train loss {'Reaction outcome loss': 0.3155985838412994, 'Total loss': 0.3155985838412994}
2022-11-28 03:00:42,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:42,632 INFO:     Epoch: 42
2022-11-28 03:00:43,369 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4865835648636485, 'Total loss': 0.4865835648636485} | train loss {'Reaction outcome loss': 0.3230294064756055, 'Total loss': 0.3230294064756055}
2022-11-28 03:00:43,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:43,369 INFO:     Epoch: 43
2022-11-28 03:00:44,107 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44933848533519477, 'Total loss': 0.44933848533519477} | train loss {'Reaction outcome loss': 0.3268762491643429, 'Total loss': 0.3268762491643429}
2022-11-28 03:00:44,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:44,108 INFO:     Epoch: 44
2022-11-28 03:00:44,843 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4189653521360353, 'Total loss': 0.4189653521360353} | train loss {'Reaction outcome loss': 0.32283272685818987, 'Total loss': 0.32283272685818987}
2022-11-28 03:00:44,843 INFO:     Found new best model at epoch 44
2022-11-28 03:00:44,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:44,844 INFO:     Epoch: 45
2022-11-28 03:00:45,579 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4627389277136603, 'Total loss': 0.4627389277136603} | train loss {'Reaction outcome loss': 0.3241755953211276, 'Total loss': 0.3241755953211276}
2022-11-28 03:00:45,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:45,580 INFO:     Epoch: 46
2022-11-28 03:00:46,317 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4347431503756102, 'Total loss': 0.4347431503756102} | train loss {'Reaction outcome loss': 0.3232942554244741, 'Total loss': 0.3232942554244741}
2022-11-28 03:00:46,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:46,317 INFO:     Epoch: 47
2022-11-28 03:00:47,053 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.439740193964437, 'Total loss': 0.439740193964437} | train loss {'Reaction outcome loss': 0.32193977141478025, 'Total loss': 0.32193977141478025}
2022-11-28 03:00:47,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:47,054 INFO:     Epoch: 48
2022-11-28 03:00:47,793 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4456391584041507, 'Total loss': 0.4456391584041507} | train loss {'Reaction outcome loss': 0.3212149660484713, 'Total loss': 0.3212149660484713}
2022-11-28 03:00:47,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:47,793 INFO:     Epoch: 49
2022-11-28 03:00:48,528 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4287355687729148, 'Total loss': 0.4287355687729148} | train loss {'Reaction outcome loss': 0.32884259231877133, 'Total loss': 0.32884259231877133}
2022-11-28 03:00:48,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:48,528 INFO:     Epoch: 50
2022-11-28 03:00:49,262 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4303819183693376, 'Total loss': 0.4303819183693376} | train loss {'Reaction outcome loss': 0.3246642521536741, 'Total loss': 0.3246642521536741}
2022-11-28 03:00:49,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:49,262 INFO:     Epoch: 51
2022-11-28 03:00:49,995 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4366404864677163, 'Total loss': 0.4366404864677163} | train loss {'Reaction outcome loss': 0.3242647246320228, 'Total loss': 0.3242647246320228}
2022-11-28 03:00:49,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:49,996 INFO:     Epoch: 52
2022-11-28 03:00:50,731 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44932779843030973, 'Total loss': 0.44932779843030973} | train loss {'Reaction outcome loss': 0.32930119311223266, 'Total loss': 0.32930119311223266}
2022-11-28 03:00:50,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:50,731 INFO:     Epoch: 53
2022-11-28 03:00:51,467 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4400316006395706, 'Total loss': 0.4400316006395706} | train loss {'Reaction outcome loss': 0.31573302408710857, 'Total loss': 0.31573302408710857}
2022-11-28 03:00:51,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:51,467 INFO:     Epoch: 54
2022-11-28 03:00:52,200 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.459217979984228, 'Total loss': 0.459217979984228} | train loss {'Reaction outcome loss': 0.3207809515908116, 'Total loss': 0.3207809515908116}
2022-11-28 03:00:52,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:52,200 INFO:     Epoch: 55
2022-11-28 03:00:52,933 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4237814722366111, 'Total loss': 0.4237814722366111} | train loss {'Reaction outcome loss': 0.32003474754632494, 'Total loss': 0.32003474754632494}
2022-11-28 03:00:52,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:52,934 INFO:     Epoch: 56
2022-11-28 03:00:53,670 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45438031332437384, 'Total loss': 0.45438031332437384} | train loss {'Reaction outcome loss': 0.32090817164385416, 'Total loss': 0.32090817164385416}
2022-11-28 03:00:53,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:53,670 INFO:     Epoch: 57
2022-11-28 03:00:54,408 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4384750481261763, 'Total loss': 0.4384750481261763} | train loss {'Reaction outcome loss': 0.31582548655569553, 'Total loss': 0.31582548655569553}
2022-11-28 03:00:54,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:54,408 INFO:     Epoch: 58
2022-11-28 03:00:55,148 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.461064827996631, 'Total loss': 0.461064827996631} | train loss {'Reaction outcome loss': 0.31716215488363486, 'Total loss': 0.31716215488363486}
2022-11-28 03:00:55,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:55,148 INFO:     Epoch: 59
2022-11-28 03:00:55,884 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45793889774832613, 'Total loss': 0.45793889774832613} | train loss {'Reaction outcome loss': 0.31824737142954695, 'Total loss': 0.31824737142954695}
2022-11-28 03:00:55,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:55,884 INFO:     Epoch: 60
2022-11-28 03:00:56,623 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4514094248067501, 'Total loss': 0.4514094248067501} | train loss {'Reaction outcome loss': 0.3198881525790594, 'Total loss': 0.3198881525790594}
2022-11-28 03:00:56,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:56,623 INFO:     Epoch: 61
2022-11-28 03:00:57,363 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4198050429654676, 'Total loss': 0.4198050429654676} | train loss {'Reaction outcome loss': 0.3223605755960844, 'Total loss': 0.3223605755960844}
2022-11-28 03:00:57,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:57,363 INFO:     Epoch: 62
2022-11-28 03:00:58,098 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4081241741429928, 'Total loss': 0.4081241741429928} | train loss {'Reaction outcome loss': 0.3182571778440329, 'Total loss': 0.3182571778440329}
2022-11-28 03:00:58,099 INFO:     Found new best model at epoch 62
2022-11-28 03:00:58,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:58,099 INFO:     Epoch: 63
2022-11-28 03:00:58,836 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41942692461401915, 'Total loss': 0.41942692461401915} | train loss {'Reaction outcome loss': 0.3058833605075469, 'Total loss': 0.3058833605075469}
2022-11-28 03:00:58,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:58,836 INFO:     Epoch: 64
2022-11-28 03:00:59,575 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4413007660660633, 'Total loss': 0.4413007660660633} | train loss {'Reaction outcome loss': 0.3072032849380716, 'Total loss': 0.3072032849380716}
2022-11-28 03:00:59,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:00:59,576 INFO:     Epoch: 65
2022-11-28 03:01:00,310 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4330057707983394, 'Total loss': 0.4330057707983394} | train loss {'Reaction outcome loss': 0.3155846713019199, 'Total loss': 0.3155846713019199}
2022-11-28 03:01:00,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:00,310 INFO:     Epoch: 66
2022-11-28 03:01:01,044 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4314385146595711, 'Total loss': 0.4314385146595711} | train loss {'Reaction outcome loss': 0.31567602442791226, 'Total loss': 0.31567602442791226}
2022-11-28 03:01:01,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:01,044 INFO:     Epoch: 67
2022-11-28 03:01:01,780 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43850640935260193, 'Total loss': 0.43850640935260193} | train loss {'Reaction outcome loss': 0.31226886253132197, 'Total loss': 0.31226886253132197}
2022-11-28 03:01:01,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:01,780 INFO:     Epoch: 68
2022-11-28 03:01:02,516 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41586094748142155, 'Total loss': 0.41586094748142155} | train loss {'Reaction outcome loss': 0.32248274890370054, 'Total loss': 0.32248274890370054}
2022-11-28 03:01:02,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:02,516 INFO:     Epoch: 69
2022-11-28 03:01:03,250 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4376986919100894, 'Total loss': 0.4376986919100894} | train loss {'Reaction outcome loss': 0.31864945741645134, 'Total loss': 0.31864945741645134}
2022-11-28 03:01:03,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:03,251 INFO:     Epoch: 70
2022-11-28 03:01:03,985 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4558459371328354, 'Total loss': 0.4558459371328354} | train loss {'Reaction outcome loss': 0.3258178612736405, 'Total loss': 0.3258178612736405}
2022-11-28 03:01:03,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:03,986 INFO:     Epoch: 71
2022-11-28 03:01:04,721 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46782093651072926, 'Total loss': 0.46782093651072926} | train loss {'Reaction outcome loss': 0.3075543073784621, 'Total loss': 0.3075543073784621}
2022-11-28 03:01:04,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:04,722 INFO:     Epoch: 72
2022-11-28 03:01:05,456 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45024443539076076, 'Total loss': 0.45024443539076076} | train loss {'Reaction outcome loss': 0.31986645120577734, 'Total loss': 0.31986645120577734}
2022-11-28 03:01:05,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:05,456 INFO:     Epoch: 73
2022-11-28 03:01:06,191 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4336324365333069, 'Total loss': 0.4336324365333069} | train loss {'Reaction outcome loss': 0.31779933391047305, 'Total loss': 0.31779933391047305}
2022-11-28 03:01:06,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:06,191 INFO:     Epoch: 74
2022-11-28 03:01:06,927 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42520885949217996, 'Total loss': 0.42520885949217996} | train loss {'Reaction outcome loss': 0.308957826712581, 'Total loss': 0.308957826712581}
2022-11-28 03:01:06,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:06,927 INFO:     Epoch: 75
2022-11-28 03:01:07,665 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42354054939608243, 'Total loss': 0.42354054939608243} | train loss {'Reaction outcome loss': 0.3125873201175547, 'Total loss': 0.3125873201175547}
2022-11-28 03:01:07,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:07,666 INFO:     Epoch: 76
2022-11-28 03:01:08,401 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4468095609268477, 'Total loss': 0.4468095609268477} | train loss {'Reaction outcome loss': 0.3114975772065217, 'Total loss': 0.3114975772065217}
2022-11-28 03:01:08,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:08,401 INFO:     Epoch: 77
2022-11-28 03:01:09,137 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4252829350704371, 'Total loss': 0.4252829350704371} | train loss {'Reaction outcome loss': 0.31461330445208513, 'Total loss': 0.31461330445208513}
2022-11-28 03:01:09,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:09,137 INFO:     Epoch: 78
2022-11-28 03:01:09,869 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42393368621205174, 'Total loss': 0.42393368621205174} | train loss {'Reaction outcome loss': 0.31903957184709486, 'Total loss': 0.31903957184709486}
2022-11-28 03:01:09,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:09,870 INFO:     Epoch: 79
2022-11-28 03:01:10,604 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45773361242094707, 'Total loss': 0.45773361242094707} | train loss {'Reaction outcome loss': 0.3101353036758841, 'Total loss': 0.3101353036758841}
2022-11-28 03:01:10,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:10,604 INFO:     Epoch: 80
2022-11-28 03:01:11,338 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44567460202893544, 'Total loss': 0.44567460202893544} | train loss {'Reaction outcome loss': 0.31244511129792596, 'Total loss': 0.31244511129792596}
2022-11-28 03:01:11,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:11,339 INFO:     Epoch: 81
2022-11-28 03:01:12,074 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4470184875089069, 'Total loss': 0.4470184875089069} | train loss {'Reaction outcome loss': 0.31873541013872037, 'Total loss': 0.31873541013872037}
2022-11-28 03:01:12,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:12,074 INFO:     Epoch: 82
2022-11-28 03:01:12,813 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.467473047070725, 'Total loss': 0.467473047070725} | train loss {'Reaction outcome loss': 0.31297683059314235, 'Total loss': 0.31297683059314235}
2022-11-28 03:01:12,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:12,814 INFO:     Epoch: 83
2022-11-28 03:01:13,548 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4362737995594047, 'Total loss': 0.4362737995594047} | train loss {'Reaction outcome loss': 0.3144109248504287, 'Total loss': 0.3144109248504287}
2022-11-28 03:01:13,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:13,548 INFO:     Epoch: 84
2022-11-28 03:01:14,282 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4397126344400783, 'Total loss': 0.4397126344400783} | train loss {'Reaction outcome loss': 0.3225723552655001, 'Total loss': 0.3225723552655001}
2022-11-28 03:01:14,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:14,282 INFO:     Epoch: 85
2022-11-28 03:01:15,016 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4260791054991789, 'Total loss': 0.4260791054991789} | train loss {'Reaction outcome loss': 0.31392581768517125, 'Total loss': 0.31392581768517125}
2022-11-28 03:01:15,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:15,016 INFO:     Epoch: 86
2022-11-28 03:01:15,752 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4237516962511595, 'Total loss': 0.4237516962511595} | train loss {'Reaction outcome loss': 0.31738789910908605, 'Total loss': 0.31738789910908605}
2022-11-28 03:01:15,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:15,753 INFO:     Epoch: 87
2022-11-28 03:01:16,488 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.420040599482004, 'Total loss': 0.420040599482004} | train loss {'Reaction outcome loss': 0.321427849075589, 'Total loss': 0.321427849075589}
2022-11-28 03:01:16,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:16,489 INFO:     Epoch: 88
2022-11-28 03:01:17,237 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4592028367657994, 'Total loss': 0.4592028367657994} | train loss {'Reaction outcome loss': 0.3060879711000646, 'Total loss': 0.3060879711000646}
2022-11-28 03:01:17,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:17,237 INFO:     Epoch: 89
2022-11-28 03:01:17,987 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45786057031431865, 'Total loss': 0.45786057031431865} | train loss {'Reaction outcome loss': 0.3251792506055265, 'Total loss': 0.3251792506055265}
2022-11-28 03:01:17,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:17,988 INFO:     Epoch: 90
2022-11-28 03:01:18,736 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42968551190786586, 'Total loss': 0.42968551190786586} | train loss {'Reaction outcome loss': 0.31450736536415386, 'Total loss': 0.31450736536415386}
2022-11-28 03:01:18,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:18,737 INFO:     Epoch: 91
2022-11-28 03:01:19,487 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44093683639238046, 'Total loss': 0.44093683639238046} | train loss {'Reaction outcome loss': 0.3145354957182388, 'Total loss': 0.3145354957182388}
2022-11-28 03:01:19,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:19,487 INFO:     Epoch: 92
2022-11-28 03:01:20,238 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44963656539140745, 'Total loss': 0.44963656539140745} | train loss {'Reaction outcome loss': 0.3221498290840231, 'Total loss': 0.3221498290840231}
2022-11-28 03:01:20,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:20,238 INFO:     Epoch: 93
2022-11-28 03:01:20,988 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42431807102159014, 'Total loss': 0.42431807102159014} | train loss {'Reaction outcome loss': 0.32201242114066103, 'Total loss': 0.32201242114066103}
2022-11-28 03:01:20,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:20,989 INFO:     Epoch: 94
2022-11-28 03:01:21,737 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4361439766578896, 'Total loss': 0.4361439766578896} | train loss {'Reaction outcome loss': 0.3076098701137988, 'Total loss': 0.3076098701137988}
2022-11-28 03:01:21,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:21,737 INFO:     Epoch: 95
2022-11-28 03:01:22,486 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4387594069852385, 'Total loss': 0.4387594069852385} | train loss {'Reaction outcome loss': 0.30968152771352747, 'Total loss': 0.30968152771352747}
2022-11-28 03:01:22,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:22,486 INFO:     Epoch: 96
2022-11-28 03:01:23,236 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4681242302406666, 'Total loss': 0.4681242302406666} | train loss {'Reaction outcome loss': 0.31441990466269315, 'Total loss': 0.31441990466269315}
2022-11-28 03:01:23,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:23,236 INFO:     Epoch: 97
2022-11-28 03:01:23,985 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4644822738198347, 'Total loss': 0.4644822738198347} | train loss {'Reaction outcome loss': 0.31347603030258514, 'Total loss': 0.31347603030258514}
2022-11-28 03:01:23,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:23,985 INFO:     Epoch: 98
2022-11-28 03:01:24,732 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40291402679543165, 'Total loss': 0.40291402679543165} | train loss {'Reaction outcome loss': 0.31432402729377396, 'Total loss': 0.31432402729377396}
2022-11-28 03:01:24,732 INFO:     Found new best model at epoch 98
2022-11-28 03:01:24,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:24,733 INFO:     Epoch: 99
2022-11-28 03:01:25,471 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42539608305276827, 'Total loss': 0.42539608305276827} | train loss {'Reaction outcome loss': 0.30916610056320665, 'Total loss': 0.30916610056320665}
2022-11-28 03:01:25,471 INFO:     Best model found after epoch 99 of 100.
2022-11-28 03:01:25,472 INFO:   Done with stage: TRAINING
2022-11-28 03:01:25,472 INFO:   Starting stage: EVALUATION
2022-11-28 03:01:25,604 INFO:   Done with stage: EVALUATION
2022-11-28 03:01:25,604 INFO:   Leaving out SEQ value Fold_3
2022-11-28 03:01:25,617 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 03:01:25,617 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:01:26,249 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:01:26,249 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:01:26,318 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:01:26,318 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:01:26,318 INFO:     No hyperparam tuning for this model
2022-11-28 03:01:26,318 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:01:26,318 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:01:26,319 INFO:     None feature selector for col prot
2022-11-28 03:01:26,319 INFO:     None feature selector for col prot
2022-11-28 03:01:26,319 INFO:     None feature selector for col prot
2022-11-28 03:01:26,320 INFO:     None feature selector for col chem
2022-11-28 03:01:26,320 INFO:     None feature selector for col chem
2022-11-28 03:01:26,320 INFO:     None feature selector for col chem
2022-11-28 03:01:26,320 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:01:26,320 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:01:26,322 INFO:     Number of params in model 169741
2022-11-28 03:01:26,325 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:01:26,325 INFO:   Starting stage: TRAINING
2022-11-28 03:01:26,379 INFO:     Val loss before train {'Reaction outcome loss': 1.0005628958690997, 'Total loss': 1.0005628958690997}
2022-11-28 03:01:26,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:26,379 INFO:     Epoch: 0
2022-11-28 03:01:27,119 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5227728770222775, 'Total loss': 0.5227728770222775} | train loss {'Reaction outcome loss': 0.6260007533137916, 'Total loss': 0.6260007533137916}
2022-11-28 03:01:27,119 INFO:     Found new best model at epoch 0
2022-11-28 03:01:27,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:27,120 INFO:     Epoch: 1
2022-11-28 03:01:27,858 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48270385972289154, 'Total loss': 0.48270385972289154} | train loss {'Reaction outcome loss': 0.4876189328974388, 'Total loss': 0.4876189328974388}
2022-11-28 03:01:27,859 INFO:     Found new best model at epoch 1
2022-11-28 03:01:27,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:27,859 INFO:     Epoch: 2
2022-11-28 03:01:28,599 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4625529875588972, 'Total loss': 0.4625529875588972} | train loss {'Reaction outcome loss': 0.4427667299254996, 'Total loss': 0.4427667299254996}
2022-11-28 03:01:28,599 INFO:     Found new best model at epoch 2
2022-11-28 03:01:28,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:28,600 INFO:     Epoch: 3
2022-11-28 03:01:29,335 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4395493327878242, 'Total loss': 0.4395493327878242} | train loss {'Reaction outcome loss': 0.4253730586287184, 'Total loss': 0.4253730586287184}
2022-11-28 03:01:29,336 INFO:     Found new best model at epoch 3
2022-11-28 03:01:29,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:29,336 INFO:     Epoch: 4
2022-11-28 03:01:30,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42344213537005493, 'Total loss': 0.42344213537005493} | train loss {'Reaction outcome loss': 0.4076788738736364, 'Total loss': 0.4076788738736364}
2022-11-28 03:01:30,075 INFO:     Found new best model at epoch 4
2022-11-28 03:01:30,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:30,076 INFO:     Epoch: 5
2022-11-28 03:01:30,812 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4356041696182517, 'Total loss': 0.4356041696182517} | train loss {'Reaction outcome loss': 0.3892470400658299, 'Total loss': 0.3892470400658299}
2022-11-28 03:01:30,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:30,812 INFO:     Epoch: 6
2022-11-28 03:01:31,546 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42076380065707275, 'Total loss': 0.42076380065707275} | train loss {'Reaction outcome loss': 0.3856466295899915, 'Total loss': 0.3856466295899915}
2022-11-28 03:01:31,546 INFO:     Found new best model at epoch 6
2022-11-28 03:01:31,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:31,547 INFO:     Epoch: 7
2022-11-28 03:01:32,282 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4427508548941723, 'Total loss': 0.4427508548941723} | train loss {'Reaction outcome loss': 0.3777915725453955, 'Total loss': 0.3777915725453955}
2022-11-28 03:01:32,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:32,282 INFO:     Epoch: 8
2022-11-28 03:01:33,017 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44456677104151526, 'Total loss': 0.44456677104151526} | train loss {'Reaction outcome loss': 0.37547322090898383, 'Total loss': 0.37547322090898383}
2022-11-28 03:01:33,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:33,017 INFO:     Epoch: 9
2022-11-28 03:01:33,754 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44224904373634694, 'Total loss': 0.44224904373634694} | train loss {'Reaction outcome loss': 0.36375185923620323, 'Total loss': 0.36375185923620323}
2022-11-28 03:01:33,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:33,755 INFO:     Epoch: 10
2022-11-28 03:01:34,494 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41413652342419294, 'Total loss': 0.41413652342419294} | train loss {'Reaction outcome loss': 0.35852225433241147, 'Total loss': 0.35852225433241147}
2022-11-28 03:01:34,494 INFO:     Found new best model at epoch 10
2022-11-28 03:01:34,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:34,495 INFO:     Epoch: 11
2022-11-28 03:01:35,229 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43380565768064455, 'Total loss': 0.43380565768064455} | train loss {'Reaction outcome loss': 0.3519717528805381, 'Total loss': 0.3519717528805381}
2022-11-28 03:01:35,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:35,229 INFO:     Epoch: 12
2022-11-28 03:01:35,964 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4814052761987198, 'Total loss': 0.4814052761987198} | train loss {'Reaction outcome loss': 0.3460560759498936, 'Total loss': 0.3460560759498936}
2022-11-28 03:01:35,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:35,964 INFO:     Epoch: 13
2022-11-28 03:01:36,697 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42683276638042095, 'Total loss': 0.42683276638042095} | train loss {'Reaction outcome loss': 0.34832958927469665, 'Total loss': 0.34832958927469665}
2022-11-28 03:01:36,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:36,697 INFO:     Epoch: 14
2022-11-28 03:01:37,435 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.398399340551953, 'Total loss': 0.398399340551953} | train loss {'Reaction outcome loss': 0.3409042007244024, 'Total loss': 0.3409042007244024}
2022-11-28 03:01:37,435 INFO:     Found new best model at epoch 14
2022-11-28 03:01:37,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:37,436 INFO:     Epoch: 15
2022-11-28 03:01:38,170 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4030363036449565, 'Total loss': 0.4030363036449565} | train loss {'Reaction outcome loss': 0.33839229738614596, 'Total loss': 0.33839229738614596}
2022-11-28 03:01:38,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:38,170 INFO:     Epoch: 16
2022-11-28 03:01:38,901 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3975595880386441, 'Total loss': 0.3975595880386441} | train loss {'Reaction outcome loss': 0.3301495112112311, 'Total loss': 0.3301495112112311}
2022-11-28 03:01:38,901 INFO:     Found new best model at epoch 16
2022-11-28 03:01:38,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:38,902 INFO:     Epoch: 17
2022-11-28 03:01:39,633 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43255112926627315, 'Total loss': 0.43255112926627315} | train loss {'Reaction outcome loss': 0.3297008334765913, 'Total loss': 0.3297008334765913}
2022-11-28 03:01:39,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:39,633 INFO:     Epoch: 18
2022-11-28 03:01:40,362 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40650668012541397, 'Total loss': 0.40650668012541397} | train loss {'Reaction outcome loss': 0.34393635065462747, 'Total loss': 0.34393635065462747}
2022-11-28 03:01:40,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:40,362 INFO:     Epoch: 19
2022-11-28 03:01:41,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.422021143311678, 'Total loss': 0.422021143311678} | train loss {'Reaction outcome loss': 0.33259766530550894, 'Total loss': 0.33259766530550894}
2022-11-28 03:01:41,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:41,095 INFO:     Epoch: 20
2022-11-28 03:01:41,824 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39755738682525105, 'Total loss': 0.39755738682525105} | train loss {'Reaction outcome loss': 0.3318128973306691, 'Total loss': 0.3318128973306691}
2022-11-28 03:01:41,824 INFO:     Found new best model at epoch 20
2022-11-28 03:01:41,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:41,825 INFO:     Epoch: 21
2022-11-28 03:01:42,559 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4427733906479769, 'Total loss': 0.4427733906479769} | train loss {'Reaction outcome loss': 0.3287801266510467, 'Total loss': 0.3287801266510467}
2022-11-28 03:01:42,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:42,560 INFO:     Epoch: 22
2022-11-28 03:01:43,294 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40301707560239836, 'Total loss': 0.40301707560239836} | train loss {'Reaction outcome loss': 0.332028492705011, 'Total loss': 0.332028492705011}
2022-11-28 03:01:43,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:43,294 INFO:     Epoch: 23
2022-11-28 03:01:44,029 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4035947730028352, 'Total loss': 0.4035947730028352} | train loss {'Reaction outcome loss': 0.32451589891045796, 'Total loss': 0.32451589891045796}
2022-11-28 03:01:44,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:44,029 INFO:     Epoch: 24
2022-11-28 03:01:44,759 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4057561332403227, 'Total loss': 0.4057561332403227} | train loss {'Reaction outcome loss': 0.3213496231702996, 'Total loss': 0.3213496231702996}
2022-11-28 03:01:44,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:44,759 INFO:     Epoch: 25
2022-11-28 03:01:45,486 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41117504135120747, 'Total loss': 0.41117504135120747} | train loss {'Reaction outcome loss': 0.3222984313720562, 'Total loss': 0.3222984313720562}
2022-11-28 03:01:45,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:45,487 INFO:     Epoch: 26
2022-11-28 03:01:46,220 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41287457249885384, 'Total loss': 0.41287457249885384} | train loss {'Reaction outcome loss': 0.32159386544686847, 'Total loss': 0.32159386544686847}
2022-11-28 03:01:46,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:46,220 INFO:     Epoch: 27
2022-11-28 03:01:46,955 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41333970254243807, 'Total loss': 0.41333970254243807} | train loss {'Reaction outcome loss': 0.321552700164621, 'Total loss': 0.321552700164621}
2022-11-28 03:01:46,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:46,955 INFO:     Epoch: 28
2022-11-28 03:01:47,688 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42657179229481273, 'Total loss': 0.42657179229481273} | train loss {'Reaction outcome loss': 0.31393419760355695, 'Total loss': 0.31393419760355695}
2022-11-28 03:01:47,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:47,688 INFO:     Epoch: 29
2022-11-28 03:01:48,424 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43357335169648015, 'Total loss': 0.43357335169648015} | train loss {'Reaction outcome loss': 0.31501080086607425, 'Total loss': 0.31501080086607425}
2022-11-28 03:01:48,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:48,424 INFO:     Epoch: 30
2022-11-28 03:01:49,160 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39693437793920205, 'Total loss': 0.39693437793920205} | train loss {'Reaction outcome loss': 0.3106612077013391, 'Total loss': 0.3106612077013391}
2022-11-28 03:01:49,161 INFO:     Found new best model at epoch 30
2022-11-28 03:01:49,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:49,162 INFO:     Epoch: 31
2022-11-28 03:01:49,893 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4050377998934236, 'Total loss': 0.4050377998934236} | train loss {'Reaction outcome loss': 0.3099037688683535, 'Total loss': 0.3099037688683535}
2022-11-28 03:01:49,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:49,893 INFO:     Epoch: 32
2022-11-28 03:01:50,622 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3874098131822985, 'Total loss': 0.3874098131822985} | train loss {'Reaction outcome loss': 0.3118071700675321, 'Total loss': 0.3118071700675321}
2022-11-28 03:01:50,622 INFO:     Found new best model at epoch 32
2022-11-28 03:01:50,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:50,623 INFO:     Epoch: 33
2022-11-28 03:01:51,354 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4308421251385711, 'Total loss': 0.4308421251385711} | train loss {'Reaction outcome loss': 0.316524696872249, 'Total loss': 0.316524696872249}
2022-11-28 03:01:51,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:51,354 INFO:     Epoch: 34
2022-11-28 03:01:52,085 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42452315154463743, 'Total loss': 0.42452315154463743} | train loss {'Reaction outcome loss': 0.30368528437235803, 'Total loss': 0.30368528437235803}
2022-11-28 03:01:52,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:52,085 INFO:     Epoch: 35
2022-11-28 03:01:52,816 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40994927702948103, 'Total loss': 0.40994927702948103} | train loss {'Reaction outcome loss': 0.3160275561796104, 'Total loss': 0.3160275561796104}
2022-11-28 03:01:52,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:52,816 INFO:     Epoch: 36
2022-11-28 03:01:53,547 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4248120919909588, 'Total loss': 0.4248120919909588} | train loss {'Reaction outcome loss': 0.30840240571586813, 'Total loss': 0.30840240571586813}
2022-11-28 03:01:53,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:53,547 INFO:     Epoch: 37
2022-11-28 03:01:54,278 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4139912007159965, 'Total loss': 0.4139912007159965} | train loss {'Reaction outcome loss': 0.30782022492074573, 'Total loss': 0.30782022492074573}
2022-11-28 03:01:54,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:54,278 INFO:     Epoch: 38
2022-11-28 03:01:55,011 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4004554360411888, 'Total loss': 0.4004554360411888} | train loss {'Reaction outcome loss': 0.3037320733009303, 'Total loss': 0.3037320733009303}
2022-11-28 03:01:55,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:55,011 INFO:     Epoch: 39
2022-11-28 03:01:55,747 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41624893109465755, 'Total loss': 0.41624893109465755} | train loss {'Reaction outcome loss': 0.30452263376629746, 'Total loss': 0.30452263376629746}
2022-11-28 03:01:55,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:55,747 INFO:     Epoch: 40
2022-11-28 03:01:56,479 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41879484403965084, 'Total loss': 0.41879484403965084} | train loss {'Reaction outcome loss': 0.3182527565504195, 'Total loss': 0.3182527565504195}
2022-11-28 03:01:56,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:56,479 INFO:     Epoch: 41
2022-11-28 03:01:57,212 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37876353984655337, 'Total loss': 0.37876353984655337} | train loss {'Reaction outcome loss': 0.3137585459063288, 'Total loss': 0.3137585459063288}
2022-11-28 03:01:57,212 INFO:     Found new best model at epoch 41
2022-11-28 03:01:57,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:57,213 INFO:     Epoch: 42
2022-11-28 03:01:57,946 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40302887247052305, 'Total loss': 0.40302887247052305} | train loss {'Reaction outcome loss': 0.3075230649260224, 'Total loss': 0.3075230649260224}
2022-11-28 03:01:57,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:57,946 INFO:     Epoch: 43
2022-11-28 03:01:58,679 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3956468382547068, 'Total loss': 0.3956468382547068} | train loss {'Reaction outcome loss': 0.3017569474845392, 'Total loss': 0.3017569474845392}
2022-11-28 03:01:58,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:58,679 INFO:     Epoch: 44
2022-11-28 03:01:59,413 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41261491352735563, 'Total loss': 0.41261491352735563} | train loss {'Reaction outcome loss': 0.30319119255501226, 'Total loss': 0.30319119255501226}
2022-11-28 03:01:59,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:01:59,414 INFO:     Epoch: 45
2022-11-28 03:02:00,150 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4394281665946162, 'Total loss': 0.4394281665946162} | train loss {'Reaction outcome loss': 0.3088814608264165, 'Total loss': 0.3088814608264165}
2022-11-28 03:02:00,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:00,151 INFO:     Epoch: 46
2022-11-28 03:02:00,887 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3984128631824671, 'Total loss': 0.3984128631824671} | train loss {'Reaction outcome loss': 0.3164672668656853, 'Total loss': 0.3164672668656853}
2022-11-28 03:02:00,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:00,888 INFO:     Epoch: 47
2022-11-28 03:02:01,623 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3933965468475985, 'Total loss': 0.3933965468475985} | train loss {'Reaction outcome loss': 0.2982739523266915, 'Total loss': 0.2982739523266915}
2022-11-28 03:02:01,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:01,624 INFO:     Epoch: 48
2022-11-28 03:02:02,356 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39271996603455656, 'Total loss': 0.39271996603455656} | train loss {'Reaction outcome loss': 0.29874082676089203, 'Total loss': 0.29874082676089203}
2022-11-28 03:02:02,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:02,356 INFO:     Epoch: 49
2022-11-28 03:02:03,089 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38446652404097625, 'Total loss': 0.38446652404097625} | train loss {'Reaction outcome loss': 0.306306890410478, 'Total loss': 0.306306890410478}
2022-11-28 03:02:03,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:03,090 INFO:     Epoch: 50
2022-11-28 03:02:03,821 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4512052179075951, 'Total loss': 0.4512052179075951} | train loss {'Reaction outcome loss': 0.3067170190395879, 'Total loss': 0.3067170190395879}
2022-11-28 03:02:03,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:03,821 INFO:     Epoch: 51
2022-11-28 03:02:04,549 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3845746094404265, 'Total loss': 0.3845746094404265} | train loss {'Reaction outcome loss': 0.29885027942354564, 'Total loss': 0.29885027942354564}
2022-11-28 03:02:04,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:04,549 INFO:     Epoch: 52
2022-11-28 03:02:05,278 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3812441510516544, 'Total loss': 0.3812441510516544} | train loss {'Reaction outcome loss': 0.3042195241776158, 'Total loss': 0.3042195241776158}
2022-11-28 03:02:05,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:05,278 INFO:     Epoch: 53
2022-11-28 03:02:06,006 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4037339247243349, 'Total loss': 0.4037339247243349} | train loss {'Reaction outcome loss': 0.3059752909008597, 'Total loss': 0.3059752909008597}
2022-11-28 03:02:06,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:06,006 INFO:     Epoch: 54
2022-11-28 03:02:06,738 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.421981948232928, 'Total loss': 0.421981948232928} | train loss {'Reaction outcome loss': 0.29941204633014123, 'Total loss': 0.29941204633014123}
2022-11-28 03:02:06,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:06,739 INFO:     Epoch: 55
2022-11-28 03:02:07,475 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3856638985317807, 'Total loss': 0.3856638985317807} | train loss {'Reaction outcome loss': 0.30626063534348713, 'Total loss': 0.30626063534348713}
2022-11-28 03:02:07,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:07,475 INFO:     Epoch: 56
2022-11-28 03:02:08,208 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38051029104132983, 'Total loss': 0.38051029104132983} | train loss {'Reaction outcome loss': 0.2976613264057602, 'Total loss': 0.2976613264057602}
2022-11-28 03:02:08,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:08,208 INFO:     Epoch: 57
2022-11-28 03:02:08,940 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38047953643078025, 'Total loss': 0.38047953643078025} | train loss {'Reaction outcome loss': 0.3047613968431461, 'Total loss': 0.3047613968431461}
2022-11-28 03:02:08,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:08,940 INFO:     Epoch: 58
2022-11-28 03:02:09,670 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3962027574347895, 'Total loss': 0.3962027574347895} | train loss {'Reaction outcome loss': 0.3016857807028306, 'Total loss': 0.3016857807028306}
2022-11-28 03:02:09,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:09,671 INFO:     Epoch: 59
2022-11-28 03:02:10,405 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38748701297959615, 'Total loss': 0.38748701297959615} | train loss {'Reaction outcome loss': 0.2978192100026568, 'Total loss': 0.2978192100026568}
2022-11-28 03:02:10,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:10,405 INFO:     Epoch: 60
2022-11-28 03:02:11,140 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39982517583425653, 'Total loss': 0.39982517583425653} | train loss {'Reaction outcome loss': 0.3014100786817611, 'Total loss': 0.3014100786817611}
2022-11-28 03:02:11,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:11,141 INFO:     Epoch: 61
2022-11-28 03:02:11,876 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38597100453321326, 'Total loss': 0.38597100453321326} | train loss {'Reaction outcome loss': 0.304472898209437, 'Total loss': 0.304472898209437}
2022-11-28 03:02:11,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:11,876 INFO:     Epoch: 62
2022-11-28 03:02:12,609 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40882505823013393, 'Total loss': 0.40882505823013393} | train loss {'Reaction outcome loss': 0.3076085917895935, 'Total loss': 0.3076085917895935}
2022-11-28 03:02:12,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:12,609 INFO:     Epoch: 63
2022-11-28 03:02:13,340 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40887381309686704, 'Total loss': 0.40887381309686704} | train loss {'Reaction outcome loss': 0.3020296172834322, 'Total loss': 0.3020296172834322}
2022-11-28 03:02:13,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:13,340 INFO:     Epoch: 64
2022-11-28 03:02:14,072 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38868727032528366, 'Total loss': 0.38868727032528366} | train loss {'Reaction outcome loss': 0.30051472673162083, 'Total loss': 0.30051472673162083}
2022-11-28 03:02:14,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:14,073 INFO:     Epoch: 65
2022-11-28 03:02:14,804 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3861637430828671, 'Total loss': 0.3861637430828671} | train loss {'Reaction outcome loss': 0.2985376259770061, 'Total loss': 0.2985376259770061}
2022-11-28 03:02:14,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:14,805 INFO:     Epoch: 66
2022-11-28 03:02:15,539 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40751535532086397, 'Total loss': 0.40751535532086397} | train loss {'Reaction outcome loss': 0.29711253638760965, 'Total loss': 0.29711253638760965}
2022-11-28 03:02:15,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:15,539 INFO:     Epoch: 67
2022-11-28 03:02:16,276 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41971282141153204, 'Total loss': 0.41971282141153204} | train loss {'Reaction outcome loss': 0.2903669119552999, 'Total loss': 0.2903669119552999}
2022-11-28 03:02:16,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:16,276 INFO:     Epoch: 68
2022-11-28 03:02:17,013 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43031968037749446, 'Total loss': 0.43031968037749446} | train loss {'Reaction outcome loss': 0.29318208859653255, 'Total loss': 0.29318208859653255}
2022-11-28 03:02:17,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:17,014 INFO:     Epoch: 69
2022-11-28 03:02:17,746 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4004047396917676, 'Total loss': 0.4004047396917676} | train loss {'Reaction outcome loss': 0.29817107979391444, 'Total loss': 0.29817107979391444}
2022-11-28 03:02:17,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:17,747 INFO:     Epoch: 70
2022-11-28 03:02:18,478 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41537120453147003, 'Total loss': 0.41537120453147003} | train loss {'Reaction outcome loss': 0.28995337938798255, 'Total loss': 0.28995337938798255}
2022-11-28 03:02:18,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:18,479 INFO:     Epoch: 71
2022-11-28 03:02:19,210 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41608329533144484, 'Total loss': 0.41608329533144484} | train loss {'Reaction outcome loss': 0.28549421068708425, 'Total loss': 0.28549421068708425}
2022-11-28 03:02:19,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:19,210 INFO:     Epoch: 72
2022-11-28 03:02:19,941 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39743990918924643, 'Total loss': 0.39743990918924643} | train loss {'Reaction outcome loss': 0.294708717919764, 'Total loss': 0.294708717919764}
2022-11-28 03:02:19,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:19,941 INFO:     Epoch: 73
2022-11-28 03:02:20,669 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4393786250851875, 'Total loss': 0.4393786250851875} | train loss {'Reaction outcome loss': 0.29667703816514523, 'Total loss': 0.29667703816514523}
2022-11-28 03:02:20,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:20,670 INFO:     Epoch: 74
2022-11-28 03:02:21,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38671035874028536, 'Total loss': 0.38671035874028536} | train loss {'Reaction outcome loss': 0.2995759737143507, 'Total loss': 0.2995759737143507}
2022-11-28 03:02:21,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:21,403 INFO:     Epoch: 75
2022-11-28 03:02:22,137 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3885000122841014, 'Total loss': 0.3885000122841014} | train loss {'Reaction outcome loss': 0.2840358932639976, 'Total loss': 0.2840358932639976}
2022-11-28 03:02:22,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:22,137 INFO:     Epoch: 76
2022-11-28 03:02:22,867 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.387281336929909, 'Total loss': 0.387281336929909} | train loss {'Reaction outcome loss': 0.29643767065994564, 'Total loss': 0.29643767065994564}
2022-11-28 03:02:22,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:22,867 INFO:     Epoch: 77
2022-11-28 03:02:23,595 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40901458973801413, 'Total loss': 0.40901458973801413} | train loss {'Reaction outcome loss': 0.29663823012140444, 'Total loss': 0.29663823012140444}
2022-11-28 03:02:23,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:23,595 INFO:     Epoch: 78
2022-11-28 03:02:24,324 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41833629857662114, 'Total loss': 0.41833629857662114} | train loss {'Reaction outcome loss': 0.295630253988822, 'Total loss': 0.295630253988822}
2022-11-28 03:02:24,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:24,324 INFO:     Epoch: 79
2022-11-28 03:02:25,057 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4128443252208621, 'Total loss': 0.4128443252208621} | train loss {'Reaction outcome loss': 0.29771282389515735, 'Total loss': 0.29771282389515735}
2022-11-28 03:02:25,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:25,057 INFO:     Epoch: 80
2022-11-28 03:02:25,791 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4319109033013499, 'Total loss': 0.4319109033013499} | train loss {'Reaction outcome loss': 0.29477493455786197, 'Total loss': 0.29477493455786197}
2022-11-28 03:02:25,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:25,791 INFO:     Epoch: 81
2022-11-28 03:02:26,523 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38957829738772193, 'Total loss': 0.38957829738772193} | train loss {'Reaction outcome loss': 0.2978982790602279, 'Total loss': 0.2978982790602279}
2022-11-28 03:02:26,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:26,523 INFO:     Epoch: 82
2022-11-28 03:02:27,255 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40681301351896554, 'Total loss': 0.40681301351896554} | train loss {'Reaction outcome loss': 0.29007401853250186, 'Total loss': 0.29007401853250186}
2022-11-28 03:02:27,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:27,256 INFO:     Epoch: 83
2022-11-28 03:02:27,985 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4192834680163583, 'Total loss': 0.4192834680163583} | train loss {'Reaction outcome loss': 0.296191631068216, 'Total loss': 0.296191631068216}
2022-11-28 03:02:27,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:27,985 INFO:     Epoch: 84
2022-11-28 03:02:28,714 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3872816787902699, 'Total loss': 0.3872816787902699} | train loss {'Reaction outcome loss': 0.2908912532367423, 'Total loss': 0.2908912532367423}
2022-11-28 03:02:28,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:28,714 INFO:     Epoch: 85
2022-11-28 03:02:29,443 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40719147754269974, 'Total loss': 0.40719147754269974} | train loss {'Reaction outcome loss': 0.29573606281373344, 'Total loss': 0.29573606281373344}
2022-11-28 03:02:29,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:29,444 INFO:     Epoch: 86
2022-11-28 03:02:30,173 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4027898322011149, 'Total loss': 0.4027898322011149} | train loss {'Reaction outcome loss': 0.2944119438437409, 'Total loss': 0.2944119438437409}
2022-11-28 03:02:30,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:30,173 INFO:     Epoch: 87
2022-11-28 03:02:30,901 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41634017818195873, 'Total loss': 0.41634017818195873} | train loss {'Reaction outcome loss': 0.2980277131265793, 'Total loss': 0.2980277131265793}
2022-11-28 03:02:30,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:30,901 INFO:     Epoch: 88
2022-11-28 03:02:31,632 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4622897613187169, 'Total loss': 0.4622897613187169} | train loss {'Reaction outcome loss': 0.29212011927433434, 'Total loss': 0.29212011927433434}
2022-11-28 03:02:31,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:31,632 INFO:     Epoch: 89
2022-11-28 03:02:32,363 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38304550772489504, 'Total loss': 0.38304550772489504} | train loss {'Reaction outcome loss': 0.2889629733580791, 'Total loss': 0.2889629733580791}
2022-11-28 03:02:32,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:32,363 INFO:     Epoch: 90
2022-11-28 03:02:33,096 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4373683312604594, 'Total loss': 0.4373683312604594} | train loss {'Reaction outcome loss': 0.29275179744438556, 'Total loss': 0.29275179744438556}
2022-11-28 03:02:33,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:33,097 INFO:     Epoch: 91
2022-11-28 03:02:33,826 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41529819993085637, 'Total loss': 0.41529819993085637} | train loss {'Reaction outcome loss': 0.30371544383405175, 'Total loss': 0.30371544383405175}
2022-11-28 03:02:33,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:33,826 INFO:     Epoch: 92
2022-11-28 03:02:34,557 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41385945573795674, 'Total loss': 0.41385945573795674} | train loss {'Reaction outcome loss': 0.2856490806081012, 'Total loss': 0.2856490806081012}
2022-11-28 03:02:34,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:34,557 INFO:     Epoch: 93
2022-11-28 03:02:35,290 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3826129831546961, 'Total loss': 0.3826129831546961} | train loss {'Reaction outcome loss': 0.29671428071670847, 'Total loss': 0.29671428071670847}
2022-11-28 03:02:35,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:35,290 INFO:     Epoch: 94
2022-11-28 03:02:36,021 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3978799030531284, 'Total loss': 0.3978799030531284} | train loss {'Reaction outcome loss': 0.2953085874314191, 'Total loss': 0.2953085874314191}
2022-11-28 03:02:36,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:36,021 INFO:     Epoch: 95
2022-11-28 03:02:36,752 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42840754292732064, 'Total loss': 0.42840754292732064} | train loss {'Reaction outcome loss': 0.30396540459917215, 'Total loss': 0.30396540459917215}
2022-11-28 03:02:36,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:36,753 INFO:     Epoch: 96
2022-11-28 03:02:37,486 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3937429312703221, 'Total loss': 0.3937429312703221} | train loss {'Reaction outcome loss': 0.2817663474649679, 'Total loss': 0.2817663474649679}
2022-11-28 03:02:37,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:37,486 INFO:     Epoch: 97
2022-11-28 03:02:38,215 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41343544250310854, 'Total loss': 0.41343544250310854} | train loss {'Reaction outcome loss': 0.29286800276060576, 'Total loss': 0.29286800276060576}
2022-11-28 03:02:38,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:38,215 INFO:     Epoch: 98
2022-11-28 03:02:38,944 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41481362906999364, 'Total loss': 0.41481362906999364} | train loss {'Reaction outcome loss': 0.2946657355355679, 'Total loss': 0.2946657355355679}
2022-11-28 03:02:38,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:38,944 INFO:     Epoch: 99
2022-11-28 03:02:39,674 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39318647807420687, 'Total loss': 0.39318647807420687} | train loss {'Reaction outcome loss': 0.28957954247588996, 'Total loss': 0.28957954247588996}
2022-11-28 03:02:39,675 INFO:     Best model found after epoch 42 of 100.
2022-11-28 03:02:39,675 INFO:   Done with stage: TRAINING
2022-11-28 03:02:39,675 INFO:   Starting stage: EVALUATION
2022-11-28 03:02:39,806 INFO:   Done with stage: EVALUATION
2022-11-28 03:02:39,806 INFO:   Leaving out SEQ value Fold_4
2022-11-28 03:02:39,819 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:02:39,820 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:02:40,450 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:02:40,451 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:02:40,519 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:02:40,519 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:02:40,519 INFO:     No hyperparam tuning for this model
2022-11-28 03:02:40,519 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:02:40,519 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:02:40,520 INFO:     None feature selector for col prot
2022-11-28 03:02:40,520 INFO:     None feature selector for col prot
2022-11-28 03:02:40,520 INFO:     None feature selector for col prot
2022-11-28 03:02:40,521 INFO:     None feature selector for col chem
2022-11-28 03:02:40,521 INFO:     None feature selector for col chem
2022-11-28 03:02:40,521 INFO:     None feature selector for col chem
2022-11-28 03:02:40,521 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:02:40,521 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:02:40,522 INFO:     Number of params in model 169741
2022-11-28 03:02:40,525 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:02:40,525 INFO:   Starting stage: TRAINING
2022-11-28 03:02:40,578 INFO:     Val loss before train {'Reaction outcome loss': 0.9847821349447424, 'Total loss': 0.9847821349447424}
2022-11-28 03:02:40,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:40,578 INFO:     Epoch: 0
2022-11-28 03:02:41,317 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5399063432758505, 'Total loss': 0.5399063432758505} | train loss {'Reaction outcome loss': 0.6476044236769077, 'Total loss': 0.6476044236769077}
2022-11-28 03:02:41,317 INFO:     Found new best model at epoch 0
2022-11-28 03:02:41,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:41,318 INFO:     Epoch: 1
2022-11-28 03:02:42,057 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.52083733914928, 'Total loss': 0.52083733914928} | train loss {'Reaction outcome loss': 0.5038470954064899, 'Total loss': 0.5038470954064899}
2022-11-28 03:02:42,057 INFO:     Found new best model at epoch 1
2022-11-28 03:02:42,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:42,058 INFO:     Epoch: 2
2022-11-28 03:02:42,799 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5174039934169162, 'Total loss': 0.5174039934169162} | train loss {'Reaction outcome loss': 0.46402596582767935, 'Total loss': 0.46402596582767935}
2022-11-28 03:02:42,799 INFO:     Found new best model at epoch 2
2022-11-28 03:02:42,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:42,800 INFO:     Epoch: 3
2022-11-28 03:02:43,544 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4642313112589446, 'Total loss': 0.4642313112589446} | train loss {'Reaction outcome loss': 0.45363298067559116, 'Total loss': 0.45363298067559116}
2022-11-28 03:02:43,544 INFO:     Found new best model at epoch 3
2022-11-28 03:02:43,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:43,545 INFO:     Epoch: 4
2022-11-28 03:02:44,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.462624212896282, 'Total loss': 0.462624212896282} | train loss {'Reaction outcome loss': 0.42999038540641304, 'Total loss': 0.42999038540641304}
2022-11-28 03:02:44,289 INFO:     Found new best model at epoch 4
2022-11-28 03:02:44,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:44,290 INFO:     Epoch: 5
2022-11-28 03:02:45,029 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4447337808934125, 'Total loss': 0.4447337808934125} | train loss {'Reaction outcome loss': 0.416900401384483, 'Total loss': 0.416900401384483}
2022-11-28 03:02:45,030 INFO:     Found new best model at epoch 5
2022-11-28 03:02:45,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:45,031 INFO:     Epoch: 6
2022-11-28 03:02:45,772 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44591759924184193, 'Total loss': 0.44591759924184193} | train loss {'Reaction outcome loss': 0.4116165737512141, 'Total loss': 0.4116165737512141}
2022-11-28 03:02:45,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:45,773 INFO:     Epoch: 7
2022-11-28 03:02:46,516 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47765799069946463, 'Total loss': 0.47765799069946463} | train loss {'Reaction outcome loss': 0.3919591473543692, 'Total loss': 0.3919591473543692}
2022-11-28 03:02:46,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:46,516 INFO:     Epoch: 8
2022-11-28 03:02:47,257 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47117500752210617, 'Total loss': 0.47117500752210617} | train loss {'Reaction outcome loss': 0.4042487727244373, 'Total loss': 0.4042487727244373}
2022-11-28 03:02:47,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:47,257 INFO:     Epoch: 9
2022-11-28 03:02:47,996 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44304532049731776, 'Total loss': 0.44304532049731776} | train loss {'Reaction outcome loss': 0.38387301637742083, 'Total loss': 0.38387301637742083}
2022-11-28 03:02:47,996 INFO:     Found new best model at epoch 9
2022-11-28 03:02:47,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:47,997 INFO:     Epoch: 10
2022-11-28 03:02:48,734 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4254573808813637, 'Total loss': 0.4254573808813637} | train loss {'Reaction outcome loss': 0.37977461531939294, 'Total loss': 0.37977461531939294}
2022-11-28 03:02:48,734 INFO:     Found new best model at epoch 10
2022-11-28 03:02:48,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:48,735 INFO:     Epoch: 11
2022-11-28 03:02:49,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4193746515295722, 'Total loss': 0.4193746515295722} | train loss {'Reaction outcome loss': 0.3695232851981272, 'Total loss': 0.3695232851981272}
2022-11-28 03:02:49,476 INFO:     Found new best model at epoch 11
2022-11-28 03:02:49,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:49,477 INFO:     Epoch: 12
2022-11-28 03:02:50,216 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42353695224631915, 'Total loss': 0.42353695224631915} | train loss {'Reaction outcome loss': 0.36803757290729144, 'Total loss': 0.36803757290729144}
2022-11-28 03:02:50,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:50,216 INFO:     Epoch: 13
2022-11-28 03:02:50,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4005411018363454, 'Total loss': 0.4005411018363454} | train loss {'Reaction outcome loss': 0.36287191022293047, 'Total loss': 0.36287191022293047}
2022-11-28 03:02:50,956 INFO:     Found new best model at epoch 13
2022-11-28 03:02:50,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:50,957 INFO:     Epoch: 14
2022-11-28 03:02:51,695 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43593614954840054, 'Total loss': 0.43593614954840054} | train loss {'Reaction outcome loss': 0.3589101515235266, 'Total loss': 0.3589101515235266}
2022-11-28 03:02:51,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:51,696 INFO:     Epoch: 15
2022-11-28 03:02:52,439 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4088953127237884, 'Total loss': 0.4088953127237884} | train loss {'Reaction outcome loss': 0.36217284202575684, 'Total loss': 0.36217284202575684}
2022-11-28 03:02:52,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:52,439 INFO:     Epoch: 16
2022-11-28 03:02:53,184 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40119907463138754, 'Total loss': 0.40119907463138754} | train loss {'Reaction outcome loss': 0.357821146260027, 'Total loss': 0.357821146260027}
2022-11-28 03:02:53,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:53,184 INFO:     Epoch: 17
2022-11-28 03:02:53,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41141471334479074, 'Total loss': 0.41141471334479074} | train loss {'Reaction outcome loss': 0.35034676191777836, 'Total loss': 0.35034676191777836}
2022-11-28 03:02:53,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:53,926 INFO:     Epoch: 18
2022-11-28 03:02:54,667 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4317642077803612, 'Total loss': 0.4317642077803612} | train loss {'Reaction outcome loss': 0.35317358663890075, 'Total loss': 0.35317358663890075}
2022-11-28 03:02:54,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:54,667 INFO:     Epoch: 19
2022-11-28 03:02:55,404 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42585196515375917, 'Total loss': 0.42585196515375917} | train loss {'Reaction outcome loss': 0.34216139636941345, 'Total loss': 0.34216139636941345}
2022-11-28 03:02:55,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:55,405 INFO:     Epoch: 20
2022-11-28 03:02:56,144 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40692687610333617, 'Total loss': 0.40692687610333617} | train loss {'Reaction outcome loss': 0.3455229540042549, 'Total loss': 0.3455229540042549}
2022-11-28 03:02:56,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:56,144 INFO:     Epoch: 21
2022-11-28 03:02:56,884 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3981304182247682, 'Total loss': 0.3981304182247682} | train loss {'Reaction outcome loss': 0.3475860169059352, 'Total loss': 0.3475860169059352}
2022-11-28 03:02:56,884 INFO:     Found new best model at epoch 21
2022-11-28 03:02:56,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:56,885 INFO:     Epoch: 22
2022-11-28 03:02:57,626 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42224045809019695, 'Total loss': 0.42224045809019695} | train loss {'Reaction outcome loss': 0.34216373305209735, 'Total loss': 0.34216373305209735}
2022-11-28 03:02:57,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:57,626 INFO:     Epoch: 23
2022-11-28 03:02:58,364 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4033052511513233, 'Total loss': 0.4033052511513233} | train loss {'Reaction outcome loss': 0.3413977699603146, 'Total loss': 0.3413977699603146}
2022-11-28 03:02:58,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:58,365 INFO:     Epoch: 24
2022-11-28 03:02:59,105 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4346932909366759, 'Total loss': 0.4346932909366759} | train loss {'Reaction outcome loss': 0.33699660760309047, 'Total loss': 0.33699660760309047}
2022-11-28 03:02:59,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:59,106 INFO:     Epoch: 25
2022-11-28 03:02:59,844 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4199339012530717, 'Total loss': 0.4199339012530717} | train loss {'Reaction outcome loss': 0.33500267017768465, 'Total loss': 0.33500267017768465}
2022-11-28 03:02:59,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:02:59,844 INFO:     Epoch: 26
2022-11-28 03:03:00,584 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43960570814934646, 'Total loss': 0.43960570814934646} | train loss {'Reaction outcome loss': 0.3359152062943107, 'Total loss': 0.3359152062943107}
2022-11-28 03:03:00,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:00,584 INFO:     Epoch: 27
2022-11-28 03:03:01,324 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4267795573581349, 'Total loss': 0.4267795573581349} | train loss {'Reaction outcome loss': 0.343201781317652, 'Total loss': 0.343201781317652}
2022-11-28 03:03:01,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:01,324 INFO:     Epoch: 28
2022-11-28 03:03:02,066 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4214893027462743, 'Total loss': 0.4214893027462743} | train loss {'Reaction outcome loss': 0.3297037809339224, 'Total loss': 0.3297037809339224}
2022-11-28 03:03:02,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:02,066 INFO:     Epoch: 29
2022-11-28 03:03:02,810 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4286078969863328, 'Total loss': 0.4286078969863328} | train loss {'Reaction outcome loss': 0.32870537455868626, 'Total loss': 0.32870537455868626}
2022-11-28 03:03:02,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:02,810 INFO:     Epoch: 30
2022-11-28 03:03:03,550 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4000907096673142, 'Total loss': 0.4000907096673142} | train loss {'Reaction outcome loss': 0.3238543634489556, 'Total loss': 0.3238543634489556}
2022-11-28 03:03:03,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:03,551 INFO:     Epoch: 31
2022-11-28 03:03:04,290 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44281368059190834, 'Total loss': 0.44281368059190834} | train loss {'Reaction outcome loss': 0.3269037206766576, 'Total loss': 0.3269037206766576}
2022-11-28 03:03:04,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:04,291 INFO:     Epoch: 32
2022-11-28 03:03:05,034 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4100290452214805, 'Total loss': 0.4100290452214805} | train loss {'Reaction outcome loss': 0.33231522694893695, 'Total loss': 0.33231522694893695}
2022-11-28 03:03:05,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:05,035 INFO:     Epoch: 33
2022-11-28 03:03:05,778 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43617149036039005, 'Total loss': 0.43617149036039005} | train loss {'Reaction outcome loss': 0.3274115892918969, 'Total loss': 0.3274115892918969}
2022-11-28 03:03:05,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:05,778 INFO:     Epoch: 34
2022-11-28 03:03:06,515 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4169047833843665, 'Total loss': 0.4169047833843665} | train loss {'Reaction outcome loss': 0.32782335691003184, 'Total loss': 0.32782335691003184}
2022-11-28 03:03:06,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:06,515 INFO:     Epoch: 35
2022-11-28 03:03:07,252 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4175788699225946, 'Total loss': 0.4175788699225946} | train loss {'Reaction outcome loss': 0.3420365802521406, 'Total loss': 0.3420365802521406}
2022-11-28 03:03:07,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:07,253 INFO:     Epoch: 36
2022-11-28 03:03:07,991 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42489391870119353, 'Total loss': 0.42489391870119353} | train loss {'Reaction outcome loss': 0.3232401636870284, 'Total loss': 0.3232401636870284}
2022-11-28 03:03:07,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:07,992 INFO:     Epoch: 37
2022-11-28 03:03:08,732 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41221209886399185, 'Total loss': 0.41221209886399185} | train loss {'Reaction outcome loss': 0.31802924774466496, 'Total loss': 0.31802924774466496}
2022-11-28 03:03:08,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:08,732 INFO:     Epoch: 38
2022-11-28 03:03:09,468 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4123473114926707, 'Total loss': 0.4123473114926707} | train loss {'Reaction outcome loss': 0.3285861021352683, 'Total loss': 0.3285861021352683}
2022-11-28 03:03:09,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:09,468 INFO:     Epoch: 39
2022-11-28 03:03:10,210 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42147721350193024, 'Total loss': 0.42147721350193024} | train loss {'Reaction outcome loss': 0.3252593511149951, 'Total loss': 0.3252593511149951}
2022-11-28 03:03:10,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:10,211 INFO:     Epoch: 40
2022-11-28 03:03:10,950 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42501325329596346, 'Total loss': 0.42501325329596346} | train loss {'Reaction outcome loss': 0.32943944442971995, 'Total loss': 0.32943944442971995}
2022-11-28 03:03:10,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:10,950 INFO:     Epoch: 41
2022-11-28 03:03:11,689 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4344782582060857, 'Total loss': 0.4344782582060857} | train loss {'Reaction outcome loss': 0.3232037544670903, 'Total loss': 0.3232037544670903}
2022-11-28 03:03:11,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:11,689 INFO:     Epoch: 42
2022-11-28 03:03:12,431 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4568891633640636, 'Total loss': 0.4568891633640636} | train loss {'Reaction outcome loss': 0.3131970832122467, 'Total loss': 0.3131970832122467}
2022-11-28 03:03:12,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:12,431 INFO:     Epoch: 43
2022-11-28 03:03:13,170 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4008113369345665, 'Total loss': 0.4008113369345665} | train loss {'Reaction outcome loss': 0.3226722303762851, 'Total loss': 0.3226722303762851}
2022-11-28 03:03:13,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:13,170 INFO:     Epoch: 44
2022-11-28 03:03:13,911 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43345592712814157, 'Total loss': 0.43345592712814157} | train loss {'Reaction outcome loss': 0.323636802773063, 'Total loss': 0.323636802773063}
2022-11-28 03:03:13,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:13,911 INFO:     Epoch: 45
2022-11-28 03:03:14,650 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3931332735175436, 'Total loss': 0.3931332735175436} | train loss {'Reaction outcome loss': 0.31590204978520087, 'Total loss': 0.31590204978520087}
2022-11-28 03:03:14,651 INFO:     Found new best model at epoch 45
2022-11-28 03:03:14,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:14,651 INFO:     Epoch: 46
2022-11-28 03:03:15,393 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3995162614367225, 'Total loss': 0.3995162614367225} | train loss {'Reaction outcome loss': 0.33019586851601657, 'Total loss': 0.33019586851601657}
2022-11-28 03:03:15,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:15,393 INFO:     Epoch: 47
2022-11-28 03:03:16,134 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4207816008817066, 'Total loss': 0.4207816008817066} | train loss {'Reaction outcome loss': 0.33227812875107476, 'Total loss': 0.33227812875107476}
2022-11-28 03:03:16,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:16,135 INFO:     Epoch: 48
2022-11-28 03:03:16,877 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4360205703838305, 'Total loss': 0.4360205703838305} | train loss {'Reaction outcome loss': 0.3180911057149833, 'Total loss': 0.3180911057149833}
2022-11-28 03:03:16,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:16,877 INFO:     Epoch: 49
2022-11-28 03:03:17,617 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4001326032660224, 'Total loss': 0.4001326032660224} | train loss {'Reaction outcome loss': 0.33137130541236776, 'Total loss': 0.33137130541236776}
2022-11-28 03:03:17,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:17,617 INFO:     Epoch: 50
2022-11-28 03:03:18,358 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3975766079330986, 'Total loss': 0.3975766079330986} | train loss {'Reaction outcome loss': 0.3162444605782387, 'Total loss': 0.3162444605782387}
2022-11-28 03:03:18,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:18,358 INFO:     Epoch: 51
2022-11-28 03:03:19,099 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4320888685231859, 'Total loss': 0.4320888685231859} | train loss {'Reaction outcome loss': 0.31718272066520536, 'Total loss': 0.31718272066520536}
2022-11-28 03:03:19,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:19,099 INFO:     Epoch: 52
2022-11-28 03:03:19,847 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4239628037268465, 'Total loss': 0.4239628037268465} | train loss {'Reaction outcome loss': 0.31679750902027737, 'Total loss': 0.31679750902027737}
2022-11-28 03:03:19,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:19,847 INFO:     Epoch: 53
2022-11-28 03:03:20,590 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39568703452294524, 'Total loss': 0.39568703452294524} | train loss {'Reaction outcome loss': 0.31581291121992505, 'Total loss': 0.31581291121992505}
2022-11-28 03:03:20,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:20,590 INFO:     Epoch: 54
2022-11-28 03:03:21,332 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4155899580906738, 'Total loss': 0.4155899580906738} | train loss {'Reaction outcome loss': 0.3323023275958623, 'Total loss': 0.3323023275958623}
2022-11-28 03:03:21,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:21,332 INFO:     Epoch: 55
2022-11-28 03:03:22,076 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.436472863805565, 'Total loss': 0.436472863805565} | train loss {'Reaction outcome loss': 0.32211822737385387, 'Total loss': 0.32211822737385387}
2022-11-28 03:03:22,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:22,076 INFO:     Epoch: 56
2022-11-28 03:03:22,818 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4265890968116847, 'Total loss': 0.4265890968116847} | train loss {'Reaction outcome loss': 0.3380049214008366, 'Total loss': 0.3380049214008366}
2022-11-28 03:03:22,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:22,819 INFO:     Epoch: 57
2022-11-28 03:03:23,563 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4007298011671413, 'Total loss': 0.4007298011671413} | train loss {'Reaction outcome loss': 0.33367691888862294, 'Total loss': 0.33367691888862294}
2022-11-28 03:03:23,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:23,563 INFO:     Epoch: 58
2022-11-28 03:03:24,305 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4093765927986665, 'Total loss': 0.4093765927986665} | train loss {'Reaction outcome loss': 0.31982752729041375, 'Total loss': 0.31982752729041375}
2022-11-28 03:03:24,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:24,305 INFO:     Epoch: 59
2022-11-28 03:03:25,050 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4449870545755733, 'Total loss': 0.4449870545755733} | train loss {'Reaction outcome loss': 0.31824431365340766, 'Total loss': 0.31824431365340766}
2022-11-28 03:03:25,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:25,050 INFO:     Epoch: 60
2022-11-28 03:03:25,795 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4207509556277232, 'Total loss': 0.4207509556277232} | train loss {'Reaction outcome loss': 0.31904762669613485, 'Total loss': 0.31904762669613485}
2022-11-28 03:03:25,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:25,796 INFO:     Epoch: 61
2022-11-28 03:03:26,546 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4210658208890395, 'Total loss': 0.4210658208890395} | train loss {'Reaction outcome loss': 0.33604816718381425, 'Total loss': 0.33604816718381425}
2022-11-28 03:03:26,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:26,546 INFO:     Epoch: 62
2022-11-28 03:03:27,294 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41897565295750444, 'Total loss': 0.41897565295750444} | train loss {'Reaction outcome loss': 0.3139276185076729, 'Total loss': 0.3139276185076729}
2022-11-28 03:03:27,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:27,294 INFO:     Epoch: 63
2022-11-28 03:03:28,045 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41142461787570606, 'Total loss': 0.41142461787570606} | train loss {'Reaction outcome loss': 0.31523325567620125, 'Total loss': 0.31523325567620125}
2022-11-28 03:03:28,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:28,046 INFO:     Epoch: 64
2022-11-28 03:03:28,792 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42509709586474026, 'Total loss': 0.42509709586474026} | train loss {'Reaction outcome loss': 0.3158188588494955, 'Total loss': 0.3158188588494955}
2022-11-28 03:03:28,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:28,792 INFO:     Epoch: 65
2022-11-28 03:03:29,541 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42472862266004086, 'Total loss': 0.42472862266004086} | train loss {'Reaction outcome loss': 0.316901193848747, 'Total loss': 0.316901193848747}
2022-11-28 03:03:29,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:29,541 INFO:     Epoch: 66
2022-11-28 03:03:30,289 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43652816861867905, 'Total loss': 0.43652816861867905} | train loss {'Reaction outcome loss': 0.316836334101343, 'Total loss': 0.316836334101343}
2022-11-28 03:03:30,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:30,289 INFO:     Epoch: 67
2022-11-28 03:03:31,039 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4303655658255924, 'Total loss': 0.4303655658255924} | train loss {'Reaction outcome loss': 0.3383485860514609, 'Total loss': 0.3383485860514609}
2022-11-28 03:03:31,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:31,039 INFO:     Epoch: 68
2022-11-28 03:03:31,789 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4085717907344753, 'Total loss': 0.4085717907344753} | train loss {'Reaction outcome loss': 0.31208456289551034, 'Total loss': 0.31208456289551034}
2022-11-28 03:03:31,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:31,789 INFO:     Epoch: 69
2022-11-28 03:03:32,538 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4180428375574676, 'Total loss': 0.4180428375574676} | train loss {'Reaction outcome loss': 0.3505642455719743, 'Total loss': 0.3505642455719743}
2022-11-28 03:03:32,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:32,538 INFO:     Epoch: 70
2022-11-28 03:03:33,287 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3961493650620634, 'Total loss': 0.3961493650620634} | train loss {'Reaction outcome loss': 0.31322555328428986, 'Total loss': 0.31322555328428986}
2022-11-28 03:03:33,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:33,287 INFO:     Epoch: 71
2022-11-28 03:03:34,040 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.404877913438461, 'Total loss': 0.404877913438461} | train loss {'Reaction outcome loss': 0.30290200272461903, 'Total loss': 0.30290200272461903}
2022-11-28 03:03:34,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:34,040 INFO:     Epoch: 72
2022-11-28 03:03:34,789 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.393468534743244, 'Total loss': 0.393468534743244} | train loss {'Reaction outcome loss': 0.3093361248552558, 'Total loss': 0.3093361248552558}
2022-11-28 03:03:34,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:34,790 INFO:     Epoch: 73
2022-11-28 03:03:35,538 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4472051818262447, 'Total loss': 0.4472051818262447} | train loss {'Reaction outcome loss': 0.3413145249249481, 'Total loss': 0.3413145249249481}
2022-11-28 03:03:35,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:35,539 INFO:     Epoch: 74
2022-11-28 03:03:36,291 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4105315279554237, 'Total loss': 0.4105315279554237} | train loss {'Reaction outcome loss': 0.31876491954331454, 'Total loss': 0.31876491954331454}
2022-11-28 03:03:36,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:36,292 INFO:     Epoch: 75
2022-11-28 03:03:37,042 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4066044237803329, 'Total loss': 0.4066044237803329} | train loss {'Reaction outcome loss': 0.3229015620523377, 'Total loss': 0.3229015620523377}
2022-11-28 03:03:37,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:37,042 INFO:     Epoch: 76
2022-11-28 03:03:37,794 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41616986505687237, 'Total loss': 0.41616986505687237} | train loss {'Reaction outcome loss': 0.31707685343498887, 'Total loss': 0.31707685343498887}
2022-11-28 03:03:37,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:37,794 INFO:     Epoch: 77
2022-11-28 03:03:38,547 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42685187743468717, 'Total loss': 0.42685187743468717} | train loss {'Reaction outcome loss': 0.30840991911014565, 'Total loss': 0.30840991911014565}
2022-11-28 03:03:38,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:38,547 INFO:     Epoch: 78
2022-11-28 03:03:39,296 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4078047409315001, 'Total loss': 0.4078047409315001} | train loss {'Reaction outcome loss': 0.31974400398943587, 'Total loss': 0.31974400398943587}
2022-11-28 03:03:39,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:39,296 INFO:     Epoch: 79
2022-11-28 03:03:40,049 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43869926170869306, 'Total loss': 0.43869926170869306} | train loss {'Reaction outcome loss': 0.3295792634127594, 'Total loss': 0.3295792634127594}
2022-11-28 03:03:40,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:40,049 INFO:     Epoch: 80
2022-11-28 03:03:40,805 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4123611663552848, 'Total loss': 0.4123611663552848} | train loss {'Reaction outcome loss': 0.3102313500304936, 'Total loss': 0.3102313500304936}
2022-11-28 03:03:40,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:40,805 INFO:     Epoch: 81
2022-11-28 03:03:41,558 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42195573381402274, 'Total loss': 0.42195573381402274} | train loss {'Reaction outcome loss': 0.307146226399039, 'Total loss': 0.307146226399039}
2022-11-28 03:03:41,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:41,558 INFO:     Epoch: 82
2022-11-28 03:03:42,311 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3964388814162124, 'Total loss': 0.3964388814162124} | train loss {'Reaction outcome loss': 0.31892292375647113, 'Total loss': 0.31892292375647113}
2022-11-28 03:03:42,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:42,311 INFO:     Epoch: 83
2022-11-28 03:03:43,062 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41986909610303963, 'Total loss': 0.41986909610303963} | train loss {'Reaction outcome loss': 0.3172240937128663, 'Total loss': 0.3172240937128663}
2022-11-28 03:03:43,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:43,063 INFO:     Epoch: 84
2022-11-28 03:03:43,815 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.417408902536739, 'Total loss': 0.417408902536739} | train loss {'Reaction outcome loss': 0.317103388594833, 'Total loss': 0.317103388594833}
2022-11-28 03:03:43,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:43,815 INFO:     Epoch: 85
2022-11-28 03:03:44,570 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.433354144746607, 'Total loss': 0.433354144746607} | train loss {'Reaction outcome loss': 0.35432070113628017, 'Total loss': 0.35432070113628017}
2022-11-28 03:03:44,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:44,570 INFO:     Epoch: 86
2022-11-28 03:03:45,323 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40122019160877576, 'Total loss': 0.40122019160877576} | train loss {'Reaction outcome loss': 0.31737477914524465, 'Total loss': 0.31737477914524465}
2022-11-28 03:03:45,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:45,323 INFO:     Epoch: 87
2022-11-28 03:03:46,077 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4423287690363147, 'Total loss': 0.4423287690363147} | train loss {'Reaction outcome loss': 0.316613766496722, 'Total loss': 0.316613766496722}
2022-11-28 03:03:46,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:46,078 INFO:     Epoch: 88
2022-11-28 03:03:46,834 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4470747771926902, 'Total loss': 0.4470747771926902} | train loss {'Reaction outcome loss': 0.3654284414039691, 'Total loss': 0.3654284414039691}
2022-11-28 03:03:46,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:46,835 INFO:     Epoch: 89
2022-11-28 03:03:47,587 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40596155331216077, 'Total loss': 0.40596155331216077} | train loss {'Reaction outcome loss': 0.32998202284911143, 'Total loss': 0.32998202284911143}
2022-11-28 03:03:47,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:47,588 INFO:     Epoch: 90
2022-11-28 03:03:48,340 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4329712800681591, 'Total loss': 0.4329712800681591} | train loss {'Reaction outcome loss': 0.3189919457652112, 'Total loss': 0.3189919457652112}
2022-11-28 03:03:48,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:48,341 INFO:     Epoch: 91
2022-11-28 03:03:49,090 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42866950177333574, 'Total loss': 0.42866950177333574} | train loss {'Reaction outcome loss': 0.3075104551879983, 'Total loss': 0.3075104551879983}
2022-11-28 03:03:49,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:49,090 INFO:     Epoch: 92
2022-11-28 03:03:49,844 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.419066402383826, 'Total loss': 0.419066402383826} | train loss {'Reaction outcome loss': 0.31025461363888945, 'Total loss': 0.31025461363888945}
2022-11-28 03:03:49,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:49,844 INFO:     Epoch: 93
2022-11-28 03:03:50,598 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4114945415746082, 'Total loss': 0.4114945415746082} | train loss {'Reaction outcome loss': 0.3098382208994043, 'Total loss': 0.3098382208994043}
2022-11-28 03:03:50,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:50,598 INFO:     Epoch: 94
2022-11-28 03:03:51,350 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4235632209615274, 'Total loss': 0.4235632209615274} | train loss {'Reaction outcome loss': 0.31183194456554136, 'Total loss': 0.31183194456554136}
2022-11-28 03:03:51,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:51,350 INFO:     Epoch: 95
2022-11-28 03:03:52,101 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4428244690326127, 'Total loss': 0.4428244690326127} | train loss {'Reaction outcome loss': 0.32527082883997965, 'Total loss': 0.32527082883997965}
2022-11-28 03:03:52,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:52,102 INFO:     Epoch: 96
2022-11-28 03:03:52,856 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4034662956202572, 'Total loss': 0.4034662956202572} | train loss {'Reaction outcome loss': 0.3145991643796004, 'Total loss': 0.3145991643796004}
2022-11-28 03:03:52,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:52,856 INFO:     Epoch: 97
2022-11-28 03:03:53,609 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4084625665775754, 'Total loss': 0.4084625665775754} | train loss {'Reaction outcome loss': 0.30550185545735997, 'Total loss': 0.30550185545735997}
2022-11-28 03:03:53,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:53,610 INFO:     Epoch: 98
2022-11-28 03:03:54,363 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45413115654479375, 'Total loss': 0.45413115654479375} | train loss {'Reaction outcome loss': 0.33931211155918445, 'Total loss': 0.33931211155918445}
2022-11-28 03:03:54,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:54,363 INFO:     Epoch: 99
2022-11-28 03:03:55,116 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4218542013656009, 'Total loss': 0.4218542013656009} | train loss {'Reaction outcome loss': 0.31664893241893305, 'Total loss': 0.31664893241893305}
2022-11-28 03:03:55,116 INFO:     Best model found after epoch 46 of 100.
2022-11-28 03:03:55,116 INFO:   Done with stage: TRAINING
2022-11-28 03:03:55,116 INFO:   Starting stage: EVALUATION
2022-11-28 03:03:55,238 INFO:   Done with stage: EVALUATION
2022-11-28 03:03:55,238 INFO:   Leaving out SEQ value Fold_5
2022-11-28 03:03:55,251 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:03:55,251 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:03:55,895 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:03:55,895 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:03:55,963 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:03:55,963 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:03:55,963 INFO:     No hyperparam tuning for this model
2022-11-28 03:03:55,963 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:03:55,963 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:03:55,964 INFO:     None feature selector for col prot
2022-11-28 03:03:55,964 INFO:     None feature selector for col prot
2022-11-28 03:03:55,964 INFO:     None feature selector for col prot
2022-11-28 03:03:55,965 INFO:     None feature selector for col chem
2022-11-28 03:03:55,965 INFO:     None feature selector for col chem
2022-11-28 03:03:55,965 INFO:     None feature selector for col chem
2022-11-28 03:03:55,965 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:03:55,965 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:03:55,966 INFO:     Number of params in model 169741
2022-11-28 03:03:55,969 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:03:55,970 INFO:   Starting stage: TRAINING
2022-11-28 03:03:56,023 INFO:     Val loss before train {'Reaction outcome loss': 1.0159520452672786, 'Total loss': 1.0159520452672786}
2022-11-28 03:03:56,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:56,024 INFO:     Epoch: 0
2022-11-28 03:03:56,775 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5291153578595682, 'Total loss': 0.5291153578595682} | train loss {'Reaction outcome loss': 0.644845999566167, 'Total loss': 0.644845999566167}
2022-11-28 03:03:56,775 INFO:     Found new best model at epoch 0
2022-11-28 03:03:56,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:56,776 INFO:     Epoch: 1
2022-11-28 03:03:57,525 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4857628541913899, 'Total loss': 0.4857628541913899} | train loss {'Reaction outcome loss': 0.5081440239903415, 'Total loss': 0.5081440239903415}
2022-11-28 03:03:57,525 INFO:     Found new best model at epoch 1
2022-11-28 03:03:57,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:57,526 INFO:     Epoch: 2
2022-11-28 03:03:58,279 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4774287881498987, 'Total loss': 0.4774287881498987} | train loss {'Reaction outcome loss': 0.45821816223835654, 'Total loss': 0.45821816223835654}
2022-11-28 03:03:58,280 INFO:     Found new best model at epoch 2
2022-11-28 03:03:58,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:58,280 INFO:     Epoch: 3
2022-11-28 03:03:59,034 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5348552329973741, 'Total loss': 0.5348552329973741} | train loss {'Reaction outcome loss': 0.4408198854459925, 'Total loss': 0.4408198854459925}
2022-11-28 03:03:59,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:59,034 INFO:     Epoch: 4
2022-11-28 03:03:59,787 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43258365751667455, 'Total loss': 0.43258365751667455} | train loss {'Reaction outcome loss': 0.4359912982715769, 'Total loss': 0.4359912982715769}
2022-11-28 03:03:59,787 INFO:     Found new best model at epoch 4
2022-11-28 03:03:59,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:03:59,788 INFO:     Epoch: 5
2022-11-28 03:04:00,537 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4617826278236779, 'Total loss': 0.4617826278236779} | train loss {'Reaction outcome loss': 0.4291458736788406, 'Total loss': 0.4291458736788406}
2022-11-28 03:04:00,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:00,537 INFO:     Epoch: 6
2022-11-28 03:04:01,289 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4274417500604283, 'Total loss': 0.4274417500604283} | train loss {'Reaction outcome loss': 0.39946543392140854, 'Total loss': 0.39946543392140854}
2022-11-28 03:04:01,289 INFO:     Found new best model at epoch 6
2022-11-28 03:04:01,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:01,290 INFO:     Epoch: 7
2022-11-28 03:04:02,045 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4613777527754957, 'Total loss': 0.4613777527754957} | train loss {'Reaction outcome loss': 0.3994646510976529, 'Total loss': 0.3994646510976529}
2022-11-28 03:04:02,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:02,045 INFO:     Epoch: 8
2022-11-28 03:04:02,795 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4295858984643763, 'Total loss': 0.4295858984643763} | train loss {'Reaction outcome loss': 0.3952929174851792, 'Total loss': 0.3952929174851792}
2022-11-28 03:04:02,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:02,795 INFO:     Epoch: 9
2022-11-28 03:04:03,547 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42506245049563324, 'Total loss': 0.42506245049563324} | train loss {'Reaction outcome loss': 0.4176421334084712, 'Total loss': 0.4176421334084712}
2022-11-28 03:04:03,547 INFO:     Found new best model at epoch 9
2022-11-28 03:04:03,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:03,548 INFO:     Epoch: 10
2022-11-28 03:04:04,297 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44289561140943656, 'Total loss': 0.44289561140943656} | train loss {'Reaction outcome loss': 0.39488126458562456, 'Total loss': 0.39488126458562456}
2022-11-28 03:04:04,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:04,297 INFO:     Epoch: 11
2022-11-28 03:04:05,046 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4837218299508095, 'Total loss': 0.4837218299508095} | train loss {'Reaction outcome loss': 0.3820672433385965, 'Total loss': 0.3820672433385965}
2022-11-28 03:04:05,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:05,047 INFO:     Epoch: 12
2022-11-28 03:04:05,798 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4278319738805294, 'Total loss': 0.4278319738805294} | train loss {'Reaction outcome loss': 0.3866224786509884, 'Total loss': 0.3866224786509884}
2022-11-28 03:04:05,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:05,799 INFO:     Epoch: 13
2022-11-28 03:04:06,551 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44455006142908876, 'Total loss': 0.44455006142908876} | train loss {'Reaction outcome loss': 0.37474703856626984, 'Total loss': 0.37474703856626984}
2022-11-28 03:04:06,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:06,551 INFO:     Epoch: 14
2022-11-28 03:04:07,305 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41972421533004806, 'Total loss': 0.41972421533004806} | train loss {'Reaction outcome loss': 0.3670654004281349, 'Total loss': 0.3670654004281349}
2022-11-28 03:04:07,305 INFO:     Found new best model at epoch 14
2022-11-28 03:04:07,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:07,306 INFO:     Epoch: 15
2022-11-28 03:04:08,059 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4380834624171257, 'Total loss': 0.4380834624171257} | train loss {'Reaction outcome loss': 0.37705539037220875, 'Total loss': 0.37705539037220875}
2022-11-28 03:04:08,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:08,059 INFO:     Epoch: 16
2022-11-28 03:04:08,810 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4382983479987491, 'Total loss': 0.4382983479987491} | train loss {'Reaction outcome loss': 0.37130506623249787, 'Total loss': 0.37130506623249787}
2022-11-28 03:04:08,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:08,810 INFO:     Epoch: 17
2022-11-28 03:04:09,562 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41598599404096603, 'Total loss': 0.41598599404096603} | train loss {'Reaction outcome loss': 0.3683845885852088, 'Total loss': 0.3683845885852088}
2022-11-28 03:04:09,563 INFO:     Found new best model at epoch 17
2022-11-28 03:04:09,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:09,563 INFO:     Epoch: 18
2022-11-28 03:04:10,321 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4265777339989489, 'Total loss': 0.4265777339989489} | train loss {'Reaction outcome loss': 0.3605790193445287, 'Total loss': 0.3605790193445287}
2022-11-28 03:04:10,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:10,321 INFO:     Epoch: 19
2022-11-28 03:04:11,074 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4070595773783597, 'Total loss': 0.4070595773783597} | train loss {'Reaction outcome loss': 0.35119738179421134, 'Total loss': 0.35119738179421134}
2022-11-28 03:04:11,074 INFO:     Found new best model at epoch 19
2022-11-28 03:04:11,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:11,075 INFO:     Epoch: 20
2022-11-28 03:04:11,828 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42893607677383855, 'Total loss': 0.42893607677383855} | train loss {'Reaction outcome loss': 0.3463543371150368, 'Total loss': 0.3463543371150368}
2022-11-28 03:04:11,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:11,828 INFO:     Epoch: 21
2022-11-28 03:04:12,580 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45633499459786847, 'Total loss': 0.45633499459786847} | train loss {'Reaction outcome loss': 0.34805921495322756, 'Total loss': 0.34805921495322756}
2022-11-28 03:04:12,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:12,580 INFO:     Epoch: 22
2022-11-28 03:04:13,335 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43946365521035413, 'Total loss': 0.43946365521035413} | train loss {'Reaction outcome loss': 0.35205415796171796, 'Total loss': 0.35205415796171796}
2022-11-28 03:04:13,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:13,336 INFO:     Epoch: 23
2022-11-28 03:04:14,086 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40065308050675824, 'Total loss': 0.40065308050675824} | train loss {'Reaction outcome loss': 0.36169422759018416, 'Total loss': 0.36169422759018416}
2022-11-28 03:04:14,086 INFO:     Found new best model at epoch 23
2022-11-28 03:04:14,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:14,087 INFO:     Epoch: 24
2022-11-28 03:04:14,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44701438600366766, 'Total loss': 0.44701438600366766} | train loss {'Reaction outcome loss': 0.3389070298567957, 'Total loss': 0.3389070298567957}
2022-11-28 03:04:14,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:14,839 INFO:     Epoch: 25
2022-11-28 03:04:15,588 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39768281570551073, 'Total loss': 0.39768281570551073} | train loss {'Reaction outcome loss': 0.3609015243919755, 'Total loss': 0.3609015243919755}
2022-11-28 03:04:15,588 INFO:     Found new best model at epoch 25
2022-11-28 03:04:15,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:15,589 INFO:     Epoch: 26
2022-11-28 03:04:16,341 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40022109245712106, 'Total loss': 0.40022109245712106} | train loss {'Reaction outcome loss': 0.3487363125797105, 'Total loss': 0.3487363125797105}
2022-11-28 03:04:16,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:16,342 INFO:     Epoch: 27
2022-11-28 03:04:17,094 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38467712023041467, 'Total loss': 0.38467712023041467} | train loss {'Reaction outcome loss': 0.3356701223988478, 'Total loss': 0.3356701223988478}
2022-11-28 03:04:17,094 INFO:     Found new best model at epoch 27
2022-11-28 03:04:17,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:17,095 INFO:     Epoch: 28
2022-11-28 03:04:17,850 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4075780114666982, 'Total loss': 0.4075780114666982} | train loss {'Reaction outcome loss': 0.331741390660851, 'Total loss': 0.331741390660851}
2022-11-28 03:04:17,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:17,851 INFO:     Epoch: 29
2022-11-28 03:04:18,606 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5124874459579587, 'Total loss': 0.5124874459579587} | train loss {'Reaction outcome loss': 0.3383250399096775, 'Total loss': 0.3383250399096775}
2022-11-28 03:04:18,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:18,607 INFO:     Epoch: 30
2022-11-28 03:04:19,356 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4094400344924493, 'Total loss': 0.4094400344924493} | train loss {'Reaction outcome loss': 0.3624101967962274, 'Total loss': 0.3624101967962274}
2022-11-28 03:04:19,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:19,356 INFO:     Epoch: 31
2022-11-28 03:04:20,111 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4673565778542649, 'Total loss': 0.4673565778542649} | train loss {'Reaction outcome loss': 0.3387047698050134, 'Total loss': 0.3387047698050134}
2022-11-28 03:04:20,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:20,112 INFO:     Epoch: 32
2022-11-28 03:04:20,867 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41860748725858604, 'Total loss': 0.41860748725858604} | train loss {'Reaction outcome loss': 0.3314412933762981, 'Total loss': 0.3314412933762981}
2022-11-28 03:04:20,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:20,867 INFO:     Epoch: 33
2022-11-28 03:04:21,619 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40973628786477173, 'Total loss': 0.40973628786477173} | train loss {'Reaction outcome loss': 0.3622127264919069, 'Total loss': 0.3622127264919069}
2022-11-28 03:04:21,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:21,619 INFO:     Epoch: 34
2022-11-28 03:04:22,373 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.417403633621606, 'Total loss': 0.417403633621606} | train loss {'Reaction outcome loss': 0.35075576462960134, 'Total loss': 0.35075576462960134}
2022-11-28 03:04:22,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:22,373 INFO:     Epoch: 35
2022-11-28 03:04:23,126 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40770991756157443, 'Total loss': 0.40770991756157443} | train loss {'Reaction outcome loss': 0.32559074208080047, 'Total loss': 0.32559074208080047}
2022-11-28 03:04:23,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:23,126 INFO:     Epoch: 36
2022-11-28 03:04:23,877 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45554517209529877, 'Total loss': 0.45554517209529877} | train loss {'Reaction outcome loss': 0.3465062159486869, 'Total loss': 0.3465062159486869}
2022-11-28 03:04:23,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:23,877 INFO:     Epoch: 37
2022-11-28 03:04:24,626 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4049265052784573, 'Total loss': 0.4049265052784573} | train loss {'Reaction outcome loss': 0.3211115280153071, 'Total loss': 0.3211115280153071}
2022-11-28 03:04:24,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:24,627 INFO:     Epoch: 38
2022-11-28 03:04:25,379 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4116022783246907, 'Total loss': 0.4116022783246907} | train loss {'Reaction outcome loss': 0.3345561153010318, 'Total loss': 0.3345561153010318}
2022-11-28 03:04:25,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:25,379 INFO:     Epoch: 39
2022-11-28 03:04:26,132 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42382649637081404, 'Total loss': 0.42382649637081404} | train loss {'Reaction outcome loss': 0.3587188408804326, 'Total loss': 0.3587188408804326}
2022-11-28 03:04:26,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:26,132 INFO:     Epoch: 40
2022-11-28 03:04:26,886 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43315805173055694, 'Total loss': 0.43315805173055694} | train loss {'Reaction outcome loss': 0.33431204993594515, 'Total loss': 0.33431204993594515}
2022-11-28 03:04:26,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:26,887 INFO:     Epoch: 41
2022-11-28 03:04:27,642 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3937542573972182, 'Total loss': 0.3937542573972182} | train loss {'Reaction outcome loss': 0.33579101908182807, 'Total loss': 0.33579101908182807}
2022-11-28 03:04:27,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:27,643 INFO:     Epoch: 42
2022-11-28 03:04:28,395 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41191694377498195, 'Total loss': 0.41191694377498195} | train loss {'Reaction outcome loss': 0.32555863069679575, 'Total loss': 0.32555863069679575}
2022-11-28 03:04:28,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:28,395 INFO:     Epoch: 43
2022-11-28 03:04:29,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3960754380307414, 'Total loss': 0.3960754380307414} | train loss {'Reaction outcome loss': 0.32683758381169725, 'Total loss': 0.32683758381169725}
2022-11-28 03:04:29,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:29,153 INFO:     Epoch: 44
2022-11-28 03:04:29,904 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40696938742290845, 'Total loss': 0.40696938742290845} | train loss {'Reaction outcome loss': 0.3125748627098948, 'Total loss': 0.3125748627098948}
2022-11-28 03:04:29,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:29,904 INFO:     Epoch: 45
2022-11-28 03:04:30,656 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41424084759571334, 'Total loss': 0.41424084759571334} | train loss {'Reaction outcome loss': 0.3139860473482715, 'Total loss': 0.3139860473482715}
2022-11-28 03:04:30,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:30,656 INFO:     Epoch: 46
2022-11-28 03:04:31,407 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3877849673682993, 'Total loss': 0.3877849673682993} | train loss {'Reaction outcome loss': 0.313367660259187, 'Total loss': 0.313367660259187}
2022-11-28 03:04:31,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:31,407 INFO:     Epoch: 47
2022-11-28 03:04:32,158 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4158789163286036, 'Total loss': 0.4158789163286036} | train loss {'Reaction outcome loss': 0.3189138491687022, 'Total loss': 0.3189138491687022}
2022-11-28 03:04:32,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:32,158 INFO:     Epoch: 48
2022-11-28 03:04:32,907 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4476446953009475, 'Total loss': 0.4476446953009475} | train loss {'Reaction outcome loss': 0.3136814474938852, 'Total loss': 0.3136814474938852}
2022-11-28 03:04:32,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:32,907 INFO:     Epoch: 49
2022-11-28 03:04:33,658 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4001649699427865, 'Total loss': 0.4001649699427865} | train loss {'Reaction outcome loss': 0.34580569284466595, 'Total loss': 0.34580569284466595}
2022-11-28 03:04:33,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:33,659 INFO:     Epoch: 50
2022-11-28 03:04:34,409 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42676079815084283, 'Total loss': 0.42676079815084283} | train loss {'Reaction outcome loss': 0.3265400726182258, 'Total loss': 0.3265400726182258}
2022-11-28 03:04:34,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:34,409 INFO:     Epoch: 51
2022-11-28 03:04:35,160 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43970981443470175, 'Total loss': 0.43970981443470175} | train loss {'Reaction outcome loss': 0.3191081572942406, 'Total loss': 0.3191081572942406}
2022-11-28 03:04:35,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:35,160 INFO:     Epoch: 52
2022-11-28 03:04:35,910 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4081178172068162, 'Total loss': 0.4081178172068162} | train loss {'Reaction outcome loss': 0.3168334613444834, 'Total loss': 0.3168334613444834}
2022-11-28 03:04:35,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:35,911 INFO:     Epoch: 53
2022-11-28 03:04:36,661 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4121626083823768, 'Total loss': 0.4121626083823768} | train loss {'Reaction outcome loss': 0.3091747605124949, 'Total loss': 0.3091747605124949}
2022-11-28 03:04:36,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:36,662 INFO:     Epoch: 54
2022-11-28 03:04:37,417 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39467440003698523, 'Total loss': 0.39467440003698523} | train loss {'Reaction outcome loss': 0.31049377358846575, 'Total loss': 0.31049377358846575}
2022-11-28 03:04:37,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:37,417 INFO:     Epoch: 55
2022-11-28 03:04:38,171 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40130192786455154, 'Total loss': 0.40130192786455154} | train loss {'Reaction outcome loss': 0.31854202818532706, 'Total loss': 0.31854202818532706}
2022-11-28 03:04:38,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:38,171 INFO:     Epoch: 56
2022-11-28 03:04:38,921 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.410923032598062, 'Total loss': 0.410923032598062} | train loss {'Reaction outcome loss': 0.30713812151720166, 'Total loss': 0.30713812151720166}
2022-11-28 03:04:38,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:38,922 INFO:     Epoch: 57
2022-11-28 03:04:39,675 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41570641472935677, 'Total loss': 0.41570641472935677} | train loss {'Reaction outcome loss': 0.31726163010365566, 'Total loss': 0.31726163010365566}
2022-11-28 03:04:39,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:39,675 INFO:     Epoch: 58
2022-11-28 03:04:40,429 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42627071047371085, 'Total loss': 0.42627071047371085} | train loss {'Reaction outcome loss': 0.3407354831605064, 'Total loss': 0.3407354831605064}
2022-11-28 03:04:40,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:40,429 INFO:     Epoch: 59
2022-11-28 03:04:41,182 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3901191313158382, 'Total loss': 0.3901191313158382} | train loss {'Reaction outcome loss': 0.32589324455150226, 'Total loss': 0.32589324455150226}
2022-11-28 03:04:41,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:41,182 INFO:     Epoch: 60
2022-11-28 03:04:41,938 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44085507128726353, 'Total loss': 0.44085507128726353} | train loss {'Reaction outcome loss': 0.33769542645466955, 'Total loss': 0.33769542645466955}
2022-11-28 03:04:41,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:41,938 INFO:     Epoch: 61
2022-11-28 03:04:42,692 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4078195829960433, 'Total loss': 0.4078195829960433} | train loss {'Reaction outcome loss': 0.3004880043025683, 'Total loss': 0.3004880043025683}
2022-11-28 03:04:42,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:42,692 INFO:     Epoch: 62
2022-11-28 03:04:43,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38755031065507367, 'Total loss': 0.38755031065507367} | train loss {'Reaction outcome loss': 0.3084082482297818, 'Total loss': 0.3084082482297818}
2022-11-28 03:04:43,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:43,446 INFO:     Epoch: 63
2022-11-28 03:04:44,195 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4082347997887568, 'Total loss': 0.4082347997887568} | train loss {'Reaction outcome loss': 0.30737083143963967, 'Total loss': 0.30737083143963967}
2022-11-28 03:04:44,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:44,195 INFO:     Epoch: 64
2022-11-28 03:04:44,947 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3746288847178221, 'Total loss': 0.3746288847178221} | train loss {'Reaction outcome loss': 0.30712821097810744, 'Total loss': 0.30712821097810744}
2022-11-28 03:04:44,947 INFO:     Found new best model at epoch 64
2022-11-28 03:04:44,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:44,948 INFO:     Epoch: 65
2022-11-28 03:04:45,704 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3793189115822315, 'Total loss': 0.3793189115822315} | train loss {'Reaction outcome loss': 0.3133649824239947, 'Total loss': 0.3133649824239947}
2022-11-28 03:04:45,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:45,704 INFO:     Epoch: 66
2022-11-28 03:04:46,455 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3980379765006629, 'Total loss': 0.3980379765006629} | train loss {'Reaction outcome loss': 0.3112829255038186, 'Total loss': 0.3112829255038186}
2022-11-28 03:04:46,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:46,455 INFO:     Epoch: 67
2022-11-28 03:04:47,207 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39691371233625844, 'Total loss': 0.39691371233625844} | train loss {'Reaction outcome loss': 0.317113634016033, 'Total loss': 0.317113634016033}
2022-11-28 03:04:47,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:47,207 INFO:     Epoch: 68
2022-11-28 03:04:47,957 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39639710736545647, 'Total loss': 0.39639710736545647} | train loss {'Reaction outcome loss': 0.3087057207337758, 'Total loss': 0.3087057207337758}
2022-11-28 03:04:47,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:47,957 INFO:     Epoch: 69
2022-11-28 03:04:48,703 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40697714483196085, 'Total loss': 0.40697714483196085} | train loss {'Reaction outcome loss': 0.30876815018690895, 'Total loss': 0.30876815018690895}
2022-11-28 03:04:48,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:48,703 INFO:     Epoch: 70
2022-11-28 03:04:49,453 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3970937854187055, 'Total loss': 0.3970937854187055} | train loss {'Reaction outcome loss': 0.3105391925917222, 'Total loss': 0.3105391925917222}
2022-11-28 03:04:49,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:49,454 INFO:     Epoch: 71
2022-11-28 03:04:50,202 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39058722081509506, 'Total loss': 0.39058722081509506} | train loss {'Reaction outcome loss': 0.311413449646249, 'Total loss': 0.311413449646249}
2022-11-28 03:04:50,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:50,202 INFO:     Epoch: 72
2022-11-28 03:04:50,950 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4417196854271672, 'Total loss': 0.4417196854271672} | train loss {'Reaction outcome loss': 0.3132522773417797, 'Total loss': 0.3132522773417797}
2022-11-28 03:04:50,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:50,950 INFO:     Epoch: 73
2022-11-28 03:04:51,696 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3834308683872223, 'Total loss': 0.3834308683872223} | train loss {'Reaction outcome loss': 0.30434369603841216, 'Total loss': 0.30434369603841216}
2022-11-28 03:04:51,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:51,696 INFO:     Epoch: 74
2022-11-28 03:04:52,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3876316598193212, 'Total loss': 0.3876316598193212} | train loss {'Reaction outcome loss': 0.3166522636919128, 'Total loss': 0.3166522636919128}
2022-11-28 03:04:52,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:52,445 INFO:     Epoch: 75
2022-11-28 03:04:53,194 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4088518394326622, 'Total loss': 0.4088518394326622} | train loss {'Reaction outcome loss': 0.3211289114386658, 'Total loss': 0.3211289114386658}
2022-11-28 03:04:53,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:53,194 INFO:     Epoch: 76
2022-11-28 03:04:53,946 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39798923988233914, 'Total loss': 0.39798923988233914} | train loss {'Reaction outcome loss': 0.3046377709866897, 'Total loss': 0.3046377709866897}
2022-11-28 03:04:53,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:53,946 INFO:     Epoch: 77
2022-11-28 03:04:54,698 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4042238103733821, 'Total loss': 0.4042238103733821} | train loss {'Reaction outcome loss': 0.32125285845476126, 'Total loss': 0.32125285845476126}
2022-11-28 03:04:54,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:54,698 INFO:     Epoch: 78
2022-11-28 03:04:55,446 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42171167412942107, 'Total loss': 0.42171167412942107} | train loss {'Reaction outcome loss': 0.3221615784563999, 'Total loss': 0.3221615784563999}
2022-11-28 03:04:55,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:55,446 INFO:     Epoch: 79
2022-11-28 03:04:56,197 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41745915467088873, 'Total loss': 0.41745915467088873} | train loss {'Reaction outcome loss': 0.3247504231577969, 'Total loss': 0.3247504231577969}
2022-11-28 03:04:56,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:56,197 INFO:     Epoch: 80
2022-11-28 03:04:56,946 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4239813759922981, 'Total loss': 0.4239813759922981} | train loss {'Reaction outcome loss': 0.3163894163331522, 'Total loss': 0.3163894163331522}
2022-11-28 03:04:56,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:56,946 INFO:     Epoch: 81
2022-11-28 03:04:57,696 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41111100363460457, 'Total loss': 0.41111100363460457} | train loss {'Reaction outcome loss': 0.3117999023482626, 'Total loss': 0.3117999023482626}
2022-11-28 03:04:57,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:57,696 INFO:     Epoch: 82
2022-11-28 03:04:58,447 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40431324900551274, 'Total loss': 0.40431324900551274} | train loss {'Reaction outcome loss': 0.31491750671795987, 'Total loss': 0.31491750671795987}
2022-11-28 03:04:58,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:58,448 INFO:     Epoch: 83
2022-11-28 03:04:59,201 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4024270982904868, 'Total loss': 0.4024270982904868} | train loss {'Reaction outcome loss': 0.3162601179922158, 'Total loss': 0.3162601179922158}
2022-11-28 03:04:59,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:59,201 INFO:     Epoch: 84
2022-11-28 03:04:59,954 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3935891410166567, 'Total loss': 0.3935891410166567} | train loss {'Reaction outcome loss': 0.31820741335028097, 'Total loss': 0.31820741335028097}
2022-11-28 03:04:59,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:04:59,954 INFO:     Epoch: 85
2022-11-28 03:05:00,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41239255192604934, 'Total loss': 0.41239255192604934} | train loss {'Reaction outcome loss': 0.31231916961278994, 'Total loss': 0.31231916961278994}
2022-11-28 03:05:00,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:00,702 INFO:     Epoch: 86
2022-11-28 03:05:01,452 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41853452202948654, 'Total loss': 0.41853452202948654} | train loss {'Reaction outcome loss': 0.3040855805500814, 'Total loss': 0.3040855805500814}
2022-11-28 03:05:01,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:01,452 INFO:     Epoch: 87
2022-11-28 03:05:02,200 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39525098218159244, 'Total loss': 0.39525098218159244} | train loss {'Reaction outcome loss': 0.31002156542018355, 'Total loss': 0.31002156542018355}
2022-11-28 03:05:02,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:02,200 INFO:     Epoch: 88
2022-11-28 03:05:02,947 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38714425706050615, 'Total loss': 0.38714425706050615} | train loss {'Reaction outcome loss': 0.3044537293990067, 'Total loss': 0.3044537293990067}
2022-11-28 03:05:02,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:02,948 INFO:     Epoch: 89
2022-11-28 03:05:03,697 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37105010907081043, 'Total loss': 0.37105010907081043} | train loss {'Reaction outcome loss': 0.30596146695311127, 'Total loss': 0.30596146695311127}
2022-11-28 03:05:03,697 INFO:     Found new best model at epoch 89
2022-11-28 03:05:03,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:03,698 INFO:     Epoch: 90
2022-11-28 03:05:04,449 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38873666812750424, 'Total loss': 0.38873666812750424} | train loss {'Reaction outcome loss': 0.29939401994349985, 'Total loss': 0.29939401994349985}
2022-11-28 03:05:04,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:04,449 INFO:     Epoch: 91
2022-11-28 03:05:05,201 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4301339062777432, 'Total loss': 0.4301339062777432} | train loss {'Reaction outcome loss': 0.3123511675413442, 'Total loss': 0.3123511675413442}
2022-11-28 03:05:05,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:05,201 INFO:     Epoch: 92
2022-11-28 03:05:05,950 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.397484594786709, 'Total loss': 0.397484594786709} | train loss {'Reaction outcome loss': 0.3043402306856173, 'Total loss': 0.3043402306856173}
2022-11-28 03:05:05,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:05,950 INFO:     Epoch: 93
2022-11-28 03:05:06,702 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3836136744780974, 'Total loss': 0.3836136744780974} | train loss {'Reaction outcome loss': 0.3028332410674346, 'Total loss': 0.3028332410674346}
2022-11-28 03:05:06,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:06,703 INFO:     Epoch: 94
2022-11-28 03:05:07,454 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.425193212587725, 'Total loss': 0.425193212587725} | train loss {'Reaction outcome loss': 0.3031862056116585, 'Total loss': 0.3031862056116585}
2022-11-28 03:05:07,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:07,454 INFO:     Epoch: 95
2022-11-28 03:05:08,200 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39486534673381934, 'Total loss': 0.39486534673381934} | train loss {'Reaction outcome loss': 0.3117596561316333, 'Total loss': 0.3117596561316333}
2022-11-28 03:05:08,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:08,201 INFO:     Epoch: 96
2022-11-28 03:05:08,951 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40660305761478166, 'Total loss': 0.40660305761478166} | train loss {'Reaction outcome loss': 0.3038611707432188, 'Total loss': 0.3038611707432188}
2022-11-28 03:05:08,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:08,952 INFO:     Epoch: 97
2022-11-28 03:05:09,703 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4007549380714243, 'Total loss': 0.4007549380714243} | train loss {'Reaction outcome loss': 0.30365798497187946, 'Total loss': 0.30365798497187946}
2022-11-28 03:05:09,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:09,704 INFO:     Epoch: 98
2022-11-28 03:05:10,452 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3678936595943841, 'Total loss': 0.3678936595943841} | train loss {'Reaction outcome loss': 0.30414270623191164, 'Total loss': 0.30414270623191164}
2022-11-28 03:05:10,452 INFO:     Found new best model at epoch 98
2022-11-28 03:05:10,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:10,453 INFO:     Epoch: 99
2022-11-28 03:05:11,203 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43563656915317883, 'Total loss': 0.43563656915317883} | train loss {'Reaction outcome loss': 0.29915930382032624, 'Total loss': 0.29915930382032624}
2022-11-28 03:05:11,203 INFO:     Best model found after epoch 99 of 100.
2022-11-28 03:05:11,203 INFO:   Done with stage: TRAINING
2022-11-28 03:05:11,203 INFO:   Starting stage: EVALUATION
2022-11-28 03:05:11,324 INFO:   Done with stage: EVALUATION
2022-11-28 03:05:11,324 INFO:   Leaving out SEQ value Fold_6
2022-11-28 03:05:11,337 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:05:11,338 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:05:11,979 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:05:11,979 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:05:12,048 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:05:12,048 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:05:12,048 INFO:     No hyperparam tuning for this model
2022-11-28 03:05:12,048 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:05:12,048 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:05:12,049 INFO:     None feature selector for col prot
2022-11-28 03:05:12,049 INFO:     None feature selector for col prot
2022-11-28 03:05:12,049 INFO:     None feature selector for col prot
2022-11-28 03:05:12,049 INFO:     None feature selector for col chem
2022-11-28 03:05:12,050 INFO:     None feature selector for col chem
2022-11-28 03:05:12,050 INFO:     None feature selector for col chem
2022-11-28 03:05:12,050 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:05:12,050 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:05:12,051 INFO:     Number of params in model 169741
2022-11-28 03:05:12,054 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:05:12,054 INFO:   Starting stage: TRAINING
2022-11-28 03:05:12,109 INFO:     Val loss before train {'Reaction outcome loss': 1.0173956927928058, 'Total loss': 1.0173956927928058}
2022-11-28 03:05:12,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:12,109 INFO:     Epoch: 0
2022-11-28 03:05:12,861 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.585261226377704, 'Total loss': 0.585261226377704} | train loss {'Reaction outcome loss': 0.6323927367526677, 'Total loss': 0.6323927367526677}
2022-11-28 03:05:12,861 INFO:     Found new best model at epoch 0
2022-11-28 03:05:12,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:12,862 INFO:     Epoch: 1
2022-11-28 03:05:13,615 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.502915274690498, 'Total loss': 0.502915274690498} | train loss {'Reaction outcome loss': 0.5054181371965716, 'Total loss': 0.5054181371965716}
2022-11-28 03:05:13,615 INFO:     Found new best model at epoch 1
2022-11-28 03:05:13,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:13,616 INFO:     Epoch: 2
2022-11-28 03:05:14,367 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5162240507250483, 'Total loss': 0.5162240507250483} | train loss {'Reaction outcome loss': 0.4678583046902091, 'Total loss': 0.4678583046902091}
2022-11-28 03:05:14,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:14,367 INFO:     Epoch: 3
2022-11-28 03:05:15,120 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5148941549387845, 'Total loss': 0.5148941549387845} | train loss {'Reaction outcome loss': 0.4439378642747479, 'Total loss': 0.4439378642747479}
2022-11-28 03:05:15,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:15,120 INFO:     Epoch: 4
2022-11-28 03:05:15,874 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45980111035433685, 'Total loss': 0.45980111035433685} | train loss {'Reaction outcome loss': 0.4284626562749186, 'Total loss': 0.4284626562749186}
2022-11-28 03:05:15,874 INFO:     Found new best model at epoch 4
2022-11-28 03:05:15,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:15,875 INFO:     Epoch: 5
2022-11-28 03:05:16,630 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47174514118920674, 'Total loss': 0.47174514118920674} | train loss {'Reaction outcome loss': 0.4193893103830276, 'Total loss': 0.4193893103830276}
2022-11-28 03:05:16,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:16,631 INFO:     Epoch: 6
2022-11-28 03:05:17,383 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45919094302437524, 'Total loss': 0.45919094302437524} | train loss {'Reaction outcome loss': 0.41292679294823637, 'Total loss': 0.41292679294823637}
2022-11-28 03:05:17,384 INFO:     Found new best model at epoch 6
2022-11-28 03:05:17,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:17,384 INFO:     Epoch: 7
2022-11-28 03:05:18,137 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46445099196650763, 'Total loss': 0.46445099196650763} | train loss {'Reaction outcome loss': 0.39872605131278116, 'Total loss': 0.39872605131278116}
2022-11-28 03:05:18,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:18,137 INFO:     Epoch: 8
2022-11-28 03:05:18,892 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43561000952666457, 'Total loss': 0.43561000952666457} | train loss {'Reaction outcome loss': 0.40198842724484785, 'Total loss': 0.40198842724484785}
2022-11-28 03:05:18,892 INFO:     Found new best model at epoch 8
2022-11-28 03:05:18,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:18,893 INFO:     Epoch: 9
2022-11-28 03:05:19,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46961851993745024, 'Total loss': 0.46961851993745024} | train loss {'Reaction outcome loss': 0.39861357897039384, 'Total loss': 0.39861357897039384}
2022-11-28 03:05:19,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:19,651 INFO:     Epoch: 10
2022-11-28 03:05:20,401 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4370557594705712, 'Total loss': 0.4370557594705712} | train loss {'Reaction outcome loss': 0.381262346050672, 'Total loss': 0.381262346050672}
2022-11-28 03:05:20,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:20,402 INFO:     Epoch: 11
2022-11-28 03:05:21,153 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44970810921354726, 'Total loss': 0.44970810921354726} | train loss {'Reaction outcome loss': 0.38208775751052365, 'Total loss': 0.38208775751052365}
2022-11-28 03:05:21,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:21,153 INFO:     Epoch: 12
2022-11-28 03:05:21,904 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45610460808331316, 'Total loss': 0.45610460808331316} | train loss {'Reaction outcome loss': 0.37877845418669526, 'Total loss': 0.37877845418669526}
2022-11-28 03:05:21,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:21,905 INFO:     Epoch: 13
2022-11-28 03:05:22,658 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.496848713606596, 'Total loss': 0.496848713606596} | train loss {'Reaction outcome loss': 0.3763130205953794, 'Total loss': 0.3763130205953794}
2022-11-28 03:05:22,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:22,658 INFO:     Epoch: 14
2022-11-28 03:05:23,416 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.439820086075501, 'Total loss': 0.439820086075501} | train loss {'Reaction outcome loss': 0.3735133730055344, 'Total loss': 0.3735133730055344}
2022-11-28 03:05:23,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:23,417 INFO:     Epoch: 15
2022-11-28 03:05:24,171 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48604087937961926, 'Total loss': 0.48604087937961926} | train loss {'Reaction outcome loss': 0.3693492743637293, 'Total loss': 0.3693492743637293}
2022-11-28 03:05:24,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:24,171 INFO:     Epoch: 16
2022-11-28 03:05:24,922 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4662051041695205, 'Total loss': 0.4662051041695205} | train loss {'Reaction outcome loss': 0.36419489318805354, 'Total loss': 0.36419489318805354}
2022-11-28 03:05:24,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:24,922 INFO:     Epoch: 17
2022-11-28 03:05:25,674 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4348611956970258, 'Total loss': 0.4348611956970258} | train loss {'Reaction outcome loss': 0.35793631172348417, 'Total loss': 0.35793631172348417}
2022-11-28 03:05:25,674 INFO:     Found new best model at epoch 17
2022-11-28 03:05:25,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:25,675 INFO:     Epoch: 18
2022-11-28 03:05:26,429 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43227956714955246, 'Total loss': 0.43227956714955246} | train loss {'Reaction outcome loss': 0.35849381899160726, 'Total loss': 0.35849381899160726}
2022-11-28 03:05:26,430 INFO:     Found new best model at epoch 18
2022-11-28 03:05:26,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:26,430 INFO:     Epoch: 19
2022-11-28 03:05:27,180 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4333891626447439, 'Total loss': 0.4333891626447439} | train loss {'Reaction outcome loss': 0.3530532482470716, 'Total loss': 0.3530532482470716}
2022-11-28 03:05:27,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:27,181 INFO:     Epoch: 20
2022-11-28 03:05:27,934 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44590035859834065, 'Total loss': 0.44590035859834065} | train loss {'Reaction outcome loss': 0.3554980580304419, 'Total loss': 0.3554980580304419}
2022-11-28 03:05:27,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:27,935 INFO:     Epoch: 21
2022-11-28 03:05:28,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4375206140631979, 'Total loss': 0.4375206140631979} | train loss {'Reaction outcome loss': 0.3573617574368273, 'Total loss': 0.3573617574368273}
2022-11-28 03:05:28,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:28,690 INFO:     Epoch: 22
2022-11-28 03:05:29,448 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4291249703277241, 'Total loss': 0.4291249703277241} | train loss {'Reaction outcome loss': 0.3555491374234759, 'Total loss': 0.3555491374234759}
2022-11-28 03:05:29,448 INFO:     Found new best model at epoch 22
2022-11-28 03:05:29,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:29,449 INFO:     Epoch: 23
2022-11-28 03:05:30,203 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45035279339010065, 'Total loss': 0.45035279339010065} | train loss {'Reaction outcome loss': 0.34386255225587276, 'Total loss': 0.34386255225587276}
2022-11-28 03:05:30,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:30,203 INFO:     Epoch: 24
2022-11-28 03:05:30,956 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4296092963354154, 'Total loss': 0.4296092963354154} | train loss {'Reaction outcome loss': 0.35242501763446676, 'Total loss': 0.35242501763446676}
2022-11-28 03:05:30,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:30,956 INFO:     Epoch: 25
2022-11-28 03:05:31,709 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43996737558733334, 'Total loss': 0.43996737558733334} | train loss {'Reaction outcome loss': 0.3453650544547746, 'Total loss': 0.3453650544547746}
2022-11-28 03:05:31,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:31,709 INFO:     Epoch: 26
2022-11-28 03:05:32,462 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.427385554056276, 'Total loss': 0.427385554056276} | train loss {'Reaction outcome loss': 0.3409360791105897, 'Total loss': 0.3409360791105897}
2022-11-28 03:05:32,462 INFO:     Found new best model at epoch 26
2022-11-28 03:05:32,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:32,463 INFO:     Epoch: 27
2022-11-28 03:05:33,219 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44404758750037715, 'Total loss': 0.44404758750037715} | train loss {'Reaction outcome loss': 0.34500400824171884, 'Total loss': 0.34500400824171884}
2022-11-28 03:05:33,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:33,220 INFO:     Epoch: 28
2022-11-28 03:05:33,973 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4524331065741452, 'Total loss': 0.4524331065741452} | train loss {'Reaction outcome loss': 0.3387073297654429, 'Total loss': 0.3387073297654429}
2022-11-28 03:05:33,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:33,973 INFO:     Epoch: 29
2022-11-28 03:05:34,732 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46500068970701913, 'Total loss': 0.46500068970701913} | train loss {'Reaction outcome loss': 0.34169797830644155, 'Total loss': 0.34169797830644155}
2022-11-28 03:05:34,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:34,732 INFO:     Epoch: 30
2022-11-28 03:05:35,486 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44841538776050915, 'Total loss': 0.44841538776050915} | train loss {'Reaction outcome loss': 0.34063726303077513, 'Total loss': 0.34063726303077513}
2022-11-28 03:05:35,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:35,487 INFO:     Epoch: 31
2022-11-28 03:05:36,242 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4309370761567896, 'Total loss': 0.4309370761567896} | train loss {'Reaction outcome loss': 0.3388309546956612, 'Total loss': 0.3388309546956612}
2022-11-28 03:05:36,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:36,242 INFO:     Epoch: 32
2022-11-28 03:05:36,996 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43500093116678973, 'Total loss': 0.43500093116678973} | train loss {'Reaction outcome loss': 0.3331091359948679, 'Total loss': 0.3331091359948679}
2022-11-28 03:05:36,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:36,997 INFO:     Epoch: 33
2022-11-28 03:05:37,755 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4424387082796205, 'Total loss': 0.4424387082796205} | train loss {'Reaction outcome loss': 0.3373512911400007, 'Total loss': 0.3373512911400007}
2022-11-28 03:05:37,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:37,755 INFO:     Epoch: 34
2022-11-28 03:05:38,510 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4450159878893332, 'Total loss': 0.4450159878893332} | train loss {'Reaction outcome loss': 0.3341348066685661, 'Total loss': 0.3341348066685661}
2022-11-28 03:05:38,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:38,511 INFO:     Epoch: 35
2022-11-28 03:05:39,266 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42407702146606013, 'Total loss': 0.42407702146606013} | train loss {'Reaction outcome loss': 0.33317432270175024, 'Total loss': 0.33317432270175024}
2022-11-28 03:05:39,266 INFO:     Found new best model at epoch 35
2022-11-28 03:05:39,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:39,267 INFO:     Epoch: 36
2022-11-28 03:05:40,024 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42673168348317797, 'Total loss': 0.42673168348317797} | train loss {'Reaction outcome loss': 0.33535802885589583, 'Total loss': 0.33535802885589583}
2022-11-28 03:05:40,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:40,025 INFO:     Epoch: 37
2022-11-28 03:05:40,783 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4205085194923661, 'Total loss': 0.4205085194923661} | train loss {'Reaction outcome loss': 0.3293505094705089, 'Total loss': 0.3293505094705089}
2022-11-28 03:05:40,784 INFO:     Found new best model at epoch 37
2022-11-28 03:05:40,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:40,784 INFO:     Epoch: 38
2022-11-28 03:05:41,539 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43006785721941426, 'Total loss': 0.43006785721941426} | train loss {'Reaction outcome loss': 0.3311667501205398, 'Total loss': 0.3311667501205398}
2022-11-28 03:05:41,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:41,540 INFO:     Epoch: 39
2022-11-28 03:05:42,298 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4476441161876375, 'Total loss': 0.4476441161876375} | train loss {'Reaction outcome loss': 0.33432800782423827, 'Total loss': 0.33432800782423827}
2022-11-28 03:05:42,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:42,298 INFO:     Epoch: 40
2022-11-28 03:05:43,050 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.407684040679173, 'Total loss': 0.407684040679173} | train loss {'Reaction outcome loss': 0.3298638938896118, 'Total loss': 0.3298638938896118}
2022-11-28 03:05:43,050 INFO:     Found new best model at epoch 40
2022-11-28 03:05:43,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:43,051 INFO:     Epoch: 41
2022-11-28 03:05:43,801 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42107250016521325, 'Total loss': 0.42107250016521325} | train loss {'Reaction outcome loss': 0.33082589552166963, 'Total loss': 0.33082589552166963}
2022-11-28 03:05:43,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:43,801 INFO:     Epoch: 42
2022-11-28 03:05:44,556 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43908925693143497, 'Total loss': 0.43908925693143497} | train loss {'Reaction outcome loss': 0.33186713756332475, 'Total loss': 0.33186713756332475}
2022-11-28 03:05:44,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:44,557 INFO:     Epoch: 43
2022-11-28 03:05:45,308 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4282145303758708, 'Total loss': 0.4282145303758708} | train loss {'Reaction outcome loss': 0.3177753539695855, 'Total loss': 0.3177753539695855}
2022-11-28 03:05:45,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:45,308 INFO:     Epoch: 44
2022-11-28 03:05:46,066 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4011743197386915, 'Total loss': 0.4011743197386915} | train loss {'Reaction outcome loss': 0.32677851367982164, 'Total loss': 0.32677851367982164}
2022-11-28 03:05:46,067 INFO:     Found new best model at epoch 44
2022-11-28 03:05:46,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:46,067 INFO:     Epoch: 45
2022-11-28 03:05:46,827 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44410827214067633, 'Total loss': 0.44410827214067633} | train loss {'Reaction outcome loss': 0.3282324668891247, 'Total loss': 0.3282324668891247}
2022-11-28 03:05:46,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:46,827 INFO:     Epoch: 46
2022-11-28 03:05:47,580 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4374612769619985, 'Total loss': 0.4374612769619985} | train loss {'Reaction outcome loss': 0.3203404121581585, 'Total loss': 0.3203404121581585}
2022-11-28 03:05:47,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:47,580 INFO:     Epoch: 47
2022-11-28 03:05:48,332 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43201780116016214, 'Total loss': 0.43201780116016214} | train loss {'Reaction outcome loss': 0.32486769037261126, 'Total loss': 0.32486769037261126}
2022-11-28 03:05:48,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:48,332 INFO:     Epoch: 48
2022-11-28 03:05:49,085 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47392258657650516, 'Total loss': 0.47392258657650516} | train loss {'Reaction outcome loss': 0.3227168557744834, 'Total loss': 0.3227168557744834}
2022-11-28 03:05:49,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:49,085 INFO:     Epoch: 49
2022-11-28 03:05:49,837 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4157603506676175, 'Total loss': 0.4157603506676175} | train loss {'Reaction outcome loss': 0.3260382184338185, 'Total loss': 0.3260382184338185}
2022-11-28 03:05:49,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:49,837 INFO:     Epoch: 50
2022-11-28 03:05:50,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43484956601803954, 'Total loss': 0.43484956601803954} | train loss {'Reaction outcome loss': 0.32306227075957483, 'Total loss': 0.32306227075957483}
2022-11-28 03:05:50,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:50,591 INFO:     Epoch: 51
2022-11-28 03:05:51,351 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41268795948814263, 'Total loss': 0.41268795948814263} | train loss {'Reaction outcome loss': 0.32441000589319774, 'Total loss': 0.32441000589319774}
2022-11-28 03:05:51,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:51,353 INFO:     Epoch: 52
2022-11-28 03:05:52,108 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41913547671654006, 'Total loss': 0.41913547671654006} | train loss {'Reaction outcome loss': 0.32196201555310716, 'Total loss': 0.32196201555310716}
2022-11-28 03:05:52,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:52,108 INFO:     Epoch: 53
2022-11-28 03:05:52,860 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43637408688664436, 'Total loss': 0.43637408688664436} | train loss {'Reaction outcome loss': 0.32966075843620685, 'Total loss': 0.32966075843620685}
2022-11-28 03:05:52,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:52,860 INFO:     Epoch: 54
2022-11-28 03:05:53,611 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47954426739703526, 'Total loss': 0.47954426739703526} | train loss {'Reaction outcome loss': 0.3318945380047925, 'Total loss': 0.3318945380047925}
2022-11-28 03:05:53,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:53,612 INFO:     Epoch: 55
2022-11-28 03:05:54,360 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4232373068278486, 'Total loss': 0.4232373068278486} | train loss {'Reaction outcome loss': 0.3206581404552825, 'Total loss': 0.3206581404552825}
2022-11-28 03:05:54,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:54,360 INFO:     Epoch: 56
2022-11-28 03:05:55,110 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41907689652659674, 'Total loss': 0.41907689652659674} | train loss {'Reaction outcome loss': 0.31991880957878405, 'Total loss': 0.31991880957878405}
2022-11-28 03:05:55,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:55,110 INFO:     Epoch: 57
2022-11-28 03:05:55,860 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42076693272048776, 'Total loss': 0.42076693272048776} | train loss {'Reaction outcome loss': 0.31753033483701365, 'Total loss': 0.31753033483701365}
2022-11-28 03:05:55,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:55,860 INFO:     Epoch: 58
2022-11-28 03:05:56,613 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4276221052489497, 'Total loss': 0.4276221052489497} | train loss {'Reaction outcome loss': 0.3204536188333746, 'Total loss': 0.3204536188333746}
2022-11-28 03:05:56,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:56,613 INFO:     Epoch: 59
2022-11-28 03:05:57,363 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4267254461618987, 'Total loss': 0.4267254461618987} | train loss {'Reaction outcome loss': 0.31635318977397775, 'Total loss': 0.31635318977397775}
2022-11-28 03:05:57,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:57,364 INFO:     Epoch: 60
2022-11-28 03:05:58,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48475494100288913, 'Total loss': 0.48475494100288913} | train loss {'Reaction outcome loss': 0.318232596521416, 'Total loss': 0.318232596521416}
2022-11-28 03:05:58,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:58,117 INFO:     Epoch: 61
2022-11-28 03:05:58,866 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.434593008661812, 'Total loss': 0.434593008661812} | train loss {'Reaction outcome loss': 0.32886954061987417, 'Total loss': 0.32886954061987417}
2022-11-28 03:05:58,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:58,867 INFO:     Epoch: 62
2022-11-28 03:05:59,615 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42741241306066513, 'Total loss': 0.42741241306066513} | train loss {'Reaction outcome loss': 0.32340784599223443, 'Total loss': 0.32340784599223443}
2022-11-28 03:05:59,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:05:59,615 INFO:     Epoch: 63
2022-11-28 03:06:00,359 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41477274014191196, 'Total loss': 0.41477274014191196} | train loss {'Reaction outcome loss': 0.3146041260671712, 'Total loss': 0.3146041260671712}
2022-11-28 03:06:00,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:00,359 INFO:     Epoch: 64
2022-11-28 03:06:01,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4026293937455524, 'Total loss': 0.4026293937455524} | train loss {'Reaction outcome loss': 0.3135559620155442, 'Total loss': 0.3135559620155442}
2022-11-28 03:06:01,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:01,109 INFO:     Epoch: 65
2022-11-28 03:06:01,859 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.453641318123449, 'Total loss': 0.453641318123449} | train loss {'Reaction outcome loss': 0.31572842898388065, 'Total loss': 0.31572842898388065}
2022-11-28 03:06:01,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:01,859 INFO:     Epoch: 66
2022-11-28 03:06:02,609 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42755992304195056, 'Total loss': 0.42755992304195056} | train loss {'Reaction outcome loss': 0.30745423796977245, 'Total loss': 0.30745423796977245}
2022-11-28 03:06:02,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:02,609 INFO:     Epoch: 67
2022-11-28 03:06:03,358 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43949823699552903, 'Total loss': 0.43949823699552903} | train loss {'Reaction outcome loss': 0.31578795440615187, 'Total loss': 0.31578795440615187}
2022-11-28 03:06:03,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:03,358 INFO:     Epoch: 68
2022-11-28 03:06:04,109 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4382585747675462, 'Total loss': 0.4382585747675462} | train loss {'Reaction outcome loss': 0.3219818188658645, 'Total loss': 0.3219818188658645}
2022-11-28 03:06:04,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:04,109 INFO:     Epoch: 69
2022-11-28 03:06:04,858 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42706147547472606, 'Total loss': 0.42706147547472606} | train loss {'Reaction outcome loss': 0.31716810935927975, 'Total loss': 0.31716810935927975}
2022-11-28 03:06:04,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:04,858 INFO:     Epoch: 70
2022-11-28 03:06:05,604 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48174343461340124, 'Total loss': 0.48174343461340124} | train loss {'Reaction outcome loss': 0.303876327500949, 'Total loss': 0.303876327500949}
2022-11-28 03:06:05,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:05,605 INFO:     Epoch: 71
2022-11-28 03:06:06,353 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4323641327633099, 'Total loss': 0.4323641327633099} | train loss {'Reaction outcome loss': 0.32500817746885363, 'Total loss': 0.32500817746885363}
2022-11-28 03:06:06,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:06,353 INFO:     Epoch: 72
2022-11-28 03:06:07,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43338105048645625, 'Total loss': 0.43338105048645625} | train loss {'Reaction outcome loss': 0.31978208881111875, 'Total loss': 0.31978208881111875}
2022-11-28 03:06:07,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:07,105 INFO:     Epoch: 73
2022-11-28 03:06:07,854 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43689385716888035, 'Total loss': 0.43689385716888035} | train loss {'Reaction outcome loss': 0.31479087096428676, 'Total loss': 0.31479087096428676}
2022-11-28 03:06:07,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:07,855 INFO:     Epoch: 74
2022-11-28 03:06:08,605 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4593326517126777, 'Total loss': 0.4593326517126777} | train loss {'Reaction outcome loss': 0.311734153138053, 'Total loss': 0.311734153138053}
2022-11-28 03:06:08,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:08,605 INFO:     Epoch: 75
2022-11-28 03:06:09,354 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4519526912746104, 'Total loss': 0.4519526912746104} | train loss {'Reaction outcome loss': 0.3126358466162797, 'Total loss': 0.3126358466162797}
2022-11-28 03:06:09,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:09,354 INFO:     Epoch: 76
2022-11-28 03:06:10,102 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48715446245941246, 'Total loss': 0.48715446245941246} | train loss {'Reaction outcome loss': 0.31922196379051576, 'Total loss': 0.31922196379051576}
2022-11-28 03:06:10,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:10,103 INFO:     Epoch: 77
2022-11-28 03:06:10,850 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44075426781042054, 'Total loss': 0.44075426781042054} | train loss {'Reaction outcome loss': 0.31437210888872225, 'Total loss': 0.31437210888872225}
2022-11-28 03:06:10,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:10,851 INFO:     Epoch: 78
2022-11-28 03:06:11,599 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43791393021290953, 'Total loss': 0.43791393021290953} | train loss {'Reaction outcome loss': 0.3159801691109615, 'Total loss': 0.3159801691109615}
2022-11-28 03:06:11,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:11,599 INFO:     Epoch: 79
2022-11-28 03:06:12,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45112723315303976, 'Total loss': 0.45112723315303976} | train loss {'Reaction outcome loss': 0.30670775458096494, 'Total loss': 0.30670775458096494}
2022-11-28 03:06:12,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:12,345 INFO:     Epoch: 80
2022-11-28 03:06:13,090 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42564169808544894, 'Total loss': 0.42564169808544894} | train loss {'Reaction outcome loss': 0.3114289613140206, 'Total loss': 0.3114289613140206}
2022-11-28 03:06:13,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:13,090 INFO:     Epoch: 81
2022-11-28 03:06:13,839 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4790616147220135, 'Total loss': 0.4790616147220135} | train loss {'Reaction outcome loss': 0.31964951852757123, 'Total loss': 0.31964951852757123}
2022-11-28 03:06:13,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:13,840 INFO:     Epoch: 82
2022-11-28 03:06:14,590 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4268978036601435, 'Total loss': 0.4268978036601435} | train loss {'Reaction outcome loss': 0.32169633187473784, 'Total loss': 0.32169633187473784}
2022-11-28 03:06:14,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:14,590 INFO:     Epoch: 83
2022-11-28 03:06:15,342 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4109086065807126, 'Total loss': 0.4109086065807126} | train loss {'Reaction outcome loss': 0.32060958841635334, 'Total loss': 0.32060958841635334}
2022-11-28 03:06:15,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:15,342 INFO:     Epoch: 84
2022-11-28 03:06:16,096 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4262685318562118, 'Total loss': 0.4262685318562118} | train loss {'Reaction outcome loss': 0.3149633404588507, 'Total loss': 0.3149633404588507}
2022-11-28 03:06:16,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:16,096 INFO:     Epoch: 85
2022-11-28 03:06:16,845 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.420718845657327, 'Total loss': 0.420718845657327} | train loss {'Reaction outcome loss': 0.3134476381894802, 'Total loss': 0.3134476381894802}
2022-11-28 03:06:16,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:16,845 INFO:     Epoch: 86
2022-11-28 03:06:17,589 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4251685819842599, 'Total loss': 0.4251685819842599} | train loss {'Reaction outcome loss': 0.3006566147350015, 'Total loss': 0.3006566147350015}
2022-11-28 03:06:17,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:17,589 INFO:     Epoch: 87
2022-11-28 03:06:18,337 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4491085078228604, 'Total loss': 0.4491085078228604} | train loss {'Reaction outcome loss': 0.3192859957475335, 'Total loss': 0.3192859957475335}
2022-11-28 03:06:18,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:18,337 INFO:     Epoch: 88
2022-11-28 03:06:19,085 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4158588566563346, 'Total loss': 0.4158588566563346} | train loss {'Reaction outcome loss': 0.31381369192874237, 'Total loss': 0.31381369192874237}
2022-11-28 03:06:19,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:19,086 INFO:     Epoch: 89
2022-11-28 03:06:19,832 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43995614553039725, 'Total loss': 0.43995614553039725} | train loss {'Reaction outcome loss': 0.30872913113524836, 'Total loss': 0.30872913113524836}
2022-11-28 03:06:19,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:19,832 INFO:     Epoch: 90
2022-11-28 03:06:20,580 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42553039877252147, 'Total loss': 0.42553039877252147} | train loss {'Reaction outcome loss': 0.31254055696509536, 'Total loss': 0.31254055696509536}
2022-11-28 03:06:20,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:20,580 INFO:     Epoch: 91
2022-11-28 03:06:21,331 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42762965708971024, 'Total loss': 0.42762965708971024} | train loss {'Reaction outcome loss': 0.31065333889977587, 'Total loss': 0.31065333889977587}
2022-11-28 03:06:21,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:21,331 INFO:     Epoch: 92
2022-11-28 03:06:22,081 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4508333866569129, 'Total loss': 0.4508333866569129} | train loss {'Reaction outcome loss': 0.3145437322917484, 'Total loss': 0.3145437322917484}
2022-11-28 03:06:22,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:22,083 INFO:     Epoch: 93
2022-11-28 03:06:22,831 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4109800576486371, 'Total loss': 0.4109800576486371} | train loss {'Reaction outcome loss': 0.3152945766585969, 'Total loss': 0.3152945766585969}
2022-11-28 03:06:22,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:22,832 INFO:     Epoch: 94
2022-11-28 03:06:23,577 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4354431432756511, 'Total loss': 0.4354431432756511} | train loss {'Reaction outcome loss': 0.31451372525865035, 'Total loss': 0.31451372525865035}
2022-11-28 03:06:23,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:23,577 INFO:     Epoch: 95
2022-11-28 03:06:24,325 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4276774183593013, 'Total loss': 0.4276774183593013} | train loss {'Reaction outcome loss': 0.3097433558394832, 'Total loss': 0.3097433558394832}
2022-11-28 03:06:24,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:24,326 INFO:     Epoch: 96
2022-11-28 03:06:25,073 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.446123462847688, 'Total loss': 0.446123462847688} | train loss {'Reaction outcome loss': 0.3113525398676434, 'Total loss': 0.3113525398676434}
2022-11-28 03:06:25,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:25,073 INFO:     Epoch: 97
2022-11-28 03:06:25,820 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43944728848609055, 'Total loss': 0.43944728848609055} | train loss {'Reaction outcome loss': 0.31148761579947126, 'Total loss': 0.31148761579947126}
2022-11-28 03:06:25,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:25,820 INFO:     Epoch: 98
2022-11-28 03:06:26,570 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41900362040508876, 'Total loss': 0.41900362040508876} | train loss {'Reaction outcome loss': 0.31753992842089745, 'Total loss': 0.31753992842089745}
2022-11-28 03:06:26,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:26,570 INFO:     Epoch: 99
2022-11-28 03:06:27,321 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4861836379224604, 'Total loss': 0.4861836379224604} | train loss {'Reaction outcome loss': 0.30911275008392913, 'Total loss': 0.30911275008392913}
2022-11-28 03:06:27,321 INFO:     Best model found after epoch 45 of 100.
2022-11-28 03:06:27,321 INFO:   Done with stage: TRAINING
2022-11-28 03:06:27,321 INFO:   Starting stage: EVALUATION
2022-11-28 03:06:27,437 INFO:   Done with stage: EVALUATION
2022-11-28 03:06:27,437 INFO:   Leaving out SEQ value Fold_7
2022-11-28 03:06:27,450 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:06:27,450 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:06:28,096 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:06:28,097 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:06:28,166 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:06:28,166 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:06:28,166 INFO:     No hyperparam tuning for this model
2022-11-28 03:06:28,166 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:06:28,166 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:06:28,167 INFO:     None feature selector for col prot
2022-11-28 03:06:28,167 INFO:     None feature selector for col prot
2022-11-28 03:06:28,167 INFO:     None feature selector for col prot
2022-11-28 03:06:28,168 INFO:     None feature selector for col chem
2022-11-28 03:06:28,168 INFO:     None feature selector for col chem
2022-11-28 03:06:28,168 INFO:     None feature selector for col chem
2022-11-28 03:06:28,168 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:06:28,168 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:06:28,170 INFO:     Number of params in model 169741
2022-11-28 03:06:28,173 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:06:28,173 INFO:   Starting stage: TRAINING
2022-11-28 03:06:28,227 INFO:     Val loss before train {'Reaction outcome loss': 1.0399081002582202, 'Total loss': 1.0399081002582202}
2022-11-28 03:06:28,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:28,227 INFO:     Epoch: 0
2022-11-28 03:06:28,980 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5915164324370298, 'Total loss': 0.5915164324370298} | train loss {'Reaction outcome loss': 0.6387318119166359, 'Total loss': 0.6387318119166359}
2022-11-28 03:06:28,980 INFO:     Found new best model at epoch 0
2022-11-28 03:06:28,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:28,981 INFO:     Epoch: 1
2022-11-28 03:06:29,727 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5203350687568838, 'Total loss': 0.5203350687568838} | train loss {'Reaction outcome loss': 0.5078488057779689, 'Total loss': 0.5078488057779689}
2022-11-28 03:06:29,727 INFO:     Found new best model at epoch 1
2022-11-28 03:06:29,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:29,728 INFO:     Epoch: 2
2022-11-28 03:06:30,475 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5031641362742945, 'Total loss': 0.5031641362742945} | train loss {'Reaction outcome loss': 0.4634667652388734, 'Total loss': 0.4634667652388734}
2022-11-28 03:06:30,476 INFO:     Found new best model at epoch 2
2022-11-28 03:06:30,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:30,476 INFO:     Epoch: 3
2022-11-28 03:06:31,225 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4993707957592877, 'Total loss': 0.4993707957592877} | train loss {'Reaction outcome loss': 0.4407667087451104, 'Total loss': 0.4407667087451104}
2022-11-28 03:06:31,225 INFO:     Found new best model at epoch 3
2022-11-28 03:06:31,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:31,226 INFO:     Epoch: 4
2022-11-28 03:06:31,975 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4779031259769743, 'Total loss': 0.4779031259769743} | train loss {'Reaction outcome loss': 0.42441966760182576, 'Total loss': 0.42441966760182576}
2022-11-28 03:06:31,975 INFO:     Found new best model at epoch 4
2022-11-28 03:06:31,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:31,976 INFO:     Epoch: 5
2022-11-28 03:06:32,728 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5379207923331044, 'Total loss': 0.5379207923331044} | train loss {'Reaction outcome loss': 0.41487473670032715, 'Total loss': 0.41487473670032715}
2022-11-28 03:06:32,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:32,728 INFO:     Epoch: 6
2022-11-28 03:06:33,478 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46201019463214005, 'Total loss': 0.46201019463214005} | train loss {'Reaction outcome loss': 0.4039907304630164, 'Total loss': 0.4039907304630164}
2022-11-28 03:06:33,478 INFO:     Found new best model at epoch 6
2022-11-28 03:06:33,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:33,479 INFO:     Epoch: 7
2022-11-28 03:06:34,229 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4721775342794982, 'Total loss': 0.4721775342794982} | train loss {'Reaction outcome loss': 0.39298543015555026, 'Total loss': 0.39298543015555026}
2022-11-28 03:06:34,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:34,230 INFO:     Epoch: 8
2022-11-28 03:06:34,979 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45939205383712595, 'Total loss': 0.45939205383712595} | train loss {'Reaction outcome loss': 0.3799336437556532, 'Total loss': 0.3799336437556532}
2022-11-28 03:06:34,979 INFO:     Found new best model at epoch 8
2022-11-28 03:06:34,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:34,980 INFO:     Epoch: 9
2022-11-28 03:06:35,726 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5409908917817202, 'Total loss': 0.5409908917817202} | train loss {'Reaction outcome loss': 0.3881885790896992, 'Total loss': 0.3881885790896992}
2022-11-28 03:06:35,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:35,726 INFO:     Epoch: 10
2022-11-28 03:06:36,476 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44623231210491876, 'Total loss': 0.44623231210491876} | train loss {'Reaction outcome loss': 0.38179424682241536, 'Total loss': 0.38179424682241536}
2022-11-28 03:06:36,476 INFO:     Found new best model at epoch 10
2022-11-28 03:06:36,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:36,477 INFO:     Epoch: 11
2022-11-28 03:06:37,224 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4616921730339527, 'Total loss': 0.4616921730339527} | train loss {'Reaction outcome loss': 0.3778287609137835, 'Total loss': 0.3778287609137835}
2022-11-28 03:06:37,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:37,225 INFO:     Epoch: 12
2022-11-28 03:06:37,972 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47344567796046083, 'Total loss': 0.47344567796046083} | train loss {'Reaction outcome loss': 0.37100750041164215, 'Total loss': 0.37100750041164215}
2022-11-28 03:06:37,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:37,972 INFO:     Epoch: 13
2022-11-28 03:06:38,725 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48294150829315186, 'Total loss': 0.48294150829315186} | train loss {'Reaction outcome loss': 0.35871590803106945, 'Total loss': 0.35871590803106945}
2022-11-28 03:06:38,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:38,725 INFO:     Epoch: 14
2022-11-28 03:06:39,472 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4332828071307052, 'Total loss': 0.4332828071307052} | train loss {'Reaction outcome loss': 0.3610527093311952, 'Total loss': 0.3610527093311952}
2022-11-28 03:06:39,472 INFO:     Found new best model at epoch 14
2022-11-28 03:06:39,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:39,473 INFO:     Epoch: 15
2022-11-28 03:06:40,222 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43330207297747786, 'Total loss': 0.43330207297747786} | train loss {'Reaction outcome loss': 0.36045867369900786, 'Total loss': 0.36045867369900786}
2022-11-28 03:06:40,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:40,223 INFO:     Epoch: 16
2022-11-28 03:06:40,970 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43210014125162904, 'Total loss': 0.43210014125162904} | train loss {'Reaction outcome loss': 0.3519665914617719, 'Total loss': 0.3519665914617719}
2022-11-28 03:06:40,970 INFO:     Found new best model at epoch 16
2022-11-28 03:06:40,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:40,971 INFO:     Epoch: 17
2022-11-28 03:06:41,720 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43705097687515343, 'Total loss': 0.43705097687515343} | train loss {'Reaction outcome loss': 0.3504236735583794, 'Total loss': 0.3504236735583794}
2022-11-28 03:06:41,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:41,720 INFO:     Epoch: 18
2022-11-28 03:06:42,470 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43552628362720663, 'Total loss': 0.43552628362720663} | train loss {'Reaction outcome loss': 0.3517225559560522, 'Total loss': 0.3517225559560522}
2022-11-28 03:06:42,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:42,471 INFO:     Epoch: 19
2022-11-28 03:06:43,222 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43552248112180014, 'Total loss': 0.43552248112180014} | train loss {'Reaction outcome loss': 0.3465197177513713, 'Total loss': 0.3465197177513713}
2022-11-28 03:06:43,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:43,222 INFO:     Epoch: 20
2022-11-28 03:06:43,970 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4404130953956734, 'Total loss': 0.4404130953956734} | train loss {'Reaction outcome loss': 0.34835545054727024, 'Total loss': 0.34835545054727024}
2022-11-28 03:06:43,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:43,971 INFO:     Epoch: 21
2022-11-28 03:06:44,721 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44161005470563064, 'Total loss': 0.44161005470563064} | train loss {'Reaction outcome loss': 0.3447852914011286, 'Total loss': 0.3447852914011286}
2022-11-28 03:06:44,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:44,721 INFO:     Epoch: 22
2022-11-28 03:06:45,467 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45864009620113805, 'Total loss': 0.45864009620113805} | train loss {'Reaction outcome loss': 0.34717048299048214, 'Total loss': 0.34717048299048214}
2022-11-28 03:06:45,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:45,468 INFO:     Epoch: 23
2022-11-28 03:06:46,214 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4625730799003081, 'Total loss': 0.4625730799003081} | train loss {'Reaction outcome loss': 0.33808601545470374, 'Total loss': 0.33808601545470374}
2022-11-28 03:06:46,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:46,214 INFO:     Epoch: 24
2022-11-28 03:06:46,961 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4402665350247513, 'Total loss': 0.4402665350247513} | train loss {'Reaction outcome loss': 0.3464029618208447, 'Total loss': 0.3464029618208447}
2022-11-28 03:06:46,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:46,961 INFO:     Epoch: 25
2022-11-28 03:06:47,708 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4459278610619632, 'Total loss': 0.4459278610619632} | train loss {'Reaction outcome loss': 0.33244726987135026, 'Total loss': 0.33244726987135026}
2022-11-28 03:06:47,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:47,708 INFO:     Epoch: 26
2022-11-28 03:06:48,459 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45844809440049256, 'Total loss': 0.45844809440049256} | train loss {'Reaction outcome loss': 0.32902935159302527, 'Total loss': 0.32902935159302527}
2022-11-28 03:06:48,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:48,460 INFO:     Epoch: 27
2022-11-28 03:06:49,215 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.434924856166948, 'Total loss': 0.434924856166948} | train loss {'Reaction outcome loss': 0.32448381428877193, 'Total loss': 0.32448381428877193}
2022-11-28 03:06:49,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:49,215 INFO:     Epoch: 28
2022-11-28 03:06:49,965 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44027310372753575, 'Total loss': 0.44027310372753575} | train loss {'Reaction outcome loss': 0.33768224421768417, 'Total loss': 0.33768224421768417}
2022-11-28 03:06:49,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:49,966 INFO:     Epoch: 29
2022-11-28 03:06:50,717 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43709949166937306, 'Total loss': 0.43709949166937306} | train loss {'Reaction outcome loss': 0.3338553981344786, 'Total loss': 0.3338553981344786}
2022-11-28 03:06:50,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:50,717 INFO:     Epoch: 30
2022-11-28 03:06:51,466 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42988898351111193, 'Total loss': 0.42988898351111193} | train loss {'Reaction outcome loss': 0.32306268892341083, 'Total loss': 0.32306268892341083}
2022-11-28 03:06:51,466 INFO:     Found new best model at epoch 30
2022-11-28 03:06:51,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:51,467 INFO:     Epoch: 31
2022-11-28 03:06:52,210 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45488062738017604, 'Total loss': 0.45488062738017604} | train loss {'Reaction outcome loss': 0.3239213113612946, 'Total loss': 0.3239213113612946}
2022-11-28 03:06:52,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:52,211 INFO:     Epoch: 32
2022-11-28 03:06:52,957 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43243105574087665, 'Total loss': 0.43243105574087665} | train loss {'Reaction outcome loss': 0.33229405045389165, 'Total loss': 0.33229405045389165}
2022-11-28 03:06:52,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:52,958 INFO:     Epoch: 33
2022-11-28 03:06:53,707 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4538981020450592, 'Total loss': 0.4538981020450592} | train loss {'Reaction outcome loss': 0.33780261111115256, 'Total loss': 0.33780261111115256}
2022-11-28 03:06:53,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:53,707 INFO:     Epoch: 34
2022-11-28 03:06:54,462 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43682245537638664, 'Total loss': 0.43682245537638664} | train loss {'Reaction outcome loss': 0.33561336934085817, 'Total loss': 0.33561336934085817}
2022-11-28 03:06:54,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:54,463 INFO:     Epoch: 35
2022-11-28 03:06:55,212 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4422800100662492, 'Total loss': 0.4422800100662492} | train loss {'Reaction outcome loss': 0.3292460253522281, 'Total loss': 0.3292460253522281}
2022-11-28 03:06:55,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:55,212 INFO:     Epoch: 36
2022-11-28 03:06:55,965 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4249385595321655, 'Total loss': 0.4249385595321655} | train loss {'Reaction outcome loss': 0.3311226511554372, 'Total loss': 0.3311226511554372}
2022-11-28 03:06:55,965 INFO:     Found new best model at epoch 36
2022-11-28 03:06:55,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:55,966 INFO:     Epoch: 37
2022-11-28 03:06:56,718 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43681885369799356, 'Total loss': 0.43681885369799356} | train loss {'Reaction outcome loss': 0.32867909671979084, 'Total loss': 0.32867909671979084}
2022-11-28 03:06:56,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:56,718 INFO:     Epoch: 38
2022-11-28 03:06:57,469 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42960015921430156, 'Total loss': 0.42960015921430156} | train loss {'Reaction outcome loss': 0.3229609483011788, 'Total loss': 0.3229609483011788}
2022-11-28 03:06:57,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:57,469 INFO:     Epoch: 39
2022-11-28 03:06:58,220 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47359015521678055, 'Total loss': 0.47359015521678055} | train loss {'Reaction outcome loss': 0.33229259188256915, 'Total loss': 0.33229259188256915}
2022-11-28 03:06:58,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:58,220 INFO:     Epoch: 40
2022-11-28 03:06:58,973 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44741857424378395, 'Total loss': 0.44741857424378395} | train loss {'Reaction outcome loss': 0.32155951929669224, 'Total loss': 0.32155951929669224}
2022-11-28 03:06:58,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:58,974 INFO:     Epoch: 41
2022-11-28 03:06:59,723 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45369658517566597, 'Total loss': 0.45369658517566597} | train loss {'Reaction outcome loss': 0.3212487726442276, 'Total loss': 0.3212487726442276}
2022-11-28 03:06:59,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:06:59,724 INFO:     Epoch: 42
2022-11-28 03:07:00,474 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43708856065164914, 'Total loss': 0.43708856065164914} | train loss {'Reaction outcome loss': 0.33110575714418966, 'Total loss': 0.33110575714418966}
2022-11-28 03:07:00,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:00,474 INFO:     Epoch: 43
2022-11-28 03:07:01,222 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4374564653262496, 'Total loss': 0.4374564653262496} | train loss {'Reaction outcome loss': 0.32075586631113, 'Total loss': 0.32075586631113}
2022-11-28 03:07:01,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:01,222 INFO:     Epoch: 44
2022-11-28 03:07:01,971 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4168490967289968, 'Total loss': 0.4168490967289968} | train loss {'Reaction outcome loss': 0.3215862099802302, 'Total loss': 0.3215862099802302}
2022-11-28 03:07:01,971 INFO:     Found new best model at epoch 44
2022-11-28 03:07:01,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:01,972 INFO:     Epoch: 45
2022-11-28 03:07:02,723 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48402645472775807, 'Total loss': 0.48402645472775807} | train loss {'Reaction outcome loss': 0.33057236154713937, 'Total loss': 0.33057236154713937}
2022-11-28 03:07:02,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:02,723 INFO:     Epoch: 46
2022-11-28 03:07:03,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4278863438151099, 'Total loss': 0.4278863438151099} | train loss {'Reaction outcome loss': 0.3254945791296421, 'Total loss': 0.3254945791296421}
2022-11-28 03:07:03,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:03,474 INFO:     Epoch: 47
2022-11-28 03:07:04,224 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42228437164290383, 'Total loss': 0.42228437164290383} | train loss {'Reaction outcome loss': 0.32300768550785797, 'Total loss': 0.32300768550785797}
2022-11-28 03:07:04,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:04,225 INFO:     Epoch: 48
2022-11-28 03:07:04,976 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4513274244964123, 'Total loss': 0.4513274244964123} | train loss {'Reaction outcome loss': 0.3189318929949114, 'Total loss': 0.3189318929949114}
2022-11-28 03:07:04,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:04,976 INFO:     Epoch: 49
2022-11-28 03:07:05,728 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42673941498452966, 'Total loss': 0.42673941498452966} | train loss {'Reaction outcome loss': 0.3242003095726813, 'Total loss': 0.3242003095726813}
2022-11-28 03:07:05,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:05,729 INFO:     Epoch: 50
2022-11-28 03:07:06,479 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4645691476762295, 'Total loss': 0.4645691476762295} | train loss {'Reaction outcome loss': 0.3198587648089855, 'Total loss': 0.3198587648089855}
2022-11-28 03:07:06,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:06,479 INFO:     Epoch: 51
2022-11-28 03:07:07,235 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43220234967090865, 'Total loss': 0.43220234967090865} | train loss {'Reaction outcome loss': 0.3199927958269273, 'Total loss': 0.3199927958269273}
2022-11-28 03:07:07,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:07,235 INFO:     Epoch: 52
2022-11-28 03:07:07,985 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49056436646391044, 'Total loss': 0.49056436646391044} | train loss {'Reaction outcome loss': 0.3207480294720059, 'Total loss': 0.3207480294720059}
2022-11-28 03:07:07,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:07,986 INFO:     Epoch: 53
2022-11-28 03:07:08,734 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4421826790679585, 'Total loss': 0.4421826790679585} | train loss {'Reaction outcome loss': 0.31786052459069797, 'Total loss': 0.31786052459069797}
2022-11-28 03:07:08,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:08,735 INFO:     Epoch: 54
2022-11-28 03:07:09,487 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44505289738828485, 'Total loss': 0.44505289738828485} | train loss {'Reaction outcome loss': 0.3164884046080612, 'Total loss': 0.3164884046080612}
2022-11-28 03:07:09,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:09,487 INFO:     Epoch: 55
2022-11-28 03:07:10,234 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4572574831545353, 'Total loss': 0.4572574831545353} | train loss {'Reaction outcome loss': 0.3141687952522789, 'Total loss': 0.3141687952522789}
2022-11-28 03:07:10,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:10,234 INFO:     Epoch: 56
2022-11-28 03:07:10,979 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44438417662273755, 'Total loss': 0.44438417662273755} | train loss {'Reaction outcome loss': 0.31912535090645355, 'Total loss': 0.31912535090645355}
2022-11-28 03:07:10,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:10,980 INFO:     Epoch: 57
2022-11-28 03:07:11,728 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42877549678087234, 'Total loss': 0.42877549678087234} | train loss {'Reaction outcome loss': 0.3187309051112783, 'Total loss': 0.3187309051112783}
2022-11-28 03:07:11,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:11,729 INFO:     Epoch: 58
2022-11-28 03:07:12,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4301396787843921, 'Total loss': 0.4301396787843921} | train loss {'Reaction outcome loss': 0.3107329554885866, 'Total loss': 0.3107329554885866}
2022-11-28 03:07:12,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:12,478 INFO:     Epoch: 59
2022-11-28 03:07:13,230 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4445208084176887, 'Total loss': 0.4445208084176887} | train loss {'Reaction outcome loss': 0.3205365620613579, 'Total loss': 0.3205365620613579}
2022-11-28 03:07:13,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:13,230 INFO:     Epoch: 60
2022-11-28 03:07:13,976 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43065092814239586, 'Total loss': 0.43065092814239586} | train loss {'Reaction outcome loss': 0.3179428776605956, 'Total loss': 0.3179428776605956}
2022-11-28 03:07:13,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:13,977 INFO:     Epoch: 61
2022-11-28 03:07:14,723 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45565064590085635, 'Total loss': 0.45565064590085635} | train loss {'Reaction outcome loss': 0.3123311648866342, 'Total loss': 0.3123311648866342}
2022-11-28 03:07:14,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:14,723 INFO:     Epoch: 62
2022-11-28 03:07:15,469 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4493065168234435, 'Total loss': 0.4493065168234435} | train loss {'Reaction outcome loss': 0.3163756292553679, 'Total loss': 0.3163756292553679}
2022-11-28 03:07:15,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:15,469 INFO:     Epoch: 63
2022-11-28 03:07:16,221 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46125835654410446, 'Total loss': 0.46125835654410446} | train loss {'Reaction outcome loss': 0.32030080533736655, 'Total loss': 0.32030080533736655}
2022-11-28 03:07:16,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:16,221 INFO:     Epoch: 64
2022-11-28 03:07:16,969 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4317672157829458, 'Total loss': 0.4317672157829458} | train loss {'Reaction outcome loss': 0.3251642189138839, 'Total loss': 0.3251642189138839}
2022-11-28 03:07:16,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:16,970 INFO:     Epoch: 65
2022-11-28 03:07:17,719 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4159664562480016, 'Total loss': 0.4159664562480016} | train loss {'Reaction outcome loss': 0.31301092503652456, 'Total loss': 0.31301092503652456}
2022-11-28 03:07:17,719 INFO:     Found new best model at epoch 65
2022-11-28 03:07:17,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:17,720 INFO:     Epoch: 66
2022-11-28 03:07:18,471 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45828924531286414, 'Total loss': 0.45828924531286414} | train loss {'Reaction outcome loss': 0.31788566951910335, 'Total loss': 0.31788566951910335}
2022-11-28 03:07:18,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:18,471 INFO:     Epoch: 67
2022-11-28 03:07:19,221 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43246506357734854, 'Total loss': 0.43246506357734854} | train loss {'Reaction outcome loss': 0.30692201594431556, 'Total loss': 0.30692201594431556}
2022-11-28 03:07:19,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:19,222 INFO:     Epoch: 68
2022-11-28 03:07:19,973 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4619832750071179, 'Total loss': 0.4619832750071179} | train loss {'Reaction outcome loss': 0.3144766887529723, 'Total loss': 0.3144766887529723}
2022-11-28 03:07:19,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:19,974 INFO:     Epoch: 69
2022-11-28 03:07:20,726 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45398308184336533, 'Total loss': 0.45398308184336533} | train loss {'Reaction outcome loss': 0.3126744673316998, 'Total loss': 0.3126744673316998}
2022-11-28 03:07:20,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:20,727 INFO:     Epoch: 70
2022-11-28 03:07:21,475 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43717697296630254, 'Total loss': 0.43717697296630254} | train loss {'Reaction outcome loss': 0.32254857705124923, 'Total loss': 0.32254857705124923}
2022-11-28 03:07:21,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:21,476 INFO:     Epoch: 71
2022-11-28 03:07:22,223 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42392483235082845, 'Total loss': 0.42392483235082845} | train loss {'Reaction outcome loss': 0.31303576390529353, 'Total loss': 0.31303576390529353}
2022-11-28 03:07:22,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:22,223 INFO:     Epoch: 72
2022-11-28 03:07:22,973 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4471121281385422, 'Total loss': 0.4471121281385422} | train loss {'Reaction outcome loss': 0.3066785413651697, 'Total loss': 0.3066785413651697}
2022-11-28 03:07:22,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:22,973 INFO:     Epoch: 73
2022-11-28 03:07:23,722 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.428120879964395, 'Total loss': 0.428120879964395} | train loss {'Reaction outcome loss': 0.3074778561600514, 'Total loss': 0.3074778561600514}
2022-11-28 03:07:23,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:23,722 INFO:     Epoch: 74
2022-11-28 03:07:24,469 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4543215344575318, 'Total loss': 0.4543215344575318} | train loss {'Reaction outcome loss': 0.3219851849360331, 'Total loss': 0.3219851849360331}
2022-11-28 03:07:24,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:24,470 INFO:     Epoch: 75
2022-11-28 03:07:25,224 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42708482491699135, 'Total loss': 0.42708482491699135} | train loss {'Reaction outcome loss': 0.31730311460071997, 'Total loss': 0.31730311460071997}
2022-11-28 03:07:25,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:25,225 INFO:     Epoch: 76
2022-11-28 03:07:25,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4406805956228213, 'Total loss': 0.4406805956228213} | train loss {'Reaction outcome loss': 0.307221443782891, 'Total loss': 0.307221443782891}
2022-11-28 03:07:25,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:25,979 INFO:     Epoch: 77
2022-11-28 03:07:26,728 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43903844261711295, 'Total loss': 0.43903844261711295} | train loss {'Reaction outcome loss': 0.313371033941005, 'Total loss': 0.313371033941005}
2022-11-28 03:07:26,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:26,728 INFO:     Epoch: 78
2022-11-28 03:07:27,478 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4631105227903886, 'Total loss': 0.4631105227903886} | train loss {'Reaction outcome loss': 0.31755574382541163, 'Total loss': 0.31755574382541163}
2022-11-28 03:07:27,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:27,478 INFO:     Epoch: 79
2022-11-28 03:07:28,231 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42078558660366316, 'Total loss': 0.42078558660366316} | train loss {'Reaction outcome loss': 0.3076956195216025, 'Total loss': 0.3076956195216025}
2022-11-28 03:07:28,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:28,231 INFO:     Epoch: 80
2022-11-28 03:07:28,981 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4353547529740767, 'Total loss': 0.4353547529740767} | train loss {'Reaction outcome loss': 0.3193166101832063, 'Total loss': 0.3193166101832063}
2022-11-28 03:07:28,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:28,981 INFO:     Epoch: 81
2022-11-28 03:07:29,732 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4404445517469536, 'Total loss': 0.4404445517469536} | train loss {'Reaction outcome loss': 0.31187221254672737, 'Total loss': 0.31187221254672737}
2022-11-28 03:07:29,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:29,733 INFO:     Epoch: 82
2022-11-28 03:07:30,482 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45725681869821116, 'Total loss': 0.45725681869821116} | train loss {'Reaction outcome loss': 0.3081176918180239, 'Total loss': 0.3081176918180239}
2022-11-28 03:07:30,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:30,483 INFO:     Epoch: 83
2022-11-28 03:07:31,233 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4690340781076388, 'Total loss': 0.4690340781076388} | train loss {'Reaction outcome loss': 0.31968276512118116, 'Total loss': 0.31968276512118116}
2022-11-28 03:07:31,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:31,233 INFO:     Epoch: 84
2022-11-28 03:07:31,987 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4369041391394355, 'Total loss': 0.4369041391394355} | train loss {'Reaction outcome loss': 0.3058537086772342, 'Total loss': 0.3058537086772342}
2022-11-28 03:07:31,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:31,987 INFO:     Epoch: 85
2022-11-28 03:07:32,738 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43068910762667656, 'Total loss': 0.43068910762667656} | train loss {'Reaction outcome loss': 0.3115916735222263, 'Total loss': 0.3115916735222263}
2022-11-28 03:07:32,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:32,738 INFO:     Epoch: 86
2022-11-28 03:07:33,488 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43012032183733856, 'Total loss': 0.43012032183733856} | train loss {'Reaction outcome loss': 0.30912026270262655, 'Total loss': 0.30912026270262655}
2022-11-28 03:07:33,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:33,489 INFO:     Epoch: 87
2022-11-28 03:07:34,238 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45073456909846177, 'Total loss': 0.45073456909846177} | train loss {'Reaction outcome loss': 0.31757265134083645, 'Total loss': 0.31757265134083645}
2022-11-28 03:07:34,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:34,239 INFO:     Epoch: 88
2022-11-28 03:07:34,986 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46733470548960293, 'Total loss': 0.46733470548960293} | train loss {'Reaction outcome loss': 0.30810696171453944, 'Total loss': 0.30810696171453944}
2022-11-28 03:07:34,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:34,986 INFO:     Epoch: 89
2022-11-28 03:07:35,736 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4718571989373727, 'Total loss': 0.4718571989373727} | train loss {'Reaction outcome loss': 0.3038387583388436, 'Total loss': 0.3038387583388436}
2022-11-28 03:07:35,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:35,737 INFO:     Epoch: 90
2022-11-28 03:07:36,487 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4643709175288677, 'Total loss': 0.4643709175288677} | train loss {'Reaction outcome loss': 0.32089936513934403, 'Total loss': 0.32089936513934403}
2022-11-28 03:07:36,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:36,487 INFO:     Epoch: 91
2022-11-28 03:07:37,238 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4385995085943829, 'Total loss': 0.4385995085943829} | train loss {'Reaction outcome loss': 0.3078831763517472, 'Total loss': 0.3078831763517472}
2022-11-28 03:07:37,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:37,238 INFO:     Epoch: 92
2022-11-28 03:07:37,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45317465913566674, 'Total loss': 0.45317465913566674} | train loss {'Reaction outcome loss': 0.3006838097447349, 'Total loss': 0.3006838097447349}
2022-11-28 03:07:37,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:37,990 INFO:     Epoch: 93
2022-11-28 03:07:38,742 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4197442578998479, 'Total loss': 0.4197442578998479} | train loss {'Reaction outcome loss': 0.31173163081609434, 'Total loss': 0.31173163081609434}
2022-11-28 03:07:38,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:38,742 INFO:     Epoch: 94
2022-11-28 03:07:39,491 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.475381731309674, 'Total loss': 0.475381731309674} | train loss {'Reaction outcome loss': 0.30539026474880593, 'Total loss': 0.30539026474880593}
2022-11-28 03:07:39,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:39,491 INFO:     Epoch: 95
2022-11-28 03:07:40,239 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46547283977270126, 'Total loss': 0.46547283977270126} | train loss {'Reaction outcome loss': 0.30864661950017175, 'Total loss': 0.30864661950017175}
2022-11-28 03:07:40,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:40,240 INFO:     Epoch: 96
2022-11-28 03:07:40,989 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4207239117134701, 'Total loss': 0.4207239117134701} | train loss {'Reaction outcome loss': 0.32505473740879565, 'Total loss': 0.32505473740879565}
2022-11-28 03:07:40,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:40,990 INFO:     Epoch: 97
2022-11-28 03:07:41,742 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4468359501863068, 'Total loss': 0.4468359501863068} | train loss {'Reaction outcome loss': 0.31696530665841793, 'Total loss': 0.31696530665841793}
2022-11-28 03:07:41,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:41,742 INFO:     Epoch: 98
2022-11-28 03:07:42,496 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4420519091866233, 'Total loss': 0.4420519091866233} | train loss {'Reaction outcome loss': 0.31491530338122, 'Total loss': 0.31491530338122}
2022-11-28 03:07:42,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:42,497 INFO:     Epoch: 99
2022-11-28 03:07:43,247 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46595648202029144, 'Total loss': 0.46595648202029144} | train loss {'Reaction outcome loss': 0.3194764748876614, 'Total loss': 0.3194764748876614}
2022-11-28 03:07:43,247 INFO:     Best model found after epoch 66 of 100.
2022-11-28 03:07:43,247 INFO:   Done with stage: TRAINING
2022-11-28 03:07:43,247 INFO:   Starting stage: EVALUATION
2022-11-28 03:07:43,363 INFO:   Done with stage: EVALUATION
2022-11-28 03:07:43,363 INFO:   Leaving out SEQ value Fold_8
2022-11-28 03:07:43,376 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:07:43,376 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:07:44,019 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:07:44,019 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:07:44,088 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:07:44,088 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:07:44,088 INFO:     No hyperparam tuning for this model
2022-11-28 03:07:44,088 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:07:44,088 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:07:44,089 INFO:     None feature selector for col prot
2022-11-28 03:07:44,089 INFO:     None feature selector for col prot
2022-11-28 03:07:44,089 INFO:     None feature selector for col prot
2022-11-28 03:07:44,090 INFO:     None feature selector for col chem
2022-11-28 03:07:44,090 INFO:     None feature selector for col chem
2022-11-28 03:07:44,090 INFO:     None feature selector for col chem
2022-11-28 03:07:44,090 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:07:44,090 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:07:44,091 INFO:     Number of params in model 169741
2022-11-28 03:07:44,094 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:07:44,094 INFO:   Starting stage: TRAINING
2022-11-28 03:07:44,148 INFO:     Val loss before train {'Reaction outcome loss': 0.9329289028590376, 'Total loss': 0.9329289028590376}
2022-11-28 03:07:44,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:44,148 INFO:     Epoch: 0
2022-11-28 03:07:44,892 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48004504157738254, 'Total loss': 0.48004504157738254} | train loss {'Reaction outcome loss': 0.6345174879680279, 'Total loss': 0.6345174879680279}
2022-11-28 03:07:44,892 INFO:     Found new best model at epoch 0
2022-11-28 03:07:44,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:44,893 INFO:     Epoch: 1
2022-11-28 03:07:45,639 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47310812601988966, 'Total loss': 0.47310812601988966} | train loss {'Reaction outcome loss': 0.5045231420561852, 'Total loss': 0.5045231420561852}
2022-11-28 03:07:45,639 INFO:     Found new best model at epoch 1
2022-11-28 03:07:45,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:45,640 INFO:     Epoch: 2
2022-11-28 03:07:46,387 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44636475667357445, 'Total loss': 0.44636475667357445} | train loss {'Reaction outcome loss': 0.46848069123833286, 'Total loss': 0.46848069123833286}
2022-11-28 03:07:46,387 INFO:     Found new best model at epoch 2
2022-11-28 03:07:46,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:46,388 INFO:     Epoch: 3
2022-11-28 03:07:47,133 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4543775326826356, 'Total loss': 0.4543775326826356} | train loss {'Reaction outcome loss': 0.4307003921041122, 'Total loss': 0.4307003921041122}
2022-11-28 03:07:47,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:47,134 INFO:     Epoch: 4
2022-11-28 03:07:47,881 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44837322390892287, 'Total loss': 0.44837322390892287} | train loss {'Reaction outcome loss': 0.42311238977107923, 'Total loss': 0.42311238977107923}
2022-11-28 03:07:47,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:47,881 INFO:     Epoch: 5
2022-11-28 03:07:48,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4411869452080943, 'Total loss': 0.4411869452080943} | train loss {'Reaction outcome loss': 0.4308753947233442, 'Total loss': 0.4308753947233442}
2022-11-28 03:07:48,627 INFO:     Found new best model at epoch 5
2022-11-28 03:07:48,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:48,628 INFO:     Epoch: 6
2022-11-28 03:07:49,371 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42305205728520046, 'Total loss': 0.42305205728520046} | train loss {'Reaction outcome loss': 0.4105219083577998, 'Total loss': 0.4105219083577998}
2022-11-28 03:07:49,372 INFO:     Found new best model at epoch 6
2022-11-28 03:07:49,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:49,372 INFO:     Epoch: 7
2022-11-28 03:07:50,116 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.436424967917529, 'Total loss': 0.436424967917529} | train loss {'Reaction outcome loss': 0.40513090928073836, 'Total loss': 0.40513090928073836}
2022-11-28 03:07:50,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:50,116 INFO:     Epoch: 8
2022-11-28 03:07:50,861 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4864215911789374, 'Total loss': 0.4864215911789374} | train loss {'Reaction outcome loss': 0.3984172501062092, 'Total loss': 0.3984172501062092}
2022-11-28 03:07:50,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:50,861 INFO:     Epoch: 9
2022-11-28 03:07:51,609 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40095399624922057, 'Total loss': 0.40095399624922057} | train loss {'Reaction outcome loss': 0.3931152544206815, 'Total loss': 0.3931152544206815}
2022-11-28 03:07:51,609 INFO:     Found new best model at epoch 9
2022-11-28 03:07:51,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:51,610 INFO:     Epoch: 10
2022-11-28 03:07:52,356 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4176413440568881, 'Total loss': 0.4176413440568881} | train loss {'Reaction outcome loss': 0.3778194374883706, 'Total loss': 0.3778194374883706}
2022-11-28 03:07:52,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:52,356 INFO:     Epoch: 11
2022-11-28 03:07:53,103 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4361154220320962, 'Total loss': 0.4361154220320962} | train loss {'Reaction outcome loss': 0.36841906043078737, 'Total loss': 0.36841906043078737}
2022-11-28 03:07:53,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:53,103 INFO:     Epoch: 12
2022-11-28 03:07:53,855 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4117186584255912, 'Total loss': 0.4117186584255912} | train loss {'Reaction outcome loss': 0.3698174995389062, 'Total loss': 0.3698174995389062}
2022-11-28 03:07:53,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:53,855 INFO:     Epoch: 13
2022-11-28 03:07:54,603 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40803530236536806, 'Total loss': 0.40803530236536806} | train loss {'Reaction outcome loss': 0.3627865686711029, 'Total loss': 0.3627865686711029}
2022-11-28 03:07:54,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:54,603 INFO:     Epoch: 14
2022-11-28 03:07:55,350 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40618679841811006, 'Total loss': 0.40618679841811006} | train loss {'Reaction outcome loss': 0.36701603720967585, 'Total loss': 0.36701603720967585}
2022-11-28 03:07:55,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:55,351 INFO:     Epoch: 15
2022-11-28 03:07:56,096 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4019879082387144, 'Total loss': 0.4019879082387144} | train loss {'Reaction outcome loss': 0.36039304967520963, 'Total loss': 0.36039304967520963}
2022-11-28 03:07:56,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:56,097 INFO:     Epoch: 16
2022-11-28 03:07:56,847 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4766029986468228, 'Total loss': 0.4766029986468228} | train loss {'Reaction outcome loss': 0.3527794026049525, 'Total loss': 0.3527794026049525}
2022-11-28 03:07:56,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:56,847 INFO:     Epoch: 17
2022-11-28 03:07:57,593 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3995605737648227, 'Total loss': 0.3995605737648227} | train loss {'Reaction outcome loss': 0.3595907413655221, 'Total loss': 0.3595907413655221}
2022-11-28 03:07:57,593 INFO:     Found new best model at epoch 17
2022-11-28 03:07:57,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:57,594 INFO:     Epoch: 18
2022-11-28 03:07:58,338 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4163219325921752, 'Total loss': 0.4163219325921752} | train loss {'Reaction outcome loss': 0.3585890575579786, 'Total loss': 0.3585890575579786}
2022-11-28 03:07:58,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:58,339 INFO:     Epoch: 19
2022-11-28 03:07:59,082 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4199926133521579, 'Total loss': 0.4199926133521579} | train loss {'Reaction outcome loss': 0.35111645084281684, 'Total loss': 0.35111645084281684}
2022-11-28 03:07:59,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:59,083 INFO:     Epoch: 20
2022-11-28 03:07:59,831 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4176597629081119, 'Total loss': 0.4176597629081119} | train loss {'Reaction outcome loss': 0.3496547532890007, 'Total loss': 0.3496547532890007}
2022-11-28 03:07:59,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:07:59,831 INFO:     Epoch: 21
2022-11-28 03:08:00,574 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44723854518749495, 'Total loss': 0.44723854518749495} | train loss {'Reaction outcome loss': 0.3559671381586476, 'Total loss': 0.3559671381586476}
2022-11-28 03:08:00,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:00,575 INFO:     Epoch: 22
2022-11-28 03:08:01,319 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39628772386773065, 'Total loss': 0.39628772386773065} | train loss {'Reaction outcome loss': 0.3464971469613433, 'Total loss': 0.3464971469613433}
2022-11-28 03:08:01,319 INFO:     Found new best model at epoch 22
2022-11-28 03:08:01,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:01,320 INFO:     Epoch: 23
2022-11-28 03:08:02,066 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39312475513328204, 'Total loss': 0.39312475513328204} | train loss {'Reaction outcome loss': 0.3456516499944061, 'Total loss': 0.3456516499944061}
2022-11-28 03:08:02,067 INFO:     Found new best model at epoch 23
2022-11-28 03:08:02,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:02,068 INFO:     Epoch: 24
2022-11-28 03:08:02,812 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4837102077224038, 'Total loss': 0.4837102077224038} | train loss {'Reaction outcome loss': 0.34878834813591925, 'Total loss': 0.34878834813591925}
2022-11-28 03:08:02,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:02,812 INFO:     Epoch: 25
2022-11-28 03:08:03,559 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43637476421215315, 'Total loss': 0.43637476421215315} | train loss {'Reaction outcome loss': 0.3816120696936542, 'Total loss': 0.3816120696936542}
2022-11-28 03:08:03,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:03,559 INFO:     Epoch: 26
2022-11-28 03:08:04,304 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42772442881356587, 'Total loss': 0.42772442881356587} | train loss {'Reaction outcome loss': 0.34596455609991483, 'Total loss': 0.34596455609991483}
2022-11-28 03:08:04,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:04,305 INFO:     Epoch: 27
2022-11-28 03:08:05,052 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4070979847826741, 'Total loss': 0.4070979847826741} | train loss {'Reaction outcome loss': 0.3454349520899024, 'Total loss': 0.3454349520899024}
2022-11-28 03:08:05,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:05,052 INFO:     Epoch: 28
2022-11-28 03:08:05,795 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4137976203452457, 'Total loss': 0.4137976203452457} | train loss {'Reaction outcome loss': 0.3546860366003957, 'Total loss': 0.3546860366003957}
2022-11-28 03:08:05,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:05,796 INFO:     Epoch: 29
2022-11-28 03:08:06,537 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4066830538213253, 'Total loss': 0.4066830538213253} | train loss {'Reaction outcome loss': 0.3615171207107513, 'Total loss': 0.3615171207107513}
2022-11-28 03:08:06,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:06,537 INFO:     Epoch: 30
2022-11-28 03:08:07,281 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42590967091647064, 'Total loss': 0.42590967091647064} | train loss {'Reaction outcome loss': 0.3491848135102627, 'Total loss': 0.3491848135102627}
2022-11-28 03:08:07,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:07,282 INFO:     Epoch: 31
2022-11-28 03:08:08,028 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40998766909946094, 'Total loss': 0.40998766909946094} | train loss {'Reaction outcome loss': 0.3290792090690088, 'Total loss': 0.3290792090690088}
2022-11-28 03:08:08,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:08,028 INFO:     Epoch: 32
2022-11-28 03:08:08,770 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4372473287988793, 'Total loss': 0.4372473287988793} | train loss {'Reaction outcome loss': 0.3280556550634052, 'Total loss': 0.3280556550634052}
2022-11-28 03:08:08,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:08,770 INFO:     Epoch: 33
2022-11-28 03:08:09,511 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42732601426541805, 'Total loss': 0.42732601426541805} | train loss {'Reaction outcome loss': 0.34115115843283444, 'Total loss': 0.34115115843283444}
2022-11-28 03:08:09,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:09,512 INFO:     Epoch: 34
2022-11-28 03:08:10,257 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4678230461749164, 'Total loss': 0.4678230461749164} | train loss {'Reaction outcome loss': 0.3326637060777378, 'Total loss': 0.3326637060777378}
2022-11-28 03:08:10,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:10,258 INFO:     Epoch: 35
2022-11-28 03:08:11,003 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38746986334974115, 'Total loss': 0.38746986334974115} | train loss {'Reaction outcome loss': 0.3304372723346297, 'Total loss': 0.3304372723346297}
2022-11-28 03:08:11,004 INFO:     Found new best model at epoch 35
2022-11-28 03:08:11,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:11,004 INFO:     Epoch: 36
2022-11-28 03:08:11,748 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38774984956464986, 'Total loss': 0.38774984956464986} | train loss {'Reaction outcome loss': 0.3265291879232596, 'Total loss': 0.3265291879232596}
2022-11-28 03:08:11,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:11,749 INFO:     Epoch: 37
2022-11-28 03:08:12,494 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4074028039520437, 'Total loss': 0.4074028039520437} | train loss {'Reaction outcome loss': 0.337469294154451, 'Total loss': 0.337469294154451}
2022-11-28 03:08:12,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:12,494 INFO:     Epoch: 38
2022-11-28 03:08:13,239 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43814811889420857, 'Total loss': 0.43814811889420857} | train loss {'Reaction outcome loss': 0.3161407015041301, 'Total loss': 0.3161407015041301}
2022-11-28 03:08:13,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:13,239 INFO:     Epoch: 39
2022-11-28 03:08:13,989 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.409770017193461, 'Total loss': 0.409770017193461} | train loss {'Reaction outcome loss': 0.32112837563219826, 'Total loss': 0.32112837563219826}
2022-11-28 03:08:13,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:13,989 INFO:     Epoch: 40
2022-11-28 03:08:14,737 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4170680164613507, 'Total loss': 0.4170680164613507} | train loss {'Reaction outcome loss': 0.3207756959746482, 'Total loss': 0.3207756959746482}
2022-11-28 03:08:14,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:14,738 INFO:     Epoch: 41
2022-11-28 03:08:15,483 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41555908728729596, 'Total loss': 0.41555908728729596} | train loss {'Reaction outcome loss': 0.3185754451855474, 'Total loss': 0.3185754451855474}
2022-11-28 03:08:15,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:15,483 INFO:     Epoch: 42
2022-11-28 03:08:16,232 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4220227792181752, 'Total loss': 0.4220227792181752} | train loss {'Reaction outcome loss': 0.3246151213553029, 'Total loss': 0.3246151213553029}
2022-11-28 03:08:16,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:16,232 INFO:     Epoch: 43
2022-11-28 03:08:16,979 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39895057237961074, 'Total loss': 0.39895057237961074} | train loss {'Reaction outcome loss': 0.3475108510448865, 'Total loss': 0.3475108510448865}
2022-11-28 03:08:16,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:16,979 INFO:     Epoch: 44
2022-11-28 03:08:17,726 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3716721187599681, 'Total loss': 0.3716721187599681} | train loss {'Reaction outcome loss': 0.3161245600776634, 'Total loss': 0.3161245600776634}
2022-11-28 03:08:17,726 INFO:     Found new best model at epoch 44
2022-11-28 03:08:17,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:17,727 INFO:     Epoch: 45
2022-11-28 03:08:18,474 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4095898460258137, 'Total loss': 0.4095898460258137} | train loss {'Reaction outcome loss': 0.32432605867624764, 'Total loss': 0.32432605867624764}
2022-11-28 03:08:18,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:18,475 INFO:     Epoch: 46
2022-11-28 03:08:19,220 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4059512686323036, 'Total loss': 0.4059512686323036} | train loss {'Reaction outcome loss': 0.3429190742100781, 'Total loss': 0.3429190742100781}
2022-11-28 03:08:19,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:19,221 INFO:     Epoch: 47
2022-11-28 03:08:19,965 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45088006945496256, 'Total loss': 0.45088006945496256} | train loss {'Reaction outcome loss': 0.3464396489022473, 'Total loss': 0.3464396489022473}
2022-11-28 03:08:19,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:19,965 INFO:     Epoch: 48
2022-11-28 03:08:20,715 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38669807209887286, 'Total loss': 0.38669807209887286} | train loss {'Reaction outcome loss': 0.3197604680833546, 'Total loss': 0.3197604680833546}
2022-11-28 03:08:20,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:20,715 INFO:     Epoch: 49
2022-11-28 03:08:21,460 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4581627005880529, 'Total loss': 0.4581627005880529} | train loss {'Reaction outcome loss': 0.33670413801785903, 'Total loss': 0.33670413801785903}
2022-11-28 03:08:21,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:21,460 INFO:     Epoch: 50
2022-11-28 03:08:22,204 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3995870663361116, 'Total loss': 0.3995870663361116} | train loss {'Reaction outcome loss': 0.32022719070134376, 'Total loss': 0.32022719070134376}
2022-11-28 03:08:22,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:22,204 INFO:     Epoch: 51
2022-11-28 03:08:22,946 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39432994106953795, 'Total loss': 0.39432994106953795} | train loss {'Reaction outcome loss': 0.32137268357453036, 'Total loss': 0.32137268357453036}
2022-11-28 03:08:22,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:22,946 INFO:     Epoch: 52
2022-11-28 03:08:23,691 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4188913916322318, 'Total loss': 0.4188913916322318} | train loss {'Reaction outcome loss': 0.31590345756788, 'Total loss': 0.31590345756788}
2022-11-28 03:08:23,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:23,692 INFO:     Epoch: 53
2022-11-28 03:08:24,438 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40469019318168814, 'Total loss': 0.40469019318168814} | train loss {'Reaction outcome loss': 0.314242968162303, 'Total loss': 0.314242968162303}
2022-11-28 03:08:24,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:24,438 INFO:     Epoch: 54
2022-11-28 03:08:25,182 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.427940849553455, 'Total loss': 0.427940849553455} | train loss {'Reaction outcome loss': 0.3190077839773676, 'Total loss': 0.3190077839773676}
2022-11-28 03:08:25,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:25,183 INFO:     Epoch: 55
2022-11-28 03:08:25,929 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4416636875407262, 'Total loss': 0.4416636875407262} | train loss {'Reaction outcome loss': 0.32048682313457677, 'Total loss': 0.32048682313457677}
2022-11-28 03:08:25,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:25,929 INFO:     Epoch: 56
2022-11-28 03:08:26,675 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4498490403321656, 'Total loss': 0.4498490403321656} | train loss {'Reaction outcome loss': 0.32333463047972083, 'Total loss': 0.32333463047972083}
2022-11-28 03:08:26,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:26,676 INFO:     Epoch: 57
2022-11-28 03:08:27,418 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4291515546766194, 'Total loss': 0.4291515546766194} | train loss {'Reaction outcome loss': 0.3169814846836604, 'Total loss': 0.3169814846836604}
2022-11-28 03:08:27,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:27,418 INFO:     Epoch: 58
2022-11-28 03:08:28,163 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41087026081301947, 'Total loss': 0.41087026081301947} | train loss {'Reaction outcome loss': 0.313897275822124, 'Total loss': 0.313897275822124}
2022-11-28 03:08:28,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:28,163 INFO:     Epoch: 59
2022-11-28 03:08:28,911 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3937524819577282, 'Total loss': 0.3937524819577282} | train loss {'Reaction outcome loss': 0.32186527233495404, 'Total loss': 0.32186527233495404}
2022-11-28 03:08:28,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:28,911 INFO:     Epoch: 60
2022-11-28 03:08:29,654 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43790789727460255, 'Total loss': 0.43790789727460255} | train loss {'Reaction outcome loss': 0.32370773849156703, 'Total loss': 0.32370773849156703}
2022-11-28 03:08:29,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:29,654 INFO:     Epoch: 61
2022-11-28 03:08:30,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4144944836470214, 'Total loss': 0.4144944836470214} | train loss {'Reaction outcome loss': 0.31686005244895943, 'Total loss': 0.31686005244895943}
2022-11-28 03:08:30,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:30,398 INFO:     Epoch: 62
2022-11-28 03:08:31,145 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4157663681967692, 'Total loss': 0.4157663681967692} | train loss {'Reaction outcome loss': 0.30865574179326566, 'Total loss': 0.30865574179326566}
2022-11-28 03:08:31,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:31,145 INFO:     Epoch: 63
2022-11-28 03:08:31,892 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41389345039020886, 'Total loss': 0.41389345039020886} | train loss {'Reaction outcome loss': 0.31295484293870596, 'Total loss': 0.31295484293870596}
2022-11-28 03:08:31,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:31,892 INFO:     Epoch: 64
2022-11-28 03:08:32,640 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4113594764335589, 'Total loss': 0.4113594764335589} | train loss {'Reaction outcome loss': 0.31508272939652904, 'Total loss': 0.31508272939652904}
2022-11-28 03:08:32,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:32,640 INFO:     Epoch: 65
2022-11-28 03:08:33,388 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40114804077893496, 'Total loss': 0.40114804077893496} | train loss {'Reaction outcome loss': 0.31715137942841176, 'Total loss': 0.31715137942841176}
2022-11-28 03:08:33,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:33,388 INFO:     Epoch: 66
2022-11-28 03:08:34,135 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4003378459337083, 'Total loss': 0.4003378459337083} | train loss {'Reaction outcome loss': 0.3565357852244546, 'Total loss': 0.3565357852244546}
2022-11-28 03:08:34,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:34,135 INFO:     Epoch: 67
2022-11-28 03:08:34,879 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40962940556081856, 'Total loss': 0.40962940556081856} | train loss {'Reaction outcome loss': 0.32846927694101563, 'Total loss': 0.32846927694101563}
2022-11-28 03:08:34,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:34,880 INFO:     Epoch: 68
2022-11-28 03:08:35,623 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4120593216608871, 'Total loss': 0.4120593216608871} | train loss {'Reaction outcome loss': 0.31787839234026094, 'Total loss': 0.31787839234026094}
2022-11-28 03:08:35,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:35,623 INFO:     Epoch: 69
2022-11-28 03:08:36,373 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45118253949013626, 'Total loss': 0.45118253949013626} | train loss {'Reaction outcome loss': 0.3228682790871574, 'Total loss': 0.3228682790871574}
2022-11-28 03:08:36,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:36,373 INFO:     Epoch: 70
2022-11-28 03:08:37,119 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43937786465341394, 'Total loss': 0.43937786465341394} | train loss {'Reaction outcome loss': 0.3198874299282487, 'Total loss': 0.3198874299282487}
2022-11-28 03:08:37,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:37,119 INFO:     Epoch: 71
2022-11-28 03:08:37,867 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42667363211512566, 'Total loss': 0.42667363211512566} | train loss {'Reaction outcome loss': 0.32862069946430955, 'Total loss': 0.32862069946430955}
2022-11-28 03:08:37,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:37,867 INFO:     Epoch: 72
2022-11-28 03:08:38,611 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39418473230166867, 'Total loss': 0.39418473230166867} | train loss {'Reaction outcome loss': 0.32942659742677743, 'Total loss': 0.32942659742677743}
2022-11-28 03:08:38,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:38,611 INFO:     Epoch: 73
2022-11-28 03:08:39,355 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4210984524000775, 'Total loss': 0.4210984524000775} | train loss {'Reaction outcome loss': 0.311110035701078, 'Total loss': 0.311110035701078}
2022-11-28 03:08:39,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:39,355 INFO:     Epoch: 74
2022-11-28 03:08:40,100 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3961486382917924, 'Total loss': 0.3961486382917924} | train loss {'Reaction outcome loss': 0.32041808310413056, 'Total loss': 0.32041808310413056}
2022-11-28 03:08:40,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:40,100 INFO:     Epoch: 75
2022-11-28 03:08:40,846 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40336715514686977, 'Total loss': 0.40336715514686977} | train loss {'Reaction outcome loss': 0.3123226391706759, 'Total loss': 0.3123226391706759}
2022-11-28 03:08:40,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:40,846 INFO:     Epoch: 76
2022-11-28 03:08:41,591 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4224965882233598, 'Total loss': 0.4224965882233598} | train loss {'Reaction outcome loss': 0.3046253820964199, 'Total loss': 0.3046253820964199}
2022-11-28 03:08:41,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:41,591 INFO:     Epoch: 77
2022-11-28 03:08:42,336 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4380864470519803, 'Total loss': 0.4380864470519803} | train loss {'Reaction outcome loss': 0.30437755316254583, 'Total loss': 0.30437755316254583}
2022-11-28 03:08:42,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:42,336 INFO:     Epoch: 78
2022-11-28 03:08:43,092 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41187198036773637, 'Total loss': 0.41187198036773637} | train loss {'Reaction outcome loss': 0.3009982356492445, 'Total loss': 0.3009982356492445}
2022-11-28 03:08:43,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:43,093 INFO:     Epoch: 79
2022-11-28 03:08:43,857 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40516515499488875, 'Total loss': 0.40516515499488875} | train loss {'Reaction outcome loss': 0.3421163261841666, 'Total loss': 0.3421163261841666}
2022-11-28 03:08:43,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:43,857 INFO:     Epoch: 80
2022-11-28 03:08:44,623 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4577528600665656, 'Total loss': 0.4577528600665656} | train loss {'Reaction outcome loss': 0.32474706393594927, 'Total loss': 0.32474706393594927}
2022-11-28 03:08:44,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:44,623 INFO:     Epoch: 81
2022-11-28 03:08:45,383 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4055865064940669, 'Total loss': 0.4055865064940669} | train loss {'Reaction outcome loss': 0.3171844106876416, 'Total loss': 0.3171844106876416}
2022-11-28 03:08:45,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:45,383 INFO:     Epoch: 82
2022-11-28 03:08:46,143 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4324186227538369, 'Total loss': 0.4324186227538369} | train loss {'Reaction outcome loss': 0.33299182283009593, 'Total loss': 0.33299182283009593}
2022-11-28 03:08:46,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:46,143 INFO:     Epoch: 83
2022-11-28 03:08:46,905 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41086005385626445, 'Total loss': 0.41086005385626445} | train loss {'Reaction outcome loss': 0.31914319767643085, 'Total loss': 0.31914319767643085}
2022-11-28 03:08:46,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:46,905 INFO:     Epoch: 84
2022-11-28 03:08:47,669 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4008138333870606, 'Total loss': 0.4008138333870606} | train loss {'Reaction outcome loss': 0.3328664970965038, 'Total loss': 0.3328664970965038}
2022-11-28 03:08:47,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:47,669 INFO:     Epoch: 85
2022-11-28 03:08:48,427 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4195528250526298, 'Total loss': 0.4195528250526298} | train loss {'Reaction outcome loss': 0.3283880099292226, 'Total loss': 0.3283880099292226}
2022-11-28 03:08:48,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:48,427 INFO:     Epoch: 86
2022-11-28 03:08:49,185 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4023398486050693, 'Total loss': 0.4023398486050693} | train loss {'Reaction outcome loss': 0.31430701802103866, 'Total loss': 0.31430701802103866}
2022-11-28 03:08:49,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:49,185 INFO:     Epoch: 87
2022-11-28 03:08:49,945 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4291514371606437, 'Total loss': 0.4291514371606437} | train loss {'Reaction outcome loss': 0.30168988757770554, 'Total loss': 0.30168988757770554}
2022-11-28 03:08:49,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:49,946 INFO:     Epoch: 88
2022-11-28 03:08:50,707 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43879186091097916, 'Total loss': 0.43879186091097916} | train loss {'Reaction outcome loss': 0.3109425006487109, 'Total loss': 0.3109425006487109}
2022-11-28 03:08:50,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:50,708 INFO:     Epoch: 89
2022-11-28 03:08:51,469 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3948741040446542, 'Total loss': 0.3948741040446542} | train loss {'Reaction outcome loss': 0.3126343603204438, 'Total loss': 0.3126343603204438}
2022-11-28 03:08:51,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:51,469 INFO:     Epoch: 90
2022-11-28 03:08:52,229 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3890477864241058, 'Total loss': 0.3890477864241058} | train loss {'Reaction outcome loss': 0.30645628388111407, 'Total loss': 0.30645628388111407}
2022-11-28 03:08:52,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:52,230 INFO:     Epoch: 91
2022-11-28 03:08:52,989 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46684530580585654, 'Total loss': 0.46684530580585654} | train loss {'Reaction outcome loss': 0.31102354824543, 'Total loss': 0.31102354824543}
2022-11-28 03:08:52,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:52,989 INFO:     Epoch: 92
2022-11-28 03:08:53,752 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40546073256568477, 'Total loss': 0.40546073256568477} | train loss {'Reaction outcome loss': 0.3090322452337153, 'Total loss': 0.3090322452337153}
2022-11-28 03:08:53,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:53,752 INFO:     Epoch: 93
2022-11-28 03:08:54,510 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40321179377761757, 'Total loss': 0.40321179377761757} | train loss {'Reaction outcome loss': 0.3061706971543038, 'Total loss': 0.3061706971543038}
2022-11-28 03:08:54,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:54,511 INFO:     Epoch: 94
2022-11-28 03:08:55,271 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38270553370768373, 'Total loss': 0.38270553370768373} | train loss {'Reaction outcome loss': 0.3298693620543248, 'Total loss': 0.3298693620543248}
2022-11-28 03:08:55,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:55,271 INFO:     Epoch: 95
2022-11-28 03:08:56,035 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4021871110255068, 'Total loss': 0.4021871110255068} | train loss {'Reaction outcome loss': 0.30434055626751744, 'Total loss': 0.30434055626751744}
2022-11-28 03:08:56,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:56,035 INFO:     Epoch: 96
2022-11-28 03:08:56,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4790762234479189, 'Total loss': 0.4790762234479189} | train loss {'Reaction outcome loss': 0.29639588567892067, 'Total loss': 0.29639588567892067}
2022-11-28 03:08:56,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:56,796 INFO:     Epoch: 97
2022-11-28 03:08:57,557 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43295594541863963, 'Total loss': 0.43295594541863963} | train loss {'Reaction outcome loss': 0.31186622955840126, 'Total loss': 0.31186622955840126}
2022-11-28 03:08:57,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:57,558 INFO:     Epoch: 98
2022-11-28 03:08:58,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41138130629604513, 'Total loss': 0.41138130629604513} | train loss {'Reaction outcome loss': 0.29799534576503856, 'Total loss': 0.29799534576503856}
2022-11-28 03:08:58,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:58,319 INFO:     Epoch: 99
2022-11-28 03:08:59,080 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43088850141926244, 'Total loss': 0.43088850141926244} | train loss {'Reaction outcome loss': 0.3134669173463636, 'Total loss': 0.3134669173463636}
2022-11-28 03:08:59,080 INFO:     Best model found after epoch 45 of 100.
2022-11-28 03:08:59,081 INFO:   Done with stage: TRAINING
2022-11-28 03:08:59,081 INFO:   Starting stage: EVALUATION
2022-11-28 03:08:59,202 INFO:   Done with stage: EVALUATION
2022-11-28 03:08:59,202 INFO:   Leaving out SEQ value Fold_9
2022-11-28 03:08:59,215 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:08:59,215 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:08:59,859 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:08:59,859 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:08:59,927 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:08:59,927 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:08:59,927 INFO:     No hyperparam tuning for this model
2022-11-28 03:08:59,927 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:08:59,927 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:08:59,928 INFO:     None feature selector for col prot
2022-11-28 03:08:59,928 INFO:     None feature selector for col prot
2022-11-28 03:08:59,928 INFO:     None feature selector for col prot
2022-11-28 03:08:59,929 INFO:     None feature selector for col chem
2022-11-28 03:08:59,929 INFO:     None feature selector for col chem
2022-11-28 03:08:59,929 INFO:     None feature selector for col chem
2022-11-28 03:08:59,929 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:08:59,929 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:08:59,931 INFO:     Number of params in model 169741
2022-11-28 03:08:59,934 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:08:59,934 INFO:   Starting stage: TRAINING
2022-11-28 03:08:59,987 INFO:     Val loss before train {'Reaction outcome loss': 1.009401874108748, 'Total loss': 1.009401874108748}
2022-11-28 03:08:59,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:08:59,987 INFO:     Epoch: 0
2022-11-28 03:09:00,749 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5069949552416801, 'Total loss': 0.5069949552416801} | train loss {'Reaction outcome loss': 0.6551591269521095, 'Total loss': 0.6551591269521095}
2022-11-28 03:09:00,749 INFO:     Found new best model at epoch 0
2022-11-28 03:09:00,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:00,750 INFO:     Epoch: 1
2022-11-28 03:09:01,513 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48268385299227456, 'Total loss': 0.48268385299227456} | train loss {'Reaction outcome loss': 0.523126500820824, 'Total loss': 0.523126500820824}
2022-11-28 03:09:01,513 INFO:     Found new best model at epoch 1
2022-11-28 03:09:01,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:01,514 INFO:     Epoch: 2
2022-11-28 03:09:02,279 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4354910730299624, 'Total loss': 0.4354910730299624} | train loss {'Reaction outcome loss': 0.479114665977868, 'Total loss': 0.479114665977868}
2022-11-28 03:09:02,280 INFO:     Found new best model at epoch 2
2022-11-28 03:09:02,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:02,281 INFO:     Epoch: 3
2022-11-28 03:09:03,043 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45077511735937814, 'Total loss': 0.45077511735937814} | train loss {'Reaction outcome loss': 0.46232800511454764, 'Total loss': 0.46232800511454764}
2022-11-28 03:09:03,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:03,043 INFO:     Epoch: 4
2022-11-28 03:09:03,808 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4595793363722888, 'Total loss': 0.4595793363722888} | train loss {'Reaction outcome loss': 0.4383172120763223, 'Total loss': 0.4383172120763223}
2022-11-28 03:09:03,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:03,809 INFO:     Epoch: 5
2022-11-28 03:09:04,571 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4288308881223202, 'Total loss': 0.4288308881223202} | train loss {'Reaction outcome loss': 0.42853753602034167, 'Total loss': 0.42853753602034167}
2022-11-28 03:09:04,571 INFO:     Found new best model at epoch 5
2022-11-28 03:09:04,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:04,572 INFO:     Epoch: 6
2022-11-28 03:09:05,335 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4693304964087226, 'Total loss': 0.4693304964087226} | train loss {'Reaction outcome loss': 0.4176800226272359, 'Total loss': 0.4176800226272359}
2022-11-28 03:09:05,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:05,335 INFO:     Epoch: 7
2022-11-28 03:09:06,097 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46796519275416026, 'Total loss': 0.46796519275416026} | train loss {'Reaction outcome loss': 0.41134301419200203, 'Total loss': 0.41134301419200203}
2022-11-28 03:09:06,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:06,097 INFO:     Epoch: 8
2022-11-28 03:09:06,860 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41868464479392226, 'Total loss': 0.41868464479392226} | train loss {'Reaction outcome loss': 0.4055096890158981, 'Total loss': 0.4055096890158981}
2022-11-28 03:09:06,860 INFO:     Found new best model at epoch 8
2022-11-28 03:09:06,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:06,861 INFO:     Epoch: 9
2022-11-28 03:09:07,625 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4119601225988431, 'Total loss': 0.4119601225988431} | train loss {'Reaction outcome loss': 0.3920262491986578, 'Total loss': 0.3920262491986578}
2022-11-28 03:09:07,625 INFO:     Found new best model at epoch 9
2022-11-28 03:09:07,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:07,626 INFO:     Epoch: 10
2022-11-28 03:09:08,392 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4427939680489627, 'Total loss': 0.4427939680489627} | train loss {'Reaction outcome loss': 0.3899610124468079, 'Total loss': 0.3899610124468079}
2022-11-28 03:09:08,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:08,392 INFO:     Epoch: 11
2022-11-28 03:09:09,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42580366879701614, 'Total loss': 0.42580366879701614} | train loss {'Reaction outcome loss': 0.40575855451556836, 'Total loss': 0.40575855451556836}
2022-11-28 03:09:09,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:09,154 INFO:     Epoch: 12
2022-11-28 03:09:09,920 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4828857058151202, 'Total loss': 0.4828857058151202} | train loss {'Reaction outcome loss': 0.39756678043287774, 'Total loss': 0.39756678043287774}
2022-11-28 03:09:09,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:09,921 INFO:     Epoch: 13
2022-11-28 03:09:10,689 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4160104790194468, 'Total loss': 0.4160104790194468} | train loss {'Reaction outcome loss': 0.3798829261590595, 'Total loss': 0.3798829261590595}
2022-11-28 03:09:10,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:10,689 INFO:     Epoch: 14
2022-11-28 03:09:11,453 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.401860430159352, 'Total loss': 0.401860430159352} | train loss {'Reaction outcome loss': 0.36502418434812955, 'Total loss': 0.36502418434812955}
2022-11-28 03:09:11,453 INFO:     Found new best model at epoch 14
2022-11-28 03:09:11,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:11,454 INFO:     Epoch: 15
2022-11-28 03:09:12,215 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39103307998315856, 'Total loss': 0.39103307998315856} | train loss {'Reaction outcome loss': 0.36750214432294553, 'Total loss': 0.36750214432294553}
2022-11-28 03:09:12,215 INFO:     Found new best model at epoch 15
2022-11-28 03:09:12,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:12,216 INFO:     Epoch: 16
2022-11-28 03:09:12,980 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4262110990556804, 'Total loss': 0.4262110990556804} | train loss {'Reaction outcome loss': 0.3749208667500299, 'Total loss': 0.3749208667500299}
2022-11-28 03:09:12,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:12,980 INFO:     Epoch: 17
2022-11-28 03:09:13,743 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42331386052749376, 'Total loss': 0.42331386052749376} | train loss {'Reaction outcome loss': 0.3772110121875157, 'Total loss': 0.3772110121875157}
2022-11-28 03:09:13,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:13,744 INFO:     Epoch: 18
2022-11-28 03:09:14,508 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4072486223144965, 'Total loss': 0.4072486223144965} | train loss {'Reaction outcome loss': 0.36185789723627965, 'Total loss': 0.36185789723627965}
2022-11-28 03:09:14,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:14,508 INFO:     Epoch: 19
2022-11-28 03:09:15,271 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46268199079416017, 'Total loss': 0.46268199079416017} | train loss {'Reaction outcome loss': 0.3565939399394912, 'Total loss': 0.3565939399394912}
2022-11-28 03:09:15,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:15,272 INFO:     Epoch: 20
2022-11-28 03:09:16,034 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41128133406693285, 'Total loss': 0.41128133406693285} | train loss {'Reaction outcome loss': 0.3713586724057854, 'Total loss': 0.3713586724057854}
2022-11-28 03:09:16,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:16,035 INFO:     Epoch: 21
2022-11-28 03:09:16,795 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4173206920650872, 'Total loss': 0.4173206920650872} | train loss {'Reaction outcome loss': 0.37029955861901465, 'Total loss': 0.37029955861901465}
2022-11-28 03:09:16,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:16,796 INFO:     Epoch: 22
2022-11-28 03:09:17,557 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4088806628503583, 'Total loss': 0.4088806628503583} | train loss {'Reaction outcome loss': 0.3596448913095934, 'Total loss': 0.3596448913095934}
2022-11-28 03:09:17,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:17,557 INFO:     Epoch: 23
2022-11-28 03:09:18,321 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40382686646824534, 'Total loss': 0.40382686646824534} | train loss {'Reaction outcome loss': 0.3482844873146731, 'Total loss': 0.3482844873146731}
2022-11-28 03:09:18,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:18,321 INFO:     Epoch: 24
2022-11-28 03:09:19,083 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4274237166074189, 'Total loss': 0.4274237166074189} | train loss {'Reaction outcome loss': 0.3445197828415676, 'Total loss': 0.3445197828415676}
2022-11-28 03:09:19,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:19,083 INFO:     Epoch: 25
2022-11-28 03:09:19,849 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40296861969611864, 'Total loss': 0.40296861969611864} | train loss {'Reaction outcome loss': 0.35036549647810006, 'Total loss': 0.35036549647810006}
2022-11-28 03:09:19,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:19,849 INFO:     Epoch: 26
2022-11-28 03:09:20,611 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.373601907864213, 'Total loss': 0.373601907864213} | train loss {'Reaction outcome loss': 0.34955379421170424, 'Total loss': 0.34955379421170424}
2022-11-28 03:09:20,611 INFO:     Found new best model at epoch 26
2022-11-28 03:09:20,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:20,612 INFO:     Epoch: 27
2022-11-28 03:09:21,380 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40917604839937255, 'Total loss': 0.40917604839937255} | train loss {'Reaction outcome loss': 0.36424986589775393, 'Total loss': 0.36424986589775393}
2022-11-28 03:09:21,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:21,380 INFO:     Epoch: 28
2022-11-28 03:09:22,141 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3884195148606192, 'Total loss': 0.3884195148606192} | train loss {'Reaction outcome loss': 0.34758080901042654, 'Total loss': 0.34758080901042654}
2022-11-28 03:09:22,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:22,142 INFO:     Epoch: 29
2022-11-28 03:09:22,905 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3994617292826826, 'Total loss': 0.3994617292826826} | train loss {'Reaction outcome loss': 0.34827655418644005, 'Total loss': 0.34827655418644005}
2022-11-28 03:09:22,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:22,905 INFO:     Epoch: 30
2022-11-28 03:09:23,669 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39644965156912804, 'Total loss': 0.39644965156912804} | train loss {'Reaction outcome loss': 0.33247580397346244, 'Total loss': 0.33247580397346244}
2022-11-28 03:09:23,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:23,669 INFO:     Epoch: 31
2022-11-28 03:09:24,432 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47916134345260536, 'Total loss': 0.47916134345260536} | train loss {'Reaction outcome loss': 0.3440505822117512, 'Total loss': 0.3440505822117512}
2022-11-28 03:09:24,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:24,432 INFO:     Epoch: 32
2022-11-28 03:09:25,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3922949240288951, 'Total loss': 0.3922949240288951} | train loss {'Reaction outcome loss': 0.349933536097347, 'Total loss': 0.349933536097347}
2022-11-28 03:09:25,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:25,197 INFO:     Epoch: 33
2022-11-28 03:09:25,962 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4515092731876807, 'Total loss': 0.4515092731876807} | train loss {'Reaction outcome loss': 0.33765550194164884, 'Total loss': 0.33765550194164884}
2022-11-28 03:09:25,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:25,962 INFO:     Epoch: 34
2022-11-28 03:09:26,730 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43498138643123885, 'Total loss': 0.43498138643123885} | train loss {'Reaction outcome loss': 0.3371755120604627, 'Total loss': 0.3371755120604627}
2022-11-28 03:09:26,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:26,730 INFO:     Epoch: 35
2022-11-28 03:09:27,496 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42822151631116867, 'Total loss': 0.42822151631116867} | train loss {'Reaction outcome loss': 0.3547452237308101, 'Total loss': 0.3547452237308101}
2022-11-28 03:09:27,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:27,496 INFO:     Epoch: 36
2022-11-28 03:09:28,260 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4384413005953485, 'Total loss': 0.4384413005953485} | train loss {'Reaction outcome loss': 0.3372537148324584, 'Total loss': 0.3372537148324584}
2022-11-28 03:09:28,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:28,261 INFO:     Epoch: 37
2022-11-28 03:09:29,028 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4552388963374225, 'Total loss': 0.4552388963374225} | train loss {'Reaction outcome loss': 0.34071283077779657, 'Total loss': 0.34071283077779657}
2022-11-28 03:09:29,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:29,028 INFO:     Epoch: 38
2022-11-28 03:09:29,793 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.416098028421402, 'Total loss': 0.416098028421402} | train loss {'Reaction outcome loss': 0.3319071918567605, 'Total loss': 0.3319071918567605}
2022-11-28 03:09:29,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:29,793 INFO:     Epoch: 39
2022-11-28 03:09:30,557 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44546275010163133, 'Total loss': 0.44546275010163133} | train loss {'Reaction outcome loss': 0.3350520910250272, 'Total loss': 0.3350520910250272}
2022-11-28 03:09:30,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:30,557 INFO:     Epoch: 40
2022-11-28 03:09:31,321 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39996487681161275, 'Total loss': 0.39996487681161275} | train loss {'Reaction outcome loss': 0.33350781007454944, 'Total loss': 0.33350781007454944}
2022-11-28 03:09:31,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:31,321 INFO:     Epoch: 41
2022-11-28 03:09:32,086 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4085983874445612, 'Total loss': 0.4085983874445612} | train loss {'Reaction outcome loss': 0.3496239332535006, 'Total loss': 0.3496239332535006}
2022-11-28 03:09:32,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:32,086 INFO:     Epoch: 42
2022-11-28 03:09:32,852 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44921690394932573, 'Total loss': 0.44921690394932573} | train loss {'Reaction outcome loss': 0.34847353247978424, 'Total loss': 0.34847353247978424}
2022-11-28 03:09:32,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:32,853 INFO:     Epoch: 43
2022-11-28 03:09:33,615 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4263402426784689, 'Total loss': 0.4263402426784689} | train loss {'Reaction outcome loss': 0.32925157792543847, 'Total loss': 0.32925157792543847}
2022-11-28 03:09:33,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:33,615 INFO:     Epoch: 44
2022-11-28 03:09:34,379 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45962669056924904, 'Total loss': 0.45962669056924904} | train loss {'Reaction outcome loss': 0.33547129602310993, 'Total loss': 0.33547129602310993}
2022-11-28 03:09:34,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:34,380 INFO:     Epoch: 45
2022-11-28 03:09:35,146 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41808589175343513, 'Total loss': 0.41808589175343513} | train loss {'Reaction outcome loss': 0.33478444512190697, 'Total loss': 0.33478444512190697}
2022-11-28 03:09:35,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:35,146 INFO:     Epoch: 46
2022-11-28 03:09:35,911 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4612002559006214, 'Total loss': 0.4612002559006214} | train loss {'Reaction outcome loss': 0.3291225904214237, 'Total loss': 0.3291225904214237}
2022-11-28 03:09:35,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:35,911 INFO:     Epoch: 47
2022-11-28 03:09:36,675 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3999818851324645, 'Total loss': 0.3999818851324645} | train loss {'Reaction outcome loss': 0.32233909448101616, 'Total loss': 0.32233909448101616}
2022-11-28 03:09:36,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:36,675 INFO:     Epoch: 48
2022-11-28 03:09:37,439 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4189653437245976, 'Total loss': 0.4189653437245976} | train loss {'Reaction outcome loss': 0.3251910936011959, 'Total loss': 0.3251910936011959}
2022-11-28 03:09:37,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:37,439 INFO:     Epoch: 49
2022-11-28 03:09:38,206 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41951630772514775, 'Total loss': 0.41951630772514775} | train loss {'Reaction outcome loss': 0.3544206966302897, 'Total loss': 0.3544206966302897}
2022-11-28 03:09:38,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:38,206 INFO:     Epoch: 50
2022-11-28 03:09:38,969 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43509030985561287, 'Total loss': 0.43509030985561287} | train loss {'Reaction outcome loss': 0.34743783003763723, 'Total loss': 0.34743783003763723}
2022-11-28 03:09:38,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:38,969 INFO:     Epoch: 51
2022-11-28 03:09:39,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42043429579247127, 'Total loss': 0.42043429579247127} | train loss {'Reaction outcome loss': 0.32826766768387455, 'Total loss': 0.32826766768387455}
2022-11-28 03:09:39,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:39,733 INFO:     Epoch: 52
2022-11-28 03:09:40,496 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3716728008267554, 'Total loss': 0.3716728008267554} | train loss {'Reaction outcome loss': 0.32048127685601896, 'Total loss': 0.32048127685601896}
2022-11-28 03:09:40,497 INFO:     Found new best model at epoch 52
2022-11-28 03:09:40,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:40,497 INFO:     Epoch: 53
2022-11-28 03:09:41,258 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3914251923561096, 'Total loss': 0.3914251923561096} | train loss {'Reaction outcome loss': 0.3318295390590241, 'Total loss': 0.3318295390590241}
2022-11-28 03:09:41,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:41,258 INFO:     Epoch: 54
2022-11-28 03:09:42,021 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42610163444822485, 'Total loss': 0.42610163444822485} | train loss {'Reaction outcome loss': 0.3234998852255856, 'Total loss': 0.3234998852255856}
2022-11-28 03:09:42,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:42,021 INFO:     Epoch: 55
2022-11-28 03:09:42,785 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4399720178070394, 'Total loss': 0.4399720178070394} | train loss {'Reaction outcome loss': 0.3524110673772179, 'Total loss': 0.3524110673772179}
2022-11-28 03:09:42,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:42,785 INFO:     Epoch: 56
2022-11-28 03:09:43,549 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40878496115857904, 'Total loss': 0.40878496115857904} | train loss {'Reaction outcome loss': 0.3253476069938497, 'Total loss': 0.3253476069938497}
2022-11-28 03:09:43,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:43,549 INFO:     Epoch: 57
2022-11-28 03:09:44,310 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4216356064108285, 'Total loss': 0.4216356064108285} | train loss {'Reaction outcome loss': 0.32290150517756155, 'Total loss': 0.32290150517756155}
2022-11-28 03:09:44,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:44,311 INFO:     Epoch: 58
2022-11-28 03:09:45,074 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4009540578858419, 'Total loss': 0.4009540578858419} | train loss {'Reaction outcome loss': 0.3367445518659533, 'Total loss': 0.3367445518659533}
2022-11-28 03:09:45,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:45,074 INFO:     Epoch: 59
2022-11-28 03:09:45,833 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39044690098274837, 'Total loss': 0.39044690098274837} | train loss {'Reaction outcome loss': 0.32805485739881696, 'Total loss': 0.32805485739881696}
2022-11-28 03:09:45,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:45,834 INFO:     Epoch: 60
2022-11-28 03:09:46,596 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39627303420142695, 'Total loss': 0.39627303420142695} | train loss {'Reaction outcome loss': 0.3294756641133777, 'Total loss': 0.3294756641133777}
2022-11-28 03:09:46,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:46,597 INFO:     Epoch: 61
2022-11-28 03:09:47,361 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39004258337345993, 'Total loss': 0.39004258337345993} | train loss {'Reaction outcome loss': 0.32074430569825385, 'Total loss': 0.32074430569825385}
2022-11-28 03:09:47,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:47,361 INFO:     Epoch: 62
2022-11-28 03:09:48,125 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3986939000473781, 'Total loss': 0.3986939000473781} | train loss {'Reaction outcome loss': 0.3214147074773968, 'Total loss': 0.3214147074773968}
2022-11-28 03:09:48,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:48,125 INFO:     Epoch: 63
2022-11-28 03:09:48,889 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4176070571623065, 'Total loss': 0.4176070571623065} | train loss {'Reaction outcome loss': 0.3361348894081618, 'Total loss': 0.3361348894081618}
2022-11-28 03:09:48,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:48,890 INFO:     Epoch: 64
2022-11-28 03:09:49,653 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4173654466867447, 'Total loss': 0.4173654466867447} | train loss {'Reaction outcome loss': 0.3345204082013415, 'Total loss': 0.3345204082013415}
2022-11-28 03:09:49,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:49,653 INFO:     Epoch: 65
2022-11-28 03:09:50,416 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3947008250450546, 'Total loss': 0.3947008250450546} | train loss {'Reaction outcome loss': 0.32270883596860445, 'Total loss': 0.32270883596860445}
2022-11-28 03:09:50,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:50,417 INFO:     Epoch: 66
2022-11-28 03:09:51,178 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44143723019144754, 'Total loss': 0.44143723019144754} | train loss {'Reaction outcome loss': 0.3214236205337222, 'Total loss': 0.3214236205337222}
2022-11-28 03:09:51,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:51,178 INFO:     Epoch: 67
2022-11-28 03:09:51,944 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.388668013905937, 'Total loss': 0.388668013905937} | train loss {'Reaction outcome loss': 0.3232698299533684, 'Total loss': 0.3232698299533684}
2022-11-28 03:09:51,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:51,944 INFO:     Epoch: 68
2022-11-28 03:09:52,709 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40517478266900236, 'Total loss': 0.40517478266900236} | train loss {'Reaction outcome loss': 0.32606154586742764, 'Total loss': 0.32606154586742764}
2022-11-28 03:09:52,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:52,709 INFO:     Epoch: 69
2022-11-28 03:09:53,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4235085154121572, 'Total loss': 0.4235085154121572} | train loss {'Reaction outcome loss': 0.32871424300437757, 'Total loss': 0.32871424300437757}
2022-11-28 03:09:53,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:53,469 INFO:     Epoch: 70
2022-11-28 03:09:54,230 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4705283929678527, 'Total loss': 0.4705283929678527} | train loss {'Reaction outcome loss': 0.3163880128036385, 'Total loss': 0.3163880128036385}
2022-11-28 03:09:54,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:54,230 INFO:     Epoch: 71
2022-11-28 03:09:54,993 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4316473728553815, 'Total loss': 0.4316473728553815} | train loss {'Reaction outcome loss': 0.3309350553673771, 'Total loss': 0.3309350553673771}
2022-11-28 03:09:54,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:54,994 INFO:     Epoch: 72
2022-11-28 03:09:55,756 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4179565981030464, 'Total loss': 0.4179565981030464} | train loss {'Reaction outcome loss': 0.32042044832518224, 'Total loss': 0.32042044832518224}
2022-11-28 03:09:55,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:55,756 INFO:     Epoch: 73
2022-11-28 03:09:56,520 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41979647266932507, 'Total loss': 0.41979647266932507} | train loss {'Reaction outcome loss': 0.3254046347067665, 'Total loss': 0.3254046347067665}
2022-11-28 03:09:56,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:56,520 INFO:     Epoch: 74
2022-11-28 03:09:57,285 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39524609968066216, 'Total loss': 0.39524609968066216} | train loss {'Reaction outcome loss': 0.3477068791987925, 'Total loss': 0.3477068791987925}
2022-11-28 03:09:57,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:57,286 INFO:     Epoch: 75
2022-11-28 03:09:58,046 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40212370324033225, 'Total loss': 0.40212370324033225} | train loss {'Reaction outcome loss': 0.34371095293235443, 'Total loss': 0.34371095293235443}
2022-11-28 03:09:58,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:58,047 INFO:     Epoch: 76
2022-11-28 03:09:58,810 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41464951498941943, 'Total loss': 0.41464951498941943} | train loss {'Reaction outcome loss': 0.31950945824927646, 'Total loss': 0.31950945824927646}
2022-11-28 03:09:58,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:58,810 INFO:     Epoch: 77
2022-11-28 03:09:59,573 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3920502547513355, 'Total loss': 0.3920502547513355} | train loss {'Reaction outcome loss': 0.31819252719582336, 'Total loss': 0.31819252719582336}
2022-11-28 03:09:59,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:09:59,574 INFO:     Epoch: 78
2022-11-28 03:10:00,339 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42376256497068837, 'Total loss': 0.42376256497068837} | train loss {'Reaction outcome loss': 0.33760305823614967, 'Total loss': 0.33760305823614967}
2022-11-28 03:10:00,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:00,339 INFO:     Epoch: 79
2022-11-28 03:10:01,102 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42601957206021657, 'Total loss': 0.42601957206021657} | train loss {'Reaction outcome loss': 0.3142655443566048, 'Total loss': 0.3142655443566048}
2022-11-28 03:10:01,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:01,102 INFO:     Epoch: 80
2022-11-28 03:10:01,868 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4184256974946369, 'Total loss': 0.4184256974946369} | train loss {'Reaction outcome loss': 0.34537144198350095, 'Total loss': 0.34537144198350095}
2022-11-28 03:10:01,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:01,868 INFO:     Epoch: 81
2022-11-28 03:10:02,629 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3897230647165667, 'Total loss': 0.3897230647165667} | train loss {'Reaction outcome loss': 0.32427649537802705, 'Total loss': 0.32427649537802705}
2022-11-28 03:10:02,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:02,629 INFO:     Epoch: 82
2022-11-28 03:10:03,389 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4185772670263594, 'Total loss': 0.4185772670263594} | train loss {'Reaction outcome loss': 0.3180586520114891, 'Total loss': 0.3180586520114891}
2022-11-28 03:10:03,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:03,390 INFO:     Epoch: 83
2022-11-28 03:10:04,151 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39961852827532723, 'Total loss': 0.39961852827532723} | train loss {'Reaction outcome loss': 0.32540971146300735, 'Total loss': 0.32540971146300735}
2022-11-28 03:10:04,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:04,151 INFO:     Epoch: 84
2022-11-28 03:10:04,914 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45478209311311896, 'Total loss': 0.45478209311311896} | train loss {'Reaction outcome loss': 0.32018205816084555, 'Total loss': 0.32018205816084555}
2022-11-28 03:10:04,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:04,915 INFO:     Epoch: 85
2022-11-28 03:10:05,665 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42767768082293595, 'Total loss': 0.42767768082293595} | train loss {'Reaction outcome loss': 0.33281513285419717, 'Total loss': 0.33281513285419717}
2022-11-28 03:10:05,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:05,666 INFO:     Epoch: 86
2022-11-28 03:10:06,415 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3880278752608733, 'Total loss': 0.3880278752608733} | train loss {'Reaction outcome loss': 0.32991062513428177, 'Total loss': 0.32991062513428177}
2022-11-28 03:10:06,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:06,415 INFO:     Epoch: 87
2022-11-28 03:10:07,162 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44081579453565856, 'Total loss': 0.44081579453565856} | train loss {'Reaction outcome loss': 0.3304680720997243, 'Total loss': 0.3304680720997243}
2022-11-28 03:10:07,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:07,162 INFO:     Epoch: 88
2022-11-28 03:10:07,909 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4256689768623222, 'Total loss': 0.4256689768623222} | train loss {'Reaction outcome loss': 0.324624437657807, 'Total loss': 0.324624437657807}
2022-11-28 03:10:07,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:07,910 INFO:     Epoch: 89
2022-11-28 03:10:08,660 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37921447391537105, 'Total loss': 0.37921447391537105} | train loss {'Reaction outcome loss': 0.3175538816312064, 'Total loss': 0.3175538816312064}
2022-11-28 03:10:08,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:08,661 INFO:     Epoch: 90
2022-11-28 03:10:09,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40959347699853504, 'Total loss': 0.40959347699853504} | train loss {'Reaction outcome loss': 0.32101765332313686, 'Total loss': 0.32101765332313686}
2022-11-28 03:10:09,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:09,408 INFO:     Epoch: 91
2022-11-28 03:10:10,154 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3897516366771676, 'Total loss': 0.3897516366771676} | train loss {'Reaction outcome loss': 0.3267424142795053, 'Total loss': 0.3267424142795053}
2022-11-28 03:10:10,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:10,154 INFO:     Epoch: 92
2022-11-28 03:10:10,900 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44504474611444905, 'Total loss': 0.44504474611444905} | train loss {'Reaction outcome loss': 0.3353592981452401, 'Total loss': 0.3353592981452401}
2022-11-28 03:10:10,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:10,900 INFO:     Epoch: 93
2022-11-28 03:10:11,647 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4008805440230803, 'Total loss': 0.4008805440230803} | train loss {'Reaction outcome loss': 0.351971729360436, 'Total loss': 0.351971729360436}
2022-11-28 03:10:11,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:11,647 INFO:     Epoch: 94
2022-11-28 03:10:12,395 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3928228843618523, 'Total loss': 0.3928228843618523} | train loss {'Reaction outcome loss': 0.3211849920059505, 'Total loss': 0.3211849920059505}
2022-11-28 03:10:12,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:12,395 INFO:     Epoch: 95
2022-11-28 03:10:13,140 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40287319096651947, 'Total loss': 0.40287319096651947} | train loss {'Reaction outcome loss': 0.3418728072377231, 'Total loss': 0.3418728072377231}
2022-11-28 03:10:13,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:13,140 INFO:     Epoch: 96
2022-11-28 03:10:13,886 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41069689562374895, 'Total loss': 0.41069689562374895} | train loss {'Reaction outcome loss': 0.32395671283225774, 'Total loss': 0.32395671283225774}
2022-11-28 03:10:13,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:13,886 INFO:     Epoch: 97
2022-11-28 03:10:14,634 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37975935197689314, 'Total loss': 0.37975935197689314} | train loss {'Reaction outcome loss': 0.31954850762248743, 'Total loss': 0.31954850762248743}
2022-11-28 03:10:14,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:14,634 INFO:     Epoch: 98
2022-11-28 03:10:15,379 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4004276694560593, 'Total loss': 0.4004276694560593} | train loss {'Reaction outcome loss': 0.31272483789003813, 'Total loss': 0.31272483789003813}
2022-11-28 03:10:15,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:15,379 INFO:     Epoch: 99
2022-11-28 03:10:16,127 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.396890817548741, 'Total loss': 0.396890817548741} | train loss {'Reaction outcome loss': 0.3253181691051495, 'Total loss': 0.3253181691051495}
2022-11-28 03:10:16,127 INFO:     Best model found after epoch 53 of 100.
2022-11-28 03:10:16,127 INFO:   Done with stage: TRAINING
2022-11-28 03:10:16,127 INFO:   Starting stage: EVALUATION
2022-11-28 03:10:16,249 INFO:   Done with stage: EVALUATION
2022-11-28 03:10:16,257 INFO:   Leaving out SEQ value Fold_0
2022-11-28 03:10:16,270 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:10:16,271 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:10:16,894 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:10:16,894 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:10:16,961 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:10:16,961 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:10:16,962 INFO:     No hyperparam tuning for this model
2022-11-28 03:10:16,962 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:10:16,962 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:10:16,962 INFO:     None feature selector for col prot
2022-11-28 03:10:16,962 INFO:     None feature selector for col prot
2022-11-28 03:10:16,963 INFO:     None feature selector for col prot
2022-11-28 03:10:16,963 INFO:     None feature selector for col chem
2022-11-28 03:10:16,963 INFO:     None feature selector for col chem
2022-11-28 03:10:16,963 INFO:     None feature selector for col chem
2022-11-28 03:10:16,963 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:10:16,963 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:10:16,965 INFO:     Number of params in model 169741
2022-11-28 03:10:16,968 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:10:16,968 INFO:   Starting stage: TRAINING
2022-11-28 03:10:17,021 INFO:     Val loss before train {'Reaction outcome loss': 0.9528241184624758, 'Total loss': 0.9528241184624758}
2022-11-28 03:10:17,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:17,021 INFO:     Epoch: 0
2022-11-28 03:10:17,762 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5294221490621567, 'Total loss': 0.5294221490621567} | train loss {'Reaction outcome loss': 0.6489536987275494, 'Total loss': 0.6489536987275494}
2022-11-28 03:10:17,763 INFO:     Found new best model at epoch 0
2022-11-28 03:10:17,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:17,764 INFO:     Epoch: 1
2022-11-28 03:10:18,507 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5078130330551754, 'Total loss': 0.5078130330551754} | train loss {'Reaction outcome loss': 0.49648428541056966, 'Total loss': 0.49648428541056966}
2022-11-28 03:10:18,507 INFO:     Found new best model at epoch 1
2022-11-28 03:10:18,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:18,508 INFO:     Epoch: 2
2022-11-28 03:10:19,251 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.507831107486378, 'Total loss': 0.507831107486378} | train loss {'Reaction outcome loss': 0.4691635283280392, 'Total loss': 0.4691635283280392}
2022-11-28 03:10:19,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:19,252 INFO:     Epoch: 3
2022-11-28 03:10:19,993 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.483923158862374, 'Total loss': 0.483923158862374} | train loss {'Reaction outcome loss': 0.4415061165179525, 'Total loss': 0.4415061165179525}
2022-11-28 03:10:19,993 INFO:     Found new best model at epoch 3
2022-11-28 03:10:19,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:19,994 INFO:     Epoch: 4
2022-11-28 03:10:20,735 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4757244951007041, 'Total loss': 0.4757244951007041} | train loss {'Reaction outcome loss': 0.423005215063387, 'Total loss': 0.423005215063387}
2022-11-28 03:10:20,735 INFO:     Found new best model at epoch 4
2022-11-28 03:10:20,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:20,736 INFO:     Epoch: 5
2022-11-28 03:10:21,477 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46204025196758186, 'Total loss': 0.46204025196758186} | train loss {'Reaction outcome loss': 0.4167850532702037, 'Total loss': 0.4167850532702037}
2022-11-28 03:10:21,477 INFO:     Found new best model at epoch 5
2022-11-28 03:10:21,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:21,478 INFO:     Epoch: 6
2022-11-28 03:10:22,221 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4577274356376041, 'Total loss': 0.4577274356376041} | train loss {'Reaction outcome loss': 0.4118058344235226, 'Total loss': 0.4118058344235226}
2022-11-28 03:10:22,221 INFO:     Found new best model at epoch 6
2022-11-28 03:10:22,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:22,222 INFO:     Epoch: 7
2022-11-28 03:10:22,964 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43198657577688043, 'Total loss': 0.43198657577688043} | train loss {'Reaction outcome loss': 0.4067600694846134, 'Total loss': 0.4067600694846134}
2022-11-28 03:10:22,964 INFO:     Found new best model at epoch 7
2022-11-28 03:10:22,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:22,965 INFO:     Epoch: 8
2022-11-28 03:10:23,704 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45346322147683665, 'Total loss': 0.45346322147683665} | train loss {'Reaction outcome loss': 0.3866437700329995, 'Total loss': 0.3866437700329995}
2022-11-28 03:10:23,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:23,705 INFO:     Epoch: 9
2022-11-28 03:10:24,447 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4399906999685548, 'Total loss': 0.4399906999685548} | train loss {'Reaction outcome loss': 0.38870850406130963, 'Total loss': 0.38870850406130963}
2022-11-28 03:10:24,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:24,447 INFO:     Epoch: 10
2022-11-28 03:10:25,191 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4739815623245456, 'Total loss': 0.4739815623245456} | train loss {'Reaction outcome loss': 0.37615129004935827, 'Total loss': 0.37615129004935827}
2022-11-28 03:10:25,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:25,192 INFO:     Epoch: 11
2022-11-28 03:10:25,934 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45116624219173734, 'Total loss': 0.45116624219173734} | train loss {'Reaction outcome loss': 0.3830232800573719, 'Total loss': 0.3830232800573719}
2022-11-28 03:10:25,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:25,935 INFO:     Epoch: 12
2022-11-28 03:10:26,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47110083258964797, 'Total loss': 0.47110083258964797} | train loss {'Reaction outcome loss': 0.36674641747863923, 'Total loss': 0.36674641747863923}
2022-11-28 03:10:26,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:26,674 INFO:     Epoch: 13
2022-11-28 03:10:27,415 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44023769619789993, 'Total loss': 0.44023769619789993} | train loss {'Reaction outcome loss': 0.36727821541075806, 'Total loss': 0.36727821541075806}
2022-11-28 03:10:27,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:27,415 INFO:     Epoch: 14
2022-11-28 03:10:28,158 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4448007152161815, 'Total loss': 0.4448007152161815} | train loss {'Reaction outcome loss': 0.36829107675929457, 'Total loss': 0.36829107675929457}
2022-11-28 03:10:28,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:28,158 INFO:     Epoch: 15
2022-11-28 03:10:28,898 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4476543739438057, 'Total loss': 0.4476543739438057} | train loss {'Reaction outcome loss': 0.3499473857332249, 'Total loss': 0.3499473857332249}
2022-11-28 03:10:28,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:28,898 INFO:     Epoch: 16
2022-11-28 03:10:29,640 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44862067563967273, 'Total loss': 0.44862067563967273} | train loss {'Reaction outcome loss': 0.35683920167538585, 'Total loss': 0.35683920167538585}
2022-11-28 03:10:29,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:29,640 INFO:     Epoch: 17
2022-11-28 03:10:30,381 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4688842496411367, 'Total loss': 0.4688842496411367} | train loss {'Reaction outcome loss': 0.3559496208721278, 'Total loss': 0.3559496208721278}
2022-11-28 03:10:30,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:30,382 INFO:     Epoch: 18
2022-11-28 03:10:31,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41205450028858404, 'Total loss': 0.41205450028858404} | train loss {'Reaction outcome loss': 0.34716683159373246, 'Total loss': 0.34716683159373246}
2022-11-28 03:10:31,122 INFO:     Found new best model at epoch 18
2022-11-28 03:10:31,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:31,123 INFO:     Epoch: 19
2022-11-28 03:10:31,865 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43744005129503255, 'Total loss': 0.43744005129503255} | train loss {'Reaction outcome loss': 0.3419593605764058, 'Total loss': 0.3419593605764058}
2022-11-28 03:10:31,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:31,866 INFO:     Epoch: 20
2022-11-28 03:10:32,606 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4818360051986846, 'Total loss': 0.4818360051986846} | train loss {'Reaction outcome loss': 0.3463674781273822, 'Total loss': 0.3463674781273822}
2022-11-28 03:10:32,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:32,606 INFO:     Epoch: 21
2022-11-28 03:10:33,344 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4512247044847093, 'Total loss': 0.4512247044847093} | train loss {'Reaction outcome loss': 0.34623452050953496, 'Total loss': 0.34623452050953496}
2022-11-28 03:10:33,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:33,344 INFO:     Epoch: 22
2022-11-28 03:10:34,085 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4198081757534634, 'Total loss': 0.4198081757534634} | train loss {'Reaction outcome loss': 0.3314365475761647, 'Total loss': 0.3314365475761647}
2022-11-28 03:10:34,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:34,085 INFO:     Epoch: 23
2022-11-28 03:10:34,825 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4290280313315717, 'Total loss': 0.4290280313315717} | train loss {'Reaction outcome loss': 0.3473710274513887, 'Total loss': 0.3473710274513887}
2022-11-28 03:10:34,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:34,825 INFO:     Epoch: 24
2022-11-28 03:10:35,565 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4247614758258516, 'Total loss': 0.4247614758258516} | train loss {'Reaction outcome loss': 0.3409175645636052, 'Total loss': 0.3409175645636052}
2022-11-28 03:10:35,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:35,565 INFO:     Epoch: 25
2022-11-28 03:10:36,307 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41505339225246146, 'Total loss': 0.41505339225246146} | train loss {'Reaction outcome loss': 0.336921051661579, 'Total loss': 0.336921051661579}
2022-11-28 03:10:36,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:36,307 INFO:     Epoch: 26
2022-11-28 03:10:37,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45263638956980273, 'Total loss': 0.45263638956980273} | train loss {'Reaction outcome loss': 0.33031155698153436, 'Total loss': 0.33031155698153436}
2022-11-28 03:10:37,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:37,053 INFO:     Epoch: 27
2022-11-28 03:10:37,802 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45562373203310097, 'Total loss': 0.45562373203310097} | train loss {'Reaction outcome loss': 0.3316275772999744, 'Total loss': 0.3316275772999744}
2022-11-28 03:10:37,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:37,802 INFO:     Epoch: 28
2022-11-28 03:10:38,549 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4627060629427433, 'Total loss': 0.4627060629427433} | train loss {'Reaction outcome loss': 0.33355914752702326, 'Total loss': 0.33355914752702326}
2022-11-28 03:10:38,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:38,550 INFO:     Epoch: 29
2022-11-28 03:10:39,297 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46792410618879576, 'Total loss': 0.46792410618879576} | train loss {'Reaction outcome loss': 0.3284613686556719, 'Total loss': 0.3284613686556719}
2022-11-28 03:10:39,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:39,298 INFO:     Epoch: 30
2022-11-28 03:10:40,048 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46665458093312656, 'Total loss': 0.46665458093312656} | train loss {'Reaction outcome loss': 0.33224106431007383, 'Total loss': 0.33224106431007383}
2022-11-28 03:10:40,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:40,048 INFO:     Epoch: 31
2022-11-28 03:10:40,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4313432284715501, 'Total loss': 0.4313432284715501} | train loss {'Reaction outcome loss': 0.3371548400545607, 'Total loss': 0.3371548400545607}
2022-11-28 03:10:40,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:40,794 INFO:     Epoch: 32
2022-11-28 03:10:41,539 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45753009617328644, 'Total loss': 0.45753009617328644} | train loss {'Reaction outcome loss': 0.32192409455168003, 'Total loss': 0.32192409455168003}
2022-11-28 03:10:41,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:41,539 INFO:     Epoch: 33
2022-11-28 03:10:42,284 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4135043993592262, 'Total loss': 0.4135043993592262} | train loss {'Reaction outcome loss': 0.32419431912047525, 'Total loss': 0.32419431912047525}
2022-11-28 03:10:42,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:42,284 INFO:     Epoch: 34
2022-11-28 03:10:43,029 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43993777476928453, 'Total loss': 0.43993777476928453} | train loss {'Reaction outcome loss': 0.32205637437956675, 'Total loss': 0.32205637437956675}
2022-11-28 03:10:43,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:43,029 INFO:     Epoch: 35
2022-11-28 03:10:43,774 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4163415423509749, 'Total loss': 0.4163415423509749} | train loss {'Reaction outcome loss': 0.3297807445939706, 'Total loss': 0.3297807445939706}
2022-11-28 03:10:43,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:43,774 INFO:     Epoch: 36
2022-11-28 03:10:44,518 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4315846342254769, 'Total loss': 0.4315846342254769} | train loss {'Reaction outcome loss': 0.3175067313167514, 'Total loss': 0.3175067313167514}
2022-11-28 03:10:44,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:44,518 INFO:     Epoch: 37
2022-11-28 03:10:45,262 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4634120114655657, 'Total loss': 0.4634120114655657} | train loss {'Reaction outcome loss': 0.3213771615101367, 'Total loss': 0.3213771615101367}
2022-11-28 03:10:45,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:45,262 INFO:     Epoch: 38
2022-11-28 03:10:46,012 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4323275038464503, 'Total loss': 0.4323275038464503} | train loss {'Reaction outcome loss': 0.3246375757820752, 'Total loss': 0.3246375757820752}
2022-11-28 03:10:46,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:46,012 INFO:     Epoch: 39
2022-11-28 03:10:46,765 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43454623594880104, 'Total loss': 0.43454623594880104} | train loss {'Reaction outcome loss': 0.325586180875496, 'Total loss': 0.325586180875496}
2022-11-28 03:10:46,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:46,765 INFO:     Epoch: 40
2022-11-28 03:10:47,516 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4122586152092977, 'Total loss': 0.4122586152092977} | train loss {'Reaction outcome loss': 0.3228693391595568, 'Total loss': 0.3228693391595568}
2022-11-28 03:10:47,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:47,516 INFO:     Epoch: 41
2022-11-28 03:10:48,263 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47239265658638696, 'Total loss': 0.47239265658638696} | train loss {'Reaction outcome loss': 0.3236734051029293, 'Total loss': 0.3236734051029293}
2022-11-28 03:10:48,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:48,263 INFO:     Epoch: 42
2022-11-28 03:10:49,008 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4394498670643026, 'Total loss': 0.4394498670643026} | train loss {'Reaction outcome loss': 0.32219807764097136, 'Total loss': 0.32219807764097136}
2022-11-28 03:10:49,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:49,009 INFO:     Epoch: 43
2022-11-28 03:10:49,756 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42456375231797044, 'Total loss': 0.42456375231797044} | train loss {'Reaction outcome loss': 0.3182974677913043, 'Total loss': 0.3182974677913043}
2022-11-28 03:10:49,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:49,757 INFO:     Epoch: 44
2022-11-28 03:10:50,501 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4428862145339901, 'Total loss': 0.4428862145339901} | train loss {'Reaction outcome loss': 0.32996338198379593, 'Total loss': 0.32996338198379593}
2022-11-28 03:10:50,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:50,501 INFO:     Epoch: 45
2022-11-28 03:10:51,248 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4262212769721042, 'Total loss': 0.4262212769721042} | train loss {'Reaction outcome loss': 0.31943810761583097, 'Total loss': 0.31943810761583097}
2022-11-28 03:10:51,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:51,248 INFO:     Epoch: 46
2022-11-28 03:10:51,996 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43306889588182623, 'Total loss': 0.43306889588182623} | train loss {'Reaction outcome loss': 0.3181261725419638, 'Total loss': 0.3181261725419638}
2022-11-28 03:10:51,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:51,996 INFO:     Epoch: 47
2022-11-28 03:10:52,744 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45633519254624844, 'Total loss': 0.45633519254624844} | train loss {'Reaction outcome loss': 0.31509848942562024, 'Total loss': 0.31509848942562024}
2022-11-28 03:10:52,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:52,744 INFO:     Epoch: 48
2022-11-28 03:10:53,492 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42521706460551784, 'Total loss': 0.42521706460551784} | train loss {'Reaction outcome loss': 0.31199862214983726, 'Total loss': 0.31199862214983726}
2022-11-28 03:10:53,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:53,492 INFO:     Epoch: 49
2022-11-28 03:10:54,242 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4897502599792047, 'Total loss': 0.4897502599792047} | train loss {'Reaction outcome loss': 0.31529892892861855, 'Total loss': 0.31529892892861855}
2022-11-28 03:10:54,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:54,242 INFO:     Epoch: 50
2022-11-28 03:10:54,988 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43340355970642785, 'Total loss': 0.43340355970642785} | train loss {'Reaction outcome loss': 0.32497758634236396, 'Total loss': 0.32497758634236396}
2022-11-28 03:10:54,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:54,989 INFO:     Epoch: 51
2022-11-28 03:10:55,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44939334013245325, 'Total loss': 0.44939334013245325} | train loss {'Reaction outcome loss': 0.31003254183701107, 'Total loss': 0.31003254183701107}
2022-11-28 03:10:55,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:55,733 INFO:     Epoch: 52
2022-11-28 03:10:56,480 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42613611692054704, 'Total loss': 0.42613611692054704} | train loss {'Reaction outcome loss': 0.3127781531336356, 'Total loss': 0.3127781531336356}
2022-11-28 03:10:56,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:56,480 INFO:     Epoch: 53
2022-11-28 03:10:57,227 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4351542297412049, 'Total loss': 0.4351542297412049} | train loss {'Reaction outcome loss': 0.3177794317809903, 'Total loss': 0.3177794317809903}
2022-11-28 03:10:57,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:57,227 INFO:     Epoch: 54
2022-11-28 03:10:57,971 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4146315750073303, 'Total loss': 0.4146315750073303} | train loss {'Reaction outcome loss': 0.31292585797455846, 'Total loss': 0.31292585797455846}
2022-11-28 03:10:57,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:57,971 INFO:     Epoch: 55
2022-11-28 03:10:58,713 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4187527099116282, 'Total loss': 0.4187527099116282} | train loss {'Reaction outcome loss': 0.3123942133419368, 'Total loss': 0.3123942133419368}
2022-11-28 03:10:58,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:58,713 INFO:     Epoch: 56
2022-11-28 03:10:59,461 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4068510735576803, 'Total loss': 0.4068510735576803} | train loss {'Reaction outcome loss': 0.32686361941147823, 'Total loss': 0.32686361941147823}
2022-11-28 03:10:59,461 INFO:     Found new best model at epoch 56
2022-11-28 03:10:59,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:10:59,462 INFO:     Epoch: 57
2022-11-28 03:11:00,208 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45392231541601097, 'Total loss': 0.45392231541601097} | train loss {'Reaction outcome loss': 0.31652285900651195, 'Total loss': 0.31652285900651195}
2022-11-28 03:11:00,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:00,208 INFO:     Epoch: 58
2022-11-28 03:11:00,955 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44937704740600154, 'Total loss': 0.44937704740600154} | train loss {'Reaction outcome loss': 0.3192825997970542, 'Total loss': 0.3192825997970542}
2022-11-28 03:11:00,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:00,955 INFO:     Epoch: 59
2022-11-28 03:11:01,701 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4310352591035718, 'Total loss': 0.4310352591035718} | train loss {'Reaction outcome loss': 0.3131981084237293, 'Total loss': 0.3131981084237293}
2022-11-28 03:11:01,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:01,702 INFO:     Epoch: 60
2022-11-28 03:11:02,451 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44275274635715917, 'Total loss': 0.44275274635715917} | train loss {'Reaction outcome loss': 0.316235355211764, 'Total loss': 0.316235355211764}
2022-11-28 03:11:02,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:02,452 INFO:     Epoch: 61
2022-11-28 03:11:03,197 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44001075557687064, 'Total loss': 0.44001075557687064} | train loss {'Reaction outcome loss': 0.3102290920609114, 'Total loss': 0.3102290920609114}
2022-11-28 03:11:03,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:03,198 INFO:     Epoch: 62
2022-11-28 03:11:03,944 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4474162178283388, 'Total loss': 0.4474162178283388} | train loss {'Reaction outcome loss': 0.3085514909150649, 'Total loss': 0.3085514909150649}
2022-11-28 03:11:03,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:03,944 INFO:     Epoch: 63
2022-11-28 03:11:04,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43830328553237696, 'Total loss': 0.43830328553237696} | train loss {'Reaction outcome loss': 0.30820810718803987, 'Total loss': 0.30820810718803987}
2022-11-28 03:11:04,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:04,688 INFO:     Epoch: 64
2022-11-28 03:11:05,437 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4581270712343129, 'Total loss': 0.4581270712343129} | train loss {'Reaction outcome loss': 0.31139047522934116, 'Total loss': 0.31139047522934116}
2022-11-28 03:11:05,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:05,437 INFO:     Epoch: 65
2022-11-28 03:11:06,181 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4037904062054374, 'Total loss': 0.4037904062054374} | train loss {'Reaction outcome loss': 0.3051710900907614, 'Total loss': 0.3051710900907614}
2022-11-28 03:11:06,181 INFO:     Found new best model at epoch 65
2022-11-28 03:11:06,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:06,182 INFO:     Epoch: 66
2022-11-28 03:11:06,929 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4424957724113483, 'Total loss': 0.4424957724113483} | train loss {'Reaction outcome loss': 0.31551016064322723, 'Total loss': 0.31551016064322723}
2022-11-28 03:11:06,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:06,929 INFO:     Epoch: 67
2022-11-28 03:11:07,673 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43921091305938637, 'Total loss': 0.43921091305938637} | train loss {'Reaction outcome loss': 0.30347326416142134, 'Total loss': 0.30347326416142134}
2022-11-28 03:11:07,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:07,674 INFO:     Epoch: 68
2022-11-28 03:11:08,421 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4654662443155592, 'Total loss': 0.4654662443155592} | train loss {'Reaction outcome loss': 0.3108212969132832, 'Total loss': 0.3108212969132832}
2022-11-28 03:11:08,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:08,422 INFO:     Epoch: 69
2022-11-28 03:11:09,168 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46535999785092746, 'Total loss': 0.46535999785092746} | train loss {'Reaction outcome loss': 0.3111858923520361, 'Total loss': 0.3111858923520361}
2022-11-28 03:11:09,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:09,169 INFO:     Epoch: 70
2022-11-28 03:11:09,913 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47156827219507913, 'Total loss': 0.47156827219507913} | train loss {'Reaction outcome loss': 0.3085638306882917, 'Total loss': 0.3085638306882917}
2022-11-28 03:11:09,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:09,913 INFO:     Epoch: 71
2022-11-28 03:11:10,659 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44650245940482075, 'Total loss': 0.44650245940482075} | train loss {'Reaction outcome loss': 0.311678466170418, 'Total loss': 0.311678466170418}
2022-11-28 03:11:10,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:10,659 INFO:     Epoch: 72
2022-11-28 03:11:11,406 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4309955616904931, 'Total loss': 0.4309955616904931} | train loss {'Reaction outcome loss': 0.31308083943262394, 'Total loss': 0.31308083943262394}
2022-11-28 03:11:11,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:11,406 INFO:     Epoch: 73
2022-11-28 03:11:12,152 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4117082670669664, 'Total loss': 0.4117082670669664} | train loss {'Reaction outcome loss': 0.31496561589289684, 'Total loss': 0.31496561589289684}
2022-11-28 03:11:12,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:12,152 INFO:     Epoch: 74
2022-11-28 03:11:12,903 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43824585882777517, 'Total loss': 0.43824585882777517} | train loss {'Reaction outcome loss': 0.30608283576308465, 'Total loss': 0.30608283576308465}
2022-11-28 03:11:12,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:12,903 INFO:     Epoch: 75
2022-11-28 03:11:13,655 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4369763723489913, 'Total loss': 0.4369763723489913} | train loss {'Reaction outcome loss': 0.31186327833910377, 'Total loss': 0.31186327833910377}
2022-11-28 03:11:13,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:13,655 INFO:     Epoch: 76
2022-11-28 03:11:14,404 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4289230694147674, 'Total loss': 0.4289230694147674} | train loss {'Reaction outcome loss': 0.31130818636441715, 'Total loss': 0.31130818636441715}
2022-11-28 03:11:14,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:14,404 INFO:     Epoch: 77
2022-11-28 03:11:15,153 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44613308628851717, 'Total loss': 0.44613308628851717} | train loss {'Reaction outcome loss': 0.31247110014059104, 'Total loss': 0.31247110014059104}
2022-11-28 03:11:15,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:15,153 INFO:     Epoch: 78
2022-11-28 03:11:15,904 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4355274465951053, 'Total loss': 0.4355274465951053} | train loss {'Reaction outcome loss': 0.30928972104982455, 'Total loss': 0.30928972104982455}
2022-11-28 03:11:15,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:15,905 INFO:     Epoch: 79
2022-11-28 03:11:16,652 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45818892222913826, 'Total loss': 0.45818892222913826} | train loss {'Reaction outcome loss': 0.3210463973028319, 'Total loss': 0.3210463973028319}
2022-11-28 03:11:16,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:16,652 INFO:     Epoch: 80
2022-11-28 03:11:17,406 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4528249254958196, 'Total loss': 0.4528249254958196} | train loss {'Reaction outcome loss': 0.3006268863775292, 'Total loss': 0.3006268863775292}
2022-11-28 03:11:17,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:17,406 INFO:     Epoch: 81
2022-11-28 03:11:18,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4510771523822438, 'Total loss': 0.4510771523822438} | train loss {'Reaction outcome loss': 0.314156170265407, 'Total loss': 0.314156170265407}
2022-11-28 03:11:18,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:18,155 INFO:     Epoch: 82
2022-11-28 03:11:18,901 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4459536593746055, 'Total loss': 0.4459536593746055} | train loss {'Reaction outcome loss': 0.3091194753744164, 'Total loss': 0.3091194753744164}
2022-11-28 03:11:18,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:18,901 INFO:     Epoch: 83
2022-11-28 03:11:19,646 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41932460716502234, 'Total loss': 0.41932460716502234} | train loss {'Reaction outcome loss': 0.31317331508106117, 'Total loss': 0.31317331508106117}
2022-11-28 03:11:19,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:19,647 INFO:     Epoch: 84
2022-11-28 03:11:20,391 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4364748454906724, 'Total loss': 0.4364748454906724} | train loss {'Reaction outcome loss': 0.31404888277151144, 'Total loss': 0.31404888277151144}
2022-11-28 03:11:20,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:20,391 INFO:     Epoch: 85
2022-11-28 03:11:21,138 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4486533284864642, 'Total loss': 0.4486533284864642} | train loss {'Reaction outcome loss': 0.3138520183611889, 'Total loss': 0.3138520183611889}
2022-11-28 03:11:21,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:21,138 INFO:     Epoch: 86
2022-11-28 03:11:21,882 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4192277216775851, 'Total loss': 0.4192277216775851} | train loss {'Reaction outcome loss': 0.3108553600858669, 'Total loss': 0.3108553600858669}
2022-11-28 03:11:21,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:21,882 INFO:     Epoch: 87
2022-11-28 03:11:22,629 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4356565018269149, 'Total loss': 0.4356565018269149} | train loss {'Reaction outcome loss': 0.3141707107728841, 'Total loss': 0.3141707107728841}
2022-11-28 03:11:22,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:22,629 INFO:     Epoch: 88
2022-11-28 03:11:23,373 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4395861016078429, 'Total loss': 0.4395861016078429} | train loss {'Reaction outcome loss': 0.3211403447146318, 'Total loss': 0.3211403447146318}
2022-11-28 03:11:23,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:23,374 INFO:     Epoch: 89
2022-11-28 03:11:24,121 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42409137467091734, 'Total loss': 0.42409137467091734} | train loss {'Reaction outcome loss': 0.3093529679945537, 'Total loss': 0.3093529679945537}
2022-11-28 03:11:24,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:24,122 INFO:     Epoch: 90
2022-11-28 03:11:24,868 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41666826741261914, 'Total loss': 0.41666826741261914} | train loss {'Reaction outcome loss': 0.31205459232537114, 'Total loss': 0.31205459232537114}
2022-11-28 03:11:24,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:24,869 INFO:     Epoch: 91
2022-11-28 03:11:25,618 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4115027839487249, 'Total loss': 0.4115027839487249} | train loss {'Reaction outcome loss': 0.3166990673055454, 'Total loss': 0.3166990673055454}
2022-11-28 03:11:25,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:25,618 INFO:     Epoch: 92
2022-11-28 03:11:26,364 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4083817047490315, 'Total loss': 0.4083817047490315} | train loss {'Reaction outcome loss': 0.30019047786386643, 'Total loss': 0.30019047786386643}
2022-11-28 03:11:26,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:26,365 INFO:     Epoch: 93
2022-11-28 03:11:27,112 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4234875089446591, 'Total loss': 0.4234875089446591} | train loss {'Reaction outcome loss': 0.3131604562912669, 'Total loss': 0.3131604562912669}
2022-11-28 03:11:27,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:27,112 INFO:     Epoch: 94
2022-11-28 03:11:27,858 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42554152282801544, 'Total loss': 0.42554152282801544} | train loss {'Reaction outcome loss': 0.3180622452984051, 'Total loss': 0.3180622452984051}
2022-11-28 03:11:27,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:27,858 INFO:     Epoch: 95
2022-11-28 03:11:28,597 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.437360278415409, 'Total loss': 0.437360278415409} | train loss {'Reaction outcome loss': 0.31128306151652824, 'Total loss': 0.31128306151652824}
2022-11-28 03:11:28,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:28,597 INFO:     Epoch: 96
2022-11-28 03:11:29,333 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41422525590116327, 'Total loss': 0.41422525590116327} | train loss {'Reaction outcome loss': 0.3054709265274661, 'Total loss': 0.3054709265274661}
2022-11-28 03:11:29,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:29,334 INFO:     Epoch: 97
2022-11-28 03:11:30,072 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.432506107471206, 'Total loss': 0.432506107471206} | train loss {'Reaction outcome loss': 0.3061638149831976, 'Total loss': 0.3061638149831976}
2022-11-28 03:11:30,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:30,073 INFO:     Epoch: 98
2022-11-28 03:11:30,813 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41903099265288224, 'Total loss': 0.41903099265288224} | train loss {'Reaction outcome loss': 0.29763670490712535, 'Total loss': 0.29763670490712535}
2022-11-28 03:11:30,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:30,813 INFO:     Epoch: 99
2022-11-28 03:11:31,555 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41653963415460155, 'Total loss': 0.41653963415460155} | train loss {'Reaction outcome loss': 0.30058125155616777, 'Total loss': 0.30058125155616777}
2022-11-28 03:11:31,555 INFO:     Best model found after epoch 66 of 100.
2022-11-28 03:11:31,556 INFO:   Done with stage: TRAINING
2022-11-28 03:11:31,556 INFO:   Starting stage: EVALUATION
2022-11-28 03:11:31,682 INFO:   Done with stage: EVALUATION
2022-11-28 03:11:31,682 INFO:   Leaving out SEQ value Fold_1
2022-11-28 03:11:31,695 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 03:11:31,695 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:11:32,322 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:11:32,322 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:11:32,390 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:11:32,390 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:11:32,390 INFO:     No hyperparam tuning for this model
2022-11-28 03:11:32,390 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:11:32,390 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:11:32,391 INFO:     None feature selector for col prot
2022-11-28 03:11:32,391 INFO:     None feature selector for col prot
2022-11-28 03:11:32,391 INFO:     None feature selector for col prot
2022-11-28 03:11:32,392 INFO:     None feature selector for col chem
2022-11-28 03:11:32,392 INFO:     None feature selector for col chem
2022-11-28 03:11:32,392 INFO:     None feature selector for col chem
2022-11-28 03:11:32,392 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:11:32,392 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:11:32,394 INFO:     Number of params in model 169741
2022-11-28 03:11:32,397 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:11:32,397 INFO:   Starting stage: TRAINING
2022-11-28 03:11:32,450 INFO:     Val loss before train {'Reaction outcome loss': 0.9359308342600978, 'Total loss': 0.9359308342600978}
2022-11-28 03:11:32,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:32,450 INFO:     Epoch: 0
2022-11-28 03:11:33,182 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5022748663674953, 'Total loss': 0.5022748663674953} | train loss {'Reaction outcome loss': 0.6310854345926495, 'Total loss': 0.6310854345926495}
2022-11-28 03:11:33,183 INFO:     Found new best model at epoch 0
2022-11-28 03:11:33,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:33,184 INFO:     Epoch: 1
2022-11-28 03:11:33,915 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45635397420373075, 'Total loss': 0.45635397420373075} | train loss {'Reaction outcome loss': 0.5047055324081515, 'Total loss': 0.5047055324081515}
2022-11-28 03:11:33,915 INFO:     Found new best model at epoch 1
2022-11-28 03:11:33,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:33,916 INFO:     Epoch: 2
2022-11-28 03:11:34,651 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44140453012876735, 'Total loss': 0.44140453012876735} | train loss {'Reaction outcome loss': 0.4612380722384961, 'Total loss': 0.4612380722384961}
2022-11-28 03:11:34,652 INFO:     Found new best model at epoch 2
2022-11-28 03:11:34,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:34,652 INFO:     Epoch: 3
2022-11-28 03:11:35,388 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4245426089957703, 'Total loss': 0.4245426089957703} | train loss {'Reaction outcome loss': 0.44469230631213696, 'Total loss': 0.44469230631213696}
2022-11-28 03:11:35,388 INFO:     Found new best model at epoch 3
2022-11-28 03:11:35,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:35,389 INFO:     Epoch: 4
2022-11-28 03:11:36,123 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42504280632318453, 'Total loss': 0.42504280632318453} | train loss {'Reaction outcome loss': 0.42786025720053034, 'Total loss': 0.42786025720053034}
2022-11-28 03:11:36,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:36,123 INFO:     Epoch: 5
2022-11-28 03:11:36,856 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4102532860151557, 'Total loss': 0.4102532860151557} | train loss {'Reaction outcome loss': 0.4191964076312839, 'Total loss': 0.4191964076312839}
2022-11-28 03:11:36,857 INFO:     Found new best model at epoch 5
2022-11-28 03:11:36,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:36,857 INFO:     Epoch: 6
2022-11-28 03:11:37,591 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4076520672371221, 'Total loss': 0.4076520672371221} | train loss {'Reaction outcome loss': 0.40904222789113637, 'Total loss': 0.40904222789113637}
2022-11-28 03:11:37,591 INFO:     Found new best model at epoch 6
2022-11-28 03:11:37,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:37,592 INFO:     Epoch: 7
2022-11-28 03:11:38,328 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4202213720526806, 'Total loss': 0.4202213720526806} | train loss {'Reaction outcome loss': 0.4042890018127004, 'Total loss': 0.4042890018127004}
2022-11-28 03:11:38,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:38,328 INFO:     Epoch: 8
2022-11-28 03:11:39,063 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44488374473050585, 'Total loss': 0.44488374473050585} | train loss {'Reaction outcome loss': 0.3988539748748795, 'Total loss': 0.3988539748748795}
2022-11-28 03:11:39,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:39,063 INFO:     Epoch: 9
2022-11-28 03:11:39,798 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4218746943529262, 'Total loss': 0.4218746943529262} | train loss {'Reaction outcome loss': 0.39260843698484976, 'Total loss': 0.39260843698484976}
2022-11-28 03:11:39,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:39,799 INFO:     Epoch: 10
2022-11-28 03:11:40,533 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47022839618283646, 'Total loss': 0.47022839618283646} | train loss {'Reaction outcome loss': 0.3781793905025134, 'Total loss': 0.3781793905025134}
2022-11-28 03:11:40,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:40,533 INFO:     Epoch: 11
2022-11-28 03:11:41,269 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41521238241084785, 'Total loss': 0.41521238241084785} | train loss {'Reaction outcome loss': 0.3874886316232017, 'Total loss': 0.3874886316232017}
2022-11-28 03:11:41,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:41,269 INFO:     Epoch: 12
2022-11-28 03:11:42,003 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4282371956248616, 'Total loss': 0.4282371956248616} | train loss {'Reaction outcome loss': 0.380949502474949, 'Total loss': 0.380949502474949}
2022-11-28 03:11:42,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:42,003 INFO:     Epoch: 13
2022-11-28 03:11:42,737 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4180821017470471, 'Total loss': 0.4180821017470471} | train loss {'Reaction outcome loss': 0.3763387516202008, 'Total loss': 0.3763387516202008}
2022-11-28 03:11:42,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:42,737 INFO:     Epoch: 14
2022-11-28 03:11:43,472 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4154958828937176, 'Total loss': 0.4154958828937176} | train loss {'Reaction outcome loss': 0.3691963900918843, 'Total loss': 0.3691963900918843}
2022-11-28 03:11:43,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:43,472 INFO:     Epoch: 15
2022-11-28 03:11:44,205 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41292226487813993, 'Total loss': 0.41292226487813993} | train loss {'Reaction outcome loss': 0.36933446205297454, 'Total loss': 0.36933446205297454}
2022-11-28 03:11:44,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:44,205 INFO:     Epoch: 16
2022-11-28 03:11:44,941 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.416372133202331, 'Total loss': 0.416372133202331} | train loss {'Reaction outcome loss': 0.3619679425705652, 'Total loss': 0.3619679425705652}
2022-11-28 03:11:44,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:44,941 INFO:     Epoch: 17
2022-11-28 03:11:45,673 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39113929088032523, 'Total loss': 0.39113929088032523} | train loss {'Reaction outcome loss': 0.35923398283050684, 'Total loss': 0.35923398283050684}
2022-11-28 03:11:45,673 INFO:     Found new best model at epoch 17
2022-11-28 03:11:45,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:45,674 INFO:     Epoch: 18
2022-11-28 03:11:46,410 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4123844674160314, 'Total loss': 0.4123844674160314} | train loss {'Reaction outcome loss': 0.3664130174906039, 'Total loss': 0.3664130174906039}
2022-11-28 03:11:46,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:46,411 INFO:     Epoch: 19
2022-11-28 03:11:47,145 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4026261387869369, 'Total loss': 0.4026261387869369} | train loss {'Reaction outcome loss': 0.35956410526252186, 'Total loss': 0.35956410526252186}
2022-11-28 03:11:47,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:47,145 INFO:     Epoch: 20
2022-11-28 03:11:47,878 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40487622729567596, 'Total loss': 0.40487622729567596} | train loss {'Reaction outcome loss': 0.3555635995552188, 'Total loss': 0.3555635995552188}
2022-11-28 03:11:47,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:47,878 INFO:     Epoch: 21
2022-11-28 03:11:48,613 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4080499545779339, 'Total loss': 0.4080499545779339} | train loss {'Reaction outcome loss': 0.3532392195441195, 'Total loss': 0.3532392195441195}
2022-11-28 03:11:48,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:48,613 INFO:     Epoch: 22
2022-11-28 03:11:49,348 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39576330469098203, 'Total loss': 0.39576330469098203} | train loss {'Reaction outcome loss': 0.34944119249455263, 'Total loss': 0.34944119249455263}
2022-11-28 03:11:49,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:49,349 INFO:     Epoch: 23
2022-11-28 03:11:50,084 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41318955289763076, 'Total loss': 0.41318955289763076} | train loss {'Reaction outcome loss': 0.34794369718578994, 'Total loss': 0.34794369718578994}
2022-11-28 03:11:50,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:50,084 INFO:     Epoch: 24
2022-11-28 03:11:50,817 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4202130341599154, 'Total loss': 0.4202130341599154} | train loss {'Reaction outcome loss': 0.35102682017156334, 'Total loss': 0.35102682017156334}
2022-11-28 03:11:50,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:50,817 INFO:     Epoch: 25
2022-11-28 03:11:51,550 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42480452531992, 'Total loss': 0.42480452531992} | train loss {'Reaction outcome loss': 0.34554505108504513, 'Total loss': 0.34554505108504513}
2022-11-28 03:11:51,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:51,550 INFO:     Epoch: 26
2022-11-28 03:11:52,286 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41956522610298425, 'Total loss': 0.41956522610298425} | train loss {'Reaction outcome loss': 0.34982032509001554, 'Total loss': 0.34982032509001554}
2022-11-28 03:11:52,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:52,286 INFO:     Epoch: 27
2022-11-28 03:11:53,023 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41373695710370706, 'Total loss': 0.41373695710370706} | train loss {'Reaction outcome loss': 0.3436314417812668, 'Total loss': 0.3436314417812668}
2022-11-28 03:11:53,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:53,023 INFO:     Epoch: 28
2022-11-28 03:11:53,757 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3927262473938077, 'Total loss': 0.3927262473938077} | train loss {'Reaction outcome loss': 0.34451184806520824, 'Total loss': 0.34451184806520824}
2022-11-28 03:11:53,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:53,758 INFO:     Epoch: 29
2022-11-28 03:11:54,493 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38850879565227864, 'Total loss': 0.38850879565227864} | train loss {'Reaction outcome loss': 0.3420229537381989, 'Total loss': 0.3420229537381989}
2022-11-28 03:11:54,493 INFO:     Found new best model at epoch 29
2022-11-28 03:11:54,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:54,494 INFO:     Epoch: 30
2022-11-28 03:11:55,229 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44899344929428986, 'Total loss': 0.44899344929428986} | train loss {'Reaction outcome loss': 0.34259262626044085, 'Total loss': 0.34259262626044085}
2022-11-28 03:11:55,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:55,229 INFO:     Epoch: 31
2022-11-28 03:11:55,966 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40140135222396184, 'Total loss': 0.40140135222396184} | train loss {'Reaction outcome loss': 0.3497851489142316, 'Total loss': 0.3497851489142316}
2022-11-28 03:11:55,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:55,966 INFO:     Epoch: 32
2022-11-28 03:11:56,699 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40808126572952713, 'Total loss': 0.40808126572952713} | train loss {'Reaction outcome loss': 0.34515104048931206, 'Total loss': 0.34515104048931206}
2022-11-28 03:11:56,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:56,700 INFO:     Epoch: 33
2022-11-28 03:11:57,440 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39876914197622343, 'Total loss': 0.39876914197622343} | train loss {'Reaction outcome loss': 0.3332541768484917, 'Total loss': 0.3332541768484917}
2022-11-28 03:11:57,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:57,440 INFO:     Epoch: 34
2022-11-28 03:11:58,176 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39530193424502086, 'Total loss': 0.39530193424502086} | train loss {'Reaction outcome loss': 0.3364998267078009, 'Total loss': 0.3364998267078009}
2022-11-28 03:11:58,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:58,176 INFO:     Epoch: 35
2022-11-28 03:11:58,911 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41857138691946516, 'Total loss': 0.41857138691946516} | train loss {'Reaction outcome loss': 0.33459684787104366, 'Total loss': 0.33459684787104366}
2022-11-28 03:11:58,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:58,911 INFO:     Epoch: 36
2022-11-28 03:11:59,646 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4179279835418213, 'Total loss': 0.4179279835418213} | train loss {'Reaction outcome loss': 0.34362376160675384, 'Total loss': 0.34362376160675384}
2022-11-28 03:11:59,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:11:59,646 INFO:     Epoch: 37
2022-11-28 03:12:00,378 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39117483863996905, 'Total loss': 0.39117483863996905} | train loss {'Reaction outcome loss': 0.3335732177632754, 'Total loss': 0.3335732177632754}
2022-11-28 03:12:00,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:00,379 INFO:     Epoch: 38
2022-11-28 03:12:01,111 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39618120844974075, 'Total loss': 0.39618120844974075} | train loss {'Reaction outcome loss': 0.3396374206745722, 'Total loss': 0.3396374206745722}
2022-11-28 03:12:01,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:01,111 INFO:     Epoch: 39
2022-11-28 03:12:01,844 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41896178417427593, 'Total loss': 0.41896178417427593} | train loss {'Reaction outcome loss': 0.3385618463097537, 'Total loss': 0.3385618463097537}
2022-11-28 03:12:01,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:01,844 INFO:     Epoch: 40
2022-11-28 03:12:02,578 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41804920552774916, 'Total loss': 0.41804920552774916} | train loss {'Reaction outcome loss': 0.33281669973349964, 'Total loss': 0.33281669973349964}
2022-11-28 03:12:02,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:02,578 INFO:     Epoch: 41
2022-11-28 03:12:03,310 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4001355604376904, 'Total loss': 0.4001355604376904} | train loss {'Reaction outcome loss': 0.3377383852102717, 'Total loss': 0.3377383852102717}
2022-11-28 03:12:03,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:03,311 INFO:     Epoch: 42
2022-11-28 03:12:04,048 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40129373170608695, 'Total loss': 0.40129373170608695} | train loss {'Reaction outcome loss': 0.3327997526856231, 'Total loss': 0.3327997526856231}
2022-11-28 03:12:04,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:04,049 INFO:     Epoch: 43
2022-11-28 03:12:04,787 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41168585731539614, 'Total loss': 0.41168585731539614} | train loss {'Reaction outcome loss': 0.33151019816515875, 'Total loss': 0.33151019816515875}
2022-11-28 03:12:04,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:04,787 INFO:     Epoch: 44
2022-11-28 03:12:05,535 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.397309031250865, 'Total loss': 0.397309031250865} | train loss {'Reaction outcome loss': 0.32594399758782544, 'Total loss': 0.32594399758782544}
2022-11-28 03:12:05,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:05,535 INFO:     Epoch: 45
2022-11-28 03:12:06,284 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3835506758024526, 'Total loss': 0.3835506758024526} | train loss {'Reaction outcome loss': 0.33112239471224486, 'Total loss': 0.33112239471224486}
2022-11-28 03:12:06,284 INFO:     Found new best model at epoch 45
2022-11-28 03:12:06,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:06,285 INFO:     Epoch: 46
2022-11-28 03:12:07,036 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39803007383679234, 'Total loss': 0.39803007383679234} | train loss {'Reaction outcome loss': 0.34010116090295744, 'Total loss': 0.34010116090295744}
2022-11-28 03:12:07,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:07,036 INFO:     Epoch: 47
2022-11-28 03:12:07,786 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3893994058287421, 'Total loss': 0.3893994058287421} | train loss {'Reaction outcome loss': 0.3325626221409098, 'Total loss': 0.3325626221409098}
2022-11-28 03:12:07,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:07,786 INFO:     Epoch: 48
2022-11-28 03:12:08,537 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.386301995969789, 'Total loss': 0.386301995969789} | train loss {'Reaction outcome loss': 0.3319012339791802, 'Total loss': 0.3319012339791802}
2022-11-28 03:12:08,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:08,537 INFO:     Epoch: 49
2022-11-28 03:12:09,295 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40834651211666506, 'Total loss': 0.40834651211666506} | train loss {'Reaction outcome loss': 0.32584024642090326, 'Total loss': 0.32584024642090326}
2022-11-28 03:12:09,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:09,295 INFO:     Epoch: 50
2022-11-28 03:12:10,047 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40520428432974703, 'Total loss': 0.40520428432974703} | train loss {'Reaction outcome loss': 0.32504091872910007, 'Total loss': 0.32504091872910007}
2022-11-28 03:12:10,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:10,048 INFO:     Epoch: 51
2022-11-28 03:12:10,799 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4157595235941022, 'Total loss': 0.4157595235941022} | train loss {'Reaction outcome loss': 0.323978919474805, 'Total loss': 0.323978919474805}
2022-11-28 03:12:10,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:10,800 INFO:     Epoch: 52
2022-11-28 03:12:11,550 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4155153441567754, 'Total loss': 0.4155153441567754} | train loss {'Reaction outcome loss': 0.32704469105076106, 'Total loss': 0.32704469105076106}
2022-11-28 03:12:11,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:11,550 INFO:     Epoch: 53
2022-11-28 03:12:12,303 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3932937463355619, 'Total loss': 0.3932937463355619} | train loss {'Reaction outcome loss': 0.3240418381927932, 'Total loss': 0.3240418381927932}
2022-11-28 03:12:12,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:12,303 INFO:     Epoch: 54
2022-11-28 03:12:13,055 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3958736051653707, 'Total loss': 0.3958736051653707} | train loss {'Reaction outcome loss': 0.3271238140945063, 'Total loss': 0.3271238140945063}
2022-11-28 03:12:13,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:13,056 INFO:     Epoch: 55
2022-11-28 03:12:13,805 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42112050673296286, 'Total loss': 0.42112050673296286} | train loss {'Reaction outcome loss': 0.32294762931519844, 'Total loss': 0.32294762931519844}
2022-11-28 03:12:13,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:13,805 INFO:     Epoch: 56
2022-11-28 03:12:14,555 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41139274593009506, 'Total loss': 0.41139274593009506} | train loss {'Reaction outcome loss': 0.3225370526741274, 'Total loss': 0.3225370526741274}
2022-11-28 03:12:14,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:14,556 INFO:     Epoch: 57
2022-11-28 03:12:15,305 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41316444825294407, 'Total loss': 0.41316444825294407} | train loss {'Reaction outcome loss': 0.32731520039502715, 'Total loss': 0.32731520039502715}
2022-11-28 03:12:15,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:15,305 INFO:     Epoch: 58
2022-11-28 03:12:16,057 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3873120702283327, 'Total loss': 0.3873120702283327} | train loss {'Reaction outcome loss': 0.3257169563201119, 'Total loss': 0.3257169563201119}
2022-11-28 03:12:16,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:16,057 INFO:     Epoch: 59
2022-11-28 03:12:16,800 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4401155079520026, 'Total loss': 0.4401155079520026} | train loss {'Reaction outcome loss': 0.3196977968709391, 'Total loss': 0.3196977968709391}
2022-11-28 03:12:16,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:16,800 INFO:     Epoch: 60
2022-11-28 03:12:17,540 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3916832648737486, 'Total loss': 0.3916832648737486} | train loss {'Reaction outcome loss': 0.322608336195594, 'Total loss': 0.322608336195594}
2022-11-28 03:12:17,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:17,540 INFO:     Epoch: 61
2022-11-28 03:12:18,278 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38107078262539795, 'Total loss': 0.38107078262539795} | train loss {'Reaction outcome loss': 0.31851635757284086, 'Total loss': 0.31851635757284086}
2022-11-28 03:12:18,278 INFO:     Found new best model at epoch 61
2022-11-28 03:12:18,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:18,279 INFO:     Epoch: 62
2022-11-28 03:12:19,017 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40350266528684037, 'Total loss': 0.40350266528684037} | train loss {'Reaction outcome loss': 0.3167039129852516, 'Total loss': 0.3167039129852516}
2022-11-28 03:12:19,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:19,017 INFO:     Epoch: 63
2022-11-28 03:12:19,752 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3713595175812411, 'Total loss': 0.3713595175812411} | train loss {'Reaction outcome loss': 0.3135111183080761, 'Total loss': 0.3135111183080761}
2022-11-28 03:12:19,752 INFO:     Found new best model at epoch 63
2022-11-28 03:12:19,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:19,753 INFO:     Epoch: 64
2022-11-28 03:12:20,492 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.392714905877446, 'Total loss': 0.392714905877446} | train loss {'Reaction outcome loss': 0.32168581625294, 'Total loss': 0.32168581625294}
2022-11-28 03:12:20,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:20,492 INFO:     Epoch: 65
2022-11-28 03:12:21,230 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.405653516220492, 'Total loss': 0.405653516220492} | train loss {'Reaction outcome loss': 0.31370266569686717, 'Total loss': 0.31370266569686717}
2022-11-28 03:12:21,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:21,230 INFO:     Epoch: 66
2022-11-28 03:12:21,972 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4026190122199613, 'Total loss': 0.4026190122199613} | train loss {'Reaction outcome loss': 0.31458789966695133, 'Total loss': 0.31458789966695133}
2022-11-28 03:12:21,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:21,972 INFO:     Epoch: 67
2022-11-28 03:12:22,707 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40470748585323957, 'Total loss': 0.40470748585323957} | train loss {'Reaction outcome loss': 0.3244265115468717, 'Total loss': 0.3244265115468717}
2022-11-28 03:12:22,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:22,708 INFO:     Epoch: 68
2022-11-28 03:12:23,444 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38787875826968704, 'Total loss': 0.38787875826968704} | train loss {'Reaction outcome loss': 0.31517701391436037, 'Total loss': 0.31517701391436037}
2022-11-28 03:12:23,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:23,445 INFO:     Epoch: 69
2022-11-28 03:12:24,183 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41365510259949884, 'Total loss': 0.41365510259949884} | train loss {'Reaction outcome loss': 0.3138841521605605, 'Total loss': 0.3138841521605605}
2022-11-28 03:12:24,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:24,183 INFO:     Epoch: 70
2022-11-28 03:12:24,920 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44821874554767166, 'Total loss': 0.44821874554767166} | train loss {'Reaction outcome loss': 0.3123679302144246, 'Total loss': 0.3123679302144246}
2022-11-28 03:12:24,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:24,920 INFO:     Epoch: 71
2022-11-28 03:12:25,656 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3721444277569305, 'Total loss': 0.3721444277569305} | train loss {'Reaction outcome loss': 0.329394789656899, 'Total loss': 0.329394789656899}
2022-11-28 03:12:25,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:25,656 INFO:     Epoch: 72
2022-11-28 03:12:26,394 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3914433064502339, 'Total loss': 0.3914433064502339} | train loss {'Reaction outcome loss': 0.31343716358552215, 'Total loss': 0.31343716358552215}
2022-11-28 03:12:26,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:26,395 INFO:     Epoch: 73
2022-11-28 03:12:27,128 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44293275128963383, 'Total loss': 0.44293275128963383} | train loss {'Reaction outcome loss': 0.314995464120732, 'Total loss': 0.314995464120732}
2022-11-28 03:12:27,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:27,128 INFO:     Epoch: 74
2022-11-28 03:12:27,866 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4019190760892491, 'Total loss': 0.4019190760892491} | train loss {'Reaction outcome loss': 0.3193233197280129, 'Total loss': 0.3193233197280129}
2022-11-28 03:12:27,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:27,866 INFO:     Epoch: 75
2022-11-28 03:12:28,606 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3836955383073452, 'Total loss': 0.3836955383073452} | train loss {'Reaction outcome loss': 0.31498822917948005, 'Total loss': 0.31498822917948005}
2022-11-28 03:12:28,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:28,606 INFO:     Epoch: 76
2022-11-28 03:12:29,345 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4082140524026959, 'Total loss': 0.4082140524026959} | train loss {'Reaction outcome loss': 0.3202241250603903, 'Total loss': 0.3202241250603903}
2022-11-28 03:12:29,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:29,345 INFO:     Epoch: 77
2022-11-28 03:12:30,080 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39693233266819355, 'Total loss': 0.39693233266819355} | train loss {'Reaction outcome loss': 0.3174340675325423, 'Total loss': 0.3174340675325423}
2022-11-28 03:12:30,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:30,080 INFO:     Epoch: 78
2022-11-28 03:12:30,813 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37690485008927277, 'Total loss': 0.37690485008927277} | train loss {'Reaction outcome loss': 0.3113281256595596, 'Total loss': 0.3113281256595596}
2022-11-28 03:12:30,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:30,813 INFO:     Epoch: 79
2022-11-28 03:12:31,547 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39061902532743853, 'Total loss': 0.39061902532743853} | train loss {'Reaction outcome loss': 0.3193818953682165, 'Total loss': 0.3193818953682165}
2022-11-28 03:12:31,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:31,547 INFO:     Epoch: 80
2022-11-28 03:12:32,282 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39360587056293045, 'Total loss': 0.39360587056293045} | train loss {'Reaction outcome loss': 0.32228579243919886, 'Total loss': 0.32228579243919886}
2022-11-28 03:12:32,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:32,283 INFO:     Epoch: 81
2022-11-28 03:12:33,016 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43262275083120477, 'Total loss': 0.43262275083120477} | train loss {'Reaction outcome loss': 0.3107903462330826, 'Total loss': 0.3107903462330826}
2022-11-28 03:12:33,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:33,016 INFO:     Epoch: 82
2022-11-28 03:12:33,752 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37937612346438476, 'Total loss': 0.37937612346438476} | train loss {'Reaction outcome loss': 0.3275024604174446, 'Total loss': 0.3275024604174446}
2022-11-28 03:12:33,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:33,752 INFO:     Epoch: 83
2022-11-28 03:12:34,488 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3840696898310684, 'Total loss': 0.3840696898310684} | train loss {'Reaction outcome loss': 0.31360551314886476, 'Total loss': 0.31360551314886476}
2022-11-28 03:12:34,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:34,488 INFO:     Epoch: 84
2022-11-28 03:12:35,221 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42312613961308504, 'Total loss': 0.42312613961308504} | train loss {'Reaction outcome loss': 0.3112502099915606, 'Total loss': 0.3112502099915606}
2022-11-28 03:12:35,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:35,222 INFO:     Epoch: 85
2022-11-28 03:12:35,960 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4616677095723707, 'Total loss': 0.4616677095723707} | train loss {'Reaction outcome loss': 0.31157065277583285, 'Total loss': 0.31157065277583285}
2022-11-28 03:12:35,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:35,961 INFO:     Epoch: 86
2022-11-28 03:12:36,696 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4135155029768168, 'Total loss': 0.4135155029768168} | train loss {'Reaction outcome loss': 0.318259152873862, 'Total loss': 0.318259152873862}
2022-11-28 03:12:36,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:36,697 INFO:     Epoch: 87
2022-11-28 03:12:37,431 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3967672184456226, 'Total loss': 0.3967672184456226} | train loss {'Reaction outcome loss': 0.3237741045104187, 'Total loss': 0.3237741045104187}
2022-11-28 03:12:37,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:37,431 INFO:     Epoch: 88
2022-11-28 03:12:38,167 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4008074293649474, 'Total loss': 0.4008074293649474} | train loss {'Reaction outcome loss': 0.31206462913971456, 'Total loss': 0.31206462913971456}
2022-11-28 03:12:38,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:38,167 INFO:     Epoch: 89
2022-11-28 03:12:38,900 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3798740599737611, 'Total loss': 0.3798740599737611} | train loss {'Reaction outcome loss': 0.32800764535538485, 'Total loss': 0.32800764535538485}
2022-11-28 03:12:38,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:38,900 INFO:     Epoch: 90
2022-11-28 03:12:39,635 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40929975689843645, 'Total loss': 0.40929975689843645} | train loss {'Reaction outcome loss': 0.304400369295942, 'Total loss': 0.304400369295942}
2022-11-28 03:12:39,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:39,635 INFO:     Epoch: 91
2022-11-28 03:12:40,367 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39203746998032857, 'Total loss': 0.39203746998032857} | train loss {'Reaction outcome loss': 0.3139404928403311, 'Total loss': 0.3139404928403311}
2022-11-28 03:12:40,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:40,368 INFO:     Epoch: 92
2022-11-28 03:12:41,100 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3939872799917709, 'Total loss': 0.3939872799917709} | train loss {'Reaction outcome loss': 0.31268194139186967, 'Total loss': 0.31268194139186967}
2022-11-28 03:12:41,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:41,100 INFO:     Epoch: 93
2022-11-28 03:12:41,831 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39938834794732025, 'Total loss': 0.39938834794732025} | train loss {'Reaction outcome loss': 0.3121349566509245, 'Total loss': 0.3121349566509245}
2022-11-28 03:12:41,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:41,832 INFO:     Epoch: 94
2022-11-28 03:12:42,566 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3886760968801587, 'Total loss': 0.3886760968801587} | train loss {'Reaction outcome loss': 0.3157589002588733, 'Total loss': 0.3157589002588733}
2022-11-28 03:12:42,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:42,566 INFO:     Epoch: 95
2022-11-28 03:12:43,298 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3847390000903329, 'Total loss': 0.3847390000903329} | train loss {'Reaction outcome loss': 0.3177993185207492, 'Total loss': 0.3177993185207492}
2022-11-28 03:12:43,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:43,298 INFO:     Epoch: 96
2022-11-28 03:12:44,032 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40515596055707265, 'Total loss': 0.40515596055707265} | train loss {'Reaction outcome loss': 0.3085187950522685, 'Total loss': 0.3085187950522685}
2022-11-28 03:12:44,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:44,032 INFO:     Epoch: 97
2022-11-28 03:12:44,764 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41476373686346896, 'Total loss': 0.41476373686346896} | train loss {'Reaction outcome loss': 0.3131008955695834, 'Total loss': 0.3131008955695834}
2022-11-28 03:12:44,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:44,764 INFO:     Epoch: 98
2022-11-28 03:12:45,500 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3760577642986941, 'Total loss': 0.3760577642986941} | train loss {'Reaction outcome loss': 0.30910505577311165, 'Total loss': 0.30910505577311165}
2022-11-28 03:12:45,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:45,501 INFO:     Epoch: 99
2022-11-28 03:12:46,234 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3893940479949463, 'Total loss': 0.3893940479949463} | train loss {'Reaction outcome loss': 0.3207943988811286, 'Total loss': 0.3207943988811286}
2022-11-28 03:12:46,235 INFO:     Best model found after epoch 64 of 100.
2022-11-28 03:12:46,235 INFO:   Done with stage: TRAINING
2022-11-28 03:12:46,235 INFO:   Starting stage: EVALUATION
2022-11-28 03:12:46,367 INFO:   Done with stage: EVALUATION
2022-11-28 03:12:46,367 INFO:   Leaving out SEQ value Fold_2
2022-11-28 03:12:46,379 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 03:12:46,380 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:12:47,004 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:12:47,005 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:12:47,074 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:12:47,074 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:12:47,074 INFO:     No hyperparam tuning for this model
2022-11-28 03:12:47,074 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:12:47,074 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:12:47,075 INFO:     None feature selector for col prot
2022-11-28 03:12:47,075 INFO:     None feature selector for col prot
2022-11-28 03:12:47,075 INFO:     None feature selector for col prot
2022-11-28 03:12:47,075 INFO:     None feature selector for col chem
2022-11-28 03:12:47,075 INFO:     None feature selector for col chem
2022-11-28 03:12:47,076 INFO:     None feature selector for col chem
2022-11-28 03:12:47,076 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:12:47,076 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:12:47,077 INFO:     Number of params in model 169741
2022-11-28 03:12:47,080 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:12:47,080 INFO:   Starting stage: TRAINING
2022-11-28 03:12:47,133 INFO:     Val loss before train {'Reaction outcome loss': 1.0027985690638077, 'Total loss': 1.0027985690638077}
2022-11-28 03:12:47,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:47,133 INFO:     Epoch: 0
2022-11-28 03:12:47,862 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5318389881488889, 'Total loss': 0.5318389881488889} | train loss {'Reaction outcome loss': 0.6393822605717819, 'Total loss': 0.6393822605717819}
2022-11-28 03:12:47,862 INFO:     Found new best model at epoch 0
2022-11-28 03:12:47,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:47,863 INFO:     Epoch: 1
2022-11-28 03:12:48,591 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4839365108068599, 'Total loss': 0.4839365108068599} | train loss {'Reaction outcome loss': 0.5150750066027229, 'Total loss': 0.5150750066027229}
2022-11-28 03:12:48,591 INFO:     Found new best model at epoch 1
2022-11-28 03:12:48,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:48,592 INFO:     Epoch: 2
2022-11-28 03:12:49,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4980809355891028, 'Total loss': 0.4980809355891028} | train loss {'Reaction outcome loss': 0.46955251932880027, 'Total loss': 0.46955251932880027}
2022-11-28 03:12:49,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:49,321 INFO:     Epoch: 3
2022-11-28 03:12:50,048 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4513928432797277, 'Total loss': 0.4513928432797277} | train loss {'Reaction outcome loss': 0.4496395307067981, 'Total loss': 0.4496395307067981}
2022-11-28 03:12:50,048 INFO:     Found new best model at epoch 3
2022-11-28 03:12:50,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:50,049 INFO:     Epoch: 4
2022-11-28 03:12:50,778 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47357241150944734, 'Total loss': 0.47357241150944734} | train loss {'Reaction outcome loss': 0.4284973466469918, 'Total loss': 0.4284973466469918}
2022-11-28 03:12:50,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:50,778 INFO:     Epoch: 5
2022-11-28 03:12:51,506 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45486752584923146, 'Total loss': 0.45486752584923146} | train loss {'Reaction outcome loss': 0.4138852791101844, 'Total loss': 0.4138852791101844}
2022-11-28 03:12:51,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:51,506 INFO:     Epoch: 6
2022-11-28 03:12:52,237 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42147000064683515, 'Total loss': 0.42147000064683515} | train loss {'Reaction outcome loss': 0.40532092299358347, 'Total loss': 0.40532092299358347}
2022-11-28 03:12:52,237 INFO:     Found new best model at epoch 6
2022-11-28 03:12:52,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:52,238 INFO:     Epoch: 7
2022-11-28 03:12:52,968 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.427838831100353, 'Total loss': 0.427838831100353} | train loss {'Reaction outcome loss': 0.4028284015601555, 'Total loss': 0.4028284015601555}
2022-11-28 03:12:52,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:52,968 INFO:     Epoch: 8
2022-11-28 03:12:53,698 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4484258158955463, 'Total loss': 0.4484258158955463} | train loss {'Reaction outcome loss': 0.39087518037837227, 'Total loss': 0.39087518037837227}
2022-11-28 03:12:53,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:53,699 INFO:     Epoch: 9
2022-11-28 03:12:54,425 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5205051427663758, 'Total loss': 0.5205051427663758} | train loss {'Reaction outcome loss': 0.3856523864185859, 'Total loss': 0.3856523864185859}
2022-11-28 03:12:54,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:54,426 INFO:     Epoch: 10
2022-11-28 03:12:55,152 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4207473445770352, 'Total loss': 0.4207473445770352} | train loss {'Reaction outcome loss': 0.38142716559608286, 'Total loss': 0.38142716559608286}
2022-11-28 03:12:55,152 INFO:     Found new best model at epoch 10
2022-11-28 03:12:55,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:55,153 INFO:     Epoch: 11
2022-11-28 03:12:55,880 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4612119766168816, 'Total loss': 0.4612119766168816} | train loss {'Reaction outcome loss': 0.3730732861431047, 'Total loss': 0.3730732861431047}
2022-11-28 03:12:55,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:55,881 INFO:     Epoch: 12
2022-11-28 03:12:56,612 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41225871097209843, 'Total loss': 0.41225871097209843} | train loss {'Reaction outcome loss': 0.37697947353369904, 'Total loss': 0.37697947353369904}
2022-11-28 03:12:56,612 INFO:     Found new best model at epoch 12
2022-11-28 03:12:56,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:56,613 INFO:     Epoch: 13
2022-11-28 03:12:57,339 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45531243917553926, 'Total loss': 0.45531243917553926} | train loss {'Reaction outcome loss': 0.3681632583278687, 'Total loss': 0.3681632583278687}
2022-11-28 03:12:57,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:57,340 INFO:     Epoch: 14
2022-11-28 03:12:58,066 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43412777504255606, 'Total loss': 0.43412777504255606} | train loss {'Reaction outcome loss': 0.3599830608002443, 'Total loss': 0.3599830608002443}
2022-11-28 03:12:58,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:58,066 INFO:     Epoch: 15
2022-11-28 03:12:58,797 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4252754799848379, 'Total loss': 0.4252754799848379} | train loss {'Reaction outcome loss': 0.3592580577718868, 'Total loss': 0.3592580577718868}
2022-11-28 03:12:58,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:58,797 INFO:     Epoch: 16
2022-11-28 03:12:59,528 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42145609197228456, 'Total loss': 0.42145609197228456} | train loss {'Reaction outcome loss': 0.3580906903792801, 'Total loss': 0.3580906903792801}
2022-11-28 03:12:59,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:12:59,528 INFO:     Epoch: 17
2022-11-28 03:13:00,260 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41378745194091354, 'Total loss': 0.41378745194091354} | train loss {'Reaction outcome loss': 0.35316420941318505, 'Total loss': 0.35316420941318505}
2022-11-28 03:13:00,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:00,260 INFO:     Epoch: 18
2022-11-28 03:13:00,989 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4107908571875373, 'Total loss': 0.4107908571875373} | train loss {'Reaction outcome loss': 0.3499762250624076, 'Total loss': 0.3499762250624076}
2022-11-28 03:13:00,989 INFO:     Found new best model at epoch 18
2022-11-28 03:13:00,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:00,990 INFO:     Epoch: 19
2022-11-28 03:13:01,718 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3880970786477244, 'Total loss': 0.3880970786477244} | train loss {'Reaction outcome loss': 0.34971369953189857, 'Total loss': 0.34971369953189857}
2022-11-28 03:13:01,718 INFO:     Found new best model at epoch 19
2022-11-28 03:13:01,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:01,719 INFO:     Epoch: 20
2022-11-28 03:13:02,446 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4039058626391167, 'Total loss': 0.4039058626391167} | train loss {'Reaction outcome loss': 0.34660757050960644, 'Total loss': 0.34660757050960644}
2022-11-28 03:13:02,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:02,446 INFO:     Epoch: 21
2022-11-28 03:13:03,173 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38980565583983134, 'Total loss': 0.38980565583983134} | train loss {'Reaction outcome loss': 0.3449091876669185, 'Total loss': 0.3449091876669185}
2022-11-28 03:13:03,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:03,174 INFO:     Epoch: 22
2022-11-28 03:13:03,900 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4318924695253372, 'Total loss': 0.4318924695253372} | train loss {'Reaction outcome loss': 0.34156219403684873, 'Total loss': 0.34156219403684873}
2022-11-28 03:13:03,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:03,900 INFO:     Epoch: 23
2022-11-28 03:13:04,630 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44638009958488994, 'Total loss': 0.44638009958488994} | train loss {'Reaction outcome loss': 0.3402645222137494, 'Total loss': 0.3402645222137494}
2022-11-28 03:13:04,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:04,630 INFO:     Epoch: 24
2022-11-28 03:13:05,364 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40661421747401705, 'Total loss': 0.40661421747401705} | train loss {'Reaction outcome loss': 0.33025271979011134, 'Total loss': 0.33025271979011134}
2022-11-28 03:13:05,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:05,365 INFO:     Epoch: 25
2022-11-28 03:13:06,096 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42171640260968096, 'Total loss': 0.42171640260968096} | train loss {'Reaction outcome loss': 0.3411229611240297, 'Total loss': 0.3411229611240297}
2022-11-28 03:13:06,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:06,097 INFO:     Epoch: 26
2022-11-28 03:13:06,830 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4075512976147408, 'Total loss': 0.4075512976147408} | train loss {'Reaction outcome loss': 0.3366442706297945, 'Total loss': 0.3366442706297945}
2022-11-28 03:13:06,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:06,830 INFO:     Epoch: 27
2022-11-28 03:13:07,558 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4240129870730777, 'Total loss': 0.4240129870730777} | train loss {'Reaction outcome loss': 0.33178540628878667, 'Total loss': 0.33178540628878667}
2022-11-28 03:13:07,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:07,558 INFO:     Epoch: 28
2022-11-28 03:13:08,288 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4420325166957323, 'Total loss': 0.4420325166957323} | train loss {'Reaction outcome loss': 0.3298030564937081, 'Total loss': 0.3298030564937081}
2022-11-28 03:13:08,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:08,288 INFO:     Epoch: 29
2022-11-28 03:13:09,019 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4334204844957174, 'Total loss': 0.4334204844957174} | train loss {'Reaction outcome loss': 0.33919249695760234, 'Total loss': 0.33919249695760234}
2022-11-28 03:13:09,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:09,020 INFO:     Epoch: 30
2022-11-28 03:13:09,745 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4038598405760388, 'Total loss': 0.4038598405760388} | train loss {'Reaction outcome loss': 0.328839339193248, 'Total loss': 0.328839339193248}
2022-11-28 03:13:09,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:09,745 INFO:     Epoch: 31
2022-11-28 03:13:10,476 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39006295800209045, 'Total loss': 0.39006295800209045} | train loss {'Reaction outcome loss': 0.32620559188196196, 'Total loss': 0.32620559188196196}
2022-11-28 03:13:10,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:10,476 INFO:     Epoch: 32
2022-11-28 03:13:11,207 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42503190941588825, 'Total loss': 0.42503190941588825} | train loss {'Reaction outcome loss': 0.3352696181508739, 'Total loss': 0.3352696181508739}
2022-11-28 03:13:11,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:11,208 INFO:     Epoch: 33
2022-11-28 03:13:11,935 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38241751457369605, 'Total loss': 0.38241751457369605} | train loss {'Reaction outcome loss': 0.3228494505026213, 'Total loss': 0.3228494505026213}
2022-11-28 03:13:11,935 INFO:     Found new best model at epoch 33
2022-11-28 03:13:11,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:11,936 INFO:     Epoch: 34
2022-11-28 03:13:12,666 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4025756723658983, 'Total loss': 0.4025756723658983} | train loss {'Reaction outcome loss': 0.32646407692888635, 'Total loss': 0.32646407692888635}
2022-11-28 03:13:12,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:12,667 INFO:     Epoch: 35
2022-11-28 03:13:13,401 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43226784502351007, 'Total loss': 0.43226784502351007} | train loss {'Reaction outcome loss': 0.32430038862543586, 'Total loss': 0.32430038862543586}
2022-11-28 03:13:13,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:13,402 INFO:     Epoch: 36
2022-11-28 03:13:14,129 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44679625055124594, 'Total loss': 0.44679625055124594} | train loss {'Reaction outcome loss': 0.32454632716291726, 'Total loss': 0.32454632716291726}
2022-11-28 03:13:14,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:14,129 INFO:     Epoch: 37
2022-11-28 03:13:14,857 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40261229144972427, 'Total loss': 0.40261229144972427} | train loss {'Reaction outcome loss': 0.3100030200379621, 'Total loss': 0.3100030200379621}
2022-11-28 03:13:14,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:14,857 INFO:     Epoch: 38
2022-11-28 03:13:15,587 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4812316811361978, 'Total loss': 0.4812316811361978} | train loss {'Reaction outcome loss': 0.32697754978765675, 'Total loss': 0.32697754978765675}
2022-11-28 03:13:15,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:15,587 INFO:     Epoch: 39
2022-11-28 03:13:16,316 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39985851926165955, 'Total loss': 0.39985851926165955} | train loss {'Reaction outcome loss': 0.3347886994082496, 'Total loss': 0.3347886994082496}
2022-11-28 03:13:16,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:16,317 INFO:     Epoch: 40
2022-11-28 03:13:17,043 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4247179734845494, 'Total loss': 0.4247179734845494} | train loss {'Reaction outcome loss': 0.317646618947816, 'Total loss': 0.317646618947816}
2022-11-28 03:13:17,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:17,043 INFO:     Epoch: 41
2022-11-28 03:13:17,773 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.440109983086586, 'Total loss': 0.440109983086586} | train loss {'Reaction outcome loss': 0.31697925787281106, 'Total loss': 0.31697925787281106}
2022-11-28 03:13:17,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:17,773 INFO:     Epoch: 42
2022-11-28 03:13:18,502 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43025719426399056, 'Total loss': 0.43025719426399056} | train loss {'Reaction outcome loss': 0.3341937802517365, 'Total loss': 0.3341937802517365}
2022-11-28 03:13:18,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:18,502 INFO:     Epoch: 43
2022-11-28 03:13:19,232 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41973906478216483, 'Total loss': 0.41973906478216483} | train loss {'Reaction outcome loss': 0.3174696950080954, 'Total loss': 0.3174696950080954}
2022-11-28 03:13:19,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:19,232 INFO:     Epoch: 44
2022-11-28 03:13:19,961 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38961966543696647, 'Total loss': 0.38961966543696647} | train loss {'Reaction outcome loss': 0.316820386919833, 'Total loss': 0.316820386919833}
2022-11-28 03:13:19,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:19,961 INFO:     Epoch: 45
2022-11-28 03:13:20,692 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38242675433325213, 'Total loss': 0.38242675433325213} | train loss {'Reaction outcome loss': 0.31406443826700925, 'Total loss': 0.31406443826700925}
2022-11-28 03:13:20,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:20,692 INFO:     Epoch: 46
2022-11-28 03:13:21,422 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4130924274755079, 'Total loss': 0.4130924274755079} | train loss {'Reaction outcome loss': 0.31727227237489486, 'Total loss': 0.31727227237489486}
2022-11-28 03:13:21,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:21,422 INFO:     Epoch: 47
2022-11-28 03:13:22,153 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42991587346376375, 'Total loss': 0.42991587346376375} | train loss {'Reaction outcome loss': 0.3164346965696709, 'Total loss': 0.3164346965696709}
2022-11-28 03:13:22,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:22,154 INFO:     Epoch: 48
2022-11-28 03:13:22,883 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39984088443046395, 'Total loss': 0.39984088443046395} | train loss {'Reaction outcome loss': 0.317254769857283, 'Total loss': 0.317254769857283}
2022-11-28 03:13:22,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:22,883 INFO:     Epoch: 49
2022-11-28 03:13:23,611 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41699718077515446, 'Total loss': 0.41699718077515446} | train loss {'Reaction outcome loss': 0.3164852540556786, 'Total loss': 0.3164852540556786}
2022-11-28 03:13:23,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:23,612 INFO:     Epoch: 50
2022-11-28 03:13:24,341 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4189314759054849, 'Total loss': 0.4189314759054849} | train loss {'Reaction outcome loss': 0.32142766252344035, 'Total loss': 0.32142766252344035}
2022-11-28 03:13:24,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:24,341 INFO:     Epoch: 51
2022-11-28 03:13:25,068 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4015154367269472, 'Total loss': 0.4015154367269472} | train loss {'Reaction outcome loss': 0.3125130220511813, 'Total loss': 0.3125130220511813}
2022-11-28 03:13:25,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:25,069 INFO:     Epoch: 52
2022-11-28 03:13:25,801 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39976186461226887, 'Total loss': 0.39976186461226887} | train loss {'Reaction outcome loss': 0.3121864149048005, 'Total loss': 0.3121864149048005}
2022-11-28 03:13:25,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:25,801 INFO:     Epoch: 53
2022-11-28 03:13:26,530 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4190869958594788, 'Total loss': 0.4190869958594788} | train loss {'Reaction outcome loss': 0.31646205736285865, 'Total loss': 0.31646205736285865}
2022-11-28 03:13:26,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:26,530 INFO:     Epoch: 54
2022-11-28 03:13:27,258 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43176911771297455, 'Total loss': 0.43176911771297455} | train loss {'Reaction outcome loss': 0.3195217126528177, 'Total loss': 0.3195217126528177}
2022-11-28 03:13:27,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:27,258 INFO:     Epoch: 55
2022-11-28 03:13:27,992 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3890245645198711, 'Total loss': 0.3890245645198711} | train loss {'Reaction outcome loss': 0.31067957663180407, 'Total loss': 0.31067957663180407}
2022-11-28 03:13:27,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:27,992 INFO:     Epoch: 56
2022-11-28 03:13:28,724 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4265428755519002, 'Total loss': 0.4265428755519002} | train loss {'Reaction outcome loss': 0.3121171889849651, 'Total loss': 0.3121171889849651}
2022-11-28 03:13:28,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:28,724 INFO:     Epoch: 57
2022-11-28 03:13:29,452 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4254269485556802, 'Total loss': 0.4254269485556802} | train loss {'Reaction outcome loss': 0.3180484537786417, 'Total loss': 0.3180484537786417}
2022-11-28 03:13:29,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:29,452 INFO:     Epoch: 58
2022-11-28 03:13:30,183 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40701232607974563, 'Total loss': 0.40701232607974563} | train loss {'Reaction outcome loss': 0.3088704077488601, 'Total loss': 0.3088704077488601}
2022-11-28 03:13:30,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:30,183 INFO:     Epoch: 59
2022-11-28 03:13:30,914 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39704376701698746, 'Total loss': 0.39704376701698746} | train loss {'Reaction outcome loss': 0.305351163808701, 'Total loss': 0.305351163808701}
2022-11-28 03:13:30,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:30,915 INFO:     Epoch: 60
2022-11-28 03:13:31,648 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4297197187362715, 'Total loss': 0.4297197187362715} | train loss {'Reaction outcome loss': 0.31090431013470327, 'Total loss': 0.31090431013470327}
2022-11-28 03:13:31,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:31,648 INFO:     Epoch: 61
2022-11-28 03:13:32,378 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.441389721839927, 'Total loss': 0.441389721839927} | train loss {'Reaction outcome loss': 0.31508969993870933, 'Total loss': 0.31508969993870933}
2022-11-28 03:13:32,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:32,379 INFO:     Epoch: 62
2022-11-28 03:13:33,108 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41688855269620584, 'Total loss': 0.41688855269620584} | train loss {'Reaction outcome loss': 0.30740495847821725, 'Total loss': 0.30740495847821725}
2022-11-28 03:13:33,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:33,108 INFO:     Epoch: 63
2022-11-28 03:13:33,837 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4017708348326905, 'Total loss': 0.4017708348326905} | train loss {'Reaction outcome loss': 0.31889877725898486, 'Total loss': 0.31889877725898486}
2022-11-28 03:13:33,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:33,837 INFO:     Epoch: 64
2022-11-28 03:13:34,567 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38833702788796537, 'Total loss': 0.38833702788796537} | train loss {'Reaction outcome loss': 0.30670097198935203, 'Total loss': 0.30670097198935203}
2022-11-28 03:13:34,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:34,568 INFO:     Epoch: 65
2022-11-28 03:13:35,296 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4190078535398772, 'Total loss': 0.4190078535398772} | train loss {'Reaction outcome loss': 0.3111095436438612, 'Total loss': 0.3111095436438612}
2022-11-28 03:13:35,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:35,296 INFO:     Epoch: 66
2022-11-28 03:13:36,024 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38562159967976944, 'Total loss': 0.38562159967976944} | train loss {'Reaction outcome loss': 0.3172671232878426, 'Total loss': 0.3172671232878426}
2022-11-28 03:13:36,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:36,024 INFO:     Epoch: 67
2022-11-28 03:13:36,752 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39451385272103684, 'Total loss': 0.39451385272103684} | train loss {'Reaction outcome loss': 0.3182250880042221, 'Total loss': 0.3182250880042221}
2022-11-28 03:13:36,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:36,752 INFO:     Epoch: 68
2022-11-28 03:13:37,482 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4086495873539947, 'Total loss': 0.4086495873539947} | train loss {'Reaction outcome loss': 0.31310500149373655, 'Total loss': 0.31310500149373655}
2022-11-28 03:13:37,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:37,483 INFO:     Epoch: 69
2022-11-28 03:13:38,213 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3745325346325719, 'Total loss': 0.3745325346325719} | train loss {'Reaction outcome loss': 0.3073433188437925, 'Total loss': 0.3073433188437925}
2022-11-28 03:13:38,213 INFO:     Found new best model at epoch 69
2022-11-28 03:13:38,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:38,214 INFO:     Epoch: 70
2022-11-28 03:13:38,943 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39766208584918533, 'Total loss': 0.39766208584918533} | train loss {'Reaction outcome loss': 0.3060711209543448, 'Total loss': 0.3060711209543448}
2022-11-28 03:13:38,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:38,943 INFO:     Epoch: 71
2022-11-28 03:13:39,675 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4228784622148026, 'Total loss': 0.4228784622148026} | train loss {'Reaction outcome loss': 0.3046344052003735, 'Total loss': 0.3046344052003735}
2022-11-28 03:13:39,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:39,675 INFO:     Epoch: 72
2022-11-28 03:13:40,405 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42191716647425365, 'Total loss': 0.42191716647425365} | train loss {'Reaction outcome loss': 0.31040335986226675, 'Total loss': 0.31040335986226675}
2022-11-28 03:13:40,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:40,405 INFO:     Epoch: 73
2022-11-28 03:13:41,136 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4025426628284676, 'Total loss': 0.4025426628284676} | train loss {'Reaction outcome loss': 0.3179535878661238, 'Total loss': 0.3179535878661238}
2022-11-28 03:13:41,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:41,136 INFO:     Epoch: 74
2022-11-28 03:13:41,866 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4166037220247956, 'Total loss': 0.4166037220247956} | train loss {'Reaction outcome loss': 0.30517998202838037, 'Total loss': 0.30517998202838037}
2022-11-28 03:13:41,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:41,866 INFO:     Epoch: 75
2022-11-28 03:13:42,596 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40895268546287405, 'Total loss': 0.40895268546287405} | train loss {'Reaction outcome loss': 0.3037109243005146, 'Total loss': 0.3037109243005146}
2022-11-28 03:13:42,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:42,596 INFO:     Epoch: 76
2022-11-28 03:13:43,326 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4202217196309289, 'Total loss': 0.4202217196309289} | train loss {'Reaction outcome loss': 0.30682827776811494, 'Total loss': 0.30682827776811494}
2022-11-28 03:13:43,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:43,326 INFO:     Epoch: 77
2022-11-28 03:13:44,056 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3714948384914287, 'Total loss': 0.3714948384914287} | train loss {'Reaction outcome loss': 0.3095571693078971, 'Total loss': 0.3095571693078971}
2022-11-28 03:13:44,057 INFO:     Found new best model at epoch 77
2022-11-28 03:13:44,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:44,058 INFO:     Epoch: 78
2022-11-28 03:13:44,795 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.448332344030225, 'Total loss': 0.448332344030225} | train loss {'Reaction outcome loss': 0.3151615209601544, 'Total loss': 0.3151615209601544}
2022-11-28 03:13:44,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:44,795 INFO:     Epoch: 79
2022-11-28 03:13:45,532 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4054707494932552, 'Total loss': 0.4054707494932552} | train loss {'Reaction outcome loss': 0.31932420235265185, 'Total loss': 0.31932420235265185}
2022-11-28 03:13:45,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:45,532 INFO:     Epoch: 80
2022-11-28 03:13:46,269 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3851183552381604, 'Total loss': 0.3851183552381604} | train loss {'Reaction outcome loss': 0.3118283488009692, 'Total loss': 0.3118283488009692}
2022-11-28 03:13:46,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:46,269 INFO:     Epoch: 81
2022-11-28 03:13:47,004 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3754321544669395, 'Total loss': 0.3754321544669395} | train loss {'Reaction outcome loss': 0.30926479317953065, 'Total loss': 0.30926479317953065}
2022-11-28 03:13:47,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:47,004 INFO:     Epoch: 82
2022-11-28 03:13:47,740 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39024668186903, 'Total loss': 0.39024668186903} | train loss {'Reaction outcome loss': 0.3170136024125319, 'Total loss': 0.3170136024125319}
2022-11-28 03:13:47,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:47,740 INFO:     Epoch: 83
2022-11-28 03:13:48,474 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40663890540599823, 'Total loss': 0.40663890540599823} | train loss {'Reaction outcome loss': 0.31542813563297806, 'Total loss': 0.31542813563297806}
2022-11-28 03:13:48,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:48,474 INFO:     Epoch: 84
2022-11-28 03:13:49,213 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43556076288223267, 'Total loss': 0.43556076288223267} | train loss {'Reaction outcome loss': 0.31168533548896693, 'Total loss': 0.31168533548896693}
2022-11-28 03:13:49,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:49,213 INFO:     Epoch: 85
2022-11-28 03:13:49,950 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41281269733295883, 'Total loss': 0.41281269733295883} | train loss {'Reaction outcome loss': 0.3107162014171175, 'Total loss': 0.3107162014171175}
2022-11-28 03:13:49,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:49,950 INFO:     Epoch: 86
2022-11-28 03:13:50,685 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3877479520648025, 'Total loss': 0.3877479520648025} | train loss {'Reaction outcome loss': 0.30909264286972365, 'Total loss': 0.30909264286972365}
2022-11-28 03:13:50,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:50,686 INFO:     Epoch: 87
2022-11-28 03:13:51,424 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43063343662855236, 'Total loss': 0.43063343662855236} | train loss {'Reaction outcome loss': 0.3031943812046522, 'Total loss': 0.3031943812046522}
2022-11-28 03:13:51,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:51,424 INFO:     Epoch: 88
2022-11-28 03:13:52,162 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3870293660912403, 'Total loss': 0.3870293660912403} | train loss {'Reaction outcome loss': 0.3083254137524852, 'Total loss': 0.3083254137524852}
2022-11-28 03:13:52,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:52,163 INFO:     Epoch: 89
2022-11-28 03:13:52,901 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4108038950105046, 'Total loss': 0.4108038950105046} | train loss {'Reaction outcome loss': 0.30589789608991685, 'Total loss': 0.30589789608991685}
2022-11-28 03:13:52,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:52,901 INFO:     Epoch: 90
2022-11-28 03:13:53,643 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4063042263652003, 'Total loss': 0.4063042263652003} | train loss {'Reaction outcome loss': 0.30761175145828185, 'Total loss': 0.30761175145828185}
2022-11-28 03:13:53,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:53,643 INFO:     Epoch: 91
2022-11-28 03:13:54,387 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3817951909677927, 'Total loss': 0.3817951909677927} | train loss {'Reaction outcome loss': 0.3108677913438636, 'Total loss': 0.3108677913438636}
2022-11-28 03:13:54,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:54,387 INFO:     Epoch: 92
2022-11-28 03:13:55,126 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40448813088411506, 'Total loss': 0.40448813088411506} | train loss {'Reaction outcome loss': 0.30425238814358235, 'Total loss': 0.30425238814358235}
2022-11-28 03:13:55,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:55,127 INFO:     Epoch: 93
2022-11-28 03:13:55,864 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4341714430687039, 'Total loss': 0.4341714430687039} | train loss {'Reaction outcome loss': 0.3031504181186849, 'Total loss': 0.3031504181186849}
2022-11-28 03:13:55,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:55,864 INFO:     Epoch: 94
2022-11-28 03:13:56,605 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.394089090616204, 'Total loss': 0.394089090616204} | train loss {'Reaction outcome loss': 0.3103438661790188, 'Total loss': 0.3103438661790188}
2022-11-28 03:13:56,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:56,606 INFO:     Epoch: 95
2022-11-28 03:13:57,344 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40949355100476464, 'Total loss': 0.40949355100476464} | train loss {'Reaction outcome loss': 0.31309789790170184, 'Total loss': 0.31309789790170184}
2022-11-28 03:13:57,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:57,344 INFO:     Epoch: 96
2022-11-28 03:13:58,081 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41092993734880934, 'Total loss': 0.41092993734880934} | train loss {'Reaction outcome loss': 0.29829148177072834, 'Total loss': 0.29829148177072834}
2022-11-28 03:13:58,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:58,082 INFO:     Epoch: 97
2022-11-28 03:13:58,817 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3704552605401638, 'Total loss': 0.3704552605401638} | train loss {'Reaction outcome loss': 0.3019287979283941, 'Total loss': 0.3019287979283941}
2022-11-28 03:13:58,817 INFO:     Found new best model at epoch 97
2022-11-28 03:13:58,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:58,818 INFO:     Epoch: 98
2022-11-28 03:13:59,556 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39320731492236605, 'Total loss': 0.39320731492236605} | train loss {'Reaction outcome loss': 0.30321401201280546, 'Total loss': 0.30321401201280546}
2022-11-28 03:13:59,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:13:59,556 INFO:     Epoch: 99
2022-11-28 03:14:00,293 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3907222605721895, 'Total loss': 0.3907222605721895} | train loss {'Reaction outcome loss': 0.3107881152488812, 'Total loss': 0.3107881152488812}
2022-11-28 03:14:00,293 INFO:     Best model found after epoch 98 of 100.
2022-11-28 03:14:00,294 INFO:   Done with stage: TRAINING
2022-11-28 03:14:00,294 INFO:   Starting stage: EVALUATION
2022-11-28 03:14:00,431 INFO:   Done with stage: EVALUATION
2022-11-28 03:14:00,431 INFO:   Leaving out SEQ value Fold_3
2022-11-28 03:14:00,445 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:14:00,445 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:14:01,090 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:14:01,090 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:14:01,158 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:14:01,158 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:14:01,158 INFO:     No hyperparam tuning for this model
2022-11-28 03:14:01,158 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:14:01,158 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:14:01,159 INFO:     None feature selector for col prot
2022-11-28 03:14:01,159 INFO:     None feature selector for col prot
2022-11-28 03:14:01,159 INFO:     None feature selector for col prot
2022-11-28 03:14:01,160 INFO:     None feature selector for col chem
2022-11-28 03:14:01,160 INFO:     None feature selector for col chem
2022-11-28 03:14:01,160 INFO:     None feature selector for col chem
2022-11-28 03:14:01,160 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:14:01,160 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:14:01,162 INFO:     Number of params in model 169741
2022-11-28 03:14:01,165 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:14:01,165 INFO:   Starting stage: TRAINING
2022-11-28 03:14:01,218 INFO:     Val loss before train {'Reaction outcome loss': 1.0518666871569373, 'Total loss': 1.0518666871569373}
2022-11-28 03:14:01,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:01,219 INFO:     Epoch: 0
2022-11-28 03:14:01,966 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5418315360491927, 'Total loss': 0.5418315360491927} | train loss {'Reaction outcome loss': 0.633016825695427, 'Total loss': 0.633016825695427}
2022-11-28 03:14:01,966 INFO:     Found new best model at epoch 0
2022-11-28 03:14:01,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:01,967 INFO:     Epoch: 1
2022-11-28 03:14:02,709 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4812442277642814, 'Total loss': 0.4812442277642814} | train loss {'Reaction outcome loss': 0.49311105000729466, 'Total loss': 0.49311105000729466}
2022-11-28 03:14:02,709 INFO:     Found new best model at epoch 1
2022-11-28 03:14:02,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:02,710 INFO:     Epoch: 2
2022-11-28 03:14:03,452 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45637132091955707, 'Total loss': 0.45637132091955707} | train loss {'Reaction outcome loss': 0.44951678417166885, 'Total loss': 0.44951678417166885}
2022-11-28 03:14:03,452 INFO:     Found new best model at epoch 2
2022-11-28 03:14:03,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:03,453 INFO:     Epoch: 3
2022-11-28 03:14:04,197 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4916830730031837, 'Total loss': 0.4916830730031837} | train loss {'Reaction outcome loss': 0.4323742714463448, 'Total loss': 0.4323742714463448}
2022-11-28 03:14:04,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:04,197 INFO:     Epoch: 4
2022-11-28 03:14:04,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4654831256378781, 'Total loss': 0.4654831256378781} | train loss {'Reaction outcome loss': 0.42154244160165594, 'Total loss': 0.42154244160165594}
2022-11-28 03:14:04,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:04,941 INFO:     Epoch: 5
2022-11-28 03:14:05,684 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46543376080014487, 'Total loss': 0.46543376080014487} | train loss {'Reaction outcome loss': 0.41346642460141864, 'Total loss': 0.41346642460141864}
2022-11-28 03:14:05,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:05,685 INFO:     Epoch: 6
2022-11-28 03:14:06,432 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4766900678249923, 'Total loss': 0.4766900678249923} | train loss {'Reaction outcome loss': 0.4021457945813938, 'Total loss': 0.4021457945813938}
2022-11-28 03:14:06,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:06,433 INFO:     Epoch: 7
2022-11-28 03:14:07,177 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42957357689738274, 'Total loss': 0.42957357689738274} | train loss {'Reaction outcome loss': 0.40135513954624835, 'Total loss': 0.40135513954624835}
2022-11-28 03:14:07,177 INFO:     Found new best model at epoch 7
2022-11-28 03:14:07,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:07,178 INFO:     Epoch: 8
2022-11-28 03:14:07,921 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44523774832487106, 'Total loss': 0.44523774832487106} | train loss {'Reaction outcome loss': 0.39558568146764017, 'Total loss': 0.39558568146764017}
2022-11-28 03:14:07,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:07,921 INFO:     Epoch: 9
2022-11-28 03:14:08,668 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43583993275057187, 'Total loss': 0.43583993275057187} | train loss {'Reaction outcome loss': 0.3857891208055068, 'Total loss': 0.3857891208055068}
2022-11-28 03:14:08,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:08,669 INFO:     Epoch: 10
2022-11-28 03:14:09,416 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4070067165250128, 'Total loss': 0.4070067165250128} | train loss {'Reaction outcome loss': 0.3770262041262218, 'Total loss': 0.3770262041262218}
2022-11-28 03:14:09,416 INFO:     Found new best model at epoch 10
2022-11-28 03:14:09,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:09,417 INFO:     Epoch: 11
2022-11-28 03:14:10,163 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4440545497292822, 'Total loss': 0.4440545497292822} | train loss {'Reaction outcome loss': 0.37246224335869965, 'Total loss': 0.37246224335869965}
2022-11-28 03:14:10,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:10,163 INFO:     Epoch: 12
2022-11-28 03:14:10,913 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4224425933577798, 'Total loss': 0.4224425933577798} | train loss {'Reaction outcome loss': 0.3753876349755696, 'Total loss': 0.3753876349755696}
2022-11-28 03:14:10,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:10,913 INFO:     Epoch: 13
2022-11-28 03:14:11,656 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4081999486820264, 'Total loss': 0.4081999486820264} | train loss {'Reaction outcome loss': 0.36395011778388703, 'Total loss': 0.36395011778388703}
2022-11-28 03:14:11,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:11,656 INFO:     Epoch: 14
2022-11-28 03:14:12,402 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41218679838559846, 'Total loss': 0.41218679838559846} | train loss {'Reaction outcome loss': 0.36084393956223315, 'Total loss': 0.36084393956223315}
2022-11-28 03:14:12,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:12,402 INFO:     Epoch: 15
2022-11-28 03:14:13,146 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3997333591634577, 'Total loss': 0.3997333591634577} | train loss {'Reaction outcome loss': 0.35755044643824196, 'Total loss': 0.35755044643824196}
2022-11-28 03:14:13,146 INFO:     Found new best model at epoch 15
2022-11-28 03:14:13,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:13,147 INFO:     Epoch: 16
2022-11-28 03:14:13,895 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41736286506056786, 'Total loss': 0.41736286506056786} | train loss {'Reaction outcome loss': 0.3606301591408496, 'Total loss': 0.3606301591408496}
2022-11-28 03:14:13,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:13,895 INFO:     Epoch: 17
2022-11-28 03:14:14,643 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41808259046890517, 'Total loss': 0.41808259046890517} | train loss {'Reaction outcome loss': 0.35363037592294266, 'Total loss': 0.35363037592294266}
2022-11-28 03:14:14,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:14,644 INFO:     Epoch: 18
2022-11-28 03:14:15,391 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4222265285524455, 'Total loss': 0.4222265285524455} | train loss {'Reaction outcome loss': 0.3521859908894617, 'Total loss': 0.3521859908894617}
2022-11-28 03:14:15,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:15,392 INFO:     Epoch: 19
2022-11-28 03:14:16,136 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39917940070683305, 'Total loss': 0.39917940070683305} | train loss {'Reaction outcome loss': 0.3467229982115784, 'Total loss': 0.3467229982115784}
2022-11-28 03:14:16,136 INFO:     Found new best model at epoch 19
2022-11-28 03:14:16,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:16,137 INFO:     Epoch: 20
2022-11-28 03:14:16,883 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4106175926598636, 'Total loss': 0.4106175926598636} | train loss {'Reaction outcome loss': 0.3494050568463851, 'Total loss': 0.3494050568463851}
2022-11-28 03:14:16,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:16,883 INFO:     Epoch: 21
2022-11-28 03:14:17,629 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3907692793079398, 'Total loss': 0.3907692793079398} | train loss {'Reaction outcome loss': 0.34331690419693384, 'Total loss': 0.34331690419693384}
2022-11-28 03:14:17,629 INFO:     Found new best model at epoch 21
2022-11-28 03:14:17,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:17,630 INFO:     Epoch: 22
2022-11-28 03:14:18,378 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4392256604676897, 'Total loss': 0.4392256604676897} | train loss {'Reaction outcome loss': 0.3406298122235707, 'Total loss': 0.3406298122235707}
2022-11-28 03:14:18,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:18,379 INFO:     Epoch: 23
2022-11-28 03:14:19,129 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41867233135483484, 'Total loss': 0.41867233135483484} | train loss {'Reaction outcome loss': 0.33845809533887977, 'Total loss': 0.33845809533887977}
2022-11-28 03:14:19,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:19,129 INFO:     Epoch: 24
2022-11-28 03:14:19,881 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43386450240557844, 'Total loss': 0.43386450240557844} | train loss {'Reaction outcome loss': 0.3409074103649782, 'Total loss': 0.3409074103649782}
2022-11-28 03:14:19,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:19,881 INFO:     Epoch: 25
2022-11-28 03:14:20,632 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38988774473016913, 'Total loss': 0.38988774473016913} | train loss {'Reaction outcome loss': 0.3359383399997439, 'Total loss': 0.3359383399997439}
2022-11-28 03:14:20,632 INFO:     Found new best model at epoch 25
2022-11-28 03:14:20,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:20,633 INFO:     Epoch: 26
2022-11-28 03:14:21,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39817221428860317, 'Total loss': 0.39817221428860317} | train loss {'Reaction outcome loss': 0.34541827397687097, 'Total loss': 0.34541827397687097}
2022-11-28 03:14:21,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:21,382 INFO:     Epoch: 27
2022-11-28 03:14:22,132 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4148555188016458, 'Total loss': 0.4148555188016458} | train loss {'Reaction outcome loss': 0.33219783075001774, 'Total loss': 0.33219783075001774}
2022-11-28 03:14:22,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:22,132 INFO:     Epoch: 28
2022-11-28 03:14:22,884 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4188271574676037, 'Total loss': 0.4188271574676037} | train loss {'Reaction outcome loss': 0.3238083625326351, 'Total loss': 0.3238083625326351}
2022-11-28 03:14:22,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:22,884 INFO:     Epoch: 29
2022-11-28 03:14:23,633 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40352005274458363, 'Total loss': 0.40352005274458363} | train loss {'Reaction outcome loss': 0.3342952743172646, 'Total loss': 0.3342952743172646}
2022-11-28 03:14:23,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:23,633 INFO:     Epoch: 30
2022-11-28 03:14:24,382 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4029672115363858, 'Total loss': 0.4029672115363858} | train loss {'Reaction outcome loss': 0.32982116946760487, 'Total loss': 0.32982116946760487}
2022-11-28 03:14:24,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:24,382 INFO:     Epoch: 31
2022-11-28 03:14:25,131 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4353688970864327, 'Total loss': 0.4353688970864327} | train loss {'Reaction outcome loss': 0.32095957218992466, 'Total loss': 0.32095957218992466}
2022-11-28 03:14:25,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:25,131 INFO:     Epoch: 32
2022-11-28 03:14:25,881 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40616372430866415, 'Total loss': 0.40616372430866415} | train loss {'Reaction outcome loss': 0.3217807910272053, 'Total loss': 0.3217807910272053}
2022-11-28 03:14:25,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:25,882 INFO:     Epoch: 33
2022-11-28 03:14:26,630 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39518950845707546, 'Total loss': 0.39518950845707546} | train loss {'Reaction outcome loss': 0.331066523020973, 'Total loss': 0.331066523020973}
2022-11-28 03:14:26,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:26,630 INFO:     Epoch: 34
2022-11-28 03:14:27,378 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38997137072411453, 'Total loss': 0.38997137072411453} | train loss {'Reaction outcome loss': 0.3191652434821032, 'Total loss': 0.3191652434821032}
2022-11-28 03:14:27,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:27,379 INFO:     Epoch: 35
2022-11-28 03:14:28,128 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.386348896024918, 'Total loss': 0.386348896024918} | train loss {'Reaction outcome loss': 0.32638332959340544, 'Total loss': 0.32638332959340544}
2022-11-28 03:14:28,129 INFO:     Found new best model at epoch 35
2022-11-28 03:14:28,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:28,129 INFO:     Epoch: 36
2022-11-28 03:14:28,887 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42711077122525737, 'Total loss': 0.42711077122525737} | train loss {'Reaction outcome loss': 0.33226971127549, 'Total loss': 0.33226971127549}
2022-11-28 03:14:28,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:28,887 INFO:     Epoch: 37
2022-11-28 03:14:29,635 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38390393216501584, 'Total loss': 0.38390393216501584} | train loss {'Reaction outcome loss': 0.3209214040515374, 'Total loss': 0.3209214040515374}
2022-11-28 03:14:29,635 INFO:     Found new best model at epoch 37
2022-11-28 03:14:29,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:29,636 INFO:     Epoch: 38
2022-11-28 03:14:30,385 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40226477486166085, 'Total loss': 0.40226477486166085} | train loss {'Reaction outcome loss': 0.31881336096902285, 'Total loss': 0.31881336096902285}
2022-11-28 03:14:30,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:30,385 INFO:     Epoch: 39
2022-11-28 03:14:31,137 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40738005292686547, 'Total loss': 0.40738005292686547} | train loss {'Reaction outcome loss': 0.3236210008360902, 'Total loss': 0.3236210008360902}
2022-11-28 03:14:31,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:31,137 INFO:     Epoch: 40
2022-11-28 03:14:31,889 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40950259972702374, 'Total loss': 0.40950259972702374} | train loss {'Reaction outcome loss': 0.3177125821308214, 'Total loss': 0.3177125821308214}
2022-11-28 03:14:31,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:31,890 INFO:     Epoch: 41
2022-11-28 03:14:32,641 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.391372082924301, 'Total loss': 0.391372082924301} | train loss {'Reaction outcome loss': 0.31781396862803674, 'Total loss': 0.31781396862803674}
2022-11-28 03:14:32,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:32,642 INFO:     Epoch: 42
2022-11-28 03:14:33,388 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42765415663068945, 'Total loss': 0.42765415663068945} | train loss {'Reaction outcome loss': 0.3200512592281614, 'Total loss': 0.3200512592281614}
2022-11-28 03:14:33,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:33,389 INFO:     Epoch: 43
2022-11-28 03:14:34,139 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3998436087911779, 'Total loss': 0.3998436087911779} | train loss {'Reaction outcome loss': 0.32219181519990064, 'Total loss': 0.32219181519990064}
2022-11-28 03:14:34,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:34,139 INFO:     Epoch: 44
2022-11-28 03:14:34,892 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4108146039599722, 'Total loss': 0.4108146039599722} | train loss {'Reaction outcome loss': 0.31719767600297927, 'Total loss': 0.31719767600297927}
2022-11-28 03:14:34,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:34,892 INFO:     Epoch: 45
2022-11-28 03:14:35,640 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4114857735958966, 'Total loss': 0.4114857735958966} | train loss {'Reaction outcome loss': 0.31846313292578776, 'Total loss': 0.31846313292578776}
2022-11-28 03:14:35,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:35,641 INFO:     Epoch: 46
2022-11-28 03:14:36,388 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40190438079563057, 'Total loss': 0.40190438079563057} | train loss {'Reaction outcome loss': 0.31787204175275197, 'Total loss': 0.31787204175275197}
2022-11-28 03:14:36,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:36,388 INFO:     Epoch: 47
2022-11-28 03:14:37,139 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4113163064149293, 'Total loss': 0.4113163064149293} | train loss {'Reaction outcome loss': 0.31346729297418985, 'Total loss': 0.31346729297418985}
2022-11-28 03:14:37,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:37,140 INFO:     Epoch: 48
2022-11-28 03:14:37,893 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3819848153401505, 'Total loss': 0.3819848153401505} | train loss {'Reaction outcome loss': 0.31641946123266707, 'Total loss': 0.31641946123266707}
2022-11-28 03:14:37,893 INFO:     Found new best model at epoch 48
2022-11-28 03:14:37,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:37,894 INFO:     Epoch: 49
2022-11-28 03:14:38,645 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4070035568015142, 'Total loss': 0.4070035568015142} | train loss {'Reaction outcome loss': 0.3098629577389481, 'Total loss': 0.3098629577389481}
2022-11-28 03:14:38,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:38,645 INFO:     Epoch: 50
2022-11-28 03:14:39,396 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38256750628352165, 'Total loss': 0.38256750628352165} | train loss {'Reaction outcome loss': 0.3150185616648927, 'Total loss': 0.3150185616648927}
2022-11-28 03:14:39,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:39,396 INFO:     Epoch: 51
2022-11-28 03:14:40,147 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3915282233872197, 'Total loss': 0.3915282233872197} | train loss {'Reaction outcome loss': 0.31607022689921516, 'Total loss': 0.31607022689921516}
2022-11-28 03:14:40,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:40,148 INFO:     Epoch: 52
2022-11-28 03:14:40,901 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3950463079593398, 'Total loss': 0.3950463079593398} | train loss {'Reaction outcome loss': 0.3140992736329838, 'Total loss': 0.3140992736329838}
2022-11-28 03:14:40,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:40,901 INFO:     Epoch: 53
2022-11-28 03:14:41,652 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3814040905034, 'Total loss': 0.3814040905034} | train loss {'Reaction outcome loss': 0.30849515192058624, 'Total loss': 0.30849515192058624}
2022-11-28 03:14:41,652 INFO:     Found new best model at epoch 53
2022-11-28 03:14:41,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:41,653 INFO:     Epoch: 54
2022-11-28 03:14:42,399 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3928380578079007, 'Total loss': 0.3928380578079007} | train loss {'Reaction outcome loss': 0.30744125967731284, 'Total loss': 0.30744125967731284}
2022-11-28 03:14:42,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:42,399 INFO:     Epoch: 55
2022-11-28 03:14:43,147 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3725905257531188, 'Total loss': 0.3725905257531188} | train loss {'Reaction outcome loss': 0.31015485221025896, 'Total loss': 0.31015485221025896}
2022-11-28 03:14:43,147 INFO:     Found new best model at epoch 55
2022-11-28 03:14:43,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:43,148 INFO:     Epoch: 56
2022-11-28 03:14:43,898 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39172933386130765, 'Total loss': 0.39172933386130765} | train loss {'Reaction outcome loss': 0.307135434387898, 'Total loss': 0.307135434387898}
2022-11-28 03:14:43,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:43,898 INFO:     Epoch: 57
2022-11-28 03:14:44,648 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41913658143444493, 'Total loss': 0.41913658143444493} | train loss {'Reaction outcome loss': 0.30462008523089545, 'Total loss': 0.30462008523089545}
2022-11-28 03:14:44,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:44,649 INFO:     Epoch: 58
2022-11-28 03:14:45,403 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38235750184817746, 'Total loss': 0.38235750184817746} | train loss {'Reaction outcome loss': 0.31324134079777466, 'Total loss': 0.31324134079777466}
2022-11-28 03:14:45,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:45,403 INFO:     Epoch: 59
2022-11-28 03:14:46,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4071448621424762, 'Total loss': 0.4071448621424762} | train loss {'Reaction outcome loss': 0.31109825340764863, 'Total loss': 0.31109825340764863}
2022-11-28 03:14:46,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:46,155 INFO:     Epoch: 60
2022-11-28 03:14:46,904 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38785234262997453, 'Total loss': 0.38785234262997453} | train loss {'Reaction outcome loss': 0.3059360352097725, 'Total loss': 0.3059360352097725}
2022-11-28 03:14:46,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:46,904 INFO:     Epoch: 61
2022-11-28 03:14:47,654 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37994991547682067, 'Total loss': 0.37994991547682067} | train loss {'Reaction outcome loss': 0.3090631096338739, 'Total loss': 0.3090631096338739}
2022-11-28 03:14:47,654 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:47,654 INFO:     Epoch: 62
2022-11-28 03:14:48,405 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3913344642655416, 'Total loss': 0.3913344642655416} | train loss {'Reaction outcome loss': 0.31275868245533534, 'Total loss': 0.31275868245533534}
2022-11-28 03:14:48,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:48,405 INFO:     Epoch: 63
2022-11-28 03:14:49,152 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4099990241229534, 'Total loss': 0.4099990241229534} | train loss {'Reaction outcome loss': 0.30791642565508276, 'Total loss': 0.30791642565508276}
2022-11-28 03:14:49,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:49,152 INFO:     Epoch: 64
2022-11-28 03:14:49,900 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3829361071640795, 'Total loss': 0.3829361071640795} | train loss {'Reaction outcome loss': 0.32143077664837544, 'Total loss': 0.32143077664837544}
2022-11-28 03:14:49,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:49,900 INFO:     Epoch: 65
2022-11-28 03:14:50,646 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39730617099187593, 'Total loss': 0.39730617099187593} | train loss {'Reaction outcome loss': 0.3243174777043109, 'Total loss': 0.3243174777043109}
2022-11-28 03:14:50,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:50,646 INFO:     Epoch: 66
2022-11-28 03:14:51,396 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39770293405110185, 'Total loss': 0.39770293405110185} | train loss {'Reaction outcome loss': 0.3091555060172568, 'Total loss': 0.3091555060172568}
2022-11-28 03:14:51,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:51,397 INFO:     Epoch: 67
2022-11-28 03:14:52,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4011862927370451, 'Total loss': 0.4011862927370451} | train loss {'Reaction outcome loss': 0.30237444040118433, 'Total loss': 0.30237444040118433}
2022-11-28 03:14:52,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:52,146 INFO:     Epoch: 68
2022-11-28 03:14:52,895 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39707355247810483, 'Total loss': 0.39707355247810483} | train loss {'Reaction outcome loss': 0.31054658106699284, 'Total loss': 0.31054658106699284}
2022-11-28 03:14:52,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:52,895 INFO:     Epoch: 69
2022-11-28 03:14:53,645 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39805539629676123, 'Total loss': 0.39805539629676123} | train loss {'Reaction outcome loss': 0.3107869537813323, 'Total loss': 0.3107869537813323}
2022-11-28 03:14:53,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:53,645 INFO:     Epoch: 70
2022-11-28 03:14:54,391 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37365930747579446, 'Total loss': 0.37365930747579446} | train loss {'Reaction outcome loss': 0.31620167192755916, 'Total loss': 0.31620167192755916}
2022-11-28 03:14:54,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:54,391 INFO:     Epoch: 71
2022-11-28 03:14:55,134 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3955132101069797, 'Total loss': 0.3955132101069797} | train loss {'Reaction outcome loss': 0.3068852980830232, 'Total loss': 0.3068852980830232}
2022-11-28 03:14:55,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:55,135 INFO:     Epoch: 72
2022-11-28 03:14:55,880 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4240401830862869, 'Total loss': 0.4240401830862869} | train loss {'Reaction outcome loss': 0.3010086842945644, 'Total loss': 0.3010086842945644}
2022-11-28 03:14:55,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:55,881 INFO:     Epoch: 73
2022-11-28 03:14:56,627 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3921157529746944, 'Total loss': 0.3921157529746944} | train loss {'Reaction outcome loss': 0.3087215319579961, 'Total loss': 0.3087215319579961}
2022-11-28 03:14:56,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:56,628 INFO:     Epoch: 74
2022-11-28 03:14:57,376 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4145259020680731, 'Total loss': 0.4145259020680731} | train loss {'Reaction outcome loss': 0.30406626918334134, 'Total loss': 0.30406626918334134}
2022-11-28 03:14:57,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:57,376 INFO:     Epoch: 75
2022-11-28 03:14:58,122 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3831235630945726, 'Total loss': 0.3831235630945726} | train loss {'Reaction outcome loss': 0.30792866847953015, 'Total loss': 0.30792866847953015}
2022-11-28 03:14:58,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:58,122 INFO:     Epoch: 76
2022-11-28 03:14:58,868 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4213652949441563, 'Total loss': 0.4213652949441563} | train loss {'Reaction outcome loss': 0.30173054878809014, 'Total loss': 0.30173054878809014}
2022-11-28 03:14:58,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:58,868 INFO:     Epoch: 77
2022-11-28 03:14:59,612 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4016313227740201, 'Total loss': 0.4016313227740201} | train loss {'Reaction outcome loss': 0.30693646456514084, 'Total loss': 0.30693646456514084}
2022-11-28 03:14:59,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:14:59,612 INFO:     Epoch: 78
2022-11-28 03:15:00,357 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40176231786608696, 'Total loss': 0.40176231786608696} | train loss {'Reaction outcome loss': 0.3040619735510982, 'Total loss': 0.3040619735510982}
2022-11-28 03:15:00,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:00,357 INFO:     Epoch: 79
2022-11-28 03:15:01,104 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39664659005674446, 'Total loss': 0.39664659005674446} | train loss {'Reaction outcome loss': 0.2970835443205979, 'Total loss': 0.2970835443205979}
2022-11-28 03:15:01,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:01,104 INFO:     Epoch: 80
2022-11-28 03:15:01,851 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42025115578012034, 'Total loss': 0.42025115578012034} | train loss {'Reaction outcome loss': 0.3035365832399349, 'Total loss': 0.3035365832399349}
2022-11-28 03:15:01,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:01,852 INFO:     Epoch: 81
2022-11-28 03:15:02,600 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40008648010817444, 'Total loss': 0.40008648010817444} | train loss {'Reaction outcome loss': 0.3131653181904433, 'Total loss': 0.3131653181904433}
2022-11-28 03:15:02,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:02,600 INFO:     Epoch: 82
2022-11-28 03:15:03,343 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4128376667133786, 'Total loss': 0.4128376667133786} | train loss {'Reaction outcome loss': 0.3078820188282704, 'Total loss': 0.3078820188282704}
2022-11-28 03:15:03,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:03,343 INFO:     Epoch: 83
2022-11-28 03:15:04,091 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40069193714721635, 'Total loss': 0.40069193714721635} | train loss {'Reaction outcome loss': 0.3058732194559915, 'Total loss': 0.3058732194559915}
2022-11-28 03:15:04,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:04,092 INFO:     Epoch: 84
2022-11-28 03:15:04,841 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38967949405989866, 'Total loss': 0.38967949405989866} | train loss {'Reaction outcome loss': 0.31424684104870776, 'Total loss': 0.31424684104870776}
2022-11-28 03:15:04,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:04,841 INFO:     Epoch: 85
2022-11-28 03:15:05,585 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40015695785934274, 'Total loss': 0.40015695785934274} | train loss {'Reaction outcome loss': 0.3094973364654852, 'Total loss': 0.3094973364654852}
2022-11-28 03:15:05,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:05,585 INFO:     Epoch: 86
2022-11-28 03:15:06,330 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37564339573410427, 'Total loss': 0.37564339573410427} | train loss {'Reaction outcome loss': 0.3083847437738156, 'Total loss': 0.3083847437738156}
2022-11-28 03:15:06,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:06,330 INFO:     Epoch: 87
2022-11-28 03:15:07,075 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4048304683105512, 'Total loss': 0.4048304683105512} | train loss {'Reaction outcome loss': 0.30251348499132663, 'Total loss': 0.30251348499132663}
2022-11-28 03:15:07,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:07,075 INFO:     Epoch: 88
2022-11-28 03:15:07,824 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3751783005215905, 'Total loss': 0.3751783005215905} | train loss {'Reaction outcome loss': 0.29751133669395835, 'Total loss': 0.29751133669395835}
2022-11-28 03:15:07,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:07,825 INFO:     Epoch: 89
2022-11-28 03:15:08,573 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42048502747308125, 'Total loss': 0.42048502747308125} | train loss {'Reaction outcome loss': 0.3072274727784857, 'Total loss': 0.3072274727784857}
2022-11-28 03:15:08,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:08,574 INFO:     Epoch: 90
2022-11-28 03:15:09,318 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3708642805841836, 'Total loss': 0.3708642805841836} | train loss {'Reaction outcome loss': 0.30467825836064866, 'Total loss': 0.30467825836064866}
2022-11-28 03:15:09,318 INFO:     Found new best model at epoch 90
2022-11-28 03:15:09,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:09,319 INFO:     Epoch: 91
2022-11-28 03:15:10,063 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3938455190509558, 'Total loss': 0.3938455190509558} | train loss {'Reaction outcome loss': 0.3020568856019147, 'Total loss': 0.3020568856019147}
2022-11-28 03:15:10,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:10,064 INFO:     Epoch: 92
2022-11-28 03:15:10,810 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40330232036384667, 'Total loss': 0.40330232036384667} | train loss {'Reaction outcome loss': 0.3047016192455681, 'Total loss': 0.3047016192455681}
2022-11-28 03:15:10,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:10,810 INFO:     Epoch: 93
2022-11-28 03:15:11,557 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40950262343341653, 'Total loss': 0.40950262343341653} | train loss {'Reaction outcome loss': 0.30709305274851467, 'Total loss': 0.30709305274851467}
2022-11-28 03:15:11,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:11,558 INFO:     Epoch: 94
2022-11-28 03:15:12,305 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3779033259594474, 'Total loss': 0.3779033259594474} | train loss {'Reaction outcome loss': 0.2989001583384008, 'Total loss': 0.2989001583384008}
2022-11-28 03:15:12,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:12,305 INFO:     Epoch: 95
2022-11-28 03:15:13,051 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38910880278457294, 'Total loss': 0.38910880278457294} | train loss {'Reaction outcome loss': 0.30357030811054364, 'Total loss': 0.30357030811054364}
2022-11-28 03:15:13,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:13,051 INFO:     Epoch: 96
2022-11-28 03:15:13,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43266409110616555, 'Total loss': 0.43266409110616555} | train loss {'Reaction outcome loss': 0.3008114024084442, 'Total loss': 0.3008114024084442}
2022-11-28 03:15:13,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:13,795 INFO:     Epoch: 97
2022-11-28 03:15:14,536 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4180571050806479, 'Total loss': 0.4180571050806479} | train loss {'Reaction outcome loss': 0.3006994408004138, 'Total loss': 0.3006994408004138}
2022-11-28 03:15:14,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:14,536 INFO:     Epoch: 98
2022-11-28 03:15:15,282 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37974519265646284, 'Total loss': 0.37974519265646284} | train loss {'Reaction outcome loss': 0.3088762294272987, 'Total loss': 0.3088762294272987}
2022-11-28 03:15:15,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:15,282 INFO:     Epoch: 99
2022-11-28 03:15:16,025 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3619235496629368, 'Total loss': 0.3619235496629368} | train loss {'Reaction outcome loss': 0.3049972436257771, 'Total loss': 0.3049972436257771}
2022-11-28 03:15:16,025 INFO:     Found new best model at epoch 99
2022-11-28 03:15:16,026 INFO:     Best model found after epoch 100 of 100.
2022-11-28 03:15:16,026 INFO:   Done with stage: TRAINING
2022-11-28 03:15:16,026 INFO:   Starting stage: EVALUATION
2022-11-28 03:15:16,153 INFO:   Done with stage: EVALUATION
2022-11-28 03:15:16,153 INFO:   Leaving out SEQ value Fold_4
2022-11-28 03:15:16,166 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:15:16,166 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:15:16,820 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:15:16,820 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:15:16,888 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:15:16,888 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:15:16,888 INFO:     No hyperparam tuning for this model
2022-11-28 03:15:16,888 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:15:16,889 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:15:16,889 INFO:     None feature selector for col prot
2022-11-28 03:15:16,889 INFO:     None feature selector for col prot
2022-11-28 03:15:16,890 INFO:     None feature selector for col prot
2022-11-28 03:15:16,890 INFO:     None feature selector for col chem
2022-11-28 03:15:16,890 INFO:     None feature selector for col chem
2022-11-28 03:15:16,890 INFO:     None feature selector for col chem
2022-11-28 03:15:16,890 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:15:16,890 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:15:16,892 INFO:     Number of params in model 169741
2022-11-28 03:15:16,895 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:15:16,895 INFO:   Starting stage: TRAINING
2022-11-28 03:15:16,949 INFO:     Val loss before train {'Reaction outcome loss': 1.0218699032610112, 'Total loss': 1.0218699032610112}
2022-11-28 03:15:16,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:16,950 INFO:     Epoch: 0
2022-11-28 03:15:17,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5344782580028881, 'Total loss': 0.5344782580028881} | train loss {'Reaction outcome loss': 0.6383372876312463, 'Total loss': 0.6383372876312463}
2022-11-28 03:15:17,706 INFO:     Found new best model at epoch 0
2022-11-28 03:15:17,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:17,707 INFO:     Epoch: 1
2022-11-28 03:15:18,460 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5743024403398688, 'Total loss': 0.5743024403398688} | train loss {'Reaction outcome loss': 0.5080222981351037, 'Total loss': 0.5080222981351037}
2022-11-28 03:15:18,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:18,460 INFO:     Epoch: 2
2022-11-28 03:15:19,211 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4940576675263318, 'Total loss': 0.4940576675263318} | train loss {'Reaction outcome loss': 0.4711894752277482, 'Total loss': 0.4711894752277482}
2022-11-28 03:15:19,211 INFO:     Found new best model at epoch 2
2022-11-28 03:15:19,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:19,212 INFO:     Epoch: 3
2022-11-28 03:15:19,966 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4658471139317209, 'Total loss': 0.4658471139317209} | train loss {'Reaction outcome loss': 0.44839531249336656, 'Total loss': 0.44839531249336656}
2022-11-28 03:15:19,966 INFO:     Found new best model at epoch 3
2022-11-28 03:15:19,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:19,967 INFO:     Epoch: 4
2022-11-28 03:15:20,720 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4954922527752139, 'Total loss': 0.4954922527752139} | train loss {'Reaction outcome loss': 0.42949677192636077, 'Total loss': 0.42949677192636077}
2022-11-28 03:15:20,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:20,720 INFO:     Epoch: 5
2022-11-28 03:15:21,475 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4883580455048518, 'Total loss': 0.4883580455048518} | train loss {'Reaction outcome loss': 0.4157214743956443, 'Total loss': 0.4157214743956443}
2022-11-28 03:15:21,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:21,475 INFO:     Epoch: 6
2022-11-28 03:15:22,230 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46476670930331404, 'Total loss': 0.46476670930331404} | train loss {'Reaction outcome loss': 0.4114389669510626, 'Total loss': 0.4114389669510626}
2022-11-28 03:15:22,230 INFO:     Found new best model at epoch 6
2022-11-28 03:15:22,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:22,231 INFO:     Epoch: 7
2022-11-28 03:15:22,983 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5440761443566192, 'Total loss': 0.5440761443566192} | train loss {'Reaction outcome loss': 0.3946251672121786, 'Total loss': 0.3946251672121786}
2022-11-28 03:15:22,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:22,983 INFO:     Epoch: 8
2022-11-28 03:15:23,736 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43328868360681966, 'Total loss': 0.43328868360681966} | train loss {'Reaction outcome loss': 0.4033361386147238, 'Total loss': 0.4033361386147238}
2022-11-28 03:15:23,736 INFO:     Found new best model at epoch 8
2022-11-28 03:15:23,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:23,737 INFO:     Epoch: 9
2022-11-28 03:15:24,488 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47116757759993727, 'Total loss': 0.47116757759993727} | train loss {'Reaction outcome loss': 0.38782354098774735, 'Total loss': 0.38782354098774735}
2022-11-28 03:15:24,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:24,488 INFO:     Epoch: 10
2022-11-28 03:15:25,240 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48169079202819953, 'Total loss': 0.48169079202819953} | train loss {'Reaction outcome loss': 0.39140996484146, 'Total loss': 0.39140996484146}
2022-11-28 03:15:25,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:25,240 INFO:     Epoch: 11
2022-11-28 03:15:25,992 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4581919170238755, 'Total loss': 0.4581919170238755} | train loss {'Reaction outcome loss': 0.38005723406170167, 'Total loss': 0.38005723406170167}
2022-11-28 03:15:25,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:25,993 INFO:     Epoch: 12
2022-11-28 03:15:26,745 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4653487280011177, 'Total loss': 0.4653487280011177} | train loss {'Reaction outcome loss': 0.37632111267697427, 'Total loss': 0.37632111267697427}
2022-11-28 03:15:26,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:26,745 INFO:     Epoch: 13
2022-11-28 03:15:27,497 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4404472072016109, 'Total loss': 0.4404472072016109} | train loss {'Reaction outcome loss': 0.3647197446891017, 'Total loss': 0.3647197446891017}
2022-11-28 03:15:27,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:27,497 INFO:     Epoch: 14
2022-11-28 03:15:28,245 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45607553845779464, 'Total loss': 0.45607553845779464} | train loss {'Reaction outcome loss': 0.3646833866894726, 'Total loss': 0.3646833866894726}
2022-11-28 03:15:28,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:28,245 INFO:     Epoch: 15
2022-11-28 03:15:28,997 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5045596928420392, 'Total loss': 0.5045596928420392} | train loss {'Reaction outcome loss': 0.35131307108508003, 'Total loss': 0.35131307108508003}
2022-11-28 03:15:28,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:28,997 INFO:     Epoch: 16
2022-11-28 03:15:29,754 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4605272683230313, 'Total loss': 0.4605272683230313} | train loss {'Reaction outcome loss': 0.3718614731464655, 'Total loss': 0.3718614731464655}
2022-11-28 03:15:29,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:29,755 INFO:     Epoch: 17
2022-11-28 03:15:30,507 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46208827570080757, 'Total loss': 0.46208827570080757} | train loss {'Reaction outcome loss': 0.3546819986114579, 'Total loss': 0.3546819986114579}
2022-11-28 03:15:30,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:30,507 INFO:     Epoch: 18
2022-11-28 03:15:31,255 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45803997360847215, 'Total loss': 0.45803997360847215} | train loss {'Reaction outcome loss': 0.36177795671767765, 'Total loss': 0.36177795671767765}
2022-11-28 03:15:31,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:31,255 INFO:     Epoch: 19
2022-11-28 03:15:32,003 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44779143177650194, 'Total loss': 0.44779143177650194} | train loss {'Reaction outcome loss': 0.35030354703626326, 'Total loss': 0.35030354703626326}
2022-11-28 03:15:32,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:32,003 INFO:     Epoch: 20
2022-11-28 03:15:32,753 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4461983408440243, 'Total loss': 0.4461983408440243} | train loss {'Reaction outcome loss': 0.3454066228662287, 'Total loss': 0.3454066228662287}
2022-11-28 03:15:32,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:32,753 INFO:     Epoch: 21
2022-11-28 03:15:33,502 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.423711032691327, 'Total loss': 0.423711032691327} | train loss {'Reaction outcome loss': 0.35315819946868765, 'Total loss': 0.35315819946868765}
2022-11-28 03:15:33,502 INFO:     Found new best model at epoch 21
2022-11-28 03:15:33,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:33,503 INFO:     Epoch: 22
2022-11-28 03:15:34,253 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44130796126343985, 'Total loss': 0.44130796126343985} | train loss {'Reaction outcome loss': 0.35191185752891246, 'Total loss': 0.35191185752891246}
2022-11-28 03:15:34,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:34,253 INFO:     Epoch: 23
2022-11-28 03:15:35,004 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45712129602378065, 'Total loss': 0.45712129602378065} | train loss {'Reaction outcome loss': 0.3445125533448112, 'Total loss': 0.3445125533448112}
2022-11-28 03:15:35,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:35,004 INFO:     Epoch: 24
2022-11-28 03:15:35,756 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4537883637980981, 'Total loss': 0.4537883637980981} | train loss {'Reaction outcome loss': 0.3474854493453618, 'Total loss': 0.3474854493453618}
2022-11-28 03:15:35,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:35,757 INFO:     Epoch: 25
2022-11-28 03:15:36,508 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.437096987596967, 'Total loss': 0.437096987596967} | train loss {'Reaction outcome loss': 0.3369725513902883, 'Total loss': 0.3369725513902883}
2022-11-28 03:15:36,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:36,508 INFO:     Epoch: 26
2022-11-28 03:15:37,263 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46494373509829695, 'Total loss': 0.46494373509829695} | train loss {'Reaction outcome loss': 0.34455014648096216, 'Total loss': 0.34455014648096216}
2022-11-28 03:15:37,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:37,263 INFO:     Epoch: 27
2022-11-28 03:15:38,012 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4315027252516963, 'Total loss': 0.4315027252516963} | train loss {'Reaction outcome loss': 0.34688090067356825, 'Total loss': 0.34688090067356825}
2022-11-28 03:15:38,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:38,012 INFO:     Epoch: 28
2022-11-28 03:15:38,759 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44942270117727195, 'Total loss': 0.44942270117727195} | train loss {'Reaction outcome loss': 0.3432560639696256, 'Total loss': 0.3432560639696256}
2022-11-28 03:15:38,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:38,760 INFO:     Epoch: 29
2022-11-28 03:15:39,508 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4442240311340852, 'Total loss': 0.4442240311340852} | train loss {'Reaction outcome loss': 0.33190225683633356, 'Total loss': 0.33190225683633356}
2022-11-28 03:15:39,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:39,508 INFO:     Epoch: 30
2022-11-28 03:15:40,260 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46342026916417206, 'Total loss': 0.46342026916417206} | train loss {'Reaction outcome loss': 0.33208364671877316, 'Total loss': 0.33208364671877316}
2022-11-28 03:15:40,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:40,260 INFO:     Epoch: 31
2022-11-28 03:15:41,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46146104112267494, 'Total loss': 0.46146104112267494} | train loss {'Reaction outcome loss': 0.3327742136654354, 'Total loss': 0.3327742136654354}
2022-11-28 03:15:41,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:41,014 INFO:     Epoch: 32
2022-11-28 03:15:41,767 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43890822611071845, 'Total loss': 0.43890822611071845} | train loss {'Reaction outcome loss': 0.34365911382220443, 'Total loss': 0.34365911382220443}
2022-11-28 03:15:41,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:41,768 INFO:     Epoch: 33
2022-11-28 03:15:42,518 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41881898282603786, 'Total loss': 0.41881898282603786} | train loss {'Reaction outcome loss': 0.32863399566661927, 'Total loss': 0.32863399566661927}
2022-11-28 03:15:42,519 INFO:     Found new best model at epoch 33
2022-11-28 03:15:42,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:42,520 INFO:     Epoch: 34
2022-11-28 03:15:43,267 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41129360466518183, 'Total loss': 0.41129360466518183} | train loss {'Reaction outcome loss': 0.3378623657889904, 'Total loss': 0.3378623657889904}
2022-11-28 03:15:43,267 INFO:     Found new best model at epoch 34
2022-11-28 03:15:43,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:43,268 INFO:     Epoch: 35
2022-11-28 03:15:44,017 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4206912263550542, 'Total loss': 0.4206912263550542} | train loss {'Reaction outcome loss': 0.33315711465453907, 'Total loss': 0.33315711465453907}
2022-11-28 03:15:44,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:44,017 INFO:     Epoch: 36
2022-11-28 03:15:44,767 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4450596052814614, 'Total loss': 0.4450596052814614} | train loss {'Reaction outcome loss': 0.32940813781873834, 'Total loss': 0.32940813781873834}
2022-11-28 03:15:44,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:44,767 INFO:     Epoch: 37
2022-11-28 03:15:45,514 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.467028562318195, 'Total loss': 0.467028562318195} | train loss {'Reaction outcome loss': 0.3269101239800934, 'Total loss': 0.3269101239800934}
2022-11-28 03:15:45,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:45,514 INFO:     Epoch: 38
2022-11-28 03:15:46,261 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4335434396158565, 'Total loss': 0.4335434396158565} | train loss {'Reaction outcome loss': 0.32976258487530774, 'Total loss': 0.32976258487530774}
2022-11-28 03:15:46,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:46,262 INFO:     Epoch: 39
2022-11-28 03:15:47,011 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4434727652167732, 'Total loss': 0.4434727652167732} | train loss {'Reaction outcome loss': 0.32265504083085444, 'Total loss': 0.32265504083085444}
2022-11-28 03:15:47,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:47,011 INFO:     Epoch: 40
2022-11-28 03:15:47,760 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42449974810535257, 'Total loss': 0.42449974810535257} | train loss {'Reaction outcome loss': 0.3260397786845363, 'Total loss': 0.3260397786845363}
2022-11-28 03:15:47,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:47,760 INFO:     Epoch: 41
2022-11-28 03:15:48,506 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4764701023020528, 'Total loss': 0.4764701023020528} | train loss {'Reaction outcome loss': 0.3248399226145158, 'Total loss': 0.3248399226145158}
2022-11-28 03:15:48,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:48,506 INFO:     Epoch: 42
2022-11-28 03:15:49,255 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46641873669895256, 'Total loss': 0.46641873669895256} | train loss {'Reaction outcome loss': 0.3263927915193621, 'Total loss': 0.3263927915193621}
2022-11-28 03:15:49,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:49,256 INFO:     Epoch: 43
2022-11-28 03:15:50,001 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4327590177682313, 'Total loss': 0.4327590177682313} | train loss {'Reaction outcome loss': 0.3268121226480411, 'Total loss': 0.3268121226480411}
2022-11-28 03:15:50,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:50,002 INFO:     Epoch: 44
2022-11-28 03:15:50,750 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.456934823400595, 'Total loss': 0.456934823400595} | train loss {'Reaction outcome loss': 0.32313475652687973, 'Total loss': 0.32313475652687973}
2022-11-28 03:15:50,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:50,751 INFO:     Epoch: 45
2022-11-28 03:15:51,503 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4357579899105159, 'Total loss': 0.4357579899105159} | train loss {'Reaction outcome loss': 0.3174441474219484, 'Total loss': 0.3174441474219484}
2022-11-28 03:15:51,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:51,503 INFO:     Epoch: 46
2022-11-28 03:15:52,251 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4242871711877259, 'Total loss': 0.4242871711877259} | train loss {'Reaction outcome loss': 0.32079210049743134, 'Total loss': 0.32079210049743134}
2022-11-28 03:15:52,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:52,252 INFO:     Epoch: 47
2022-11-28 03:15:52,996 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46126736514270306, 'Total loss': 0.46126736514270306} | train loss {'Reaction outcome loss': 0.32538996462620073, 'Total loss': 0.32538996462620073}
2022-11-28 03:15:52,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:52,996 INFO:     Epoch: 48
2022-11-28 03:15:53,742 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44416771189902315, 'Total loss': 0.44416771189902315} | train loss {'Reaction outcome loss': 0.32503354744685276, 'Total loss': 0.32503354744685276}
2022-11-28 03:15:53,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:53,743 INFO:     Epoch: 49
2022-11-28 03:15:54,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4280530715530569, 'Total loss': 0.4280530715530569} | train loss {'Reaction outcome loss': 0.31808652695749073, 'Total loss': 0.31808652695749073}
2022-11-28 03:15:54,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:54,490 INFO:     Epoch: 50
2022-11-28 03:15:55,240 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4367600472813303, 'Total loss': 0.4367600472813303} | train loss {'Reaction outcome loss': 0.32446317520413187, 'Total loss': 0.32446317520413187}
2022-11-28 03:15:55,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:55,241 INFO:     Epoch: 51
2022-11-28 03:15:55,986 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44012150608680467, 'Total loss': 0.44012150608680467} | train loss {'Reaction outcome loss': 0.30801666272623884, 'Total loss': 0.30801666272623884}
2022-11-28 03:15:55,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:55,986 INFO:     Epoch: 52
2022-11-28 03:15:56,732 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4224684038622813, 'Total loss': 0.4224684038622813} | train loss {'Reaction outcome loss': 0.31566343002862507, 'Total loss': 0.31566343002862507}
2022-11-28 03:15:56,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:56,732 INFO:     Epoch: 53
2022-11-28 03:15:57,479 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4344964152710004, 'Total loss': 0.4344964152710004} | train loss {'Reaction outcome loss': 0.33247624900973133, 'Total loss': 0.33247624900973133}
2022-11-28 03:15:57,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:57,479 INFO:     Epoch: 54
2022-11-28 03:15:58,225 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4652513329955665, 'Total loss': 0.4652513329955665} | train loss {'Reaction outcome loss': 0.3171465440593179, 'Total loss': 0.3171465440593179}
2022-11-28 03:15:58,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:58,225 INFO:     Epoch: 55
2022-11-28 03:15:58,972 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5108539502729069, 'Total loss': 0.5108539502729069} | train loss {'Reaction outcome loss': 0.31355300473590053, 'Total loss': 0.31355300473590053}
2022-11-28 03:15:58,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:58,972 INFO:     Epoch: 56
2022-11-28 03:15:59,719 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4344055693257939, 'Total loss': 0.4344055693257939} | train loss {'Reaction outcome loss': 0.33187881412525333, 'Total loss': 0.33187881412525333}
2022-11-28 03:15:59,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:15:59,720 INFO:     Epoch: 57
2022-11-28 03:16:00,466 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42037348313765094, 'Total loss': 0.42037348313765094} | train loss {'Reaction outcome loss': 0.325182021926007, 'Total loss': 0.325182021926007}
2022-11-28 03:16:00,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:00,466 INFO:     Epoch: 58
2022-11-28 03:16:01,217 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44394745135849173, 'Total loss': 0.44394745135849173} | train loss {'Reaction outcome loss': 0.3238467799815079, 'Total loss': 0.3238467799815079}
2022-11-28 03:16:01,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:01,217 INFO:     Epoch: 59
2022-11-28 03:16:01,963 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42831750823692843, 'Total loss': 0.42831750823692843} | train loss {'Reaction outcome loss': 0.3240489840447422, 'Total loss': 0.3240489840447422}
2022-11-28 03:16:01,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:01,964 INFO:     Epoch: 60
2022-11-28 03:16:02,711 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4413533441045068, 'Total loss': 0.4413533441045068} | train loss {'Reaction outcome loss': 0.3191780468689338, 'Total loss': 0.3191780468689338}
2022-11-28 03:16:02,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:02,712 INFO:     Epoch: 61
2022-11-28 03:16:03,460 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4429446230219169, 'Total loss': 0.4429446230219169} | train loss {'Reaction outcome loss': 0.31636529106406436, 'Total loss': 0.31636529106406436}
2022-11-28 03:16:03,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:03,461 INFO:     Epoch: 62
2022-11-28 03:16:04,213 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45533649013801053, 'Total loss': 0.45533649013801053} | train loss {'Reaction outcome loss': 0.3138678899455455, 'Total loss': 0.3138678899455455}
2022-11-28 03:16:04,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:04,213 INFO:     Epoch: 63
2022-11-28 03:16:04,963 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4430566802620888, 'Total loss': 0.4430566802620888} | train loss {'Reaction outcome loss': 0.31922226423217404, 'Total loss': 0.31922226423217404}
2022-11-28 03:16:04,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:04,964 INFO:     Epoch: 64
2022-11-28 03:16:05,713 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48950165205381135, 'Total loss': 0.48950165205381135} | train loss {'Reaction outcome loss': 0.3275361374140747, 'Total loss': 0.3275361374140747}
2022-11-28 03:16:05,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:05,713 INFO:     Epoch: 65
2022-11-28 03:16:06,464 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44015698541294446, 'Total loss': 0.44015698541294446} | train loss {'Reaction outcome loss': 0.311058166955087, 'Total loss': 0.311058166955087}
2022-11-28 03:16:06,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:06,464 INFO:     Epoch: 66
2022-11-28 03:16:07,212 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4511012922633778, 'Total loss': 0.4511012922633778} | train loss {'Reaction outcome loss': 0.3217413339523538, 'Total loss': 0.3217413339523538}
2022-11-28 03:16:07,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:07,213 INFO:     Epoch: 67
2022-11-28 03:16:07,964 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41620222716168925, 'Total loss': 0.41620222716168925} | train loss {'Reaction outcome loss': 0.30793038271968404, 'Total loss': 0.30793038271968404}
2022-11-28 03:16:07,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:07,965 INFO:     Epoch: 68
2022-11-28 03:16:08,713 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4379747249186039, 'Total loss': 0.4379747249186039} | train loss {'Reaction outcome loss': 0.31747555789808113, 'Total loss': 0.31747555789808113}
2022-11-28 03:16:08,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:08,713 INFO:     Epoch: 69
2022-11-28 03:16:09,461 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45868313617326995, 'Total loss': 0.45868313617326995} | train loss {'Reaction outcome loss': 0.32158469838360626, 'Total loss': 0.32158469838360626}
2022-11-28 03:16:09,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:09,461 INFO:     Epoch: 70
2022-11-28 03:16:10,207 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43316063843667507, 'Total loss': 0.43316063843667507} | train loss {'Reaction outcome loss': 0.3160618155023023, 'Total loss': 0.3160618155023023}
2022-11-28 03:16:10,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:10,208 INFO:     Epoch: 71
2022-11-28 03:16:10,958 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4831781935962764, 'Total loss': 0.4831781935962764} | train loss {'Reaction outcome loss': 0.3046941011843662, 'Total loss': 0.3046941011843662}
2022-11-28 03:16:10,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:10,959 INFO:     Epoch: 72
2022-11-28 03:16:11,711 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4431656866588376, 'Total loss': 0.4431656866588376} | train loss {'Reaction outcome loss': 0.31959819319027083, 'Total loss': 0.31959819319027083}
2022-11-28 03:16:11,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:11,711 INFO:     Epoch: 73
2022-11-28 03:16:12,460 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4389412799342112, 'Total loss': 0.4389412799342112} | train loss {'Reaction outcome loss': 0.313298552537397, 'Total loss': 0.313298552537397}
2022-11-28 03:16:12,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:12,460 INFO:     Epoch: 74
2022-11-28 03:16:13,210 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4590110937980088, 'Total loss': 0.4590110937980088} | train loss {'Reaction outcome loss': 0.302423222981874, 'Total loss': 0.302423222981874}
2022-11-28 03:16:13,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:13,211 INFO:     Epoch: 75
2022-11-28 03:16:13,961 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4653278426690535, 'Total loss': 0.4653278426690535} | train loss {'Reaction outcome loss': 0.3244137444323109, 'Total loss': 0.3244137444323109}
2022-11-28 03:16:13,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:13,961 INFO:     Epoch: 76
2022-11-28 03:16:14,708 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4131056080487641, 'Total loss': 0.4131056080487641} | train loss {'Reaction outcome loss': 0.311148637184693, 'Total loss': 0.311148637184693}
2022-11-28 03:16:14,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:14,708 INFO:     Epoch: 77
2022-11-28 03:16:15,462 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46826065467162564, 'Total loss': 0.46826065467162564} | train loss {'Reaction outcome loss': 0.3139598810774905, 'Total loss': 0.3139598810774905}
2022-11-28 03:16:15,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:15,462 INFO:     Epoch: 78
2022-11-28 03:16:16,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4829046854918653, 'Total loss': 0.4829046854918653} | train loss {'Reaction outcome loss': 0.3254199121147394, 'Total loss': 0.3254199121147394}
2022-11-28 03:16:16,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:16,211 INFO:     Epoch: 79
2022-11-28 03:16:16,960 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4270138144493103, 'Total loss': 0.4270138144493103} | train loss {'Reaction outcome loss': 0.3134355737316993, 'Total loss': 0.3134355737316993}
2022-11-28 03:16:16,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:16,960 INFO:     Epoch: 80
2022-11-28 03:16:17,711 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41474749046293174, 'Total loss': 0.41474749046293174} | train loss {'Reaction outcome loss': 0.3182046309474014, 'Total loss': 0.3182046309474014}
2022-11-28 03:16:17,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:17,711 INFO:     Epoch: 81
2022-11-28 03:16:18,460 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4406980223615061, 'Total loss': 0.4406980223615061} | train loss {'Reaction outcome loss': 0.31023581228369185, 'Total loss': 0.31023581228369185}
2022-11-28 03:16:18,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:18,460 INFO:     Epoch: 82
2022-11-28 03:16:19,207 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43891890109940007, 'Total loss': 0.43891890109940007} | train loss {'Reaction outcome loss': 0.31838439705391086, 'Total loss': 0.31838439705391086}
2022-11-28 03:16:19,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:19,208 INFO:     Epoch: 83
2022-11-28 03:16:19,956 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4393348985097625, 'Total loss': 0.4393348985097625} | train loss {'Reaction outcome loss': 0.31155551450266955, 'Total loss': 0.31155551450266955}
2022-11-28 03:16:19,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:19,957 INFO:     Epoch: 84
2022-11-28 03:16:20,701 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4388824328780174, 'Total loss': 0.4388824328780174} | train loss {'Reaction outcome loss': 0.31122606307748824, 'Total loss': 0.31122606307748824}
2022-11-28 03:16:20,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:20,701 INFO:     Epoch: 85
2022-11-28 03:16:21,449 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4473330828953873, 'Total loss': 0.4473330828953873} | train loss {'Reaction outcome loss': 0.3193000259719068, 'Total loss': 0.3193000259719068}
2022-11-28 03:16:21,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:21,450 INFO:     Epoch: 86
2022-11-28 03:16:22,198 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4457874868742444, 'Total loss': 0.4457874868742444} | train loss {'Reaction outcome loss': 0.3094773008187692, 'Total loss': 0.3094773008187692}
2022-11-28 03:16:22,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:22,199 INFO:     Epoch: 87
2022-11-28 03:16:22,947 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43606976622884924, 'Total loss': 0.43606976622884924} | train loss {'Reaction outcome loss': 0.3126307148636589, 'Total loss': 0.3126307148636589}
2022-11-28 03:16:22,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:22,948 INFO:     Epoch: 88
2022-11-28 03:16:23,696 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4875531992451711, 'Total loss': 0.4875531992451711} | train loss {'Reaction outcome loss': 0.31706425233653956, 'Total loss': 0.31706425233653956}
2022-11-28 03:16:23,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:23,696 INFO:     Epoch: 89
2022-11-28 03:16:24,444 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44696651737798343, 'Total loss': 0.44696651737798343} | train loss {'Reaction outcome loss': 0.31729307911929583, 'Total loss': 0.31729307911929583}
2022-11-28 03:16:24,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:24,444 INFO:     Epoch: 90
2022-11-28 03:16:25,192 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41511160795661534, 'Total loss': 0.41511160795661534} | train loss {'Reaction outcome loss': 0.32314379915835395, 'Total loss': 0.32314379915835395}
2022-11-28 03:16:25,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:25,192 INFO:     Epoch: 91
2022-11-28 03:16:25,943 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4449866717173295, 'Total loss': 0.4449866717173295} | train loss {'Reaction outcome loss': 0.317201616062272, 'Total loss': 0.317201616062272}
2022-11-28 03:16:25,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:25,944 INFO:     Epoch: 92
2022-11-28 03:16:26,694 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4749204076149247, 'Total loss': 0.4749204076149247} | train loss {'Reaction outcome loss': 0.3029740531027557, 'Total loss': 0.3029740531027557}
2022-11-28 03:16:26,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:26,694 INFO:     Epoch: 93
2022-11-28 03:16:27,442 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45980723337693646, 'Total loss': 0.45980723337693646} | train loss {'Reaction outcome loss': 0.3158030168063218, 'Total loss': 0.3158030168063218}
2022-11-28 03:16:27,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:27,442 INFO:     Epoch: 94
2022-11-28 03:16:28,192 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4728310832923109, 'Total loss': 0.4728310832923109} | train loss {'Reaction outcome loss': 0.32207722874778894, 'Total loss': 0.32207722874778894}
2022-11-28 03:16:28,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:28,192 INFO:     Epoch: 95
2022-11-28 03:16:28,942 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42774743688377465, 'Total loss': 0.42774743688377465} | train loss {'Reaction outcome loss': 0.31327236096765243, 'Total loss': 0.31327236096765243}
2022-11-28 03:16:28,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:28,942 INFO:     Epoch: 96
2022-11-28 03:16:29,692 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42691231349652464, 'Total loss': 0.42691231349652464} | train loss {'Reaction outcome loss': 0.3157180688013473, 'Total loss': 0.3157180688013473}
2022-11-28 03:16:29,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:29,692 INFO:     Epoch: 97
2022-11-28 03:16:30,443 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4280677678232843, 'Total loss': 0.4280677678232843} | train loss {'Reaction outcome loss': 0.3150794588690323, 'Total loss': 0.3150794588690323}
2022-11-28 03:16:30,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:30,443 INFO:     Epoch: 98
2022-11-28 03:16:31,189 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4440965943715789, 'Total loss': 0.4440965943715789} | train loss {'Reaction outcome loss': 0.3201459453501288, 'Total loss': 0.3201459453501288}
2022-11-28 03:16:31,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:31,189 INFO:     Epoch: 99
2022-11-28 03:16:31,940 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4562520335682414, 'Total loss': 0.4562520335682414} | train loss {'Reaction outcome loss': 0.3103175284941831, 'Total loss': 0.3103175284941831}
2022-11-28 03:16:31,940 INFO:     Best model found after epoch 35 of 100.
2022-11-28 03:16:31,940 INFO:   Done with stage: TRAINING
2022-11-28 03:16:31,940 INFO:   Starting stage: EVALUATION
2022-11-28 03:16:32,055 INFO:   Done with stage: EVALUATION
2022-11-28 03:16:32,055 INFO:   Leaving out SEQ value Fold_5
2022-11-28 03:16:32,068 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:16:32,068 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:16:32,712 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:16:32,712 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:16:32,780 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:16:32,780 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:16:32,780 INFO:     No hyperparam tuning for this model
2022-11-28 03:16:32,780 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:16:32,780 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:16:32,781 INFO:     None feature selector for col prot
2022-11-28 03:16:32,781 INFO:     None feature selector for col prot
2022-11-28 03:16:32,781 INFO:     None feature selector for col prot
2022-11-28 03:16:32,782 INFO:     None feature selector for col chem
2022-11-28 03:16:32,782 INFO:     None feature selector for col chem
2022-11-28 03:16:32,782 INFO:     None feature selector for col chem
2022-11-28 03:16:32,782 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:16:32,782 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:16:32,784 INFO:     Number of params in model 169741
2022-11-28 03:16:32,787 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:16:32,787 INFO:   Starting stage: TRAINING
2022-11-28 03:16:32,840 INFO:     Val loss before train {'Reaction outcome loss': 0.9133713299577887, 'Total loss': 0.9133713299577887}
2022-11-28 03:16:32,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:32,840 INFO:     Epoch: 0
2022-11-28 03:16:33,585 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5300272513519634, 'Total loss': 0.5300272513519634} | train loss {'Reaction outcome loss': 0.6296840698848809, 'Total loss': 0.6296840698848809}
2022-11-28 03:16:33,585 INFO:     Found new best model at epoch 0
2022-11-28 03:16:33,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:33,586 INFO:     Epoch: 1
2022-11-28 03:16:34,336 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4086154888976704, 'Total loss': 0.4086154888976704} | train loss {'Reaction outcome loss': 0.49889272072863194, 'Total loss': 0.49889272072863194}
2022-11-28 03:16:34,336 INFO:     Found new best model at epoch 1
2022-11-28 03:16:34,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:34,337 INFO:     Epoch: 2
2022-11-28 03:16:35,082 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4148470281877301, 'Total loss': 0.4148470281877301} | train loss {'Reaction outcome loss': 0.46669148707822444, 'Total loss': 0.46669148707822444}
2022-11-28 03:16:35,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:35,082 INFO:     Epoch: 3
2022-11-28 03:16:35,829 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4225039424544031, 'Total loss': 0.4225039424544031} | train loss {'Reaction outcome loss': 0.4457257298091727, 'Total loss': 0.4457257298091727}
2022-11-28 03:16:35,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:35,829 INFO:     Epoch: 4
2022-11-28 03:16:36,578 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4414519217203964, 'Total loss': 0.4414519217203964} | train loss {'Reaction outcome loss': 0.4298024452742069, 'Total loss': 0.4298024452742069}
2022-11-28 03:16:36,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:36,578 INFO:     Epoch: 5
2022-11-28 03:16:37,327 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39703183756633237, 'Total loss': 0.39703183756633237} | train loss {'Reaction outcome loss': 0.4188339109382322, 'Total loss': 0.4188339109382322}
2022-11-28 03:16:37,328 INFO:     Found new best model at epoch 5
2022-11-28 03:16:37,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:37,328 INFO:     Epoch: 6
2022-11-28 03:16:38,076 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37866534834558313, 'Total loss': 0.37866534834558313} | train loss {'Reaction outcome loss': 0.41489846415577397, 'Total loss': 0.41489846415577397}
2022-11-28 03:16:38,077 INFO:     Found new best model at epoch 6
2022-11-28 03:16:38,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:38,078 INFO:     Epoch: 7
2022-11-28 03:16:38,825 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39863621460443194, 'Total loss': 0.39863621460443194} | train loss {'Reaction outcome loss': 0.39711025345229334, 'Total loss': 0.39711025345229334}
2022-11-28 03:16:38,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:38,825 INFO:     Epoch: 8
2022-11-28 03:16:39,573 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.386027985506437, 'Total loss': 0.386027985506437} | train loss {'Reaction outcome loss': 0.3923658350061986, 'Total loss': 0.3923658350061986}
2022-11-28 03:16:39,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:39,573 INFO:     Epoch: 9
2022-11-28 03:16:40,326 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42617945474657143, 'Total loss': 0.42617945474657143} | train loss {'Reaction outcome loss': 0.3809403750384527, 'Total loss': 0.3809403750384527}
2022-11-28 03:16:40,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:40,326 INFO:     Epoch: 10
2022-11-28 03:16:41,072 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3943368988958272, 'Total loss': 0.3943368988958272} | train loss {'Reaction outcome loss': 0.3864533255898183, 'Total loss': 0.3864533255898183}
2022-11-28 03:16:41,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:41,073 INFO:     Epoch: 11
2022-11-28 03:16:41,824 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4258514270186424, 'Total loss': 0.4258514270186424} | train loss {'Reaction outcome loss': 0.3749156267712674, 'Total loss': 0.3749156267712674}
2022-11-28 03:16:41,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:41,824 INFO:     Epoch: 12
2022-11-28 03:16:42,577 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44715146686543117, 'Total loss': 0.44715146686543117} | train loss {'Reaction outcome loss': 0.37977250340965485, 'Total loss': 0.37977250340965485}
2022-11-28 03:16:42,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:42,577 INFO:     Epoch: 13
2022-11-28 03:16:43,324 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38934035870161926, 'Total loss': 0.38934035870161926} | train loss {'Reaction outcome loss': 0.37120550125837326, 'Total loss': 0.37120550125837326}
2022-11-28 03:16:43,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:43,324 INFO:     Epoch: 14
2022-11-28 03:16:44,076 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38812962047417054, 'Total loss': 0.38812962047417054} | train loss {'Reaction outcome loss': 0.3760256445816448, 'Total loss': 0.3760256445816448}
2022-11-28 03:16:44,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:44,077 INFO:     Epoch: 15
2022-11-28 03:16:44,826 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44421025467189873, 'Total loss': 0.44421025467189873} | train loss {'Reaction outcome loss': 0.3644460360970228, 'Total loss': 0.3644460360970228}
2022-11-28 03:16:44,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:44,827 INFO:     Epoch: 16
2022-11-28 03:16:45,574 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3932060602713715, 'Total loss': 0.3932060602713715} | train loss {'Reaction outcome loss': 0.3651782125535031, 'Total loss': 0.3651782125535031}
2022-11-28 03:16:45,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:45,574 INFO:     Epoch: 17
2022-11-28 03:16:46,321 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3554627269675786, 'Total loss': 0.3554627269675786} | train loss {'Reaction outcome loss': 0.35847806936550525, 'Total loss': 0.35847806936550525}
2022-11-28 03:16:46,321 INFO:     Found new best model at epoch 17
2022-11-28 03:16:46,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:46,322 INFO:     Epoch: 18
2022-11-28 03:16:47,069 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37589883702722465, 'Total loss': 0.37589883702722465} | train loss {'Reaction outcome loss': 0.34937039531406855, 'Total loss': 0.34937039531406855}
2022-11-28 03:16:47,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:47,069 INFO:     Epoch: 19
2022-11-28 03:16:47,816 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3972500159659169, 'Total loss': 0.3972500159659169} | train loss {'Reaction outcome loss': 0.36390035937450105, 'Total loss': 0.36390035937450105}
2022-11-28 03:16:47,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:47,817 INFO:     Epoch: 20
2022-11-28 03:16:48,563 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.371384128250859, 'Total loss': 0.371384128250859} | train loss {'Reaction outcome loss': 0.35169742241381635, 'Total loss': 0.35169742241381635}
2022-11-28 03:16:48,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:48,563 INFO:     Epoch: 21
2022-11-28 03:16:49,310 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3932471359995278, 'Total loss': 0.3932471359995278} | train loss {'Reaction outcome loss': 0.35157884600301903, 'Total loss': 0.35157884600301903}
2022-11-28 03:16:49,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:49,310 INFO:     Epoch: 22
2022-11-28 03:16:50,058 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38532226803627884, 'Total loss': 0.38532226803627884} | train loss {'Reaction outcome loss': 0.34673607562698666, 'Total loss': 0.34673607562698666}
2022-11-28 03:16:50,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:50,059 INFO:     Epoch: 23
2022-11-28 03:16:50,810 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3660568513653495, 'Total loss': 0.3660568513653495} | train loss {'Reaction outcome loss': 0.3533139612465616, 'Total loss': 0.3533139612465616}
2022-11-28 03:16:50,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:50,811 INFO:     Epoch: 24
2022-11-28 03:16:51,560 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3638945502991026, 'Total loss': 0.3638945502991026} | train loss {'Reaction outcome loss': 0.3405481083018164, 'Total loss': 0.3405481083018164}
2022-11-28 03:16:51,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:51,560 INFO:     Epoch: 25
2022-11-28 03:16:52,308 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36914005215195095, 'Total loss': 0.36914005215195095} | train loss {'Reaction outcome loss': 0.3385177287611089, 'Total loss': 0.3385177287611089}
2022-11-28 03:16:52,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:52,308 INFO:     Epoch: 26
2022-11-28 03:16:53,059 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3648429194634611, 'Total loss': 0.3648429194634611} | train loss {'Reaction outcome loss': 0.35013105080372864, 'Total loss': 0.35013105080372864}
2022-11-28 03:16:53,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:53,060 INFO:     Epoch: 27
2022-11-28 03:16:53,806 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3840746899897402, 'Total loss': 0.3840746899897402} | train loss {'Reaction outcome loss': 0.3389109839354792, 'Total loss': 0.3389109839354792}
2022-11-28 03:16:53,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:53,806 INFO:     Epoch: 28
2022-11-28 03:16:54,553 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.414900578558445, 'Total loss': 0.414900578558445} | train loss {'Reaction outcome loss': 0.34573791599682263, 'Total loss': 0.34573791599682263}
2022-11-28 03:16:54,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:54,554 INFO:     Epoch: 29
2022-11-28 03:16:55,301 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.34405362233519554, 'Total loss': 0.34405362233519554} | train loss {'Reaction outcome loss': 0.33322146078271253, 'Total loss': 0.33322146078271253}
2022-11-28 03:16:55,301 INFO:     Found new best model at epoch 29
2022-11-28 03:16:55,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:55,302 INFO:     Epoch: 30
2022-11-28 03:16:56,048 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37065542421557685, 'Total loss': 0.37065542421557685} | train loss {'Reaction outcome loss': 0.3371653435451369, 'Total loss': 0.3371653435451369}
2022-11-28 03:16:56,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:56,048 INFO:     Epoch: 31
2022-11-28 03:16:56,799 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37199138409712096, 'Total loss': 0.37199138409712096} | train loss {'Reaction outcome loss': 0.3391148598203736, 'Total loss': 0.3391148598203736}
2022-11-28 03:16:56,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:56,799 INFO:     Epoch: 32
2022-11-28 03:16:57,549 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4104767736386169, 'Total loss': 0.4104767736386169} | train loss {'Reaction outcome loss': 0.32843558733621914, 'Total loss': 0.32843558733621914}
2022-11-28 03:16:57,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:57,550 INFO:     Epoch: 33
2022-11-28 03:16:58,299 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3937637230212038, 'Total loss': 0.3937637230212038} | train loss {'Reaction outcome loss': 0.3362524975091219, 'Total loss': 0.3362524975091219}
2022-11-28 03:16:58,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:58,299 INFO:     Epoch: 34
2022-11-28 03:16:59,047 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3911966430869969, 'Total loss': 0.3911966430869969} | train loss {'Reaction outcome loss': 0.33727844233714765, 'Total loss': 0.33727844233714765}
2022-11-28 03:16:59,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:59,047 INFO:     Epoch: 35
2022-11-28 03:16:59,792 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39373167062347586, 'Total loss': 0.39373167062347586} | train loss {'Reaction outcome loss': 0.33347235064232544, 'Total loss': 0.33347235064232544}
2022-11-28 03:16:59,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:16:59,792 INFO:     Epoch: 36
2022-11-28 03:17:00,540 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37907020781527867, 'Total loss': 0.37907020781527867} | train loss {'Reaction outcome loss': 0.33244086351365815, 'Total loss': 0.33244086351365815}
2022-11-28 03:17:00,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:00,540 INFO:     Epoch: 37
2022-11-28 03:17:01,291 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36556353453885426, 'Total loss': 0.36556353453885426} | train loss {'Reaction outcome loss': 0.3314408671200996, 'Total loss': 0.3314408671200996}
2022-11-28 03:17:01,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:01,291 INFO:     Epoch: 38
2022-11-28 03:17:02,039 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3630419448018074, 'Total loss': 0.3630419448018074} | train loss {'Reaction outcome loss': 0.33553983661676606, 'Total loss': 0.33553983661676606}
2022-11-28 03:17:02,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:02,039 INFO:     Epoch: 39
2022-11-28 03:17:02,787 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39618111300197517, 'Total loss': 0.39618111300197517} | train loss {'Reaction outcome loss': 0.32697817629143117, 'Total loss': 0.32697817629143117}
2022-11-28 03:17:02,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:02,787 INFO:     Epoch: 40
2022-11-28 03:17:03,537 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3771060268309983, 'Total loss': 0.3771060268309983} | train loss {'Reaction outcome loss': 0.33196773923813333, 'Total loss': 0.33196773923813333}
2022-11-28 03:17:03,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:03,538 INFO:     Epoch: 41
2022-11-28 03:17:04,287 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.366973905231465, 'Total loss': 0.366973905231465} | train loss {'Reaction outcome loss': 0.3296687005748672, 'Total loss': 0.3296687005748672}
2022-11-28 03:17:04,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:04,287 INFO:     Epoch: 42
2022-11-28 03:17:05,035 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3640932567756284, 'Total loss': 0.3640932567756284} | train loss {'Reaction outcome loss': 0.3296372077818359, 'Total loss': 0.3296372077818359}
2022-11-28 03:17:05,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:05,035 INFO:     Epoch: 43
2022-11-28 03:17:05,781 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3607925351031802, 'Total loss': 0.3607925351031802} | train loss {'Reaction outcome loss': 0.32850188746928205, 'Total loss': 0.32850188746928205}
2022-11-28 03:17:05,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:05,782 INFO:     Epoch: 44
2022-11-28 03:17:06,531 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.360183245587078, 'Total loss': 0.360183245587078} | train loss {'Reaction outcome loss': 0.3305105656806019, 'Total loss': 0.3305105656806019}
2022-11-28 03:17:06,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:06,532 INFO:     Epoch: 45
2022-11-28 03:17:07,283 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37259521013633773, 'Total loss': 0.37259521013633773} | train loss {'Reaction outcome loss': 0.3214742325606846, 'Total loss': 0.3214742325606846}
2022-11-28 03:17:07,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:07,283 INFO:     Epoch: 46
2022-11-28 03:17:08,034 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3783358062871478, 'Total loss': 0.3783358062871478} | train loss {'Reaction outcome loss': 0.3262536842976847, 'Total loss': 0.3262536842976847}
2022-11-28 03:17:08,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:08,034 INFO:     Epoch: 47
2022-11-28 03:17:08,784 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.372106115587733, 'Total loss': 0.372106115587733} | train loss {'Reaction outcome loss': 0.3267884575912068, 'Total loss': 0.3267884575912068}
2022-11-28 03:17:08,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:08,784 INFO:     Epoch: 48
2022-11-28 03:17:09,532 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37551778656515206, 'Total loss': 0.37551778656515206} | train loss {'Reaction outcome loss': 0.3253194209368479, 'Total loss': 0.3253194209368479}
2022-11-28 03:17:09,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:09,532 INFO:     Epoch: 49
2022-11-28 03:17:10,278 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36583253876729444, 'Total loss': 0.36583253876729444} | train loss {'Reaction outcome loss': 0.33115015345655624, 'Total loss': 0.33115015345655624}
2022-11-28 03:17:10,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:10,279 INFO:     Epoch: 50
2022-11-28 03:17:11,024 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36021356691013684, 'Total loss': 0.36021356691013684} | train loss {'Reaction outcome loss': 0.3218055348242483, 'Total loss': 0.3218055348242483}
2022-11-28 03:17:11,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:11,025 INFO:     Epoch: 51
2022-11-28 03:17:11,771 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40985024551099, 'Total loss': 0.40985024551099} | train loss {'Reaction outcome loss': 0.32351913246055763, 'Total loss': 0.32351913246055763}
2022-11-28 03:17:11,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:11,771 INFO:     Epoch: 52
2022-11-28 03:17:12,520 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42182518101551314, 'Total loss': 0.42182518101551314} | train loss {'Reaction outcome loss': 0.3264287524676371, 'Total loss': 0.3264287524676371}
2022-11-28 03:17:12,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:12,520 INFO:     Epoch: 53
2022-11-28 03:17:13,272 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35425841994583607, 'Total loss': 0.35425841994583607} | train loss {'Reaction outcome loss': 0.3248156936418626, 'Total loss': 0.3248156936418626}
2022-11-28 03:17:13,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:13,273 INFO:     Epoch: 54
2022-11-28 03:17:14,021 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38818458061326633, 'Total loss': 0.38818458061326633} | train loss {'Reaction outcome loss': 0.3351019367936157, 'Total loss': 0.3351019367936157}
2022-11-28 03:17:14,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:14,021 INFO:     Epoch: 55
2022-11-28 03:17:14,769 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36637414077466185, 'Total loss': 0.36637414077466185} | train loss {'Reaction outcome loss': 0.3245011453606909, 'Total loss': 0.3245011453606909}
2022-11-28 03:17:14,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:14,769 INFO:     Epoch: 56
2022-11-28 03:17:15,518 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4127797447144985, 'Total loss': 0.4127797447144985} | train loss {'Reaction outcome loss': 0.3205274929022116, 'Total loss': 0.3205274929022116}
2022-11-28 03:17:15,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:15,519 INFO:     Epoch: 57
2022-11-28 03:17:16,270 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35978973284363747, 'Total loss': 0.35978973284363747} | train loss {'Reaction outcome loss': 0.32350805624117773, 'Total loss': 0.32350805624117773}
2022-11-28 03:17:16,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:16,270 INFO:     Epoch: 58
2022-11-28 03:17:17,021 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38735658218237484, 'Total loss': 0.38735658218237484} | train loss {'Reaction outcome loss': 0.32299983991129744, 'Total loss': 0.32299983991129744}
2022-11-28 03:17:17,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:17,021 INFO:     Epoch: 59
2022-11-28 03:17:17,769 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4253455891527913, 'Total loss': 0.4253455891527913} | train loss {'Reaction outcome loss': 0.3253912734648874, 'Total loss': 0.3253912734648874}
2022-11-28 03:17:17,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:17,769 INFO:     Epoch: 60
2022-11-28 03:17:18,518 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37273802574385295, 'Total loss': 0.37273802574385295} | train loss {'Reaction outcome loss': 0.316098477015452, 'Total loss': 0.316098477015452}
2022-11-28 03:17:18,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:18,518 INFO:     Epoch: 61
2022-11-28 03:17:19,268 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3911315250125798, 'Total loss': 0.3911315250125798} | train loss {'Reaction outcome loss': 0.32972003874038497, 'Total loss': 0.32972003874038497}
2022-11-28 03:17:19,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:19,268 INFO:     Epoch: 62
2022-11-28 03:17:20,015 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.419309886680408, 'Total loss': 0.419309886680408} | train loss {'Reaction outcome loss': 0.3130959794225712, 'Total loss': 0.3130959794225712}
2022-11-28 03:17:20,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:20,015 INFO:     Epoch: 63
2022-11-28 03:17:20,765 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4211284189739011, 'Total loss': 0.4211284189739011} | train loss {'Reaction outcome loss': 0.31457384570591873, 'Total loss': 0.31457384570591873}
2022-11-28 03:17:20,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:20,766 INFO:     Epoch: 64
2022-11-28 03:17:21,512 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3892424919388511, 'Total loss': 0.3892424919388511} | train loss {'Reaction outcome loss': 0.31328472682845687, 'Total loss': 0.31328472682845687}
2022-11-28 03:17:21,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:21,512 INFO:     Epoch: 65
2022-11-28 03:17:22,257 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4132406291636554, 'Total loss': 0.4132406291636554} | train loss {'Reaction outcome loss': 0.3267580110940241, 'Total loss': 0.3267580110940241}
2022-11-28 03:17:22,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:22,257 INFO:     Epoch: 66
2022-11-28 03:17:23,006 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41353549605066126, 'Total loss': 0.41353549605066126} | train loss {'Reaction outcome loss': 0.32511081390323177, 'Total loss': 0.32511081390323177}
2022-11-28 03:17:23,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:23,006 INFO:     Epoch: 67
2022-11-28 03:17:23,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3410839927806096, 'Total loss': 0.3410839927806096} | train loss {'Reaction outcome loss': 0.3153271533008064, 'Total loss': 0.3153271533008064}
2022-11-28 03:17:23,753 INFO:     Found new best model at epoch 67
2022-11-28 03:17:23,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:23,754 INFO:     Epoch: 68
2022-11-28 03:17:24,499 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.386004297232086, 'Total loss': 0.386004297232086} | train loss {'Reaction outcome loss': 0.31914218154645735, 'Total loss': 0.31914218154645735}
2022-11-28 03:17:24,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:24,500 INFO:     Epoch: 69
2022-11-28 03:17:25,247 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41485573080453003, 'Total loss': 0.41485573080453003} | train loss {'Reaction outcome loss': 0.32294581797454625, 'Total loss': 0.32294581797454625}
2022-11-28 03:17:25,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:25,247 INFO:     Epoch: 70
2022-11-28 03:17:25,996 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38161981681531126, 'Total loss': 0.38161981681531126} | train loss {'Reaction outcome loss': 0.32267584180038783, 'Total loss': 0.32267584180038783}
2022-11-28 03:17:25,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:25,996 INFO:     Epoch: 71
2022-11-28 03:17:26,746 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36242955415086314, 'Total loss': 0.36242955415086314} | train loss {'Reaction outcome loss': 0.3221413361269139, 'Total loss': 0.3221413361269139}
2022-11-28 03:17:26,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:26,746 INFO:     Epoch: 72
2022-11-28 03:17:27,498 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4025632783093236, 'Total loss': 0.4025632783093236} | train loss {'Reaction outcome loss': 0.32518089604714223, 'Total loss': 0.32518089604714223}
2022-11-28 03:17:27,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:27,498 INFO:     Epoch: 73
2022-11-28 03:17:28,247 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3742817084050991, 'Total loss': 0.3742817084050991} | train loss {'Reaction outcome loss': 0.3231705483349581, 'Total loss': 0.3231705483349581}
2022-11-28 03:17:28,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:28,247 INFO:     Epoch: 74
2022-11-28 03:17:28,995 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37631646916270256, 'Total loss': 0.37631646916270256} | train loss {'Reaction outcome loss': 0.32267058123984643, 'Total loss': 0.32267058123984643}
2022-11-28 03:17:28,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:28,995 INFO:     Epoch: 75
2022-11-28 03:17:29,741 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3763190992176533, 'Total loss': 0.3763190992176533} | train loss {'Reaction outcome loss': 0.32295712897734297, 'Total loss': 0.32295712897734297}
2022-11-28 03:17:29,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:29,741 INFO:     Epoch: 76
2022-11-28 03:17:30,491 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37532463974573393, 'Total loss': 0.37532463974573393} | train loss {'Reaction outcome loss': 0.3208217990975226, 'Total loss': 0.3208217990975226}
2022-11-28 03:17:30,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:30,491 INFO:     Epoch: 77
2022-11-28 03:17:31,235 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3856869676912373, 'Total loss': 0.3856869676912373} | train loss {'Reaction outcome loss': 0.3231271672393045, 'Total loss': 0.3231271672393045}
2022-11-28 03:17:31,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:31,236 INFO:     Epoch: 78
2022-11-28 03:17:31,981 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3788037305189805, 'Total loss': 0.3788037305189805} | train loss {'Reaction outcome loss': 0.32508783408951375, 'Total loss': 0.32508783408951375}
2022-11-28 03:17:31,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:31,981 INFO:     Epoch: 79
2022-11-28 03:17:32,729 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3730687080797824, 'Total loss': 0.3730687080797824} | train loss {'Reaction outcome loss': 0.31571876365811596, 'Total loss': 0.31571876365811596}
2022-11-28 03:17:32,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:32,729 INFO:     Epoch: 80
2022-11-28 03:17:33,479 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35767473551360046, 'Total loss': 0.35767473551360046} | train loss {'Reaction outcome loss': 0.32253120689382475, 'Total loss': 0.32253120689382475}
2022-11-28 03:17:33,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:33,480 INFO:     Epoch: 81
2022-11-28 03:17:34,228 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3914174280044707, 'Total loss': 0.3914174280044707} | train loss {'Reaction outcome loss': 0.31875400137036075, 'Total loss': 0.31875400137036075}
2022-11-28 03:17:34,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:34,228 INFO:     Epoch: 82
2022-11-28 03:17:34,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3953176476061344, 'Total loss': 0.3953176476061344} | train loss {'Reaction outcome loss': 0.3175943321097762, 'Total loss': 0.3175943321097762}
2022-11-28 03:17:34,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:34,979 INFO:     Epoch: 83
2022-11-28 03:17:35,727 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36133291640064935, 'Total loss': 0.36133291640064935} | train loss {'Reaction outcome loss': 0.3227827727734562, 'Total loss': 0.3227827727734562}
2022-11-28 03:17:35,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:35,727 INFO:     Epoch: 84
2022-11-28 03:17:36,476 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3564369485459544, 'Total loss': 0.3564369485459544} | train loss {'Reaction outcome loss': 0.32494935898050187, 'Total loss': 0.32494935898050187}
2022-11-28 03:17:36,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:36,476 INFO:     Epoch: 85
2022-11-28 03:17:37,226 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4242603426629847, 'Total loss': 0.4242603426629847} | train loss {'Reaction outcome loss': 0.31372608683041986, 'Total loss': 0.31372608683041986}
2022-11-28 03:17:37,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:37,226 INFO:     Epoch: 86
2022-11-28 03:17:37,975 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34758818318898027, 'Total loss': 0.34758818318898027} | train loss {'Reaction outcome loss': 0.3316846899237604, 'Total loss': 0.3316846899237604}
2022-11-28 03:17:37,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:37,975 INFO:     Epoch: 87
2022-11-28 03:17:38,722 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4042049785229293, 'Total loss': 0.4042049785229293} | train loss {'Reaction outcome loss': 0.31784648201878996, 'Total loss': 0.31784648201878996}
2022-11-28 03:17:38,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:38,723 INFO:     Epoch: 88
2022-11-28 03:17:39,468 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36054408753460104, 'Total loss': 0.36054408753460104} | train loss {'Reaction outcome loss': 0.32322731511967795, 'Total loss': 0.32322731511967795}
2022-11-28 03:17:39,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:39,468 INFO:     Epoch: 89
2022-11-28 03:17:40,217 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37585500068962574, 'Total loss': 0.37585500068962574} | train loss {'Reaction outcome loss': 0.3151137583979195, 'Total loss': 0.3151137583979195}
2022-11-28 03:17:40,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:40,218 INFO:     Epoch: 90
2022-11-28 03:17:40,967 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3792695944959467, 'Total loss': 0.3792695944959467} | train loss {'Reaction outcome loss': 0.3166771122524815, 'Total loss': 0.3166771122524815}
2022-11-28 03:17:40,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:40,967 INFO:     Epoch: 91
2022-11-28 03:17:41,718 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38329019702293654, 'Total loss': 0.38329019702293654} | train loss {'Reaction outcome loss': 0.3143155848787677, 'Total loss': 0.3143155848787677}
2022-11-28 03:17:41,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:41,718 INFO:     Epoch: 92
2022-11-28 03:17:42,466 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4025183411484415, 'Total loss': 0.4025183411484415} | train loss {'Reaction outcome loss': 0.3163162942134565, 'Total loss': 0.3163162942134565}
2022-11-28 03:17:42,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:42,467 INFO:     Epoch: 93
2022-11-28 03:17:43,217 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3784003762358969, 'Total loss': 0.3784003762358969} | train loss {'Reaction outcome loss': 0.32322530003805316, 'Total loss': 0.32322530003805316}
2022-11-28 03:17:43,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:43,217 INFO:     Epoch: 94
2022-11-28 03:17:43,966 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41649167375131085, 'Total loss': 0.41649167375131085} | train loss {'Reaction outcome loss': 0.3184756841810961, 'Total loss': 0.3184756841810961}
2022-11-28 03:17:43,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:43,966 INFO:     Epoch: 95
2022-11-28 03:17:44,715 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38056962564587593, 'Total loss': 0.38056962564587593} | train loss {'Reaction outcome loss': 0.3115533156500709, 'Total loss': 0.3115533156500709}
2022-11-28 03:17:44,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:44,715 INFO:     Epoch: 96
2022-11-28 03:17:45,463 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38567642122507095, 'Total loss': 0.38567642122507095} | train loss {'Reaction outcome loss': 0.31525715019914413, 'Total loss': 0.31525715019914413}
2022-11-28 03:17:45,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:45,464 INFO:     Epoch: 97
2022-11-28 03:17:46,214 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4064246023243124, 'Total loss': 0.4064246023243124} | train loss {'Reaction outcome loss': 0.3124802160647608, 'Total loss': 0.3124802160647608}
2022-11-28 03:17:46,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:46,214 INFO:     Epoch: 98
2022-11-28 03:17:46,963 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3949770697138526, 'Total loss': 0.3949770697138526} | train loss {'Reaction outcome loss': 0.31015600133386834, 'Total loss': 0.31015600133386834}
2022-11-28 03:17:46,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:46,964 INFO:     Epoch: 99
2022-11-28 03:17:47,713 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3692409787327051, 'Total loss': 0.3692409787327051} | train loss {'Reaction outcome loss': 0.32445265581050226, 'Total loss': 0.32445265581050226}
2022-11-28 03:17:47,713 INFO:     Best model found after epoch 68 of 100.
2022-11-28 03:17:47,713 INFO:   Done with stage: TRAINING
2022-11-28 03:17:47,714 INFO:   Starting stage: EVALUATION
2022-11-28 03:17:47,830 INFO:   Done with stage: EVALUATION
2022-11-28 03:17:47,830 INFO:   Leaving out SEQ value Fold_6
2022-11-28 03:17:47,843 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:17:47,843 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:17:48,482 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:17:48,482 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:17:48,551 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:17:48,551 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:17:48,551 INFO:     No hyperparam tuning for this model
2022-11-28 03:17:48,551 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:17:48,552 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:17:48,552 INFO:     None feature selector for col prot
2022-11-28 03:17:48,552 INFO:     None feature selector for col prot
2022-11-28 03:17:48,552 INFO:     None feature selector for col prot
2022-11-28 03:17:48,553 INFO:     None feature selector for col chem
2022-11-28 03:17:48,553 INFO:     None feature selector for col chem
2022-11-28 03:17:48,553 INFO:     None feature selector for col chem
2022-11-28 03:17:48,553 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:17:48,553 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:17:48,555 INFO:     Number of params in model 169741
2022-11-28 03:17:48,558 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:17:48,558 INFO:   Starting stage: TRAINING
2022-11-28 03:17:48,611 INFO:     Val loss before train {'Reaction outcome loss': 0.9144510572606867, 'Total loss': 0.9144510572606867}
2022-11-28 03:17:48,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:48,611 INFO:     Epoch: 0
2022-11-28 03:17:49,362 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.4826049174774777, 'Total loss': 0.4826049174774777} | train loss {'Reaction outcome loss': 0.6348766723587629, 'Total loss': 0.6348766723587629}
2022-11-28 03:17:49,362 INFO:     Found new best model at epoch 0
2022-11-28 03:17:49,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:49,363 INFO:     Epoch: 1
2022-11-28 03:17:50,112 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4268179014325142, 'Total loss': 0.4268179014325142} | train loss {'Reaction outcome loss': 0.49855600009041445, 'Total loss': 0.49855600009041445}
2022-11-28 03:17:50,112 INFO:     Found new best model at epoch 1
2022-11-28 03:17:50,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:50,113 INFO:     Epoch: 2
2022-11-28 03:17:50,860 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4741113483905792, 'Total loss': 0.4741113483905792} | train loss {'Reaction outcome loss': 0.4617756180945904, 'Total loss': 0.4617756180945904}
2022-11-28 03:17:50,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:50,861 INFO:     Epoch: 3
2022-11-28 03:17:51,607 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4374151626093821, 'Total loss': 0.4374151626093821} | train loss {'Reaction outcome loss': 0.43787659638591353, 'Total loss': 0.43787659638591353}
2022-11-28 03:17:51,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:51,607 INFO:     Epoch: 4
2022-11-28 03:17:52,358 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4202430441298268, 'Total loss': 0.4202430441298268} | train loss {'Reaction outcome loss': 0.42449962894522375, 'Total loss': 0.42449962894522375}
2022-11-28 03:17:52,358 INFO:     Found new best model at epoch 4
2022-11-28 03:17:52,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:52,359 INFO:     Epoch: 5
2022-11-28 03:17:53,109 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4295358888127587, 'Total loss': 0.4295358888127587} | train loss {'Reaction outcome loss': 0.40673613337980163, 'Total loss': 0.40673613337980163}
2022-11-28 03:17:53,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:53,110 INFO:     Epoch: 6
2022-11-28 03:17:53,859 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.397514891048724, 'Total loss': 0.397514891048724} | train loss {'Reaction outcome loss': 0.40693398922561635, 'Total loss': 0.40693398922561635}
2022-11-28 03:17:53,859 INFO:     Found new best model at epoch 6
2022-11-28 03:17:53,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:53,860 INFO:     Epoch: 7
2022-11-28 03:17:54,609 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40485664761879225, 'Total loss': 0.40485664761879225} | train loss {'Reaction outcome loss': 0.38573239229980016, 'Total loss': 0.38573239229980016}
2022-11-28 03:17:54,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:54,610 INFO:     Epoch: 8
2022-11-28 03:17:55,360 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4280311685394157, 'Total loss': 0.4280311685394157} | train loss {'Reaction outcome loss': 0.3900831171701993, 'Total loss': 0.3900831171701993}
2022-11-28 03:17:55,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:55,360 INFO:     Epoch: 9
2022-11-28 03:17:56,121 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4693815511736003, 'Total loss': 0.4693815511736003} | train loss {'Reaction outcome loss': 0.37849658822280263, 'Total loss': 0.37849658822280263}
2022-11-28 03:17:56,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:56,122 INFO:     Epoch: 10
2022-11-28 03:17:56,884 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3904254978353327, 'Total loss': 0.3904254978353327} | train loss {'Reaction outcome loss': 0.37272223430655654, 'Total loss': 0.37272223430655654}
2022-11-28 03:17:56,884 INFO:     Found new best model at epoch 10
2022-11-28 03:17:56,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:56,885 INFO:     Epoch: 11
2022-11-28 03:17:57,651 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4267656488174742, 'Total loss': 0.4267656488174742} | train loss {'Reaction outcome loss': 0.3666715903448001, 'Total loss': 0.3666715903448001}
2022-11-28 03:17:57,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:57,651 INFO:     Epoch: 12
2022-11-28 03:17:58,415 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40192831781777466, 'Total loss': 0.40192831781777466} | train loss {'Reaction outcome loss': 0.36865671742106637, 'Total loss': 0.36865671742106637}
2022-11-28 03:17:58,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:58,416 INFO:     Epoch: 13
2022-11-28 03:17:59,182 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.406937316398729, 'Total loss': 0.406937316398729} | train loss {'Reaction outcome loss': 0.35699922074714013, 'Total loss': 0.35699922074714013}
2022-11-28 03:17:59,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:59,182 INFO:     Epoch: 14
2022-11-28 03:17:59,946 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41210460832173174, 'Total loss': 0.41210460832173174} | train loss {'Reaction outcome loss': 0.3593910670568866, 'Total loss': 0.3593910670568866}
2022-11-28 03:17:59,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:17:59,947 INFO:     Epoch: 15
2022-11-28 03:18:00,713 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41304532573981717, 'Total loss': 0.41304532573981717} | train loss {'Reaction outcome loss': 0.35843925851006664, 'Total loss': 0.35843925851006664}
2022-11-28 03:18:00,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:00,713 INFO:     Epoch: 16
2022-11-28 03:18:01,477 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3835728239606727, 'Total loss': 0.3835728239606727} | train loss {'Reaction outcome loss': 0.345891363543248, 'Total loss': 0.345891363543248}
2022-11-28 03:18:01,477 INFO:     Found new best model at epoch 16
2022-11-28 03:18:01,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:01,478 INFO:     Epoch: 17
2022-11-28 03:18:02,240 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40582750229672954, 'Total loss': 0.40582750229672954} | train loss {'Reaction outcome loss': 0.34285161103452405, 'Total loss': 0.34285161103452405}
2022-11-28 03:18:02,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:02,240 INFO:     Epoch: 18
2022-11-28 03:18:03,004 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4262508109889247, 'Total loss': 0.4262508109889247} | train loss {'Reaction outcome loss': 0.34040786983865884, 'Total loss': 0.34040786983865884}
2022-11-28 03:18:03,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:03,005 INFO:     Epoch: 19
2022-11-28 03:18:03,769 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40522005696865643, 'Total loss': 0.40522005696865643} | train loss {'Reaction outcome loss': 0.3410804558004583, 'Total loss': 0.3410804558004583}
2022-11-28 03:18:03,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:03,769 INFO:     Epoch: 20
2022-11-28 03:18:04,532 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4192564629695632, 'Total loss': 0.4192564629695632} | train loss {'Reaction outcome loss': 0.3406097587017763, 'Total loss': 0.3406097587017763}
2022-11-28 03:18:04,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:04,532 INFO:     Epoch: 21
2022-11-28 03:18:05,289 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4162896979938854, 'Total loss': 0.4162896979938854} | train loss {'Reaction outcome loss': 0.3402223903986235, 'Total loss': 0.3402223903986235}
2022-11-28 03:18:05,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:05,290 INFO:     Epoch: 22
2022-11-28 03:18:06,038 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41359864276918495, 'Total loss': 0.41359864276918495} | train loss {'Reaction outcome loss': 0.338872276261569, 'Total loss': 0.338872276261569}
2022-11-28 03:18:06,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:06,038 INFO:     Epoch: 23
2022-11-28 03:18:06,787 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41066043790091167, 'Total loss': 0.41066043790091167} | train loss {'Reaction outcome loss': 0.3358517887761756, 'Total loss': 0.3358517887761756}
2022-11-28 03:18:06,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:06,787 INFO:     Epoch: 24
2022-11-28 03:18:07,539 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4243626113642346, 'Total loss': 0.4243626113642346} | train loss {'Reaction outcome loss': 0.33503274075807105, 'Total loss': 0.33503274075807105}
2022-11-28 03:18:07,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:07,540 INFO:     Epoch: 25
2022-11-28 03:18:08,288 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4120031615549868, 'Total loss': 0.4120031615549868} | train loss {'Reaction outcome loss': 0.3385291851065572, 'Total loss': 0.3385291851065572}
2022-11-28 03:18:08,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:08,288 INFO:     Epoch: 26
2022-11-28 03:18:09,037 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.396712217818607, 'Total loss': 0.396712217818607} | train loss {'Reaction outcome loss': 0.3194334119137737, 'Total loss': 0.3194334119137737}
2022-11-28 03:18:09,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:09,037 INFO:     Epoch: 27
2022-11-28 03:18:09,784 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39355615797367965, 'Total loss': 0.39355615797367965} | train loss {'Reaction outcome loss': 0.3234183675339145, 'Total loss': 0.3234183675339145}
2022-11-28 03:18:09,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:09,785 INFO:     Epoch: 28
2022-11-28 03:18:10,534 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43066360157999123, 'Total loss': 0.43066360157999123} | train loss {'Reaction outcome loss': 0.322443085121772, 'Total loss': 0.322443085121772}
2022-11-28 03:18:10,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:10,535 INFO:     Epoch: 29
2022-11-28 03:18:11,285 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3887318012050607, 'Total loss': 0.3887318012050607} | train loss {'Reaction outcome loss': 0.32440235784217236, 'Total loss': 0.32440235784217236}
2022-11-28 03:18:11,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:11,285 INFO:     Epoch: 30
2022-11-28 03:18:12,036 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5286333916539495, 'Total loss': 0.5286333916539495} | train loss {'Reaction outcome loss': 0.32998340928386294, 'Total loss': 0.32998340928386294}
2022-11-28 03:18:12,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:12,036 INFO:     Epoch: 31
2022-11-28 03:18:12,785 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4421530272811651, 'Total loss': 0.4421530272811651} | train loss {'Reaction outcome loss': 0.32849353759159006, 'Total loss': 0.32849353759159006}
2022-11-28 03:18:12,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:12,785 INFO:     Epoch: 32
2022-11-28 03:18:13,533 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3993088166144761, 'Total loss': 0.3993088166144761} | train loss {'Reaction outcome loss': 0.3243585975179749, 'Total loss': 0.3243585975179749}
2022-11-28 03:18:13,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:13,533 INFO:     Epoch: 33
2022-11-28 03:18:14,286 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41201675005934457, 'Total loss': 0.41201675005934457} | train loss {'Reaction outcome loss': 0.3255332739002282, 'Total loss': 0.3255332739002282}
2022-11-28 03:18:14,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:14,287 INFO:     Epoch: 34
2022-11-28 03:18:15,033 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42741309478878975, 'Total loss': 0.42741309478878975} | train loss {'Reaction outcome loss': 0.3248850666286965, 'Total loss': 0.3248850666286965}
2022-11-28 03:18:15,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:15,033 INFO:     Epoch: 35
2022-11-28 03:18:15,779 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.422887913713401, 'Total loss': 0.422887913713401} | train loss {'Reaction outcome loss': 0.31769155948272637, 'Total loss': 0.31769155948272637}
2022-11-28 03:18:15,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:15,779 INFO:     Epoch: 36
2022-11-28 03:18:16,529 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4239576941525394, 'Total loss': 0.4239576941525394} | train loss {'Reaction outcome loss': 0.3140759594858654, 'Total loss': 0.3140759594858654}
2022-11-28 03:18:16,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:16,529 INFO:     Epoch: 37
2022-11-28 03:18:17,279 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41564784808592364, 'Total loss': 0.41564784808592364} | train loss {'Reaction outcome loss': 0.3253294957741614, 'Total loss': 0.3253294957741614}
2022-11-28 03:18:17,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:17,279 INFO:     Epoch: 38
2022-11-28 03:18:18,029 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3861554434353655, 'Total loss': 0.3861554434353655} | train loss {'Reaction outcome loss': 0.31617218856849977, 'Total loss': 0.31617218856849977}
2022-11-28 03:18:18,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:18,030 INFO:     Epoch: 39
2022-11-28 03:18:18,780 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3912835332819007, 'Total loss': 0.3912835332819007} | train loss {'Reaction outcome loss': 0.3187079607178607, 'Total loss': 0.3187079607178607}
2022-11-28 03:18:18,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:18,780 INFO:     Epoch: 40
2022-11-28 03:18:19,532 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3984054909511046, 'Total loss': 0.3984054909511046} | train loss {'Reaction outcome loss': 0.3269538691627883, 'Total loss': 0.3269538691627883}
2022-11-28 03:18:19,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:19,533 INFO:     Epoch: 41
2022-11-28 03:18:20,284 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40399129214611923, 'Total loss': 0.40399129214611923} | train loss {'Reaction outcome loss': 0.32418407409662203, 'Total loss': 0.32418407409662203}
2022-11-28 03:18:20,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:20,284 INFO:     Epoch: 42
2022-11-28 03:18:21,035 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4542132517830892, 'Total loss': 0.4542132517830892} | train loss {'Reaction outcome loss': 0.3128592317563392, 'Total loss': 0.3128592317563392}
2022-11-28 03:18:21,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:21,036 INFO:     Epoch: 43
2022-11-28 03:18:21,785 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41789665377952834, 'Total loss': 0.41789665377952834} | train loss {'Reaction outcome loss': 0.30971776648995375, 'Total loss': 0.30971776648995375}
2022-11-28 03:18:21,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:21,785 INFO:     Epoch: 44
2022-11-28 03:18:22,537 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3948303395035592, 'Total loss': 0.3948303395035592} | train loss {'Reaction outcome loss': 0.31988788677018976, 'Total loss': 0.31988788677018976}
2022-11-28 03:18:22,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:22,537 INFO:     Epoch: 45
2022-11-28 03:18:23,286 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39654531397602777, 'Total loss': 0.39654531397602777} | train loss {'Reaction outcome loss': 0.31678839206635473, 'Total loss': 0.31678839206635473}
2022-11-28 03:18:23,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:23,286 INFO:     Epoch: 46
2022-11-28 03:18:24,034 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4153980812565847, 'Total loss': 0.4153980812565847} | train loss {'Reaction outcome loss': 0.31405497850069114, 'Total loss': 0.31405497850069114}
2022-11-28 03:18:24,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:24,035 INFO:     Epoch: 47
2022-11-28 03:18:24,784 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41459667073054746, 'Total loss': 0.41459667073054746} | train loss {'Reaction outcome loss': 0.31865991787203857, 'Total loss': 0.31865991787203857}
2022-11-28 03:18:24,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:24,784 INFO:     Epoch: 48
2022-11-28 03:18:25,531 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40580661256204953, 'Total loss': 0.40580661256204953} | train loss {'Reaction outcome loss': 0.313554726390829, 'Total loss': 0.313554726390829}
2022-11-28 03:18:25,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:25,531 INFO:     Epoch: 49
2022-11-28 03:18:26,281 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39907478575002064, 'Total loss': 0.39907478575002064} | train loss {'Reaction outcome loss': 0.3112065351357864, 'Total loss': 0.3112065351357864}
2022-11-28 03:18:26,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:26,282 INFO:     Epoch: 50
2022-11-28 03:18:27,029 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42756761475042865, 'Total loss': 0.42756761475042865} | train loss {'Reaction outcome loss': 0.3130312456238654, 'Total loss': 0.3130312456238654}
2022-11-28 03:18:27,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:27,029 INFO:     Epoch: 51
2022-11-28 03:18:27,781 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4165188946168531, 'Total loss': 0.4165188946168531} | train loss {'Reaction outcome loss': 0.31689382680962164, 'Total loss': 0.31689382680962164}
2022-11-28 03:18:27,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:27,781 INFO:     Epoch: 52
2022-11-28 03:18:28,532 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4372743412174962, 'Total loss': 0.4372743412174962} | train loss {'Reaction outcome loss': 0.3217820776326041, 'Total loss': 0.3217820776326041}
2022-11-28 03:18:28,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:28,533 INFO:     Epoch: 53
2022-11-28 03:18:29,282 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38047452304850926, 'Total loss': 0.38047452304850926} | train loss {'Reaction outcome loss': 0.31411469859942315, 'Total loss': 0.31411469859942315}
2022-11-28 03:18:29,282 INFO:     Found new best model at epoch 53
2022-11-28 03:18:29,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:29,283 INFO:     Epoch: 54
2022-11-28 03:18:30,029 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39626779474995355, 'Total loss': 0.39626779474995355} | train loss {'Reaction outcome loss': 0.3149794976737711, 'Total loss': 0.3149794976737711}
2022-11-28 03:18:30,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:30,029 INFO:     Epoch: 55
2022-11-28 03:18:30,777 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4390487777577205, 'Total loss': 0.4390487777577205} | train loss {'Reaction outcome loss': 0.31123842718079686, 'Total loss': 0.31123842718079686}
2022-11-28 03:18:30,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:30,777 INFO:     Epoch: 56
2022-11-28 03:18:31,523 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.393425046720288, 'Total loss': 0.393425046720288} | train loss {'Reaction outcome loss': 0.31419320738003137, 'Total loss': 0.31419320738003137}
2022-11-28 03:18:31,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:31,524 INFO:     Epoch: 57
2022-11-28 03:18:32,271 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3991645183414221, 'Total loss': 0.3991645183414221} | train loss {'Reaction outcome loss': 0.30814531899147457, 'Total loss': 0.30814531899147457}
2022-11-28 03:18:32,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:32,271 INFO:     Epoch: 58
2022-11-28 03:18:33,019 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39888280765576795, 'Total loss': 0.39888280765576795} | train loss {'Reaction outcome loss': 0.3146975095113439, 'Total loss': 0.3146975095113439}
2022-11-28 03:18:33,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:33,020 INFO:     Epoch: 59
2022-11-28 03:18:33,769 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4328808198598298, 'Total loss': 0.4328808198598298} | train loss {'Reaction outcome loss': 0.3199067284923888, 'Total loss': 0.3199067284923888}
2022-11-28 03:18:33,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:33,769 INFO:     Epoch: 60
2022-11-28 03:18:34,519 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40170117061246524, 'Total loss': 0.40170117061246524} | train loss {'Reaction outcome loss': 0.3231505765729854, 'Total loss': 0.3231505765729854}
2022-11-28 03:18:34,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:34,519 INFO:     Epoch: 61
2022-11-28 03:18:35,267 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3960760628635233, 'Total loss': 0.3960760628635233} | train loss {'Reaction outcome loss': 0.3076589849567221, 'Total loss': 0.3076589849567221}
2022-11-28 03:18:35,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:35,268 INFO:     Epoch: 62
2022-11-28 03:18:36,018 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43281309780749405, 'Total loss': 0.43281309780749405} | train loss {'Reaction outcome loss': 0.31048605350717423, 'Total loss': 0.31048605350717423}
2022-11-28 03:18:36,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:36,018 INFO:     Epoch: 63
2022-11-28 03:18:36,766 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4055302476679737, 'Total loss': 0.4055302476679737} | train loss {'Reaction outcome loss': 0.30711112407997493, 'Total loss': 0.30711112407997493}
2022-11-28 03:18:36,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:36,767 INFO:     Epoch: 64
2022-11-28 03:18:37,516 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3878414874727076, 'Total loss': 0.3878414874727076} | train loss {'Reaction outcome loss': 0.3082731102683371, 'Total loss': 0.3082731102683371}
2022-11-28 03:18:37,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:37,516 INFO:     Epoch: 65
2022-11-28 03:18:38,265 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41142379255457356, 'Total loss': 0.41142379255457356} | train loss {'Reaction outcome loss': 0.31919947941036475, 'Total loss': 0.31919947941036475}
2022-11-28 03:18:38,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:38,265 INFO:     Epoch: 66
2022-11-28 03:18:39,012 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40955115312879736, 'Total loss': 0.40955115312879736} | train loss {'Reaction outcome loss': 0.3120999712076399, 'Total loss': 0.3120999712076399}
2022-11-28 03:18:39,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:39,013 INFO:     Epoch: 67
2022-11-28 03:18:39,759 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4334580989723856, 'Total loss': 0.4334580989723856} | train loss {'Reaction outcome loss': 0.3133181068866003, 'Total loss': 0.3133181068866003}
2022-11-28 03:18:39,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:39,760 INFO:     Epoch: 68
2022-11-28 03:18:40,508 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3943075212565335, 'Total loss': 0.3943075212565335} | train loss {'Reaction outcome loss': 0.30903478104981685, 'Total loss': 0.30903478104981685}
2022-11-28 03:18:40,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:40,509 INFO:     Epoch: 69
2022-11-28 03:18:41,254 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4025988277386535, 'Total loss': 0.4025988277386535} | train loss {'Reaction outcome loss': 0.3088792400554784, 'Total loss': 0.3088792400554784}
2022-11-28 03:18:41,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:41,254 INFO:     Epoch: 70
2022-11-28 03:18:42,001 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4099522029811686, 'Total loss': 0.4099522029811686} | train loss {'Reaction outcome loss': 0.30772025793069796, 'Total loss': 0.30772025793069796}
2022-11-28 03:18:42,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:42,002 INFO:     Epoch: 71
2022-11-28 03:18:42,750 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38964873128993943, 'Total loss': 0.38964873128993943} | train loss {'Reaction outcome loss': 0.3189844796584258, 'Total loss': 0.3189844796584258}
2022-11-28 03:18:42,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:42,750 INFO:     Epoch: 72
2022-11-28 03:18:43,497 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39654898338697175, 'Total loss': 0.39654898338697175} | train loss {'Reaction outcome loss': 0.3068464325680848, 'Total loss': 0.3068464325680848}
2022-11-28 03:18:43,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:43,497 INFO:     Epoch: 73
2022-11-28 03:18:44,245 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4099296836013144, 'Total loss': 0.4099296836013144} | train loss {'Reaction outcome loss': 0.30665930901323596, 'Total loss': 0.30665930901323596}
2022-11-28 03:18:44,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:44,245 INFO:     Epoch: 74
2022-11-28 03:18:44,995 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41377867690541525, 'Total loss': 0.41377867690541525} | train loss {'Reaction outcome loss': 0.31103860803188815, 'Total loss': 0.31103860803188815}
2022-11-28 03:18:44,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:44,995 INFO:     Epoch: 75
2022-11-28 03:18:45,745 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4263366807929494, 'Total loss': 0.4263366807929494} | train loss {'Reaction outcome loss': 0.31638118768140916, 'Total loss': 0.31638118768140916}
2022-11-28 03:18:45,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:45,746 INFO:     Epoch: 76
2022-11-28 03:18:46,497 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3863969048993154, 'Total loss': 0.3863969048993154} | train loss {'Reaction outcome loss': 0.301313161008781, 'Total loss': 0.301313161008781}
2022-11-28 03:18:46,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:46,497 INFO:     Epoch: 77
2022-11-28 03:18:47,249 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4349799819967963, 'Total loss': 0.4349799819967963} | train loss {'Reaction outcome loss': 0.31330404304448634, 'Total loss': 0.31330404304448634}
2022-11-28 03:18:47,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:47,249 INFO:     Epoch: 78
2022-11-28 03:18:48,000 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3911096182736484, 'Total loss': 0.3911096182736484} | train loss {'Reaction outcome loss': 0.3075084500615635, 'Total loss': 0.3075084500615635}
2022-11-28 03:18:48,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:48,000 INFO:     Epoch: 79
2022-11-28 03:18:48,749 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37422795983200724, 'Total loss': 0.37422795983200724} | train loss {'Reaction outcome loss': 0.2999788746237755, 'Total loss': 0.2999788746237755}
2022-11-28 03:18:48,749 INFO:     Found new best model at epoch 79
2022-11-28 03:18:48,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:48,750 INFO:     Epoch: 80
2022-11-28 03:18:49,497 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39833912473510613, 'Total loss': 0.39833912473510613} | train loss {'Reaction outcome loss': 0.3031923856225706, 'Total loss': 0.3031923856225706}
2022-11-28 03:18:49,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:49,499 INFO:     Epoch: 81
2022-11-28 03:18:50,246 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41691617227413436, 'Total loss': 0.41691617227413436} | train loss {'Reaction outcome loss': 0.31285052051046686, 'Total loss': 0.31285052051046686}
2022-11-28 03:18:50,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:50,246 INFO:     Epoch: 82
2022-11-28 03:18:50,999 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4302872913804921, 'Total loss': 0.4302872913804921} | train loss {'Reaction outcome loss': 0.31093023624271154, 'Total loss': 0.31093023624271154}
2022-11-28 03:18:50,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:50,999 INFO:     Epoch: 83
2022-11-28 03:18:51,752 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43542083860798314, 'Total loss': 0.43542083860798314} | train loss {'Reaction outcome loss': 0.3135627649063545, 'Total loss': 0.3135627649063545}
2022-11-28 03:18:51,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:51,752 INFO:     Epoch: 84
2022-11-28 03:18:52,505 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.411182141778144, 'Total loss': 0.411182141778144} | train loss {'Reaction outcome loss': 0.32186852620854495, 'Total loss': 0.32186852620854495}
2022-11-28 03:18:52,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:52,505 INFO:     Epoch: 85
2022-11-28 03:18:53,257 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4006099409677766, 'Total loss': 0.4006099409677766} | train loss {'Reaction outcome loss': 0.31046472697128213, 'Total loss': 0.31046472697128213}
2022-11-28 03:18:53,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:53,257 INFO:     Epoch: 86
2022-11-28 03:18:54,007 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37225878424942493, 'Total loss': 0.37225878424942493} | train loss {'Reaction outcome loss': 0.3082032819849349, 'Total loss': 0.3082032819849349}
2022-11-28 03:18:54,007 INFO:     Found new best model at epoch 86
2022-11-28 03:18:54,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:54,008 INFO:     Epoch: 87
2022-11-28 03:18:54,758 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4336468387733806, 'Total loss': 0.4336468387733806} | train loss {'Reaction outcome loss': 0.3001072710199702, 'Total loss': 0.3001072710199702}
2022-11-28 03:18:54,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:54,758 INFO:     Epoch: 88
2022-11-28 03:18:55,505 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40386463871056383, 'Total loss': 0.40386463871056383} | train loss {'Reaction outcome loss': 0.3064540236016675, 'Total loss': 0.3064540236016675}
2022-11-28 03:18:55,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:55,506 INFO:     Epoch: 89
2022-11-28 03:18:56,257 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4120468180626631, 'Total loss': 0.4120468180626631} | train loss {'Reaction outcome loss': 0.3036626599308464, 'Total loss': 0.3036626599308464}
2022-11-28 03:18:56,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:56,257 INFO:     Epoch: 90
2022-11-28 03:18:57,005 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4239010919224132, 'Total loss': 0.4239010919224132} | train loss {'Reaction outcome loss': 0.30538803758099675, 'Total loss': 0.30538803758099675}
2022-11-28 03:18:57,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:57,005 INFO:     Epoch: 91
2022-11-28 03:18:57,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40950335596095433, 'Total loss': 0.40950335596095433} | train loss {'Reaction outcome loss': 0.3013310006429111, 'Total loss': 0.3013310006429111}
2022-11-28 03:18:57,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:57,757 INFO:     Epoch: 92
2022-11-28 03:18:58,505 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43339085578918457, 'Total loss': 0.43339085578918457} | train loss {'Reaction outcome loss': 0.309550808998005, 'Total loss': 0.309550808998005}
2022-11-28 03:18:58,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:58,505 INFO:     Epoch: 93
2022-11-28 03:18:59,258 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.418709493834864, 'Total loss': 0.418709493834864} | train loss {'Reaction outcome loss': 0.2976511340858715, 'Total loss': 0.2976511340858715}
2022-11-28 03:18:59,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:18:59,259 INFO:     Epoch: 94
2022-11-28 03:19:00,007 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41799286380410194, 'Total loss': 0.41799286380410194} | train loss {'Reaction outcome loss': 0.29792118760486763, 'Total loss': 0.29792118760486763}
2022-11-28 03:19:00,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:00,007 INFO:     Epoch: 95
2022-11-28 03:19:00,755 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40624643760648643, 'Total loss': 0.40624643760648643} | train loss {'Reaction outcome loss': 0.304328813157495, 'Total loss': 0.304328813157495}
2022-11-28 03:19:00,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:00,756 INFO:     Epoch: 96
2022-11-28 03:19:01,502 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4176240529526364, 'Total loss': 0.4176240529526364} | train loss {'Reaction outcome loss': 0.3004203918840616, 'Total loss': 0.3004203918840616}
2022-11-28 03:19:01,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:01,503 INFO:     Epoch: 97
2022-11-28 03:19:02,253 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41678657044063916, 'Total loss': 0.41678657044063916} | train loss {'Reaction outcome loss': 0.29999790918983277, 'Total loss': 0.29999790918983277}
2022-11-28 03:19:02,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:02,254 INFO:     Epoch: 98
2022-11-28 03:19:03,004 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42191787741400977, 'Total loss': 0.42191787741400977} | train loss {'Reaction outcome loss': 0.3019924911580259, 'Total loss': 0.3019924911580259}
2022-11-28 03:19:03,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:03,005 INFO:     Epoch: 99
2022-11-28 03:19:03,753 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44041200896555727, 'Total loss': 0.44041200896555727} | train loss {'Reaction outcome loss': 0.303522611367366, 'Total loss': 0.303522611367366}
2022-11-28 03:19:03,754 INFO:     Best model found after epoch 87 of 100.
2022-11-28 03:19:03,754 INFO:   Done with stage: TRAINING
2022-11-28 03:19:03,754 INFO:   Starting stage: EVALUATION
2022-11-28 03:19:03,869 INFO:   Done with stage: EVALUATION
2022-11-28 03:19:03,869 INFO:   Leaving out SEQ value Fold_7
2022-11-28 03:19:03,882 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:19:03,882 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:19:04,520 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:19:04,520 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:19:04,588 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:19:04,589 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:19:04,589 INFO:     No hyperparam tuning for this model
2022-11-28 03:19:04,589 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:19:04,589 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:19:04,589 INFO:     None feature selector for col prot
2022-11-28 03:19:04,590 INFO:     None feature selector for col prot
2022-11-28 03:19:04,590 INFO:     None feature selector for col prot
2022-11-28 03:19:04,590 INFO:     None feature selector for col chem
2022-11-28 03:19:04,590 INFO:     None feature selector for col chem
2022-11-28 03:19:04,590 INFO:     None feature selector for col chem
2022-11-28 03:19:04,590 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:19:04,590 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:19:04,592 INFO:     Number of params in model 169741
2022-11-28 03:19:04,595 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:19:04,595 INFO:   Starting stage: TRAINING
2022-11-28 03:19:04,649 INFO:     Val loss before train {'Reaction outcome loss': 0.9915967244993557, 'Total loss': 0.9915967244993557}
2022-11-28 03:19:04,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:04,649 INFO:     Epoch: 0
2022-11-28 03:19:05,396 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.55328823084181, 'Total loss': 0.55328823084181} | train loss {'Reaction outcome loss': 0.6330481527913963, 'Total loss': 0.6330481527913963}
2022-11-28 03:19:05,396 INFO:     Found new best model at epoch 0
2022-11-28 03:19:05,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:05,397 INFO:     Epoch: 1
2022-11-28 03:19:06,147 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5112409083680673, 'Total loss': 0.5112409083680673} | train loss {'Reaction outcome loss': 0.4984437235360665, 'Total loss': 0.4984437235360665}
2022-11-28 03:19:06,147 INFO:     Found new best model at epoch 1
2022-11-28 03:19:06,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:06,148 INFO:     Epoch: 2
2022-11-28 03:19:06,896 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5366476079957052, 'Total loss': 0.5366476079957052} | train loss {'Reaction outcome loss': 0.4560055526333951, 'Total loss': 0.4560055526333951}
2022-11-28 03:19:06,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:06,896 INFO:     Epoch: 3
2022-11-28 03:19:07,643 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4770920852368528, 'Total loss': 0.4770920852368528} | train loss {'Reaction outcome loss': 0.43264976146841244, 'Total loss': 0.43264976146841244}
2022-11-28 03:19:07,644 INFO:     Found new best model at epoch 3
2022-11-28 03:19:07,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:07,645 INFO:     Epoch: 4
2022-11-28 03:19:08,392 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47984246841885825, 'Total loss': 0.47984246841885825} | train loss {'Reaction outcome loss': 0.41450559612243404, 'Total loss': 0.41450559612243404}
2022-11-28 03:19:08,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:08,393 INFO:     Epoch: 5
2022-11-28 03:19:09,140 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4589241353625601, 'Total loss': 0.4589241353625601} | train loss {'Reaction outcome loss': 0.41112299365622385, 'Total loss': 0.41112299365622385}
2022-11-28 03:19:09,140 INFO:     Found new best model at epoch 5
2022-11-28 03:19:09,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:09,141 INFO:     Epoch: 6
2022-11-28 03:19:09,888 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42154130271889945, 'Total loss': 0.42154130271889945} | train loss {'Reaction outcome loss': 0.39722251396385894, 'Total loss': 0.39722251396385894}
2022-11-28 03:19:09,888 INFO:     Found new best model at epoch 6
2022-11-28 03:19:09,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:09,889 INFO:     Epoch: 7
2022-11-28 03:19:10,639 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42931996201249684, 'Total loss': 0.42931996201249684} | train loss {'Reaction outcome loss': 0.39291807585546085, 'Total loss': 0.39291807585546085}
2022-11-28 03:19:10,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:10,639 INFO:     Epoch: 8
2022-11-28 03:19:11,387 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4672629643570293, 'Total loss': 0.4672629643570293} | train loss {'Reaction outcome loss': 0.38323517948869734, 'Total loss': 0.38323517948869734}
2022-11-28 03:19:11,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:11,388 INFO:     Epoch: 9
2022-11-28 03:19:12,134 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4410499310628934, 'Total loss': 0.4410499310628934} | train loss {'Reaction outcome loss': 0.37734608204975245, 'Total loss': 0.37734608204975245}
2022-11-28 03:19:12,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:12,134 INFO:     Epoch: 10
2022-11-28 03:19:12,882 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.439182562245564, 'Total loss': 0.439182562245564} | train loss {'Reaction outcome loss': 0.37439885628860325, 'Total loss': 0.37439885628860325}
2022-11-28 03:19:12,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:12,883 INFO:     Epoch: 11
2022-11-28 03:19:13,632 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4406219736080278, 'Total loss': 0.4406219736080278} | train loss {'Reaction outcome loss': 0.3683836997576779, 'Total loss': 0.3683836997576779}
2022-11-28 03:19:13,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:13,632 INFO:     Epoch: 12
2022-11-28 03:19:14,378 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45487931404601445, 'Total loss': 0.45487931404601445} | train loss {'Reaction outcome loss': 0.36642868931014694, 'Total loss': 0.36642868931014694}
2022-11-28 03:19:14,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:14,379 INFO:     Epoch: 13
2022-11-28 03:19:15,127 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44336133484135976, 'Total loss': 0.44336133484135976} | train loss {'Reaction outcome loss': 0.35553835777025067, 'Total loss': 0.35553835777025067}
2022-11-28 03:19:15,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:15,127 INFO:     Epoch: 14
2022-11-28 03:19:15,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4303182949396697, 'Total loss': 0.4303182949396697} | train loss {'Reaction outcome loss': 0.35209454097334414, 'Total loss': 0.35209454097334414}
2022-11-28 03:19:15,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:15,873 INFO:     Epoch: 15
2022-11-28 03:19:16,620 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46138042753393, 'Total loss': 0.46138042753393} | train loss {'Reaction outcome loss': 0.355505830818607, 'Total loss': 0.355505830818607}
2022-11-28 03:19:16,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:16,620 INFO:     Epoch: 16
2022-11-28 03:19:17,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4385241871191697, 'Total loss': 0.4385241871191697} | train loss {'Reaction outcome loss': 0.353971368242656, 'Total loss': 0.353971368242656}
2022-11-28 03:19:17,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:17,370 INFO:     Epoch: 17
2022-11-28 03:19:18,117 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40336770665916527, 'Total loss': 0.40336770665916527} | train loss {'Reaction outcome loss': 0.35322444423312144, 'Total loss': 0.35322444423312144}
2022-11-28 03:19:18,118 INFO:     Found new best model at epoch 17
2022-11-28 03:19:18,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:18,119 INFO:     Epoch: 18
2022-11-28 03:19:18,865 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49764889952811325, 'Total loss': 0.49764889952811325} | train loss {'Reaction outcome loss': 0.34752073826929253, 'Total loss': 0.34752073826929253}
2022-11-28 03:19:18,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:18,865 INFO:     Epoch: 19
2022-11-28 03:19:19,609 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42050464112650265, 'Total loss': 0.42050464112650265} | train loss {'Reaction outcome loss': 0.34125197776443056, 'Total loss': 0.34125197776443056}
2022-11-28 03:19:19,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:19,609 INFO:     Epoch: 20
2022-11-28 03:19:20,362 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4420743110505017, 'Total loss': 0.4420743110505017} | train loss {'Reaction outcome loss': 0.3424201742896149, 'Total loss': 0.3424201742896149}
2022-11-28 03:19:20,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:20,363 INFO:     Epoch: 21
2022-11-28 03:19:21,111 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39991413903507317, 'Total loss': 0.39991413903507317} | train loss {'Reaction outcome loss': 0.33310557255942014, 'Total loss': 0.33310557255942014}
2022-11-28 03:19:21,111 INFO:     Found new best model at epoch 21
2022-11-28 03:19:21,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:21,112 INFO:     Epoch: 22
2022-11-28 03:19:21,859 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39111470024694095, 'Total loss': 0.39111470024694095} | train loss {'Reaction outcome loss': 0.33775343027927224, 'Total loss': 0.33775343027927224}
2022-11-28 03:19:21,859 INFO:     Found new best model at epoch 22
2022-11-28 03:19:21,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:21,860 INFO:     Epoch: 23
2022-11-28 03:19:22,605 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42879019948569214, 'Total loss': 0.42879019948569214} | train loss {'Reaction outcome loss': 0.336220191626419, 'Total loss': 0.336220191626419}
2022-11-28 03:19:22,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:22,605 INFO:     Epoch: 24
2022-11-28 03:19:23,352 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43775722960179503, 'Total loss': 0.43775722960179503} | train loss {'Reaction outcome loss': 0.3388012244756664, 'Total loss': 0.3388012244756664}
2022-11-28 03:19:23,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:23,352 INFO:     Epoch: 25
2022-11-28 03:19:24,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41237205791879783, 'Total loss': 0.41237205791879783} | train loss {'Reaction outcome loss': 0.327519184459121, 'Total loss': 0.327519184459121}
2022-11-28 03:19:24,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:24,101 INFO:     Epoch: 26
2022-11-28 03:19:24,851 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3943230174481869, 'Total loss': 0.3943230174481869} | train loss {'Reaction outcome loss': 0.32737608416186226, 'Total loss': 0.32737608416186226}
2022-11-28 03:19:24,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:24,851 INFO:     Epoch: 27
2022-11-28 03:19:25,597 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42538704215125606, 'Total loss': 0.42538704215125606} | train loss {'Reaction outcome loss': 0.32067611035440236, 'Total loss': 0.32067611035440236}
2022-11-28 03:19:25,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:25,597 INFO:     Epoch: 28
2022-11-28 03:19:26,345 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4145724001255902, 'Total loss': 0.4145724001255902} | train loss {'Reaction outcome loss': 0.32655785355957284, 'Total loss': 0.32655785355957284}
2022-11-28 03:19:26,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:26,345 INFO:     Epoch: 29
2022-11-28 03:19:27,093 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4475228639150208, 'Total loss': 0.4475228639150208} | train loss {'Reaction outcome loss': 0.3231205656944263, 'Total loss': 0.3231205656944263}
2022-11-28 03:19:27,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:27,094 INFO:     Epoch: 30
2022-11-28 03:19:27,842 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44383189488540997, 'Total loss': 0.44383189488540997} | train loss {'Reaction outcome loss': 0.3269488255102788, 'Total loss': 0.3269488255102788}
2022-11-28 03:19:27,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:27,842 INFO:     Epoch: 31
2022-11-28 03:19:28,589 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43848192251541396, 'Total loss': 0.43848192251541396} | train loss {'Reaction outcome loss': 0.3112214810905918, 'Total loss': 0.3112214810905918}
2022-11-28 03:19:28,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:28,589 INFO:     Epoch: 32
2022-11-28 03:19:29,335 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4175762828778137, 'Total loss': 0.4175762828778137} | train loss {'Reaction outcome loss': 0.32390779298880407, 'Total loss': 0.32390779298880407}
2022-11-28 03:19:29,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:29,335 INFO:     Epoch: 33
2022-11-28 03:19:30,080 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40905650095506146, 'Total loss': 0.40905650095506146} | train loss {'Reaction outcome loss': 0.3163652750400586, 'Total loss': 0.3163652750400586}
2022-11-28 03:19:30,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:30,080 INFO:     Epoch: 34
2022-11-28 03:19:30,832 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4342422234741124, 'Total loss': 0.4342422234741124} | train loss {'Reaction outcome loss': 0.31636071121019704, 'Total loss': 0.31636071121019704}
2022-11-28 03:19:30,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:30,832 INFO:     Epoch: 35
2022-11-28 03:19:31,597 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4238652446391908, 'Total loss': 0.4238652446391908} | train loss {'Reaction outcome loss': 0.3103760343285338, 'Total loss': 0.3103760343285338}
2022-11-28 03:19:31,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:31,597 INFO:     Epoch: 36
2022-11-28 03:19:32,360 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41592548736794427, 'Total loss': 0.41592548736794427} | train loss {'Reaction outcome loss': 0.31722488233278834, 'Total loss': 0.31722488233278834}
2022-11-28 03:19:32,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:32,360 INFO:     Epoch: 37
2022-11-28 03:19:33,123 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4155434959314086, 'Total loss': 0.4155434959314086} | train loss {'Reaction outcome loss': 0.32314393338897535, 'Total loss': 0.32314393338897535}
2022-11-28 03:19:33,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:33,123 INFO:     Epoch: 38
2022-11-28 03:19:33,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39362039586359804, 'Total loss': 0.39362039586359804} | train loss {'Reaction outcome loss': 0.3142795670597303, 'Total loss': 0.3142795670597303}
2022-11-28 03:19:33,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:33,884 INFO:     Epoch: 39
2022-11-28 03:19:34,649 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4217276864431121, 'Total loss': 0.4217276864431121} | train loss {'Reaction outcome loss': 0.31246307017582076, 'Total loss': 0.31246307017582076}
2022-11-28 03:19:34,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:34,649 INFO:     Epoch: 40
2022-11-28 03:19:35,413 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4255025769499215, 'Total loss': 0.4255025769499215} | train loss {'Reaction outcome loss': 0.31889100105411583, 'Total loss': 0.31889100105411583}
2022-11-28 03:19:35,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:35,413 INFO:     Epoch: 41
2022-11-28 03:19:36,176 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41381323100491, 'Total loss': 0.41381323100491} | train loss {'Reaction outcome loss': 0.3142869666278843, 'Total loss': 0.3142869666278843}
2022-11-28 03:19:36,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:36,177 INFO:     Epoch: 42
2022-11-28 03:19:36,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4082600884139538, 'Total loss': 0.4082600884139538} | train loss {'Reaction outcome loss': 0.3119126272598101, 'Total loss': 0.3119126272598101}
2022-11-28 03:19:36,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:36,940 INFO:     Epoch: 43
2022-11-28 03:19:37,703 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3927904475818981, 'Total loss': 0.3927904475818981} | train loss {'Reaction outcome loss': 0.3114316863488526, 'Total loss': 0.3114316863488526}
2022-11-28 03:19:37,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:37,703 INFO:     Epoch: 44
2022-11-28 03:19:38,466 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39780942689288745, 'Total loss': 0.39780942689288745} | train loss {'Reaction outcome loss': 0.306952710804199, 'Total loss': 0.306952710804199}
2022-11-28 03:19:38,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:38,466 INFO:     Epoch: 45
2022-11-28 03:19:39,230 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4093695856969465, 'Total loss': 0.4093695856969465} | train loss {'Reaction outcome loss': 0.3110688694061772, 'Total loss': 0.3110688694061772}
2022-11-28 03:19:39,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:39,231 INFO:     Epoch: 46
2022-11-28 03:19:39,994 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40808591653000226, 'Total loss': 0.40808591653000226} | train loss {'Reaction outcome loss': 0.30933279063432445, 'Total loss': 0.30933279063432445}
2022-11-28 03:19:39,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:39,994 INFO:     Epoch: 47
2022-11-28 03:19:40,757 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43283173170956696, 'Total loss': 0.43283173170956696} | train loss {'Reaction outcome loss': 0.3203341328809338, 'Total loss': 0.3203341328809338}
2022-11-28 03:19:40,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:40,757 INFO:     Epoch: 48
2022-11-28 03:19:41,522 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4285229937258092, 'Total loss': 0.4285229937258092} | train loss {'Reaction outcome loss': 0.3173709742484554, 'Total loss': 0.3173709742484554}
2022-11-28 03:19:41,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:41,522 INFO:     Epoch: 49
2022-11-28 03:19:42,285 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4219248579307036, 'Total loss': 0.4219248579307036} | train loss {'Reaction outcome loss': 0.31130104834934874, 'Total loss': 0.31130104834934874}
2022-11-28 03:19:42,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:42,285 INFO:     Epoch: 50
2022-11-28 03:19:43,046 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42944329672239046, 'Total loss': 0.42944329672239046} | train loss {'Reaction outcome loss': 0.3191741434707036, 'Total loss': 0.3191741434707036}
2022-11-28 03:19:43,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:43,047 INFO:     Epoch: 51
2022-11-28 03:19:43,807 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.424772249026732, 'Total loss': 0.424772249026732} | train loss {'Reaction outcome loss': 0.3047334981871949, 'Total loss': 0.3047334981871949}
2022-11-28 03:19:43,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:43,807 INFO:     Epoch: 52
2022-11-28 03:19:44,570 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42606772821057926, 'Total loss': 0.42606772821057926} | train loss {'Reaction outcome loss': 0.31377177865755174, 'Total loss': 0.31377177865755174}
2022-11-28 03:19:44,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:44,570 INFO:     Epoch: 53
2022-11-28 03:19:45,334 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4044843969697302, 'Total loss': 0.4044843969697302} | train loss {'Reaction outcome loss': 0.31254355450190846, 'Total loss': 0.31254355450190846}
2022-11-28 03:19:45,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:45,335 INFO:     Epoch: 54
2022-11-28 03:19:46,099 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4329165064475753, 'Total loss': 0.4329165064475753} | train loss {'Reaction outcome loss': 0.3109526595761699, 'Total loss': 0.3109526595761699}
2022-11-28 03:19:46,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:46,099 INFO:     Epoch: 55
2022-11-28 03:19:46,863 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4170191555537961, 'Total loss': 0.4170191555537961} | train loss {'Reaction outcome loss': 0.3038589059855909, 'Total loss': 0.3038589059855909}
2022-11-28 03:19:46,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:46,864 INFO:     Epoch: 56
2022-11-28 03:19:47,631 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40823271735148, 'Total loss': 0.40823271735148} | train loss {'Reaction outcome loss': 0.3181085841459853, 'Total loss': 0.3181085841459853}
2022-11-28 03:19:47,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:47,631 INFO:     Epoch: 57
2022-11-28 03:19:48,397 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.420567162334919, 'Total loss': 0.420567162334919} | train loss {'Reaction outcome loss': 0.3168645061312183, 'Total loss': 0.3168645061312183}
2022-11-28 03:19:48,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:48,397 INFO:     Epoch: 58
2022-11-28 03:19:49,162 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.414864491332661, 'Total loss': 0.414864491332661} | train loss {'Reaction outcome loss': 0.30359104660249525, 'Total loss': 0.30359104660249525}
2022-11-28 03:19:49,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:49,163 INFO:     Epoch: 59
2022-11-28 03:19:49,927 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4698002807457339, 'Total loss': 0.4698002807457339} | train loss {'Reaction outcome loss': 0.302471874552148, 'Total loss': 0.302471874552148}
2022-11-28 03:19:49,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:49,928 INFO:     Epoch: 60
2022-11-28 03:19:50,690 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42027112909338693, 'Total loss': 0.42027112909338693} | train loss {'Reaction outcome loss': 0.30637098264489926, 'Total loss': 0.30637098264489926}
2022-11-28 03:19:50,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:50,691 INFO:     Epoch: 61
2022-11-28 03:19:51,454 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4183990548957478, 'Total loss': 0.4183990548957478} | train loss {'Reaction outcome loss': 0.3072751996618125, 'Total loss': 0.3072751996618125}
2022-11-28 03:19:51,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:51,455 INFO:     Epoch: 62
2022-11-28 03:19:52,221 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4119847992604429, 'Total loss': 0.4119847992604429} | train loss {'Reaction outcome loss': 0.3149053148865219, 'Total loss': 0.3149053148865219}
2022-11-28 03:19:52,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:52,221 INFO:     Epoch: 63
2022-11-28 03:19:52,982 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4212405735796148, 'Total loss': 0.4212405735796148} | train loss {'Reaction outcome loss': 0.3086615928238438, 'Total loss': 0.3086615928238438}
2022-11-28 03:19:52,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:52,982 INFO:     Epoch: 64
2022-11-28 03:19:53,749 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43411332538182085, 'Total loss': 0.43411332538182085} | train loss {'Reaction outcome loss': 0.3100041213685707, 'Total loss': 0.3100041213685707}
2022-11-28 03:19:53,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:53,749 INFO:     Epoch: 65
2022-11-28 03:19:54,515 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41645110195333307, 'Total loss': 0.41645110195333307} | train loss {'Reaction outcome loss': 0.3018780504203131, 'Total loss': 0.3018780504203131}
2022-11-28 03:19:54,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:54,515 INFO:     Epoch: 66
2022-11-28 03:19:55,281 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4285835376517339, 'Total loss': 0.4285835376517339} | train loss {'Reaction outcome loss': 0.30819121453790893, 'Total loss': 0.30819121453790893}
2022-11-28 03:19:55,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:55,282 INFO:     Epoch: 67
2022-11-28 03:19:56,045 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4094191195273941, 'Total loss': 0.4094191195273941} | train loss {'Reaction outcome loss': 0.30514243216584286, 'Total loss': 0.30514243216584286}
2022-11-28 03:19:56,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:56,045 INFO:     Epoch: 68
2022-11-28 03:19:56,807 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4233981916172938, 'Total loss': 0.4233981916172938} | train loss {'Reaction outcome loss': 0.3028950071968739, 'Total loss': 0.3028950071968739}
2022-11-28 03:19:56,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:56,807 INFO:     Epoch: 69
2022-11-28 03:19:57,572 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40010700171644037, 'Total loss': 0.40010700171644037} | train loss {'Reaction outcome loss': 0.30886077036660525, 'Total loss': 0.30886077036660525}
2022-11-28 03:19:57,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:57,573 INFO:     Epoch: 70
2022-11-28 03:19:58,324 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44640532914887776, 'Total loss': 0.44640532914887776} | train loss {'Reaction outcome loss': 0.3050386798868497, 'Total loss': 0.3050386798868497}
2022-11-28 03:19:58,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:58,324 INFO:     Epoch: 71
2022-11-28 03:19:59,076 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4142506823621013, 'Total loss': 0.4142506823621013} | train loss {'Reaction outcome loss': 0.30237214850832617, 'Total loss': 0.30237214850832617}
2022-11-28 03:19:59,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:59,076 INFO:     Epoch: 72
2022-11-28 03:19:59,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4100606068968773, 'Total loss': 0.4100606068968773} | train loss {'Reaction outcome loss': 0.29919646539154554, 'Total loss': 0.29919646539154554}
2022-11-28 03:19:59,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:19:59,825 INFO:     Epoch: 73
2022-11-28 03:20:00,574 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4117929996414618, 'Total loss': 0.4117929996414618} | train loss {'Reaction outcome loss': 0.3028397170316067, 'Total loss': 0.3028397170316067}
2022-11-28 03:20:00,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:00,574 INFO:     Epoch: 74
2022-11-28 03:20:01,320 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3988169226795435, 'Total loss': 0.3988169226795435} | train loss {'Reaction outcome loss': 0.3085058102264039, 'Total loss': 0.3085058102264039}
2022-11-28 03:20:01,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:01,320 INFO:     Epoch: 75
2022-11-28 03:20:02,064 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40417911332439294, 'Total loss': 0.40417911332439294} | train loss {'Reaction outcome loss': 0.2959003532906213, 'Total loss': 0.2959003532906213}
2022-11-28 03:20:02,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:02,064 INFO:     Epoch: 76
2022-11-28 03:20:02,815 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41363647106018936, 'Total loss': 0.41363647106018936} | train loss {'Reaction outcome loss': 0.3093702054071811, 'Total loss': 0.3093702054071811}
2022-11-28 03:20:02,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:02,815 INFO:     Epoch: 77
2022-11-28 03:20:03,565 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4507639336992394, 'Total loss': 0.4507639336992394} | train loss {'Reaction outcome loss': 0.30859266230536087, 'Total loss': 0.30859266230536087}
2022-11-28 03:20:03,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:03,565 INFO:     Epoch: 78
2022-11-28 03:20:04,316 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4121737534349615, 'Total loss': 0.4121737534349615} | train loss {'Reaction outcome loss': 0.30501548263935313, 'Total loss': 0.30501548263935313}
2022-11-28 03:20:04,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:04,316 INFO:     Epoch: 79
2022-11-28 03:20:05,073 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42379066280343314, 'Total loss': 0.42379066280343314} | train loss {'Reaction outcome loss': 0.30958836271818124, 'Total loss': 0.30958836271818124}
2022-11-28 03:20:05,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:05,073 INFO:     Epoch: 80
2022-11-28 03:20:05,826 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4119920324195515, 'Total loss': 0.4119920324195515} | train loss {'Reaction outcome loss': 0.3058641141340617, 'Total loss': 0.3058641141340617}
2022-11-28 03:20:05,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:05,826 INFO:     Epoch: 81
2022-11-28 03:20:06,576 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4517620781605894, 'Total loss': 0.4517620781605894} | train loss {'Reaction outcome loss': 0.31012768289374726, 'Total loss': 0.31012768289374726}
2022-11-28 03:20:06,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:06,577 INFO:     Epoch: 82
2022-11-28 03:20:07,327 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42606309902938927, 'Total loss': 0.42606309902938927} | train loss {'Reaction outcome loss': 0.3029388424249426, 'Total loss': 0.3029388424249426}
2022-11-28 03:20:07,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:07,327 INFO:     Epoch: 83
2022-11-28 03:20:08,077 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4554197695106268, 'Total loss': 0.4554197695106268} | train loss {'Reaction outcome loss': 0.29792562929252464, 'Total loss': 0.29792562929252464}
2022-11-28 03:20:08,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:08,078 INFO:     Epoch: 84
2022-11-28 03:20:08,830 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4174704478884285, 'Total loss': 0.4174704478884285} | train loss {'Reaction outcome loss': 0.30485537491979137, 'Total loss': 0.30485537491979137}
2022-11-28 03:20:08,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:08,830 INFO:     Epoch: 85
2022-11-28 03:20:09,585 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4105222336947918, 'Total loss': 0.4105222336947918} | train loss {'Reaction outcome loss': 0.3057396285416138, 'Total loss': 0.3057396285416138}
2022-11-28 03:20:09,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:09,586 INFO:     Epoch: 86
2022-11-28 03:20:10,341 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40932981619103387, 'Total loss': 0.40932981619103387} | train loss {'Reaction outcome loss': 0.30441647751497164, 'Total loss': 0.30441647751497164}
2022-11-28 03:20:10,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:10,341 INFO:     Epoch: 87
2022-11-28 03:20:11,093 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3946996768089858, 'Total loss': 0.3946996768089858} | train loss {'Reaction outcome loss': 0.30784241146137636, 'Total loss': 0.30784241146137636}
2022-11-28 03:20:11,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:11,093 INFO:     Epoch: 88
2022-11-28 03:20:11,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4106939534910701, 'Total loss': 0.4106939534910701} | train loss {'Reaction outcome loss': 0.2960368920898726, 'Total loss': 0.2960368920898726}
2022-11-28 03:20:11,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:11,852 INFO:     Epoch: 89
2022-11-28 03:20:12,606 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4272234429689971, 'Total loss': 0.4272234429689971} | train loss {'Reaction outcome loss': 0.3035521312286296, 'Total loss': 0.3035521312286296}
2022-11-28 03:20:12,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:12,606 INFO:     Epoch: 90
2022-11-28 03:20:13,360 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41138836301185866, 'Total loss': 0.41138836301185866} | train loss {'Reaction outcome loss': 0.3016029374613877, 'Total loss': 0.3016029374613877}
2022-11-28 03:20:13,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:13,360 INFO:     Epoch: 91
2022-11-28 03:20:14,114 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45070285858078435, 'Total loss': 0.45070285858078435} | train loss {'Reaction outcome loss': 0.3011953721063272, 'Total loss': 0.3011953721063272}
2022-11-28 03:20:14,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:14,114 INFO:     Epoch: 92
2022-11-28 03:20:14,867 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4217846187000925, 'Total loss': 0.4217846187000925} | train loss {'Reaction outcome loss': 0.29571886087257054, 'Total loss': 0.29571886087257054}
2022-11-28 03:20:14,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:14,868 INFO:     Epoch: 93
2022-11-28 03:20:15,622 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4278348303315314, 'Total loss': 0.4278348303315314} | train loss {'Reaction outcome loss': 0.30208831857289037, 'Total loss': 0.30208831857289037}
2022-11-28 03:20:15,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:15,622 INFO:     Epoch: 94
2022-11-28 03:20:16,377 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4494594413448464, 'Total loss': 0.4494594413448464} | train loss {'Reaction outcome loss': 0.30072835828327843, 'Total loss': 0.30072835828327843}
2022-11-28 03:20:16,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:16,377 INFO:     Epoch: 95
2022-11-28 03:20:17,131 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45022155276753684, 'Total loss': 0.45022155276753684} | train loss {'Reaction outcome loss': 0.2957671490768271, 'Total loss': 0.2957671490768271}
2022-11-28 03:20:17,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:17,132 INFO:     Epoch: 96
2022-11-28 03:20:17,885 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40359588695520704, 'Total loss': 0.40359588695520704} | train loss {'Reaction outcome loss': 0.3023659435942048, 'Total loss': 0.3023659435942048}
2022-11-28 03:20:17,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:17,885 INFO:     Epoch: 97
2022-11-28 03:20:18,636 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43859543990005145, 'Total loss': 0.43859543990005145} | train loss {'Reaction outcome loss': 0.3120135682214412, 'Total loss': 0.3120135682214412}
2022-11-28 03:20:18,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:18,636 INFO:     Epoch: 98
2022-11-28 03:20:19,387 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4392318586734208, 'Total loss': 0.4392318586734208} | train loss {'Reaction outcome loss': 0.2987253049448613, 'Total loss': 0.2987253049448613}
2022-11-28 03:20:19,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:19,388 INFO:     Epoch: 99
2022-11-28 03:20:20,137 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40753577717325906, 'Total loss': 0.40753577717325906} | train loss {'Reaction outcome loss': 0.30589106937329613, 'Total loss': 0.30589106937329613}
2022-11-28 03:20:20,138 INFO:     Best model found after epoch 23 of 100.
2022-11-28 03:20:20,138 INFO:   Done with stage: TRAINING
2022-11-28 03:20:20,138 INFO:   Starting stage: EVALUATION
2022-11-28 03:20:20,253 INFO:   Done with stage: EVALUATION
2022-11-28 03:20:20,253 INFO:   Leaving out SEQ value Fold_8
2022-11-28 03:20:20,266 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:20:20,266 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:20:20,908 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:20:20,908 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:20:20,977 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:20:20,977 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:20:20,977 INFO:     No hyperparam tuning for this model
2022-11-28 03:20:20,977 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:20:20,977 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:20:20,978 INFO:     None feature selector for col prot
2022-11-28 03:20:20,978 INFO:     None feature selector for col prot
2022-11-28 03:20:20,978 INFO:     None feature selector for col prot
2022-11-28 03:20:20,979 INFO:     None feature selector for col chem
2022-11-28 03:20:20,979 INFO:     None feature selector for col chem
2022-11-28 03:20:20,979 INFO:     None feature selector for col chem
2022-11-28 03:20:20,979 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:20:20,979 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:20:20,980 INFO:     Number of params in model 169741
2022-11-28 03:20:20,984 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:20:20,984 INFO:   Starting stage: TRAINING
2022-11-28 03:20:21,037 INFO:     Val loss before train {'Reaction outcome loss': 1.0086247528141195, 'Total loss': 1.0086247528141195}
2022-11-28 03:20:21,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:21,038 INFO:     Epoch: 0
2022-11-28 03:20:21,779 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5650906400247053, 'Total loss': 0.5650906400247053} | train loss {'Reaction outcome loss': 0.650628504826098, 'Total loss': 0.650628504826098}
2022-11-28 03:20:21,779 INFO:     Found new best model at epoch 0
2022-11-28 03:20:21,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:21,780 INFO:     Epoch: 1
2022-11-28 03:20:22,522 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5914906283671205, 'Total loss': 0.5914906283671205} | train loss {'Reaction outcome loss': 0.5061928312997429, 'Total loss': 0.5061928312997429}
2022-11-28 03:20:22,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:22,523 INFO:     Epoch: 2
2022-11-28 03:20:23,263 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48056555539369583, 'Total loss': 0.48056555539369583} | train loss {'Reaction outcome loss': 0.46664518111822556, 'Total loss': 0.46664518111822556}
2022-11-28 03:20:23,263 INFO:     Found new best model at epoch 2
2022-11-28 03:20:23,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:23,264 INFO:     Epoch: 3
2022-11-28 03:20:24,008 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44372041658921674, 'Total loss': 0.44372041658921674} | train loss {'Reaction outcome loss': 0.44100964537688664, 'Total loss': 0.44100964537688664}
2022-11-28 03:20:24,008 INFO:     Found new best model at epoch 3
2022-11-28 03:20:24,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:24,009 INFO:     Epoch: 4
2022-11-28 03:20:24,750 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4434797145764936, 'Total loss': 0.4434797145764936} | train loss {'Reaction outcome loss': 0.42587031253746577, 'Total loss': 0.42587031253746577}
2022-11-28 03:20:24,751 INFO:     Found new best model at epoch 4
2022-11-28 03:20:24,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:24,751 INFO:     Epoch: 5
2022-11-28 03:20:25,495 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4488278925418854, 'Total loss': 0.4488278925418854} | train loss {'Reaction outcome loss': 0.41961934098175596, 'Total loss': 0.41961934098175596}
2022-11-28 03:20:25,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:25,495 INFO:     Epoch: 6
2022-11-28 03:20:26,236 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44329293173822487, 'Total loss': 0.44329293173822487} | train loss {'Reaction outcome loss': 0.40769544633067384, 'Total loss': 0.40769544633067384}
2022-11-28 03:20:26,236 INFO:     Found new best model at epoch 6
2022-11-28 03:20:26,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:26,237 INFO:     Epoch: 7
2022-11-28 03:20:26,978 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4442220441997051, 'Total loss': 0.4442220441997051} | train loss {'Reaction outcome loss': 0.40536669158205696, 'Total loss': 0.40536669158205696}
2022-11-28 03:20:26,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:26,978 INFO:     Epoch: 8
2022-11-28 03:20:27,720 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45663781599564984, 'Total loss': 0.45663781599564984} | train loss {'Reaction outcome loss': 0.3943123312020788, 'Total loss': 0.3943123312020788}
2022-11-28 03:20:27,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:27,720 INFO:     Epoch: 9
2022-11-28 03:20:28,463 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42738632146607747, 'Total loss': 0.42738632146607747} | train loss {'Reaction outcome loss': 0.3834330588883283, 'Total loss': 0.3834330588883283}
2022-11-28 03:20:28,463 INFO:     Found new best model at epoch 9
2022-11-28 03:20:28,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:28,464 INFO:     Epoch: 10
2022-11-28 03:20:29,206 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4537024768916043, 'Total loss': 0.4537024768916043} | train loss {'Reaction outcome loss': 0.3839726238834615, 'Total loss': 0.3839726238834615}
2022-11-28 03:20:29,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:29,207 INFO:     Epoch: 11
2022-11-28 03:20:29,949 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4254710620099848, 'Total loss': 0.4254710620099848} | train loss {'Reaction outcome loss': 0.38669490370215204, 'Total loss': 0.38669490370215204}
2022-11-28 03:20:29,949 INFO:     Found new best model at epoch 11
2022-11-28 03:20:29,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:29,949 INFO:     Epoch: 12
2022-11-28 03:20:30,688 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4573484984311191, 'Total loss': 0.4573484984311191} | train loss {'Reaction outcome loss': 0.3783953021679606, 'Total loss': 0.3783953021679606}
2022-11-28 03:20:30,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:30,688 INFO:     Epoch: 13
2022-11-28 03:20:31,432 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4362714233046228, 'Total loss': 0.4362714233046228} | train loss {'Reaction outcome loss': 0.3730532684800576, 'Total loss': 0.3730532684800576}
2022-11-28 03:20:31,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:31,433 INFO:     Epoch: 14
2022-11-28 03:20:32,175 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4482941468330947, 'Total loss': 0.4482941468330947} | train loss {'Reaction outcome loss': 0.37411367102545134, 'Total loss': 0.37411367102545134}
2022-11-28 03:20:32,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:32,175 INFO:     Epoch: 15
2022-11-28 03:20:32,922 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42931765351783147, 'Total loss': 0.42931765351783147} | train loss {'Reaction outcome loss': 0.3712124449866159, 'Total loss': 0.3712124449866159}
2022-11-28 03:20:32,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:32,922 INFO:     Epoch: 16
2022-11-28 03:20:33,664 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45483737642114813, 'Total loss': 0.45483737642114813} | train loss {'Reaction outcome loss': 0.3610668730066747, 'Total loss': 0.3610668730066747}
2022-11-28 03:20:33,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:33,664 INFO:     Epoch: 17
2022-11-28 03:20:34,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40916402180763806, 'Total loss': 0.40916402180763806} | train loss {'Reaction outcome loss': 0.3606089900950996, 'Total loss': 0.3606089900950996}
2022-11-28 03:20:34,405 INFO:     Found new best model at epoch 17
2022-11-28 03:20:34,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:34,406 INFO:     Epoch: 18
2022-11-28 03:20:35,149 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4149680838666179, 'Total loss': 0.4149680838666179} | train loss {'Reaction outcome loss': 0.3548987104272356, 'Total loss': 0.3548987104272356}
2022-11-28 03:20:35,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:35,149 INFO:     Epoch: 19
2022-11-28 03:20:35,889 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44180282713337377, 'Total loss': 0.44180282713337377} | train loss {'Reaction outcome loss': 0.36308275768343284, 'Total loss': 0.36308275768343284}
2022-11-28 03:20:35,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:35,889 INFO:     Epoch: 20
2022-11-28 03:20:36,632 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4169092300263318, 'Total loss': 0.4169092300263318} | train loss {'Reaction outcome loss': 0.36103614787666166, 'Total loss': 0.36103614787666166}
2022-11-28 03:20:36,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:36,633 INFO:     Epoch: 21
2022-11-28 03:20:37,377 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4306983690370213, 'Total loss': 0.4306983690370213} | train loss {'Reaction outcome loss': 0.35021245817140656, 'Total loss': 0.35021245817140656}
2022-11-28 03:20:37,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:37,377 INFO:     Epoch: 22
2022-11-28 03:20:38,121 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42271378060633485, 'Total loss': 0.42271378060633485} | train loss {'Reaction outcome loss': 0.35642320075813605, 'Total loss': 0.35642320075813605}
2022-11-28 03:20:38,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:38,121 INFO:     Epoch: 23
2022-11-28 03:20:38,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4081562344323505, 'Total loss': 0.4081562344323505} | train loss {'Reaction outcome loss': 0.3435604791860191, 'Total loss': 0.3435604791860191}
2022-11-28 03:20:38,864 INFO:     Found new best model at epoch 23
2022-11-28 03:20:38,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:38,865 INFO:     Epoch: 24
2022-11-28 03:20:39,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43758472393859515, 'Total loss': 0.43758472393859515} | train loss {'Reaction outcome loss': 0.34572519249453837, 'Total loss': 0.34572519249453837}
2022-11-28 03:20:39,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:39,607 INFO:     Epoch: 25
2022-11-28 03:20:40,349 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42480671033263206, 'Total loss': 0.42480671033263206} | train loss {'Reaction outcome loss': 0.35002132128087843, 'Total loss': 0.35002132128087843}
2022-11-28 03:20:40,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:40,350 INFO:     Epoch: 26
2022-11-28 03:20:41,091 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4378050856969573, 'Total loss': 0.4378050856969573} | train loss {'Reaction outcome loss': 0.34346377837414643, 'Total loss': 0.34346377837414643}
2022-11-28 03:20:41,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:41,091 INFO:     Epoch: 27
2022-11-28 03:20:41,834 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4204300763932141, 'Total loss': 0.4204300763932141} | train loss {'Reaction outcome loss': 0.34918386890571945, 'Total loss': 0.34918386890571945}
2022-11-28 03:20:41,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:41,835 INFO:     Epoch: 28
2022-11-28 03:20:42,577 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40535155666822736, 'Total loss': 0.40535155666822736} | train loss {'Reaction outcome loss': 0.33960528948477336, 'Total loss': 0.33960528948477336}
2022-11-28 03:20:42,578 INFO:     Found new best model at epoch 28
2022-11-28 03:20:42,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:42,579 INFO:     Epoch: 29
2022-11-28 03:20:43,324 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43293290229683573, 'Total loss': 0.43293290229683573} | train loss {'Reaction outcome loss': 0.33970733701574557, 'Total loss': 0.33970733701574557}
2022-11-28 03:20:43,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:43,324 INFO:     Epoch: 30
2022-11-28 03:20:44,067 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40073163680393586, 'Total loss': 0.40073163680393586} | train loss {'Reaction outcome loss': 0.34399845885987185, 'Total loss': 0.34399845885987185}
2022-11-28 03:20:44,067 INFO:     Found new best model at epoch 30
2022-11-28 03:20:44,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:44,068 INFO:     Epoch: 31
2022-11-28 03:20:44,809 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4417277720164169, 'Total loss': 0.4417277720164169} | train loss {'Reaction outcome loss': 0.35404647023093944, 'Total loss': 0.35404647023093944}
2022-11-28 03:20:44,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:44,810 INFO:     Epoch: 32
2022-11-28 03:20:45,556 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41325864229689946, 'Total loss': 0.41325864229689946} | train loss {'Reaction outcome loss': 0.33707215799664964, 'Total loss': 0.33707215799664964}
2022-11-28 03:20:45,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:45,556 INFO:     Epoch: 33
2022-11-28 03:20:46,302 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41734364154663955, 'Total loss': 0.41734364154663955} | train loss {'Reaction outcome loss': 0.3389450026714072, 'Total loss': 0.3389450026714072}
2022-11-28 03:20:46,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:46,302 INFO:     Epoch: 34
2022-11-28 03:20:47,049 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3942844471470876, 'Total loss': 0.3942844471470876} | train loss {'Reaction outcome loss': 0.33513680778595867, 'Total loss': 0.33513680778595867}
2022-11-28 03:20:47,049 INFO:     Found new best model at epoch 34
2022-11-28 03:20:47,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:47,050 INFO:     Epoch: 35
2022-11-28 03:20:47,794 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42612491446462547, 'Total loss': 0.42612491446462547} | train loss {'Reaction outcome loss': 0.33148494481432195, 'Total loss': 0.33148494481432195}
2022-11-28 03:20:47,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:47,794 INFO:     Epoch: 36
2022-11-28 03:20:48,535 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3993393714455041, 'Total loss': 0.3993393714455041} | train loss {'Reaction outcome loss': 0.3352231082867603, 'Total loss': 0.3352231082867603}
2022-11-28 03:20:48,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:48,536 INFO:     Epoch: 37
2022-11-28 03:20:49,282 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45652868158437987, 'Total loss': 0.45652868158437987} | train loss {'Reaction outcome loss': 0.3278376667475214, 'Total loss': 0.3278376667475214}
2022-11-28 03:20:49,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:49,282 INFO:     Epoch: 38
2022-11-28 03:20:50,023 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4325677752494812, 'Total loss': 0.4325677752494812} | train loss {'Reaction outcome loss': 0.3361838471068411, 'Total loss': 0.3361838471068411}
2022-11-28 03:20:50,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:50,023 INFO:     Epoch: 39
2022-11-28 03:20:50,764 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4160659712823955, 'Total loss': 0.4160659712823955} | train loss {'Reaction outcome loss': 0.33137084616690266, 'Total loss': 0.33137084616690266}
2022-11-28 03:20:50,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:50,764 INFO:     Epoch: 40
2022-11-28 03:20:51,507 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43591322817585687, 'Total loss': 0.43591322817585687} | train loss {'Reaction outcome loss': 0.33584424077856295, 'Total loss': 0.33584424077856295}
2022-11-28 03:20:51,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:51,507 INFO:     Epoch: 41
2022-11-28 03:20:52,253 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39554532210935245, 'Total loss': 0.39554532210935245} | train loss {'Reaction outcome loss': 0.3313582654814331, 'Total loss': 0.3313582654814331}
2022-11-28 03:20:52,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:52,254 INFO:     Epoch: 42
2022-11-28 03:20:52,997 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3994351997971535, 'Total loss': 0.3994351997971535} | train loss {'Reaction outcome loss': 0.33857508622566046, 'Total loss': 0.33857508622566046}
2022-11-28 03:20:52,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:52,997 INFO:     Epoch: 43
2022-11-28 03:20:53,739 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41695147820494394, 'Total loss': 0.41695147820494394} | train loss {'Reaction outcome loss': 0.32647794497256377, 'Total loss': 0.32647794497256377}
2022-11-28 03:20:53,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:53,740 INFO:     Epoch: 44
2022-11-28 03:20:54,485 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39691474932161247, 'Total loss': 0.39691474932161247} | train loss {'Reaction outcome loss': 0.32391352918075056, 'Total loss': 0.32391352918075056}
2022-11-28 03:20:54,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:54,485 INFO:     Epoch: 45
2022-11-28 03:20:55,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40807474302974617, 'Total loss': 0.40807474302974617} | train loss {'Reaction outcome loss': 0.3276740538222449, 'Total loss': 0.3276740538222449}
2022-11-28 03:20:55,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:55,228 INFO:     Epoch: 46
2022-11-28 03:20:55,973 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.422060200097886, 'Total loss': 0.422060200097886} | train loss {'Reaction outcome loss': 0.32310855785498815, 'Total loss': 0.32310855785498815}
2022-11-28 03:20:55,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:55,974 INFO:     Epoch: 47
2022-11-28 03:20:56,719 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4431385147300633, 'Total loss': 0.4431385147300633} | train loss {'Reaction outcome loss': 0.3235663214660421, 'Total loss': 0.3235663214660421}
2022-11-28 03:20:56,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:56,720 INFO:     Epoch: 48
2022-11-28 03:20:57,463 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41302450983361766, 'Total loss': 0.41302450983361766} | train loss {'Reaction outcome loss': 0.32373682579823904, 'Total loss': 0.32373682579823904}
2022-11-28 03:20:57,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:57,463 INFO:     Epoch: 49
2022-11-28 03:20:58,206 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4063291131434115, 'Total loss': 0.4063291131434115} | train loss {'Reaction outcome loss': 0.3204559296977763, 'Total loss': 0.3204559296977763}
2022-11-28 03:20:58,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:58,206 INFO:     Epoch: 50
2022-11-28 03:20:58,949 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4305286989970641, 'Total loss': 0.4305286989970641} | train loss {'Reaction outcome loss': 0.32817633097269094, 'Total loss': 0.32817633097269094}
2022-11-28 03:20:58,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:58,949 INFO:     Epoch: 51
2022-11-28 03:20:59,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40056265450336714, 'Total loss': 0.40056265450336714} | train loss {'Reaction outcome loss': 0.3258888852839567, 'Total loss': 0.3258888852839567}
2022-11-28 03:20:59,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:20:59,693 INFO:     Epoch: 52
2022-11-28 03:21:00,437 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3912904491140084, 'Total loss': 0.3912904491140084} | train loss {'Reaction outcome loss': 0.3194888031604339, 'Total loss': 0.3194888031604339}
2022-11-28 03:21:00,438 INFO:     Found new best model at epoch 52
2022-11-28 03:21:00,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:00,439 INFO:     Epoch: 53
2022-11-28 03:21:01,183 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42090136295353825, 'Total loss': 0.42090136295353825} | train loss {'Reaction outcome loss': 0.31771846501802914, 'Total loss': 0.31771846501802914}
2022-11-28 03:21:01,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:01,183 INFO:     Epoch: 54
2022-11-28 03:21:01,926 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4123840108513832, 'Total loss': 0.4123840108513832} | train loss {'Reaction outcome loss': 0.31887200055073717, 'Total loss': 0.31887200055073717}
2022-11-28 03:21:01,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:01,926 INFO:     Epoch: 55
2022-11-28 03:21:02,674 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4195334320379929, 'Total loss': 0.4195334320379929} | train loss {'Reaction outcome loss': 0.3246069855835973, 'Total loss': 0.3246069855835973}
2022-11-28 03:21:02,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:02,675 INFO:     Epoch: 56
2022-11-28 03:21:03,420 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4035047692331401, 'Total loss': 0.4035047692331401} | train loss {'Reaction outcome loss': 0.3148754040805661, 'Total loss': 0.3148754040805661}
2022-11-28 03:21:03,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:03,420 INFO:     Epoch: 57
2022-11-28 03:21:04,162 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4533222175457261, 'Total loss': 0.4533222175457261} | train loss {'Reaction outcome loss': 0.316773855929472, 'Total loss': 0.316773855929472}
2022-11-28 03:21:04,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:04,163 INFO:     Epoch: 58
2022-11-28 03:21:04,906 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3987905869091099, 'Total loss': 0.3987905869091099} | train loss {'Reaction outcome loss': 0.3216401530771839, 'Total loss': 0.3216401530771839}
2022-11-28 03:21:04,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:04,906 INFO:     Epoch: 59
2022-11-28 03:21:05,649 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39200824025002395, 'Total loss': 0.39200824025002395} | train loss {'Reaction outcome loss': 0.31422024706796725, 'Total loss': 0.31422024706796725}
2022-11-28 03:21:05,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:05,649 INFO:     Epoch: 60
2022-11-28 03:21:06,391 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42907359112392773, 'Total loss': 0.42907359112392773} | train loss {'Reaction outcome loss': 0.31368906306368965, 'Total loss': 0.31368906306368965}
2022-11-28 03:21:06,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:06,391 INFO:     Epoch: 61
2022-11-28 03:21:07,136 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40787679194049403, 'Total loss': 0.40787679194049403} | train loss {'Reaction outcome loss': 0.31647250568684265, 'Total loss': 0.31647250568684265}
2022-11-28 03:21:07,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:07,137 INFO:     Epoch: 62
2022-11-28 03:21:07,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4334141720424999, 'Total loss': 0.4334141720424999} | train loss {'Reaction outcome loss': 0.31891017954568474, 'Total loss': 0.31891017954568474}
2022-11-28 03:21:07,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:07,879 INFO:     Epoch: 63
2022-11-28 03:21:08,621 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4115140339867635, 'Total loss': 0.4115140339867635} | train loss {'Reaction outcome loss': 0.32095969583915207, 'Total loss': 0.32095969583915207}
2022-11-28 03:21:08,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:08,622 INFO:     Epoch: 64
2022-11-28 03:21:09,366 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4010945192792199, 'Total loss': 0.4010945192792199} | train loss {'Reaction outcome loss': 0.31102541873649675, 'Total loss': 0.31102541873649675}
2022-11-28 03:21:09,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:09,366 INFO:     Epoch: 65
2022-11-28 03:21:10,111 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42119490304453805, 'Total loss': 0.42119490304453805} | train loss {'Reaction outcome loss': 0.31393027679652585, 'Total loss': 0.31393027679652585}
2022-11-28 03:21:10,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:10,111 INFO:     Epoch: 66
2022-11-28 03:21:10,853 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.410263071175326, 'Total loss': 0.410263071175326} | train loss {'Reaction outcome loss': 0.31351758776878824, 'Total loss': 0.31351758776878824}
2022-11-28 03:21:10,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:10,853 INFO:     Epoch: 67
2022-11-28 03:21:11,599 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4133611775257371, 'Total loss': 0.4133611775257371} | train loss {'Reaction outcome loss': 0.31757495512767714, 'Total loss': 0.31757495512767714}
2022-11-28 03:21:11,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:11,599 INFO:     Epoch: 68
2022-11-28 03:21:12,343 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41786047138951044, 'Total loss': 0.41786047138951044} | train loss {'Reaction outcome loss': 0.3187323569339149, 'Total loss': 0.3187323569339149}
2022-11-28 03:21:12,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:12,344 INFO:     Epoch: 69
2022-11-28 03:21:13,087 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42850210703909397, 'Total loss': 0.42850210703909397} | train loss {'Reaction outcome loss': 0.31600723929551183, 'Total loss': 0.31600723929551183}
2022-11-28 03:21:13,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:13,088 INFO:     Epoch: 70
2022-11-28 03:21:13,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4043756718323989, 'Total loss': 0.4043756718323989} | train loss {'Reaction outcome loss': 0.3255917772042508, 'Total loss': 0.3255917772042508}
2022-11-28 03:21:13,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:13,830 INFO:     Epoch: 71
2022-11-28 03:21:14,573 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40552687272429466, 'Total loss': 0.40552687272429466} | train loss {'Reaction outcome loss': 0.3164271453509525, 'Total loss': 0.3164271453509525}
2022-11-28 03:21:14,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:14,574 INFO:     Epoch: 72
2022-11-28 03:21:15,315 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.426643519831652, 'Total loss': 0.426643519831652} | train loss {'Reaction outcome loss': 0.31245639240559264, 'Total loss': 0.31245639240559264}
2022-11-28 03:21:15,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:15,316 INFO:     Epoch: 73
2022-11-28 03:21:16,061 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4198739244179292, 'Total loss': 0.4198739244179292} | train loss {'Reaction outcome loss': 0.3148661331862819, 'Total loss': 0.3148661331862819}
2022-11-28 03:21:16,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:16,061 INFO:     Epoch: 74
2022-11-28 03:21:16,805 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39486198635263875, 'Total loss': 0.39486198635263875} | train loss {'Reaction outcome loss': 0.31943730450406366, 'Total loss': 0.31943730450406366}
2022-11-28 03:21:16,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:16,806 INFO:     Epoch: 75
2022-11-28 03:21:17,548 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4369691457938064, 'Total loss': 0.4369691457938064} | train loss {'Reaction outcome loss': 0.3114787626175248, 'Total loss': 0.3114787626175248}
2022-11-28 03:21:17,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:17,549 INFO:     Epoch: 76
2022-11-28 03:21:18,289 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41340722727843304, 'Total loss': 0.41340722727843304} | train loss {'Reaction outcome loss': 0.3200753548011488, 'Total loss': 0.3200753548011488}
2022-11-28 03:21:18,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:18,290 INFO:     Epoch: 77
2022-11-28 03:21:19,028 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3844030234454708, 'Total loss': 0.3844030234454708} | train loss {'Reaction outcome loss': 0.3117373348194726, 'Total loss': 0.3117373348194726}
2022-11-28 03:21:19,028 INFO:     Found new best model at epoch 77
2022-11-28 03:21:19,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:19,029 INFO:     Epoch: 78
2022-11-28 03:21:19,773 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40324111215092917, 'Total loss': 0.40324111215092917} | train loss {'Reaction outcome loss': 0.3082164332422675, 'Total loss': 0.3082164332422675}
2022-11-28 03:21:19,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:19,774 INFO:     Epoch: 79
2022-11-28 03:21:20,516 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4225179477679459, 'Total loss': 0.4225179477679459} | train loss {'Reaction outcome loss': 0.31392129381396333, 'Total loss': 0.31392129381396333}
2022-11-28 03:21:20,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:20,517 INFO:     Epoch: 80
2022-11-28 03:21:21,264 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41737329214811325, 'Total loss': 0.41737329214811325} | train loss {'Reaction outcome loss': 0.31106691369596795, 'Total loss': 0.31106691369596795}
2022-11-28 03:21:21,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:21,264 INFO:     Epoch: 81
2022-11-28 03:21:22,008 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4390989677472548, 'Total loss': 0.4390989677472548} | train loss {'Reaction outcome loss': 0.3227255390918985, 'Total loss': 0.3227255390918985}
2022-11-28 03:21:22,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:22,009 INFO:     Epoch: 82
2022-11-28 03:21:22,753 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4187282574447719, 'Total loss': 0.4187282574447719} | train loss {'Reaction outcome loss': 0.3224386041565817, 'Total loss': 0.3224386041565817}
2022-11-28 03:21:22,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:22,754 INFO:     Epoch: 83
2022-11-28 03:21:23,495 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3919301615519957, 'Total loss': 0.3919301615519957} | train loss {'Reaction outcome loss': 0.31052267785583226, 'Total loss': 0.31052267785583226}
2022-11-28 03:21:23,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:23,495 INFO:     Epoch: 84
2022-11-28 03:21:24,239 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4262547628446059, 'Total loss': 0.4262547628446059} | train loss {'Reaction outcome loss': 0.31077895918670967, 'Total loss': 0.31077895918670967}
2022-11-28 03:21:24,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:24,239 INFO:     Epoch: 85
2022-11-28 03:21:24,982 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4056640798437663, 'Total loss': 0.4056640798437663} | train loss {'Reaction outcome loss': 0.3086641260251707, 'Total loss': 0.3086641260251707}
2022-11-28 03:21:24,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:24,984 INFO:     Epoch: 86
2022-11-28 03:21:25,726 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4368380204859105, 'Total loss': 0.4368380204859105} | train loss {'Reaction outcome loss': 0.3109509196816658, 'Total loss': 0.3109509196816658}
2022-11-28 03:21:25,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:25,727 INFO:     Epoch: 87
2022-11-28 03:21:26,468 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3741587143052708, 'Total loss': 0.3741587143052708} | train loss {'Reaction outcome loss': 0.3149594033859214, 'Total loss': 0.3149594033859214}
2022-11-28 03:21:26,468 INFO:     Found new best model at epoch 87
2022-11-28 03:21:26,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:26,469 INFO:     Epoch: 88
2022-11-28 03:21:27,211 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4597547037357634, 'Total loss': 0.4597547037357634} | train loss {'Reaction outcome loss': 0.30513390250960176, 'Total loss': 0.30513390250960176}
2022-11-28 03:21:27,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:27,211 INFO:     Epoch: 89
2022-11-28 03:21:27,957 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42324867912314157, 'Total loss': 0.42324867912314157} | train loss {'Reaction outcome loss': 0.3115328965138416, 'Total loss': 0.3115328965138416}
2022-11-28 03:21:27,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:27,957 INFO:     Epoch: 90
2022-11-28 03:21:28,700 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40897122668949043, 'Total loss': 0.40897122668949043} | train loss {'Reaction outcome loss': 0.31165610640024655, 'Total loss': 0.31165610640024655}
2022-11-28 03:21:28,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:28,700 INFO:     Epoch: 91
2022-11-28 03:21:29,445 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3974193228747357, 'Total loss': 0.3974193228747357} | train loss {'Reaction outcome loss': 0.3238529526153389, 'Total loss': 0.3238529526153389}
2022-11-28 03:21:29,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:29,445 INFO:     Epoch: 92
2022-11-28 03:21:30,188 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44520827213471587, 'Total loss': 0.44520827213471587} | train loss {'Reaction outcome loss': 0.30730442794001833, 'Total loss': 0.30730442794001833}
2022-11-28 03:21:30,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:30,188 INFO:     Epoch: 93
2022-11-28 03:21:30,932 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4211296381598169, 'Total loss': 0.4211296381598169} | train loss {'Reaction outcome loss': 0.3070064575392373, 'Total loss': 0.3070064575392373}
2022-11-28 03:21:30,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:30,932 INFO:     Epoch: 94
2022-11-28 03:21:31,677 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42626757496459916, 'Total loss': 0.42626757496459916} | train loss {'Reaction outcome loss': 0.3013526283052503, 'Total loss': 0.3013526283052503}
2022-11-28 03:21:31,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:31,677 INFO:     Epoch: 95
2022-11-28 03:21:32,421 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41271530904553155, 'Total loss': 0.41271530904553155} | train loss {'Reaction outcome loss': 0.3188300917951428, 'Total loss': 0.3188300917951428}
2022-11-28 03:21:32,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:32,421 INFO:     Epoch: 96
2022-11-28 03:21:33,165 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41880166524259205, 'Total loss': 0.41880166524259205} | train loss {'Reaction outcome loss': 0.3051531670348985, 'Total loss': 0.3051531670348985}
2022-11-28 03:21:33,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:33,165 INFO:     Epoch: 97
2022-11-28 03:21:33,907 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4136615971272642, 'Total loss': 0.4136615971272642} | train loss {'Reaction outcome loss': 0.30701989142262204, 'Total loss': 0.30701989142262204}
2022-11-28 03:21:33,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:33,907 INFO:     Epoch: 98
2022-11-28 03:21:34,649 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.389823933893984, 'Total loss': 0.389823933893984} | train loss {'Reaction outcome loss': 0.3096035615217929, 'Total loss': 0.3096035615217929}
2022-11-28 03:21:34,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:34,649 INFO:     Epoch: 99
2022-11-28 03:21:35,393 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42790126326409256, 'Total loss': 0.42790126326409256} | train loss {'Reaction outcome loss': 0.3056411737994272, 'Total loss': 0.3056411737994272}
2022-11-28 03:21:35,393 INFO:     Best model found after epoch 88 of 100.
2022-11-28 03:21:35,394 INFO:   Done with stage: TRAINING
2022-11-28 03:21:35,394 INFO:   Starting stage: EVALUATION
2022-11-28 03:21:35,520 INFO:   Done with stage: EVALUATION
2022-11-28 03:21:35,521 INFO:   Leaving out SEQ value Fold_9
2022-11-28 03:21:35,533 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:21:35,534 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:21:36,182 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:21:36,183 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:21:36,252 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:21:36,252 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:21:36,252 INFO:     No hyperparam tuning for this model
2022-11-28 03:21:36,252 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:21:36,252 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:21:36,253 INFO:     None feature selector for col prot
2022-11-28 03:21:36,253 INFO:     None feature selector for col prot
2022-11-28 03:21:36,253 INFO:     None feature selector for col prot
2022-11-28 03:21:36,253 INFO:     None feature selector for col chem
2022-11-28 03:21:36,254 INFO:     None feature selector for col chem
2022-11-28 03:21:36,254 INFO:     None feature selector for col chem
2022-11-28 03:21:36,254 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:21:36,254 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:21:36,255 INFO:     Number of params in model 169741
2022-11-28 03:21:36,258 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:21:36,259 INFO:   Starting stage: TRAINING
2022-11-28 03:21:36,313 INFO:     Val loss before train {'Reaction outcome loss': 1.0241905464367433, 'Total loss': 1.0241905464367433}
2022-11-28 03:21:36,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:36,314 INFO:     Epoch: 0
2022-11-28 03:21:37,067 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5656799724833532, 'Total loss': 0.5656799724833532} | train loss {'Reaction outcome loss': 0.6269452872305263, 'Total loss': 0.6269452872305263}
2022-11-28 03:21:37,067 INFO:     Found new best model at epoch 0
2022-11-28 03:21:37,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:37,068 INFO:     Epoch: 1
2022-11-28 03:21:37,813 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5294517194005576, 'Total loss': 0.5294517194005576} | train loss {'Reaction outcome loss': 0.4916227161884308, 'Total loss': 0.4916227161884308}
2022-11-28 03:21:37,814 INFO:     Found new best model at epoch 1
2022-11-28 03:21:37,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:37,814 INFO:     Epoch: 2
2022-11-28 03:21:38,566 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.508265958590941, 'Total loss': 0.508265958590941} | train loss {'Reaction outcome loss': 0.44257842156628846, 'Total loss': 0.44257842156628846}
2022-11-28 03:21:38,566 INFO:     Found new best model at epoch 2
2022-11-28 03:21:38,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:38,567 INFO:     Epoch: 3
2022-11-28 03:21:39,317 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5101548392664302, 'Total loss': 0.5101548392664302} | train loss {'Reaction outcome loss': 0.4309588090369576, 'Total loss': 0.4309588090369576}
2022-11-28 03:21:39,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:39,317 INFO:     Epoch: 4
2022-11-28 03:21:40,070 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5270083756609396, 'Total loss': 0.5270083756609396} | train loss {'Reaction outcome loss': 0.416923111327264, 'Total loss': 0.416923111327264}
2022-11-28 03:21:40,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:40,070 INFO:     Epoch: 5
2022-11-28 03:21:40,821 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49598237533460965, 'Total loss': 0.49598237533460965} | train loss {'Reaction outcome loss': 0.4081555888177412, 'Total loss': 0.4081555888177412}
2022-11-28 03:21:40,822 INFO:     Found new best model at epoch 5
2022-11-28 03:21:40,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:40,822 INFO:     Epoch: 6
2022-11-28 03:21:41,574 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5462565703148191, 'Total loss': 0.5462565703148191} | train loss {'Reaction outcome loss': 0.39066431909678917, 'Total loss': 0.39066431909678917}
2022-11-28 03:21:41,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:41,574 INFO:     Epoch: 7
2022-11-28 03:21:42,325 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5513824095780199, 'Total loss': 0.5513824095780199} | train loss {'Reaction outcome loss': 0.3939968278171562, 'Total loss': 0.3939968278171562}
2022-11-28 03:21:42,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:42,325 INFO:     Epoch: 8
2022-11-28 03:21:43,077 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5093039192936637, 'Total loss': 0.5093039192936637} | train loss {'Reaction outcome loss': 0.384868748274892, 'Total loss': 0.384868748274892}
2022-11-28 03:21:43,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:43,077 INFO:     Epoch: 9
2022-11-28 03:21:43,828 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48554508286443626, 'Total loss': 0.48554508286443626} | train loss {'Reaction outcome loss': 0.3707547448424675, 'Total loss': 0.3707547448424675}
2022-11-28 03:21:43,828 INFO:     Found new best model at epoch 9
2022-11-28 03:21:43,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:43,829 INFO:     Epoch: 10
2022-11-28 03:21:44,580 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4841406975280155, 'Total loss': 0.4841406975280155} | train loss {'Reaction outcome loss': 0.367608688907464, 'Total loss': 0.367608688907464}
2022-11-28 03:21:44,580 INFO:     Found new best model at epoch 10
2022-11-28 03:21:44,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:44,581 INFO:     Epoch: 11
2022-11-28 03:21:45,327 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4651547125117345, 'Total loss': 0.4651547125117345} | train loss {'Reaction outcome loss': 0.3636471375611871, 'Total loss': 0.3636471375611871}
2022-11-28 03:21:45,327 INFO:     Found new best model at epoch 11
2022-11-28 03:21:45,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:45,328 INFO:     Epoch: 12
2022-11-28 03:21:46,078 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48108502240343526, 'Total loss': 0.48108502240343526} | train loss {'Reaction outcome loss': 0.36028280878356594, 'Total loss': 0.36028280878356594}
2022-11-28 03:21:46,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:46,078 INFO:     Epoch: 13
2022-11-28 03:21:46,827 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49128505248915066, 'Total loss': 0.49128505248915066} | train loss {'Reaction outcome loss': 0.37219584994168897, 'Total loss': 0.37219584994168897}
2022-11-28 03:21:46,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:46,828 INFO:     Epoch: 14
2022-11-28 03:21:47,578 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4653084437278184, 'Total loss': 0.4653084437278184} | train loss {'Reaction outcome loss': 0.3500798427375403, 'Total loss': 0.3500798427375403}
2022-11-28 03:21:47,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:47,578 INFO:     Epoch: 15
2022-11-28 03:21:48,326 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4986176633022048, 'Total loss': 0.4986176633022048} | train loss {'Reaction outcome loss': 0.3447315609949803, 'Total loss': 0.3447315609949803}
2022-11-28 03:21:48,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:48,326 INFO:     Epoch: 16
2022-11-28 03:21:49,074 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5267368321391669, 'Total loss': 0.5267368321391669} | train loss {'Reaction outcome loss': 0.35164432257775835, 'Total loss': 0.35164432257775835}
2022-11-28 03:21:49,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:49,074 INFO:     Epoch: 17
2022-11-28 03:21:49,818 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4740869304673238, 'Total loss': 0.4740869304673238} | train loss {'Reaction outcome loss': 0.3493176666107255, 'Total loss': 0.3493176666107255}
2022-11-28 03:21:49,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:49,818 INFO:     Epoch: 18
2022-11-28 03:21:50,569 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49403683604164556, 'Total loss': 0.49403683604164556} | train loss {'Reaction outcome loss': 0.34315675976667326, 'Total loss': 0.34315675976667326}
2022-11-28 03:21:50,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:50,569 INFO:     Epoch: 19
2022-11-28 03:21:51,321 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5017277322370898, 'Total loss': 0.5017277322370898} | train loss {'Reaction outcome loss': 0.3343757285938225, 'Total loss': 0.3343757285938225}
2022-11-28 03:21:51,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:51,322 INFO:     Epoch: 20
2022-11-28 03:21:52,077 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4671774787658995, 'Total loss': 0.4671774787658995} | train loss {'Reaction outcome loss': 0.3345290353966628, 'Total loss': 0.3345290353966628}
2022-11-28 03:21:52,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:52,077 INFO:     Epoch: 21
2022-11-28 03:21:52,827 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4766015647487207, 'Total loss': 0.4766015647487207} | train loss {'Reaction outcome loss': 0.3433928971408832, 'Total loss': 0.3433928971408832}
2022-11-28 03:21:52,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:52,827 INFO:     Epoch: 22
2022-11-28 03:21:53,578 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.508632783185352, 'Total loss': 0.508632783185352} | train loss {'Reaction outcome loss': 0.3371626677723066, 'Total loss': 0.3371626677723066}
2022-11-28 03:21:53,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:53,578 INFO:     Epoch: 23
2022-11-28 03:21:54,331 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5050172348591414, 'Total loss': 0.5050172348591414} | train loss {'Reaction outcome loss': 0.3383961022164115, 'Total loss': 0.3383961022164115}
2022-11-28 03:21:54,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:54,331 INFO:     Epoch: 24
2022-11-28 03:21:55,085 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5165066190741279, 'Total loss': 0.5165066190741279} | train loss {'Reaction outcome loss': 0.32575236159840576, 'Total loss': 0.32575236159840576}
2022-11-28 03:21:55,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:55,085 INFO:     Epoch: 25
2022-11-28 03:21:55,835 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47885497015985573, 'Total loss': 0.47885497015985573} | train loss {'Reaction outcome loss': 0.3541280649572249, 'Total loss': 0.3541280649572249}
2022-11-28 03:21:55,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:55,836 INFO:     Epoch: 26
2022-11-28 03:21:56,589 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48019839044321666, 'Total loss': 0.48019839044321666} | train loss {'Reaction outcome loss': 0.32358839975949, 'Total loss': 0.32358839975949}
2022-11-28 03:21:56,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:56,589 INFO:     Epoch: 27
2022-11-28 03:21:57,339 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47878575189547107, 'Total loss': 0.47878575189547107} | train loss {'Reaction outcome loss': 0.33209362375712104, 'Total loss': 0.33209362375712104}
2022-11-28 03:21:57,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:57,339 INFO:     Epoch: 28
2022-11-28 03:21:58,090 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47493392533876677, 'Total loss': 0.47493392533876677} | train loss {'Reaction outcome loss': 0.31958726795978454, 'Total loss': 0.31958726795978454}
2022-11-28 03:21:58,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:58,091 INFO:     Epoch: 29
2022-11-28 03:21:58,835 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4996436502445828, 'Total loss': 0.4996436502445828} | train loss {'Reaction outcome loss': 0.3153730074418822, 'Total loss': 0.3153730074418822}
2022-11-28 03:21:58,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:58,835 INFO:     Epoch: 30
2022-11-28 03:21:59,582 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5093156532807783, 'Total loss': 0.5093156532807783} | train loss {'Reaction outcome loss': 0.32105778667487594, 'Total loss': 0.32105778667487594}
2022-11-28 03:21:59,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:21:59,582 INFO:     Epoch: 31
2022-11-28 03:22:00,328 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4953004450283267, 'Total loss': 0.4953004450283267} | train loss {'Reaction outcome loss': 0.3281314226870353, 'Total loss': 0.3281314226870353}
2022-11-28 03:22:00,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:00,328 INFO:     Epoch: 32
2022-11-28 03:22:01,077 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4958744943141937, 'Total loss': 0.4958744943141937} | train loss {'Reaction outcome loss': 0.3277620017407877, 'Total loss': 0.3277620017407877}
2022-11-28 03:22:01,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:01,077 INFO:     Epoch: 33
2022-11-28 03:22:01,825 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5216222261501984, 'Total loss': 0.5216222261501984} | train loss {'Reaction outcome loss': 0.3185385754897527, 'Total loss': 0.3185385754897527}
2022-11-28 03:22:01,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:01,825 INFO:     Epoch: 34
2022-11-28 03:22:02,574 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48414616083556955, 'Total loss': 0.48414616083556955} | train loss {'Reaction outcome loss': 0.33988844097058407, 'Total loss': 0.33988844097058407}
2022-11-28 03:22:02,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:02,575 INFO:     Epoch: 35
2022-11-28 03:22:03,323 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48247581110759213, 'Total loss': 0.48247581110759213} | train loss {'Reaction outcome loss': 0.3121915679605987, 'Total loss': 0.3121915679605987}
2022-11-28 03:22:03,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:03,323 INFO:     Epoch: 36
2022-11-28 03:22:04,071 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47059006142345344, 'Total loss': 0.47059006142345344} | train loss {'Reaction outcome loss': 0.3142345931139673, 'Total loss': 0.3142345931139673}
2022-11-28 03:22:04,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:04,071 INFO:     Epoch: 37
2022-11-28 03:22:04,817 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47243276780301874, 'Total loss': 0.47243276780301874} | train loss {'Reaction outcome loss': 0.3078700859469139, 'Total loss': 0.3078700859469139}
2022-11-28 03:22:04,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:04,818 INFO:     Epoch: 38
2022-11-28 03:22:05,564 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49663798544894566, 'Total loss': 0.49663798544894566} | train loss {'Reaction outcome loss': 0.31048839192400096, 'Total loss': 0.31048839192400096}
2022-11-28 03:22:05,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:05,564 INFO:     Epoch: 39
2022-11-28 03:22:06,310 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4700196964496916, 'Total loss': 0.4700196964496916} | train loss {'Reaction outcome loss': 0.30429895495173903, 'Total loss': 0.30429895495173903}
2022-11-28 03:22:06,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:06,311 INFO:     Epoch: 40
2022-11-28 03:22:07,059 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5186036025935953, 'Total loss': 0.5186036025935953} | train loss {'Reaction outcome loss': 0.31189702053060414, 'Total loss': 0.31189702053060414}
2022-11-28 03:22:07,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:07,060 INFO:     Epoch: 41
2022-11-28 03:22:07,809 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47193983976136555, 'Total loss': 0.47193983976136555} | train loss {'Reaction outcome loss': 0.32401068644364356, 'Total loss': 0.32401068644364356}
2022-11-28 03:22:07,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:07,809 INFO:     Epoch: 42
2022-11-28 03:22:08,557 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4838393445719372, 'Total loss': 0.4838393445719372} | train loss {'Reaction outcome loss': 0.3118296994371453, 'Total loss': 0.3118296994371453}
2022-11-28 03:22:08,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:08,558 INFO:     Epoch: 43
2022-11-28 03:22:09,304 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.463260726664554, 'Total loss': 0.463260726664554} | train loss {'Reaction outcome loss': 0.33222487870498224, 'Total loss': 0.33222487870498224}
2022-11-28 03:22:09,304 INFO:     Found new best model at epoch 43
2022-11-28 03:22:09,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:09,305 INFO:     Epoch: 44
2022-11-28 03:22:10,052 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5064817368984222, 'Total loss': 0.5064817368984222} | train loss {'Reaction outcome loss': 0.31555232357399665, 'Total loss': 0.31555232357399665}
2022-11-28 03:22:10,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:10,052 INFO:     Epoch: 45
2022-11-28 03:22:10,801 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5142038559371774, 'Total loss': 0.5142038559371774} | train loss {'Reaction outcome loss': 0.3150672759966329, 'Total loss': 0.3150672759966329}
2022-11-28 03:22:10,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:10,802 INFO:     Epoch: 46
2022-11-28 03:22:11,554 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4819978360425342, 'Total loss': 0.4819978360425342} | train loss {'Reaction outcome loss': 0.326403860500467, 'Total loss': 0.326403860500467}
2022-11-28 03:22:11,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:11,555 INFO:     Epoch: 47
2022-11-28 03:22:12,305 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47725446589968423, 'Total loss': 0.47725446589968423} | train loss {'Reaction outcome loss': 0.3180021290414729, 'Total loss': 0.3180021290414729}
2022-11-28 03:22:12,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:12,305 INFO:     Epoch: 48
2022-11-28 03:22:13,055 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49689723043279216, 'Total loss': 0.49689723043279216} | train loss {'Reaction outcome loss': 0.3104931178845857, 'Total loss': 0.3104931178845857}
2022-11-28 03:22:13,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:13,055 INFO:     Epoch: 49
2022-11-28 03:22:13,805 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5108269205824896, 'Total loss': 0.5108269205824896} | train loss {'Reaction outcome loss': 0.32439556621346877, 'Total loss': 0.32439556621346877}
2022-11-28 03:22:13,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:13,805 INFO:     Epoch: 50
2022-11-28 03:22:14,555 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.489643667909232, 'Total loss': 0.489643667909232} | train loss {'Reaction outcome loss': 0.3338010821204919, 'Total loss': 0.3338010821204919}
2022-11-28 03:22:14,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:14,556 INFO:     Epoch: 51
2022-11-28 03:22:15,305 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46438704363324423, 'Total loss': 0.46438704363324423} | train loss {'Reaction outcome loss': 0.3112211435852263, 'Total loss': 0.3112211435852263}
2022-11-28 03:22:15,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:15,306 INFO:     Epoch: 52
2022-11-28 03:22:16,055 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4794047266583551, 'Total loss': 0.4794047266583551} | train loss {'Reaction outcome loss': 0.31249311174217026, 'Total loss': 0.31249311174217026}
2022-11-28 03:22:16,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:16,055 INFO:     Epoch: 53
2022-11-28 03:22:16,801 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4975593621757897, 'Total loss': 0.4975593621757897} | train loss {'Reaction outcome loss': 0.30317873287538766, 'Total loss': 0.30317873287538766}
2022-11-28 03:22:16,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:16,802 INFO:     Epoch: 54
2022-11-28 03:22:17,552 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47891509194265713, 'Total loss': 0.47891509194265713} | train loss {'Reaction outcome loss': 0.30476893024586954, 'Total loss': 0.30476893024586954}
2022-11-28 03:22:17,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:17,552 INFO:     Epoch: 55
2022-11-28 03:22:18,298 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5187501529739662, 'Total loss': 0.5187501529739662} | train loss {'Reaction outcome loss': 0.31879706982417627, 'Total loss': 0.31879706982417627}
2022-11-28 03:22:18,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:18,298 INFO:     Epoch: 56
2022-11-28 03:22:19,047 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4853688773106445, 'Total loss': 0.4853688773106445} | train loss {'Reaction outcome loss': 0.33510760127412165, 'Total loss': 0.33510760127412165}
2022-11-28 03:22:19,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:19,047 INFO:     Epoch: 57
2022-11-28 03:22:19,793 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5003218677910891, 'Total loss': 0.5003218677910891} | train loss {'Reaction outcome loss': 0.2962458561304655, 'Total loss': 0.2962458561304655}
2022-11-28 03:22:19,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:19,793 INFO:     Epoch: 58
2022-11-28 03:22:20,540 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5008289424533193, 'Total loss': 0.5008289424533193} | train loss {'Reaction outcome loss': 0.29521165100427776, 'Total loss': 0.29521165100427776}
2022-11-28 03:22:20,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:20,540 INFO:     Epoch: 59
2022-11-28 03:22:21,289 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4892297065393491, 'Total loss': 0.4892297065393491} | train loss {'Reaction outcome loss': 0.3026703820235816, 'Total loss': 0.3026703820235816}
2022-11-28 03:22:21,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:21,289 INFO:     Epoch: 60
2022-11-28 03:22:22,038 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49468676847490395, 'Total loss': 0.49468676847490395} | train loss {'Reaction outcome loss': 0.3046002097518338, 'Total loss': 0.3046002097518338}
2022-11-28 03:22:22,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:22,038 INFO:     Epoch: 61
2022-11-28 03:22:22,785 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4755224497480826, 'Total loss': 0.4755224497480826} | train loss {'Reaction outcome loss': 0.3275601929543834, 'Total loss': 0.3275601929543834}
2022-11-28 03:22:22,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:22,785 INFO:     Epoch: 62
2022-11-28 03:22:23,532 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49768379229036247, 'Total loss': 0.49768379229036247} | train loss {'Reaction outcome loss': 0.29939553229070387, 'Total loss': 0.29939553229070387}
2022-11-28 03:22:23,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:23,532 INFO:     Epoch: 63
2022-11-28 03:22:24,279 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4538834924724969, 'Total loss': 0.4538834924724969} | train loss {'Reaction outcome loss': 0.313579643182909, 'Total loss': 0.313579643182909}
2022-11-28 03:22:24,279 INFO:     Found new best model at epoch 63
2022-11-28 03:22:24,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:24,280 INFO:     Epoch: 64
2022-11-28 03:22:25,027 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5147561747580767, 'Total loss': 0.5147561747580767} | train loss {'Reaction outcome loss': 0.31205987199190777, 'Total loss': 0.31205987199190777}
2022-11-28 03:22:25,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:25,027 INFO:     Epoch: 65
2022-11-28 03:22:25,773 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4922649772329764, 'Total loss': 0.4922649772329764} | train loss {'Reaction outcome loss': 0.29258073312852545, 'Total loss': 0.29258073312852545}
2022-11-28 03:22:25,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:25,773 INFO:     Epoch: 66
2022-11-28 03:22:26,519 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4929423647170717, 'Total loss': 0.4929423647170717} | train loss {'Reaction outcome loss': 0.2997383036488584, 'Total loss': 0.2997383036488584}
2022-11-28 03:22:26,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:26,519 INFO:     Epoch: 67
2022-11-28 03:22:27,267 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49897636236114934, 'Total loss': 0.49897636236114934} | train loss {'Reaction outcome loss': 0.3048577080612723, 'Total loss': 0.3048577080612723}
2022-11-28 03:22:27,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:27,269 INFO:     Epoch: 68
2022-11-28 03:22:28,020 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4913626831363548, 'Total loss': 0.4913626831363548} | train loss {'Reaction outcome loss': 0.31078965838683714, 'Total loss': 0.31078965838683714}
2022-11-28 03:22:28,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:28,020 INFO:     Epoch: 69
2022-11-28 03:22:28,771 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47063188966025005, 'Total loss': 0.47063188966025005} | train loss {'Reaction outcome loss': 0.298501776870687, 'Total loss': 0.298501776870687}
2022-11-28 03:22:28,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:28,771 INFO:     Epoch: 70
2022-11-28 03:22:29,517 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.491889340295033, 'Total loss': 0.491889340295033} | train loss {'Reaction outcome loss': 0.3180021499453286, 'Total loss': 0.3180021499453286}
2022-11-28 03:22:29,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:29,518 INFO:     Epoch: 71
2022-11-28 03:22:30,265 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.492455067621036, 'Total loss': 0.492455067621036} | train loss {'Reaction outcome loss': 0.30570314621349215, 'Total loss': 0.30570314621349215}
2022-11-28 03:22:30,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:30,266 INFO:     Epoch: 72
2022-11-28 03:22:31,013 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5132778405465863, 'Total loss': 0.5132778405465863} | train loss {'Reaction outcome loss': 0.30633360812598875, 'Total loss': 0.30633360812598875}
2022-11-28 03:22:31,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:31,013 INFO:     Epoch: 73
2022-11-28 03:22:31,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5165775844996626, 'Total loss': 0.5165775844996626} | train loss {'Reaction outcome loss': 0.30033448890515185, 'Total loss': 0.30033448890515185}
2022-11-28 03:22:31,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:31,758 INFO:     Epoch: 74
2022-11-28 03:22:32,503 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46877458082004025, 'Total loss': 0.46877458082004025} | train loss {'Reaction outcome loss': 0.31563993383515704, 'Total loss': 0.31563993383515704}
2022-11-28 03:22:32,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:32,503 INFO:     Epoch: 75
2022-11-28 03:22:33,249 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47492745044556534, 'Total loss': 0.47492745044556534} | train loss {'Reaction outcome loss': 0.3010570859981452, 'Total loss': 0.3010570859981452}
2022-11-28 03:22:33,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:33,250 INFO:     Epoch: 76
2022-11-28 03:22:33,990 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49151792377233505, 'Total loss': 0.49151792377233505} | train loss {'Reaction outcome loss': 0.3000029944531951, 'Total loss': 0.3000029944531951}
2022-11-28 03:22:33,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:33,991 INFO:     Epoch: 77
2022-11-28 03:22:34,736 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4874460588801991, 'Total loss': 0.4874460588801991} | train loss {'Reaction outcome loss': 0.2974566092737291, 'Total loss': 0.2974566092737291}
2022-11-28 03:22:34,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:34,737 INFO:     Epoch: 78
2022-11-28 03:22:35,477 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5312073799696836, 'Total loss': 0.5312073799696836} | train loss {'Reaction outcome loss': 0.3106416325548641, 'Total loss': 0.3106416325548641}
2022-11-28 03:22:35,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:35,478 INFO:     Epoch: 79
2022-11-28 03:22:36,222 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48868086663159455, 'Total loss': 0.48868086663159455} | train loss {'Reaction outcome loss': 0.3101641499863462, 'Total loss': 0.3101641499863462}
2022-11-28 03:22:36,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:36,223 INFO:     Epoch: 80
2022-11-28 03:22:36,967 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4789361540566791, 'Total loss': 0.4789361540566791} | train loss {'Reaction outcome loss': 0.3193373376360306, 'Total loss': 0.3193373376360306}
2022-11-28 03:22:36,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:36,967 INFO:     Epoch: 81
2022-11-28 03:22:37,710 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4678360665725036, 'Total loss': 0.4678360665725036} | train loss {'Reaction outcome loss': 0.3068633970003509, 'Total loss': 0.3068633970003509}
2022-11-28 03:22:37,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:37,710 INFO:     Epoch: 82
2022-11-28 03:22:38,454 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5031517578119581, 'Total loss': 0.5031517578119581} | train loss {'Reaction outcome loss': 0.30699767074302625, 'Total loss': 0.30699767074302625}
2022-11-28 03:22:38,454 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:38,454 INFO:     Epoch: 83
2022-11-28 03:22:39,195 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4968638000163165, 'Total loss': 0.4968638000163165} | train loss {'Reaction outcome loss': 0.29957796173238077, 'Total loss': 0.29957796173238077}
2022-11-28 03:22:39,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:39,196 INFO:     Epoch: 84
2022-11-28 03:22:39,938 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.485825563357635, 'Total loss': 0.485825563357635} | train loss {'Reaction outcome loss': 0.29411599397478316, 'Total loss': 0.29411599397478316}
2022-11-28 03:22:39,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:39,938 INFO:     Epoch: 85
2022-11-28 03:22:40,680 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48557249016382475, 'Total loss': 0.48557249016382475} | train loss {'Reaction outcome loss': 0.3028904803489384, 'Total loss': 0.3028904803489384}
2022-11-28 03:22:40,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:40,680 INFO:     Epoch: 86
2022-11-28 03:22:41,422 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47943376952951605, 'Total loss': 0.47943376952951605} | train loss {'Reaction outcome loss': 0.3050722197034709, 'Total loss': 0.3050722197034709}
2022-11-28 03:22:41,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:41,422 INFO:     Epoch: 87
2022-11-28 03:22:42,162 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4651502733203498, 'Total loss': 0.4651502733203498} | train loss {'Reaction outcome loss': 0.30091714497037264, 'Total loss': 0.30091714497037264}
2022-11-28 03:22:42,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:42,162 INFO:     Epoch: 88
2022-11-28 03:22:42,901 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.465421588583426, 'Total loss': 0.465421588583426} | train loss {'Reaction outcome loss': 0.3013240152344047, 'Total loss': 0.3013240152344047}
2022-11-28 03:22:42,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:42,901 INFO:     Epoch: 89
2022-11-28 03:22:43,642 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45720462230118836, 'Total loss': 0.45720462230118836} | train loss {'Reaction outcome loss': 0.29393395537186245, 'Total loss': 0.29393395537186245}
2022-11-28 03:22:43,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:43,642 INFO:     Epoch: 90
2022-11-28 03:22:44,384 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45963743464513257, 'Total loss': 0.45963743464513257} | train loss {'Reaction outcome loss': 0.29873393755606453, 'Total loss': 0.29873393755606453}
2022-11-28 03:22:44,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:44,384 INFO:     Epoch: 91
2022-11-28 03:22:45,127 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4844257130541585, 'Total loss': 0.4844257130541585} | train loss {'Reaction outcome loss': 0.2870472681063872, 'Total loss': 0.2870472681063872}
2022-11-28 03:22:45,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:45,127 INFO:     Epoch: 92
2022-11-28 03:22:45,869 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4977064176716588, 'Total loss': 0.4977064176716588} | train loss {'Reaction outcome loss': 0.30087428645566405, 'Total loss': 0.30087428645566405}
2022-11-28 03:22:45,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:45,869 INFO:     Epoch: 93
2022-11-28 03:22:46,611 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49046146937391977, 'Total loss': 0.49046146937391977} | train loss {'Reaction outcome loss': 0.2899405522204121, 'Total loss': 0.2899405522204121}
2022-11-28 03:22:46,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:46,612 INFO:     Epoch: 94
2022-11-28 03:22:47,354 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5084717913784764, 'Total loss': 0.5084717913784764} | train loss {'Reaction outcome loss': 0.3069488196633756, 'Total loss': 0.3069488196633756}
2022-11-28 03:22:47,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:47,354 INFO:     Epoch: 95
2022-11-28 03:22:48,096 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5070154578848318, 'Total loss': 0.5070154578848318} | train loss {'Reaction outcome loss': 0.30180365534929127, 'Total loss': 0.30180365534929127}
2022-11-28 03:22:48,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:48,096 INFO:     Epoch: 96
2022-11-28 03:22:48,837 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46683078564026137, 'Total loss': 0.46683078564026137} | train loss {'Reaction outcome loss': 0.31557019994531, 'Total loss': 0.31557019994531}
2022-11-28 03:22:48,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:48,838 INFO:     Epoch: 97
2022-11-28 03:22:49,578 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4611265381628817, 'Total loss': 0.4611265381628817} | train loss {'Reaction outcome loss': 0.29428652901700153, 'Total loss': 0.29428652901700153}
2022-11-28 03:22:49,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:49,579 INFO:     Epoch: 98
2022-11-28 03:22:50,322 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4890049242160537, 'Total loss': 0.4890049242160537} | train loss {'Reaction outcome loss': 0.31107782442801396, 'Total loss': 0.31107782442801396}
2022-11-28 03:22:50,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:50,322 INFO:     Epoch: 99
2022-11-28 03:22:51,064 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5014966011724689, 'Total loss': 0.5014966011724689} | train loss {'Reaction outcome loss': 0.32040803417985736, 'Total loss': 0.32040803417985736}
2022-11-28 03:22:51,064 INFO:     Best model found after epoch 64 of 100.
2022-11-28 03:22:51,065 INFO:   Done with stage: TRAINING
2022-11-28 03:22:51,065 INFO:   Starting stage: EVALUATION
2022-11-28 03:22:51,187 INFO:   Done with stage: EVALUATION
2022-11-28 03:22:51,196 INFO:   Leaving out SEQ value Fold_0
2022-11-28 03:22:51,209 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 03:22:51,209 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:22:51,840 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:22:51,840 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:22:51,907 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:22:51,908 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:22:51,908 INFO:     No hyperparam tuning for this model
2022-11-28 03:22:51,908 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:22:51,908 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:22:51,908 INFO:     None feature selector for col prot
2022-11-28 03:22:51,909 INFO:     None feature selector for col prot
2022-11-28 03:22:51,909 INFO:     None feature selector for col prot
2022-11-28 03:22:51,909 INFO:     None feature selector for col chem
2022-11-28 03:22:51,909 INFO:     None feature selector for col chem
2022-11-28 03:22:51,909 INFO:     None feature selector for col chem
2022-11-28 03:22:51,909 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:22:51,909 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:22:51,911 INFO:     Number of params in model 169741
2022-11-28 03:22:51,914 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:22:51,914 INFO:   Starting stage: TRAINING
2022-11-28 03:22:51,965 INFO:     Val loss before train {'Reaction outcome loss': 0.9991931818252386, 'Total loss': 0.9991931818252386}
2022-11-28 03:22:51,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:51,966 INFO:     Epoch: 0
2022-11-28 03:22:52,695 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5387890210678411, 'Total loss': 0.5387890210678411} | train loss {'Reaction outcome loss': 0.6298198622685892, 'Total loss': 0.6298198622685892}
2022-11-28 03:22:52,695 INFO:     Found new best model at epoch 0
2022-11-28 03:22:52,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:52,696 INFO:     Epoch: 1
2022-11-28 03:22:53,427 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4902429310388343, 'Total loss': 0.4902429310388343} | train loss {'Reaction outcome loss': 0.48472057672317137, 'Total loss': 0.48472057672317137}
2022-11-28 03:22:53,427 INFO:     Found new best model at epoch 1
2022-11-28 03:22:53,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:53,428 INFO:     Epoch: 2
2022-11-28 03:22:54,157 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5000759605751481, 'Total loss': 0.5000759605751481} | train loss {'Reaction outcome loss': 0.4435142091027013, 'Total loss': 0.4435142091027013}
2022-11-28 03:22:54,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:54,158 INFO:     Epoch: 3
2022-11-28 03:22:54,889 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4877547871234805, 'Total loss': 0.4877547871234805} | train loss {'Reaction outcome loss': 0.4303625552251996, 'Total loss': 0.4303625552251996}
2022-11-28 03:22:54,890 INFO:     Found new best model at epoch 3
2022-11-28 03:22:54,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:54,890 INFO:     Epoch: 4
2022-11-28 03:22:55,620 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4568333102520122, 'Total loss': 0.4568333102520122} | train loss {'Reaction outcome loss': 0.41599150253421485, 'Total loss': 0.41599150253421485}
2022-11-28 03:22:55,620 INFO:     Found new best model at epoch 4
2022-11-28 03:22:55,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:55,621 INFO:     Epoch: 5
2022-11-28 03:22:56,350 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4658909204394318, 'Total loss': 0.4658909204394318} | train loss {'Reaction outcome loss': 0.39921905909791405, 'Total loss': 0.39921905909791405}
2022-11-28 03:22:56,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:56,350 INFO:     Epoch: 6
2022-11-28 03:22:57,077 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49967018705467847, 'Total loss': 0.49967018705467847} | train loss {'Reaction outcome loss': 0.3888217194519416, 'Total loss': 0.3888217194519416}
2022-11-28 03:22:57,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:57,078 INFO:     Epoch: 7
2022-11-28 03:22:57,808 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48221732572067616, 'Total loss': 0.48221732572067616} | train loss {'Reaction outcome loss': 0.38171831601195866, 'Total loss': 0.38171831601195866}
2022-11-28 03:22:57,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:57,808 INFO:     Epoch: 8
2022-11-28 03:22:58,537 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4339860695046048, 'Total loss': 0.4339860695046048} | train loss {'Reaction outcome loss': 0.38216274988994675, 'Total loss': 0.38216274988994675}
2022-11-28 03:22:58,538 INFO:     Found new best model at epoch 8
2022-11-28 03:22:58,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:58,539 INFO:     Epoch: 9
2022-11-28 03:22:59,269 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4210604086171749, 'Total loss': 0.4210604086171749} | train loss {'Reaction outcome loss': 0.37995591428544784, 'Total loss': 0.37995591428544784}
2022-11-28 03:22:59,269 INFO:     Found new best model at epoch 9
2022-11-28 03:22:59,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:22:59,270 INFO:     Epoch: 10
2022-11-28 03:23:00,002 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45601578957812733, 'Total loss': 0.45601578957812733} | train loss {'Reaction outcome loss': 0.37097063942701236, 'Total loss': 0.37097063942701236}
2022-11-28 03:23:00,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:00,003 INFO:     Epoch: 11
2022-11-28 03:23:00,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4344087759422701, 'Total loss': 0.4344087759422701} | train loss {'Reaction outcome loss': 0.35952824596392274, 'Total loss': 0.35952824596392274}
2022-11-28 03:23:00,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:00,735 INFO:     Epoch: 12
2022-11-28 03:23:01,467 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5094442935877068, 'Total loss': 0.5094442935877068} | train loss {'Reaction outcome loss': 0.3596238329883956, 'Total loss': 0.3596238329883956}
2022-11-28 03:23:01,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:01,468 INFO:     Epoch: 13
2022-11-28 03:23:02,202 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43188887349394867, 'Total loss': 0.43188887349394867} | train loss {'Reaction outcome loss': 0.3531880591509273, 'Total loss': 0.3531880591509273}
2022-11-28 03:23:02,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:02,202 INFO:     Epoch: 14
2022-11-28 03:23:02,933 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4356591053480326, 'Total loss': 0.4356591053480326} | train loss {'Reaction outcome loss': 0.35960737125250536, 'Total loss': 0.35960737125250536}
2022-11-28 03:23:02,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:02,933 INFO:     Epoch: 15
2022-11-28 03:23:03,666 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4335206934185915, 'Total loss': 0.4335206934185915} | train loss {'Reaction outcome loss': 0.34688675627418997, 'Total loss': 0.34688675627418997}
2022-11-28 03:23:03,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:03,666 INFO:     Epoch: 16
2022-11-28 03:23:04,398 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4498908904402755, 'Total loss': 0.4498908904402755} | train loss {'Reaction outcome loss': 0.34598985343496985, 'Total loss': 0.34598985343496985}
2022-11-28 03:23:04,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:04,398 INFO:     Epoch: 17
2022-11-28 03:23:05,131 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4213907139938931, 'Total loss': 0.4213907139938931} | train loss {'Reaction outcome loss': 0.35033456711366834, 'Total loss': 0.35033456711366834}
2022-11-28 03:23:05,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:05,132 INFO:     Epoch: 18
2022-11-28 03:23:05,862 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4930252377377, 'Total loss': 0.4930252377377} | train loss {'Reaction outcome loss': 0.3380821691251095, 'Total loss': 0.3380821691251095}
2022-11-28 03:23:05,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:05,862 INFO:     Epoch: 19
2022-11-28 03:23:06,594 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.458864196788433, 'Total loss': 0.458864196788433} | train loss {'Reaction outcome loss': 0.33986853227141955, 'Total loss': 0.33986853227141955}
2022-11-28 03:23:06,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:06,594 INFO:     Epoch: 20
2022-11-28 03:23:07,326 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42583339228186495, 'Total loss': 0.42583339228186495} | train loss {'Reaction outcome loss': 0.3352139028011526, 'Total loss': 0.3352139028011526}
2022-11-28 03:23:07,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:07,326 INFO:     Epoch: 21
2022-11-28 03:23:08,059 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4180134035820185, 'Total loss': 0.4180134035820185} | train loss {'Reaction outcome loss': 0.33842568783235155, 'Total loss': 0.33842568783235155}
2022-11-28 03:23:08,060 INFO:     Found new best model at epoch 21
2022-11-28 03:23:08,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:08,060 INFO:     Epoch: 22
2022-11-28 03:23:08,790 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43488425432249556, 'Total loss': 0.43488425432249556} | train loss {'Reaction outcome loss': 0.3373312336151247, 'Total loss': 0.3373312336151247}
2022-11-28 03:23:08,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:08,791 INFO:     Epoch: 23
2022-11-28 03:23:09,519 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4345418516286584, 'Total loss': 0.4345418516286584} | train loss {'Reaction outcome loss': 0.3253691508875462, 'Total loss': 0.3253691508875462}
2022-11-28 03:23:09,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:09,520 INFO:     Epoch: 24
2022-11-28 03:23:10,250 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.436783951728843, 'Total loss': 0.436783951728843} | train loss {'Reaction outcome loss': 0.3411535616703485, 'Total loss': 0.3411535616703485}
2022-11-28 03:23:10,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:10,250 INFO:     Epoch: 25
2022-11-28 03:23:10,983 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4049367571985999, 'Total loss': 0.4049367571985999} | train loss {'Reaction outcome loss': 0.3249287428985898, 'Total loss': 0.3249287428985898}
2022-11-28 03:23:10,983 INFO:     Found new best model at epoch 25
2022-11-28 03:23:10,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:10,984 INFO:     Epoch: 26
2022-11-28 03:23:11,713 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41295859876067137, 'Total loss': 0.41295859876067137} | train loss {'Reaction outcome loss': 0.32851986764880364, 'Total loss': 0.32851986764880364}
2022-11-28 03:23:11,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:11,713 INFO:     Epoch: 27
2022-11-28 03:23:12,443 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42860754250093946, 'Total loss': 0.42860754250093946} | train loss {'Reaction outcome loss': 0.33033201346794766, 'Total loss': 0.33033201346794766}
2022-11-28 03:23:12,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:12,443 INFO:     Epoch: 28
2022-11-28 03:23:13,174 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4209264582672784, 'Total loss': 0.4209264582672784} | train loss {'Reaction outcome loss': 0.3174712801114522, 'Total loss': 0.3174712801114522}
2022-11-28 03:23:13,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:13,174 INFO:     Epoch: 29
2022-11-28 03:23:13,907 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4294992026894592, 'Total loss': 0.4294992026894592} | train loss {'Reaction outcome loss': 0.32765636853720426, 'Total loss': 0.32765636853720426}
2022-11-28 03:23:13,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:13,907 INFO:     Epoch: 30
2022-11-28 03:23:14,639 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43534805053888365, 'Total loss': 0.43534805053888365} | train loss {'Reaction outcome loss': 0.3229704271434756, 'Total loss': 0.3229704271434756}
2022-11-28 03:23:14,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:14,639 INFO:     Epoch: 31
2022-11-28 03:23:15,366 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41506505636281743, 'Total loss': 0.41506505636281743} | train loss {'Reaction outcome loss': 0.32241271289425744, 'Total loss': 0.32241271289425744}
2022-11-28 03:23:15,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:15,366 INFO:     Epoch: 32
2022-11-28 03:23:16,095 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42488241871429044, 'Total loss': 0.42488241871429044} | train loss {'Reaction outcome loss': 0.32402834746174114, 'Total loss': 0.32402834746174114}
2022-11-28 03:23:16,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:16,095 INFO:     Epoch: 33
2022-11-28 03:23:16,823 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42377144670070604, 'Total loss': 0.42377144670070604} | train loss {'Reaction outcome loss': 0.31687360500663886, 'Total loss': 0.31687360500663886}
2022-11-28 03:23:16,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:16,824 INFO:     Epoch: 34
2022-11-28 03:23:17,557 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4359471898439319, 'Total loss': 0.4359471898439319} | train loss {'Reaction outcome loss': 0.31386631530989345, 'Total loss': 0.31386631530989345}
2022-11-28 03:23:17,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:17,557 INFO:     Epoch: 35
2022-11-28 03:23:18,292 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4142399179034455, 'Total loss': 0.4142399179034455} | train loss {'Reaction outcome loss': 0.32148949670080296, 'Total loss': 0.32148949670080296}
2022-11-28 03:23:18,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:18,293 INFO:     Epoch: 36
2022-11-28 03:23:19,025 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4103233913003012, 'Total loss': 0.4103233913003012} | train loss {'Reaction outcome loss': 0.3126110581090911, 'Total loss': 0.3126110581090911}
2022-11-28 03:23:19,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:19,026 INFO:     Epoch: 37
2022-11-28 03:23:19,753 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44482547772485154, 'Total loss': 0.44482547772485154} | train loss {'Reaction outcome loss': 0.30978090472427416, 'Total loss': 0.30978090472427416}
2022-11-28 03:23:19,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:19,753 INFO:     Epoch: 38
2022-11-28 03:23:20,485 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42585923054883645, 'Total loss': 0.42585923054883645} | train loss {'Reaction outcome loss': 0.3140793161106453, 'Total loss': 0.3140793161106453}
2022-11-28 03:23:20,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:20,485 INFO:     Epoch: 39
2022-11-28 03:23:21,219 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.431052659833154, 'Total loss': 0.431052659833154} | train loss {'Reaction outcome loss': 0.31539058685302734, 'Total loss': 0.31539058685302734}
2022-11-28 03:23:21,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:21,219 INFO:     Epoch: 40
2022-11-28 03:23:21,950 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39144373737102334, 'Total loss': 0.39144373737102334} | train loss {'Reaction outcome loss': 0.3153625279358385, 'Total loss': 0.3153625279358385}
2022-11-28 03:23:21,950 INFO:     Found new best model at epoch 40
2022-11-28 03:23:21,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:21,951 INFO:     Epoch: 41
2022-11-28 03:23:22,680 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4180218570454176, 'Total loss': 0.4180218570454176} | train loss {'Reaction outcome loss': 0.3117985213060438, 'Total loss': 0.3117985213060438}
2022-11-28 03:23:22,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:22,680 INFO:     Epoch: 42
2022-11-28 03:23:23,412 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42813918444999427, 'Total loss': 0.42813918444999427} | train loss {'Reaction outcome loss': 0.3128823981976803, 'Total loss': 0.3128823981976803}
2022-11-28 03:23:23,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:23,412 INFO:     Epoch: 43
2022-11-28 03:23:24,140 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43741483535877496, 'Total loss': 0.43741483535877496} | train loss {'Reaction outcome loss': 0.3133067899525411, 'Total loss': 0.3133067899525411}
2022-11-28 03:23:24,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:24,140 INFO:     Epoch: 44
2022-11-28 03:23:24,870 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43013338224832404, 'Total loss': 0.43013338224832404} | train loss {'Reaction outcome loss': 0.3137317148071748, 'Total loss': 0.3137317148071748}
2022-11-28 03:23:24,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:24,870 INFO:     Epoch: 45
2022-11-28 03:23:25,598 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.433126347702603, 'Total loss': 0.433126347702603} | train loss {'Reaction outcome loss': 0.31323150686015194, 'Total loss': 0.31323150686015194}
2022-11-28 03:23:25,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:25,598 INFO:     Epoch: 46
2022-11-28 03:23:26,329 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4160614117633465, 'Total loss': 0.4160614117633465} | train loss {'Reaction outcome loss': 0.30650254164213014, 'Total loss': 0.30650254164213014}
2022-11-28 03:23:26,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:26,329 INFO:     Epoch: 47
2022-11-28 03:23:27,061 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40987874931374263, 'Total loss': 0.40987874931374263} | train loss {'Reaction outcome loss': 0.309079496565547, 'Total loss': 0.309079496565547}
2022-11-28 03:23:27,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:27,061 INFO:     Epoch: 48
2022-11-28 03:23:27,793 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4495413313771403, 'Total loss': 0.4495413313771403} | train loss {'Reaction outcome loss': 0.300610930570727, 'Total loss': 0.300610930570727}
2022-11-28 03:23:27,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:27,793 INFO:     Epoch: 49
2022-11-28 03:23:28,522 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4197799702023351, 'Total loss': 0.4197799702023351} | train loss {'Reaction outcome loss': 0.3129337311112954, 'Total loss': 0.3129337311112954}
2022-11-28 03:23:28,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:28,522 INFO:     Epoch: 50
2022-11-28 03:23:29,251 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.430436336023863, 'Total loss': 0.430436336023863} | train loss {'Reaction outcome loss': 0.303236022039696, 'Total loss': 0.303236022039696}
2022-11-28 03:23:29,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:29,251 INFO:     Epoch: 51
2022-11-28 03:23:29,979 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43444584379362505, 'Total loss': 0.43444584379362505} | train loss {'Reaction outcome loss': 0.3034756108198637, 'Total loss': 0.3034756108198637}
2022-11-28 03:23:29,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:29,980 INFO:     Epoch: 52
2022-11-28 03:23:30,708 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43782789831937746, 'Total loss': 0.43782789831937746} | train loss {'Reaction outcome loss': 0.3056403897978641, 'Total loss': 0.3056403897978641}
2022-11-28 03:23:30,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:30,708 INFO:     Epoch: 53
2022-11-28 03:23:31,441 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42415786725144056, 'Total loss': 0.42415786725144056} | train loss {'Reaction outcome loss': 0.31340563773281044, 'Total loss': 0.31340563773281044}
2022-11-28 03:23:31,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:31,441 INFO:     Epoch: 54
2022-11-28 03:23:32,174 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4527108256900033, 'Total loss': 0.4527108256900033} | train loss {'Reaction outcome loss': 0.3038319891985552, 'Total loss': 0.3038319891985552}
2022-11-28 03:23:32,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:32,174 INFO:     Epoch: 55
2022-11-28 03:23:32,909 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4157660735207935, 'Total loss': 0.4157660735207935} | train loss {'Reaction outcome loss': 0.3103838175719167, 'Total loss': 0.3103838175719167}
2022-11-28 03:23:32,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:32,909 INFO:     Epoch: 56
2022-11-28 03:23:33,640 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41287445952725965, 'Total loss': 0.41287445952725965} | train loss {'Reaction outcome loss': 0.30319987961048944, 'Total loss': 0.30319987961048944}
2022-11-28 03:23:33,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:33,641 INFO:     Epoch: 57
2022-11-28 03:23:34,373 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4500717253879059, 'Total loss': 0.4500717253879059} | train loss {'Reaction outcome loss': 0.3024697866858033, 'Total loss': 0.3024697866858033}
2022-11-28 03:23:34,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:34,373 INFO:     Epoch: 58
2022-11-28 03:23:35,100 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4350874444773031, 'Total loss': 0.4350874444773031} | train loss {'Reaction outcome loss': 0.30740498323683385, 'Total loss': 0.30740498323683385}
2022-11-28 03:23:35,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:35,100 INFO:     Epoch: 59
2022-11-28 03:23:35,827 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4128453890944636, 'Total loss': 0.4128453890944636} | train loss {'Reaction outcome loss': 0.29343322652234954, 'Total loss': 0.29343322652234954}
2022-11-28 03:23:35,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:35,827 INFO:     Epoch: 60
2022-11-28 03:23:36,556 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4332741419243258, 'Total loss': 0.4332741419243258} | train loss {'Reaction outcome loss': 0.30884664427535036, 'Total loss': 0.30884664427535036}
2022-11-28 03:23:36,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:36,557 INFO:     Epoch: 61
2022-11-28 03:23:37,286 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40862035248861756, 'Total loss': 0.40862035248861756} | train loss {'Reaction outcome loss': 0.3050196517274213, 'Total loss': 0.3050196517274213}
2022-11-28 03:23:37,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:37,286 INFO:     Epoch: 62
2022-11-28 03:23:38,017 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39804141760565515, 'Total loss': 0.39804141760565515} | train loss {'Reaction outcome loss': 0.2981709401303358, 'Total loss': 0.2981709401303358}
2022-11-28 03:23:38,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:38,017 INFO:     Epoch: 63
2022-11-28 03:23:38,745 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4158343055913615, 'Total loss': 0.4158343055913615} | train loss {'Reaction outcome loss': 0.29725260381038787, 'Total loss': 0.29725260381038787}
2022-11-28 03:23:38,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:38,745 INFO:     Epoch: 64
2022-11-28 03:23:39,476 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4296154010781022, 'Total loss': 0.4296154010781022} | train loss {'Reaction outcome loss': 0.30480265076207036, 'Total loss': 0.30480265076207036}
2022-11-28 03:23:39,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:39,476 INFO:     Epoch: 65
2022-11-28 03:23:40,205 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41884805764569794, 'Total loss': 0.41884805764569794} | train loss {'Reaction outcome loss': 0.3027006459610207, 'Total loss': 0.3027006459610207}
2022-11-28 03:23:40,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:40,205 INFO:     Epoch: 66
2022-11-28 03:23:40,937 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.407058727602626, 'Total loss': 0.407058727602626} | train loss {'Reaction outcome loss': 0.30526506805738796, 'Total loss': 0.30526506805738796}
2022-11-28 03:23:40,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:40,937 INFO:     Epoch: 67
2022-11-28 03:23:41,668 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4038338480993759, 'Total loss': 0.4038338480993759} | train loss {'Reaction outcome loss': 0.3009432568655583, 'Total loss': 0.3009432568655583}
2022-11-28 03:23:41,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:41,668 INFO:     Epoch: 68
2022-11-28 03:23:42,396 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4213563910750456, 'Total loss': 0.4213563910750456} | train loss {'Reaction outcome loss': 0.3075310183160099, 'Total loss': 0.3075310183160099}
2022-11-28 03:23:42,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:42,396 INFO:     Epoch: 69
2022-11-28 03:23:43,130 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4319808309854463, 'Total loss': 0.4319808309854463} | train loss {'Reaction outcome loss': 0.2974278342147423, 'Total loss': 0.2974278342147423}
2022-11-28 03:23:43,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:43,130 INFO:     Epoch: 70
2022-11-28 03:23:43,862 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4395144678825556, 'Total loss': 0.4395144678825556} | train loss {'Reaction outcome loss': 0.3001170545325848, 'Total loss': 0.3001170545325848}
2022-11-28 03:23:43,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:43,862 INFO:     Epoch: 71
2022-11-28 03:23:44,592 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41121660398189414, 'Total loss': 0.41121660398189414} | train loss {'Reaction outcome loss': 0.29936802539391894, 'Total loss': 0.29936802539391894}
2022-11-28 03:23:44,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:44,592 INFO:     Epoch: 72
2022-11-28 03:23:45,324 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4232202089110086, 'Total loss': 0.4232202089110086} | train loss {'Reaction outcome loss': 0.29679481485866227, 'Total loss': 0.29679481485866227}
2022-11-28 03:23:45,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:45,325 INFO:     Epoch: 73
2022-11-28 03:23:46,059 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40437350075605305, 'Total loss': 0.40437350075605305} | train loss {'Reaction outcome loss': 0.29280960878717555, 'Total loss': 0.29280960878717555}
2022-11-28 03:23:46,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:46,059 INFO:     Epoch: 74
2022-11-28 03:23:46,790 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41319695669551226, 'Total loss': 0.41319695669551226} | train loss {'Reaction outcome loss': 0.2965600388162911, 'Total loss': 0.2965600388162911}
2022-11-28 03:23:46,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:46,791 INFO:     Epoch: 75
2022-11-28 03:23:47,522 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45325740236182543, 'Total loss': 0.45325740236182543} | train loss {'Reaction outcome loss': 0.30635411139010404, 'Total loss': 0.30635411139010404}
2022-11-28 03:23:47,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:47,523 INFO:     Epoch: 76
2022-11-28 03:23:48,254 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.437212361152782, 'Total loss': 0.437212361152782} | train loss {'Reaction outcome loss': 0.30215414993679574, 'Total loss': 0.30215414993679574}
2022-11-28 03:23:48,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:48,254 INFO:     Epoch: 77
2022-11-28 03:23:48,983 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43112371792626936, 'Total loss': 0.43112371792626936} | train loss {'Reaction outcome loss': 0.30561829131449203, 'Total loss': 0.30561829131449203}
2022-11-28 03:23:48,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:48,984 INFO:     Epoch: 78
2022-11-28 03:23:49,716 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40683009891315947, 'Total loss': 0.40683009891315947} | train loss {'Reaction outcome loss': 0.30250191118246245, 'Total loss': 0.30250191118246245}
2022-11-28 03:23:49,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:49,717 INFO:     Epoch: 79
2022-11-28 03:23:50,448 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40008643997270005, 'Total loss': 0.40008643997270005} | train loss {'Reaction outcome loss': 0.308032168619672, 'Total loss': 0.308032168619672}
2022-11-28 03:23:50,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:50,448 INFO:     Epoch: 80
2022-11-28 03:23:51,176 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42633470269136653, 'Total loss': 0.42633470269136653} | train loss {'Reaction outcome loss': 0.2929156039661341, 'Total loss': 0.2929156039661341}
2022-11-28 03:23:51,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:51,176 INFO:     Epoch: 81
2022-11-28 03:23:51,907 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41804731533277867, 'Total loss': 0.41804731533277867} | train loss {'Reaction outcome loss': 0.30749431917819464, 'Total loss': 0.30749431917819464}
2022-11-28 03:23:51,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:51,907 INFO:     Epoch: 82
2022-11-28 03:23:52,639 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41286096617926, 'Total loss': 0.41286096617926} | train loss {'Reaction outcome loss': 0.3127125978101919, 'Total loss': 0.3127125978101919}
2022-11-28 03:23:52,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:52,639 INFO:     Epoch: 83
2022-11-28 03:23:53,368 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4205215029245199, 'Total loss': 0.4205215029245199} | train loss {'Reaction outcome loss': 0.3053670572461905, 'Total loss': 0.3053670572461905}
2022-11-28 03:23:53,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:53,368 INFO:     Epoch: 84
2022-11-28 03:23:54,098 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43743196597626044, 'Total loss': 0.43743196597626044} | train loss {'Reaction outcome loss': 0.29776350841110133, 'Total loss': 0.29776350841110133}
2022-11-28 03:23:54,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:54,098 INFO:     Epoch: 85
2022-11-28 03:23:54,826 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42625585510287173, 'Total loss': 0.42625585510287173} | train loss {'Reaction outcome loss': 0.30496692410651055, 'Total loss': 0.30496692410651055}
2022-11-28 03:23:54,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:54,827 INFO:     Epoch: 86
2022-11-28 03:23:55,557 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45236703406932743, 'Total loss': 0.45236703406932743} | train loss {'Reaction outcome loss': 0.30419011306738164, 'Total loss': 0.30419011306738164}
2022-11-28 03:23:55,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:55,558 INFO:     Epoch: 87
2022-11-28 03:23:56,289 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42752431974161503, 'Total loss': 0.42752431974161503} | train loss {'Reaction outcome loss': 0.3077668094156701, 'Total loss': 0.3077668094156701}
2022-11-28 03:23:56,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:56,290 INFO:     Epoch: 88
2022-11-28 03:23:57,023 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41465188424254573, 'Total loss': 0.41465188424254573} | train loss {'Reaction outcome loss': 0.2997243970080658, 'Total loss': 0.2997243970080658}
2022-11-28 03:23:57,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:57,023 INFO:     Epoch: 89
2022-11-28 03:23:57,755 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4383557348750358, 'Total loss': 0.4383557348750358} | train loss {'Reaction outcome loss': 0.2999323163135552, 'Total loss': 0.2999323163135552}
2022-11-28 03:23:57,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:57,756 INFO:     Epoch: 90
2022-11-28 03:23:58,500 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39586025441801825, 'Total loss': 0.39586025441801825} | train loss {'Reaction outcome loss': 0.31190090004829957, 'Total loss': 0.31190090004829957}
2022-11-28 03:23:58,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:58,500 INFO:     Epoch: 91
2022-11-28 03:23:59,248 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42618257188519765, 'Total loss': 0.42618257188519765} | train loss {'Reaction outcome loss': 0.30499383960486437, 'Total loss': 0.30499383960486437}
2022-11-28 03:23:59,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:59,248 INFO:     Epoch: 92
2022-11-28 03:23:59,995 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40479744156432707, 'Total loss': 0.40479744156432707} | train loss {'Reaction outcome loss': 0.3099733570843567, 'Total loss': 0.3099733570843567}
2022-11-28 03:23:59,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:23:59,995 INFO:     Epoch: 93
2022-11-28 03:24:00,743 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41065505805403685, 'Total loss': 0.41065505805403685} | train loss {'Reaction outcome loss': 0.3012327611936954, 'Total loss': 0.3012327611936954}
2022-11-28 03:24:00,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:00,744 INFO:     Epoch: 94
2022-11-28 03:24:01,488 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4267392598612364, 'Total loss': 0.4267392598612364} | train loss {'Reaction outcome loss': 0.3068342463960373, 'Total loss': 0.3068342463960373}
2022-11-28 03:24:01,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:01,489 INFO:     Epoch: 95
2022-11-28 03:24:02,236 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4367493205638819, 'Total loss': 0.4367493205638819} | train loss {'Reaction outcome loss': 0.29860654287806754, 'Total loss': 0.29860654287806754}
2022-11-28 03:24:02,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:02,236 INFO:     Epoch: 96
2022-11-28 03:24:02,981 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4269739628531212, 'Total loss': 0.4269739628531212} | train loss {'Reaction outcome loss': 0.29985129463758486, 'Total loss': 0.29985129463758486}
2022-11-28 03:24:02,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:02,981 INFO:     Epoch: 97
2022-11-28 03:24:03,728 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40213562478852827, 'Total loss': 0.40213562478852827} | train loss {'Reaction outcome loss': 0.29568096887274287, 'Total loss': 0.29568096887274287}
2022-11-28 03:24:03,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:03,728 INFO:     Epoch: 98
2022-11-28 03:24:04,472 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4166369386190592, 'Total loss': 0.4166369386190592} | train loss {'Reaction outcome loss': 0.29722796270140894, 'Total loss': 0.29722796270140894}
2022-11-28 03:24:04,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:04,473 INFO:     Epoch: 99
2022-11-28 03:24:05,216 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44338904563770737, 'Total loss': 0.44338904563770737} | train loss {'Reaction outcome loss': 0.29376535516216923, 'Total loss': 0.29376535516216923}
2022-11-28 03:24:05,216 INFO:     Best model found after epoch 41 of 100.
2022-11-28 03:24:05,216 INFO:   Done with stage: TRAINING
2022-11-28 03:24:05,216 INFO:   Starting stage: EVALUATION
2022-11-28 03:24:05,354 INFO:   Done with stage: EVALUATION
2022-11-28 03:24:05,355 INFO:   Leaving out SEQ value Fold_1
2022-11-28 03:24:05,368 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:24:05,368 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:24:06,000 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:24:06,000 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:24:06,068 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:24:06,068 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:24:06,068 INFO:     No hyperparam tuning for this model
2022-11-28 03:24:06,068 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:24:06,068 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:24:06,069 INFO:     None feature selector for col prot
2022-11-28 03:24:06,069 INFO:     None feature selector for col prot
2022-11-28 03:24:06,069 INFO:     None feature selector for col prot
2022-11-28 03:24:06,069 INFO:     None feature selector for col chem
2022-11-28 03:24:06,069 INFO:     None feature selector for col chem
2022-11-28 03:24:06,069 INFO:     None feature selector for col chem
2022-11-28 03:24:06,069 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:24:06,070 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:24:06,071 INFO:     Number of params in model 169741
2022-11-28 03:24:06,074 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:24:06,074 INFO:   Starting stage: TRAINING
2022-11-28 03:24:06,127 INFO:     Val loss before train {'Reaction outcome loss': 0.9692964174530723, 'Total loss': 0.9692964174530723}
2022-11-28 03:24:06,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:06,127 INFO:     Epoch: 0
2022-11-28 03:24:06,883 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5747496993704275, 'Total loss': 0.5747496993704275} | train loss {'Reaction outcome loss': 0.6552440114167272, 'Total loss': 0.6552440114167272}
2022-11-28 03:24:06,884 INFO:     Found new best model at epoch 0
2022-11-28 03:24:06,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:06,884 INFO:     Epoch: 1
2022-11-28 03:24:07,636 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.490255303342234, 'Total loss': 0.490255303342234} | train loss {'Reaction outcome loss': 0.5114427340882165, 'Total loss': 0.5114427340882165}
2022-11-28 03:24:07,637 INFO:     Found new best model at epoch 1
2022-11-28 03:24:07,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:07,638 INFO:     Epoch: 2
2022-11-28 03:24:08,391 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46401081166484137, 'Total loss': 0.46401081166484137} | train loss {'Reaction outcome loss': 0.47867252413107425, 'Total loss': 0.47867252413107425}
2022-11-28 03:24:08,391 INFO:     Found new best model at epoch 2
2022-11-28 03:24:08,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:08,392 INFO:     Epoch: 3
2022-11-28 03:24:09,144 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5042114264585755, 'Total loss': 0.5042114264585755} | train loss {'Reaction outcome loss': 0.452006185906274, 'Total loss': 0.452006185906274}
2022-11-28 03:24:09,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:09,144 INFO:     Epoch: 4
2022-11-28 03:24:09,896 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4335008224641735, 'Total loss': 0.4335008224641735} | train loss {'Reaction outcome loss': 0.4385300677649829, 'Total loss': 0.4385300677649829}
2022-11-28 03:24:09,896 INFO:     Found new best model at epoch 4
2022-11-28 03:24:09,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:09,897 INFO:     Epoch: 5
2022-11-28 03:24:10,649 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4610938324847005, 'Total loss': 0.4610938324847005} | train loss {'Reaction outcome loss': 0.42486744942713756, 'Total loss': 0.42486744942713756}
2022-11-28 03:24:10,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:10,649 INFO:     Epoch: 6
2022-11-28 03:24:11,403 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4503522677855058, 'Total loss': 0.4503522677855058} | train loss {'Reaction outcome loss': 0.3960501858166286, 'Total loss': 0.3960501858166286}
2022-11-28 03:24:11,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:11,403 INFO:     Epoch: 7
2022-11-28 03:24:12,158 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4400878663767468, 'Total loss': 0.4400878663767468} | train loss {'Reaction outcome loss': 0.4060592749593209, 'Total loss': 0.4060592749593209}
2022-11-28 03:24:12,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:12,158 INFO:     Epoch: 8
2022-11-28 03:24:12,914 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4298204224218022, 'Total loss': 0.4298204224218022} | train loss {'Reaction outcome loss': 0.4049829585819828, 'Total loss': 0.4049829585819828}
2022-11-28 03:24:12,914 INFO:     Found new best model at epoch 8
2022-11-28 03:24:12,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:12,915 INFO:     Epoch: 9
2022-11-28 03:24:13,667 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44569618559696456, 'Total loss': 0.44569618559696456} | train loss {'Reaction outcome loss': 0.3881500165073239, 'Total loss': 0.3881500165073239}
2022-11-28 03:24:13,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:13,667 INFO:     Epoch: 10
2022-11-28 03:24:14,420 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44193126599897037, 'Total loss': 0.44193126599897037} | train loss {'Reaction outcome loss': 0.3832625206027712, 'Total loss': 0.3832625206027712}
2022-11-28 03:24:14,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:14,420 INFO:     Epoch: 11
2022-11-28 03:24:15,174 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42877489294518123, 'Total loss': 0.42877489294518123} | train loss {'Reaction outcome loss': 0.37178298271432214, 'Total loss': 0.37178298271432214}
2022-11-28 03:24:15,174 INFO:     Found new best model at epoch 11
2022-11-28 03:24:15,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:15,175 INFO:     Epoch: 12
2022-11-28 03:24:15,927 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41007042134349997, 'Total loss': 0.41007042134349997} | train loss {'Reaction outcome loss': 0.3726794699320988, 'Total loss': 0.3726794699320988}
2022-11-28 03:24:15,927 INFO:     Found new best model at epoch 12
2022-11-28 03:24:15,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:15,928 INFO:     Epoch: 13
2022-11-28 03:24:16,681 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44527961110526865, 'Total loss': 0.44527961110526865} | train loss {'Reaction outcome loss': 0.37021220429819457, 'Total loss': 0.37021220429819457}
2022-11-28 03:24:16,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:16,682 INFO:     Epoch: 14
2022-11-28 03:24:17,436 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44222263009710744, 'Total loss': 0.44222263009710744} | train loss {'Reaction outcome loss': 0.36068728949342455, 'Total loss': 0.36068728949342455}
2022-11-28 03:24:17,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:17,436 INFO:     Epoch: 15
2022-11-28 03:24:18,190 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4179258117960258, 'Total loss': 0.4179258117960258} | train loss {'Reaction outcome loss': 0.3563472528238686, 'Total loss': 0.3563472528238686}
2022-11-28 03:24:18,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:18,190 INFO:     Epoch: 16
2022-11-28 03:24:18,946 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42244967581196263, 'Total loss': 0.42244967581196263} | train loss {'Reaction outcome loss': 0.35604978973159984, 'Total loss': 0.35604978973159984}
2022-11-28 03:24:18,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:18,946 INFO:     Epoch: 17
2022-11-28 03:24:19,696 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41052221947095613, 'Total loss': 0.41052221947095613} | train loss {'Reaction outcome loss': 0.3626714041342541, 'Total loss': 0.3626714041342541}
2022-11-28 03:24:19,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:19,697 INFO:     Epoch: 18
2022-11-28 03:24:20,448 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4024621754546057, 'Total loss': 0.4024621754546057} | train loss {'Reaction outcome loss': 0.34716816167442166, 'Total loss': 0.34716816167442166}
2022-11-28 03:24:20,448 INFO:     Found new best model at epoch 18
2022-11-28 03:24:20,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:20,449 INFO:     Epoch: 19
2022-11-28 03:24:21,203 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43345516649159516, 'Total loss': 0.43345516649159516} | train loss {'Reaction outcome loss': 0.3551036568928738, 'Total loss': 0.3551036568928738}
2022-11-28 03:24:21,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:21,204 INFO:     Epoch: 20
2022-11-28 03:24:21,957 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40165541659701953, 'Total loss': 0.40165541659701953} | train loss {'Reaction outcome loss': 0.3520165764555639, 'Total loss': 0.3520165764555639}
2022-11-28 03:24:21,958 INFO:     Found new best model at epoch 20
2022-11-28 03:24:21,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:21,958 INFO:     Epoch: 21
2022-11-28 03:24:22,710 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4100289771502668, 'Total loss': 0.4100289771502668} | train loss {'Reaction outcome loss': 0.3481139849643318, 'Total loss': 0.3481139849643318}
2022-11-28 03:24:22,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:22,711 INFO:     Epoch: 22
2022-11-28 03:24:23,463 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39555242556062614, 'Total loss': 0.39555242556062614} | train loss {'Reaction outcome loss': 0.3527011132970148, 'Total loss': 0.3527011132970148}
2022-11-28 03:24:23,463 INFO:     Found new best model at epoch 22
2022-11-28 03:24:23,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:23,464 INFO:     Epoch: 23
2022-11-28 03:24:24,216 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39329212429848587, 'Total loss': 0.39329212429848587} | train loss {'Reaction outcome loss': 0.3507942178419658, 'Total loss': 0.3507942178419658}
2022-11-28 03:24:24,216 INFO:     Found new best model at epoch 23
2022-11-28 03:24:24,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:24,217 INFO:     Epoch: 24
2022-11-28 03:24:24,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38324332154694607, 'Total loss': 0.38324332154694607} | train loss {'Reaction outcome loss': 0.3463488665466406, 'Total loss': 0.3463488665466406}
2022-11-28 03:24:24,970 INFO:     Found new best model at epoch 24
2022-11-28 03:24:24,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:24,971 INFO:     Epoch: 25
2022-11-28 03:24:25,726 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3856226595287973, 'Total loss': 0.3856226595287973} | train loss {'Reaction outcome loss': 0.3446121958749635, 'Total loss': 0.3446121958749635}
2022-11-28 03:24:25,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:25,726 INFO:     Epoch: 26
2022-11-28 03:24:26,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44871957701715554, 'Total loss': 0.44871957701715554} | train loss {'Reaction outcome loss': 0.3411582493660401, 'Total loss': 0.3411582493660401}
2022-11-28 03:24:26,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:26,482 INFO:     Epoch: 27
2022-11-28 03:24:27,232 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3831991675225171, 'Total loss': 0.3831991675225171} | train loss {'Reaction outcome loss': 0.33752422650553743, 'Total loss': 0.33752422650553743}
2022-11-28 03:24:27,232 INFO:     Found new best model at epoch 27
2022-11-28 03:24:27,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:27,233 INFO:     Epoch: 28
2022-11-28 03:24:27,983 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3950737157667225, 'Total loss': 0.3950737157667225} | train loss {'Reaction outcome loss': 0.33813960281561833, 'Total loss': 0.33813960281561833}
2022-11-28 03:24:27,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:27,984 INFO:     Epoch: 29
2022-11-28 03:24:28,737 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3998801223933697, 'Total loss': 0.3998801223933697} | train loss {'Reaction outcome loss': 0.3368080925576541, 'Total loss': 0.3368080925576541}
2022-11-28 03:24:28,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:28,737 INFO:     Epoch: 30
2022-11-28 03:24:29,491 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3880957930602811, 'Total loss': 0.3880957930602811} | train loss {'Reaction outcome loss': 0.33957886790134467, 'Total loss': 0.33957886790134467}
2022-11-28 03:24:29,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:29,491 INFO:     Epoch: 31
2022-11-28 03:24:30,245 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3990304114889692, 'Total loss': 0.3990304114889692} | train loss {'Reaction outcome loss': 0.3468303005306088, 'Total loss': 0.3468303005306088}
2022-11-28 03:24:30,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:30,245 INFO:     Epoch: 32
2022-11-28 03:24:30,999 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3977425350722941, 'Total loss': 0.3977425350722941} | train loss {'Reaction outcome loss': 0.33920353276997195, 'Total loss': 0.33920353276997195}
2022-11-28 03:24:30,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:30,999 INFO:     Epoch: 33
2022-11-28 03:24:31,753 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45918695391579106, 'Total loss': 0.45918695391579106} | train loss {'Reaction outcome loss': 0.3441828554458156, 'Total loss': 0.3441828554458156}
2022-11-28 03:24:31,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:31,753 INFO:     Epoch: 34
2022-11-28 03:24:32,508 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4144918921996247, 'Total loss': 0.4144918921996247} | train loss {'Reaction outcome loss': 0.33477123966630623, 'Total loss': 0.33477123966630623}
2022-11-28 03:24:32,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:32,509 INFO:     Epoch: 35
2022-11-28 03:24:33,263 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4333328062837774, 'Total loss': 0.4333328062837774} | train loss {'Reaction outcome loss': 0.34179221808302157, 'Total loss': 0.34179221808302157}
2022-11-28 03:24:33,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:33,263 INFO:     Epoch: 36
2022-11-28 03:24:34,014 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41999668695709924, 'Total loss': 0.41999668695709924} | train loss {'Reaction outcome loss': 0.3314398832771243, 'Total loss': 0.3314398832771243}
2022-11-28 03:24:34,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:34,014 INFO:     Epoch: 37
2022-11-28 03:24:34,771 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41368914988230576, 'Total loss': 0.41368914988230576} | train loss {'Reaction outcome loss': 0.33528414110139926, 'Total loss': 0.33528414110139926}
2022-11-28 03:24:34,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:34,771 INFO:     Epoch: 38
2022-11-28 03:24:35,531 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4114134833216667, 'Total loss': 0.4114134833216667} | train loss {'Reaction outcome loss': 0.33466646507078285, 'Total loss': 0.33466646507078285}
2022-11-28 03:24:35,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:35,532 INFO:     Epoch: 39
2022-11-28 03:24:36,283 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3952193566682664, 'Total loss': 0.3952193566682664} | train loss {'Reaction outcome loss': 0.3331518574940915, 'Total loss': 0.3331518574940915}
2022-11-28 03:24:36,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:36,283 INFO:     Epoch: 40
2022-11-28 03:24:37,037 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42338946055282245, 'Total loss': 0.42338946055282245} | train loss {'Reaction outcome loss': 0.3319831798575362, 'Total loss': 0.3319831798575362}
2022-11-28 03:24:37,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:37,037 INFO:     Epoch: 41
2022-11-28 03:24:37,788 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38038119292733347, 'Total loss': 0.38038119292733347} | train loss {'Reaction outcome loss': 0.3241315791497425, 'Total loss': 0.3241315791497425}
2022-11-28 03:24:37,789 INFO:     Found new best model at epoch 41
2022-11-28 03:24:37,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:37,789 INFO:     Epoch: 42
2022-11-28 03:24:38,546 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4144154485653747, 'Total loss': 0.4144154485653747} | train loss {'Reaction outcome loss': 0.33788091148040733, 'Total loss': 0.33788091148040733}
2022-11-28 03:24:38,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:38,546 INFO:     Epoch: 43
2022-11-28 03:24:39,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4169282149946825, 'Total loss': 0.4169282149946825} | train loss {'Reaction outcome loss': 0.32783380603911927, 'Total loss': 0.32783380603911927}
2022-11-28 03:24:39,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:39,298 INFO:     Epoch: 44
2022-11-28 03:24:40,047 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46783995865420863, 'Total loss': 0.46783995865420863} | train loss {'Reaction outcome loss': 0.33213757942525707, 'Total loss': 0.33213757942525707}
2022-11-28 03:24:40,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:40,048 INFO:     Epoch: 45
2022-11-28 03:24:40,801 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.388656071471897, 'Total loss': 0.388656071471897} | train loss {'Reaction outcome loss': 0.3298106344074619, 'Total loss': 0.3298106344074619}
2022-11-28 03:24:40,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:40,801 INFO:     Epoch: 46
2022-11-28 03:24:41,555 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40312813459472224, 'Total loss': 0.40312813459472224} | train loss {'Reaction outcome loss': 0.33143365863634616, 'Total loss': 0.33143365863634616}
2022-11-28 03:24:41,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:41,555 INFO:     Epoch: 47
2022-11-28 03:24:42,313 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41257623820142314, 'Total loss': 0.41257623820142314} | train loss {'Reaction outcome loss': 0.33458316681944594, 'Total loss': 0.33458316681944594}
2022-11-28 03:24:42,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:42,313 INFO:     Epoch: 48
2022-11-28 03:24:43,066 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4278793643144044, 'Total loss': 0.4278793643144044} | train loss {'Reaction outcome loss': 0.33436075819998373, 'Total loss': 0.33436075819998373}
2022-11-28 03:24:43,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:43,066 INFO:     Epoch: 49
2022-11-28 03:24:43,817 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4340433783151887, 'Total loss': 0.4340433783151887} | train loss {'Reaction outcome loss': 0.326328922047907, 'Total loss': 0.326328922047907}
2022-11-28 03:24:43,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:43,818 INFO:     Epoch: 50
2022-11-28 03:24:44,568 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.384066663089801, 'Total loss': 0.384066663089801} | train loss {'Reaction outcome loss': 0.3264529701702449, 'Total loss': 0.3264529701702449}
2022-11-28 03:24:44,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:44,569 INFO:     Epoch: 51
2022-11-28 03:24:45,322 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4195899184454571, 'Total loss': 0.4195899184454571} | train loss {'Reaction outcome loss': 0.3221219259257219, 'Total loss': 0.3221219259257219}
2022-11-28 03:24:45,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:45,322 INFO:     Epoch: 52
2022-11-28 03:24:46,078 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4301990815861659, 'Total loss': 0.4301990815861659} | train loss {'Reaction outcome loss': 0.3319693965267162, 'Total loss': 0.3319693965267162}
2022-11-28 03:24:46,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:46,078 INFO:     Epoch: 53
2022-11-28 03:24:46,833 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38525622473521665, 'Total loss': 0.38525622473521665} | train loss {'Reaction outcome loss': 0.3227367484143802, 'Total loss': 0.3227367484143802}
2022-11-28 03:24:46,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:46,833 INFO:     Epoch: 54
2022-11-28 03:24:47,587 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43231638859618793, 'Total loss': 0.43231638859618793} | train loss {'Reaction outcome loss': 0.32917662211218657, 'Total loss': 0.32917662211218657}
2022-11-28 03:24:47,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:47,587 INFO:     Epoch: 55
2022-11-28 03:24:48,341 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41240196268666873, 'Total loss': 0.41240196268666873} | train loss {'Reaction outcome loss': 0.3319326201263739, 'Total loss': 0.3319326201263739}
2022-11-28 03:24:48,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:48,341 INFO:     Epoch: 56
2022-11-28 03:24:49,092 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4174652662636204, 'Total loss': 0.4174652662636204} | train loss {'Reaction outcome loss': 0.31818185226649653, 'Total loss': 0.31818185226649653}
2022-11-28 03:24:49,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:49,092 INFO:     Epoch: 57
2022-11-28 03:24:49,832 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3876448351551186, 'Total loss': 0.3876448351551186} | train loss {'Reaction outcome loss': 0.3219724794735714, 'Total loss': 0.3219724794735714}
2022-11-28 03:24:49,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:49,832 INFO:     Epoch: 58
2022-11-28 03:24:50,576 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4284434027292512, 'Total loss': 0.4284434027292512} | train loss {'Reaction outcome loss': 0.3146721194593274, 'Total loss': 0.3146721194593274}
2022-11-28 03:24:50,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:50,577 INFO:     Epoch: 59
2022-11-28 03:24:51,320 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.428290295837955, 'Total loss': 0.428290295837955} | train loss {'Reaction outcome loss': 0.3201198795316171, 'Total loss': 0.3201198795316171}
2022-11-28 03:24:51,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:51,320 INFO:     Epoch: 60
2022-11-28 03:24:52,059 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4300423931669105, 'Total loss': 0.4300423931669105} | train loss {'Reaction outcome loss': 0.32053345142274486, 'Total loss': 0.32053345142274486}
2022-11-28 03:24:52,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:52,059 INFO:     Epoch: 61
2022-11-28 03:24:52,797 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38704124448651617, 'Total loss': 0.38704124448651617} | train loss {'Reaction outcome loss': 0.3250304242786096, 'Total loss': 0.3250304242786096}
2022-11-28 03:24:52,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:52,797 INFO:     Epoch: 62
2022-11-28 03:24:53,539 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3898513713343577, 'Total loss': 0.3898513713343577} | train loss {'Reaction outcome loss': 0.3259203469266697, 'Total loss': 0.3259203469266697}
2022-11-28 03:24:53,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:53,539 INFO:     Epoch: 63
2022-11-28 03:24:54,280 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38969723507761955, 'Total loss': 0.38969723507761955} | train loss {'Reaction outcome loss': 0.3195781731787993, 'Total loss': 0.3195781731787993}
2022-11-28 03:24:54,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:54,280 INFO:     Epoch: 64
2022-11-28 03:24:55,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3946458497508006, 'Total loss': 0.3946458497508006} | train loss {'Reaction outcome loss': 0.32364478059569185, 'Total loss': 0.32364478059569185}
2022-11-28 03:24:55,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:55,021 INFO:     Epoch: 65
2022-11-28 03:24:55,760 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39619331366636534, 'Total loss': 0.39619331366636534} | train loss {'Reaction outcome loss': 0.3124408841133118, 'Total loss': 0.3124408841133118}
2022-11-28 03:24:55,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:55,760 INFO:     Epoch: 66
2022-11-28 03:24:56,501 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4181644049557773, 'Total loss': 0.4181644049557773} | train loss {'Reaction outcome loss': 0.32109711016623343, 'Total loss': 0.32109711016623343}
2022-11-28 03:24:56,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:56,501 INFO:     Epoch: 67
2022-11-28 03:24:57,244 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41816719553687354, 'Total loss': 0.41816719553687354} | train loss {'Reaction outcome loss': 0.3252033435872623, 'Total loss': 0.3252033435872623}
2022-11-28 03:24:57,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:57,244 INFO:     Epoch: 68
2022-11-28 03:24:57,983 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.386513928798112, 'Total loss': 0.386513928798112} | train loss {'Reaction outcome loss': 0.32905144603276737, 'Total loss': 0.32905144603276737}
2022-11-28 03:24:57,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:57,983 INFO:     Epoch: 69
2022-11-28 03:24:58,724 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4205141128464179, 'Total loss': 0.4205141128464179} | train loss {'Reaction outcome loss': 0.3168589826141085, 'Total loss': 0.3168589826141085}
2022-11-28 03:24:58,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:58,724 INFO:     Epoch: 70
2022-11-28 03:24:59,461 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41245788926343346, 'Total loss': 0.41245788926343346} | train loss {'Reaction outcome loss': 0.3144064863725584, 'Total loss': 0.3144064863725584}
2022-11-28 03:24:59,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:24:59,461 INFO:     Epoch: 71
2022-11-28 03:25:00,201 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41984017261049966, 'Total loss': 0.41984017261049966} | train loss {'Reaction outcome loss': 0.31760176037039073, 'Total loss': 0.31760176037039073}
2022-11-28 03:25:00,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:00,201 INFO:     Epoch: 72
2022-11-28 03:25:00,943 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44227026538415387, 'Total loss': 0.44227026538415387} | train loss {'Reaction outcome loss': 0.3217906780997101, 'Total loss': 0.3217906780997101}
2022-11-28 03:25:00,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:00,943 INFO:     Epoch: 73
2022-11-28 03:25:01,688 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37538547356697644, 'Total loss': 0.37538547356697644} | train loss {'Reaction outcome loss': 0.32665663467986245, 'Total loss': 0.32665663467986245}
2022-11-28 03:25:01,688 INFO:     Found new best model at epoch 73
2022-11-28 03:25:01,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:01,689 INFO:     Epoch: 74
2022-11-28 03:25:02,429 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38593141243539075, 'Total loss': 0.38593141243539075} | train loss {'Reaction outcome loss': 0.3157137605608726, 'Total loss': 0.3157137605608726}
2022-11-28 03:25:02,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:02,430 INFO:     Epoch: 75
2022-11-28 03:25:03,169 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3686653401025317, 'Total loss': 0.3686653401025317} | train loss {'Reaction outcome loss': 0.32210558728904143, 'Total loss': 0.32210558728904143}
2022-11-28 03:25:03,169 INFO:     Found new best model at epoch 75
2022-11-28 03:25:03,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:03,170 INFO:     Epoch: 76
2022-11-28 03:25:03,911 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4303642003373666, 'Total loss': 0.4303642003373666} | train loss {'Reaction outcome loss': 0.3142203518170483, 'Total loss': 0.3142203518170483}
2022-11-28 03:25:03,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:03,912 INFO:     Epoch: 77
2022-11-28 03:25:04,652 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42454970153895294, 'Total loss': 0.42454970153895294} | train loss {'Reaction outcome loss': 0.3266460670804491, 'Total loss': 0.3266460670804491}
2022-11-28 03:25:04,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:04,652 INFO:     Epoch: 78
2022-11-28 03:25:05,395 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4120699336582964, 'Total loss': 0.4120699336582964} | train loss {'Reaction outcome loss': 0.3168771654367447, 'Total loss': 0.3168771654367447}
2022-11-28 03:25:05,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:05,395 INFO:     Epoch: 79
2022-11-28 03:25:06,135 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4251042695885355, 'Total loss': 0.4251042695885355} | train loss {'Reaction outcome loss': 0.3316178542010638, 'Total loss': 0.3316178542010638}
2022-11-28 03:25:06,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:06,135 INFO:     Epoch: 80
2022-11-28 03:25:06,873 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4024197747084228, 'Total loss': 0.4024197747084228} | train loss {'Reaction outcome loss': 0.31412382779680953, 'Total loss': 0.31412382779680953}
2022-11-28 03:25:06,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:06,874 INFO:     Epoch: 81
2022-11-28 03:25:07,612 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4226507903500037, 'Total loss': 0.4226507903500037} | train loss {'Reaction outcome loss': 0.33393377027645404, 'Total loss': 0.33393377027645404}
2022-11-28 03:25:07,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:07,612 INFO:     Epoch: 82
2022-11-28 03:25:08,351 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4302003011107445, 'Total loss': 0.4302003011107445} | train loss {'Reaction outcome loss': 0.3193586697383803, 'Total loss': 0.3193586697383803}
2022-11-28 03:25:08,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:08,351 INFO:     Epoch: 83
2022-11-28 03:25:09,089 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39429273490201344, 'Total loss': 0.39429273490201344} | train loss {'Reaction outcome loss': 0.31983094610729995, 'Total loss': 0.31983094610729995}
2022-11-28 03:25:09,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:09,089 INFO:     Epoch: 84
2022-11-28 03:25:09,827 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4192335478622805, 'Total loss': 0.4192335478622805} | train loss {'Reaction outcome loss': 0.3096232612826386, 'Total loss': 0.3096232612826386}
2022-11-28 03:25:09,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:09,827 INFO:     Epoch: 85
2022-11-28 03:25:10,565 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3774932927706025, 'Total loss': 0.3774932927706025} | train loss {'Reaction outcome loss': 0.31267618159858546, 'Total loss': 0.31267618159858546}
2022-11-28 03:25:10,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:10,566 INFO:     Epoch: 86
2022-11-28 03:25:11,304 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4190444147044962, 'Total loss': 0.4190444147044962} | train loss {'Reaction outcome loss': 0.31045941328819915, 'Total loss': 0.31045941328819915}
2022-11-28 03:25:11,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:11,304 INFO:     Epoch: 87
2022-11-28 03:25:12,043 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43090693618763576, 'Total loss': 0.43090693618763576} | train loss {'Reaction outcome loss': 0.3255340639425784, 'Total loss': 0.3255340639425784}
2022-11-28 03:25:12,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:12,043 INFO:     Epoch: 88
2022-11-28 03:25:12,781 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4138492132452401, 'Total loss': 0.4138492132452401} | train loss {'Reaction outcome loss': 0.31921521215414517, 'Total loss': 0.31921521215414517}
2022-11-28 03:25:12,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:12,781 INFO:     Epoch: 89
2022-11-28 03:25:13,523 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4228966344486583, 'Total loss': 0.4228966344486583} | train loss {'Reaction outcome loss': 0.3207238822871325, 'Total loss': 0.3207238822871325}
2022-11-28 03:25:13,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:13,524 INFO:     Epoch: 90
2022-11-28 03:25:14,264 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41109754687005823, 'Total loss': 0.41109754687005823} | train loss {'Reaction outcome loss': 0.3177753432216693, 'Total loss': 0.3177753432216693}
2022-11-28 03:25:14,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:14,264 INFO:     Epoch: 91
2022-11-28 03:25:15,003 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4049520306289196, 'Total loss': 0.4049520306289196} | train loss {'Reaction outcome loss': 0.3232819394417563, 'Total loss': 0.3232819394417563}
2022-11-28 03:25:15,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:15,003 INFO:     Epoch: 92
2022-11-28 03:25:15,745 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4278890775008635, 'Total loss': 0.4278890775008635} | train loss {'Reaction outcome loss': 0.31444296560117174, 'Total loss': 0.31444296560117174}
2022-11-28 03:25:15,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:15,745 INFO:     Epoch: 93
2022-11-28 03:25:16,483 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39603511887517845, 'Total loss': 0.39603511887517845} | train loss {'Reaction outcome loss': 0.3173279986393695, 'Total loss': 0.3173279986393695}
2022-11-28 03:25:16,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:16,484 INFO:     Epoch: 94
2022-11-28 03:25:17,222 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41186751357533713, 'Total loss': 0.41186751357533713} | train loss {'Reaction outcome loss': 0.31628935829717286, 'Total loss': 0.31628935829717286}
2022-11-28 03:25:17,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:17,222 INFO:     Epoch: 95
2022-11-28 03:25:17,960 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3938419446349144, 'Total loss': 0.3938419446349144} | train loss {'Reaction outcome loss': 0.31444264337116357, 'Total loss': 0.31444264337116357}
2022-11-28 03:25:17,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:17,960 INFO:     Epoch: 96
2022-11-28 03:25:18,701 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39303227920423855, 'Total loss': 0.39303227920423855} | train loss {'Reaction outcome loss': 0.31627656537659316, 'Total loss': 0.31627656537659316}
2022-11-28 03:25:18,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:18,702 INFO:     Epoch: 97
2022-11-28 03:25:19,440 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4120325723832304, 'Total loss': 0.4120325723832304} | train loss {'Reaction outcome loss': 0.316516630898933, 'Total loss': 0.316516630898933}
2022-11-28 03:25:19,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:19,440 INFO:     Epoch: 98
2022-11-28 03:25:20,181 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42164028334346687, 'Total loss': 0.42164028334346687} | train loss {'Reaction outcome loss': 0.32123868459341476, 'Total loss': 0.32123868459341476}
2022-11-28 03:25:20,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:20,182 INFO:     Epoch: 99
2022-11-28 03:25:20,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.401453918015415, 'Total loss': 0.401453918015415} | train loss {'Reaction outcome loss': 0.316112155421656, 'Total loss': 0.316112155421656}
2022-11-28 03:25:20,918 INFO:     Best model found after epoch 76 of 100.
2022-11-28 03:25:20,919 INFO:   Done with stage: TRAINING
2022-11-28 03:25:20,919 INFO:   Starting stage: EVALUATION
2022-11-28 03:25:21,045 INFO:   Done with stage: EVALUATION
2022-11-28 03:25:21,045 INFO:   Leaving out SEQ value Fold_2
2022-11-28 03:25:21,058 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:25:21,058 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:25:21,703 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:25:21,703 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:25:21,771 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:25:21,771 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:25:21,771 INFO:     No hyperparam tuning for this model
2022-11-28 03:25:21,771 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:25:21,771 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:25:21,772 INFO:     None feature selector for col prot
2022-11-28 03:25:21,772 INFO:     None feature selector for col prot
2022-11-28 03:25:21,772 INFO:     None feature selector for col prot
2022-11-28 03:25:21,773 INFO:     None feature selector for col chem
2022-11-28 03:25:21,773 INFO:     None feature selector for col chem
2022-11-28 03:25:21,773 INFO:     None feature selector for col chem
2022-11-28 03:25:21,773 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:25:21,773 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:25:21,774 INFO:     Number of params in model 169741
2022-11-28 03:25:21,777 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:25:21,777 INFO:   Starting stage: TRAINING
2022-11-28 03:25:21,831 INFO:     Val loss before train {'Reaction outcome loss': 1.010978918861259, 'Total loss': 1.010978918861259}
2022-11-28 03:25:21,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:21,831 INFO:     Epoch: 0
2022-11-28 03:25:22,573 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5270018594508822, 'Total loss': 0.5270018594508822} | train loss {'Reaction outcome loss': 0.6271035318311892, 'Total loss': 0.6271035318311892}
2022-11-28 03:25:22,574 INFO:     Found new best model at epoch 0
2022-11-28 03:25:22,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:22,575 INFO:     Epoch: 1
2022-11-28 03:25:23,320 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5116725326939062, 'Total loss': 0.5116725326939062} | train loss {'Reaction outcome loss': 0.492726256248922, 'Total loss': 0.492726256248922}
2022-11-28 03:25:23,320 INFO:     Found new best model at epoch 1
2022-11-28 03:25:23,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:23,321 INFO:     Epoch: 2
2022-11-28 03:25:24,064 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46230446750467474, 'Total loss': 0.46230446750467474} | train loss {'Reaction outcome loss': 0.463911157538775, 'Total loss': 0.463911157538775}
2022-11-28 03:25:24,064 INFO:     Found new best model at epoch 2
2022-11-28 03:25:24,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:24,065 INFO:     Epoch: 3
2022-11-28 03:25:24,806 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45683719658038835, 'Total loss': 0.45683719658038835} | train loss {'Reaction outcome loss': 0.4369112765227976, 'Total loss': 0.4369112765227976}
2022-11-28 03:25:24,806 INFO:     Found new best model at epoch 3
2022-11-28 03:25:24,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:24,807 INFO:     Epoch: 4
2022-11-28 03:25:25,553 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4553052129393274, 'Total loss': 0.4553052129393274} | train loss {'Reaction outcome loss': 0.42440561865746734, 'Total loss': 0.42440561865746734}
2022-11-28 03:25:25,553 INFO:     Found new best model at epoch 4
2022-11-28 03:25:25,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:25,554 INFO:     Epoch: 5
2022-11-28 03:25:26,297 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45917379212650383, 'Total loss': 0.45917379212650383} | train loss {'Reaction outcome loss': 0.41989138601762566, 'Total loss': 0.41989138601762566}
2022-11-28 03:25:26,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:26,297 INFO:     Epoch: 6
2022-11-28 03:25:27,043 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46929759870875964, 'Total loss': 0.46929759870875964} | train loss {'Reaction outcome loss': 0.39854532787915664, 'Total loss': 0.39854532787915664}
2022-11-28 03:25:27,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:27,043 INFO:     Epoch: 7
2022-11-28 03:25:27,789 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.429238248616457, 'Total loss': 0.429238248616457} | train loss {'Reaction outcome loss': 0.4120025330143962, 'Total loss': 0.4120025330143962}
2022-11-28 03:25:27,789 INFO:     Found new best model at epoch 7
2022-11-28 03:25:27,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:27,790 INFO:     Epoch: 8
2022-11-28 03:25:28,537 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42504328523169865, 'Total loss': 0.42504328523169865} | train loss {'Reaction outcome loss': 0.3814623490511346, 'Total loss': 0.3814623490511346}
2022-11-28 03:25:28,537 INFO:     Found new best model at epoch 8
2022-11-28 03:25:28,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:28,538 INFO:     Epoch: 9
2022-11-28 03:25:29,280 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4274493892761794, 'Total loss': 0.4274493892761794} | train loss {'Reaction outcome loss': 0.3864509868718352, 'Total loss': 0.3864509868718352}
2022-11-28 03:25:29,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:29,280 INFO:     Epoch: 10
2022-11-28 03:25:30,025 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42895413630388, 'Total loss': 0.42895413630388} | train loss {'Reaction outcome loss': 0.3830493459636383, 'Total loss': 0.3830493459636383}
2022-11-28 03:25:30,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:30,025 INFO:     Epoch: 11
2022-11-28 03:25:30,771 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4123843579807065, 'Total loss': 0.4123843579807065} | train loss {'Reaction outcome loss': 0.3794482885390946, 'Total loss': 0.3794482885390946}
2022-11-28 03:25:30,771 INFO:     Found new best model at epoch 11
2022-11-28 03:25:30,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:30,772 INFO:     Epoch: 12
2022-11-28 03:25:31,518 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41972208192402666, 'Total loss': 0.41972208192402666} | train loss {'Reaction outcome loss': 0.3642811228027228, 'Total loss': 0.3642811228027228}
2022-11-28 03:25:31,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:31,518 INFO:     Epoch: 13
2022-11-28 03:25:32,266 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42495003071698273, 'Total loss': 0.42495003071698273} | train loss {'Reaction outcome loss': 0.37785904531778114, 'Total loss': 0.37785904531778114}
2022-11-28 03:25:32,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:32,267 INFO:     Epoch: 14
2022-11-28 03:25:33,010 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4245338656685569, 'Total loss': 0.4245338656685569} | train loss {'Reaction outcome loss': 0.3805632988134256, 'Total loss': 0.3805632988134256}
2022-11-28 03:25:33,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:33,011 INFO:     Epoch: 15
2022-11-28 03:25:33,753 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40460667572915554, 'Total loss': 0.40460667572915554} | train loss {'Reaction outcome loss': 0.35416255574598005, 'Total loss': 0.35416255574598005}
2022-11-28 03:25:33,753 INFO:     Found new best model at epoch 15
2022-11-28 03:25:33,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:33,754 INFO:     Epoch: 16
2022-11-28 03:25:34,494 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4053630960935896, 'Total loss': 0.4053630960935896} | train loss {'Reaction outcome loss': 0.36009660915203906, 'Total loss': 0.36009660915203906}
2022-11-28 03:25:34,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:34,494 INFO:     Epoch: 17
2022-11-28 03:25:35,243 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4703913547775962, 'Total loss': 0.4703913547775962} | train loss {'Reaction outcome loss': 0.3590131854781738, 'Total loss': 0.3590131854781738}
2022-11-28 03:25:35,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:35,244 INFO:     Epoch: 18
2022-11-28 03:25:35,985 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38604084707119246, 'Total loss': 0.38604084707119246} | train loss {'Reaction outcome loss': 0.36335305721774275, 'Total loss': 0.36335305721774275}
2022-11-28 03:25:35,985 INFO:     Found new best model at epoch 18
2022-11-28 03:25:35,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:35,986 INFO:     Epoch: 19
2022-11-28 03:25:36,728 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4355772469531406, 'Total loss': 0.4355772469531406} | train loss {'Reaction outcome loss': 0.3513955079049234, 'Total loss': 0.3513955079049234}
2022-11-28 03:25:36,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:36,728 INFO:     Epoch: 20
2022-11-28 03:25:37,471 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.426999531686306, 'Total loss': 0.426999531686306} | train loss {'Reaction outcome loss': 0.35792062028880545, 'Total loss': 0.35792062028880545}
2022-11-28 03:25:37,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:37,471 INFO:     Epoch: 21
2022-11-28 03:25:38,215 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4434224141930992, 'Total loss': 0.4434224141930992} | train loss {'Reaction outcome loss': 0.36599630722210474, 'Total loss': 0.36599630722210474}
2022-11-28 03:25:38,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:38,216 INFO:     Epoch: 22
2022-11-28 03:25:38,958 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43002760308710014, 'Total loss': 0.43002760308710014} | train loss {'Reaction outcome loss': 0.3453134309183731, 'Total loss': 0.3453134309183731}
2022-11-28 03:25:38,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:38,958 INFO:     Epoch: 23
2022-11-28 03:25:39,702 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4154596829956228, 'Total loss': 0.4154596829956228} | train loss {'Reaction outcome loss': 0.35068795463515195, 'Total loss': 0.35068795463515195}
2022-11-28 03:25:39,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:39,703 INFO:     Epoch: 24
2022-11-28 03:25:40,446 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4053156274286183, 'Total loss': 0.4053156274286183} | train loss {'Reaction outcome loss': 0.345598832652282, 'Total loss': 0.345598832652282}
2022-11-28 03:25:40,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:40,446 INFO:     Epoch: 25
2022-11-28 03:25:41,186 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4241605604236776, 'Total loss': 0.4241605604236776} | train loss {'Reaction outcome loss': 0.342944264971851, 'Total loss': 0.342944264971851}
2022-11-28 03:25:41,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:41,187 INFO:     Epoch: 26
2022-11-28 03:25:41,934 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43599878962744365, 'Total loss': 0.43599878962744365} | train loss {'Reaction outcome loss': 0.33547253019896595, 'Total loss': 0.33547253019896595}
2022-11-28 03:25:41,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:41,935 INFO:     Epoch: 27
2022-11-28 03:25:42,681 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4161942665549842, 'Total loss': 0.4161942665549842} | train loss {'Reaction outcome loss': 0.36446493404053965, 'Total loss': 0.36446493404053965}
2022-11-28 03:25:42,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:42,681 INFO:     Epoch: 28
2022-11-28 03:25:43,424 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42807800898497755, 'Total loss': 0.42807800898497755} | train loss {'Reaction outcome loss': 0.33210726240687527, 'Total loss': 0.33210726240687527}
2022-11-28 03:25:43,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:43,424 INFO:     Epoch: 29
2022-11-28 03:25:44,165 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45592069354924286, 'Total loss': 0.45592069354924286} | train loss {'Reaction outcome loss': 0.32919473610752403, 'Total loss': 0.32919473610752403}
2022-11-28 03:25:44,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:44,165 INFO:     Epoch: 30
2022-11-28 03:25:44,909 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49708084914494644, 'Total loss': 0.49708084914494644} | train loss {'Reaction outcome loss': 0.3350923679833138, 'Total loss': 0.3350923679833138}
2022-11-28 03:25:44,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:44,909 INFO:     Epoch: 31
2022-11-28 03:25:45,656 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41653965413570404, 'Total loss': 0.41653965413570404} | train loss {'Reaction outcome loss': 0.34125426761534533, 'Total loss': 0.34125426761534533}
2022-11-28 03:25:45,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:45,656 INFO:     Epoch: 32
2022-11-28 03:25:46,401 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39438536390662193, 'Total loss': 0.39438536390662193} | train loss {'Reaction outcome loss': 0.338671741484917, 'Total loss': 0.338671741484917}
2022-11-28 03:25:46,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:46,401 INFO:     Epoch: 33
2022-11-28 03:25:47,142 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4316708162765611, 'Total loss': 0.4316708162765611} | train loss {'Reaction outcome loss': 0.33324489039689426, 'Total loss': 0.33324489039689426}
2022-11-28 03:25:47,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:47,142 INFO:     Epoch: 34
2022-11-28 03:25:47,885 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4399463927203959, 'Total loss': 0.4399463927203959} | train loss {'Reaction outcome loss': 0.33338390972450194, 'Total loss': 0.33338390972450194}
2022-11-28 03:25:47,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:47,885 INFO:     Epoch: 35
2022-11-28 03:25:48,628 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42141813175244763, 'Total loss': 0.42141813175244763} | train loss {'Reaction outcome loss': 0.332781409499752, 'Total loss': 0.332781409499752}
2022-11-28 03:25:48,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:48,628 INFO:     Epoch: 36
2022-11-28 03:25:49,372 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4345953097058968, 'Total loss': 0.4345953097058968} | train loss {'Reaction outcome loss': 0.34353796643042855, 'Total loss': 0.34353796643042855}
2022-11-28 03:25:49,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:49,372 INFO:     Epoch: 37
2022-11-28 03:25:50,114 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4471579464999112, 'Total loss': 0.4471579464999112} | train loss {'Reaction outcome loss': 0.3504746028708543, 'Total loss': 0.3504746028708543}
2022-11-28 03:25:50,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:50,114 INFO:     Epoch: 38
2022-11-28 03:25:50,860 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42813514274629677, 'Total loss': 0.42813514274629677} | train loss {'Reaction outcome loss': 0.34727677708936605, 'Total loss': 0.34727677708936605}
2022-11-28 03:25:50,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:50,860 INFO:     Epoch: 39
2022-11-28 03:25:51,604 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40797837992960756, 'Total loss': 0.40797837992960756} | train loss {'Reaction outcome loss': 0.32113477048513134, 'Total loss': 0.32113477048513134}
2022-11-28 03:25:51,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:51,604 INFO:     Epoch: 40
2022-11-28 03:25:52,351 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4412454085593874, 'Total loss': 0.4412454085593874} | train loss {'Reaction outcome loss': 0.33360532776788177, 'Total loss': 0.33360532776788177}
2022-11-28 03:25:52,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:52,351 INFO:     Epoch: 41
2022-11-28 03:25:53,095 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3986894363029437, 'Total loss': 0.3986894363029437} | train loss {'Reaction outcome loss': 0.32738966366600414, 'Total loss': 0.32738966366600414}
2022-11-28 03:25:53,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:53,095 INFO:     Epoch: 42
2022-11-28 03:25:53,836 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4203537739813328, 'Total loss': 0.4203537739813328} | train loss {'Reaction outcome loss': 0.324227357939308, 'Total loss': 0.324227357939308}
2022-11-28 03:25:53,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:53,836 INFO:     Epoch: 43
2022-11-28 03:25:54,582 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47249857539480383, 'Total loss': 0.47249857539480383} | train loss {'Reaction outcome loss': 0.3270563014937557, 'Total loss': 0.3270563014937557}
2022-11-28 03:25:54,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:54,583 INFO:     Epoch: 44
2022-11-28 03:25:55,326 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40964157472957263, 'Total loss': 0.40964157472957263} | train loss {'Reaction outcome loss': 0.3292894208811314, 'Total loss': 0.3292894208811314}
2022-11-28 03:25:55,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:55,326 INFO:     Epoch: 45
2022-11-28 03:25:56,070 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3972673151980747, 'Total loss': 0.3972673151980747} | train loss {'Reaction outcome loss': 0.3370420538814671, 'Total loss': 0.3370420538814671}
2022-11-28 03:25:56,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:56,071 INFO:     Epoch: 46
2022-11-28 03:25:56,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3997266605835069, 'Total loss': 0.3997266605835069} | train loss {'Reaction outcome loss': 0.33233191845146753, 'Total loss': 0.33233191845146753}
2022-11-28 03:25:56,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:56,817 INFO:     Epoch: 47
2022-11-28 03:25:57,561 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4094172407957641, 'Total loss': 0.4094172407957641} | train loss {'Reaction outcome loss': 0.3361224590193646, 'Total loss': 0.3361224590193646}
2022-11-28 03:25:57,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:57,562 INFO:     Epoch: 48
2022-11-28 03:25:58,306 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4305082847448913, 'Total loss': 0.4305082847448913} | train loss {'Reaction outcome loss': 0.3443296428796692, 'Total loss': 0.3443296428796692}
2022-11-28 03:25:58,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:58,307 INFO:     Epoch: 49
2022-11-28 03:25:59,051 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42385740036314185, 'Total loss': 0.42385740036314185} | train loss {'Reaction outcome loss': 0.32346336063947756, 'Total loss': 0.32346336063947756}
2022-11-28 03:25:59,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:59,051 INFO:     Epoch: 50
2022-11-28 03:25:59,798 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4106727906248786, 'Total loss': 0.4106727906248786} | train loss {'Reaction outcome loss': 0.33312344469360045, 'Total loss': 0.33312344469360045}
2022-11-28 03:25:59,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:25:59,798 INFO:     Epoch: 51
2022-11-28 03:26:00,543 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42548109794204886, 'Total loss': 0.42548109794204886} | train loss {'Reaction outcome loss': 0.3213922702026297, 'Total loss': 0.3213922702026297}
2022-11-28 03:26:00,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:00,543 INFO:     Epoch: 52
2022-11-28 03:26:01,286 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4230082109570503, 'Total loss': 0.4230082109570503} | train loss {'Reaction outcome loss': 0.3276948338772287, 'Total loss': 0.3276948338772287}
2022-11-28 03:26:01,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:01,286 INFO:     Epoch: 53
2022-11-28 03:26:02,034 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4206129095771096, 'Total loss': 0.4206129095771096} | train loss {'Reaction outcome loss': 0.3276547134103563, 'Total loss': 0.3276547134103563}
2022-11-28 03:26:02,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:02,034 INFO:     Epoch: 54
2022-11-28 03:26:02,780 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41056118803945457, 'Total loss': 0.41056118803945457} | train loss {'Reaction outcome loss': 0.32695710612272444, 'Total loss': 0.32695710612272444}
2022-11-28 03:26:02,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:02,780 INFO:     Epoch: 55
2022-11-28 03:26:03,521 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4077340735291893, 'Total loss': 0.4077340735291893} | train loss {'Reaction outcome loss': 0.32940922472399736, 'Total loss': 0.32940922472399736}
2022-11-28 03:26:03,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:03,521 INFO:     Epoch: 56
2022-11-28 03:26:04,262 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42841973663731053, 'Total loss': 0.42841973663731053} | train loss {'Reaction outcome loss': 0.32988378845969674, 'Total loss': 0.32988378845969674}
2022-11-28 03:26:04,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:04,262 INFO:     Epoch: 57
2022-11-28 03:26:05,009 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4060368151827292, 'Total loss': 0.4060368151827292} | train loss {'Reaction outcome loss': 0.3273497024166439, 'Total loss': 0.3273497024166439}
2022-11-28 03:26:05,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:05,009 INFO:     Epoch: 58
2022-11-28 03:26:05,752 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43336407975717023, 'Total loss': 0.43336407975717023} | train loss {'Reaction outcome loss': 0.32294356887066655, 'Total loss': 0.32294356887066655}
2022-11-28 03:26:05,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:05,752 INFO:     Epoch: 59
2022-11-28 03:26:06,496 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41449152085591445, 'Total loss': 0.41449152085591445} | train loss {'Reaction outcome loss': 0.3235904180637074, 'Total loss': 0.3235904180637074}
2022-11-28 03:26:06,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:06,497 INFO:     Epoch: 60
2022-11-28 03:26:07,241 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44680386917157605, 'Total loss': 0.44680386917157605} | train loss {'Reaction outcome loss': 0.32545015976013925, 'Total loss': 0.32545015976013925}
2022-11-28 03:26:07,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:07,241 INFO:     Epoch: 61
2022-11-28 03:26:07,986 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4080013053661043, 'Total loss': 0.4080013053661043} | train loss {'Reaction outcome loss': 0.32588124492390436, 'Total loss': 0.32588124492390436}
2022-11-28 03:26:07,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:07,986 INFO:     Epoch: 62
2022-11-28 03:26:08,728 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40244954180988396, 'Total loss': 0.40244954180988396} | train loss {'Reaction outcome loss': 0.3268225976390395, 'Total loss': 0.3268225976390395}
2022-11-28 03:26:08,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:08,728 INFO:     Epoch: 63
2022-11-28 03:26:09,471 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4250055829232389, 'Total loss': 0.4250055829232389} | train loss {'Reaction outcome loss': 0.3223067812719627, 'Total loss': 0.3223067812719627}
2022-11-28 03:26:09,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:09,472 INFO:     Epoch: 64
2022-11-28 03:26:10,212 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.430376374586062, 'Total loss': 0.430376374586062} | train loss {'Reaction outcome loss': 0.31920114358668383, 'Total loss': 0.31920114358668383}
2022-11-28 03:26:10,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:10,212 INFO:     Epoch: 65
2022-11-28 03:26:10,954 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37983446703715756, 'Total loss': 0.37983446703715756} | train loss {'Reaction outcome loss': 0.3281442278671844, 'Total loss': 0.3281442278671844}
2022-11-28 03:26:10,954 INFO:     Found new best model at epoch 65
2022-11-28 03:26:10,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:10,955 INFO:     Epoch: 66
2022-11-28 03:26:11,700 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42393754524263466, 'Total loss': 0.42393754524263466} | train loss {'Reaction outcome loss': 0.3331752085553007, 'Total loss': 0.3331752085553007}
2022-11-28 03:26:11,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:11,701 INFO:     Epoch: 67
2022-11-28 03:26:12,444 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4102919233793562, 'Total loss': 0.4102919233793562} | train loss {'Reaction outcome loss': 0.3495758977616847, 'Total loss': 0.3495758977616847}
2022-11-28 03:26:12,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:12,444 INFO:     Epoch: 68
2022-11-28 03:26:13,188 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43624542585828086, 'Total loss': 0.43624542585828086} | train loss {'Reaction outcome loss': 0.320212319312308, 'Total loss': 0.320212319312308}
2022-11-28 03:26:13,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:13,189 INFO:     Epoch: 69
2022-11-28 03:26:13,932 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45530549030412326, 'Total loss': 0.45530549030412326} | train loss {'Reaction outcome loss': 0.3402748965179389, 'Total loss': 0.3402748965179389}
2022-11-28 03:26:13,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:13,932 INFO:     Epoch: 70
2022-11-28 03:26:14,675 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4316282028501684, 'Total loss': 0.4316282028501684} | train loss {'Reaction outcome loss': 0.33101237010256, 'Total loss': 0.33101237010256}
2022-11-28 03:26:14,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:14,675 INFO:     Epoch: 71
2022-11-28 03:26:15,418 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4178715216165239, 'Total loss': 0.4178715216165239} | train loss {'Reaction outcome loss': 0.32490889359310815, 'Total loss': 0.32490889359310815}
2022-11-28 03:26:15,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:15,418 INFO:     Epoch: 72
2022-11-28 03:26:16,160 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4358701187778603, 'Total loss': 0.4358701187778603} | train loss {'Reaction outcome loss': 0.33526614139437194, 'Total loss': 0.33526614139437194}
2022-11-28 03:26:16,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:16,160 INFO:     Epoch: 73
2022-11-28 03:26:16,907 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39701861346309836, 'Total loss': 0.39701861346309836} | train loss {'Reaction outcome loss': 0.36093194607781015, 'Total loss': 0.36093194607781015}
2022-11-28 03:26:16,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:16,908 INFO:     Epoch: 74
2022-11-28 03:26:17,656 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.452804468233477, 'Total loss': 0.452804468233477} | train loss {'Reaction outcome loss': 0.31899462377856136, 'Total loss': 0.31899462377856136}
2022-11-28 03:26:17,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:17,656 INFO:     Epoch: 75
2022-11-28 03:26:18,401 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4103514553809708, 'Total loss': 0.4103514553809708} | train loss {'Reaction outcome loss': 0.3291842747660663, 'Total loss': 0.3291842747660663}
2022-11-28 03:26:18,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:18,401 INFO:     Epoch: 76
2022-11-28 03:26:19,147 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42111577466130257, 'Total loss': 0.42111577466130257} | train loss {'Reaction outcome loss': 0.32527196009149434, 'Total loss': 0.32527196009149434}
2022-11-28 03:26:19,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:19,147 INFO:     Epoch: 77
2022-11-28 03:26:19,891 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4430807237936692, 'Total loss': 0.4430807237936692} | train loss {'Reaction outcome loss': 0.31919309403370266, 'Total loss': 0.31919309403370266}
2022-11-28 03:26:19,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:19,891 INFO:     Epoch: 78
2022-11-28 03:26:20,634 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4138174551454457, 'Total loss': 0.4138174551454457} | train loss {'Reaction outcome loss': 0.3208462236880849, 'Total loss': 0.3208462236880849}
2022-11-28 03:26:20,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:20,634 INFO:     Epoch: 79
2022-11-28 03:26:21,380 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4315148879858581, 'Total loss': 0.4315148879858581} | train loss {'Reaction outcome loss': 0.32364622500502627, 'Total loss': 0.32364622500502627}
2022-11-28 03:26:21,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:21,380 INFO:     Epoch: 80
2022-11-28 03:26:22,123 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42384518970820034, 'Total loss': 0.42384518970820034} | train loss {'Reaction outcome loss': 0.3266548576730828, 'Total loss': 0.3266548576730828}
2022-11-28 03:26:22,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:22,124 INFO:     Epoch: 81
2022-11-28 03:26:22,868 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41270624101161957, 'Total loss': 0.41270624101161957} | train loss {'Reaction outcome loss': 0.32889717719272565, 'Total loss': 0.32889717719272565}
2022-11-28 03:26:22,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:22,868 INFO:     Epoch: 82
2022-11-28 03:26:23,614 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3881113051690839, 'Total loss': 0.3881113051690839} | train loss {'Reaction outcome loss': 0.33586987708261623, 'Total loss': 0.33586987708261623}
2022-11-28 03:26:23,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:23,614 INFO:     Epoch: 83
2022-11-28 03:26:24,358 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4112722272561355, 'Total loss': 0.4112722272561355} | train loss {'Reaction outcome loss': 0.3257499931734583, 'Total loss': 0.3257499931734583}
2022-11-28 03:26:24,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:24,358 INFO:     Epoch: 84
2022-11-28 03:26:25,104 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4167944423177026, 'Total loss': 0.4167944423177026} | train loss {'Reaction outcome loss': 0.33256250117652814, 'Total loss': 0.33256250117652814}
2022-11-28 03:26:25,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:25,104 INFO:     Epoch: 85
2022-11-28 03:26:25,849 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3895493339408528, 'Total loss': 0.3895493339408528} | train loss {'Reaction outcome loss': 0.3142635106799091, 'Total loss': 0.3142635106799091}
2022-11-28 03:26:25,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:25,850 INFO:     Epoch: 86
2022-11-28 03:26:26,593 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4193069562315941, 'Total loss': 0.4193069562315941} | train loss {'Reaction outcome loss': 0.3244598206539868, 'Total loss': 0.3244598206539868}
2022-11-28 03:26:26,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:26,594 INFO:     Epoch: 87
2022-11-28 03:26:27,341 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42425123432820494, 'Total loss': 0.42425123432820494} | train loss {'Reaction outcome loss': 0.33151953889981767, 'Total loss': 0.33151953889981767}
2022-11-28 03:26:27,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:27,341 INFO:     Epoch: 88
2022-11-28 03:26:28,090 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42853210714053025, 'Total loss': 0.42853210714053025} | train loss {'Reaction outcome loss': 0.326144648291197, 'Total loss': 0.326144648291197}
2022-11-28 03:26:28,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:28,091 INFO:     Epoch: 89
2022-11-28 03:26:28,835 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41757460412654007, 'Total loss': 0.41757460412654007} | train loss {'Reaction outcome loss': 0.31989094457986883, 'Total loss': 0.31989094457986883}
2022-11-28 03:26:28,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:28,835 INFO:     Epoch: 90
2022-11-28 03:26:29,580 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5053245025602254, 'Total loss': 0.5053245025602254} | train loss {'Reaction outcome loss': 0.32831264833207074, 'Total loss': 0.32831264833207074}
2022-11-28 03:26:29,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:29,581 INFO:     Epoch: 91
2022-11-28 03:26:30,321 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41754326901652594, 'Total loss': 0.41754326901652594} | train loss {'Reaction outcome loss': 0.32067308195221883, 'Total loss': 0.32067308195221883}
2022-11-28 03:26:30,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:30,322 INFO:     Epoch: 92
2022-11-28 03:26:31,067 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3938420668921687, 'Total loss': 0.3938420668921687} | train loss {'Reaction outcome loss': 0.3195011978327987, 'Total loss': 0.3195011978327987}
2022-11-28 03:26:31,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:31,067 INFO:     Epoch: 93
2022-11-28 03:26:31,811 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4275855452499606, 'Total loss': 0.4275855452499606} | train loss {'Reaction outcome loss': 0.3214076116288963, 'Total loss': 0.3214076116288963}
2022-11-28 03:26:31,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:31,811 INFO:     Epoch: 94
2022-11-28 03:26:32,553 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39294482564384287, 'Total loss': 0.39294482564384287} | train loss {'Reaction outcome loss': 0.3335769722438022, 'Total loss': 0.3335769722438022}
2022-11-28 03:26:32,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:32,554 INFO:     Epoch: 95
2022-11-28 03:26:33,296 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45321282879872754, 'Total loss': 0.45321282879872754} | train loss {'Reaction outcome loss': 0.31256748633346093, 'Total loss': 0.31256748633346093}
2022-11-28 03:26:33,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:33,296 INFO:     Epoch: 96
2022-11-28 03:26:34,037 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4054882302880287, 'Total loss': 0.4054882302880287} | train loss {'Reaction outcome loss': 0.32999731511299907, 'Total loss': 0.32999731511299907}
2022-11-28 03:26:34,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:34,037 INFO:     Epoch: 97
2022-11-28 03:26:34,780 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41785834899002855, 'Total loss': 0.41785834899002855} | train loss {'Reaction outcome loss': 0.3232293767545387, 'Total loss': 0.3232293767545387}
2022-11-28 03:26:34,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:34,780 INFO:     Epoch: 98
2022-11-28 03:26:35,527 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.476482956585559, 'Total loss': 0.476482956585559} | train loss {'Reaction outcome loss': 0.3334678601518816, 'Total loss': 0.3334678601518816}
2022-11-28 03:26:35,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:35,527 INFO:     Epoch: 99
2022-11-28 03:26:36,270 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41033771295439114, 'Total loss': 0.41033771295439114} | train loss {'Reaction outcome loss': 0.33116639882084814, 'Total loss': 0.33116639882084814}
2022-11-28 03:26:36,270 INFO:     Best model found after epoch 66 of 100.
2022-11-28 03:26:36,270 INFO:   Done with stage: TRAINING
2022-11-28 03:26:36,270 INFO:   Starting stage: EVALUATION
2022-11-28 03:26:36,392 INFO:   Done with stage: EVALUATION
2022-11-28 03:26:36,392 INFO:   Leaving out SEQ value Fold_3
2022-11-28 03:26:36,405 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:26:36,406 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:26:37,056 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:26:37,056 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:26:37,126 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:26:37,126 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:26:37,126 INFO:     No hyperparam tuning for this model
2022-11-28 03:26:37,126 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:26:37,126 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:26:37,127 INFO:     None feature selector for col prot
2022-11-28 03:26:37,127 INFO:     None feature selector for col prot
2022-11-28 03:26:37,127 INFO:     None feature selector for col prot
2022-11-28 03:26:37,128 INFO:     None feature selector for col chem
2022-11-28 03:26:37,128 INFO:     None feature selector for col chem
2022-11-28 03:26:37,128 INFO:     None feature selector for col chem
2022-11-28 03:26:37,128 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:26:37,128 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:26:37,130 INFO:     Number of params in model 169741
2022-11-28 03:26:37,133 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:26:37,133 INFO:   Starting stage: TRAINING
2022-11-28 03:26:37,187 INFO:     Val loss before train {'Reaction outcome loss': 1.0090288736603477, 'Total loss': 1.0090288736603477}
2022-11-28 03:26:37,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:37,187 INFO:     Epoch: 0
2022-11-28 03:26:37,932 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5939657938751307, 'Total loss': 0.5939657938751307} | train loss {'Reaction outcome loss': 0.6387895308887428, 'Total loss': 0.6387895308887428}
2022-11-28 03:26:37,933 INFO:     Found new best model at epoch 0
2022-11-28 03:26:37,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:37,934 INFO:     Epoch: 1
2022-11-28 03:26:38,679 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4941106472503055, 'Total loss': 0.4941106472503055} | train loss {'Reaction outcome loss': 0.5077671829746803, 'Total loss': 0.5077671829746803}
2022-11-28 03:26:38,679 INFO:     Found new best model at epoch 1
2022-11-28 03:26:38,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:38,680 INFO:     Epoch: 2
2022-11-28 03:26:39,422 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49468675594438205, 'Total loss': 0.49468675594438205} | train loss {'Reaction outcome loss': 0.4703128260941158, 'Total loss': 0.4703128260941158}
2022-11-28 03:26:39,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:39,422 INFO:     Epoch: 3
2022-11-28 03:26:40,163 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4858160791071979, 'Total loss': 0.4858160791071979} | train loss {'Reaction outcome loss': 0.4481469216617013, 'Total loss': 0.4481469216617013}
2022-11-28 03:26:40,163 INFO:     Found new best model at epoch 3
2022-11-28 03:26:40,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:40,164 INFO:     Epoch: 4
2022-11-28 03:26:40,907 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47824307260188187, 'Total loss': 0.47824307260188187} | train loss {'Reaction outcome loss': 0.43928502023461374, 'Total loss': 0.43928502023461374}
2022-11-28 03:26:40,907 INFO:     Found new best model at epoch 4
2022-11-28 03:26:40,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:40,908 INFO:     Epoch: 5
2022-11-28 03:26:41,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4435406124049967, 'Total loss': 0.4435406124049967} | train loss {'Reaction outcome loss': 0.42423751757212497, 'Total loss': 0.42423751757212497}
2022-11-28 03:26:41,652 INFO:     Found new best model at epoch 5
2022-11-28 03:26:41,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:41,653 INFO:     Epoch: 6
2022-11-28 03:26:42,398 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47212999999861827, 'Total loss': 0.47212999999861827} | train loss {'Reaction outcome loss': 0.40716818551182266, 'Total loss': 0.40716818551182266}
2022-11-28 03:26:42,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:42,398 INFO:     Epoch: 7
2022-11-28 03:26:43,140 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44547158919952135, 'Total loss': 0.44547158919952135} | train loss {'Reaction outcome loss': 0.39441687797727853, 'Total loss': 0.39441687797727853}
2022-11-28 03:26:43,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:43,140 INFO:     Epoch: 8
2022-11-28 03:26:43,882 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4578409663994204, 'Total loss': 0.4578409663994204} | train loss {'Reaction outcome loss': 0.38353203077185977, 'Total loss': 0.38353203077185977}
2022-11-28 03:26:43,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:43,882 INFO:     Epoch: 9
2022-11-28 03:26:44,625 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4653568670830943, 'Total loss': 0.4653568670830943} | train loss {'Reaction outcome loss': 0.3791706717086707, 'Total loss': 0.3791706717086707}
2022-11-28 03:26:44,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:44,626 INFO:     Epoch: 10
2022-11-28 03:26:45,368 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4552654027938843, 'Total loss': 0.4552654027938843} | train loss {'Reaction outcome loss': 0.37604158039596913, 'Total loss': 0.37604158039596913}
2022-11-28 03:26:45,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:45,368 INFO:     Epoch: 11
2022-11-28 03:26:46,117 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4497991163622249, 'Total loss': 0.4497991163622249} | train loss {'Reaction outcome loss': 0.36875749930271856, 'Total loss': 0.36875749930271856}
2022-11-28 03:26:46,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:46,117 INFO:     Epoch: 12
2022-11-28 03:26:46,862 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4631459748541767, 'Total loss': 0.4631459748541767} | train loss {'Reaction outcome loss': 0.3609347146170342, 'Total loss': 0.3609347146170342}
2022-11-28 03:26:46,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:46,862 INFO:     Epoch: 13
2022-11-28 03:26:47,605 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47221899506720627, 'Total loss': 0.47221899506720627} | train loss {'Reaction outcome loss': 0.361706808903198, 'Total loss': 0.361706808903198}
2022-11-28 03:26:47,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:47,605 INFO:     Epoch: 14
2022-11-28 03:26:48,348 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42597707377916033, 'Total loss': 0.42597707377916033} | train loss {'Reaction outcome loss': 0.35739679746178965, 'Total loss': 0.35739679746178965}
2022-11-28 03:26:48,349 INFO:     Found new best model at epoch 14
2022-11-28 03:26:48,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:48,349 INFO:     Epoch: 15
2022-11-28 03:26:49,095 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47289351881905034, 'Total loss': 0.47289351881905034} | train loss {'Reaction outcome loss': 0.3535522315726589, 'Total loss': 0.3535522315726589}
2022-11-28 03:26:49,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:49,095 INFO:     Epoch: 16
2022-11-28 03:26:49,837 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43267137658866966, 'Total loss': 0.43267137658866966} | train loss {'Reaction outcome loss': 0.35554373048072463, 'Total loss': 0.35554373048072463}
2022-11-28 03:26:49,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:49,837 INFO:     Epoch: 17
2022-11-28 03:26:50,582 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44594683159481396, 'Total loss': 0.44594683159481396} | train loss {'Reaction outcome loss': 0.3430781847220442, 'Total loss': 0.3430781847220442}
2022-11-28 03:26:50,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:50,582 INFO:     Epoch: 18
2022-11-28 03:26:51,326 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4512185891243545, 'Total loss': 0.4512185891243545} | train loss {'Reaction outcome loss': 0.34934318729257774, 'Total loss': 0.34934318729257774}
2022-11-28 03:26:51,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:51,326 INFO:     Epoch: 19
2022-11-28 03:26:52,070 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4251897497610612, 'Total loss': 0.4251897497610612} | train loss {'Reaction outcome loss': 0.34345797757026153, 'Total loss': 0.34345797757026153}
2022-11-28 03:26:52,070 INFO:     Found new best model at epoch 19
2022-11-28 03:26:52,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:52,071 INFO:     Epoch: 20
2022-11-28 03:26:52,815 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4264194196598096, 'Total loss': 0.4264194196598096} | train loss {'Reaction outcome loss': 0.3398569618702417, 'Total loss': 0.3398569618702417}
2022-11-28 03:26:52,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:52,815 INFO:     Epoch: 21
2022-11-28 03:26:53,560 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4345542456616055, 'Total loss': 0.4345542456616055} | train loss {'Reaction outcome loss': 0.34004191697955977, 'Total loss': 0.34004191697955977}
2022-11-28 03:26:53,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:53,560 INFO:     Epoch: 22
2022-11-28 03:26:54,303 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45672049441120843, 'Total loss': 0.45672049441120843} | train loss {'Reaction outcome loss': 0.3281246398383307, 'Total loss': 0.3281246398383307}
2022-11-28 03:26:54,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:54,303 INFO:     Epoch: 23
2022-11-28 03:26:55,045 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4329961568794467, 'Total loss': 0.4329961568794467} | train loss {'Reaction outcome loss': 0.346019018064385, 'Total loss': 0.346019018064385}
2022-11-28 03:26:55,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:55,045 INFO:     Epoch: 24
2022-11-28 03:26:55,786 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4283432059667327, 'Total loss': 0.4283432059667327} | train loss {'Reaction outcome loss': 0.32888794059936816, 'Total loss': 0.32888794059936816}
2022-11-28 03:26:55,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:55,787 INFO:     Epoch: 25
2022-11-28 03:26:56,530 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44320136308670044, 'Total loss': 0.44320136308670044} | train loss {'Reaction outcome loss': 0.3354332693494283, 'Total loss': 0.3354332693494283}
2022-11-28 03:26:56,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:56,530 INFO:     Epoch: 26
2022-11-28 03:26:57,275 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43539442562244157, 'Total loss': 0.43539442562244157} | train loss {'Reaction outcome loss': 0.33339673313896667, 'Total loss': 0.33339673313896667}
2022-11-28 03:26:57,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:57,276 INFO:     Epoch: 27
2022-11-28 03:26:58,020 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46328103880990634, 'Total loss': 0.46328103880990634} | train loss {'Reaction outcome loss': 0.33684044409268027, 'Total loss': 0.33684044409268027}
2022-11-28 03:26:58,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:58,021 INFO:     Epoch: 28
2022-11-28 03:26:58,765 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4109437336975878, 'Total loss': 0.4109437336975878} | train loss {'Reaction outcome loss': 0.3365178208360788, 'Total loss': 0.3365178208360788}
2022-11-28 03:26:58,765 INFO:     Found new best model at epoch 28
2022-11-28 03:26:58,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:58,766 INFO:     Epoch: 29
2022-11-28 03:26:59,512 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4407374564219605, 'Total loss': 0.4407374564219605} | train loss {'Reaction outcome loss': 0.33434240423474715, 'Total loss': 0.33434240423474715}
2022-11-28 03:26:59,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:26:59,512 INFO:     Epoch: 30
2022-11-28 03:27:00,253 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4365134107118303, 'Total loss': 0.4365134107118303} | train loss {'Reaction outcome loss': 0.3275581382908802, 'Total loss': 0.3275581382908802}
2022-11-28 03:27:00,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:00,253 INFO:     Epoch: 31
2022-11-28 03:27:00,996 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44643747027624736, 'Total loss': 0.44643747027624736} | train loss {'Reaction outcome loss': 0.3245264263710512, 'Total loss': 0.3245264263710512}
2022-11-28 03:27:00,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:00,996 INFO:     Epoch: 32
2022-11-28 03:27:01,737 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47071952745318413, 'Total loss': 0.47071952745318413} | train loss {'Reaction outcome loss': 0.3263725036913567, 'Total loss': 0.3263725036913567}
2022-11-28 03:27:01,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:01,737 INFO:     Epoch: 33
2022-11-28 03:27:02,480 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43273381888866425, 'Total loss': 0.43273381888866425} | train loss {'Reaction outcome loss': 0.3313451813088979, 'Total loss': 0.3313451813088979}
2022-11-28 03:27:02,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:02,481 INFO:     Epoch: 34
2022-11-28 03:27:03,222 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44600835916670883, 'Total loss': 0.44600835916670883} | train loss {'Reaction outcome loss': 0.3223184772167611, 'Total loss': 0.3223184772167611}
2022-11-28 03:27:03,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:03,222 INFO:     Epoch: 35
2022-11-28 03:27:03,962 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4594958768310872, 'Total loss': 0.4594958768310872} | train loss {'Reaction outcome loss': 0.3175020557573736, 'Total loss': 0.3175020557573736}
2022-11-28 03:27:03,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:03,963 INFO:     Epoch: 36
2022-11-28 03:27:04,707 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4752967447381128, 'Total loss': 0.4752967447381128} | train loss {'Reaction outcome loss': 0.3236016695791109, 'Total loss': 0.3236016695791109}
2022-11-28 03:27:04,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:04,707 INFO:     Epoch: 37
2022-11-28 03:27:05,447 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43961717967282643, 'Total loss': 0.43961717967282643} | train loss {'Reaction outcome loss': 0.3207721885252246, 'Total loss': 0.3207721885252246}
2022-11-28 03:27:05,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:05,447 INFO:     Epoch: 38
2022-11-28 03:27:06,189 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4187182607975873, 'Total loss': 0.4187182607975873} | train loss {'Reaction outcome loss': 0.3234139971947863, 'Total loss': 0.3234139971947863}
2022-11-28 03:27:06,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:06,190 INFO:     Epoch: 39
2022-11-28 03:27:06,932 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42359491691670637, 'Total loss': 0.42359491691670637} | train loss {'Reaction outcome loss': 0.3211547701585631, 'Total loss': 0.3211547701585631}
2022-11-28 03:27:06,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:06,932 INFO:     Epoch: 40
2022-11-28 03:27:07,675 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4595230750062249, 'Total loss': 0.4595230750062249} | train loss {'Reaction outcome loss': 0.32993494861039074, 'Total loss': 0.32993494861039074}
2022-11-28 03:27:07,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:07,675 INFO:     Epoch: 41
2022-11-28 03:27:08,419 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46560251780531625, 'Total loss': 0.46560251780531625} | train loss {'Reaction outcome loss': 0.32411265970483, 'Total loss': 0.32411265970483}
2022-11-28 03:27:08,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:08,419 INFO:     Epoch: 42
2022-11-28 03:27:09,164 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4351275253363631, 'Total loss': 0.4351275253363631} | train loss {'Reaction outcome loss': 0.3176956199381033, 'Total loss': 0.3176956199381033}
2022-11-28 03:27:09,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:09,165 INFO:     Epoch: 43
2022-11-28 03:27:09,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42856857214461674, 'Total loss': 0.42856857214461674} | train loss {'Reaction outcome loss': 0.3203056901994987, 'Total loss': 0.3203056901994987}
2022-11-28 03:27:09,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:09,908 INFO:     Epoch: 44
2022-11-28 03:27:10,652 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4541468965736302, 'Total loss': 0.4541468965736302} | train loss {'Reaction outcome loss': 0.32170275861193776, 'Total loss': 0.32170275861193776}
2022-11-28 03:27:10,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:10,652 INFO:     Epoch: 45
2022-11-28 03:27:11,395 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4153633801774545, 'Total loss': 0.4153633801774545} | train loss {'Reaction outcome loss': 0.33670477195065995, 'Total loss': 0.33670477195065995}
2022-11-28 03:27:11,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:11,395 INFO:     Epoch: 46
2022-11-28 03:27:12,135 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4448619020933455, 'Total loss': 0.4448619020933455} | train loss {'Reaction outcome loss': 0.31881660832325937, 'Total loss': 0.31881660832325937}
2022-11-28 03:27:12,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:12,135 INFO:     Epoch: 47
2022-11-28 03:27:12,874 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4495688710700382, 'Total loss': 0.4495688710700382} | train loss {'Reaction outcome loss': 0.31274695799603297, 'Total loss': 0.31274695799603297}
2022-11-28 03:27:12,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:12,875 INFO:     Epoch: 48
2022-11-28 03:27:13,613 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43868654390627687, 'Total loss': 0.43868654390627687} | train loss {'Reaction outcome loss': 0.31093598564385405, 'Total loss': 0.31093598564385405}
2022-11-28 03:27:13,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:13,614 INFO:     Epoch: 49
2022-11-28 03:27:14,358 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43223080479285936, 'Total loss': 0.43223080479285936} | train loss {'Reaction outcome loss': 0.3195659226326928, 'Total loss': 0.3195659226326928}
2022-11-28 03:27:14,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:14,358 INFO:     Epoch: 50
2022-11-28 03:27:15,101 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40046966753222724, 'Total loss': 0.40046966753222724} | train loss {'Reaction outcome loss': 0.3063301433722379, 'Total loss': 0.3063301433722379}
2022-11-28 03:27:15,102 INFO:     Found new best model at epoch 50
2022-11-28 03:27:15,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:15,102 INFO:     Epoch: 51
2022-11-28 03:27:15,844 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44198639115149324, 'Total loss': 0.44198639115149324} | train loss {'Reaction outcome loss': 0.3134614786638422, 'Total loss': 0.3134614786638422}
2022-11-28 03:27:15,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:15,845 INFO:     Epoch: 52
2022-11-28 03:27:16,590 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4624849310652776, 'Total loss': 0.4624849310652776} | train loss {'Reaction outcome loss': 0.31157672227273586, 'Total loss': 0.31157672227273586}
2022-11-28 03:27:16,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:16,590 INFO:     Epoch: 53
2022-11-28 03:27:17,333 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.434449167414145, 'Total loss': 0.434449167414145} | train loss {'Reaction outcome loss': 0.3046692488224883, 'Total loss': 0.3046692488224883}
2022-11-28 03:27:17,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:17,334 INFO:     Epoch: 54
2022-11-28 03:27:18,081 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48093471879308874, 'Total loss': 0.48093471879308874} | train loss {'Reaction outcome loss': 0.31710130217586935, 'Total loss': 0.31710130217586935}
2022-11-28 03:27:18,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:18,081 INFO:     Epoch: 55
2022-11-28 03:27:18,826 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42896489291028544, 'Total loss': 0.42896489291028544} | train loss {'Reaction outcome loss': 0.31325197109654696, 'Total loss': 0.31325197109654696}
2022-11-28 03:27:18,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:18,826 INFO:     Epoch: 56
2022-11-28 03:27:19,568 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44731280918825755, 'Total loss': 0.44731280918825755} | train loss {'Reaction outcome loss': 0.3017783812756239, 'Total loss': 0.3017783812756239}
2022-11-28 03:27:19,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:19,568 INFO:     Epoch: 57
2022-11-28 03:27:20,312 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43408944898030977, 'Total loss': 0.43408944898030977} | train loss {'Reaction outcome loss': 0.312626462233694, 'Total loss': 0.312626462233694}
2022-11-28 03:27:20,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:20,313 INFO:     Epoch: 58
2022-11-28 03:27:21,057 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42748374305665493, 'Total loss': 0.42748374305665493} | train loss {'Reaction outcome loss': 0.3076143021947942, 'Total loss': 0.3076143021947942}
2022-11-28 03:27:21,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:21,057 INFO:     Epoch: 59
2022-11-28 03:27:21,800 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4410053760829297, 'Total loss': 0.4410053760829297} | train loss {'Reaction outcome loss': 0.3236385797096703, 'Total loss': 0.3236385797096703}
2022-11-28 03:27:21,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:21,801 INFO:     Epoch: 60
2022-11-28 03:27:22,545 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44639370184053073, 'Total loss': 0.44639370184053073} | train loss {'Reaction outcome loss': 0.3046565610068937, 'Total loss': 0.3046565610068937}
2022-11-28 03:27:22,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:22,545 INFO:     Epoch: 61
2022-11-28 03:27:23,287 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41862109303474426, 'Total loss': 0.41862109303474426} | train loss {'Reaction outcome loss': 0.3035846023381073, 'Total loss': 0.3035846023381073}
2022-11-28 03:27:23,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:23,288 INFO:     Epoch: 62
2022-11-28 03:27:24,033 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4758089848540046, 'Total loss': 0.4758089848540046} | train loss {'Reaction outcome loss': 0.30703697558907184, 'Total loss': 0.30703697558907184}
2022-11-28 03:27:24,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:24,033 INFO:     Epoch: 63
2022-11-28 03:27:24,775 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4337429543957114, 'Total loss': 0.4337429543957114} | train loss {'Reaction outcome loss': 0.30764774498548586, 'Total loss': 0.30764774498548586}
2022-11-28 03:27:24,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:24,776 INFO:     Epoch: 64
2022-11-28 03:27:25,520 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47149503366513684, 'Total loss': 0.47149503366513684} | train loss {'Reaction outcome loss': 0.3006553222111385, 'Total loss': 0.3006553222111385}
2022-11-28 03:27:25,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:25,520 INFO:     Epoch: 65
2022-11-28 03:27:26,263 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43630552156405017, 'Total loss': 0.43630552156405017} | train loss {'Reaction outcome loss': 0.3064934736803958, 'Total loss': 0.3064934736803958}
2022-11-28 03:27:26,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:26,264 INFO:     Epoch: 66
2022-11-28 03:27:27,007 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4736228249967098, 'Total loss': 0.4736228249967098} | train loss {'Reaction outcome loss': 0.3098702811417339, 'Total loss': 0.3098702811417339}
2022-11-28 03:27:27,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:27,007 INFO:     Epoch: 67
2022-11-28 03:27:27,749 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4401958750730211, 'Total loss': 0.4401958750730211} | train loss {'Reaction outcome loss': 0.3019297585411653, 'Total loss': 0.3019297585411653}
2022-11-28 03:27:27,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:27,749 INFO:     Epoch: 68
2022-11-28 03:27:28,491 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4349635270508853, 'Total loss': 0.4349635270508853} | train loss {'Reaction outcome loss': 0.2965429964124674, 'Total loss': 0.2965429964124674}
2022-11-28 03:27:28,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:28,492 INFO:     Epoch: 69
2022-11-28 03:27:29,234 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4514753334224224, 'Total loss': 0.4514753334224224} | train loss {'Reaction outcome loss': 0.3148516319420656, 'Total loss': 0.3148516319420656}
2022-11-28 03:27:29,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:29,234 INFO:     Epoch: 70
2022-11-28 03:27:29,976 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4358191425827416, 'Total loss': 0.4358191425827416} | train loss {'Reaction outcome loss': 0.2996066694981174, 'Total loss': 0.2996066694981174}
2022-11-28 03:27:29,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:29,976 INFO:     Epoch: 71
2022-11-28 03:27:30,717 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4373194145208055, 'Total loss': 0.4373194145208055} | train loss {'Reaction outcome loss': 0.30349886741655074, 'Total loss': 0.30349886741655074}
2022-11-28 03:27:30,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:30,717 INFO:     Epoch: 72
2022-11-28 03:27:31,457 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4525134820829738, 'Total loss': 0.4525134820829738} | train loss {'Reaction outcome loss': 0.29990806650212, 'Total loss': 0.29990806650212}
2022-11-28 03:27:31,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:31,458 INFO:     Epoch: 73
2022-11-28 03:27:32,199 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44607511738484557, 'Total loss': 0.44607511738484557} | train loss {'Reaction outcome loss': 0.3081474715564777, 'Total loss': 0.3081474715564777}
2022-11-28 03:27:32,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:32,200 INFO:     Epoch: 74
2022-11-28 03:27:32,948 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4381968429820104, 'Total loss': 0.4381968429820104} | train loss {'Reaction outcome loss': 0.3024558324502547, 'Total loss': 0.3024558324502547}
2022-11-28 03:27:32,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:32,948 INFO:     Epoch: 75
2022-11-28 03:27:33,691 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4807291488078507, 'Total loss': 0.4807291488078507} | train loss {'Reaction outcome loss': 0.30679210324428585, 'Total loss': 0.30679210324428585}
2022-11-28 03:27:33,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:33,691 INFO:     Epoch: 76
2022-11-28 03:27:34,434 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4357841204513203, 'Total loss': 0.4357841204513203} | train loss {'Reaction outcome loss': 0.3066106691564384, 'Total loss': 0.3066106691564384}
2022-11-28 03:27:34,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:34,434 INFO:     Epoch: 77
2022-11-28 03:27:35,175 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4306033597412435, 'Total loss': 0.4306033597412435} | train loss {'Reaction outcome loss': 0.3106939398084092, 'Total loss': 0.3106939398084092}
2022-11-28 03:27:35,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:35,176 INFO:     Epoch: 78
2022-11-28 03:27:35,915 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42392509210516105, 'Total loss': 0.42392509210516105} | train loss {'Reaction outcome loss': 0.3134002340467353, 'Total loss': 0.3134002340467353}
2022-11-28 03:27:35,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:35,916 INFO:     Epoch: 79
2022-11-28 03:27:36,656 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4213446487079967, 'Total loss': 0.4213446487079967} | train loss {'Reaction outcome loss': 0.3054422805244141, 'Total loss': 0.3054422805244141}
2022-11-28 03:27:36,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:36,657 INFO:     Epoch: 80
2022-11-28 03:27:37,402 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4160572442818772, 'Total loss': 0.4160572442818772} | train loss {'Reaction outcome loss': 0.3035967358753749, 'Total loss': 0.3035967358753749}
2022-11-28 03:27:37,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:37,402 INFO:     Epoch: 81
2022-11-28 03:27:38,146 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43890918300233106, 'Total loss': 0.43890918300233106} | train loss {'Reaction outcome loss': 0.31598404233875543, 'Total loss': 0.31598404233875543}
2022-11-28 03:27:38,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:38,146 INFO:     Epoch: 82
2022-11-28 03:27:38,885 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4404378736560995, 'Total loss': 0.4404378736560995} | train loss {'Reaction outcome loss': 0.3075991614291874, 'Total loss': 0.3075991614291874}
2022-11-28 03:27:38,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:38,886 INFO:     Epoch: 83
2022-11-28 03:27:39,627 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5091217949309133, 'Total loss': 0.5091217949309133} | train loss {'Reaction outcome loss': 0.31132897058961845, 'Total loss': 0.31132897058961845}
2022-11-28 03:27:39,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:39,627 INFO:     Epoch: 84
2022-11-28 03:27:40,371 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4361773013052615, 'Total loss': 0.4361773013052615} | train loss {'Reaction outcome loss': 0.31673212708369924, 'Total loss': 0.31673212708369924}
2022-11-28 03:27:40,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:40,372 INFO:     Epoch: 85
2022-11-28 03:27:41,113 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41723770140246913, 'Total loss': 0.41723770140246913} | train loss {'Reaction outcome loss': 0.326968338144453, 'Total loss': 0.326968338144453}
2022-11-28 03:27:41,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:41,113 INFO:     Epoch: 86
2022-11-28 03:27:41,858 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4483102404258468, 'Total loss': 0.4483102404258468} | train loss {'Reaction outcome loss': 0.3026680820564992, 'Total loss': 0.3026680820564992}
2022-11-28 03:27:41,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:41,858 INFO:     Epoch: 87
2022-11-28 03:27:42,600 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4381961641325192, 'Total loss': 0.4381961641325192} | train loss {'Reaction outcome loss': 0.297645161901167, 'Total loss': 0.297645161901167}
2022-11-28 03:27:42,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:42,600 INFO:     Epoch: 88
2022-11-28 03:27:43,340 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4375946464186365, 'Total loss': 0.4375946464186365} | train loss {'Reaction outcome loss': 0.29838646949330266, 'Total loss': 0.29838646949330266}
2022-11-28 03:27:43,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:43,341 INFO:     Epoch: 89
2022-11-28 03:27:44,083 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4660529426553033, 'Total loss': 0.4660529426553033} | train loss {'Reaction outcome loss': 0.2997847863356112, 'Total loss': 0.2997847863356112}
2022-11-28 03:27:44,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:44,084 INFO:     Epoch: 90
2022-11-28 03:27:44,825 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4207828715443611, 'Total loss': 0.4207828715443611} | train loss {'Reaction outcome loss': 0.30741741588334026, 'Total loss': 0.30741741588334026}
2022-11-28 03:27:44,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:44,825 INFO:     Epoch: 91
2022-11-28 03:27:45,568 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4356712814081799, 'Total loss': 0.4356712814081799} | train loss {'Reaction outcome loss': 0.3037615994270514, 'Total loss': 0.3037615994270514}
2022-11-28 03:27:45,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:45,568 INFO:     Epoch: 92
2022-11-28 03:27:46,310 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47134834494103084, 'Total loss': 0.47134834494103084} | train loss {'Reaction outcome loss': 0.30866516954623735, 'Total loss': 0.30866516954623735}
2022-11-28 03:27:46,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:46,310 INFO:     Epoch: 93
2022-11-28 03:27:47,053 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4402145855128765, 'Total loss': 0.4402145855128765} | train loss {'Reaction outcome loss': 0.3174347515380093, 'Total loss': 0.3174347515380093}
2022-11-28 03:27:47,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:47,054 INFO:     Epoch: 94
2022-11-28 03:27:47,798 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4163218408145688, 'Total loss': 0.4163218408145688} | train loss {'Reaction outcome loss': 0.30036627581184694, 'Total loss': 0.30036627581184694}
2022-11-28 03:27:47,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:47,798 INFO:     Epoch: 95
2022-11-28 03:27:48,539 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44676889208230103, 'Total loss': 0.44676889208230103} | train loss {'Reaction outcome loss': 0.3226358714675614, 'Total loss': 0.3226358714675614}
2022-11-28 03:27:48,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:48,540 INFO:     Epoch: 96
2022-11-28 03:27:49,285 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43721808764067566, 'Total loss': 0.43721808764067566} | train loss {'Reaction outcome loss': 0.3083286053738613, 'Total loss': 0.3083286053738613}
2022-11-28 03:27:49,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:49,285 INFO:     Epoch: 97
2022-11-28 03:27:50,029 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4839730801230127, 'Total loss': 0.4839730801230127} | train loss {'Reaction outcome loss': 0.30956135822935144, 'Total loss': 0.30956135822935144}
2022-11-28 03:27:50,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:50,029 INFO:     Epoch: 98
2022-11-28 03:27:50,773 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44092324071309785, 'Total loss': 0.44092324071309785} | train loss {'Reaction outcome loss': 0.30881417271217354, 'Total loss': 0.30881417271217354}
2022-11-28 03:27:50,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:50,773 INFO:     Epoch: 99
2022-11-28 03:27:51,517 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43827543627809395, 'Total loss': 0.43827543627809395} | train loss {'Reaction outcome loss': 0.2817491372964281, 'Total loss': 0.2817491372964281}
2022-11-28 03:27:51,518 INFO:     Best model found after epoch 51 of 100.
2022-11-28 03:27:51,518 INFO:   Done with stage: TRAINING
2022-11-28 03:27:51,518 INFO:   Starting stage: EVALUATION
2022-11-28 03:27:51,639 INFO:   Done with stage: EVALUATION
2022-11-28 03:27:51,640 INFO:   Leaving out SEQ value Fold_4
2022-11-28 03:27:51,653 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:27:51,653 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:27:52,294 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:27:52,295 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:27:52,363 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:27:52,363 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:27:52,363 INFO:     No hyperparam tuning for this model
2022-11-28 03:27:52,363 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:27:52,363 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:27:52,364 INFO:     None feature selector for col prot
2022-11-28 03:27:52,364 INFO:     None feature selector for col prot
2022-11-28 03:27:52,364 INFO:     None feature selector for col prot
2022-11-28 03:27:52,365 INFO:     None feature selector for col chem
2022-11-28 03:27:52,365 INFO:     None feature selector for col chem
2022-11-28 03:27:52,365 INFO:     None feature selector for col chem
2022-11-28 03:27:52,365 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:27:52,365 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:27:52,367 INFO:     Number of params in model 169741
2022-11-28 03:27:52,370 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:27:52,370 INFO:   Starting stage: TRAINING
2022-11-28 03:27:52,424 INFO:     Val loss before train {'Reaction outcome loss': 0.9784167002547871, 'Total loss': 0.9784167002547871}
2022-11-28 03:27:52,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:52,424 INFO:     Epoch: 0
2022-11-28 03:27:53,173 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5245840055021372, 'Total loss': 0.5245840055021372} | train loss {'Reaction outcome loss': 0.6319675463582238, 'Total loss': 0.6319675463582238}
2022-11-28 03:27:53,173 INFO:     Found new best model at epoch 0
2022-11-28 03:27:53,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:53,174 INFO:     Epoch: 1
2022-11-28 03:27:53,921 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.486221660267223, 'Total loss': 0.486221660267223} | train loss {'Reaction outcome loss': 0.5084730164418297, 'Total loss': 0.5084730164418297}
2022-11-28 03:27:53,922 INFO:     Found new best model at epoch 1
2022-11-28 03:27:53,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:53,922 INFO:     Epoch: 2
2022-11-28 03:27:54,672 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4836975877935236, 'Total loss': 0.4836975877935236} | train loss {'Reaction outcome loss': 0.4680353657853219, 'Total loss': 0.4680353657853219}
2022-11-28 03:27:54,673 INFO:     Found new best model at epoch 2
2022-11-28 03:27:54,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:54,673 INFO:     Epoch: 3
2022-11-28 03:27:55,423 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46425479515032336, 'Total loss': 0.46425479515032336} | train loss {'Reaction outcome loss': 0.44683606279713495, 'Total loss': 0.44683606279713495}
2022-11-28 03:27:55,423 INFO:     Found new best model at epoch 3
2022-11-28 03:27:55,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:55,424 INFO:     Epoch: 4
2022-11-28 03:27:56,167 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47854816710407083, 'Total loss': 0.47854816710407083} | train loss {'Reaction outcome loss': 0.4271038333855329, 'Total loss': 0.4271038333855329}
2022-11-28 03:27:56,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:56,168 INFO:     Epoch: 5
2022-11-28 03:27:56,914 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46797446059909736, 'Total loss': 0.46797446059909736} | train loss {'Reaction outcome loss': 0.42364768623825044, 'Total loss': 0.42364768623825044}
2022-11-28 03:27:56,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:56,914 INFO:     Epoch: 6
2022-11-28 03:27:57,661 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4694954287260771, 'Total loss': 0.4694954287260771} | train loss {'Reaction outcome loss': 0.40811430092059797, 'Total loss': 0.40811430092059797}
2022-11-28 03:27:57,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:57,661 INFO:     Epoch: 7
2022-11-28 03:27:58,407 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45577794618227263, 'Total loss': 0.45577794618227263} | train loss {'Reaction outcome loss': 0.4057165447382196, 'Total loss': 0.4057165447382196}
2022-11-28 03:27:58,407 INFO:     Found new best model at epoch 7
2022-11-28 03:27:58,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:58,408 INFO:     Epoch: 8
2022-11-28 03:27:59,154 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46928895535794174, 'Total loss': 0.46928895535794174} | train loss {'Reaction outcome loss': 0.39851471715636794, 'Total loss': 0.39851471715636794}
2022-11-28 03:27:59,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:59,154 INFO:     Epoch: 9
2022-11-28 03:27:59,905 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4534714523364197, 'Total loss': 0.4534714523364197} | train loss {'Reaction outcome loss': 0.38499081092736415, 'Total loss': 0.38499081092736415}
2022-11-28 03:27:59,905 INFO:     Found new best model at epoch 9
2022-11-28 03:27:59,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:27:59,906 INFO:     Epoch: 10
2022-11-28 03:28:00,657 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45110185512087564, 'Total loss': 0.45110185512087564} | train loss {'Reaction outcome loss': 0.3764350846289627, 'Total loss': 0.3764350846289627}
2022-11-28 03:28:00,657 INFO:     Found new best model at epoch 10
2022-11-28 03:28:00,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:00,658 INFO:     Epoch: 11
2022-11-28 03:28:01,405 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44402744400907646, 'Total loss': 0.44402744400907646} | train loss {'Reaction outcome loss': 0.3849254876915966, 'Total loss': 0.3849254876915966}
2022-11-28 03:28:01,406 INFO:     Found new best model at epoch 11
2022-11-28 03:28:01,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:01,406 INFO:     Epoch: 12
2022-11-28 03:28:02,154 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45172781751237134, 'Total loss': 0.45172781751237134} | train loss {'Reaction outcome loss': 0.3705085560739521, 'Total loss': 0.3705085560739521}
2022-11-28 03:28:02,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:02,155 INFO:     Epoch: 13
2022-11-28 03:28:02,903 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4432581995021213, 'Total loss': 0.4432581995021213} | train loss {'Reaction outcome loss': 0.36829726205718133, 'Total loss': 0.36829726205718133}
2022-11-28 03:28:02,903 INFO:     Found new best model at epoch 13
2022-11-28 03:28:02,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:02,904 INFO:     Epoch: 14
2022-11-28 03:28:03,652 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46331787210973824, 'Total loss': 0.46331787210973824} | train loss {'Reaction outcome loss': 0.35425085550354374, 'Total loss': 0.35425085550354374}
2022-11-28 03:28:03,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:03,652 INFO:     Epoch: 15
2022-11-28 03:28:04,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4441711977124214, 'Total loss': 0.4441711977124214} | train loss {'Reaction outcome loss': 0.36502647081450107, 'Total loss': 0.36502647081450107}
2022-11-28 03:28:04,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:04,402 INFO:     Epoch: 16
2022-11-28 03:28:05,150 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4156452508812601, 'Total loss': 0.4156452508812601} | train loss {'Reaction outcome loss': 0.3665807643725026, 'Total loss': 0.3665807643725026}
2022-11-28 03:28:05,150 INFO:     Found new best model at epoch 16
2022-11-28 03:28:05,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:05,151 INFO:     Epoch: 17
2022-11-28 03:28:05,903 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43940390104597266, 'Total loss': 0.43940390104597266} | train loss {'Reaction outcome loss': 0.3595050857252171, 'Total loss': 0.3595050857252171}
2022-11-28 03:28:05,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:05,903 INFO:     Epoch: 18
2022-11-28 03:28:06,653 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4454762437804179, 'Total loss': 0.4454762437804179} | train loss {'Reaction outcome loss': 0.3546414580496569, 'Total loss': 0.3546414580496569}
2022-11-28 03:28:06,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:06,654 INFO:     Epoch: 19
2022-11-28 03:28:07,405 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4137122370302677, 'Total loss': 0.4137122370302677} | train loss {'Reaction outcome loss': 0.34734396636486053, 'Total loss': 0.34734396636486053}
2022-11-28 03:28:07,405 INFO:     Found new best model at epoch 19
2022-11-28 03:28:07,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:07,406 INFO:     Epoch: 20
2022-11-28 03:28:08,159 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4520204541358081, 'Total loss': 0.4520204541358081} | train loss {'Reaction outcome loss': 0.3444538084159215, 'Total loss': 0.3444538084159215}
2022-11-28 03:28:08,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:08,159 INFO:     Epoch: 21
2022-11-28 03:28:08,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45293250578370964, 'Total loss': 0.45293250578370964} | train loss {'Reaction outcome loss': 0.3337084474342485, 'Total loss': 0.3337084474342485}
2022-11-28 03:28:08,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:08,910 INFO:     Epoch: 22
2022-11-28 03:28:09,658 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.454151723195206, 'Total loss': 0.454151723195206} | train loss {'Reaction outcome loss': 0.34691663188559396, 'Total loss': 0.34691663188559396}
2022-11-28 03:28:09,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:09,658 INFO:     Epoch: 23
2022-11-28 03:28:10,407 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47701195999979973, 'Total loss': 0.47701195999979973} | train loss {'Reaction outcome loss': 0.33924271490785385, 'Total loss': 0.33924271490785385}
2022-11-28 03:28:10,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:10,407 INFO:     Epoch: 24
2022-11-28 03:28:11,156 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3927851988171989, 'Total loss': 0.3927851988171989} | train loss {'Reaction outcome loss': 0.34163171810007864, 'Total loss': 0.34163171810007864}
2022-11-28 03:28:11,156 INFO:     Found new best model at epoch 24
2022-11-28 03:28:11,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:11,157 INFO:     Epoch: 25
2022-11-28 03:28:11,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4239812574603341, 'Total loss': 0.4239812574603341} | train loss {'Reaction outcome loss': 0.34566314755788735, 'Total loss': 0.34566314755788735}
2022-11-28 03:28:11,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:11,911 INFO:     Epoch: 26
2022-11-28 03:28:12,663 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40762569484385575, 'Total loss': 0.40762569484385575} | train loss {'Reaction outcome loss': 0.3394688991829753, 'Total loss': 0.3394688991829753}
2022-11-28 03:28:12,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:12,663 INFO:     Epoch: 27
2022-11-28 03:28:13,413 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40971031988208945, 'Total loss': 0.40971031988208945} | train loss {'Reaction outcome loss': 0.33420036126288677, 'Total loss': 0.33420036126288677}
2022-11-28 03:28:13,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:13,414 INFO:     Epoch: 28
2022-11-28 03:28:14,164 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42812190306457604, 'Total loss': 0.42812190306457604} | train loss {'Reaction outcome loss': 0.33503209733434264, 'Total loss': 0.33503209733434264}
2022-11-28 03:28:14,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:14,164 INFO:     Epoch: 29
2022-11-28 03:28:14,916 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4883413152261214, 'Total loss': 0.4883413152261214} | train loss {'Reaction outcome loss': 0.3409696347530811, 'Total loss': 0.3409696347530811}
2022-11-28 03:28:14,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:14,916 INFO:     Epoch: 30
2022-11-28 03:28:15,667 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4355253634805029, 'Total loss': 0.4355253634805029} | train loss {'Reaction outcome loss': 0.3302899478454023, 'Total loss': 0.3302899478454023}
2022-11-28 03:28:15,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:15,668 INFO:     Epoch: 31
2022-11-28 03:28:16,422 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4182519943199374, 'Total loss': 0.4182519943199374} | train loss {'Reaction outcome loss': 0.3330115369190612, 'Total loss': 0.3330115369190612}
2022-11-28 03:28:16,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:16,422 INFO:     Epoch: 32
2022-11-28 03:28:17,179 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4407665753229098, 'Total loss': 0.4407665753229098} | train loss {'Reaction outcome loss': 0.32282399509342447, 'Total loss': 0.32282399509342447}
2022-11-28 03:28:17,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:17,179 INFO:     Epoch: 33
2022-11-28 03:28:17,940 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4565204815431075, 'Total loss': 0.4565204815431075} | train loss {'Reaction outcome loss': 0.3266939520235023, 'Total loss': 0.3266939520235023}
2022-11-28 03:28:17,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:17,940 INFO:     Epoch: 34
2022-11-28 03:28:18,698 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.433829797601158, 'Total loss': 0.433829797601158} | train loss {'Reaction outcome loss': 0.3287490826220282, 'Total loss': 0.3287490826220282}
2022-11-28 03:28:18,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:18,698 INFO:     Epoch: 35
2022-11-28 03:28:19,453 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4413199902258136, 'Total loss': 0.4413199902258136} | train loss {'Reaction outcome loss': 0.3288979160208856, 'Total loss': 0.3288979160208856}
2022-11-28 03:28:19,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:19,453 INFO:     Epoch: 36
2022-11-28 03:28:20,206 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41487569971518085, 'Total loss': 0.41487569971518085} | train loss {'Reaction outcome loss': 0.32568455823967535, 'Total loss': 0.32568455823967535}
2022-11-28 03:28:20,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:20,206 INFO:     Epoch: 37
2022-11-28 03:28:20,956 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41318419677290047, 'Total loss': 0.41318419677290047} | train loss {'Reaction outcome loss': 0.3216951687429701, 'Total loss': 0.3216951687429701}
2022-11-28 03:28:20,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:20,957 INFO:     Epoch: 38
2022-11-28 03:28:21,714 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4572749571366744, 'Total loss': 0.4572749571366744} | train loss {'Reaction outcome loss': 0.3261033913210755, 'Total loss': 0.3261033913210755}
2022-11-28 03:28:21,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:21,714 INFO:     Epoch: 39
2022-11-28 03:28:22,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4066218554296277, 'Total loss': 0.4066218554296277} | train loss {'Reaction outcome loss': 0.33592304316980226, 'Total loss': 0.33592304316980226}
2022-11-28 03:28:22,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:22,467 INFO:     Epoch: 40
2022-11-28 03:28:23,217 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47994053160602396, 'Total loss': 0.47994053160602396} | train loss {'Reaction outcome loss': 0.3240349411123222, 'Total loss': 0.3240349411123222}
2022-11-28 03:28:23,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:23,217 INFO:     Epoch: 41
2022-11-28 03:28:23,969 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41684226048263634, 'Total loss': 0.41684226048263634} | train loss {'Reaction outcome loss': 0.3385688399956111, 'Total loss': 0.3385688399956111}
2022-11-28 03:28:23,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:23,970 INFO:     Epoch: 42
2022-11-28 03:28:24,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4045273620973934, 'Total loss': 0.4045273620973934} | train loss {'Reaction outcome loss': 0.3249622155281325, 'Total loss': 0.3249622155281325}
2022-11-28 03:28:24,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:24,723 INFO:     Epoch: 43
2022-11-28 03:28:25,476 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4113451357592236, 'Total loss': 0.4113451357592236} | train loss {'Reaction outcome loss': 0.3251965237000296, 'Total loss': 0.3251965237000296}
2022-11-28 03:28:25,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:25,477 INFO:     Epoch: 44
2022-11-28 03:28:26,228 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40231954949823295, 'Total loss': 0.40231954949823295} | train loss {'Reaction outcome loss': 0.3151614283692212, 'Total loss': 0.3151614283692212}
2022-11-28 03:28:26,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:26,228 INFO:     Epoch: 45
2022-11-28 03:28:26,980 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.468593469736251, 'Total loss': 0.468593469736251} | train loss {'Reaction outcome loss': 0.3319131128429886, 'Total loss': 0.3319131128429886}
2022-11-28 03:28:26,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:26,980 INFO:     Epoch: 46
2022-11-28 03:28:27,728 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44612024250355636, 'Total loss': 0.44612024250355636} | train loss {'Reaction outcome loss': 0.31636114700907664, 'Total loss': 0.31636114700907664}
2022-11-28 03:28:27,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:27,729 INFO:     Epoch: 47
2022-11-28 03:28:28,475 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4081575026608665, 'Total loss': 0.4081575026608665} | train loss {'Reaction outcome loss': 0.31997064203624764, 'Total loss': 0.31997064203624764}
2022-11-28 03:28:28,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:28,476 INFO:     Epoch: 48
2022-11-28 03:28:29,224 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4038500069555911, 'Total loss': 0.4038500069555911} | train loss {'Reaction outcome loss': 0.32230235834515863, 'Total loss': 0.32230235834515863}
2022-11-28 03:28:29,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:29,224 INFO:     Epoch: 49
2022-11-28 03:28:29,969 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41403174332597037, 'Total loss': 0.41403174332597037} | train loss {'Reaction outcome loss': 0.3224202304676686, 'Total loss': 0.3224202304676686}
2022-11-28 03:28:29,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:29,970 INFO:     Epoch: 50
2022-11-28 03:28:30,721 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4091729773208499, 'Total loss': 0.4091729773208499} | train loss {'Reaction outcome loss': 0.31696664614062153, 'Total loss': 0.31696664614062153}
2022-11-28 03:28:30,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:30,721 INFO:     Epoch: 51
2022-11-28 03:28:31,470 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4037820270115679, 'Total loss': 0.4037820270115679} | train loss {'Reaction outcome loss': 0.3185007479492455, 'Total loss': 0.3185007479492455}
2022-11-28 03:28:31,470 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:31,470 INFO:     Epoch: 52
2022-11-28 03:28:32,218 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4368949667973952, 'Total loss': 0.4368949667973952} | train loss {'Reaction outcome loss': 0.32071149274105987, 'Total loss': 0.32071149274105987}
2022-11-28 03:28:32,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:32,218 INFO:     Epoch: 53
2022-11-28 03:28:32,968 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4546885781667449, 'Total loss': 0.4546885781667449} | train loss {'Reaction outcome loss': 0.325793182544951, 'Total loss': 0.325793182544951}
2022-11-28 03:28:32,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:32,968 INFO:     Epoch: 54
2022-11-28 03:28:33,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4198843435468999, 'Total loss': 0.4198843435468999} | train loss {'Reaction outcome loss': 0.3183399373515239, 'Total loss': 0.3183399373515239}
2022-11-28 03:28:33,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:33,715 INFO:     Epoch: 55
2022-11-28 03:28:34,458 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4443966908888383, 'Total loss': 0.4443966908888383} | train loss {'Reaction outcome loss': 0.3222247261193491, 'Total loss': 0.3222247261193491}
2022-11-28 03:28:34,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:34,459 INFO:     Epoch: 56
2022-11-28 03:28:35,205 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4390656148845499, 'Total loss': 0.4390656148845499} | train loss {'Reaction outcome loss': 0.31153597319198234, 'Total loss': 0.31153597319198234}
2022-11-28 03:28:35,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:35,206 INFO:     Epoch: 57
2022-11-28 03:28:35,952 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42843384837562387, 'Total loss': 0.42843384837562387} | train loss {'Reaction outcome loss': 0.31814556236889574, 'Total loss': 0.31814556236889574}
2022-11-28 03:28:35,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:35,952 INFO:     Epoch: 58
2022-11-28 03:28:36,699 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.411084931851788, 'Total loss': 0.411084931851788} | train loss {'Reaction outcome loss': 0.31987687221337713, 'Total loss': 0.31987687221337713}
2022-11-28 03:28:36,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:36,699 INFO:     Epoch: 59
2022-11-28 03:28:37,445 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45748588544401253, 'Total loss': 0.45748588544401253} | train loss {'Reaction outcome loss': 0.32107505622890686, 'Total loss': 0.32107505622890686}
2022-11-28 03:28:37,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:37,446 INFO:     Epoch: 60
2022-11-28 03:28:38,191 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4018038402904164, 'Total loss': 0.4018038402904164} | train loss {'Reaction outcome loss': 0.3278251337488332, 'Total loss': 0.3278251337488332}
2022-11-28 03:28:38,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:38,191 INFO:     Epoch: 61
2022-11-28 03:28:38,937 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43129660392349417, 'Total loss': 0.43129660392349417} | train loss {'Reaction outcome loss': 0.3093575844841619, 'Total loss': 0.3093575844841619}
2022-11-28 03:28:38,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:38,938 INFO:     Epoch: 62
2022-11-28 03:28:39,684 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42617638341405173, 'Total loss': 0.42617638341405173} | train loss {'Reaction outcome loss': 0.3219112206340557, 'Total loss': 0.3219112206340557}
2022-11-28 03:28:39,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:39,685 INFO:     Epoch: 63
2022-11-28 03:28:40,432 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44349405101754447, 'Total loss': 0.44349405101754447} | train loss {'Reaction outcome loss': 0.31657763336965394, 'Total loss': 0.31657763336965394}
2022-11-28 03:28:40,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:40,433 INFO:     Epoch: 64
2022-11-28 03:28:41,183 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4161475771530108, 'Total loss': 0.4161475771530108} | train loss {'Reaction outcome loss': 0.3204625369079651, 'Total loss': 0.3204625369079651}
2022-11-28 03:28:41,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:41,183 INFO:     Epoch: 65
2022-11-28 03:28:41,935 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4117564311759038, 'Total loss': 0.4117564311759038} | train loss {'Reaction outcome loss': 0.3143888204208305, 'Total loss': 0.3143888204208305}
2022-11-28 03:28:41,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:41,935 INFO:     Epoch: 66
2022-11-28 03:28:42,684 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4213189519941807, 'Total loss': 0.4213189519941807} | train loss {'Reaction outcome loss': 0.3238720856907387, 'Total loss': 0.3238720856907387}
2022-11-28 03:28:42,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:42,684 INFO:     Epoch: 67
2022-11-28 03:28:43,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40529339523477986, 'Total loss': 0.40529339523477986} | train loss {'Reaction outcome loss': 0.3099936477900032, 'Total loss': 0.3099936477900032}
2022-11-28 03:28:43,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:43,435 INFO:     Epoch: 68
2022-11-28 03:28:44,182 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.411381607028571, 'Total loss': 0.411381607028571} | train loss {'Reaction outcome loss': 0.3109762273248165, 'Total loss': 0.3109762273248165}
2022-11-28 03:28:44,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:44,182 INFO:     Epoch: 69
2022-11-28 03:28:44,932 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4099247587675398, 'Total loss': 0.4099247587675398} | train loss {'Reaction outcome loss': 0.3139952956849048, 'Total loss': 0.3139952956849048}
2022-11-28 03:28:44,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:44,932 INFO:     Epoch: 70
2022-11-28 03:28:45,680 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4201350455934351, 'Total loss': 0.4201350455934351} | train loss {'Reaction outcome loss': 0.31329267444990333, 'Total loss': 0.31329267444990333}
2022-11-28 03:28:45,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:45,680 INFO:     Epoch: 71
2022-11-28 03:28:46,428 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4418788674202832, 'Total loss': 0.4418788674202832} | train loss {'Reaction outcome loss': 0.32170574490221276, 'Total loss': 0.32170574490221276}
2022-11-28 03:28:46,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:46,428 INFO:     Epoch: 72
2022-11-28 03:28:47,176 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43680691211061046, 'Total loss': 0.43680691211061046} | train loss {'Reaction outcome loss': 0.3131621643119762, 'Total loss': 0.3131621643119762}
2022-11-28 03:28:47,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:47,177 INFO:     Epoch: 73
2022-11-28 03:28:47,922 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43112450059164653, 'Total loss': 0.43112450059164653} | train loss {'Reaction outcome loss': 0.3231879238399767, 'Total loss': 0.3231879238399767}
2022-11-28 03:28:47,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:47,922 INFO:     Epoch: 74
2022-11-28 03:28:48,669 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40710552951151674, 'Total loss': 0.40710552951151674} | train loss {'Reaction outcome loss': 0.3121557059066911, 'Total loss': 0.3121557059066911}
2022-11-28 03:28:48,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:48,669 INFO:     Epoch: 75
2022-11-28 03:28:49,417 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4325917705216191, 'Total loss': 0.4325917705216191} | train loss {'Reaction outcome loss': 0.3086828535062171, 'Total loss': 0.3086828535062171}
2022-11-28 03:28:49,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:49,417 INFO:     Epoch: 76
2022-11-28 03:28:50,167 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44137505763633683, 'Total loss': 0.44137505763633683} | train loss {'Reaction outcome loss': 0.31856321768775103, 'Total loss': 0.31856321768775103}
2022-11-28 03:28:50,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:50,168 INFO:     Epoch: 77
2022-11-28 03:28:50,919 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4440270841798999, 'Total loss': 0.4440270841798999} | train loss {'Reaction outcome loss': 0.3128797637238618, 'Total loss': 0.3128797637238618}
2022-11-28 03:28:50,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:50,919 INFO:     Epoch: 78
2022-11-28 03:28:51,667 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4156815182756294, 'Total loss': 0.4156815182756294} | train loss {'Reaction outcome loss': 0.3127215924792953, 'Total loss': 0.3127215924792953}
2022-11-28 03:28:51,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:51,668 INFO:     Epoch: 79
2022-11-28 03:28:52,417 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46665833788839256, 'Total loss': 0.46665833788839256} | train loss {'Reaction outcome loss': 0.31133972456859005, 'Total loss': 0.31133972456859005}
2022-11-28 03:28:52,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:52,417 INFO:     Epoch: 80
2022-11-28 03:28:53,165 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44268553382293746, 'Total loss': 0.44268553382293746} | train loss {'Reaction outcome loss': 0.32164868174661554, 'Total loss': 0.32164868174661554}
2022-11-28 03:28:53,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:53,165 INFO:     Epoch: 81
2022-11-28 03:28:53,912 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4218706596981395, 'Total loss': 0.4218706596981395} | train loss {'Reaction outcome loss': 0.3180802688303013, 'Total loss': 0.3180802688303013}
2022-11-28 03:28:53,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:53,913 INFO:     Epoch: 82
2022-11-28 03:28:54,662 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38935041935606435, 'Total loss': 0.38935041935606435} | train loss {'Reaction outcome loss': 0.31032182065950287, 'Total loss': 0.31032182065950287}
2022-11-28 03:28:54,662 INFO:     Found new best model at epoch 82
2022-11-28 03:28:54,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:54,663 INFO:     Epoch: 83
2022-11-28 03:28:55,413 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41913696175271814, 'Total loss': 0.41913696175271814} | train loss {'Reaction outcome loss': 0.314640733037865, 'Total loss': 0.314640733037865}
2022-11-28 03:28:55,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:55,413 INFO:     Epoch: 84
2022-11-28 03:28:56,160 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4317362162877213, 'Total loss': 0.4317362162877213} | train loss {'Reaction outcome loss': 0.30755748095050933, 'Total loss': 0.30755748095050933}
2022-11-28 03:28:56,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:56,160 INFO:     Epoch: 85
2022-11-28 03:28:56,906 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3926716568795117, 'Total loss': 0.3926716568795117} | train loss {'Reaction outcome loss': 0.3172195352944395, 'Total loss': 0.3172195352944395}
2022-11-28 03:28:56,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:56,906 INFO:     Epoch: 86
2022-11-28 03:28:57,652 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41403868929906323, 'Total loss': 0.41403868929906323} | train loss {'Reaction outcome loss': 0.3153208639292467, 'Total loss': 0.3153208639292467}
2022-11-28 03:28:57,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:57,652 INFO:     Epoch: 87
2022-11-28 03:28:58,399 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39777301488952205, 'Total loss': 0.39777301488952205} | train loss {'Reaction outcome loss': 0.31024149874405516, 'Total loss': 0.31024149874405516}
2022-11-28 03:28:58,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:58,399 INFO:     Epoch: 88
2022-11-28 03:28:59,148 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4513694078407504, 'Total loss': 0.4513694078407504} | train loss {'Reaction outcome loss': 0.3147939517793636, 'Total loss': 0.3147939517793636}
2022-11-28 03:28:59,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:59,148 INFO:     Epoch: 89
2022-11-28 03:28:59,896 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4277953129600395, 'Total loss': 0.4277953129600395} | train loss {'Reaction outcome loss': 0.29872654898152234, 'Total loss': 0.29872654898152234}
2022-11-28 03:28:59,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:28:59,896 INFO:     Epoch: 90
2022-11-28 03:29:00,644 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4384338625452735, 'Total loss': 0.4384338625452735} | train loss {'Reaction outcome loss': 0.30629466101527214, 'Total loss': 0.30629466101527214}
2022-11-28 03:29:00,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:00,645 INFO:     Epoch: 91
2022-11-28 03:29:01,391 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4101478760554032, 'Total loss': 0.4101478760554032} | train loss {'Reaction outcome loss': 0.3131219265501826, 'Total loss': 0.3131219265501826}
2022-11-28 03:29:01,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:01,391 INFO:     Epoch: 92
2022-11-28 03:29:02,141 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43005151945081627, 'Total loss': 0.43005151945081627} | train loss {'Reaction outcome loss': 0.3133756596174452, 'Total loss': 0.3133756596174452}
2022-11-28 03:29:02,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:02,141 INFO:     Epoch: 93
2022-11-28 03:29:02,889 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4466413107107986, 'Total loss': 0.4466413107107986} | train loss {'Reaction outcome loss': 0.31131446082144976, 'Total loss': 0.31131446082144976}
2022-11-28 03:29:02,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:02,890 INFO:     Epoch: 94
2022-11-28 03:29:03,640 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41221394220536406, 'Total loss': 0.41221394220536406} | train loss {'Reaction outcome loss': 0.31020279318815275, 'Total loss': 0.31020279318815275}
2022-11-28 03:29:03,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:03,640 INFO:     Epoch: 95
2022-11-28 03:29:04,387 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4398702968927947, 'Total loss': 0.4398702968927947} | train loss {'Reaction outcome loss': 0.305133486647279, 'Total loss': 0.305133486647279}
2022-11-28 03:29:04,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:04,387 INFO:     Epoch: 96
2022-11-28 03:29:05,136 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4711107919839295, 'Total loss': 0.4711107919839295} | train loss {'Reaction outcome loss': 0.31195899736016025, 'Total loss': 0.31195899736016025}
2022-11-28 03:29:05,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:05,136 INFO:     Epoch: 97
2022-11-28 03:29:05,883 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4235073121433908, 'Total loss': 0.4235073121433908} | train loss {'Reaction outcome loss': 0.31435624798459394, 'Total loss': 0.31435624798459394}
2022-11-28 03:29:05,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:05,884 INFO:     Epoch: 98
2022-11-28 03:29:06,629 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44947097585959866, 'Total loss': 0.44947097585959866} | train loss {'Reaction outcome loss': 0.31628966559806176, 'Total loss': 0.31628966559806176}
2022-11-28 03:29:06,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:06,630 INFO:     Epoch: 99
2022-11-28 03:29:07,375 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49400823427872226, 'Total loss': 0.49400823427872226} | train loss {'Reaction outcome loss': 0.30994503266148027, 'Total loss': 0.30994503266148027}
2022-11-28 03:29:07,375 INFO:     Best model found after epoch 83 of 100.
2022-11-28 03:29:07,375 INFO:   Done with stage: TRAINING
2022-11-28 03:29:07,375 INFO:   Starting stage: EVALUATION
2022-11-28 03:29:07,491 INFO:   Done with stage: EVALUATION
2022-11-28 03:29:07,491 INFO:   Leaving out SEQ value Fold_5
2022-11-28 03:29:07,503 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:29:07,503 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:29:08,139 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:29:08,140 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:29:08,208 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:29:08,208 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:29:08,208 INFO:     No hyperparam tuning for this model
2022-11-28 03:29:08,208 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:29:08,208 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:29:08,209 INFO:     None feature selector for col prot
2022-11-28 03:29:08,209 INFO:     None feature selector for col prot
2022-11-28 03:29:08,209 INFO:     None feature selector for col prot
2022-11-28 03:29:08,210 INFO:     None feature selector for col chem
2022-11-28 03:29:08,210 INFO:     None feature selector for col chem
2022-11-28 03:29:08,210 INFO:     None feature selector for col chem
2022-11-28 03:29:08,210 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:29:08,210 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:29:08,212 INFO:     Number of params in model 169741
2022-11-28 03:29:08,215 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:29:08,215 INFO:   Starting stage: TRAINING
2022-11-28 03:29:08,269 INFO:     Val loss before train {'Reaction outcome loss': 0.9609603543173183, 'Total loss': 0.9609603543173183}
2022-11-28 03:29:08,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:08,269 INFO:     Epoch: 0
2022-11-28 03:29:09,013 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.532532811164856, 'Total loss': 0.532532811164856} | train loss {'Reaction outcome loss': 0.6290886583376903, 'Total loss': 0.6290886583376903}
2022-11-28 03:29:09,013 INFO:     Found new best model at epoch 0
2022-11-28 03:29:09,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:09,014 INFO:     Epoch: 1
2022-11-28 03:29:09,757 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5310047045350075, 'Total loss': 0.5310047045350075} | train loss {'Reaction outcome loss': 0.49152080343694105, 'Total loss': 0.49152080343694105}
2022-11-28 03:29:09,757 INFO:     Found new best model at epoch 1
2022-11-28 03:29:09,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:09,758 INFO:     Epoch: 2
2022-11-28 03:29:10,500 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47060189870270813, 'Total loss': 0.47060189870270813} | train loss {'Reaction outcome loss': 0.462302881175158, 'Total loss': 0.462302881175158}
2022-11-28 03:29:10,500 INFO:     Found new best model at epoch 2
2022-11-28 03:29:10,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:10,501 INFO:     Epoch: 3
2022-11-28 03:29:11,243 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.439430639825084, 'Total loss': 0.439430639825084} | train loss {'Reaction outcome loss': 0.43945461310902423, 'Total loss': 0.43945461310902423}
2022-11-28 03:29:11,243 INFO:     Found new best model at epoch 3
2022-11-28 03:29:11,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:11,244 INFO:     Epoch: 4
2022-11-28 03:29:11,986 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4578537507490678, 'Total loss': 0.4578537507490678} | train loss {'Reaction outcome loss': 0.42592651576411966, 'Total loss': 0.42592651576411966}
2022-11-28 03:29:11,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:11,986 INFO:     Epoch: 5
2022-11-28 03:29:12,727 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42257149111140857, 'Total loss': 0.42257149111140857} | train loss {'Reaction outcome loss': 0.4091770637400296, 'Total loss': 0.4091770637400296}
2022-11-28 03:29:12,727 INFO:     Found new best model at epoch 5
2022-11-28 03:29:12,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:12,728 INFO:     Epoch: 6
2022-11-28 03:29:13,467 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42012070458043704, 'Total loss': 0.42012070458043704} | train loss {'Reaction outcome loss': 0.39435533309469417, 'Total loss': 0.39435533309469417}
2022-11-28 03:29:13,467 INFO:     Found new best model at epoch 6
2022-11-28 03:29:13,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:13,468 INFO:     Epoch: 7
2022-11-28 03:29:14,207 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4234140376475724, 'Total loss': 0.4234140376475724} | train loss {'Reaction outcome loss': 0.40257100262203993, 'Total loss': 0.40257100262203993}
2022-11-28 03:29:14,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:14,208 INFO:     Epoch: 8
2022-11-28 03:29:14,948 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41126753999428317, 'Total loss': 0.41126753999428317} | train loss {'Reaction outcome loss': 0.3806297304070726, 'Total loss': 0.3806297304070726}
2022-11-28 03:29:14,948 INFO:     Found new best model at epoch 8
2022-11-28 03:29:14,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:14,949 INFO:     Epoch: 9
2022-11-28 03:29:15,687 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44640028747645294, 'Total loss': 0.44640028747645294} | train loss {'Reaction outcome loss': 0.37805758848482246, 'Total loss': 0.37805758848482246}
2022-11-28 03:29:15,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:15,688 INFO:     Epoch: 10
2022-11-28 03:29:16,428 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4177376072515141, 'Total loss': 0.4177376072515141} | train loss {'Reaction outcome loss': 0.37210298344797016, 'Total loss': 0.37210298344797016}
2022-11-28 03:29:16,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:16,428 INFO:     Epoch: 11
2022-11-28 03:29:17,168 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44103218987584114, 'Total loss': 0.44103218987584114} | train loss {'Reaction outcome loss': 0.36752304224943627, 'Total loss': 0.36752304224943627}
2022-11-28 03:29:17,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:17,168 INFO:     Epoch: 12
2022-11-28 03:29:17,907 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41937790167602623, 'Total loss': 0.41937790167602623} | train loss {'Reaction outcome loss': 0.3760202635003596, 'Total loss': 0.3760202635003596}
2022-11-28 03:29:17,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:17,907 INFO:     Epoch: 13
2022-11-28 03:29:18,647 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40029792502437805, 'Total loss': 0.40029792502437805} | train loss {'Reaction outcome loss': 0.36564103848471935, 'Total loss': 0.36564103848471935}
2022-11-28 03:29:18,647 INFO:     Found new best model at epoch 13
2022-11-28 03:29:18,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:18,648 INFO:     Epoch: 14
2022-11-28 03:29:19,389 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41642652367326344, 'Total loss': 0.41642652367326344} | train loss {'Reaction outcome loss': 0.36976133004135014, 'Total loss': 0.36976133004135014}
2022-11-28 03:29:19,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:19,389 INFO:     Epoch: 15
2022-11-28 03:29:20,132 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4198026138950478, 'Total loss': 0.4198026138950478} | train loss {'Reaction outcome loss': 0.3578809604961045, 'Total loss': 0.3578809604961045}
2022-11-28 03:29:20,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:20,132 INFO:     Epoch: 16
2022-11-28 03:29:20,875 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38441755351695145, 'Total loss': 0.38441755351695145} | train loss {'Reaction outcome loss': 0.3566483556311958, 'Total loss': 0.3566483556311958}
2022-11-28 03:29:20,875 INFO:     Found new best model at epoch 16
2022-11-28 03:29:20,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:20,876 INFO:     Epoch: 17
2022-11-28 03:29:21,616 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4206519976935603, 'Total loss': 0.4206519976935603} | train loss {'Reaction outcome loss': 0.3435279295456653, 'Total loss': 0.3435279295456653}
2022-11-28 03:29:21,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:21,617 INFO:     Epoch: 18
2022-11-28 03:29:22,355 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38481948033652524, 'Total loss': 0.38481948033652524} | train loss {'Reaction outcome loss': 0.3448066309398534, 'Total loss': 0.3448066309398534}
2022-11-28 03:29:22,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:22,355 INFO:     Epoch: 19
2022-11-28 03:29:23,097 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40534657646309247, 'Total loss': 0.40534657646309247} | train loss {'Reaction outcome loss': 0.34070181049862686, 'Total loss': 0.34070181049862686}
2022-11-28 03:29:23,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:23,097 INFO:     Epoch: 20
2022-11-28 03:29:23,838 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3984847586940635, 'Total loss': 0.3984847586940635} | train loss {'Reaction outcome loss': 0.3451557388111037, 'Total loss': 0.3451557388111037}
2022-11-28 03:29:23,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:23,838 INFO:     Epoch: 21
2022-11-28 03:29:24,577 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4370949822054668, 'Total loss': 0.4370949822054668} | train loss {'Reaction outcome loss': 0.3405163199469751, 'Total loss': 0.3405163199469751}
2022-11-28 03:29:24,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:24,577 INFO:     Epoch: 22
2022-11-28 03:29:25,314 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4177857312289151, 'Total loss': 0.4177857312289151} | train loss {'Reaction outcome loss': 0.33510403377669196, 'Total loss': 0.33510403377669196}
2022-11-28 03:29:25,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:25,314 INFO:     Epoch: 23
2022-11-28 03:29:26,052 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4311845857988704, 'Total loss': 0.4311845857988704} | train loss {'Reaction outcome loss': 0.3428790082736891, 'Total loss': 0.3428790082736891}
2022-11-28 03:29:26,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:26,053 INFO:     Epoch: 24
2022-11-28 03:29:26,792 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40305688354948704, 'Total loss': 0.40305688354948704} | train loss {'Reaction outcome loss': 0.3361238207744092, 'Total loss': 0.3361238207744092}
2022-11-28 03:29:26,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:26,792 INFO:     Epoch: 25
2022-11-28 03:29:27,532 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4092390798032284, 'Total loss': 0.4092390798032284} | train loss {'Reaction outcome loss': 0.3371615656480497, 'Total loss': 0.3371615656480497}
2022-11-28 03:29:27,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:27,532 INFO:     Epoch: 26
2022-11-28 03:29:28,273 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40739487517963757, 'Total loss': 0.40739487517963757} | train loss {'Reaction outcome loss': 0.3269721085927924, 'Total loss': 0.3269721085927924}
2022-11-28 03:29:28,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:28,273 INFO:     Epoch: 27
2022-11-28 03:29:29,011 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41480885310606525, 'Total loss': 0.41480885310606525} | train loss {'Reaction outcome loss': 0.3356574746418972, 'Total loss': 0.3356574746418972}
2022-11-28 03:29:29,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:29,011 INFO:     Epoch: 28
2022-11-28 03:29:29,747 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4507288065823642, 'Total loss': 0.4507288065823642} | train loss {'Reaction outcome loss': 0.3369650557029004, 'Total loss': 0.3369650557029004}
2022-11-28 03:29:29,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:29,748 INFO:     Epoch: 29
2022-11-28 03:29:30,485 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40343839793720027, 'Total loss': 0.40343839793720027} | train loss {'Reaction outcome loss': 0.32701304995892, 'Total loss': 0.32701304995892}
2022-11-28 03:29:30,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:30,485 INFO:     Epoch: 30
2022-11-28 03:29:31,223 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38653592342002824, 'Total loss': 0.38653592342002824} | train loss {'Reaction outcome loss': 0.3187204721630836, 'Total loss': 0.3187204721630836}
2022-11-28 03:29:31,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:31,223 INFO:     Epoch: 31
2022-11-28 03:29:31,962 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38006571714173665, 'Total loss': 0.38006571714173665} | train loss {'Reaction outcome loss': 0.32601098688889524, 'Total loss': 0.32601098688889524}
2022-11-28 03:29:31,962 INFO:     Found new best model at epoch 31
2022-11-28 03:29:31,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:31,963 INFO:     Epoch: 32
2022-11-28 03:29:32,702 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42433843964880164, 'Total loss': 0.42433843964880164} | train loss {'Reaction outcome loss': 0.32469657501395865, 'Total loss': 0.32469657501395865}
2022-11-28 03:29:32,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:32,703 INFO:     Epoch: 33
2022-11-28 03:29:33,447 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41212325780229137, 'Total loss': 0.41212325780229137} | train loss {'Reaction outcome loss': 0.31614746454418924, 'Total loss': 0.31614746454418924}
2022-11-28 03:29:33,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:33,448 INFO:     Epoch: 34
2022-11-28 03:29:34,191 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.396560433617031, 'Total loss': 0.396560433617031} | train loss {'Reaction outcome loss': 0.32295522118101316, 'Total loss': 0.32295522118101316}
2022-11-28 03:29:34,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:34,191 INFO:     Epoch: 35
2022-11-28 03:29:34,934 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40945371917702933, 'Total loss': 0.40945371917702933} | train loss {'Reaction outcome loss': 0.3321404083346834, 'Total loss': 0.3321404083346834}
2022-11-28 03:29:34,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:34,934 INFO:     Epoch: 36
2022-11-28 03:29:35,676 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40975914878601377, 'Total loss': 0.40975914878601377} | train loss {'Reaction outcome loss': 0.3255127352719404, 'Total loss': 0.3255127352719404}
2022-11-28 03:29:35,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:35,677 INFO:     Epoch: 37
2022-11-28 03:29:36,421 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4240557974712415, 'Total loss': 0.4240557974712415} | train loss {'Reaction outcome loss': 0.32340957762635486, 'Total loss': 0.32340957762635486}
2022-11-28 03:29:36,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:36,422 INFO:     Epoch: 38
2022-11-28 03:29:37,161 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39538334123790264, 'Total loss': 0.39538334123790264} | train loss {'Reaction outcome loss': 0.32528349623388175, 'Total loss': 0.32528349623388175}
2022-11-28 03:29:37,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:37,161 INFO:     Epoch: 39
2022-11-28 03:29:37,901 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41668462685563346, 'Total loss': 0.41668462685563346} | train loss {'Reaction outcome loss': 0.3237455047210869, 'Total loss': 0.3237455047210869}
2022-11-28 03:29:37,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:37,901 INFO:     Epoch: 40
2022-11-28 03:29:38,641 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42413762042468245, 'Total loss': 0.42413762042468245} | train loss {'Reaction outcome loss': 0.3306805004422762, 'Total loss': 0.3306805004422762}
2022-11-28 03:29:38,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:38,641 INFO:     Epoch: 41
2022-11-28 03:29:39,381 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38710742511532525, 'Total loss': 0.38710742511532525} | train loss {'Reaction outcome loss': 0.31783926727212203, 'Total loss': 0.31783926727212203}
2022-11-28 03:29:39,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:39,382 INFO:     Epoch: 42
2022-11-28 03:29:40,120 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38949229703708127, 'Total loss': 0.38949229703708127} | train loss {'Reaction outcome loss': 0.31240006402439, 'Total loss': 0.31240006402439}
2022-11-28 03:29:40,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:40,121 INFO:     Epoch: 43
2022-11-28 03:29:40,862 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4111961221153086, 'Total loss': 0.4111961221153086} | train loss {'Reaction outcome loss': 0.3316300545724071, 'Total loss': 0.3316300545724071}
2022-11-28 03:29:40,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:40,862 INFO:     Epoch: 44
2022-11-28 03:29:41,601 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.412382396446033, 'Total loss': 0.412382396446033} | train loss {'Reaction outcome loss': 0.3213615472827639, 'Total loss': 0.3213615472827639}
2022-11-28 03:29:41,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:41,601 INFO:     Epoch: 45
2022-11-28 03:29:42,342 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3976895118301565, 'Total loss': 0.3976895118301565} | train loss {'Reaction outcome loss': 0.3220287607944742, 'Total loss': 0.3220287607944742}
2022-11-28 03:29:42,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:42,343 INFO:     Epoch: 46
2022-11-28 03:29:43,083 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42092462798411195, 'Total loss': 0.42092462798411195} | train loss {'Reaction outcome loss': 0.31601274314583566, 'Total loss': 0.31601274314583566}
2022-11-28 03:29:43,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:43,083 INFO:     Epoch: 47
2022-11-28 03:29:43,824 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42300381375984714, 'Total loss': 0.42300381375984714} | train loss {'Reaction outcome loss': 0.32318400140015446, 'Total loss': 0.32318400140015446}
2022-11-28 03:29:43,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:43,824 INFO:     Epoch: 48
2022-11-28 03:29:44,564 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4038434430787509, 'Total loss': 0.4038434430787509} | train loss {'Reaction outcome loss': 0.3170569826297614, 'Total loss': 0.3170569826297614}
2022-11-28 03:29:44,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:44,565 INFO:     Epoch: 49
2022-11-28 03:29:45,310 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4102928712964058, 'Total loss': 0.4102928712964058} | train loss {'Reaction outcome loss': 0.3177719275258025, 'Total loss': 0.3177719275258025}
2022-11-28 03:29:45,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:45,311 INFO:     Epoch: 50
2022-11-28 03:29:46,052 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3897321589968421, 'Total loss': 0.3897321589968421} | train loss {'Reaction outcome loss': 0.3202841980420813, 'Total loss': 0.3202841980420813}
2022-11-28 03:29:46,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:46,053 INFO:     Epoch: 51
2022-11-28 03:29:46,793 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3975286612456495, 'Total loss': 0.3975286612456495} | train loss {'Reaction outcome loss': 0.30833885172496034, 'Total loss': 0.30833885172496034}
2022-11-28 03:29:46,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:46,793 INFO:     Epoch: 52
2022-11-28 03:29:47,533 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.443494799123569, 'Total loss': 0.443494799123569} | train loss {'Reaction outcome loss': 0.3295875301014404, 'Total loss': 0.3295875301014404}
2022-11-28 03:29:47,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:47,534 INFO:     Epoch: 53
2022-11-28 03:29:48,274 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42166821573945606, 'Total loss': 0.42166821573945606} | train loss {'Reaction outcome loss': 0.3111832004116506, 'Total loss': 0.3111832004116506}
2022-11-28 03:29:48,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:48,274 INFO:     Epoch: 54
2022-11-28 03:29:49,013 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4449956545775587, 'Total loss': 0.4449956545775587} | train loss {'Reaction outcome loss': 0.31911456995472615, 'Total loss': 0.31911456995472615}
2022-11-28 03:29:49,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:49,013 INFO:     Epoch: 55
2022-11-28 03:29:49,754 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40834008589048276, 'Total loss': 0.40834008589048276} | train loss {'Reaction outcome loss': 0.3141591676035706, 'Total loss': 0.3141591676035706}
2022-11-28 03:29:49,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:49,754 INFO:     Epoch: 56
2022-11-28 03:29:50,498 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4130221675573425, 'Total loss': 0.4130221675573425} | train loss {'Reaction outcome loss': 0.3154192867631815, 'Total loss': 0.3154192867631815}
2022-11-28 03:29:50,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:50,498 INFO:     Epoch: 57
2022-11-28 03:29:51,239 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4087039445611564, 'Total loss': 0.4087039445611564} | train loss {'Reaction outcome loss': 0.31126261672803335, 'Total loss': 0.31126261672803335}
2022-11-28 03:29:51,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:51,239 INFO:     Epoch: 58
2022-11-28 03:29:51,978 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4090020609172908, 'Total loss': 0.4090020609172908} | train loss {'Reaction outcome loss': 0.3204834613568929, 'Total loss': 0.3204834613568929}
2022-11-28 03:29:51,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:51,979 INFO:     Epoch: 59
2022-11-28 03:29:52,718 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40104775774207985, 'Total loss': 0.40104775774207985} | train loss {'Reaction outcome loss': 0.304216499368147, 'Total loss': 0.304216499368147}
2022-11-28 03:29:52,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:52,719 INFO:     Epoch: 60
2022-11-28 03:29:53,459 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.451736275783994, 'Total loss': 0.451736275783994} | train loss {'Reaction outcome loss': 0.32267059467884956, 'Total loss': 0.32267059467884956}
2022-11-28 03:29:53,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:53,459 INFO:     Epoch: 61
2022-11-28 03:29:54,195 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41435225443406537, 'Total loss': 0.41435225443406537} | train loss {'Reaction outcome loss': 0.3180766895869557, 'Total loss': 0.3180766895869557}
2022-11-28 03:29:54,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:54,195 INFO:     Epoch: 62
2022-11-28 03:29:54,935 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4188299101184715, 'Total loss': 0.4188299101184715} | train loss {'Reaction outcome loss': 0.31816065542551936, 'Total loss': 0.31816065542551936}
2022-11-28 03:29:54,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:54,935 INFO:     Epoch: 63
2022-11-28 03:29:55,676 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41187432780861855, 'Total loss': 0.41187432780861855} | train loss {'Reaction outcome loss': 0.3122967016636109, 'Total loss': 0.3122967016636109}
2022-11-28 03:29:55,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:55,676 INFO:     Epoch: 64
2022-11-28 03:29:56,417 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4099416251886975, 'Total loss': 0.4099416251886975} | train loss {'Reaction outcome loss': 0.3129580200174633, 'Total loss': 0.3129580200174633}
2022-11-28 03:29:56,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:56,417 INFO:     Epoch: 65
2022-11-28 03:29:57,161 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4245211472734809, 'Total loss': 0.4245211472734809} | train loss {'Reaction outcome loss': 0.3102446747069456, 'Total loss': 0.3102446747069456}
2022-11-28 03:29:57,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:57,161 INFO:     Epoch: 66
2022-11-28 03:29:57,899 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4161269349808043, 'Total loss': 0.4161269349808043} | train loss {'Reaction outcome loss': 0.2999777166210875, 'Total loss': 0.2999777166210875}
2022-11-28 03:29:57,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:57,899 INFO:     Epoch: 67
2022-11-28 03:29:58,642 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41066119278019125, 'Total loss': 0.41066119278019125} | train loss {'Reaction outcome loss': 0.3171877603141629, 'Total loss': 0.3171877603141629}
2022-11-28 03:29:58,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:58,642 INFO:     Epoch: 68
2022-11-28 03:29:59,383 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4405526779592037, 'Total loss': 0.4405526779592037} | train loss {'Reaction outcome loss': 0.31589243597522076, 'Total loss': 0.31589243597522076}
2022-11-28 03:29:59,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:29:59,383 INFO:     Epoch: 69
2022-11-28 03:30:00,126 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4272152808579532, 'Total loss': 0.4272152808579532} | train loss {'Reaction outcome loss': 0.3094192200625429, 'Total loss': 0.3094192200625429}
2022-11-28 03:30:00,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:00,126 INFO:     Epoch: 70
2022-11-28 03:30:00,867 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4349008199166168, 'Total loss': 0.4349008199166168} | train loss {'Reaction outcome loss': 0.31419262575859924, 'Total loss': 0.31419262575859924}
2022-11-28 03:30:00,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:00,867 INFO:     Epoch: 71
2022-11-28 03:30:01,610 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41130478138273413, 'Total loss': 0.41130478138273413} | train loss {'Reaction outcome loss': 0.31312199505616206, 'Total loss': 0.31312199505616206}
2022-11-28 03:30:01,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:01,611 INFO:     Epoch: 72
2022-11-28 03:30:02,348 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4187963687899438, 'Total loss': 0.4187963687899438} | train loss {'Reaction outcome loss': 0.30583246620942134, 'Total loss': 0.30583246620942134}
2022-11-28 03:30:02,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:02,348 INFO:     Epoch: 73
2022-11-28 03:30:03,090 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4220318391241811, 'Total loss': 0.4220318391241811} | train loss {'Reaction outcome loss': 0.30628618608628, 'Total loss': 0.30628618608628}
2022-11-28 03:30:03,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:03,090 INFO:     Epoch: 74
2022-11-28 03:30:03,832 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40963290191509505, 'Total loss': 0.40963290191509505} | train loss {'Reaction outcome loss': 0.30992603321768797, 'Total loss': 0.30992603321768797}
2022-11-28 03:30:03,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:03,832 INFO:     Epoch: 75
2022-11-28 03:30:04,575 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4333131871270863, 'Total loss': 0.4333131871270863} | train loss {'Reaction outcome loss': 0.3102672304121815, 'Total loss': 0.3102672304121815}
2022-11-28 03:30:04,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:04,576 INFO:     Epoch: 76
2022-11-28 03:30:05,316 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45995574444532394, 'Total loss': 0.45995574444532394} | train loss {'Reaction outcome loss': 0.31091109517277504, 'Total loss': 0.31091109517277504}
2022-11-28 03:30:05,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:05,316 INFO:     Epoch: 77
2022-11-28 03:30:06,057 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40568174862048845, 'Total loss': 0.40568174862048845} | train loss {'Reaction outcome loss': 0.31169924459287096, 'Total loss': 0.31169924459287096}
2022-11-28 03:30:06,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:06,057 INFO:     Epoch: 78
2022-11-28 03:30:06,800 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3988536581058394, 'Total loss': 0.3988536581058394} | train loss {'Reaction outcome loss': 0.31432053909009816, 'Total loss': 0.31432053909009816}
2022-11-28 03:30:06,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:06,800 INFO:     Epoch: 79
2022-11-28 03:30:07,540 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42673138359730894, 'Total loss': 0.42673138359730894} | train loss {'Reaction outcome loss': 0.3133708391566666, 'Total loss': 0.3133708391566666}
2022-11-28 03:30:07,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:07,540 INFO:     Epoch: 80
2022-11-28 03:30:08,281 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3973875001750209, 'Total loss': 0.3973875001750209} | train loss {'Reaction outcome loss': 0.3066258725767233, 'Total loss': 0.3066258725767233}
2022-11-28 03:30:08,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:08,281 INFO:     Epoch: 81
2022-11-28 03:30:09,023 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43395278399640863, 'Total loss': 0.43395278399640863} | train loss {'Reaction outcome loss': 0.30186205171808905, 'Total loss': 0.30186205171808905}
2022-11-28 03:30:09,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:09,024 INFO:     Epoch: 82
2022-11-28 03:30:09,769 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4179757474498315, 'Total loss': 0.4179757474498315} | train loss {'Reaction outcome loss': 0.3202604888957374, 'Total loss': 0.3202604888957374}
2022-11-28 03:30:09,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:09,770 INFO:     Epoch: 83
2022-11-28 03:30:10,512 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4151077155362476, 'Total loss': 0.4151077155362476} | train loss {'Reaction outcome loss': 0.31205066360381184, 'Total loss': 0.31205066360381184}
2022-11-28 03:30:10,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:10,512 INFO:     Epoch: 84
2022-11-28 03:30:11,253 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3979187169196931, 'Total loss': 0.3979187169196931} | train loss {'Reaction outcome loss': 0.3021558414916603, 'Total loss': 0.3021558414916603}
2022-11-28 03:30:11,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:11,253 INFO:     Epoch: 85
2022-11-28 03:30:11,993 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39965927736325696, 'Total loss': 0.39965927736325696} | train loss {'Reaction outcome loss': 0.3086575663819605, 'Total loss': 0.3086575663819605}
2022-11-28 03:30:11,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:11,993 INFO:     Epoch: 86
2022-11-28 03:30:12,735 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4116778554902835, 'Total loss': 0.4116778554902835} | train loss {'Reaction outcome loss': 0.3091901457431365, 'Total loss': 0.3091901457431365}
2022-11-28 03:30:12,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:12,736 INFO:     Epoch: 87
2022-11-28 03:30:13,478 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3886994184418158, 'Total loss': 0.3886994184418158} | train loss {'Reaction outcome loss': 0.30944444570614366, 'Total loss': 0.30944444570614366}
2022-11-28 03:30:13,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:13,478 INFO:     Epoch: 88
2022-11-28 03:30:14,222 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.433129059150815, 'Total loss': 0.433129059150815} | train loss {'Reaction outcome loss': 0.30266436905581123, 'Total loss': 0.30266436905581123}
2022-11-28 03:30:14,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:14,222 INFO:     Epoch: 89
2022-11-28 03:30:14,965 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40484926985068753, 'Total loss': 0.40484926985068753} | train loss {'Reaction outcome loss': 0.3041357495650953, 'Total loss': 0.3041357495650953}
2022-11-28 03:30:14,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:14,965 INFO:     Epoch: 90
2022-11-28 03:30:15,706 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40062249011614104, 'Total loss': 0.40062249011614104} | train loss {'Reaction outcome loss': 0.3137455581098187, 'Total loss': 0.3137455581098187}
2022-11-28 03:30:15,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:15,706 INFO:     Epoch: 91
2022-11-28 03:30:16,443 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4191417412155054, 'Total loss': 0.4191417412155054} | train loss {'Reaction outcome loss': 0.30826837606728075, 'Total loss': 0.30826837606728075}
2022-11-28 03:30:16,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:16,444 INFO:     Epoch: 92
2022-11-28 03:30:17,187 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39259133563080634, 'Total loss': 0.39259133563080634} | train loss {'Reaction outcome loss': 0.31137102186983945, 'Total loss': 0.31137102186983945}
2022-11-28 03:30:17,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:17,187 INFO:     Epoch: 93
2022-11-28 03:30:17,927 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43068083172494714, 'Total loss': 0.43068083172494714} | train loss {'Reaction outcome loss': 0.30072985112058875, 'Total loss': 0.30072985112058875}
2022-11-28 03:30:17,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:17,927 INFO:     Epoch: 94
2022-11-28 03:30:18,665 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43568734282797034, 'Total loss': 0.43568734282797034} | train loss {'Reaction outcome loss': 0.3076637202987865, 'Total loss': 0.3076637202987865}
2022-11-28 03:30:18,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:18,665 INFO:     Epoch: 95
2022-11-28 03:30:19,403 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4324472180821679, 'Total loss': 0.4324472180821679} | train loss {'Reaction outcome loss': 0.30577535227853425, 'Total loss': 0.30577535227853425}
2022-11-28 03:30:19,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:19,403 INFO:     Epoch: 96
2022-11-28 03:30:20,143 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4209606379947879, 'Total loss': 0.4209606379947879} | train loss {'Reaction outcome loss': 0.2990027538215628, 'Total loss': 0.2990027538215628}
2022-11-28 03:30:20,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:20,143 INFO:     Epoch: 97
2022-11-28 03:30:20,885 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40384548462250014, 'Total loss': 0.40384548462250014} | train loss {'Reaction outcome loss': 0.30715799947478334, 'Total loss': 0.30715799947478334}
2022-11-28 03:30:20,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:20,886 INFO:     Epoch: 98
2022-11-28 03:30:21,626 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4069928117096424, 'Total loss': 0.4069928117096424} | train loss {'Reaction outcome loss': 0.3024503706517268, 'Total loss': 0.3024503706517268}
2022-11-28 03:30:21,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:21,627 INFO:     Epoch: 99
2022-11-28 03:30:22,364 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40990043262189085, 'Total loss': 0.40990043262189085} | train loss {'Reaction outcome loss': 0.3051814172340899, 'Total loss': 0.3051814172340899}
2022-11-28 03:30:22,364 INFO:     Best model found after epoch 32 of 100.
2022-11-28 03:30:22,364 INFO:   Done with stage: TRAINING
2022-11-28 03:30:22,364 INFO:   Starting stage: EVALUATION
2022-11-28 03:30:22,491 INFO:   Done with stage: EVALUATION
2022-11-28 03:30:22,491 INFO:   Leaving out SEQ value Fold_6
2022-11-28 03:30:22,504 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 03:30:22,504 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:30:23,132 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:30:23,132 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:30:23,199 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:30:23,199 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:30:23,199 INFO:     No hyperparam tuning for this model
2022-11-28 03:30:23,199 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:30:23,199 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:30:23,200 INFO:     None feature selector for col prot
2022-11-28 03:30:23,200 INFO:     None feature selector for col prot
2022-11-28 03:30:23,200 INFO:     None feature selector for col prot
2022-11-28 03:30:23,201 INFO:     None feature selector for col chem
2022-11-28 03:30:23,201 INFO:     None feature selector for col chem
2022-11-28 03:30:23,201 INFO:     None feature selector for col chem
2022-11-28 03:30:23,201 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:30:23,201 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:30:23,203 INFO:     Number of params in model 169741
2022-11-28 03:30:23,206 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:30:23,206 INFO:   Starting stage: TRAINING
2022-11-28 03:30:23,258 INFO:     Val loss before train {'Reaction outcome loss': 1.0319139167319897, 'Total loss': 1.0319139167319897}
2022-11-28 03:30:23,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:23,258 INFO:     Epoch: 0
2022-11-28 03:30:23,992 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.581042758947195, 'Total loss': 0.581042758947195} | train loss {'Reaction outcome loss': 0.6290349370998437, 'Total loss': 0.6290349370998437}
2022-11-28 03:30:23,992 INFO:     Found new best model at epoch 0
2022-11-28 03:30:23,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:23,993 INFO:     Epoch: 1
2022-11-28 03:30:24,727 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5473556421523871, 'Total loss': 0.5473556421523871} | train loss {'Reaction outcome loss': 0.5006623236370868, 'Total loss': 0.5006623236370868}
2022-11-28 03:30:24,728 INFO:     Found new best model at epoch 1
2022-11-28 03:30:24,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:24,728 INFO:     Epoch: 2
2022-11-28 03:30:25,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5105351788360019, 'Total loss': 0.5105351788360019} | train loss {'Reaction outcome loss': 0.4531580297673335, 'Total loss': 0.4531580297673335}
2022-11-28 03:30:25,466 INFO:     Found new best model at epoch 2
2022-11-28 03:30:25,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:25,467 INFO:     Epoch: 3
2022-11-28 03:30:26,203 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5282914770203967, 'Total loss': 0.5282914770203967} | train loss {'Reaction outcome loss': 0.4268467657145907, 'Total loss': 0.4268467657145907}
2022-11-28 03:30:26,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:26,203 INFO:     Epoch: 4
2022-11-28 03:30:26,939 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48202363141747406, 'Total loss': 0.48202363141747406} | train loss {'Reaction outcome loss': 0.4234518970622391, 'Total loss': 0.4234518970622391}
2022-11-28 03:30:26,939 INFO:     Found new best model at epoch 4
2022-11-28 03:30:26,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:26,940 INFO:     Epoch: 5
2022-11-28 03:30:27,672 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.513277452352435, 'Total loss': 0.513277452352435} | train loss {'Reaction outcome loss': 0.4071753040933218, 'Total loss': 0.4071753040933218}
2022-11-28 03:30:27,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:27,672 INFO:     Epoch: 6
2022-11-28 03:30:28,408 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5000949318325797, 'Total loss': 0.5000949318325797} | train loss {'Reaction outcome loss': 0.3907659827868958, 'Total loss': 0.3907659827868958}
2022-11-28 03:30:28,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:28,408 INFO:     Epoch: 7
2022-11-28 03:30:29,140 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4942260783079059, 'Total loss': 0.4942260783079059} | train loss {'Reaction outcome loss': 0.38321856491756245, 'Total loss': 0.38321856491756245}
2022-11-28 03:30:29,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:29,140 INFO:     Epoch: 8
2022-11-28 03:30:29,873 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.487564368303432, 'Total loss': 0.487564368303432} | train loss {'Reaction outcome loss': 0.38273714223235356, 'Total loss': 0.38273714223235356}
2022-11-28 03:30:29,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:29,873 INFO:     Epoch: 9
2022-11-28 03:30:30,606 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4762760806222295, 'Total loss': 0.4762760806222295} | train loss {'Reaction outcome loss': 0.37537889081801545, 'Total loss': 0.37537889081801545}
2022-11-28 03:30:30,607 INFO:     Found new best model at epoch 9
2022-11-28 03:30:30,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:30,607 INFO:     Epoch: 10
2022-11-28 03:30:31,339 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46749983069508577, 'Total loss': 0.46749983069508577} | train loss {'Reaction outcome loss': 0.3641022695075782, 'Total loss': 0.3641022695075782}
2022-11-28 03:30:31,340 INFO:     Found new best model at epoch 10
2022-11-28 03:30:31,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:31,340 INFO:     Epoch: 11
2022-11-28 03:30:32,072 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.473094578052676, 'Total loss': 0.473094578052676} | train loss {'Reaction outcome loss': 0.35182316344781, 'Total loss': 0.35182316344781}
2022-11-28 03:30:32,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:32,073 INFO:     Epoch: 12
2022-11-28 03:30:32,810 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4594356739936873, 'Total loss': 0.4594356739936873} | train loss {'Reaction outcome loss': 0.3618137583014418, 'Total loss': 0.3618137583014418}
2022-11-28 03:30:32,810 INFO:     Found new best model at epoch 12
2022-11-28 03:30:32,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:32,811 INFO:     Epoch: 13
2022-11-28 03:30:33,544 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47416233773841415, 'Total loss': 0.47416233773841415} | train loss {'Reaction outcome loss': 0.35815477493356485, 'Total loss': 0.35815477493356485}
2022-11-28 03:30:33,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:33,544 INFO:     Epoch: 14
2022-11-28 03:30:34,276 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47154096496659653, 'Total loss': 0.47154096496659653} | train loss {'Reaction outcome loss': 0.35581903579476915, 'Total loss': 0.35581903579476915}
2022-11-28 03:30:34,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:34,277 INFO:     Epoch: 15
2022-11-28 03:30:35,011 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4479785370965337, 'Total loss': 0.4479785370965337} | train loss {'Reaction outcome loss': 0.34717197224619933, 'Total loss': 0.34717197224619933}
2022-11-28 03:30:35,012 INFO:     Found new best model at epoch 15
2022-11-28 03:30:35,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:35,012 INFO:     Epoch: 16
2022-11-28 03:30:35,747 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4420414317485898, 'Total loss': 0.4420414317485898} | train loss {'Reaction outcome loss': 0.3475430343666526, 'Total loss': 0.3475430343666526}
2022-11-28 03:30:35,747 INFO:     Found new best model at epoch 16
2022-11-28 03:30:35,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:35,748 INFO:     Epoch: 17
2022-11-28 03:30:36,484 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.465842179434244, 'Total loss': 0.465842179434244} | train loss {'Reaction outcome loss': 0.33880395903328403, 'Total loss': 0.33880395903328403}
2022-11-28 03:30:36,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:36,484 INFO:     Epoch: 18
2022-11-28 03:30:37,216 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4476245225862015, 'Total loss': 0.4476245225862015} | train loss {'Reaction outcome loss': 0.3445768228380895, 'Total loss': 0.3445768228380895}
2022-11-28 03:30:37,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:37,216 INFO:     Epoch: 19
2022-11-28 03:30:37,952 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47906579285166984, 'Total loss': 0.47906579285166984} | train loss {'Reaction outcome loss': 0.34034538288890825, 'Total loss': 0.34034538288890825}
2022-11-28 03:30:37,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:37,952 INFO:     Epoch: 20
2022-11-28 03:30:38,685 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.470184997417206, 'Total loss': 0.470184997417206} | train loss {'Reaction outcome loss': 0.3376333591390829, 'Total loss': 0.3376333591390829}
2022-11-28 03:30:38,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:38,686 INFO:     Epoch: 21
2022-11-28 03:30:39,414 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47341563223406324, 'Total loss': 0.47341563223406324} | train loss {'Reaction outcome loss': 0.3322223043527271, 'Total loss': 0.3322223043527271}
2022-11-28 03:30:39,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:39,414 INFO:     Epoch: 22
2022-11-28 03:30:40,143 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47863188905771387, 'Total loss': 0.47863188905771387} | train loss {'Reaction outcome loss': 0.330084147939428, 'Total loss': 0.330084147939428}
2022-11-28 03:30:40,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:40,143 INFO:     Epoch: 23
2022-11-28 03:30:40,876 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.469224683333968, 'Total loss': 0.469224683333968} | train loss {'Reaction outcome loss': 0.33169852123885857, 'Total loss': 0.33169852123885857}
2022-11-28 03:30:40,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:40,876 INFO:     Epoch: 24
2022-11-28 03:30:41,612 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.475343321298444, 'Total loss': 0.475343321298444} | train loss {'Reaction outcome loss': 0.3375015623378949, 'Total loss': 0.3375015623378949}
2022-11-28 03:30:41,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:41,613 INFO:     Epoch: 25
2022-11-28 03:30:42,344 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.470072612859482, 'Total loss': 0.470072612859482} | train loss {'Reaction outcome loss': 0.33223269032467095, 'Total loss': 0.33223269032467095}
2022-11-28 03:30:42,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:42,344 INFO:     Epoch: 26
2022-11-28 03:30:43,076 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47564971446990967, 'Total loss': 0.47564971446990967} | train loss {'Reaction outcome loss': 0.3308291646850402, 'Total loss': 0.3308291646850402}
2022-11-28 03:30:43,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:43,076 INFO:     Epoch: 27
2022-11-28 03:30:43,807 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4520912211994792, 'Total loss': 0.4520912211994792} | train loss {'Reaction outcome loss': 0.3301548925152079, 'Total loss': 0.3301548925152079}
2022-11-28 03:30:43,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:43,807 INFO:     Epoch: 28
2022-11-28 03:30:44,542 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48050031880306643, 'Total loss': 0.48050031880306643} | train loss {'Reaction outcome loss': 0.3325734117724856, 'Total loss': 0.3325734117724856}
2022-11-28 03:30:44,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:44,543 INFO:     Epoch: 29
2022-11-28 03:30:45,279 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46099878119867904, 'Total loss': 0.46099878119867904} | train loss {'Reaction outcome loss': 0.3176633726316886, 'Total loss': 0.3176633726316886}
2022-11-28 03:30:45,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:45,279 INFO:     Epoch: 30
2022-11-28 03:30:46,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4712269278459771, 'Total loss': 0.4712269278459771} | train loss {'Reaction outcome loss': 0.320333797057144, 'Total loss': 0.320333797057144}
2022-11-28 03:30:46,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:46,013 INFO:     Epoch: 31
2022-11-28 03:30:46,746 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49963937665140906, 'Total loss': 0.49963937665140906} | train loss {'Reaction outcome loss': 0.333080008595449, 'Total loss': 0.333080008595449}
2022-11-28 03:30:46,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:46,746 INFO:     Epoch: 32
2022-11-28 03:30:47,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4589704160773477, 'Total loss': 0.4589704160773477} | train loss {'Reaction outcome loss': 0.32663329577714695, 'Total loss': 0.32663329577714695}
2022-11-28 03:30:47,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:47,477 INFO:     Epoch: 33
2022-11-28 03:30:48,212 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4999031289372333, 'Total loss': 0.4999031289372333} | train loss {'Reaction outcome loss': 0.3237587974299906, 'Total loss': 0.3237587974299906}
2022-11-28 03:30:48,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:48,212 INFO:     Epoch: 34
2022-11-28 03:30:48,945 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47853711697944373, 'Total loss': 0.47853711697944373} | train loss {'Reaction outcome loss': 0.32202186896542057, 'Total loss': 0.32202186896542057}
2022-11-28 03:30:48,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:48,945 INFO:     Epoch: 35
2022-11-28 03:30:49,675 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4613829362531041, 'Total loss': 0.4613829362531041} | train loss {'Reaction outcome loss': 0.3248519880361244, 'Total loss': 0.3248519880361244}
2022-11-28 03:30:49,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:49,676 INFO:     Epoch: 36
2022-11-28 03:30:50,412 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4728142120117365, 'Total loss': 0.4728142120117365} | train loss {'Reaction outcome loss': 0.31343130788720047, 'Total loss': 0.31343130788720047}
2022-11-28 03:30:50,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:50,412 INFO:     Epoch: 37
2022-11-28 03:30:51,149 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47781815431838814, 'Total loss': 0.47781815431838814} | train loss {'Reaction outcome loss': 0.3196100743609618, 'Total loss': 0.3196100743609618}
2022-11-28 03:30:51,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:51,149 INFO:     Epoch: 38
2022-11-28 03:30:51,889 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4556029418180155, 'Total loss': 0.4556029418180155} | train loss {'Reaction outcome loss': 0.3184452634304762, 'Total loss': 0.3184452634304762}
2022-11-28 03:30:51,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:51,889 INFO:     Epoch: 39
2022-11-28 03:30:52,634 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47017002833444016, 'Total loss': 0.47017002833444016} | train loss {'Reaction outcome loss': 0.316976006585555, 'Total loss': 0.316976006585555}
2022-11-28 03:30:52,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:52,634 INFO:     Epoch: 40
2022-11-28 03:30:53,371 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4821658605752989, 'Total loss': 0.4821658605752989} | train loss {'Reaction outcome loss': 0.31632460012543395, 'Total loss': 0.31632460012543395}
2022-11-28 03:30:53,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:53,372 INFO:     Epoch: 41
2022-11-28 03:30:54,111 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4571136302033136, 'Total loss': 0.4571136302033136} | train loss {'Reaction outcome loss': 0.3057384041489148, 'Total loss': 0.3057384041489148}
2022-11-28 03:30:54,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:54,112 INFO:     Epoch: 42
2022-11-28 03:30:54,850 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48591314290845117, 'Total loss': 0.48591314290845117} | train loss {'Reaction outcome loss': 0.32468540819941977, 'Total loss': 0.32468540819941977}
2022-11-28 03:30:54,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:54,850 INFO:     Epoch: 43
2022-11-28 03:30:55,591 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48076785719671916, 'Total loss': 0.48076785719671916} | train loss {'Reaction outcome loss': 0.31784500087015943, 'Total loss': 0.31784500087015943}
2022-11-28 03:30:55,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:55,592 INFO:     Epoch: 44
2022-11-28 03:30:56,332 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4699537282766298, 'Total loss': 0.4699537282766298} | train loss {'Reaction outcome loss': 0.3149748449137465, 'Total loss': 0.3149748449137465}
2022-11-28 03:30:56,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:56,332 INFO:     Epoch: 45
2022-11-28 03:30:57,071 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4556470877209375, 'Total loss': 0.4556470877209375} | train loss {'Reaction outcome loss': 0.3176155528206317, 'Total loss': 0.3176155528206317}
2022-11-28 03:30:57,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:57,071 INFO:     Epoch: 46
2022-11-28 03:30:57,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4527902537307074, 'Total loss': 0.4527902537307074} | train loss {'Reaction outcome loss': 0.3113676427298638, 'Total loss': 0.3113676427298638}
2022-11-28 03:30:57,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:57,817 INFO:     Epoch: 47
2022-11-28 03:30:58,555 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47140313303747844, 'Total loss': 0.47140313303747844} | train loss {'Reaction outcome loss': 0.3159636085333883, 'Total loss': 0.3159636085333883}
2022-11-28 03:30:58,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:58,555 INFO:     Epoch: 48
2022-11-28 03:30:59,297 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4758404236893321, 'Total loss': 0.4758404236893321} | train loss {'Reaction outcome loss': 0.31467813512951626, 'Total loss': 0.31467813512951626}
2022-11-28 03:30:59,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:30:59,297 INFO:     Epoch: 49
2022-11-28 03:31:00,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48530133969562, 'Total loss': 0.48530133969562} | train loss {'Reaction outcome loss': 0.3115883445306147, 'Total loss': 0.3115883445306147}
2022-11-28 03:31:00,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:00,039 INFO:     Epoch: 50
2022-11-28 03:31:00,778 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4964023014140684, 'Total loss': 0.4964023014140684} | train loss {'Reaction outcome loss': 0.31554430506390624, 'Total loss': 0.31554430506390624}
2022-11-28 03:31:00,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:00,778 INFO:     Epoch: 51
2022-11-28 03:31:01,522 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46890018395213195, 'Total loss': 0.46890018395213195} | train loss {'Reaction outcome loss': 0.31246219062414327, 'Total loss': 0.31246219062414327}
2022-11-28 03:31:01,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:01,522 INFO:     Epoch: 52
2022-11-28 03:31:02,267 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46989341322765793, 'Total loss': 0.46989341322765793} | train loss {'Reaction outcome loss': 0.3041019448247112, 'Total loss': 0.3041019448247112}
2022-11-28 03:31:02,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:02,268 INFO:     Epoch: 53
2022-11-28 03:31:03,013 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4699944642394088, 'Total loss': 0.4699944642394088} | train loss {'Reaction outcome loss': 0.31072619939070256, 'Total loss': 0.31072619939070256}
2022-11-28 03:31:03,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:03,013 INFO:     Epoch: 54
2022-11-28 03:31:03,755 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4554221196923145, 'Total loss': 0.4554221196923145} | train loss {'Reaction outcome loss': 0.31283632381895526, 'Total loss': 0.31283632381895526}
2022-11-28 03:31:03,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:03,755 INFO:     Epoch: 55
2022-11-28 03:31:04,499 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45831921835278355, 'Total loss': 0.45831921835278355} | train loss {'Reaction outcome loss': 0.3101512038866516, 'Total loss': 0.3101512038866516}
2022-11-28 03:31:04,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:04,499 INFO:     Epoch: 56
2022-11-28 03:31:05,245 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46754776461179864, 'Total loss': 0.46754776461179864} | train loss {'Reaction outcome loss': 0.3109458797290677, 'Total loss': 0.3109458797290677}
2022-11-28 03:31:05,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:05,245 INFO:     Epoch: 57
2022-11-28 03:31:05,990 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.479853403776191, 'Total loss': 0.479853403776191} | train loss {'Reaction outcome loss': 0.31733150957304923, 'Total loss': 0.31733150957304923}
2022-11-28 03:31:05,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:05,990 INFO:     Epoch: 58
2022-11-28 03:31:06,732 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5281710586575574, 'Total loss': 0.5281710586575574} | train loss {'Reaction outcome loss': 0.30952824679676627, 'Total loss': 0.30952824679676627}
2022-11-28 03:31:06,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:06,733 INFO:     Epoch: 59
2022-11-28 03:31:07,476 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45754017005133074, 'Total loss': 0.45754017005133074} | train loss {'Reaction outcome loss': 0.32076962545636245, 'Total loss': 0.32076962545636245}
2022-11-28 03:31:07,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:07,476 INFO:     Epoch: 60
2022-11-28 03:31:08,219 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4803240968044414, 'Total loss': 0.4803240968044414} | train loss {'Reaction outcome loss': 0.3047422222090793, 'Total loss': 0.3047422222090793}
2022-11-28 03:31:08,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:08,219 INFO:     Epoch: 61
2022-11-28 03:31:08,966 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48271584060303, 'Total loss': 0.48271584060303} | train loss {'Reaction outcome loss': 0.3117494487554812, 'Total loss': 0.3117494487554812}
2022-11-28 03:31:08,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:08,967 INFO:     Epoch: 62
2022-11-28 03:31:09,712 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4565717113572498, 'Total loss': 0.4565717113572498} | train loss {'Reaction outcome loss': 0.3036710912835036, 'Total loss': 0.3036710912835036}
2022-11-28 03:31:09,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:09,713 INFO:     Epoch: 63
2022-11-28 03:31:10,459 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4778371331996696, 'Total loss': 0.4778371331996696} | train loss {'Reaction outcome loss': 0.30736002710754756, 'Total loss': 0.30736002710754756}
2022-11-28 03:31:10,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:10,460 INFO:     Epoch: 64
2022-11-28 03:31:11,205 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4657008564749429, 'Total loss': 0.4657008564749429} | train loss {'Reaction outcome loss': 0.31022366278301006, 'Total loss': 0.31022366278301006}
2022-11-28 03:31:11,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:11,205 INFO:     Epoch: 65
2022-11-28 03:31:11,949 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.473108837077784, 'Total loss': 0.473108837077784} | train loss {'Reaction outcome loss': 0.3153391887937657, 'Total loss': 0.3153391887937657}
2022-11-28 03:31:11,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:11,949 INFO:     Epoch: 66
2022-11-28 03:31:12,688 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4742155154777128, 'Total loss': 0.4742155154777128} | train loss {'Reaction outcome loss': 0.3109335360407341, 'Total loss': 0.3109335360407341}
2022-11-28 03:31:12,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:12,689 INFO:     Epoch: 67
2022-11-28 03:31:13,429 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49438066087489907, 'Total loss': 0.49438066087489907} | train loss {'Reaction outcome loss': 0.3070263963375912, 'Total loss': 0.3070263963375912}
2022-11-28 03:31:13,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:13,429 INFO:     Epoch: 68
2022-11-28 03:31:14,167 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46535747550254647, 'Total loss': 0.46535747550254647} | train loss {'Reaction outcome loss': 0.3066263421453902, 'Total loss': 0.3066263421453902}
2022-11-28 03:31:14,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:14,167 INFO:     Epoch: 69
2022-11-28 03:31:14,908 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44508519318214684, 'Total loss': 0.44508519318214684} | train loss {'Reaction outcome loss': 0.3122410599875157, 'Total loss': 0.3122410599875157}
2022-11-28 03:31:14,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:14,908 INFO:     Epoch: 70
2022-11-28 03:31:15,648 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4743461054424907, 'Total loss': 0.4743461054424907} | train loss {'Reaction outcome loss': 0.299108172522583, 'Total loss': 0.299108172522583}
2022-11-28 03:31:15,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:15,648 INFO:     Epoch: 71
2022-11-28 03:31:16,387 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4677618041981098, 'Total loss': 0.4677618041981098} | train loss {'Reaction outcome loss': 0.30891905157048194, 'Total loss': 0.30891905157048194}
2022-11-28 03:31:16,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:16,387 INFO:     Epoch: 72
2022-11-28 03:31:17,130 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4481248969948569, 'Total loss': 0.4481248969948569} | train loss {'Reaction outcome loss': 0.3059140838774257, 'Total loss': 0.3059140838774257}
2022-11-28 03:31:17,130 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:17,130 INFO:     Epoch: 73
2022-11-28 03:31:17,872 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46539363819499346, 'Total loss': 0.46539363819499346} | train loss {'Reaction outcome loss': 0.30610992275483784, 'Total loss': 0.30610992275483784}
2022-11-28 03:31:17,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:17,872 INFO:     Epoch: 74
2022-11-28 03:31:18,613 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44633535763552024, 'Total loss': 0.44633535763552024} | train loss {'Reaction outcome loss': 0.3017559510762574, 'Total loss': 0.3017559510762574}
2022-11-28 03:31:18,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:18,614 INFO:     Epoch: 75
2022-11-28 03:31:19,353 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47559654192869055, 'Total loss': 0.47559654192869055} | train loss {'Reaction outcome loss': 0.2959595262149318, 'Total loss': 0.2959595262149318}
2022-11-28 03:31:19,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:19,353 INFO:     Epoch: 76
2022-11-28 03:31:20,095 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47031542069690174, 'Total loss': 0.47031542069690174} | train loss {'Reaction outcome loss': 0.3006139439454333, 'Total loss': 0.3006139439454333}
2022-11-28 03:31:20,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:20,096 INFO:     Epoch: 77
2022-11-28 03:31:20,838 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4819209714268529, 'Total loss': 0.4819209714268529} | train loss {'Reaction outcome loss': 0.30119062523494977, 'Total loss': 0.30119062523494977}
2022-11-28 03:31:20,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:20,838 INFO:     Epoch: 78
2022-11-28 03:31:21,581 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.462706211001374, 'Total loss': 0.462706211001374} | train loss {'Reaction outcome loss': 0.3056910758776987, 'Total loss': 0.3056910758776987}
2022-11-28 03:31:21,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:21,581 INFO:     Epoch: 79
2022-11-28 03:31:22,322 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45797398339870365, 'Total loss': 0.45797398339870365} | train loss {'Reaction outcome loss': 0.30525900090693453, 'Total loss': 0.30525900090693453}
2022-11-28 03:31:22,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:22,322 INFO:     Epoch: 80
2022-11-28 03:31:23,064 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4851942547532015, 'Total loss': 0.4851942547532015} | train loss {'Reaction outcome loss': 0.30461860826758086, 'Total loss': 0.30461860826758086}
2022-11-28 03:31:23,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:23,064 INFO:     Epoch: 81
2022-11-28 03:31:23,805 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.464927030164142, 'Total loss': 0.464927030164142} | train loss {'Reaction outcome loss': 0.30975959007246573, 'Total loss': 0.30975959007246573}
2022-11-28 03:31:23,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:23,805 INFO:     Epoch: 82
2022-11-28 03:31:24,546 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4719953776098961, 'Total loss': 0.4719953776098961} | train loss {'Reaction outcome loss': 0.30419601939740726, 'Total loss': 0.30419601939740726}
2022-11-28 03:31:24,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:24,546 INFO:     Epoch: 83
2022-11-28 03:31:25,286 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4633658060500788, 'Total loss': 0.4633658060500788} | train loss {'Reaction outcome loss': 0.2977600932335023, 'Total loss': 0.2977600932335023}
2022-11-28 03:31:25,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:25,287 INFO:     Epoch: 84
2022-11-28 03:31:26,027 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47500904181668924, 'Total loss': 0.47500904181668924} | train loss {'Reaction outcome loss': 0.3115237412333, 'Total loss': 0.3115237412333}
2022-11-28 03:31:26,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:26,027 INFO:     Epoch: 85
2022-11-28 03:31:26,766 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4743943446597388, 'Total loss': 0.4743943446597388} | train loss {'Reaction outcome loss': 0.32106833248475536, 'Total loss': 0.32106833248475536}
2022-11-28 03:31:26,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:26,766 INFO:     Epoch: 86
2022-11-28 03:31:27,505 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4730576172817585, 'Total loss': 0.4730576172817585} | train loss {'Reaction outcome loss': 0.3018479037297065, 'Total loss': 0.3018479037297065}
2022-11-28 03:31:27,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:27,505 INFO:     Epoch: 87
2022-11-28 03:31:28,246 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47585786463216295, 'Total loss': 0.47585786463216295} | train loss {'Reaction outcome loss': 0.29853893266838105, 'Total loss': 0.29853893266838105}
2022-11-28 03:31:28,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:28,246 INFO:     Epoch: 88
2022-11-28 03:31:28,988 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.483972359535306, 'Total loss': 0.483972359535306} | train loss {'Reaction outcome loss': 0.311514722137544, 'Total loss': 0.311514722137544}
2022-11-28 03:31:28,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:28,988 INFO:     Epoch: 89
2022-11-28 03:31:29,729 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48534068291963534, 'Total loss': 0.48534068291963534} | train loss {'Reaction outcome loss': 0.3025815284459806, 'Total loss': 0.3025815284459806}
2022-11-28 03:31:29,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:29,729 INFO:     Epoch: 90
2022-11-28 03:31:30,473 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4399886831294659, 'Total loss': 0.4399886831294659} | train loss {'Reaction outcome loss': 0.3071407895443625, 'Total loss': 0.3071407895443625}
2022-11-28 03:31:30,473 INFO:     Found new best model at epoch 90
2022-11-28 03:31:30,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:30,474 INFO:     Epoch: 91
2022-11-28 03:31:31,215 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4439535279606664, 'Total loss': 0.4439535279606664} | train loss {'Reaction outcome loss': 0.3021904867539396, 'Total loss': 0.3021904867539396}
2022-11-28 03:31:31,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:31,215 INFO:     Epoch: 92
2022-11-28 03:31:31,957 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45990014041579047, 'Total loss': 0.45990014041579047} | train loss {'Reaction outcome loss': 0.30109611303224915, 'Total loss': 0.30109611303224915}
2022-11-28 03:31:31,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:31,957 INFO:     Epoch: 93
2022-11-28 03:31:32,696 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4653338192160739, 'Total loss': 0.4653338192160739} | train loss {'Reaction outcome loss': 0.30795155083913295, 'Total loss': 0.30795155083913295}
2022-11-28 03:31:32,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:32,696 INFO:     Epoch: 94
2022-11-28 03:31:33,434 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4429829103309055, 'Total loss': 0.4429829103309055} | train loss {'Reaction outcome loss': 0.30217753912581774, 'Total loss': 0.30217753912581774}
2022-11-28 03:31:33,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:33,434 INFO:     Epoch: 95
2022-11-28 03:31:34,174 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5053244087585184, 'Total loss': 0.5053244087585184} | train loss {'Reaction outcome loss': 0.2999813353764962, 'Total loss': 0.2999813353764962}
2022-11-28 03:31:34,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:34,174 INFO:     Epoch: 96
2022-11-28 03:31:34,914 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.441120492857556, 'Total loss': 0.441120492857556} | train loss {'Reaction outcome loss': 0.30762245130465654, 'Total loss': 0.30762245130465654}
2022-11-28 03:31:34,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:34,915 INFO:     Epoch: 97
2022-11-28 03:31:35,658 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45455385051494424, 'Total loss': 0.45455385051494424} | train loss {'Reaction outcome loss': 0.3031291402876377, 'Total loss': 0.3031291402876377}
2022-11-28 03:31:35,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:35,658 INFO:     Epoch: 98
2022-11-28 03:31:36,394 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46696914143340534, 'Total loss': 0.46696914143340534} | train loss {'Reaction outcome loss': 0.2996096842632186, 'Total loss': 0.2996096842632186}
2022-11-28 03:31:36,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:36,394 INFO:     Epoch: 99
2022-11-28 03:31:37,130 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45811359289773673, 'Total loss': 0.45811359289773673} | train loss {'Reaction outcome loss': 0.3107305507740525, 'Total loss': 0.3107305507740525}
2022-11-28 03:31:37,130 INFO:     Best model found after epoch 91 of 100.
2022-11-28 03:31:37,130 INFO:   Done with stage: TRAINING
2022-11-28 03:31:37,130 INFO:   Starting stage: EVALUATION
2022-11-28 03:31:37,262 INFO:   Done with stage: EVALUATION
2022-11-28 03:31:37,262 INFO:   Leaving out SEQ value Fold_7
2022-11-28 03:31:37,276 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:31:37,276 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:31:37,925 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:31:37,926 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:31:37,995 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:31:37,995 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:31:37,995 INFO:     No hyperparam tuning for this model
2022-11-28 03:31:37,996 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:31:37,996 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:31:37,996 INFO:     None feature selector for col prot
2022-11-28 03:31:37,996 INFO:     None feature selector for col prot
2022-11-28 03:31:37,997 INFO:     None feature selector for col prot
2022-11-28 03:31:37,997 INFO:     None feature selector for col chem
2022-11-28 03:31:37,997 INFO:     None feature selector for col chem
2022-11-28 03:31:37,997 INFO:     None feature selector for col chem
2022-11-28 03:31:37,997 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:31:37,997 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:31:37,999 INFO:     Number of params in model 169741
2022-11-28 03:31:38,002 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:31:38,002 INFO:   Starting stage: TRAINING
2022-11-28 03:31:38,056 INFO:     Val loss before train {'Reaction outcome loss': 1.0509694746949456, 'Total loss': 1.0509694746949456}
2022-11-28 03:31:38,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:38,056 INFO:     Epoch: 0
2022-11-28 03:31:38,804 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5703702399676497, 'Total loss': 0.5703702399676497} | train loss {'Reaction outcome loss': 0.6406365229838318, 'Total loss': 0.6406365229838318}
2022-11-28 03:31:38,804 INFO:     Found new best model at epoch 0
2022-11-28 03:31:38,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:38,805 INFO:     Epoch: 1
2022-11-28 03:31:39,552 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5297902084209702, 'Total loss': 0.5297902084209702} | train loss {'Reaction outcome loss': 0.4939392584736549, 'Total loss': 0.4939392584736549}
2022-11-28 03:31:39,552 INFO:     Found new best model at epoch 1
2022-11-28 03:31:39,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:39,553 INFO:     Epoch: 2
2022-11-28 03:31:40,301 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5335168811407957, 'Total loss': 0.5335168811407957} | train loss {'Reaction outcome loss': 0.458239977518397, 'Total loss': 0.458239977518397}
2022-11-28 03:31:40,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:40,302 INFO:     Epoch: 3
2022-11-28 03:31:41,052 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4818804043937813, 'Total loss': 0.4818804043937813} | train loss {'Reaction outcome loss': 0.4377040613683001, 'Total loss': 0.4377040613683001}
2022-11-28 03:31:41,052 INFO:     Found new best model at epoch 3
2022-11-28 03:31:41,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:41,053 INFO:     Epoch: 4
2022-11-28 03:31:41,801 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49654971808195114, 'Total loss': 0.49654971808195114} | train loss {'Reaction outcome loss': 0.421391517945355, 'Total loss': 0.421391517945355}
2022-11-28 03:31:41,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:41,801 INFO:     Epoch: 5
2022-11-28 03:31:42,554 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.460984160954302, 'Total loss': 0.460984160954302} | train loss {'Reaction outcome loss': 0.4036183636635542, 'Total loss': 0.4036183636635542}
2022-11-28 03:31:42,554 INFO:     Found new best model at epoch 5
2022-11-28 03:31:42,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:42,555 INFO:     Epoch: 6
2022-11-28 03:31:43,303 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4828408313068477, 'Total loss': 0.4828408313068477} | train loss {'Reaction outcome loss': 0.39221163953263916, 'Total loss': 0.39221163953263916}
2022-11-28 03:31:43,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:43,303 INFO:     Epoch: 7
2022-11-28 03:31:44,052 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4496894394132224, 'Total loss': 0.4496894394132224} | train loss {'Reaction outcome loss': 0.39012390113766154, 'Total loss': 0.39012390113766154}
2022-11-28 03:31:44,052 INFO:     Found new best model at epoch 7
2022-11-28 03:31:44,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:44,053 INFO:     Epoch: 8
2022-11-28 03:31:44,801 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46292183378880675, 'Total loss': 0.46292183378880675} | train loss {'Reaction outcome loss': 0.3782151718473723, 'Total loss': 0.3782151718473723}
2022-11-28 03:31:44,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:44,802 INFO:     Epoch: 9
2022-11-28 03:31:45,548 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4707995886829766, 'Total loss': 0.4707995886829766} | train loss {'Reaction outcome loss': 0.36815019973343416, 'Total loss': 0.36815019973343416}
2022-11-28 03:31:45,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:45,549 INFO:     Epoch: 10
2022-11-28 03:31:46,295 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4524645121260123, 'Total loss': 0.4524645121260123} | train loss {'Reaction outcome loss': 0.36444787134326273, 'Total loss': 0.36444787134326273}
2022-11-28 03:31:46,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:46,295 INFO:     Epoch: 11
2022-11-28 03:31:47,045 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47618580440228636, 'Total loss': 0.47618580440228636} | train loss {'Reaction outcome loss': 0.3684247573537211, 'Total loss': 0.3684247573537211}
2022-11-28 03:31:47,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:47,045 INFO:     Epoch: 12
2022-11-28 03:31:47,794 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4361340224065564, 'Total loss': 0.4361340224065564} | train loss {'Reaction outcome loss': 0.3559958049727063, 'Total loss': 0.3559958049727063}
2022-11-28 03:31:47,794 INFO:     Found new best model at epoch 12
2022-11-28 03:31:47,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:47,795 INFO:     Epoch: 13
2022-11-28 03:31:48,544 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4566748507998206, 'Total loss': 0.4566748507998206} | train loss {'Reaction outcome loss': 0.34884931555678766, 'Total loss': 0.34884931555678766}
2022-11-28 03:31:48,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:48,545 INFO:     Epoch: 14
2022-11-28 03:31:49,292 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4482644491574981, 'Total loss': 0.4482644491574981} | train loss {'Reaction outcome loss': 0.3485387980697616, 'Total loss': 0.3485387980697616}
2022-11-28 03:31:49,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:49,292 INFO:     Epoch: 15
2022-11-28 03:31:50,041 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4468273811719634, 'Total loss': 0.4468273811719634} | train loss {'Reaction outcome loss': 0.34231530992133963, 'Total loss': 0.34231530992133963}
2022-11-28 03:31:50,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:50,042 INFO:     Epoch: 16
2022-11-28 03:31:50,792 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4341055649248036, 'Total loss': 0.4341055649248036} | train loss {'Reaction outcome loss': 0.340519409656765, 'Total loss': 0.340519409656765}
2022-11-28 03:31:50,792 INFO:     Found new best model at epoch 16
2022-11-28 03:31:50,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:50,793 INFO:     Epoch: 17
2022-11-28 03:31:51,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4391872137784958, 'Total loss': 0.4391872137784958} | train loss {'Reaction outcome loss': 0.33783450317118435, 'Total loss': 0.33783450317118435}
2022-11-28 03:31:51,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:51,543 INFO:     Epoch: 18
2022-11-28 03:31:52,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42974991182034666, 'Total loss': 0.42974991182034666} | train loss {'Reaction outcome loss': 0.3330538876715206, 'Total loss': 0.3330538876715206}
2022-11-28 03:31:52,297 INFO:     Found new best model at epoch 18
2022-11-28 03:31:52,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:52,298 INFO:     Epoch: 19
2022-11-28 03:31:53,052 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4319316843016581, 'Total loss': 0.4319316843016581} | train loss {'Reaction outcome loss': 0.3294302463501452, 'Total loss': 0.3294302463501452}
2022-11-28 03:31:53,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:53,053 INFO:     Epoch: 20
2022-11-28 03:31:53,805 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4339981937611645, 'Total loss': 0.4339981937611645} | train loss {'Reaction outcome loss': 0.32922416172861574, 'Total loss': 0.32922416172861574}
2022-11-28 03:31:53,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:53,805 INFO:     Epoch: 21
2022-11-28 03:31:54,555 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45003553344444797, 'Total loss': 0.45003553344444797} | train loss {'Reaction outcome loss': 0.3286089829860195, 'Total loss': 0.3286089829860195}
2022-11-28 03:31:54,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:54,555 INFO:     Epoch: 22
2022-11-28 03:31:55,307 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4494248059662906, 'Total loss': 0.4494248059662906} | train loss {'Reaction outcome loss': 0.3264337732126155, 'Total loss': 0.3264337732126155}
2022-11-28 03:31:55,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:55,307 INFO:     Epoch: 23
2022-11-28 03:31:56,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4458869773555886, 'Total loss': 0.4458869773555886} | train loss {'Reaction outcome loss': 0.3341472072286471, 'Total loss': 0.3341472072286471}
2022-11-28 03:31:56,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:56,065 INFO:     Epoch: 24
2022-11-28 03:31:56,825 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4303704219108278, 'Total loss': 0.4303704219108278} | train loss {'Reaction outcome loss': 0.33049991759922237, 'Total loss': 0.33049991759922237}
2022-11-28 03:31:56,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:56,825 INFO:     Epoch: 25
2022-11-28 03:31:57,579 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4325978976081718, 'Total loss': 0.4325978976081718} | train loss {'Reaction outcome loss': 0.3193210938404645, 'Total loss': 0.3193210938404645}
2022-11-28 03:31:57,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:57,579 INFO:     Epoch: 26
2022-11-28 03:31:58,334 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4111406207084656, 'Total loss': 0.4111406207084656} | train loss {'Reaction outcome loss': 0.32549278155690237, 'Total loss': 0.32549278155690237}
2022-11-28 03:31:58,334 INFO:     Found new best model at epoch 26
2022-11-28 03:31:58,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:58,335 INFO:     Epoch: 27
2022-11-28 03:31:59,084 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44549192538992927, 'Total loss': 0.44549192538992927} | train loss {'Reaction outcome loss': 0.3204545019074313, 'Total loss': 0.3204545019074313}
2022-11-28 03:31:59,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:59,084 INFO:     Epoch: 28
2022-11-28 03:31:59,833 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44394021278077905, 'Total loss': 0.44394021278077905} | train loss {'Reaction outcome loss': 0.3251457210149496, 'Total loss': 0.3251457210149496}
2022-11-28 03:31:59,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:31:59,833 INFO:     Epoch: 29
2022-11-28 03:32:00,581 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4544672295451164, 'Total loss': 0.4544672295451164} | train loss {'Reaction outcome loss': 0.3187111680651264, 'Total loss': 0.3187111680651264}
2022-11-28 03:32:00,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:00,581 INFO:     Epoch: 30
2022-11-28 03:32:01,326 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4389780419455333, 'Total loss': 0.4389780419455333} | train loss {'Reaction outcome loss': 0.3233576325789815, 'Total loss': 0.3233576325789815}
2022-11-28 03:32:01,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:01,326 INFO:     Epoch: 31
2022-11-28 03:32:02,076 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4273286190899936, 'Total loss': 0.4273286190899936} | train loss {'Reaction outcome loss': 0.31515254284585675, 'Total loss': 0.31515254284585675}
2022-11-28 03:32:02,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:02,076 INFO:     Epoch: 32
2022-11-28 03:32:02,825 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4764702679081397, 'Total loss': 0.4764702679081397} | train loss {'Reaction outcome loss': 0.3143490193141324, 'Total loss': 0.3143490193141324}
2022-11-28 03:32:02,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:02,825 INFO:     Epoch: 33
2022-11-28 03:32:03,574 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45403317226604983, 'Total loss': 0.45403317226604983} | train loss {'Reaction outcome loss': 0.3223906777678959, 'Total loss': 0.3223906777678959}
2022-11-28 03:32:03,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:03,575 INFO:     Epoch: 34
2022-11-28 03:32:04,321 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44486700709570537, 'Total loss': 0.44486700709570537} | train loss {'Reaction outcome loss': 0.32012506762158965, 'Total loss': 0.32012506762158965}
2022-11-28 03:32:04,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:04,322 INFO:     Epoch: 35
2022-11-28 03:32:05,069 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4603490892120383, 'Total loss': 0.4603490892120383} | train loss {'Reaction outcome loss': 0.30871807151444014, 'Total loss': 0.30871807151444014}
2022-11-28 03:32:05,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:05,069 INFO:     Epoch: 36
2022-11-28 03:32:05,817 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4551759981973605, 'Total loss': 0.4551759981973605} | train loss {'Reaction outcome loss': 0.30810942564670357, 'Total loss': 0.30810942564670357}
2022-11-28 03:32:05,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:05,818 INFO:     Epoch: 37
2022-11-28 03:32:06,566 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42466534267772327, 'Total loss': 0.42466534267772327} | train loss {'Reaction outcome loss': 0.3195454602940909, 'Total loss': 0.3195454602940909}
2022-11-28 03:32:06,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:06,566 INFO:     Epoch: 38
2022-11-28 03:32:07,314 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4477199021388184, 'Total loss': 0.4477199021388184} | train loss {'Reaction outcome loss': 0.31265208877683165, 'Total loss': 0.31265208877683165}
2022-11-28 03:32:07,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:07,315 INFO:     Epoch: 39
2022-11-28 03:32:08,063 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43480289388786664, 'Total loss': 0.43480289388786664} | train loss {'Reaction outcome loss': 0.31948148196322784, 'Total loss': 0.31948148196322784}
2022-11-28 03:32:08,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:08,064 INFO:     Epoch: 40
2022-11-28 03:32:08,810 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46517005478116596, 'Total loss': 0.46517005478116596} | train loss {'Reaction outcome loss': 0.3125205858640613, 'Total loss': 0.3125205858640613}
2022-11-28 03:32:08,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:08,810 INFO:     Epoch: 41
2022-11-28 03:32:09,558 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43540188974954863, 'Total loss': 0.43540188974954863} | train loss {'Reaction outcome loss': 0.3090312111702177, 'Total loss': 0.3090312111702177}
2022-11-28 03:32:09,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:09,558 INFO:     Epoch: 42
2022-11-28 03:32:10,310 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4321093318814581, 'Total loss': 0.4321093318814581} | train loss {'Reaction outcome loss': 0.30669368391916635, 'Total loss': 0.30669368391916635}
2022-11-28 03:32:10,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:10,310 INFO:     Epoch: 43
2022-11-28 03:32:11,063 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4272324087267572, 'Total loss': 0.4272324087267572} | train loss {'Reaction outcome loss': 0.308712474956748, 'Total loss': 0.308712474956748}
2022-11-28 03:32:11,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:11,063 INFO:     Epoch: 44
2022-11-28 03:32:11,813 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43803227455778554, 'Total loss': 0.43803227455778554} | train loss {'Reaction outcome loss': 0.30945281205218167, 'Total loss': 0.30945281205218167}
2022-11-28 03:32:11,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:11,813 INFO:     Epoch: 45
2022-11-28 03:32:12,562 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4272906936027787, 'Total loss': 0.4272906936027787} | train loss {'Reaction outcome loss': 0.3083755199406897, 'Total loss': 0.3083755199406897}
2022-11-28 03:32:12,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:12,562 INFO:     Epoch: 46
2022-11-28 03:32:13,312 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.427271747792309, 'Total loss': 0.427271747792309} | train loss {'Reaction outcome loss': 0.30848117114134854, 'Total loss': 0.30848117114134854}
2022-11-28 03:32:13,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:13,313 INFO:     Epoch: 47
2022-11-28 03:32:14,061 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45221949368715286, 'Total loss': 0.45221949368715286} | train loss {'Reaction outcome loss': 0.30542020839188366, 'Total loss': 0.30542020839188366}
2022-11-28 03:32:14,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:14,062 INFO:     Epoch: 48
2022-11-28 03:32:14,811 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44796122644435277, 'Total loss': 0.44796122644435277} | train loss {'Reaction outcome loss': 0.31046118554208546, 'Total loss': 0.31046118554208546}
2022-11-28 03:32:14,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:14,812 INFO:     Epoch: 49
2022-11-28 03:32:15,561 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4428676404058933, 'Total loss': 0.4428676404058933} | train loss {'Reaction outcome loss': 0.3005195929098033, 'Total loss': 0.3005195929098033}
2022-11-28 03:32:15,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:15,561 INFO:     Epoch: 50
2022-11-28 03:32:16,312 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4465543996881355, 'Total loss': 0.4465543996881355} | train loss {'Reaction outcome loss': 0.3141650591916855, 'Total loss': 0.3141650591916855}
2022-11-28 03:32:16,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:16,312 INFO:     Epoch: 51
2022-11-28 03:32:17,062 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41596084680746903, 'Total loss': 0.41596084680746903} | train loss {'Reaction outcome loss': 0.30802175812723653, 'Total loss': 0.30802175812723653}
2022-11-28 03:32:17,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:17,062 INFO:     Epoch: 52
2022-11-28 03:32:17,813 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46340023285963317, 'Total loss': 0.46340023285963317} | train loss {'Reaction outcome loss': 0.2993145979520294, 'Total loss': 0.2993145979520294}
2022-11-28 03:32:17,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:17,813 INFO:     Epoch: 53
2022-11-28 03:32:18,567 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42469727857546374, 'Total loss': 0.42469727857546374} | train loss {'Reaction outcome loss': 0.30667292108879457, 'Total loss': 0.30667292108879457}
2022-11-28 03:32:18,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:18,567 INFO:     Epoch: 54
2022-11-28 03:32:19,314 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4287344535643404, 'Total loss': 0.4287344535643404} | train loss {'Reaction outcome loss': 0.31037451798516896, 'Total loss': 0.31037451798516896}
2022-11-28 03:32:19,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:19,314 INFO:     Epoch: 55
2022-11-28 03:32:20,064 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4616048840636557, 'Total loss': 0.4616048840636557} | train loss {'Reaction outcome loss': 0.30415240799888005, 'Total loss': 0.30415240799888005}
2022-11-28 03:32:20,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:20,064 INFO:     Epoch: 56
2022-11-28 03:32:20,814 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4301020083102313, 'Total loss': 0.4301020083102313} | train loss {'Reaction outcome loss': 0.3055967977570911, 'Total loss': 0.3055967977570911}
2022-11-28 03:32:20,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:20,814 INFO:     Epoch: 57
2022-11-28 03:32:21,564 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45541696216572414, 'Total loss': 0.45541696216572414} | train loss {'Reaction outcome loss': 0.3102715853902121, 'Total loss': 0.3102715853902121}
2022-11-28 03:32:21,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:21,565 INFO:     Epoch: 58
2022-11-28 03:32:22,316 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46819464455951343, 'Total loss': 0.46819464455951343} | train loss {'Reaction outcome loss': 0.3052302054279754, 'Total loss': 0.3052302054279754}
2022-11-28 03:32:22,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:22,317 INFO:     Epoch: 59
2022-11-28 03:32:23,068 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43693870543078944, 'Total loss': 0.43693870543078944} | train loss {'Reaction outcome loss': 0.30094755648244775, 'Total loss': 0.30094755648244775}
2022-11-28 03:32:23,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:23,068 INFO:     Epoch: 60
2022-11-28 03:32:23,818 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44144605879079213, 'Total loss': 0.44144605879079213} | train loss {'Reaction outcome loss': 0.30668047343891475, 'Total loss': 0.30668047343891475}
2022-11-28 03:32:23,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:23,819 INFO:     Epoch: 61
2022-11-28 03:32:24,571 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47627409953962674, 'Total loss': 0.47627409953962674} | train loss {'Reaction outcome loss': 0.30462318770737656, 'Total loss': 0.30462318770737656}
2022-11-28 03:32:24,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:24,571 INFO:     Epoch: 62
2022-11-28 03:32:25,321 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42439356954260304, 'Total loss': 0.42439356954260304} | train loss {'Reaction outcome loss': 0.3004588951627093, 'Total loss': 0.3004588951627093}
2022-11-28 03:32:25,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:25,321 INFO:     Epoch: 63
2022-11-28 03:32:26,074 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43018350479277695, 'Total loss': 0.43018350479277695} | train loss {'Reaction outcome loss': 0.30533453077077866, 'Total loss': 0.30533453077077866}
2022-11-28 03:32:26,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:26,074 INFO:     Epoch: 64
2022-11-28 03:32:26,822 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4349160539832982, 'Total loss': 0.4349160539832982} | train loss {'Reaction outcome loss': 0.2874595112497768, 'Total loss': 0.2874595112497768}
2022-11-28 03:32:26,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:26,823 INFO:     Epoch: 65
2022-11-28 03:32:27,573 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4524589858271859, 'Total loss': 0.4524589858271859} | train loss {'Reaction outcome loss': 0.3008083893106349, 'Total loss': 0.3008083893106349}
2022-11-28 03:32:27,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:27,574 INFO:     Epoch: 66
2022-11-28 03:32:28,325 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4442479146475142, 'Total loss': 0.4442479146475142} | train loss {'Reaction outcome loss': 0.30345934389099, 'Total loss': 0.30345934389099}
2022-11-28 03:32:28,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:28,325 INFO:     Epoch: 67
2022-11-28 03:32:29,073 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4255031364207918, 'Total loss': 0.4255031364207918} | train loss {'Reaction outcome loss': 0.3015102504962875, 'Total loss': 0.3015102504962875}
2022-11-28 03:32:29,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:29,073 INFO:     Epoch: 68
2022-11-28 03:32:29,822 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4587436850098046, 'Total loss': 0.4587436850098046} | train loss {'Reaction outcome loss': 0.30812289529750425, 'Total loss': 0.30812289529750425}
2022-11-28 03:32:29,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:29,823 INFO:     Epoch: 69
2022-11-28 03:32:30,571 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46387995406985283, 'Total loss': 0.46387995406985283} | train loss {'Reaction outcome loss': 0.30238959197736076, 'Total loss': 0.30238959197736076}
2022-11-28 03:32:30,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:30,571 INFO:     Epoch: 70
2022-11-28 03:32:31,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44697058776562865, 'Total loss': 0.44697058776562865} | train loss {'Reaction outcome loss': 0.30373610733377354, 'Total loss': 0.30373610733377354}
2022-11-28 03:32:31,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:31,320 INFO:     Epoch: 71
2022-11-28 03:32:32,067 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45048037357628345, 'Total loss': 0.45048037357628345} | train loss {'Reaction outcome loss': 0.2984312562752635, 'Total loss': 0.2984312562752635}
2022-11-28 03:32:32,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:32,067 INFO:     Epoch: 72
2022-11-28 03:32:32,814 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4284007664431225, 'Total loss': 0.4284007664431225} | train loss {'Reaction outcome loss': 0.3062070143529244, 'Total loss': 0.3062070143529244}
2022-11-28 03:32:32,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:32,814 INFO:     Epoch: 73
2022-11-28 03:32:33,563 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4517922089858489, 'Total loss': 0.4517922089858489} | train loss {'Reaction outcome loss': 0.28973989152619917, 'Total loss': 0.28973989152619917}
2022-11-28 03:32:33,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:33,564 INFO:     Epoch: 74
2022-11-28 03:32:34,311 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42681932652538473, 'Total loss': 0.42681932652538473} | train loss {'Reaction outcome loss': 0.3009572729107834, 'Total loss': 0.3009572729107834}
2022-11-28 03:32:34,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:34,312 INFO:     Epoch: 75
2022-11-28 03:32:35,062 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44592052562670276, 'Total loss': 0.44592052562670276} | train loss {'Reaction outcome loss': 0.3009620812090655, 'Total loss': 0.3009620812090655}
2022-11-28 03:32:35,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:35,062 INFO:     Epoch: 76
2022-11-28 03:32:35,810 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41748848659071053, 'Total loss': 0.41748848659071053} | train loss {'Reaction outcome loss': 0.2962945648769458, 'Total loss': 0.2962945648769458}
2022-11-28 03:32:35,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:35,810 INFO:     Epoch: 77
2022-11-28 03:32:36,563 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4335231994363395, 'Total loss': 0.4335231994363395} | train loss {'Reaction outcome loss': 0.29322718005747567, 'Total loss': 0.29322718005747567}
2022-11-28 03:32:36,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:36,564 INFO:     Epoch: 78
2022-11-28 03:32:37,313 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4500920609994368, 'Total loss': 0.4500920609994368} | train loss {'Reaction outcome loss': 0.29925352279397266, 'Total loss': 0.29925352279397266}
2022-11-28 03:32:37,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:37,313 INFO:     Epoch: 79
2022-11-28 03:32:38,064 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4348045513033867, 'Total loss': 0.4348045513033867} | train loss {'Reaction outcome loss': 0.30204363675006934, 'Total loss': 0.30204363675006934}
2022-11-28 03:32:38,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:38,064 INFO:     Epoch: 80
2022-11-28 03:32:38,814 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4455075026913123, 'Total loss': 0.4455075026913123} | train loss {'Reaction outcome loss': 0.2956993416282198, 'Total loss': 0.2956993416282198}
2022-11-28 03:32:38,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:38,814 INFO:     Epoch: 81
2022-11-28 03:32:39,561 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46430643275380135, 'Total loss': 0.46430643275380135} | train loss {'Reaction outcome loss': 0.29965618084515294, 'Total loss': 0.29965618084515294}
2022-11-28 03:32:39,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:39,561 INFO:     Epoch: 82
2022-11-28 03:32:40,312 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4408360496163368, 'Total loss': 0.4408360496163368} | train loss {'Reaction outcome loss': 0.302528913478337, 'Total loss': 0.302528913478337}
2022-11-28 03:32:40,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:40,313 INFO:     Epoch: 83
2022-11-28 03:32:41,066 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47305113009431143, 'Total loss': 0.47305113009431143} | train loss {'Reaction outcome loss': 0.29686280321930686, 'Total loss': 0.29686280321930686}
2022-11-28 03:32:41,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:41,066 INFO:     Epoch: 84
2022-11-28 03:32:41,817 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4426009086045352, 'Total loss': 0.4426009086045352} | train loss {'Reaction outcome loss': 0.3012570909134323, 'Total loss': 0.3012570909134323}
2022-11-28 03:32:41,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:41,817 INFO:     Epoch: 85
2022-11-28 03:32:42,570 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45900752835653047, 'Total loss': 0.45900752835653047} | train loss {'Reaction outcome loss': 0.3014644532344274, 'Total loss': 0.3014644532344274}
2022-11-28 03:32:42,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:42,570 INFO:     Epoch: 86
2022-11-28 03:32:43,319 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4113837419585748, 'Total loss': 0.4113837419585748} | train loss {'Reaction outcome loss': 0.3000233947720018, 'Total loss': 0.3000233947720018}
2022-11-28 03:32:43,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:43,319 INFO:     Epoch: 87
2022-11-28 03:32:44,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4345976188778877, 'Total loss': 0.4345976188778877} | train loss {'Reaction outcome loss': 0.29810007080255496, 'Total loss': 0.29810007080255496}
2022-11-28 03:32:44,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:44,070 INFO:     Epoch: 88
2022-11-28 03:32:44,817 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4364254278215495, 'Total loss': 0.4364254278215495} | train loss {'Reaction outcome loss': 0.2979949061428347, 'Total loss': 0.2979949061428347}
2022-11-28 03:32:44,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:44,817 INFO:     Epoch: 89
2022-11-28 03:32:45,567 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43117670477791264, 'Total loss': 0.43117670477791264} | train loss {'Reaction outcome loss': 0.2946060039403458, 'Total loss': 0.2946060039403458}
2022-11-28 03:32:45,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:45,568 INFO:     Epoch: 90
2022-11-28 03:32:46,318 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43809166008775885, 'Total loss': 0.43809166008775885} | train loss {'Reaction outcome loss': 0.30070176053672065, 'Total loss': 0.30070176053672065}
2022-11-28 03:32:46,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:46,319 INFO:     Epoch: 91
2022-11-28 03:32:47,064 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4320308825170452, 'Total loss': 0.4320308825170452} | train loss {'Reaction outcome loss': 0.2897777005939955, 'Total loss': 0.2897777005939955}
2022-11-28 03:32:47,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:47,065 INFO:     Epoch: 92
2022-11-28 03:32:47,813 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4555696519938382, 'Total loss': 0.4555696519938382} | train loss {'Reaction outcome loss': 0.29029693706862386, 'Total loss': 0.29029693706862386}
2022-11-28 03:32:47,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:47,813 INFO:     Epoch: 93
2022-11-28 03:32:48,564 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47821789438074286, 'Total loss': 0.47821789438074286} | train loss {'Reaction outcome loss': 0.28420692408877996, 'Total loss': 0.28420692408877996}
2022-11-28 03:32:48,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:48,564 INFO:     Epoch: 94
2022-11-28 03:32:49,314 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41658147221261804, 'Total loss': 0.41658147221261804} | train loss {'Reaction outcome loss': 0.3028927660817581, 'Total loss': 0.3028927660817581}
2022-11-28 03:32:49,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:49,318 INFO:     Epoch: 95
2022-11-28 03:32:50,067 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40813014724037866, 'Total loss': 0.40813014724037866} | train loss {'Reaction outcome loss': 0.299054539837544, 'Total loss': 0.299054539837544}
2022-11-28 03:32:50,067 INFO:     Found new best model at epoch 95
2022-11-28 03:32:50,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:50,068 INFO:     Epoch: 96
2022-11-28 03:32:50,816 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4069355394352566, 'Total loss': 0.4069355394352566} | train loss {'Reaction outcome loss': 0.292340453654047, 'Total loss': 0.292340453654047}
2022-11-28 03:32:50,816 INFO:     Found new best model at epoch 96
2022-11-28 03:32:50,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:50,817 INFO:     Epoch: 97
2022-11-28 03:32:51,567 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4390889375724576, 'Total loss': 0.4390889375724576} | train loss {'Reaction outcome loss': 0.30407519405707717, 'Total loss': 0.30407519405707717}
2022-11-28 03:32:51,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:51,568 INFO:     Epoch: 98
2022-11-28 03:32:52,314 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4306434985588897, 'Total loss': 0.4306434985588897} | train loss {'Reaction outcome loss': 0.3017845347884201, 'Total loss': 0.3017845347884201}
2022-11-28 03:32:52,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:52,315 INFO:     Epoch: 99
2022-11-28 03:32:53,063 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4362021667713469, 'Total loss': 0.4362021667713469} | train loss {'Reaction outcome loss': 0.29097738510538496, 'Total loss': 0.29097738510538496}
2022-11-28 03:32:53,064 INFO:     Best model found after epoch 97 of 100.
2022-11-28 03:32:53,064 INFO:   Done with stage: TRAINING
2022-11-28 03:32:53,064 INFO:   Starting stage: EVALUATION
2022-11-28 03:32:53,179 INFO:   Done with stage: EVALUATION
2022-11-28 03:32:53,179 INFO:   Leaving out SEQ value Fold_8
2022-11-28 03:32:53,192 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:32:53,192 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:32:53,826 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:32:53,826 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:32:53,895 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:32:53,895 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:32:53,895 INFO:     No hyperparam tuning for this model
2022-11-28 03:32:53,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:32:53,895 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:32:53,896 INFO:     None feature selector for col prot
2022-11-28 03:32:53,896 INFO:     None feature selector for col prot
2022-11-28 03:32:53,896 INFO:     None feature selector for col prot
2022-11-28 03:32:53,897 INFO:     None feature selector for col chem
2022-11-28 03:32:53,897 INFO:     None feature selector for col chem
2022-11-28 03:32:53,897 INFO:     None feature selector for col chem
2022-11-28 03:32:53,897 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:32:53,897 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:32:53,898 INFO:     Number of params in model 169741
2022-11-28 03:32:53,901 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:32:53,901 INFO:   Starting stage: TRAINING
2022-11-28 03:32:53,955 INFO:     Val loss before train {'Reaction outcome loss': 1.062256164171479, 'Total loss': 1.062256164171479}
2022-11-28 03:32:53,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:53,955 INFO:     Epoch: 0
2022-11-28 03:32:54,703 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5413689887659117, 'Total loss': 0.5413689887659117} | train loss {'Reaction outcome loss': 0.6275414199481609, 'Total loss': 0.6275414199481609}
2022-11-28 03:32:54,703 INFO:     Found new best model at epoch 0
2022-11-28 03:32:54,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:54,704 INFO:     Epoch: 1
2022-11-28 03:32:55,450 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5144658217375929, 'Total loss': 0.5144658217375929} | train loss {'Reaction outcome loss': 0.4974397171726111, 'Total loss': 0.4974397171726111}
2022-11-28 03:32:55,450 INFO:     Found new best model at epoch 1
2022-11-28 03:32:55,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:55,451 INFO:     Epoch: 2
2022-11-28 03:32:56,200 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46598541702736507, 'Total loss': 0.46598541702736507} | train loss {'Reaction outcome loss': 0.47238470997042986, 'Total loss': 0.47238470997042986}
2022-11-28 03:32:56,200 INFO:     Found new best model at epoch 2
2022-11-28 03:32:56,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:56,201 INFO:     Epoch: 3
2022-11-28 03:32:56,947 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47418067333373154, 'Total loss': 0.47418067333373154} | train loss {'Reaction outcome loss': 0.44792148853965136, 'Total loss': 0.44792148853965136}
2022-11-28 03:32:56,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:56,947 INFO:     Epoch: 4
2022-11-28 03:32:57,697 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4286274581470273, 'Total loss': 0.4286274581470273} | train loss {'Reaction outcome loss': 0.42672095342203675, 'Total loss': 0.42672095342203675}
2022-11-28 03:32:57,697 INFO:     Found new best model at epoch 4
2022-11-28 03:32:57,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:57,698 INFO:     Epoch: 5
2022-11-28 03:32:58,445 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4668842987580733, 'Total loss': 0.4668842987580733} | train loss {'Reaction outcome loss': 0.4245596037732686, 'Total loss': 0.4245596037732686}
2022-11-28 03:32:58,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:58,446 INFO:     Epoch: 6
2022-11-28 03:32:59,197 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49513536115938966, 'Total loss': 0.49513536115938966} | train loss {'Reaction outcome loss': 0.4097252223293791, 'Total loss': 0.4097252223293791}
2022-11-28 03:32:59,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:59,197 INFO:     Epoch: 7
2022-11-28 03:32:59,943 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.458041021769697, 'Total loss': 0.458041021769697} | train loss {'Reaction outcome loss': 0.4066775594630584, 'Total loss': 0.4066775594630584}
2022-11-28 03:32:59,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:32:59,943 INFO:     Epoch: 8
2022-11-28 03:33:00,691 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4624174677512862, 'Total loss': 0.4624174677512862} | train loss {'Reaction outcome loss': 0.3935658573983652, 'Total loss': 0.3935658573983652}
2022-11-28 03:33:00,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:00,692 INFO:     Epoch: 9
2022-11-28 03:33:01,439 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44629308953881264, 'Total loss': 0.44629308953881264} | train loss {'Reaction outcome loss': 0.38752735635408986, 'Total loss': 0.38752735635408986}
2022-11-28 03:33:01,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:01,439 INFO:     Epoch: 10
2022-11-28 03:33:02,183 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4387804957276041, 'Total loss': 0.4387804957276041} | train loss {'Reaction outcome loss': 0.3776330593671755, 'Total loss': 0.3776330593671755}
2022-11-28 03:33:02,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:02,183 INFO:     Epoch: 11
2022-11-28 03:33:02,927 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44747483798048715, 'Total loss': 0.44747483798048715} | train loss {'Reaction outcome loss': 0.3667453490951766, 'Total loss': 0.3667453490951766}
2022-11-28 03:33:02,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:02,927 INFO:     Epoch: 12
2022-11-28 03:33:03,676 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43140907009894197, 'Total loss': 0.43140907009894197} | train loss {'Reaction outcome loss': 0.3749876797862864, 'Total loss': 0.3749876797862864}
2022-11-28 03:33:03,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:03,677 INFO:     Epoch: 13
2022-11-28 03:33:04,423 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44386714933948085, 'Total loss': 0.44386714933948085} | train loss {'Reaction outcome loss': 0.36908854816772557, 'Total loss': 0.36908854816772557}
2022-11-28 03:33:04,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:04,423 INFO:     Epoch: 14
2022-11-28 03:33:05,166 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4275006797503341, 'Total loss': 0.4275006797503341} | train loss {'Reaction outcome loss': 0.37097586646133107, 'Total loss': 0.37097586646133107}
2022-11-28 03:33:05,166 INFO:     Found new best model at epoch 14
2022-11-28 03:33:05,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:05,167 INFO:     Epoch: 15
2022-11-28 03:33:05,910 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4359201727942987, 'Total loss': 0.4359201727942987} | train loss {'Reaction outcome loss': 0.36375037113181974, 'Total loss': 0.36375037113181974}
2022-11-28 03:33:05,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:05,910 INFO:     Epoch: 16
2022-11-28 03:33:06,656 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39571330323815346, 'Total loss': 0.39571330323815346} | train loss {'Reaction outcome loss': 0.3695205145096972, 'Total loss': 0.3695205145096972}
2022-11-28 03:33:06,656 INFO:     Found new best model at epoch 16
2022-11-28 03:33:06,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:06,657 INFO:     Epoch: 17
2022-11-28 03:33:07,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41350419040430675, 'Total loss': 0.41350419040430675} | train loss {'Reaction outcome loss': 0.3704149010572356, 'Total loss': 0.3704149010572356}
2022-11-28 03:33:07,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:07,406 INFO:     Epoch: 18
2022-11-28 03:33:08,153 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45207157934253867, 'Total loss': 0.45207157934253867} | train loss {'Reaction outcome loss': 0.36495746500216997, 'Total loss': 0.36495746500216997}
2022-11-28 03:33:08,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:08,153 INFO:     Epoch: 19
2022-11-28 03:33:08,901 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40715503895824606, 'Total loss': 0.40715503895824606} | train loss {'Reaction outcome loss': 0.3537948389767635, 'Total loss': 0.3537948389767635}
2022-11-28 03:33:08,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:08,901 INFO:     Epoch: 20
2022-11-28 03:33:09,651 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.418532247570428, 'Total loss': 0.418532247570428} | train loss {'Reaction outcome loss': 0.3501135690537421, 'Total loss': 0.3501135690537421}
2022-11-28 03:33:09,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:09,651 INFO:     Epoch: 21
2022-11-28 03:33:10,399 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4745428287847476, 'Total loss': 0.4745428287847476} | train loss {'Reaction outcome loss': 0.3547123891682277, 'Total loss': 0.3547123891682277}
2022-11-28 03:33:10,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:10,399 INFO:     Epoch: 22
2022-11-28 03:33:11,149 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43917625092647294, 'Total loss': 0.43917625092647294} | train loss {'Reaction outcome loss': 0.35015959663671037, 'Total loss': 0.35015959663671037}
2022-11-28 03:33:11,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:11,150 INFO:     Epoch: 23
2022-11-28 03:33:11,898 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4385163790800355, 'Total loss': 0.4385163790800355} | train loss {'Reaction outcome loss': 0.3585262231317609, 'Total loss': 0.3585262231317609}
2022-11-28 03:33:11,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:11,898 INFO:     Epoch: 24
2022-11-28 03:33:12,646 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4316278990696777, 'Total loss': 0.4316278990696777} | train loss {'Reaction outcome loss': 0.3616173123179177, 'Total loss': 0.3616173123179177}
2022-11-28 03:33:12,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:12,646 INFO:     Epoch: 25
2022-11-28 03:33:13,393 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4532294032925909, 'Total loss': 0.4532294032925909} | train loss {'Reaction outcome loss': 0.394398545326009, 'Total loss': 0.394398545326009}
2022-11-28 03:33:13,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:13,394 INFO:     Epoch: 26
2022-11-28 03:33:14,141 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41451710157773713, 'Total loss': 0.41451710157773713} | train loss {'Reaction outcome loss': 0.34997662660564005, 'Total loss': 0.34997662660564005}
2022-11-28 03:33:14,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:14,142 INFO:     Epoch: 27
2022-11-28 03:33:14,891 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40816490148956125, 'Total loss': 0.40816490148956125} | train loss {'Reaction outcome loss': 0.3431357506677689, 'Total loss': 0.3431357506677689}
2022-11-28 03:33:14,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:14,891 INFO:     Epoch: 28
2022-11-28 03:33:15,643 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42397343255156145, 'Total loss': 0.42397343255156145} | train loss {'Reaction outcome loss': 0.3443068970552823, 'Total loss': 0.3443068970552823}
2022-11-28 03:33:15,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:15,643 INFO:     Epoch: 29
2022-11-28 03:33:16,395 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4131754145703532, 'Total loss': 0.4131754145703532} | train loss {'Reaction outcome loss': 0.3498537812102963, 'Total loss': 0.3498537812102963}
2022-11-28 03:33:16,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:16,395 INFO:     Epoch: 30
2022-11-28 03:33:17,145 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42925806292756036, 'Total loss': 0.42925806292756036} | train loss {'Reaction outcome loss': 0.32757741945837193, 'Total loss': 0.32757741945837193}
2022-11-28 03:33:17,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:17,145 INFO:     Epoch: 31
2022-11-28 03:33:17,899 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4338289611041546, 'Total loss': 0.4338289611041546} | train loss {'Reaction outcome loss': 0.3553553324660309, 'Total loss': 0.3553553324660309}
2022-11-28 03:33:17,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:17,900 INFO:     Epoch: 32
2022-11-28 03:33:18,649 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.427895552394065, 'Total loss': 0.427895552394065} | train loss {'Reaction outcome loss': 0.337714354520822, 'Total loss': 0.337714354520822}
2022-11-28 03:33:18,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:18,649 INFO:     Epoch: 33
2022-11-28 03:33:19,397 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3919000546024604, 'Total loss': 0.3919000546024604} | train loss {'Reaction outcome loss': 0.33397444995942144, 'Total loss': 0.33397444995942144}
2022-11-28 03:33:19,397 INFO:     Found new best model at epoch 33
2022-11-28 03:33:19,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:19,398 INFO:     Epoch: 34
2022-11-28 03:33:20,154 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4046244238587943, 'Total loss': 0.4046244238587943} | train loss {'Reaction outcome loss': 0.3250014559641058, 'Total loss': 0.3250014559641058}
2022-11-28 03:33:20,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:20,155 INFO:     Epoch: 35
2022-11-28 03:33:20,904 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43140682070092723, 'Total loss': 0.43140682070092723} | train loss {'Reaction outcome loss': 0.35034245831763694, 'Total loss': 0.35034245831763694}
2022-11-28 03:33:20,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:20,904 INFO:     Epoch: 36
2022-11-28 03:33:21,653 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4110977104441686, 'Total loss': 0.4110977104441686} | train loss {'Reaction outcome loss': 0.3557889737520623, 'Total loss': 0.3557889737520623}
2022-11-28 03:33:21,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:21,654 INFO:     Epoch: 37
2022-11-28 03:33:22,405 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4202121516520327, 'Total loss': 0.4202121516520327} | train loss {'Reaction outcome loss': 0.33832645509769077, 'Total loss': 0.33832645509769077}
2022-11-28 03:33:22,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:22,406 INFO:     Epoch: 38
2022-11-28 03:33:23,158 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46744710647247056, 'Total loss': 0.46744710647247056} | train loss {'Reaction outcome loss': 0.34103343593567487, 'Total loss': 0.34103343593567487}
2022-11-28 03:33:23,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:23,160 INFO:     Epoch: 39
2022-11-28 03:33:23,909 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38541025532917544, 'Total loss': 0.38541025532917544} | train loss {'Reaction outcome loss': 0.3414622810207353, 'Total loss': 0.3414622810207353}
2022-11-28 03:33:23,909 INFO:     Found new best model at epoch 39
2022-11-28 03:33:23,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:23,910 INFO:     Epoch: 40
2022-11-28 03:33:24,660 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4487453709271821, 'Total loss': 0.4487453709271821} | train loss {'Reaction outcome loss': 0.32715704177811683, 'Total loss': 0.32715704177811683}
2022-11-28 03:33:24,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:24,661 INFO:     Epoch: 41
2022-11-28 03:33:25,410 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41561365533958783, 'Total loss': 0.41561365533958783} | train loss {'Reaction outcome loss': 0.3312452448991991, 'Total loss': 0.3312452448991991}
2022-11-28 03:33:25,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:25,410 INFO:     Epoch: 42
2022-11-28 03:33:26,160 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41264151070605626, 'Total loss': 0.41264151070605626} | train loss {'Reaction outcome loss': 0.3300528676562041, 'Total loss': 0.3300528676562041}
2022-11-28 03:33:26,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:26,160 INFO:     Epoch: 43
2022-11-28 03:33:26,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42468620430339465, 'Total loss': 0.42468620430339465} | train loss {'Reaction outcome loss': 0.3328927691709175, 'Total loss': 0.3328927691709175}
2022-11-28 03:33:26,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:26,912 INFO:     Epoch: 44
2022-11-28 03:33:27,662 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.404223294082013, 'Total loss': 0.404223294082013} | train loss {'Reaction outcome loss': 0.33605615990726573, 'Total loss': 0.33605615990726573}
2022-11-28 03:33:27,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:27,662 INFO:     Epoch: 45
2022-11-28 03:33:28,411 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4070723063566468, 'Total loss': 0.4070723063566468} | train loss {'Reaction outcome loss': 0.32430639867821653, 'Total loss': 0.32430639867821653}
2022-11-28 03:33:28,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:28,411 INFO:     Epoch: 46
2022-11-28 03:33:29,159 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4207400506870313, 'Total loss': 0.4207400506870313} | train loss {'Reaction outcome loss': 0.3255615333163063, 'Total loss': 0.3255615333163063}
2022-11-28 03:33:29,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:29,160 INFO:     Epoch: 47
2022-11-28 03:33:29,908 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40052120065824554, 'Total loss': 0.40052120065824554} | train loss {'Reaction outcome loss': 0.31858997574822623, 'Total loss': 0.31858997574822623}
2022-11-28 03:33:29,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:29,909 INFO:     Epoch: 48
2022-11-28 03:33:30,657 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38946223800832575, 'Total loss': 0.38946223800832575} | train loss {'Reaction outcome loss': 0.3219035118686314, 'Total loss': 0.3219035118686314}
2022-11-28 03:33:30,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:30,657 INFO:     Epoch: 49
2022-11-28 03:33:31,408 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4085682491687211, 'Total loss': 0.4085682491687211} | train loss {'Reaction outcome loss': 0.3252846063953647, 'Total loss': 0.3252846063953647}
2022-11-28 03:33:31,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:31,408 INFO:     Epoch: 50
2022-11-28 03:33:32,158 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41832870939238503, 'Total loss': 0.41832870939238503} | train loss {'Reaction outcome loss': 0.3277068487792709, 'Total loss': 0.3277068487792709}
2022-11-28 03:33:32,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:32,158 INFO:     Epoch: 51
2022-11-28 03:33:32,911 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4031619280576706, 'Total loss': 0.4031619280576706} | train loss {'Reaction outcome loss': 0.328200423290674, 'Total loss': 0.328200423290674}
2022-11-28 03:33:32,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:32,911 INFO:     Epoch: 52
2022-11-28 03:33:33,660 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40702562711455603, 'Total loss': 0.40702562711455603} | train loss {'Reaction outcome loss': 0.3232507845952443, 'Total loss': 0.3232507845952443}
2022-11-28 03:33:33,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:33,661 INFO:     Epoch: 53
2022-11-28 03:33:34,411 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4235664287751371, 'Total loss': 0.4235664287751371} | train loss {'Reaction outcome loss': 0.3367976300146898, 'Total loss': 0.3367976300146898}
2022-11-28 03:33:34,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:34,411 INFO:     Epoch: 54
2022-11-28 03:33:35,162 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38423815403472295, 'Total loss': 0.38423815403472295} | train loss {'Reaction outcome loss': 0.32494351640343666, 'Total loss': 0.32494351640343666}
2022-11-28 03:33:35,163 INFO:     Found new best model at epoch 54
2022-11-28 03:33:35,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:35,163 INFO:     Epoch: 55
2022-11-28 03:33:35,914 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38507350432601845, 'Total loss': 0.38507350432601845} | train loss {'Reaction outcome loss': 0.32121613896960916, 'Total loss': 0.32121613896960916}
2022-11-28 03:33:35,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:35,914 INFO:     Epoch: 56
2022-11-28 03:33:36,662 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4343953352760185, 'Total loss': 0.4343953352760185} | train loss {'Reaction outcome loss': 0.32172359263728023, 'Total loss': 0.32172359263728023}
2022-11-28 03:33:36,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:36,662 INFO:     Epoch: 57
2022-11-28 03:33:37,410 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42712209475311363, 'Total loss': 0.42712209475311363} | train loss {'Reaction outcome loss': 0.33180560075078414, 'Total loss': 0.33180560075078414}
2022-11-28 03:33:37,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:37,410 INFO:     Epoch: 58
2022-11-28 03:33:38,157 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4340333796360276, 'Total loss': 0.4340333796360276} | train loss {'Reaction outcome loss': 0.3268637487189731, 'Total loss': 0.3268637487189731}
2022-11-28 03:33:38,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:38,157 INFO:     Epoch: 59
2022-11-28 03:33:38,906 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42651763422922656, 'Total loss': 0.42651763422922656} | train loss {'Reaction outcome loss': 0.3317769798431319, 'Total loss': 0.3317769798431319}
2022-11-28 03:33:38,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:38,906 INFO:     Epoch: 60
2022-11-28 03:33:39,656 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4040630104189569, 'Total loss': 0.4040630104189569} | train loss {'Reaction outcome loss': 0.3227934047640094, 'Total loss': 0.3227934047640094}
2022-11-28 03:33:39,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:39,656 INFO:     Epoch: 61
2022-11-28 03:33:40,407 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4164899570698088, 'Total loss': 0.4164899570698088} | train loss {'Reaction outcome loss': 0.3369099793103542, 'Total loss': 0.3369099793103542}
2022-11-28 03:33:40,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:40,407 INFO:     Epoch: 62
2022-11-28 03:33:41,162 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46143719960342755, 'Total loss': 0.46143719960342755} | train loss {'Reaction outcome loss': 0.3456988381108774, 'Total loss': 0.3456988381108774}
2022-11-28 03:33:41,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:41,162 INFO:     Epoch: 63
2022-11-28 03:33:41,912 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38911219889467413, 'Total loss': 0.38911219889467413} | train loss {'Reaction outcome loss': 0.32724538756542, 'Total loss': 0.32724538756542}
2022-11-28 03:33:41,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:41,912 INFO:     Epoch: 64
2022-11-28 03:33:42,662 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4233280758966099, 'Total loss': 0.4233280758966099} | train loss {'Reaction outcome loss': 0.3229568604726782, 'Total loss': 0.3229568604726782}
2022-11-28 03:33:42,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:42,662 INFO:     Epoch: 65
2022-11-28 03:33:43,412 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39714536036957393, 'Total loss': 0.39714536036957393} | train loss {'Reaction outcome loss': 0.32341008594161585, 'Total loss': 0.32341008594161585}
2022-11-28 03:33:43,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:43,412 INFO:     Epoch: 66
2022-11-28 03:33:44,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4157992096787149, 'Total loss': 0.4157992096787149} | train loss {'Reaction outcome loss': 0.31980417566260827, 'Total loss': 0.31980417566260827}
2022-11-28 03:33:44,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:44,160 INFO:     Epoch: 67
2022-11-28 03:33:44,910 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43505320156162436, 'Total loss': 0.43505320156162436} | train loss {'Reaction outcome loss': 0.3260608849788239, 'Total loss': 0.3260608849788239}
2022-11-28 03:33:44,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:44,910 INFO:     Epoch: 68
2022-11-28 03:33:45,659 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48993451486934314, 'Total loss': 0.48993451486934314} | train loss {'Reaction outcome loss': 0.3232663092523934, 'Total loss': 0.3232663092523934}
2022-11-28 03:33:45,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:45,660 INFO:     Epoch: 69
2022-11-28 03:33:46,402 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41678047823635017, 'Total loss': 0.41678047823635017} | train loss {'Reaction outcome loss': 0.35188556302655566, 'Total loss': 0.35188556302655566}
2022-11-28 03:33:46,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:46,402 INFO:     Epoch: 70
2022-11-28 03:33:47,145 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4082911539484154, 'Total loss': 0.4082911539484154} | train loss {'Reaction outcome loss': 0.3266403335731039, 'Total loss': 0.3266403335731039}
2022-11-28 03:33:47,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:47,145 INFO:     Epoch: 71
2022-11-28 03:33:47,887 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4138418879698623, 'Total loss': 0.4138418879698623} | train loss {'Reaction outcome loss': 0.3174325542784624, 'Total loss': 0.3174325542784624}
2022-11-28 03:33:47,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:47,887 INFO:     Epoch: 72
2022-11-28 03:33:48,630 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4018459066071294, 'Total loss': 0.4018459066071294} | train loss {'Reaction outcome loss': 0.320229914872662, 'Total loss': 0.320229914872662}
2022-11-28 03:33:48,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:48,630 INFO:     Epoch: 73
2022-11-28 03:33:49,376 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3930922428315336, 'Total loss': 0.3930922428315336} | train loss {'Reaction outcome loss': 0.3077101805523087, 'Total loss': 0.3077101805523087}
2022-11-28 03:33:49,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:49,376 INFO:     Epoch: 74
2022-11-28 03:33:50,117 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41888404976237903, 'Total loss': 0.41888404976237903} | train loss {'Reaction outcome loss': 0.31920628985654004, 'Total loss': 0.31920628985654004}
2022-11-28 03:33:50,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:50,117 INFO:     Epoch: 75
2022-11-28 03:33:50,859 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3946491236036474, 'Total loss': 0.3946491236036474} | train loss {'Reaction outcome loss': 0.31593800799992794, 'Total loss': 0.31593800799992794}
2022-11-28 03:33:50,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:50,860 INFO:     Epoch: 76
2022-11-28 03:33:51,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41717118126424874, 'Total loss': 0.41717118126424874} | train loss {'Reaction outcome loss': 0.30592268373937864, 'Total loss': 0.30592268373937864}
2022-11-28 03:33:51,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:51,603 INFO:     Epoch: 77
2022-11-28 03:33:52,350 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4369684071703391, 'Total loss': 0.4369684071703391} | train loss {'Reaction outcome loss': 0.33065320669036163, 'Total loss': 0.33065320669036163}
2022-11-28 03:33:52,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:52,350 INFO:     Epoch: 78
2022-11-28 03:33:53,095 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4077414448627017, 'Total loss': 0.4077414448627017} | train loss {'Reaction outcome loss': 0.3308830071798703, 'Total loss': 0.3308830071798703}
2022-11-28 03:33:53,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:53,095 INFO:     Epoch: 79
2022-11-28 03:33:53,839 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44040239805525, 'Total loss': 0.44040239805525} | train loss {'Reaction outcome loss': 0.3278963114040704, 'Total loss': 0.3278963114040704}
2022-11-28 03:33:53,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:53,839 INFO:     Epoch: 80
2022-11-28 03:33:54,586 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3883636031638492, 'Total loss': 0.3883636031638492} | train loss {'Reaction outcome loss': 0.3215365402310001, 'Total loss': 0.3215365402310001}
2022-11-28 03:33:54,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:54,587 INFO:     Epoch: 81
2022-11-28 03:33:55,335 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3962774788114158, 'Total loss': 0.3962774788114158} | train loss {'Reaction outcome loss': 0.32415516606301326, 'Total loss': 0.32415516606301326}
2022-11-28 03:33:55,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:55,335 INFO:     Epoch: 82
2022-11-28 03:33:56,081 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4072066227143461, 'Total loss': 0.4072066227143461} | train loss {'Reaction outcome loss': 0.3141473377974674, 'Total loss': 0.3141473377974674}
2022-11-28 03:33:56,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:56,081 INFO:     Epoch: 83
2022-11-28 03:33:56,827 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4052512530576099, 'Total loss': 0.4052512530576099} | train loss {'Reaction outcome loss': 0.3162345890755113, 'Total loss': 0.3162345890755113}
2022-11-28 03:33:56,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:56,827 INFO:     Epoch: 84
2022-11-28 03:33:57,570 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42705695805224503, 'Total loss': 0.42705695805224503} | train loss {'Reaction outcome loss': 0.32488897192454047, 'Total loss': 0.32488897192454047}
2022-11-28 03:33:57,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:57,570 INFO:     Epoch: 85
2022-11-28 03:33:58,317 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4108774790709669, 'Total loss': 0.4108774790709669} | train loss {'Reaction outcome loss': 0.30744137082094336, 'Total loss': 0.30744137082094336}
2022-11-28 03:33:58,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:58,317 INFO:     Epoch: 86
2022-11-28 03:33:59,062 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4187057643112811, 'Total loss': 0.4187057643112811} | train loss {'Reaction outcome loss': 0.3160891303800137, 'Total loss': 0.3160891303800137}
2022-11-28 03:33:59,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:59,062 INFO:     Epoch: 87
2022-11-28 03:33:59,808 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3931966722011566, 'Total loss': 0.3931966722011566} | train loss {'Reaction outcome loss': 0.31197101903347835, 'Total loss': 0.31197101903347835}
2022-11-28 03:33:59,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:33:59,809 INFO:     Epoch: 88
2022-11-28 03:34:00,552 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4109971262514591, 'Total loss': 0.4109971262514591} | train loss {'Reaction outcome loss': 0.3148114649571388, 'Total loss': 0.3148114649571388}
2022-11-28 03:34:00,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:00,552 INFO:     Epoch: 89
2022-11-28 03:34:01,296 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39676777544346725, 'Total loss': 0.39676777544346725} | train loss {'Reaction outcome loss': 0.3275042895061767, 'Total loss': 0.3275042895061767}
2022-11-28 03:34:01,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:01,297 INFO:     Epoch: 90
2022-11-28 03:34:02,039 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4370433874428272, 'Total loss': 0.4370433874428272} | train loss {'Reaction outcome loss': 0.30991214411220086, 'Total loss': 0.30991214411220086}
2022-11-28 03:34:02,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:02,039 INFO:     Epoch: 91
2022-11-28 03:34:02,789 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39117247103290126, 'Total loss': 0.39117247103290126} | train loss {'Reaction outcome loss': 0.3123501639979088, 'Total loss': 0.3123501639979088}
2022-11-28 03:34:02,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:02,790 INFO:     Epoch: 92
2022-11-28 03:34:03,530 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40988493422892963, 'Total loss': 0.40988493422892963} | train loss {'Reaction outcome loss': 0.30614004245683973, 'Total loss': 0.30614004245683973}
2022-11-28 03:34:03,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:03,530 INFO:     Epoch: 93
2022-11-28 03:34:04,276 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3995651717890393, 'Total loss': 0.3995651717890393} | train loss {'Reaction outcome loss': 0.3223559700616217, 'Total loss': 0.3223559700616217}
2022-11-28 03:34:04,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:04,276 INFO:     Epoch: 94
2022-11-28 03:34:05,024 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44372087209062144, 'Total loss': 0.44372087209062144} | train loss {'Reaction outcome loss': 0.30989587430649923, 'Total loss': 0.30989587430649923}
2022-11-28 03:34:05,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:05,024 INFO:     Epoch: 95
2022-11-28 03:34:05,770 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40652860972014343, 'Total loss': 0.40652860972014343} | train loss {'Reaction outcome loss': 0.3063235554074952, 'Total loss': 0.3063235554074952}
2022-11-28 03:34:05,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:05,771 INFO:     Epoch: 96
2022-11-28 03:34:06,516 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4050739204341715, 'Total loss': 0.4050739204341715} | train loss {'Reaction outcome loss': 0.3148981744069078, 'Total loss': 0.3148981744069078}
2022-11-28 03:34:06,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:06,516 INFO:     Epoch: 97
2022-11-28 03:34:07,261 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4201330346139995, 'Total loss': 0.4201330346139995} | train loss {'Reaction outcome loss': 0.3545091703896098, 'Total loss': 0.3545091703896098}
2022-11-28 03:34:07,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:07,261 INFO:     Epoch: 98
2022-11-28 03:34:08,008 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4084667062217539, 'Total loss': 0.4084667062217539} | train loss {'Reaction outcome loss': 0.3144502074517562, 'Total loss': 0.3144502074517562}
2022-11-28 03:34:08,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:08,008 INFO:     Epoch: 99
2022-11-28 03:34:08,756 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4007641100748019, 'Total loss': 0.4007641100748019} | train loss {'Reaction outcome loss': 0.31492547155849837, 'Total loss': 0.31492547155849837}
2022-11-28 03:34:08,757 INFO:     Best model found after epoch 55 of 100.
2022-11-28 03:34:08,757 INFO:   Done with stage: TRAINING
2022-11-28 03:34:08,757 INFO:   Starting stage: EVALUATION
2022-11-28 03:34:08,879 INFO:   Done with stage: EVALUATION
2022-11-28 03:34:08,879 INFO:   Leaving out SEQ value Fold_9
2022-11-28 03:34:08,892 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:34:08,892 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:34:09,533 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:34:09,533 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:34:09,602 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:34:09,602 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:34:09,602 INFO:     No hyperparam tuning for this model
2022-11-28 03:34:09,602 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:34:09,602 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:34:09,603 INFO:     None feature selector for col prot
2022-11-28 03:34:09,603 INFO:     None feature selector for col prot
2022-11-28 03:34:09,603 INFO:     None feature selector for col prot
2022-11-28 03:34:09,604 INFO:     None feature selector for col chem
2022-11-28 03:34:09,604 INFO:     None feature selector for col chem
2022-11-28 03:34:09,604 INFO:     None feature selector for col chem
2022-11-28 03:34:09,604 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:34:09,604 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:34:09,606 INFO:     Number of params in model 169741
2022-11-28 03:34:09,609 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:34:09,609 INFO:   Starting stage: TRAINING
2022-11-28 03:34:09,663 INFO:     Val loss before train {'Reaction outcome loss': 0.99765744805336, 'Total loss': 0.99765744805336}
2022-11-28 03:34:09,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:09,664 INFO:     Epoch: 0
2022-11-28 03:34:10,415 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5310257591984489, 'Total loss': 0.5310257591984489} | train loss {'Reaction outcome loss': 0.6404364355389149, 'Total loss': 0.6404364355389149}
2022-11-28 03:34:10,415 INFO:     Found new best model at epoch 0
2022-11-28 03:34:10,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:10,416 INFO:     Epoch: 1
2022-11-28 03:34:11,165 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5150113356384364, 'Total loss': 0.5150113356384364} | train loss {'Reaction outcome loss': 0.5123977295213169, 'Total loss': 0.5123977295213169}
2022-11-28 03:34:11,165 INFO:     Found new best model at epoch 1
2022-11-28 03:34:11,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:11,166 INFO:     Epoch: 2
2022-11-28 03:34:11,917 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47961873798207805, 'Total loss': 0.47961873798207805} | train loss {'Reaction outcome loss': 0.4711694272775804, 'Total loss': 0.4711694272775804}
2022-11-28 03:34:11,917 INFO:     Found new best model at epoch 2
2022-11-28 03:34:11,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:11,918 INFO:     Epoch: 3
2022-11-28 03:34:12,668 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.481146903200583, 'Total loss': 0.481146903200583} | train loss {'Reaction outcome loss': 0.45407541240415267, 'Total loss': 0.45407541240415267}
2022-11-28 03:34:12,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:12,668 INFO:     Epoch: 4
2022-11-28 03:34:13,416 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4800941056825898, 'Total loss': 0.4800941056825898} | train loss {'Reaction outcome loss': 0.4368697041345219, 'Total loss': 0.4368697041345219}
2022-11-28 03:34:13,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:13,417 INFO:     Epoch: 5
2022-11-28 03:34:14,166 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.450818518684669, 'Total loss': 0.450818518684669} | train loss {'Reaction outcome loss': 0.42487202470581376, 'Total loss': 0.42487202470581376}
2022-11-28 03:34:14,167 INFO:     Found new best model at epoch 5
2022-11-28 03:34:14,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:14,167 INFO:     Epoch: 6
2022-11-28 03:34:14,918 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45123751122843136, 'Total loss': 0.45123751122843136} | train loss {'Reaction outcome loss': 0.40480322817400577, 'Total loss': 0.40480322817400577}
2022-11-28 03:34:14,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:14,918 INFO:     Epoch: 7
2022-11-28 03:34:15,666 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46062459965998476, 'Total loss': 0.46062459965998476} | train loss {'Reaction outcome loss': 0.4091527118918396, 'Total loss': 0.4091527118918396}
2022-11-28 03:34:15,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:15,666 INFO:     Epoch: 8
2022-11-28 03:34:16,418 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4372544302181764, 'Total loss': 0.4372544302181764} | train loss {'Reaction outcome loss': 0.3967770696767876, 'Total loss': 0.3967770696767876}
2022-11-28 03:34:16,418 INFO:     Found new best model at epoch 8
2022-11-28 03:34:16,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:16,419 INFO:     Epoch: 9
2022-11-28 03:34:17,166 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4439779235558076, 'Total loss': 0.4439779235558076} | train loss {'Reaction outcome loss': 0.38939589147846543, 'Total loss': 0.38939589147846543}
2022-11-28 03:34:17,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:17,166 INFO:     Epoch: 10
2022-11-28 03:34:17,914 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47572679445147514, 'Total loss': 0.47572679445147514} | train loss {'Reaction outcome loss': 0.3843021701961275, 'Total loss': 0.3843021701961275}
2022-11-28 03:34:17,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:17,914 INFO:     Epoch: 11
2022-11-28 03:34:18,663 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4425250992856242, 'Total loss': 0.4425250992856242} | train loss {'Reaction outcome loss': 0.3789960518779774, 'Total loss': 0.3789960518779774}
2022-11-28 03:34:18,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:18,663 INFO:     Epoch: 12
2022-11-28 03:34:19,409 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46528238633816893, 'Total loss': 0.46528238633816893} | train loss {'Reaction outcome loss': 0.37859719360788024, 'Total loss': 0.37859719360788024}
2022-11-28 03:34:19,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:19,409 INFO:     Epoch: 13
2022-11-28 03:34:20,159 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48437753455205396, 'Total loss': 0.48437753455205396} | train loss {'Reaction outcome loss': 0.3720391649272173, 'Total loss': 0.3720391649272173}
2022-11-28 03:34:20,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:20,159 INFO:     Epoch: 14
2022-11-28 03:34:20,908 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4513259946622632, 'Total loss': 0.4513259946622632} | train loss {'Reaction outcome loss': 0.363534712262692, 'Total loss': 0.363534712262692}
2022-11-28 03:34:20,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:20,909 INFO:     Epoch: 15
2022-11-28 03:34:21,660 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4522892974994399, 'Total loss': 0.4522892974994399} | train loss {'Reaction outcome loss': 0.35964134922100893, 'Total loss': 0.35964134922100893}
2022-11-28 03:34:21,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:21,660 INFO:     Epoch: 16
2022-11-28 03:34:22,409 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4507797671989961, 'Total loss': 0.4507797671989961} | train loss {'Reaction outcome loss': 0.35878936958409124, 'Total loss': 0.35878936958409124}
2022-11-28 03:34:22,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:22,409 INFO:     Epoch: 17
2022-11-28 03:34:23,158 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4671408137814565, 'Total loss': 0.4671408137814565} | train loss {'Reaction outcome loss': 0.35595754607610647, 'Total loss': 0.35595754607610647}
2022-11-28 03:34:23,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:23,159 INFO:     Epoch: 18
2022-11-28 03:34:23,911 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4493934034623883, 'Total loss': 0.4493934034623883} | train loss {'Reaction outcome loss': 0.3569893254147422, 'Total loss': 0.3569893254147422}
2022-11-28 03:34:23,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:23,911 INFO:     Epoch: 19
2022-11-28 03:34:24,659 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4978779608553106, 'Total loss': 0.4978779608553106} | train loss {'Reaction outcome loss': 0.3493277610189492, 'Total loss': 0.3493277610189492}
2022-11-28 03:34:24,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:24,660 INFO:     Epoch: 20
2022-11-28 03:34:25,409 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4412918060340665, 'Total loss': 0.4412918060340665} | train loss {'Reaction outcome loss': 0.3594367872142503, 'Total loss': 0.3594367872142503}
2022-11-28 03:34:25,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:25,411 INFO:     Epoch: 21
2022-11-28 03:34:26,163 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4449582099914551, 'Total loss': 0.4449582099914551} | train loss {'Reaction outcome loss': 0.35506453103716334, 'Total loss': 0.35506453103716334}
2022-11-28 03:34:26,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:26,163 INFO:     Epoch: 22
2022-11-28 03:34:26,914 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45418251576748764, 'Total loss': 0.45418251576748764} | train loss {'Reaction outcome loss': 0.3439363183814191, 'Total loss': 0.3439363183814191}
2022-11-28 03:34:26,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:26,914 INFO:     Epoch: 23
2022-11-28 03:34:27,663 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46102891252799466, 'Total loss': 0.46102891252799466} | train loss {'Reaction outcome loss': 0.34274442695201407, 'Total loss': 0.34274442695201407}
2022-11-28 03:34:27,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:27,663 INFO:     Epoch: 24
2022-11-28 03:34:28,413 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4591707776893269, 'Total loss': 0.4591707776893269} | train loss {'Reaction outcome loss': 0.35382910138897355, 'Total loss': 0.35382910138897355}
2022-11-28 03:34:28,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:28,413 INFO:     Epoch: 25
2022-11-28 03:34:29,162 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4744462045756253, 'Total loss': 0.4744462045756253} | train loss {'Reaction outcome loss': 0.34390448619641606, 'Total loss': 0.34390448619641606}
2022-11-28 03:34:29,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:29,163 INFO:     Epoch: 26
2022-11-28 03:34:29,913 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42713064226237213, 'Total loss': 0.42713064226237213} | train loss {'Reaction outcome loss': 0.3449829425963183, 'Total loss': 0.3449829425963183}
2022-11-28 03:34:29,913 INFO:     Found new best model at epoch 26
2022-11-28 03:34:29,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:29,914 INFO:     Epoch: 27
2022-11-28 03:34:30,664 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4450812722471627, 'Total loss': 0.4450812722471627} | train loss {'Reaction outcome loss': 0.3471001955650507, 'Total loss': 0.3471001955650507}
2022-11-28 03:34:30,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:30,664 INFO:     Epoch: 28
2022-11-28 03:34:31,413 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43351751125671645, 'Total loss': 0.43351751125671645} | train loss {'Reaction outcome loss': 0.3408102098431799, 'Total loss': 0.3408102098431799}
2022-11-28 03:34:31,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:31,414 INFO:     Epoch: 29
2022-11-28 03:34:32,166 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4384637698531151, 'Total loss': 0.4384637698531151} | train loss {'Reaction outcome loss': 0.3373223432610112, 'Total loss': 0.3373223432610112}
2022-11-28 03:34:32,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:32,166 INFO:     Epoch: 30
2022-11-28 03:34:32,913 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44068392433903436, 'Total loss': 0.44068392433903436} | train loss {'Reaction outcome loss': 0.338313894646783, 'Total loss': 0.338313894646783}
2022-11-28 03:34:32,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:32,914 INFO:     Epoch: 31
2022-11-28 03:34:33,661 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4558990736576644, 'Total loss': 0.4558990736576644} | train loss {'Reaction outcome loss': 0.33401428433435576, 'Total loss': 0.33401428433435576}
2022-11-28 03:34:33,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:33,661 INFO:     Epoch: 32
2022-11-28 03:34:34,411 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4446765155616132, 'Total loss': 0.4446765155616132} | train loss {'Reaction outcome loss': 0.35118729954645517, 'Total loss': 0.35118729954645517}
2022-11-28 03:34:34,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:34,411 INFO:     Epoch: 33
2022-11-28 03:34:35,161 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4618537253276868, 'Total loss': 0.4618537253276868} | train loss {'Reaction outcome loss': 0.34797930996865034, 'Total loss': 0.34797930996865034}
2022-11-28 03:34:35,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:35,161 INFO:     Epoch: 34
2022-11-28 03:34:35,908 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4403884759680791, 'Total loss': 0.4403884759680791} | train loss {'Reaction outcome loss': 0.33862329681494063, 'Total loss': 0.33862329681494063}
2022-11-28 03:34:35,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:35,908 INFO:     Epoch: 35
2022-11-28 03:34:36,655 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4430599994957447, 'Total loss': 0.4430599994957447} | train loss {'Reaction outcome loss': 0.3358465344194443, 'Total loss': 0.3358465344194443}
2022-11-28 03:34:36,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:36,656 INFO:     Epoch: 36
2022-11-28 03:34:37,405 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4503538479859179, 'Total loss': 0.4503538479859179} | train loss {'Reaction outcome loss': 0.33386075947313537, 'Total loss': 0.33386075947313537}
2022-11-28 03:34:37,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:37,405 INFO:     Epoch: 37
2022-11-28 03:34:38,150 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43777820078486746, 'Total loss': 0.43777820078486746} | train loss {'Reaction outcome loss': 0.3401266092494611, 'Total loss': 0.3401266092494611}
2022-11-28 03:34:38,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:38,151 INFO:     Epoch: 38
2022-11-28 03:34:38,896 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4640272002328526, 'Total loss': 0.4640272002328526} | train loss {'Reaction outcome loss': 0.33277148918639265, 'Total loss': 0.33277148918639265}
2022-11-28 03:34:38,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:38,897 INFO:     Epoch: 39
2022-11-28 03:34:39,644 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44798988036134024, 'Total loss': 0.44798988036134024} | train loss {'Reaction outcome loss': 0.33140927414980625, 'Total loss': 0.33140927414980625}
2022-11-28 03:34:39,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:39,644 INFO:     Epoch: 40
2022-11-28 03:34:40,394 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4309342649172653, 'Total loss': 0.4309342649172653} | train loss {'Reaction outcome loss': 0.3216937317573015, 'Total loss': 0.3216937317573015}
2022-11-28 03:34:40,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:40,394 INFO:     Epoch: 41
2022-11-28 03:34:41,141 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43139434131709015, 'Total loss': 0.43139434131709015} | train loss {'Reaction outcome loss': 0.3269161890230833, 'Total loss': 0.3269161890230833}
2022-11-28 03:34:41,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:41,142 INFO:     Epoch: 42
2022-11-28 03:34:41,887 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43566702848131006, 'Total loss': 0.43566702848131006} | train loss {'Reaction outcome loss': 0.3332285351089893, 'Total loss': 0.3332285351089893}
2022-11-28 03:34:41,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:41,887 INFO:     Epoch: 43
2022-11-28 03:34:42,633 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4469903443347324, 'Total loss': 0.4469903443347324} | train loss {'Reaction outcome loss': 0.32693117072865846, 'Total loss': 0.32693117072865846}
2022-11-28 03:34:42,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:42,633 INFO:     Epoch: 44
2022-11-28 03:34:43,381 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45073270120403985, 'Total loss': 0.45073270120403985} | train loss {'Reaction outcome loss': 0.32765424942537663, 'Total loss': 0.32765424942537663}
2022-11-28 03:34:43,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:43,382 INFO:     Epoch: 45
2022-11-28 03:34:44,129 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4260901293971322, 'Total loss': 0.4260901293971322} | train loss {'Reaction outcome loss': 0.3284394686981555, 'Total loss': 0.3284394686981555}
2022-11-28 03:34:44,130 INFO:     Found new best model at epoch 45
2022-11-28 03:34:44,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:44,131 INFO:     Epoch: 46
2022-11-28 03:34:44,878 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4302808122540062, 'Total loss': 0.4302808122540062} | train loss {'Reaction outcome loss': 0.3178193380815848, 'Total loss': 0.3178193380815848}
2022-11-28 03:34:44,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:44,878 INFO:     Epoch: 47
2022-11-28 03:34:45,624 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4720753905448047, 'Total loss': 0.4720753905448047} | train loss {'Reaction outcome loss': 0.33163681295850583, 'Total loss': 0.33163681295850583}
2022-11-28 03:34:45,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:45,624 INFO:     Epoch: 48
2022-11-28 03:34:46,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45158255709843204, 'Total loss': 0.45158255709843204} | train loss {'Reaction outcome loss': 0.33186353100163324, 'Total loss': 0.33186353100163324}
2022-11-28 03:34:46,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:46,376 INFO:     Epoch: 49
2022-11-28 03:34:47,123 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44067757712169126, 'Total loss': 0.44067757712169126} | train loss {'Reaction outcome loss': 0.3291804699767982, 'Total loss': 0.3291804699767982}
2022-11-28 03:34:47,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:47,123 INFO:     Epoch: 50
2022-11-28 03:34:47,871 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4636670628731901, 'Total loss': 0.4636670628731901} | train loss {'Reaction outcome loss': 0.32234112329540715, 'Total loss': 0.32234112329540715}
2022-11-28 03:34:47,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:47,871 INFO:     Epoch: 51
2022-11-28 03:34:48,616 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45594339817762375, 'Total loss': 0.45594339817762375} | train loss {'Reaction outcome loss': 0.3242588494003059, 'Total loss': 0.3242588494003059}
2022-11-28 03:34:48,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:48,617 INFO:     Epoch: 52
2022-11-28 03:34:49,365 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43229911815036426, 'Total loss': 0.43229911815036426} | train loss {'Reaction outcome loss': 0.3195771967331248, 'Total loss': 0.3195771967331248}
2022-11-28 03:34:49,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:49,365 INFO:     Epoch: 53
2022-11-28 03:34:50,114 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4403912926262075, 'Total loss': 0.4403912926262075} | train loss {'Reaction outcome loss': 0.3320107793645753, 'Total loss': 0.3320107793645753}
2022-11-28 03:34:50,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:50,114 INFO:     Epoch: 54
2022-11-28 03:34:50,863 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4331720359623432, 'Total loss': 0.4331720359623432} | train loss {'Reaction outcome loss': 0.315281824659436, 'Total loss': 0.315281824659436}
2022-11-28 03:34:50,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:50,863 INFO:     Epoch: 55
2022-11-28 03:34:51,617 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4384010901505297, 'Total loss': 0.4384010901505297} | train loss {'Reaction outcome loss': 0.3284237729685922, 'Total loss': 0.3284237729685922}
2022-11-28 03:34:51,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:51,617 INFO:     Epoch: 56
2022-11-28 03:34:52,362 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43160493367097597, 'Total loss': 0.43160493367097597} | train loss {'Reaction outcome loss': 0.31740124586729274, 'Total loss': 0.31740124586729274}
2022-11-28 03:34:52,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:52,362 INFO:     Epoch: 57
2022-11-28 03:34:53,109 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4988549026575955, 'Total loss': 0.4988549026575955} | train loss {'Reaction outcome loss': 0.3256488952845816, 'Total loss': 0.3256488952845816}
2022-11-28 03:34:53,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:53,110 INFO:     Epoch: 58
2022-11-28 03:34:53,857 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4618827284059741, 'Total loss': 0.4618827284059741} | train loss {'Reaction outcome loss': 0.32704267913715973, 'Total loss': 0.32704267913715973}
2022-11-28 03:34:53,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:53,858 INFO:     Epoch: 59
2022-11-28 03:34:54,603 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4379091913049871, 'Total loss': 0.4379091913049871} | train loss {'Reaction outcome loss': 0.3239907842850493, 'Total loss': 0.3239907842850493}
2022-11-28 03:34:54,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:54,603 INFO:     Epoch: 60
2022-11-28 03:34:55,349 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4390104196288369, 'Total loss': 0.4390104196288369} | train loss {'Reaction outcome loss': 0.3233104143892565, 'Total loss': 0.3233104143892565}
2022-11-28 03:34:55,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:55,350 INFO:     Epoch: 61
2022-11-28 03:34:56,102 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4578631327233531, 'Total loss': 0.4578631327233531} | train loss {'Reaction outcome loss': 0.31090543064619264, 'Total loss': 0.31090543064619264}
2022-11-28 03:34:56,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:56,102 INFO:     Epoch: 62
2022-11-28 03:34:56,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.437056090682745, 'Total loss': 0.437056090682745} | train loss {'Reaction outcome loss': 0.3203103597305955, 'Total loss': 0.3203103597305955}
2022-11-28 03:34:56,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:56,857 INFO:     Epoch: 63
2022-11-28 03:34:57,604 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4157685774632476, 'Total loss': 0.4157685774632476} | train loss {'Reaction outcome loss': 0.3164470623878221, 'Total loss': 0.3164470623878221}
2022-11-28 03:34:57,604 INFO:     Found new best model at epoch 63
2022-11-28 03:34:57,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:57,604 INFO:     Epoch: 64
2022-11-28 03:34:58,353 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43150495805523614, 'Total loss': 0.43150495805523614} | train loss {'Reaction outcome loss': 0.31612863653008977, 'Total loss': 0.31612863653008977}
2022-11-28 03:34:58,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:58,353 INFO:     Epoch: 65
2022-11-28 03:34:59,102 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.456834443252195, 'Total loss': 0.456834443252195} | train loss {'Reaction outcome loss': 0.3152287964889359, 'Total loss': 0.3152287964889359}
2022-11-28 03:34:59,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:59,103 INFO:     Epoch: 66
2022-11-28 03:34:59,853 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4705777239393104, 'Total loss': 0.4705777239393104} | train loss {'Reaction outcome loss': 0.31842989835046953, 'Total loss': 0.31842989835046953}
2022-11-28 03:34:59,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:34:59,853 INFO:     Epoch: 67
2022-11-28 03:35:00,604 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4162198677659035, 'Total loss': 0.4162198677659035} | train loss {'Reaction outcome loss': 0.31725301157923474, 'Total loss': 0.31725301157923474}
2022-11-28 03:35:00,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:00,604 INFO:     Epoch: 68
2022-11-28 03:35:01,353 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4599146975035017, 'Total loss': 0.4599146975035017} | train loss {'Reaction outcome loss': 0.31411507086557966, 'Total loss': 0.31411507086557966}
2022-11-28 03:35:01,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:01,353 INFO:     Epoch: 69
2022-11-28 03:35:02,104 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4310462105680596, 'Total loss': 0.4310462105680596} | train loss {'Reaction outcome loss': 0.3160008080754309, 'Total loss': 0.3160008080754309}
2022-11-28 03:35:02,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:02,104 INFO:     Epoch: 70
2022-11-28 03:35:02,855 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4619817567819899, 'Total loss': 0.4619817567819899} | train loss {'Reaction outcome loss': 0.32199521170508477, 'Total loss': 0.32199521170508477}
2022-11-28 03:35:02,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:02,856 INFO:     Epoch: 71
2022-11-28 03:35:03,605 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45555503327738156, 'Total loss': 0.45555503327738156} | train loss {'Reaction outcome loss': 0.3181099773294503, 'Total loss': 0.3181099773294503}
2022-11-28 03:35:03,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:03,605 INFO:     Epoch: 72
2022-11-28 03:35:04,353 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4430364399132403, 'Total loss': 0.4430364399132403} | train loss {'Reaction outcome loss': 0.3172101105953897, 'Total loss': 0.3172101105953897}
2022-11-28 03:35:04,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:04,353 INFO:     Epoch: 73
2022-11-28 03:35:05,097 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4382623613558032, 'Total loss': 0.4382623613558032} | train loss {'Reaction outcome loss': 0.3076879096427752, 'Total loss': 0.3076879096427752}
2022-11-28 03:35:05,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:05,097 INFO:     Epoch: 74
2022-11-28 03:35:05,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43672591921958054, 'Total loss': 0.43672591921958054} | train loss {'Reaction outcome loss': 0.32244597480542236, 'Total loss': 0.32244597480542236}
2022-11-28 03:35:05,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:05,846 INFO:     Epoch: 75
2022-11-28 03:35:06,593 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42958983169360593, 'Total loss': 0.42958983169360593} | train loss {'Reaction outcome loss': 0.31084180974792086, 'Total loss': 0.31084180974792086}
2022-11-28 03:35:06,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:06,593 INFO:     Epoch: 76
2022-11-28 03:35:07,341 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4485832608558915, 'Total loss': 0.4485832608558915} | train loss {'Reaction outcome loss': 0.30982865124279935, 'Total loss': 0.30982865124279935}
2022-11-28 03:35:07,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:07,341 INFO:     Epoch: 77
2022-11-28 03:35:08,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43653290143067186, 'Total loss': 0.43653290143067186} | train loss {'Reaction outcome loss': 0.3189048019027518, 'Total loss': 0.3189048019027518}
2022-11-28 03:35:08,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:08,089 INFO:     Epoch: 78
2022-11-28 03:35:08,834 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.429819735952399, 'Total loss': 0.429819735952399} | train loss {'Reaction outcome loss': 0.31461610008151303, 'Total loss': 0.31461610008151303}
2022-11-28 03:35:08,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:08,834 INFO:     Epoch: 79
2022-11-28 03:35:09,584 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45388574491847644, 'Total loss': 0.45388574491847644} | train loss {'Reaction outcome loss': 0.31511774917523705, 'Total loss': 0.31511774917523705}
2022-11-28 03:35:09,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:09,584 INFO:     Epoch: 80
2022-11-28 03:35:10,333 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46372437138449063, 'Total loss': 0.46372437138449063} | train loss {'Reaction outcome loss': 0.3216048102495411, 'Total loss': 0.3216048102495411}
2022-11-28 03:35:10,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:10,334 INFO:     Epoch: 81
2022-11-28 03:35:11,083 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45781179500574415, 'Total loss': 0.45781179500574415} | train loss {'Reaction outcome loss': 0.31698485821365346, 'Total loss': 0.31698485821365346}
2022-11-28 03:35:11,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:11,084 INFO:     Epoch: 82
2022-11-28 03:35:11,834 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47097363390705804, 'Total loss': 0.47097363390705804} | train loss {'Reaction outcome loss': 0.31587210452304254, 'Total loss': 0.31587210452304254}
2022-11-28 03:35:11,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:11,834 INFO:     Epoch: 83
2022-11-28 03:35:12,582 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42581179670312186, 'Total loss': 0.42581179670312186} | train loss {'Reaction outcome loss': 0.3168801100504014, 'Total loss': 0.3168801100504014}
2022-11-28 03:35:12,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:12,583 INFO:     Epoch: 84
2022-11-28 03:35:13,333 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4318862638690255, 'Total loss': 0.4318862638690255} | train loss {'Reaction outcome loss': 0.31435141333889577, 'Total loss': 0.31435141333889577}
2022-11-28 03:35:13,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:13,334 INFO:     Epoch: 85
2022-11-28 03:35:14,084 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4590718360109763, 'Total loss': 0.4590718360109763} | train loss {'Reaction outcome loss': 0.3181128880279439, 'Total loss': 0.3181128880279439}
2022-11-28 03:35:14,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:14,084 INFO:     Epoch: 86
2022-11-28 03:35:14,832 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4453302445736798, 'Total loss': 0.4453302445736798} | train loss {'Reaction outcome loss': 0.31112672601856534, 'Total loss': 0.31112672601856534}
2022-11-28 03:35:14,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:14,832 INFO:     Epoch: 87
2022-11-28 03:35:15,581 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4337267093360424, 'Total loss': 0.4337267093360424} | train loss {'Reaction outcome loss': 0.31795147737307894, 'Total loss': 0.31795147737307894}
2022-11-28 03:35:15,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:15,581 INFO:     Epoch: 88
2022-11-28 03:35:16,332 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43151171471584926, 'Total loss': 0.43151171471584926} | train loss {'Reaction outcome loss': 0.31115807747588525, 'Total loss': 0.31115807747588525}
2022-11-28 03:35:16,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:16,332 INFO:     Epoch: 89
2022-11-28 03:35:17,082 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4535612497817386, 'Total loss': 0.4535612497817386} | train loss {'Reaction outcome loss': 0.316873638680385, 'Total loss': 0.316873638680385}
2022-11-28 03:35:17,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:17,082 INFO:     Epoch: 90
2022-11-28 03:35:17,832 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44831446117975493, 'Total loss': 0.44831446117975493} | train loss {'Reaction outcome loss': 0.31140184489589545, 'Total loss': 0.31140184489589545}
2022-11-28 03:35:17,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:17,832 INFO:     Epoch: 91
2022-11-28 03:35:18,579 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4480490640483119, 'Total loss': 0.4480490640483119} | train loss {'Reaction outcome loss': 0.31364324334408006, 'Total loss': 0.31364324334408006}
2022-11-28 03:35:18,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:18,579 INFO:     Epoch: 92
2022-11-28 03:35:19,329 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4806630347262729, 'Total loss': 0.4806630347262729} | train loss {'Reaction outcome loss': 0.31518629511758206, 'Total loss': 0.31518629511758206}
2022-11-28 03:35:19,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:19,329 INFO:     Epoch: 93
2022-11-28 03:35:20,077 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4565743577073921, 'Total loss': 0.4565743577073921} | train loss {'Reaction outcome loss': 0.3157476189456159, 'Total loss': 0.3157476189456159}
2022-11-28 03:35:20,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:20,077 INFO:     Epoch: 94
2022-11-28 03:35:20,824 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42881336029280315, 'Total loss': 0.42881336029280315} | train loss {'Reaction outcome loss': 0.31794719689435536, 'Total loss': 0.31794719689435536}
2022-11-28 03:35:20,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:20,824 INFO:     Epoch: 95
2022-11-28 03:35:21,571 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43280162797732785, 'Total loss': 0.43280162797732785} | train loss {'Reaction outcome loss': 0.3110159290654044, 'Total loss': 0.3110159290654044}
2022-11-28 03:35:21,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:21,571 INFO:     Epoch: 96
2022-11-28 03:35:22,320 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4485621106895534, 'Total loss': 0.4485621106895534} | train loss {'Reaction outcome loss': 0.30308037575694824, 'Total loss': 0.30308037575694824}
2022-11-28 03:35:22,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:22,321 INFO:     Epoch: 97
2022-11-28 03:35:23,066 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4422521879049865, 'Total loss': 0.4422521879049865} | train loss {'Reaction outcome loss': 0.3179419434839679, 'Total loss': 0.3179419434839679}
2022-11-28 03:35:23,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:23,066 INFO:     Epoch: 98
2022-11-28 03:35:23,811 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46449918841773813, 'Total loss': 0.46449918841773813} | train loss {'Reaction outcome loss': 0.31152926325317354, 'Total loss': 0.31152926325317354}
2022-11-28 03:35:23,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:23,812 INFO:     Epoch: 99
2022-11-28 03:35:24,559 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45610739053650334, 'Total loss': 0.45610739053650334} | train loss {'Reaction outcome loss': 0.3076842522038327, 'Total loss': 0.3076842522038327}
2022-11-28 03:35:24,559 INFO:     Best model found after epoch 64 of 100.
2022-11-28 03:35:24,560 INFO:   Done with stage: TRAINING
2022-11-28 03:35:24,560 INFO:   Starting stage: EVALUATION
2022-11-28 03:35:24,675 INFO:   Done with stage: EVALUATION
2022-11-28 03:35:24,684 INFO:   Leaving out SEQ value Fold_0
2022-11-28 03:35:24,697 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:35:24,697 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:35:25,339 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:35:25,339 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:35:25,407 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:35:25,407 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:35:25,407 INFO:     No hyperparam tuning for this model
2022-11-28 03:35:25,407 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:35:25,407 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:35:25,408 INFO:     None feature selector for col prot
2022-11-28 03:35:25,408 INFO:     None feature selector for col prot
2022-11-28 03:35:25,408 INFO:     None feature selector for col prot
2022-11-28 03:35:25,408 INFO:     None feature selector for col chem
2022-11-28 03:35:25,408 INFO:     None feature selector for col chem
2022-11-28 03:35:25,408 INFO:     None feature selector for col chem
2022-11-28 03:35:25,409 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:35:25,409 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:35:25,410 INFO:     Number of params in model 169741
2022-11-28 03:35:25,413 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:35:25,413 INFO:   Starting stage: TRAINING
2022-11-28 03:35:25,467 INFO:     Val loss before train {'Reaction outcome loss': 1.0188993960618973, 'Total loss': 1.0188993960618973}
2022-11-28 03:35:25,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:25,467 INFO:     Epoch: 0
2022-11-28 03:35:26,210 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.536269641735337, 'Total loss': 0.536269641735337} | train loss {'Reaction outcome loss': 0.6520323280380805, 'Total loss': 0.6520323280380805}
2022-11-28 03:35:26,210 INFO:     Found new best model at epoch 0
2022-11-28 03:35:26,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:26,211 INFO:     Epoch: 1
2022-11-28 03:35:26,958 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5162120732394132, 'Total loss': 0.5162120732394132} | train loss {'Reaction outcome loss': 0.5059414425118249, 'Total loss': 0.5059414425118249}
2022-11-28 03:35:26,958 INFO:     Found new best model at epoch 1
2022-11-28 03:35:26,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:26,959 INFO:     Epoch: 2
2022-11-28 03:35:27,707 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.524210012094541, 'Total loss': 0.524210012094541} | train loss {'Reaction outcome loss': 0.478665389452386, 'Total loss': 0.478665389452386}
2022-11-28 03:35:27,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:27,708 INFO:     Epoch: 3
2022-11-28 03:35:28,457 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5093506662683054, 'Total loss': 0.5093506662683054} | train loss {'Reaction outcome loss': 0.4607493666260831, 'Total loss': 0.4607493666260831}
2022-11-28 03:35:28,457 INFO:     Found new best model at epoch 3
2022-11-28 03:35:28,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:28,458 INFO:     Epoch: 4
2022-11-28 03:35:29,208 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4687908904796297, 'Total loss': 0.4687908904796297} | train loss {'Reaction outcome loss': 0.4424385669893823, 'Total loss': 0.4424385669893823}
2022-11-28 03:35:29,208 INFO:     Found new best model at epoch 4
2022-11-28 03:35:29,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:29,209 INFO:     Epoch: 5
2022-11-28 03:35:29,956 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47299198382957414, 'Total loss': 0.47299198382957414} | train loss {'Reaction outcome loss': 0.4219474558707191, 'Total loss': 0.4219474558707191}
2022-11-28 03:35:29,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:29,956 INFO:     Epoch: 6
2022-11-28 03:35:30,702 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47198022868145595, 'Total loss': 0.47198022868145595} | train loss {'Reaction outcome loss': 0.41874406360059613, 'Total loss': 0.41874406360059613}
2022-11-28 03:35:30,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:30,702 INFO:     Epoch: 7
2022-11-28 03:35:31,450 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46063007922335103, 'Total loss': 0.46063007922335103} | train loss {'Reaction outcome loss': 0.4147540875050703, 'Total loss': 0.4147540875050703}
2022-11-28 03:35:31,451 INFO:     Found new best model at epoch 7
2022-11-28 03:35:31,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:31,451 INFO:     Epoch: 8
2022-11-28 03:35:32,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4833522323857654, 'Total loss': 0.4833522323857654} | train loss {'Reaction outcome loss': 0.3916935930971192, 'Total loss': 0.3916935930971192}
2022-11-28 03:35:32,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:32,202 INFO:     Epoch: 9
2022-11-28 03:35:32,965 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4791021269153465, 'Total loss': 0.4791021269153465} | train loss {'Reaction outcome loss': 0.3983628410122052, 'Total loss': 0.3983628410122052}
2022-11-28 03:35:32,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:32,965 INFO:     Epoch: 10
2022-11-28 03:35:33,727 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4806931774047288, 'Total loss': 0.4806931774047288} | train loss {'Reaction outcome loss': 0.3836511316735614, 'Total loss': 0.3836511316735614}
2022-11-28 03:35:33,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:33,728 INFO:     Epoch: 11
2022-11-28 03:35:34,473 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46363055875355547, 'Total loss': 0.46363055875355547} | train loss {'Reaction outcome loss': 0.38125327126941216, 'Total loss': 0.38125327126941216}
2022-11-28 03:35:34,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:34,473 INFO:     Epoch: 12
2022-11-28 03:35:35,220 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4496697138317607, 'Total loss': 0.4496697138317607} | train loss {'Reaction outcome loss': 0.3848055197370921, 'Total loss': 0.3848055197370921}
2022-11-28 03:35:35,220 INFO:     Found new best model at epoch 12
2022-11-28 03:35:35,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:35,221 INFO:     Epoch: 13
2022-11-28 03:35:35,971 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4669295789843256, 'Total loss': 0.4669295789843256} | train loss {'Reaction outcome loss': 0.37247076793479533, 'Total loss': 0.37247076793479533}
2022-11-28 03:35:35,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:35,971 INFO:     Epoch: 14
2022-11-28 03:35:36,720 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45177394591949205, 'Total loss': 0.45177394591949205} | train loss {'Reaction outcome loss': 0.3930508485026205, 'Total loss': 0.3930508485026205}
2022-11-28 03:35:36,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:36,720 INFO:     Epoch: 15
2022-11-28 03:35:37,469 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47444100881164725, 'Total loss': 0.47444100881164725} | train loss {'Reaction outcome loss': 0.3745587125443194, 'Total loss': 0.3745587125443194}
2022-11-28 03:35:37,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:37,470 INFO:     Epoch: 16
2022-11-28 03:35:38,222 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45028549195690587, 'Total loss': 0.45028549195690587} | train loss {'Reaction outcome loss': 0.3635298303565998, 'Total loss': 0.3635298303565998}
2022-11-28 03:35:38,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:38,222 INFO:     Epoch: 17
2022-11-28 03:35:38,975 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46402723409912805, 'Total loss': 0.46402723409912805} | train loss {'Reaction outcome loss': 0.3576084407657264, 'Total loss': 0.3576084407657264}
2022-11-28 03:35:38,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:38,975 INFO:     Epoch: 18
2022-11-28 03:35:39,728 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45463642274791544, 'Total loss': 0.45463642274791544} | train loss {'Reaction outcome loss': 0.36018644632236196, 'Total loss': 0.36018644632236196}
2022-11-28 03:35:39,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:39,728 INFO:     Epoch: 19
2022-11-28 03:35:40,485 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45090496235273103, 'Total loss': 0.45090496235273103} | train loss {'Reaction outcome loss': 0.3572120389595688, 'Total loss': 0.3572120389595688}
2022-11-28 03:35:40,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:40,485 INFO:     Epoch: 20
2022-11-28 03:35:41,236 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44629359821026976, 'Total loss': 0.44629359821026976} | train loss {'Reaction outcome loss': 0.3607700402859734, 'Total loss': 0.3607700402859734}
2022-11-28 03:35:41,237 INFO:     Found new best model at epoch 20
2022-11-28 03:35:41,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:41,237 INFO:     Epoch: 21
2022-11-28 03:35:41,989 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4341916397891261, 'Total loss': 0.4341916397891261} | train loss {'Reaction outcome loss': 0.3454396777790085, 'Total loss': 0.3454396777790085}
2022-11-28 03:35:41,989 INFO:     Found new best model at epoch 21
2022-11-28 03:35:41,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:41,990 INFO:     Epoch: 22
2022-11-28 03:35:42,742 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43128811635754327, 'Total loss': 0.43128811635754327} | train loss {'Reaction outcome loss': 0.3731180280447006, 'Total loss': 0.3731180280447006}
2022-11-28 03:35:42,742 INFO:     Found new best model at epoch 22
2022-11-28 03:35:42,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:42,743 INFO:     Epoch: 23
2022-11-28 03:35:43,494 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.427890406074849, 'Total loss': 0.427890406074849} | train loss {'Reaction outcome loss': 0.34827048250055503, 'Total loss': 0.34827048250055503}
2022-11-28 03:35:43,495 INFO:     Found new best model at epoch 23
2022-11-28 03:35:43,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:43,495 INFO:     Epoch: 24
2022-11-28 03:35:44,250 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47416031089696015, 'Total loss': 0.47416031089696015} | train loss {'Reaction outcome loss': 0.35231828596065884, 'Total loss': 0.35231828596065884}
2022-11-28 03:35:44,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:44,250 INFO:     Epoch: 25
2022-11-28 03:35:45,002 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43417017940770497, 'Total loss': 0.43417017940770497} | train loss {'Reaction outcome loss': 0.36081921178018034, 'Total loss': 0.36081921178018034}
2022-11-28 03:35:45,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:45,003 INFO:     Epoch: 26
2022-11-28 03:35:45,759 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44971545971930027, 'Total loss': 0.44971545971930027} | train loss {'Reaction outcome loss': 0.34516950865768214, 'Total loss': 0.34516950865768214}
2022-11-28 03:35:45,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:45,760 INFO:     Epoch: 27
2022-11-28 03:35:46,519 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4210996109653603, 'Total loss': 0.4210996109653603} | train loss {'Reaction outcome loss': 0.33355520837582076, 'Total loss': 0.33355520837582076}
2022-11-28 03:35:46,520 INFO:     Found new best model at epoch 27
2022-11-28 03:35:46,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:46,520 INFO:     Epoch: 28
2022-11-28 03:35:47,280 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42425629953769123, 'Total loss': 0.42425629953769123} | train loss {'Reaction outcome loss': 0.3465292617256342, 'Total loss': 0.3465292617256342}
2022-11-28 03:35:47,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:47,280 INFO:     Epoch: 29
2022-11-28 03:35:48,035 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45215661891482095, 'Total loss': 0.45215661891482095} | train loss {'Reaction outcome loss': 0.3442033803173405, 'Total loss': 0.3442033803173405}
2022-11-28 03:35:48,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:48,036 INFO:     Epoch: 30
2022-11-28 03:35:48,790 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4712727012282068, 'Total loss': 0.4712727012282068} | train loss {'Reaction outcome loss': 0.3335003043232233, 'Total loss': 0.3335003043232233}
2022-11-28 03:35:48,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:48,790 INFO:     Epoch: 31
2022-11-28 03:35:49,542 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4513507593761791, 'Total loss': 0.4513507593761791} | train loss {'Reaction outcome loss': 0.33005561531018957, 'Total loss': 0.33005561531018957}
2022-11-28 03:35:49,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:49,542 INFO:     Epoch: 32
2022-11-28 03:35:50,294 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4323924851011146, 'Total loss': 0.4323924851011146} | train loss {'Reaction outcome loss': 0.33135123801255517, 'Total loss': 0.33135123801255517}
2022-11-28 03:35:50,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:50,294 INFO:     Epoch: 33
2022-11-28 03:35:51,050 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47094591842456296, 'Total loss': 0.47094591842456296} | train loss {'Reaction outcome loss': 0.34867753827499476, 'Total loss': 0.34867753827499476}
2022-11-28 03:35:51,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:51,050 INFO:     Epoch: 34
2022-11-28 03:35:51,805 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45189172672954475, 'Total loss': 0.45189172672954475} | train loss {'Reaction outcome loss': 0.3261379246347346, 'Total loss': 0.3261379246347346}
2022-11-28 03:35:51,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:51,806 INFO:     Epoch: 35
2022-11-28 03:35:52,557 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42754533378915355, 'Total loss': 0.42754533378915355} | train loss {'Reaction outcome loss': 0.3319619189088161, 'Total loss': 0.3319619189088161}
2022-11-28 03:35:52,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:52,558 INFO:     Epoch: 36
2022-11-28 03:35:53,309 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40599947490475397, 'Total loss': 0.40599947490475397} | train loss {'Reaction outcome loss': 0.33321170335605377, 'Total loss': 0.33321170335605377}
2022-11-28 03:35:53,309 INFO:     Found new best model at epoch 36
2022-11-28 03:35:53,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:53,310 INFO:     Epoch: 37
2022-11-28 03:35:54,064 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4326864457265897, 'Total loss': 0.4326864457265897} | train loss {'Reaction outcome loss': 0.3241547397997698, 'Total loss': 0.3241547397997698}
2022-11-28 03:35:54,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:54,064 INFO:     Epoch: 38
2022-11-28 03:35:54,818 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4345497607507489, 'Total loss': 0.4345497607507489} | train loss {'Reaction outcome loss': 0.3374835756505549, 'Total loss': 0.3374835756505549}
2022-11-28 03:35:54,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:54,819 INFO:     Epoch: 39
2022-11-28 03:35:55,575 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4303404986858368, 'Total loss': 0.4303404986858368} | train loss {'Reaction outcome loss': 0.36139222490129924, 'Total loss': 0.36139222490129924}
2022-11-28 03:35:55,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:55,575 INFO:     Epoch: 40
2022-11-28 03:35:56,329 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39673750881444325, 'Total loss': 0.39673750881444325} | train loss {'Reaction outcome loss': 0.32398190679356664, 'Total loss': 0.32398190679356664}
2022-11-28 03:35:56,329 INFO:     Found new best model at epoch 40
2022-11-28 03:35:56,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:56,330 INFO:     Epoch: 41
2022-11-28 03:35:57,082 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4249311534857208, 'Total loss': 0.4249311534857208} | train loss {'Reaction outcome loss': 0.318044281108418, 'Total loss': 0.318044281108418}
2022-11-28 03:35:57,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:57,082 INFO:     Epoch: 42
2022-11-28 03:35:57,841 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.426989059895277, 'Total loss': 0.426989059895277} | train loss {'Reaction outcome loss': 0.32198000500197355, 'Total loss': 0.32198000500197355}
2022-11-28 03:35:57,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:57,841 INFO:     Epoch: 43
2022-11-28 03:35:58,599 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4348302964459766, 'Total loss': 0.4348302964459766} | train loss {'Reaction outcome loss': 0.3333037155133631, 'Total loss': 0.3333037155133631}
2022-11-28 03:35:58,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:58,599 INFO:     Epoch: 44
2022-11-28 03:35:59,351 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43330020051110874, 'Total loss': 0.43330020051110874} | train loss {'Reaction outcome loss': 0.3210972565026418, 'Total loss': 0.3210972565026418}
2022-11-28 03:35:59,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:35:59,352 INFO:     Epoch: 45
2022-11-28 03:36:00,103 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43927764384583995, 'Total loss': 0.43927764384583995} | train loss {'Reaction outcome loss': 0.3281996090885116, 'Total loss': 0.3281996090885116}
2022-11-28 03:36:00,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:00,103 INFO:     Epoch: 46
2022-11-28 03:36:00,855 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.442134365439415, 'Total loss': 0.442134365439415} | train loss {'Reaction outcome loss': 0.3225590026812997, 'Total loss': 0.3225590026812997}
2022-11-28 03:36:00,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:00,856 INFO:     Epoch: 47
2022-11-28 03:36:01,608 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43557455289092933, 'Total loss': 0.43557455289092933} | train loss {'Reaction outcome loss': 0.3346163542254975, 'Total loss': 0.3346163542254975}
2022-11-28 03:36:01,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:01,608 INFO:     Epoch: 48
2022-11-28 03:36:02,360 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40352814813906496, 'Total loss': 0.40352814813906496} | train loss {'Reaction outcome loss': 0.3279296031244371, 'Total loss': 0.3279296031244371}
2022-11-28 03:36:02,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:02,361 INFO:     Epoch: 49
2022-11-28 03:36:03,115 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40581858733838255, 'Total loss': 0.40581858733838255} | train loss {'Reaction outcome loss': 0.32403758182737086, 'Total loss': 0.32403758182737086}
2022-11-28 03:36:03,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:03,115 INFO:     Epoch: 50
2022-11-28 03:36:03,866 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46178886937824165, 'Total loss': 0.46178886937824165} | train loss {'Reaction outcome loss': 0.3259061120058361, 'Total loss': 0.3259061120058361}
2022-11-28 03:36:03,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:03,866 INFO:     Epoch: 51
2022-11-28 03:36:04,621 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42937334863977, 'Total loss': 0.42937334863977} | train loss {'Reaction outcome loss': 0.3297135407436895, 'Total loss': 0.3297135407436895}
2022-11-28 03:36:04,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:04,621 INFO:     Epoch: 52
2022-11-28 03:36:05,372 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44417397474700754, 'Total loss': 0.44417397474700754} | train loss {'Reaction outcome loss': 0.32121003963496736, 'Total loss': 0.32121003963496736}
2022-11-28 03:36:05,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:05,373 INFO:     Epoch: 53
2022-11-28 03:36:06,126 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45861857756972313, 'Total loss': 0.45861857756972313} | train loss {'Reaction outcome loss': 0.32396028938925703, 'Total loss': 0.32396028938925703}
2022-11-28 03:36:06,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:06,126 INFO:     Epoch: 54
2022-11-28 03:36:06,875 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4380089942027222, 'Total loss': 0.4380089942027222} | train loss {'Reaction outcome loss': 0.32921200827789693, 'Total loss': 0.32921200827789693}
2022-11-28 03:36:06,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:06,875 INFO:     Epoch: 55
2022-11-28 03:36:07,625 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42816176130013034, 'Total loss': 0.42816176130013034} | train loss {'Reaction outcome loss': 0.31947666382500034, 'Total loss': 0.31947666382500034}
2022-11-28 03:36:07,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:07,625 INFO:     Epoch: 56
2022-11-28 03:36:08,375 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45810274441133847, 'Total loss': 0.45810274441133847} | train loss {'Reaction outcome loss': 0.32811991342528146, 'Total loss': 0.32811991342528146}
2022-11-28 03:36:08,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:08,376 INFO:     Epoch: 57
2022-11-28 03:36:09,131 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4279754717241634, 'Total loss': 0.4279754717241634} | train loss {'Reaction outcome loss': 0.3331091866983093, 'Total loss': 0.3331091866983093}
2022-11-28 03:36:09,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:09,131 INFO:     Epoch: 58
2022-11-28 03:36:09,883 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4364793339574879, 'Total loss': 0.4364793339574879} | train loss {'Reaction outcome loss': 0.328046527076588, 'Total loss': 0.328046527076588}
2022-11-28 03:36:09,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:09,883 INFO:     Epoch: 59
2022-11-28 03:36:10,636 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41649014401164924, 'Total loss': 0.41649014401164924} | train loss {'Reaction outcome loss': 0.3291974188646807, 'Total loss': 0.3291974188646807}
2022-11-28 03:36:10,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:10,636 INFO:     Epoch: 60
2022-11-28 03:36:11,391 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44751517627049575, 'Total loss': 0.44751517627049575} | train loss {'Reaction outcome loss': 0.31971729524162135, 'Total loss': 0.31971729524162135}
2022-11-28 03:36:11,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:11,392 INFO:     Epoch: 61
2022-11-28 03:36:12,144 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43327765607021074, 'Total loss': 0.43327765607021074} | train loss {'Reaction outcome loss': 0.34620495798134127, 'Total loss': 0.34620495798134127}
2022-11-28 03:36:12,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:12,145 INFO:     Epoch: 62
2022-11-28 03:36:12,894 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40312266011129727, 'Total loss': 0.40312266011129727} | train loss {'Reaction outcome loss': 0.32210838284931687, 'Total loss': 0.32210838284931687}
2022-11-28 03:36:12,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:12,895 INFO:     Epoch: 63
2022-11-28 03:36:13,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43847282349385996, 'Total loss': 0.43847282349385996} | train loss {'Reaction outcome loss': 0.3179098164082056, 'Total loss': 0.3179098164082056}
2022-11-28 03:36:13,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:13,647 INFO:     Epoch: 64
2022-11-28 03:36:14,399 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45587357065894385, 'Total loss': 0.45587357065894385} | train loss {'Reaction outcome loss': 0.3212034996704534, 'Total loss': 0.3212034996704534}
2022-11-28 03:36:14,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:14,399 INFO:     Epoch: 65
2022-11-28 03:36:15,147 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43216214227405464, 'Total loss': 0.43216214227405464} | train loss {'Reaction outcome loss': 0.32164634464059766, 'Total loss': 0.32164634464059766}
2022-11-28 03:36:15,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:15,147 INFO:     Epoch: 66
2022-11-28 03:36:15,900 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4415923333303495, 'Total loss': 0.4415923333303495} | train loss {'Reaction outcome loss': 0.31080573248235804, 'Total loss': 0.31080573248235804}
2022-11-28 03:36:15,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:15,900 INFO:     Epoch: 67
2022-11-28 03:36:16,656 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44704194587062707, 'Total loss': 0.44704194587062707} | train loss {'Reaction outcome loss': 0.3180973966896293, 'Total loss': 0.3180973966896293}
2022-11-28 03:36:16,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:16,656 INFO:     Epoch: 68
2022-11-28 03:36:17,409 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44221216440200806, 'Total loss': 0.44221216440200806} | train loss {'Reaction outcome loss': 0.31826960752474953, 'Total loss': 0.31826960752474953}
2022-11-28 03:36:17,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:17,410 INFO:     Epoch: 69
2022-11-28 03:36:18,164 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43874156271869486, 'Total loss': 0.43874156271869486} | train loss {'Reaction outcome loss': 0.3167203893670096, 'Total loss': 0.3167203893670096}
2022-11-28 03:36:18,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:18,164 INFO:     Epoch: 70
2022-11-28 03:36:18,919 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4562332982366735, 'Total loss': 0.4562332982366735} | train loss {'Reaction outcome loss': 0.32274601424512595, 'Total loss': 0.32274601424512595}
2022-11-28 03:36:18,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:18,920 INFO:     Epoch: 71
2022-11-28 03:36:19,668 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48173253559930757, 'Total loss': 0.48173253559930757} | train loss {'Reaction outcome loss': 0.3183528298006849, 'Total loss': 0.3183528298006849}
2022-11-28 03:36:19,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:19,668 INFO:     Epoch: 72
2022-11-28 03:36:20,422 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4737318246202035, 'Total loss': 0.4737318246202035} | train loss {'Reaction outcome loss': 0.33238563664740156, 'Total loss': 0.33238563664740156}
2022-11-28 03:36:20,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:20,422 INFO:     Epoch: 73
2022-11-28 03:36:21,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4472923891788179, 'Total loss': 0.4472923891788179} | train loss {'Reaction outcome loss': 0.3370288375167455, 'Total loss': 0.3370288375167455}
2022-11-28 03:36:21,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:21,178 INFO:     Epoch: 74
2022-11-28 03:36:21,929 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43362596427852457, 'Total loss': 0.43362596427852457} | train loss {'Reaction outcome loss': 0.31802574177140647, 'Total loss': 0.31802574177140647}
2022-11-28 03:36:21,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:21,930 INFO:     Epoch: 75
2022-11-28 03:36:22,682 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4162364707074382, 'Total loss': 0.4162364707074382} | train loss {'Reaction outcome loss': 0.32464054543977444, 'Total loss': 0.32464054543977444}
2022-11-28 03:36:22,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:22,683 INFO:     Epoch: 76
2022-11-28 03:36:23,437 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44651295498690824, 'Total loss': 0.44651295498690824} | train loss {'Reaction outcome loss': 0.3106495341369015, 'Total loss': 0.3106495341369015}
2022-11-28 03:36:23,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:23,437 INFO:     Epoch: 77
2022-11-28 03:36:24,187 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4513848694888028, 'Total loss': 0.4513848694888028} | train loss {'Reaction outcome loss': 0.3264201051189832, 'Total loss': 0.3264201051189832}
2022-11-28 03:36:24,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:24,187 INFO:     Epoch: 78
2022-11-28 03:36:24,943 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4569715935398232, 'Total loss': 0.4569715935398232} | train loss {'Reaction outcome loss': 0.33836684876728634, 'Total loss': 0.33836684876728634}
2022-11-28 03:36:24,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:24,943 INFO:     Epoch: 79
2022-11-28 03:36:25,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4319745149802078, 'Total loss': 0.4319745149802078} | train loss {'Reaction outcome loss': 0.31381308309640077, 'Total loss': 0.31381308309640077}
2022-11-28 03:36:25,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:25,695 INFO:     Epoch: 80
2022-11-28 03:36:26,443 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42335524037480354, 'Total loss': 0.42335524037480354} | train loss {'Reaction outcome loss': 0.30925123802261795, 'Total loss': 0.30925123802261795}
2022-11-28 03:36:26,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:26,443 INFO:     Epoch: 81
2022-11-28 03:36:27,194 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4091778478839181, 'Total loss': 0.4091778478839181} | train loss {'Reaction outcome loss': 0.3186273388715408, 'Total loss': 0.3186273388715408}
2022-11-28 03:36:27,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:27,194 INFO:     Epoch: 82
2022-11-28 03:36:27,949 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43171868981285527, 'Total loss': 0.43171868981285527} | train loss {'Reaction outcome loss': 0.3273110479636774, 'Total loss': 0.3273110479636774}
2022-11-28 03:36:27,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:27,949 INFO:     Epoch: 83
2022-11-28 03:36:28,699 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4371071593327956, 'Total loss': 0.4371071593327956} | train loss {'Reaction outcome loss': 0.31287019070886407, 'Total loss': 0.31287019070886407}
2022-11-28 03:36:28,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:28,699 INFO:     Epoch: 84
2022-11-28 03:36:29,450 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42588933489539404, 'Total loss': 0.42588933489539404} | train loss {'Reaction outcome loss': 0.31921289216063403, 'Total loss': 0.31921289216063403}
2022-11-28 03:36:29,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:29,450 INFO:     Epoch: 85
2022-11-28 03:36:30,202 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43836652318185027, 'Total loss': 0.43836652318185027} | train loss {'Reaction outcome loss': 0.3170463179260764, 'Total loss': 0.3170463179260764}
2022-11-28 03:36:30,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:30,204 INFO:     Epoch: 86
2022-11-28 03:36:30,960 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4487188251858408, 'Total loss': 0.4487188251858408} | train loss {'Reaction outcome loss': 0.3085718940036665, 'Total loss': 0.3085718940036665}
2022-11-28 03:36:30,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:30,960 INFO:     Epoch: 87
2022-11-28 03:36:31,714 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.431670738553459, 'Total loss': 0.431670738553459} | train loss {'Reaction outcome loss': 0.3165262218881474, 'Total loss': 0.3165262218881474}
2022-11-28 03:36:31,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:31,714 INFO:     Epoch: 88
2022-11-28 03:36:32,474 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4418231856755235, 'Total loss': 0.4418231856755235} | train loss {'Reaction outcome loss': 0.30995026601832887, 'Total loss': 0.30995026601832887}
2022-11-28 03:36:32,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:32,474 INFO:     Epoch: 89
2022-11-28 03:36:33,226 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45944562486626883, 'Total loss': 0.45944562486626883} | train loss {'Reaction outcome loss': 0.32614913674802914, 'Total loss': 0.32614913674802914}
2022-11-28 03:36:33,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:33,226 INFO:     Epoch: 90
2022-11-28 03:36:33,978 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49191324412822723, 'Total loss': 0.49191324412822723} | train loss {'Reaction outcome loss': 0.3179787399420733, 'Total loss': 0.3179787399420733}
2022-11-28 03:36:33,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:33,978 INFO:     Epoch: 91
2022-11-28 03:36:34,727 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4592547799375924, 'Total loss': 0.4592547799375924} | train loss {'Reaction outcome loss': 0.3113465931357039, 'Total loss': 0.3113465931357039}
2022-11-28 03:36:34,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:34,727 INFO:     Epoch: 92
2022-11-28 03:36:35,478 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4424682557582855, 'Total loss': 0.4424682557582855} | train loss {'Reaction outcome loss': 0.3188905463618064, 'Total loss': 0.3188905463618064}
2022-11-28 03:36:35,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:35,478 INFO:     Epoch: 93
2022-11-28 03:36:36,228 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44346635788679123, 'Total loss': 0.44346635788679123} | train loss {'Reaction outcome loss': 0.3164927584990135, 'Total loss': 0.3164927584990135}
2022-11-28 03:36:36,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:36,229 INFO:     Epoch: 94
2022-11-28 03:36:36,988 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44544513151049614, 'Total loss': 0.44544513151049614} | train loss {'Reaction outcome loss': 0.3122944244700164, 'Total loss': 0.3122944244700164}
2022-11-28 03:36:36,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:36,989 INFO:     Epoch: 95
2022-11-28 03:36:37,738 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43214205652475357, 'Total loss': 0.43214205652475357} | train loss {'Reaction outcome loss': 0.33401723145714657, 'Total loss': 0.33401723145714657}
2022-11-28 03:36:37,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:37,738 INFO:     Epoch: 96
2022-11-28 03:36:38,486 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44709395651112904, 'Total loss': 0.44709395651112904} | train loss {'Reaction outcome loss': 0.3187722015507549, 'Total loss': 0.3187722015507549}
2022-11-28 03:36:38,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:38,487 INFO:     Epoch: 97
2022-11-28 03:36:39,243 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4048854261636734, 'Total loss': 0.4048854261636734} | train loss {'Reaction outcome loss': 0.3156438294990433, 'Total loss': 0.3156438294990433}
2022-11-28 03:36:39,243 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:39,243 INFO:     Epoch: 98
2022-11-28 03:36:39,993 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41607909167016094, 'Total loss': 0.41607909167016094} | train loss {'Reaction outcome loss': 0.31304294993037635, 'Total loss': 0.31304294993037635}
2022-11-28 03:36:39,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:39,993 INFO:     Epoch: 99
2022-11-28 03:36:40,747 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4314473902975971, 'Total loss': 0.4314473902975971} | train loss {'Reaction outcome loss': 0.33882838495920303, 'Total loss': 0.33882838495920303}
2022-11-28 03:36:40,748 INFO:     Best model found after epoch 41 of 100.
2022-11-28 03:36:40,748 INFO:   Done with stage: TRAINING
2022-11-28 03:36:40,748 INFO:   Starting stage: EVALUATION
2022-11-28 03:36:40,869 INFO:   Done with stage: EVALUATION
2022-11-28 03:36:40,870 INFO:   Leaving out SEQ value Fold_1
2022-11-28 03:36:40,883 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 03:36:40,883 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:36:41,529 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:36:41,529 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:36:41,597 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:36:41,597 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:36:41,597 INFO:     No hyperparam tuning for this model
2022-11-28 03:36:41,597 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:36:41,597 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:36:41,598 INFO:     None feature selector for col prot
2022-11-28 03:36:41,598 INFO:     None feature selector for col prot
2022-11-28 03:36:41,598 INFO:     None feature selector for col prot
2022-11-28 03:36:41,599 INFO:     None feature selector for col chem
2022-11-28 03:36:41,599 INFO:     None feature selector for col chem
2022-11-28 03:36:41,599 INFO:     None feature selector for col chem
2022-11-28 03:36:41,599 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:36:41,599 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:36:41,600 INFO:     Number of params in model 169741
2022-11-28 03:36:41,603 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:36:41,603 INFO:   Starting stage: TRAINING
2022-11-28 03:36:41,658 INFO:     Val loss before train {'Reaction outcome loss': 0.9896161935546182, 'Total loss': 0.9896161935546182}
2022-11-28 03:36:41,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:41,658 INFO:     Epoch: 0
2022-11-28 03:36:42,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5497977090152827, 'Total loss': 0.5497977090152827} | train loss {'Reaction outcome loss': 0.6317968322680547, 'Total loss': 0.6317968322680547}
2022-11-28 03:36:42,410 INFO:     Found new best model at epoch 0
2022-11-28 03:36:42,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:42,411 INFO:     Epoch: 1
2022-11-28 03:36:43,165 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5244683376090093, 'Total loss': 0.5244683376090093} | train loss {'Reaction outcome loss': 0.50686181243132, 'Total loss': 0.50686181243132}
2022-11-28 03:36:43,165 INFO:     Found new best model at epoch 1
2022-11-28 03:36:43,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:43,166 INFO:     Epoch: 2
2022-11-28 03:36:43,919 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4864920960231261, 'Total loss': 0.4864920960231261} | train loss {'Reaction outcome loss': 0.469185174114791, 'Total loss': 0.469185174114791}
2022-11-28 03:36:43,919 INFO:     Found new best model at epoch 2
2022-11-28 03:36:43,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:43,920 INFO:     Epoch: 3
2022-11-28 03:36:44,672 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45003497532822867, 'Total loss': 0.45003497532822867} | train loss {'Reaction outcome loss': 0.4457409719932779, 'Total loss': 0.4457409719932779}
2022-11-28 03:36:44,672 INFO:     Found new best model at epoch 3
2022-11-28 03:36:44,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:44,673 INFO:     Epoch: 4
2022-11-28 03:36:45,429 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4167889901860194, 'Total loss': 0.4167889901860194} | train loss {'Reaction outcome loss': 0.4285582857214005, 'Total loss': 0.4285582857214005}
2022-11-28 03:36:45,429 INFO:     Found new best model at epoch 4
2022-11-28 03:36:45,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:45,430 INFO:     Epoch: 5
2022-11-28 03:36:46,183 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44937260618264024, 'Total loss': 0.44937260618264024} | train loss {'Reaction outcome loss': 0.41890749633915514, 'Total loss': 0.41890749633915514}
2022-11-28 03:36:46,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:46,183 INFO:     Epoch: 6
2022-11-28 03:36:46,935 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4499599371444095, 'Total loss': 0.4499599371444095} | train loss {'Reaction outcome loss': 0.41315092704436074, 'Total loss': 0.41315092704436074}
2022-11-28 03:36:46,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:46,936 INFO:     Epoch: 7
2022-11-28 03:36:47,689 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4289936582473191, 'Total loss': 0.4289936582473191} | train loss {'Reaction outcome loss': 0.41000840010551304, 'Total loss': 0.41000840010551304}
2022-11-28 03:36:47,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:47,690 INFO:     Epoch: 8
2022-11-28 03:36:48,440 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4575421183624051, 'Total loss': 0.4575421183624051} | train loss {'Reaction outcome loss': 0.4005620907313428, 'Total loss': 0.4005620907313428}
2022-11-28 03:36:48,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:48,441 INFO:     Epoch: 9
2022-11-28 03:36:49,190 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4273252487182617, 'Total loss': 0.4273252487182617} | train loss {'Reaction outcome loss': 0.4081204022744648, 'Total loss': 0.4081204022744648}
2022-11-28 03:36:49,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:49,190 INFO:     Epoch: 10
2022-11-28 03:36:49,946 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4300892579961907, 'Total loss': 0.4300892579961907} | train loss {'Reaction outcome loss': 0.39105304484425285, 'Total loss': 0.39105304484425285}
2022-11-28 03:36:49,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:49,946 INFO:     Epoch: 11
2022-11-28 03:36:50,700 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4139893207360398, 'Total loss': 0.4139893207360398} | train loss {'Reaction outcome loss': 0.3872233366495685, 'Total loss': 0.3872233366495685}
2022-11-28 03:36:50,700 INFO:     Found new best model at epoch 11
2022-11-28 03:36:50,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:50,701 INFO:     Epoch: 12
2022-11-28 03:36:51,458 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42088069157166913, 'Total loss': 0.42088069157166913} | train loss {'Reaction outcome loss': 0.3750823961819714, 'Total loss': 0.3750823961819714}
2022-11-28 03:36:51,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:51,458 INFO:     Epoch: 13
2022-11-28 03:36:52,211 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4008790471337058, 'Total loss': 0.4008790471337058} | train loss {'Reaction outcome loss': 0.3761705064067715, 'Total loss': 0.3761705064067715}
2022-11-28 03:36:52,211 INFO:     Found new best model at epoch 13
2022-11-28 03:36:52,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:52,212 INFO:     Epoch: 14
2022-11-28 03:36:52,961 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42721785909750243, 'Total loss': 0.42721785909750243} | train loss {'Reaction outcome loss': 0.37103991442725726, 'Total loss': 0.37103991442725726}
2022-11-28 03:36:52,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:52,962 INFO:     Epoch: 15
2022-11-28 03:36:53,715 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4276811836118048, 'Total loss': 0.4276811836118048} | train loss {'Reaction outcome loss': 0.37152724975704965, 'Total loss': 0.37152724975704965}
2022-11-28 03:36:53,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:53,715 INFO:     Epoch: 16
2022-11-28 03:36:54,462 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4114187356423248, 'Total loss': 0.4114187356423248} | train loss {'Reaction outcome loss': 0.35889178502414876, 'Total loss': 0.35889178502414876}
2022-11-28 03:36:54,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:54,462 INFO:     Epoch: 17
2022-11-28 03:36:55,213 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45056803592226724, 'Total loss': 0.45056803592226724} | train loss {'Reaction outcome loss': 0.36480544091236256, 'Total loss': 0.36480544091236256}
2022-11-28 03:36:55,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:55,213 INFO:     Epoch: 18
2022-11-28 03:36:55,964 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4160444966771386, 'Total loss': 0.4160444966771386} | train loss {'Reaction outcome loss': 0.369375949446489, 'Total loss': 0.369375949446489}
2022-11-28 03:36:55,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:55,964 INFO:     Epoch: 19
2022-11-28 03:36:56,717 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4613699611615051, 'Total loss': 0.4613699611615051} | train loss {'Reaction outcome loss': 0.3646717904067715, 'Total loss': 0.3646717904067715}
2022-11-28 03:36:56,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:56,718 INFO:     Epoch: 20
2022-11-28 03:36:57,467 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39983285836536775, 'Total loss': 0.39983285836536775} | train loss {'Reaction outcome loss': 0.3681899996357499, 'Total loss': 0.3681899996357499}
2022-11-28 03:36:57,467 INFO:     Found new best model at epoch 20
2022-11-28 03:36:57,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:57,468 INFO:     Epoch: 21
2022-11-28 03:36:58,216 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4044524072246118, 'Total loss': 0.4044524072246118} | train loss {'Reaction outcome loss': 0.3468962615122076, 'Total loss': 0.3468962615122076}
2022-11-28 03:36:58,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:58,217 INFO:     Epoch: 22
2022-11-28 03:36:58,965 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4064322926781394, 'Total loss': 0.4064322926781394} | train loss {'Reaction outcome loss': 0.3539880587519542, 'Total loss': 0.3539880587519542}
2022-11-28 03:36:58,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:58,966 INFO:     Epoch: 23
2022-11-28 03:36:59,718 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4198039075867696, 'Total loss': 0.4198039075867696} | train loss {'Reaction outcome loss': 0.3512871421511598, 'Total loss': 0.3512871421511598}
2022-11-28 03:36:59,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:36:59,718 INFO:     Epoch: 24
2022-11-28 03:37:00,464 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4328005557710474, 'Total loss': 0.4328005557710474} | train loss {'Reaction outcome loss': 0.3541281670030312, 'Total loss': 0.3541281670030312}
2022-11-28 03:37:00,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:00,465 INFO:     Epoch: 25
2022-11-28 03:37:01,215 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41776934096759016, 'Total loss': 0.41776934096759016} | train loss {'Reaction outcome loss': 0.36001882352960496, 'Total loss': 0.36001882352960496}
2022-11-28 03:37:01,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:01,216 INFO:     Epoch: 26
2022-11-28 03:37:01,969 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4313481150364334, 'Total loss': 0.4313481150364334} | train loss {'Reaction outcome loss': 0.3513911745024596, 'Total loss': 0.3513911745024596}
2022-11-28 03:37:01,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:01,969 INFO:     Epoch: 27
2022-11-28 03:37:02,721 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42895829474384134, 'Total loss': 0.42895829474384134} | train loss {'Reaction outcome loss': 0.3475621595586601, 'Total loss': 0.3475621595586601}
2022-11-28 03:37:02,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:02,721 INFO:     Epoch: 28
2022-11-28 03:37:03,475 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.429147679020058, 'Total loss': 0.429147679020058} | train loss {'Reaction outcome loss': 0.34585105811777384, 'Total loss': 0.34585105811777384}
2022-11-28 03:37:03,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:03,475 INFO:     Epoch: 29
2022-11-28 03:37:04,228 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42325201393528417, 'Total loss': 0.42325201393528417} | train loss {'Reaction outcome loss': 0.34569396861350005, 'Total loss': 0.34569396861350005}
2022-11-28 03:37:04,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:04,228 INFO:     Epoch: 30
2022-11-28 03:37:04,983 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4374032027342103, 'Total loss': 0.4374032027342103} | train loss {'Reaction outcome loss': 0.3518303746153951, 'Total loss': 0.3518303746153951}
2022-11-28 03:37:04,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:04,983 INFO:     Epoch: 31
2022-11-28 03:37:05,735 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40824644707820634, 'Total loss': 0.40824644707820634} | train loss {'Reaction outcome loss': 0.35015853437093586, 'Total loss': 0.35015853437093586}
2022-11-28 03:37:05,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:05,735 INFO:     Epoch: 32
2022-11-28 03:37:06,484 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4166522540829398, 'Total loss': 0.4166522540829398} | train loss {'Reaction outcome loss': 0.339628655146732, 'Total loss': 0.339628655146732}
2022-11-28 03:37:06,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:06,485 INFO:     Epoch: 33
2022-11-28 03:37:07,236 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4463800676167011, 'Total loss': 0.4463800676167011} | train loss {'Reaction outcome loss': 0.3468733004215155, 'Total loss': 0.3468733004215155}
2022-11-28 03:37:07,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:07,237 INFO:     Epoch: 34
2022-11-28 03:37:07,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40725199573419313, 'Total loss': 0.40725199573419313} | train loss {'Reaction outcome loss': 0.34133398572081014, 'Total loss': 0.34133398572081014}
2022-11-28 03:37:07,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:07,988 INFO:     Epoch: 35
2022-11-28 03:37:08,740 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4326650940559127, 'Total loss': 0.4326650940559127} | train loss {'Reaction outcome loss': 0.3435810535301564, 'Total loss': 0.3435810535301564}
2022-11-28 03:37:08,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:08,741 INFO:     Epoch: 36
2022-11-28 03:37:09,490 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43713137710636313, 'Total loss': 0.43713137710636313} | train loss {'Reaction outcome loss': 0.34355051483702564, 'Total loss': 0.34355051483702564}
2022-11-28 03:37:09,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:09,490 INFO:     Epoch: 37
2022-11-28 03:37:10,240 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42591139538721606, 'Total loss': 0.42591139538721606} | train loss {'Reaction outcome loss': 0.34439426720866306, 'Total loss': 0.34439426720866306}
2022-11-28 03:37:10,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:10,241 INFO:     Epoch: 38
2022-11-28 03:37:10,992 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4255910993299701, 'Total loss': 0.4255910993299701} | train loss {'Reaction outcome loss': 0.3396129597398841, 'Total loss': 0.3396129597398841}
2022-11-28 03:37:10,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:10,992 INFO:     Epoch: 39
2022-11-28 03:37:11,744 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4096156693994999, 'Total loss': 0.4096156693994999} | train loss {'Reaction outcome loss': 0.33104096828141677, 'Total loss': 0.33104096828141677}
2022-11-28 03:37:11,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:11,745 INFO:     Epoch: 40
2022-11-28 03:37:12,496 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4448086030103944, 'Total loss': 0.4448086030103944} | train loss {'Reaction outcome loss': 0.3622617466791876, 'Total loss': 0.3622617466791876}
2022-11-28 03:37:12,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:12,497 INFO:     Epoch: 41
2022-11-28 03:37:13,251 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4216965268450705, 'Total loss': 0.4216965268450705} | train loss {'Reaction outcome loss': 0.3311188827883377, 'Total loss': 0.3311188827883377}
2022-11-28 03:37:13,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:13,251 INFO:     Epoch: 42
2022-11-28 03:37:14,004 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4216828393665227, 'Total loss': 0.4216828393665227} | train loss {'Reaction outcome loss': 0.32589773752213824, 'Total loss': 0.32589773752213824}
2022-11-28 03:37:14,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:14,004 INFO:     Epoch: 43
2022-11-28 03:37:14,755 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43955671854994516, 'Total loss': 0.43955671854994516} | train loss {'Reaction outcome loss': 0.3259650816017317, 'Total loss': 0.3259650816017317}
2022-11-28 03:37:14,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:14,755 INFO:     Epoch: 44
2022-11-28 03:37:15,507 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.427630464123054, 'Total loss': 0.427630464123054} | train loss {'Reaction outcome loss': 0.34146074402294035, 'Total loss': 0.34146074402294035}
2022-11-28 03:37:15,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:15,507 INFO:     Epoch: 45
2022-11-28 03:37:16,257 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4338763423941352, 'Total loss': 0.4338763423941352} | train loss {'Reaction outcome loss': 0.33225638386209, 'Total loss': 0.33225638386209}
2022-11-28 03:37:16,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:16,257 INFO:     Epoch: 46
2022-11-28 03:37:17,008 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43045442923903465, 'Total loss': 0.43045442923903465} | train loss {'Reaction outcome loss': 0.34165854540183155, 'Total loss': 0.34165854540183155}
2022-11-28 03:37:17,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:17,008 INFO:     Epoch: 47
2022-11-28 03:37:17,762 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4051981341432441, 'Total loss': 0.4051981341432441} | train loss {'Reaction outcome loss': 0.32893555351959064, 'Total loss': 0.32893555351959064}
2022-11-28 03:37:17,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:17,762 INFO:     Epoch: 48
2022-11-28 03:37:18,514 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40370866520838306, 'Total loss': 0.40370866520838306} | train loss {'Reaction outcome loss': 0.33320534956096654, 'Total loss': 0.33320534956096654}
2022-11-28 03:37:18,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:18,514 INFO:     Epoch: 49
2022-11-28 03:37:19,265 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42665917561812833, 'Total loss': 0.42665917561812833} | train loss {'Reaction outcome loss': 0.3265817748224325, 'Total loss': 0.3265817748224325}
2022-11-28 03:37:19,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:19,266 INFO:     Epoch: 50
2022-11-28 03:37:20,019 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43109083378856833, 'Total loss': 0.43109083378856833} | train loss {'Reaction outcome loss': 0.32307308709634436, 'Total loss': 0.32307308709634436}
2022-11-28 03:37:20,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:20,019 INFO:     Epoch: 51
2022-11-28 03:37:20,772 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41571537540717557, 'Total loss': 0.41571537540717557} | train loss {'Reaction outcome loss': 0.3370542292019375, 'Total loss': 0.3370542292019375}
2022-11-28 03:37:20,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:20,773 INFO:     Epoch: 52
2022-11-28 03:37:21,525 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4187359119003469, 'Total loss': 0.4187359119003469} | train loss {'Reaction outcome loss': 0.32770915106240556, 'Total loss': 0.32770915106240556}
2022-11-28 03:37:21,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:21,526 INFO:     Epoch: 53
2022-11-28 03:37:22,275 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3999905904585665, 'Total loss': 0.3999905904585665} | train loss {'Reaction outcome loss': 0.32813791805493686, 'Total loss': 0.32813791805493686}
2022-11-28 03:37:22,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:22,275 INFO:     Epoch: 54
2022-11-28 03:37:23,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4091825762086294, 'Total loss': 0.4091825762086294} | train loss {'Reaction outcome loss': 0.3246637859385506, 'Total loss': 0.3246637859385506}
2022-11-28 03:37:23,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:23,028 INFO:     Epoch: 55
2022-11-28 03:37:23,780 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44274810227480804, 'Total loss': 0.44274810227480804} | train loss {'Reaction outcome loss': 0.3292197335194721, 'Total loss': 0.3292197335194721}
2022-11-28 03:37:23,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:23,780 INFO:     Epoch: 56
2022-11-28 03:37:24,533 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4131005880507556, 'Total loss': 0.4131005880507556} | train loss {'Reaction outcome loss': 0.33266366885499915, 'Total loss': 0.33266366885499915}
2022-11-28 03:37:24,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:24,534 INFO:     Epoch: 57
2022-11-28 03:37:25,290 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41268339549953287, 'Total loss': 0.41268339549953287} | train loss {'Reaction outcome loss': 0.32515890869172476, 'Total loss': 0.32515890869172476}
2022-11-28 03:37:25,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:25,291 INFO:     Epoch: 58
2022-11-28 03:37:26,043 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4016193649308248, 'Total loss': 0.4016193649308248} | train loss {'Reaction outcome loss': 0.31989088377006625, 'Total loss': 0.31989088377006625}
2022-11-28 03:37:26,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:26,043 INFO:     Epoch: 59
2022-11-28 03:37:26,794 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.426400884647261, 'Total loss': 0.426400884647261} | train loss {'Reaction outcome loss': 0.3367012653213281, 'Total loss': 0.3367012653213281}
2022-11-28 03:37:26,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:26,794 INFO:     Epoch: 60
2022-11-28 03:37:27,546 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.409255157478831, 'Total loss': 0.409255157478831} | train loss {'Reaction outcome loss': 0.32269945214709894, 'Total loss': 0.32269945214709894}
2022-11-28 03:37:27,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:27,546 INFO:     Epoch: 61
2022-11-28 03:37:28,298 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4285680949687958, 'Total loss': 0.4285680949687958} | train loss {'Reaction outcome loss': 0.3208655860738806, 'Total loss': 0.3208655860738806}
2022-11-28 03:37:28,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:28,299 INFO:     Epoch: 62
2022-11-28 03:37:29,051 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41584807532754814, 'Total loss': 0.41584807532754814} | train loss {'Reaction outcome loss': 0.3170016712625982, 'Total loss': 0.3170016712625982}
2022-11-28 03:37:29,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:29,051 INFO:     Epoch: 63
2022-11-28 03:37:29,799 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4283807193013755, 'Total loss': 0.4283807193013755} | train loss {'Reaction outcome loss': 0.3187422138838633, 'Total loss': 0.3187422138838633}
2022-11-28 03:37:29,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:29,799 INFO:     Epoch: 64
2022-11-28 03:37:30,550 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4079446003518321, 'Total loss': 0.4079446003518321} | train loss {'Reaction outcome loss': 0.3210683100317654, 'Total loss': 0.3210683100317654}
2022-11-28 03:37:30,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:30,550 INFO:     Epoch: 65
2022-11-28 03:37:31,301 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43346431698988785, 'Total loss': 0.43346431698988785} | train loss {'Reaction outcome loss': 0.32194355579643597, 'Total loss': 0.32194355579643597}
2022-11-28 03:37:31,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:31,301 INFO:     Epoch: 66
2022-11-28 03:37:32,054 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43535893749107013, 'Total loss': 0.43535893749107013} | train loss {'Reaction outcome loss': 0.3394180489817129, 'Total loss': 0.3394180489817129}
2022-11-28 03:37:32,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:32,055 INFO:     Epoch: 67
2022-11-28 03:37:32,811 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4101910706270825, 'Total loss': 0.4101910706270825} | train loss {'Reaction outcome loss': 0.3138089689137678, 'Total loss': 0.3138089689137678}
2022-11-28 03:37:32,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:32,811 INFO:     Epoch: 68
2022-11-28 03:37:33,561 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4201708734035492, 'Total loss': 0.4201708734035492} | train loss {'Reaction outcome loss': 0.31888288065971643, 'Total loss': 0.31888288065971643}
2022-11-28 03:37:33,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:33,561 INFO:     Epoch: 69
2022-11-28 03:37:34,316 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4305616452951323, 'Total loss': 0.4305616452951323} | train loss {'Reaction outcome loss': 0.3189509811128682, 'Total loss': 0.3189509811128682}
2022-11-28 03:37:34,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:34,316 INFO:     Epoch: 70
2022-11-28 03:37:35,068 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39836852895942604, 'Total loss': 0.39836852895942604} | train loss {'Reaction outcome loss': 0.34525247279418864, 'Total loss': 0.34525247279418864}
2022-11-28 03:37:35,068 INFO:     Found new best model at epoch 70
2022-11-28 03:37:35,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:35,069 INFO:     Epoch: 71
2022-11-28 03:37:35,821 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39770030145618046, 'Total loss': 0.39770030145618046} | train loss {'Reaction outcome loss': 0.32392309660371016, 'Total loss': 0.32392309660371016}
2022-11-28 03:37:35,821 INFO:     Found new best model at epoch 71
2022-11-28 03:37:35,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:35,822 INFO:     Epoch: 72
2022-11-28 03:37:36,573 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4014333638108589, 'Total loss': 0.4014333638108589} | train loss {'Reaction outcome loss': 0.32324816576141097, 'Total loss': 0.32324816576141097}
2022-11-28 03:37:36,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:36,573 INFO:     Epoch: 73
2022-11-28 03:37:37,323 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42719220708717, 'Total loss': 0.42719220708717} | train loss {'Reaction outcome loss': 0.3286855908540579, 'Total loss': 0.3286855908540579}
2022-11-28 03:37:37,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:37,324 INFO:     Epoch: 74
2022-11-28 03:37:38,079 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4128676461563869, 'Total loss': 0.4128676461563869} | train loss {'Reaction outcome loss': 0.31799057215784, 'Total loss': 0.31799057215784}
2022-11-28 03:37:38,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:38,079 INFO:     Epoch: 75
2022-11-28 03:37:38,837 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4233584322712638, 'Total loss': 0.4233584322712638} | train loss {'Reaction outcome loss': 0.31808387120122367, 'Total loss': 0.31808387120122367}
2022-11-28 03:37:38,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:38,838 INFO:     Epoch: 76
2022-11-28 03:37:39,596 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41623313995924865, 'Total loss': 0.41623313995924865} | train loss {'Reaction outcome loss': 0.31416146618574253, 'Total loss': 0.31416146618574253}
2022-11-28 03:37:39,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:39,596 INFO:     Epoch: 77
2022-11-28 03:37:40,354 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43411690707911144, 'Total loss': 0.43411690707911144} | train loss {'Reaction outcome loss': 0.32724336499059836, 'Total loss': 0.32724336499059836}
2022-11-28 03:37:40,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:40,354 INFO:     Epoch: 78
2022-11-28 03:37:41,106 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41405406763607805, 'Total loss': 0.41405406763607805} | train loss {'Reaction outcome loss': 0.32880658609085617, 'Total loss': 0.32880658609085617}
2022-11-28 03:37:41,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:41,107 INFO:     Epoch: 79
2022-11-28 03:37:41,858 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39860477298498154, 'Total loss': 0.39860477298498154} | train loss {'Reaction outcome loss': 0.3113526529689067, 'Total loss': 0.3113526529689067}
2022-11-28 03:37:41,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:41,858 INFO:     Epoch: 80
2022-11-28 03:37:42,609 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4199536491862752, 'Total loss': 0.4199536491862752} | train loss {'Reaction outcome loss': 0.34234827020872943, 'Total loss': 0.34234827020872943}
2022-11-28 03:37:42,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:42,609 INFO:     Epoch: 81
2022-11-28 03:37:43,359 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42643393643877725, 'Total loss': 0.42643393643877725} | train loss {'Reaction outcome loss': 0.33427876188808126, 'Total loss': 0.33427876188808126}
2022-11-28 03:37:43,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:43,359 INFO:     Epoch: 82
2022-11-28 03:37:44,109 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4389211376282302, 'Total loss': 0.4389211376282302} | train loss {'Reaction outcome loss': 0.3130659745772358, 'Total loss': 0.3130659745772358}
2022-11-28 03:37:44,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:44,109 INFO:     Epoch: 83
2022-11-28 03:37:44,863 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40834207798946986, 'Total loss': 0.40834207798946986} | train loss {'Reaction outcome loss': 0.31574994715134264, 'Total loss': 0.31574994715134264}
2022-11-28 03:37:44,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:44,864 INFO:     Epoch: 84
2022-11-28 03:37:45,615 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45786491950804536, 'Total loss': 0.45786491950804536} | train loss {'Reaction outcome loss': 0.3131378894975326, 'Total loss': 0.3131378894975326}
2022-11-28 03:37:45,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:45,615 INFO:     Epoch: 85
2022-11-28 03:37:46,367 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4261695637621663, 'Total loss': 0.4261695637621663} | train loss {'Reaction outcome loss': 0.31565538672013926, 'Total loss': 0.31565538672013926}
2022-11-28 03:37:46,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:46,367 INFO:     Epoch: 86
2022-11-28 03:37:47,119 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4337353625080802, 'Total loss': 0.4337353625080802} | train loss {'Reaction outcome loss': 0.32678201952986874, 'Total loss': 0.32678201952986874}
2022-11-28 03:37:47,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:47,120 INFO:     Epoch: 87
2022-11-28 03:37:47,869 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4045514203608036, 'Total loss': 0.4045514203608036} | train loss {'Reaction outcome loss': 0.3277792694265785, 'Total loss': 0.3277792694265785}
2022-11-28 03:37:47,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:47,869 INFO:     Epoch: 88
2022-11-28 03:37:48,624 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41645419191230426, 'Total loss': 0.41645419191230426} | train loss {'Reaction outcome loss': 0.32037035728755753, 'Total loss': 0.32037035728755753}
2022-11-28 03:37:48,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:48,624 INFO:     Epoch: 89
2022-11-28 03:37:49,380 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4152158884839578, 'Total loss': 0.4152158884839578} | train loss {'Reaction outcome loss': 0.3138293002238158, 'Total loss': 0.3138293002238158}
2022-11-28 03:37:49,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:49,380 INFO:     Epoch: 90
2022-11-28 03:37:50,135 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4101394379342144, 'Total loss': 0.4101394379342144} | train loss {'Reaction outcome loss': 0.3177544303796431, 'Total loss': 0.3177544303796431}
2022-11-28 03:37:50,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:50,136 INFO:     Epoch: 91
2022-11-28 03:37:50,892 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4081487872383811, 'Total loss': 0.4081487872383811} | train loss {'Reaction outcome loss': 0.3107103276922394, 'Total loss': 0.3107103276922394}
2022-11-28 03:37:50,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:50,893 INFO:     Epoch: 92
2022-11-28 03:37:51,647 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3901607030155984, 'Total loss': 0.3901607030155984} | train loss {'Reaction outcome loss': 0.314445926075394, 'Total loss': 0.314445926075394}
2022-11-28 03:37:51,647 INFO:     Found new best model at epoch 92
2022-11-28 03:37:51,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:51,648 INFO:     Epoch: 93
2022-11-28 03:37:52,401 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4301684017885815, 'Total loss': 0.4301684017885815} | train loss {'Reaction outcome loss': 0.32070267185387824, 'Total loss': 0.32070267185387824}
2022-11-28 03:37:52,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:52,401 INFO:     Epoch: 94
2022-11-28 03:37:53,149 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3995039210739461, 'Total loss': 0.3995039210739461} | train loss {'Reaction outcome loss': 0.31127205438278466, 'Total loss': 0.31127205438278466}
2022-11-28 03:37:53,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:53,150 INFO:     Epoch: 95
2022-11-28 03:37:53,899 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4024659681387923, 'Total loss': 0.4024659681387923} | train loss {'Reaction outcome loss': 0.3258687564537593, 'Total loss': 0.3258687564537593}
2022-11-28 03:37:53,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:53,899 INFO:     Epoch: 96
2022-11-28 03:37:54,650 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.408092642033642, 'Total loss': 0.408092642033642} | train loss {'Reaction outcome loss': 0.32135687785426736, 'Total loss': 0.32135687785426736}
2022-11-28 03:37:54,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:54,650 INFO:     Epoch: 97
2022-11-28 03:37:55,401 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4518052884800868, 'Total loss': 0.4518052884800868} | train loss {'Reaction outcome loss': 0.3065311634076028, 'Total loss': 0.3065311634076028}
2022-11-28 03:37:55,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:55,401 INFO:     Epoch: 98
2022-11-28 03:37:56,153 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4170417535034093, 'Total loss': 0.4170417535034093} | train loss {'Reaction outcome loss': 0.33553913540842184, 'Total loss': 0.33553913540842184}
2022-11-28 03:37:56,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:56,153 INFO:     Epoch: 99
2022-11-28 03:37:56,904 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4492079188877886, 'Total loss': 0.4492079188877886} | train loss {'Reaction outcome loss': 0.3137110471725464, 'Total loss': 0.3137110471725464}
2022-11-28 03:37:56,904 INFO:     Best model found after epoch 93 of 100.
2022-11-28 03:37:56,905 INFO:   Done with stage: TRAINING
2022-11-28 03:37:56,905 INFO:   Starting stage: EVALUATION
2022-11-28 03:37:57,027 INFO:   Done with stage: EVALUATION
2022-11-28 03:37:57,027 INFO:   Leaving out SEQ value Fold_2
2022-11-28 03:37:57,040 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 03:37:57,040 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:37:57,673 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:37:57,673 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:37:57,741 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:37:57,742 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:37:57,742 INFO:     No hyperparam tuning for this model
2022-11-28 03:37:57,742 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:37:57,742 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:37:57,743 INFO:     None feature selector for col prot
2022-11-28 03:37:57,743 INFO:     None feature selector for col prot
2022-11-28 03:37:57,743 INFO:     None feature selector for col prot
2022-11-28 03:37:57,743 INFO:     None feature selector for col chem
2022-11-28 03:37:57,743 INFO:     None feature selector for col chem
2022-11-28 03:37:57,743 INFO:     None feature selector for col chem
2022-11-28 03:37:57,743 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:37:57,744 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:37:57,745 INFO:     Number of params in model 169741
2022-11-28 03:37:57,748 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:37:57,748 INFO:   Starting stage: TRAINING
2022-11-28 03:37:57,802 INFO:     Val loss before train {'Reaction outcome loss': 0.999868934930757, 'Total loss': 0.999868934930757}
2022-11-28 03:37:57,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:57,802 INFO:     Epoch: 0
2022-11-28 03:37:58,542 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5070158853087314, 'Total loss': 0.5070158853087314} | train loss {'Reaction outcome loss': 0.6479328998935566, 'Total loss': 0.6479328998935566}
2022-11-28 03:37:58,542 INFO:     Found new best model at epoch 0
2022-11-28 03:37:58,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:58,543 INFO:     Epoch: 1
2022-11-28 03:37:59,282 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4531439570493476, 'Total loss': 0.4531439570493476} | train loss {'Reaction outcome loss': 0.5050992641306709, 'Total loss': 0.5050992641306709}
2022-11-28 03:37:59,282 INFO:     Found new best model at epoch 1
2022-11-28 03:37:59,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:37:59,283 INFO:     Epoch: 2
2022-11-28 03:38:00,027 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45134585749271305, 'Total loss': 0.45134585749271305} | train loss {'Reaction outcome loss': 0.4659605514365459, 'Total loss': 0.4659605514365459}
2022-11-28 03:38:00,027 INFO:     Found new best model at epoch 2
2022-11-28 03:38:00,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:00,028 INFO:     Epoch: 3
2022-11-28 03:38:00,769 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46415855025136193, 'Total loss': 0.46415855025136193} | train loss {'Reaction outcome loss': 0.4506760789656345, 'Total loss': 0.4506760789656345}
2022-11-28 03:38:00,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:00,770 INFO:     Epoch: 4
2022-11-28 03:38:01,514 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4597903112339419, 'Total loss': 0.4597903112339419} | train loss {'Reaction outcome loss': 0.42652854734242207, 'Total loss': 0.42652854734242207}
2022-11-28 03:38:01,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:01,514 INFO:     Epoch: 5
2022-11-28 03:38:02,254 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4360415928585585, 'Total loss': 0.4360415928585585} | train loss {'Reaction outcome loss': 0.4225448628144009, 'Total loss': 0.4225448628144009}
2022-11-28 03:38:02,254 INFO:     Found new best model at epoch 5
2022-11-28 03:38:02,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:02,255 INFO:     Epoch: 6
2022-11-28 03:38:02,996 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4304983615875244, 'Total loss': 0.4304983615875244} | train loss {'Reaction outcome loss': 0.4026596532375724, 'Total loss': 0.4026596532375724}
2022-11-28 03:38:02,997 INFO:     Found new best model at epoch 6
2022-11-28 03:38:02,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:02,998 INFO:     Epoch: 7
2022-11-28 03:38:03,737 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4153544861216878, 'Total loss': 0.4153544861216878} | train loss {'Reaction outcome loss': 0.3992262534766531, 'Total loss': 0.3992262534766531}
2022-11-28 03:38:03,737 INFO:     Found new best model at epoch 7
2022-11-28 03:38:03,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:03,738 INFO:     Epoch: 8
2022-11-28 03:38:04,482 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4564004256281742, 'Total loss': 0.4564004256281742} | train loss {'Reaction outcome loss': 0.3868561584517789, 'Total loss': 0.3868561584517789}
2022-11-28 03:38:04,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:04,482 INFO:     Epoch: 9
2022-11-28 03:38:05,222 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4410319986731507, 'Total loss': 0.4410319986731507} | train loss {'Reaction outcome loss': 0.3781812175985717, 'Total loss': 0.3781812175985717}
2022-11-28 03:38:05,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:05,222 INFO:     Epoch: 10
2022-11-28 03:38:05,965 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46654599974321764, 'Total loss': 0.46654599974321764} | train loss {'Reaction outcome loss': 0.37245125844768046, 'Total loss': 0.37245125844768046}
2022-11-28 03:38:05,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:05,965 INFO:     Epoch: 11
2022-11-28 03:38:06,709 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41413177376569704, 'Total loss': 0.41413177376569704} | train loss {'Reaction outcome loss': 0.37354301707244214, 'Total loss': 0.37354301707244214}
2022-11-28 03:38:06,709 INFO:     Found new best model at epoch 11
2022-11-28 03:38:06,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:06,710 INFO:     Epoch: 12
2022-11-28 03:38:07,446 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43705659619597503, 'Total loss': 0.43705659619597503} | train loss {'Reaction outcome loss': 0.36340558127243333, 'Total loss': 0.36340558127243333}
2022-11-28 03:38:07,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:07,446 INFO:     Epoch: 13
2022-11-28 03:38:08,184 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4198201735352361, 'Total loss': 0.4198201735352361} | train loss {'Reaction outcome loss': 0.36076989245635493, 'Total loss': 0.36076989245635493}
2022-11-28 03:38:08,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:08,184 INFO:     Epoch: 14
2022-11-28 03:38:08,923 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4165146295414415, 'Total loss': 0.4165146295414415} | train loss {'Reaction outcome loss': 0.366806247536047, 'Total loss': 0.366806247536047}
2022-11-28 03:38:08,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:08,924 INFO:     Epoch: 15
2022-11-28 03:38:09,662 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46384843768075457, 'Total loss': 0.46384843768075457} | train loss {'Reaction outcome loss': 0.36175277945681367, 'Total loss': 0.36175277945681367}
2022-11-28 03:38:09,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:09,662 INFO:     Epoch: 16
2022-11-28 03:38:10,398 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4611186520304791, 'Total loss': 0.4611186520304791} | train loss {'Reaction outcome loss': 0.3494718825988809, 'Total loss': 0.3494718825988809}
2022-11-28 03:38:10,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:10,398 INFO:     Epoch: 17
2022-11-28 03:38:11,137 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4132124091996703, 'Total loss': 0.4132124091996703} | train loss {'Reaction outcome loss': 0.3567007925100778, 'Total loss': 0.3567007925100778}
2022-11-28 03:38:11,137 INFO:     Found new best model at epoch 17
2022-11-28 03:38:11,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:11,138 INFO:     Epoch: 18
2022-11-28 03:38:11,877 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4382872841385908, 'Total loss': 0.4382872841385908} | train loss {'Reaction outcome loss': 0.34280168136328826, 'Total loss': 0.34280168136328826}
2022-11-28 03:38:11,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:11,877 INFO:     Epoch: 19
2022-11-28 03:38:12,615 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43384042728778927, 'Total loss': 0.43384042728778927} | train loss {'Reaction outcome loss': 0.34421285441137633, 'Total loss': 0.34421285441137633}
2022-11-28 03:38:12,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:12,615 INFO:     Epoch: 20
2022-11-28 03:38:13,355 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4223865923839946, 'Total loss': 0.4223865923839946} | train loss {'Reaction outcome loss': 0.3429976803683695, 'Total loss': 0.3429976803683695}
2022-11-28 03:38:13,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:13,355 INFO:     Epoch: 21
2022-11-28 03:38:14,094 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43792228487341905, 'Total loss': 0.43792228487341905} | train loss {'Reaction outcome loss': 0.34583214710278765, 'Total loss': 0.34583214710278765}
2022-11-28 03:38:14,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:14,094 INFO:     Epoch: 22
2022-11-28 03:38:14,834 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.409391455179037, 'Total loss': 0.409391455179037} | train loss {'Reaction outcome loss': 0.3385728991632599, 'Total loss': 0.3385728991632599}
2022-11-28 03:38:14,834 INFO:     Found new best model at epoch 22
2022-11-28 03:38:14,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:14,835 INFO:     Epoch: 23
2022-11-28 03:38:15,577 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45485445753086445, 'Total loss': 0.45485445753086445} | train loss {'Reaction outcome loss': 0.32758109700777893, 'Total loss': 0.32758109700777893}
2022-11-28 03:38:15,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:15,577 INFO:     Epoch: 24
2022-11-28 03:38:16,317 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4146038695823315, 'Total loss': 0.4146038695823315} | train loss {'Reaction outcome loss': 0.3329415233966745, 'Total loss': 0.3329415233966745}
2022-11-28 03:38:16,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:16,317 INFO:     Epoch: 25
2022-11-28 03:38:17,056 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4246151118084442, 'Total loss': 0.4246151118084442} | train loss {'Reaction outcome loss': 0.3358425461369042, 'Total loss': 0.3358425461369042}
2022-11-28 03:38:17,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:17,057 INFO:     Epoch: 26
2022-11-28 03:38:17,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42853055305259175, 'Total loss': 0.42853055305259175} | train loss {'Reaction outcome loss': 0.3355783433519273, 'Total loss': 0.3355783433519273}
2022-11-28 03:38:17,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:17,799 INFO:     Epoch: 27
2022-11-28 03:38:18,539 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4318050731753194, 'Total loss': 0.4318050731753194} | train loss {'Reaction outcome loss': 0.3309931635488699, 'Total loss': 0.3309931635488699}
2022-11-28 03:38:18,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:18,539 INFO:     Epoch: 28
2022-11-28 03:38:19,281 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41735209455323774, 'Total loss': 0.41735209455323774} | train loss {'Reaction outcome loss': 0.33082179075160634, 'Total loss': 0.33082179075160634}
2022-11-28 03:38:19,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:19,281 INFO:     Epoch: 29
2022-11-28 03:38:20,025 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40060503850149554, 'Total loss': 0.40060503850149554} | train loss {'Reaction outcome loss': 0.3230847124884158, 'Total loss': 0.3230847124884158}
2022-11-28 03:38:20,026 INFO:     Found new best model at epoch 29
2022-11-28 03:38:20,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:20,026 INFO:     Epoch: 30
2022-11-28 03:38:20,766 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4041099978047748, 'Total loss': 0.4041099978047748} | train loss {'Reaction outcome loss': 0.3233598462102835, 'Total loss': 0.3233598462102835}
2022-11-28 03:38:20,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:20,766 INFO:     Epoch: 31
2022-11-28 03:38:21,506 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4006874024174934, 'Total loss': 0.4006874024174934} | train loss {'Reaction outcome loss': 0.3240055426525972, 'Total loss': 0.3240055426525972}
2022-11-28 03:38:21,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:21,507 INFO:     Epoch: 32
2022-11-28 03:38:22,243 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4277425224697867, 'Total loss': 0.4277425224697867} | train loss {'Reaction outcome loss': 0.31955057270671605, 'Total loss': 0.31955057270671605}
2022-11-28 03:38:22,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:22,244 INFO:     Epoch: 33
2022-11-28 03:38:22,982 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42453422276086583, 'Total loss': 0.42453422276086583} | train loss {'Reaction outcome loss': 0.3249549970276071, 'Total loss': 0.3249549970276071}
2022-11-28 03:38:22,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:22,982 INFO:     Epoch: 34
2022-11-28 03:38:23,720 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40966679658307587, 'Total loss': 0.40966679658307587} | train loss {'Reaction outcome loss': 0.32665254187927323, 'Total loss': 0.32665254187927323}
2022-11-28 03:38:23,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:23,720 INFO:     Epoch: 35
2022-11-28 03:38:24,458 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40027825465035993, 'Total loss': 0.40027825465035993} | train loss {'Reaction outcome loss': 0.3235842497260482, 'Total loss': 0.3235842497260482}
2022-11-28 03:38:24,458 INFO:     Found new best model at epoch 35
2022-11-28 03:38:24,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:24,459 INFO:     Epoch: 36
2022-11-28 03:38:25,198 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43721729447675306, 'Total loss': 0.43721729447675306} | train loss {'Reaction outcome loss': 0.3219044719335964, 'Total loss': 0.3219044719335964}
2022-11-28 03:38:25,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:25,198 INFO:     Epoch: 37
2022-11-28 03:38:25,933 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44377340826877326, 'Total loss': 0.44377340826877326} | train loss {'Reaction outcome loss': 0.3194389209887128, 'Total loss': 0.3194389209887128}
2022-11-28 03:38:25,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:25,933 INFO:     Epoch: 38
2022-11-28 03:38:26,668 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40315439188203145, 'Total loss': 0.40315439188203145} | train loss {'Reaction outcome loss': 0.3222127375288755, 'Total loss': 0.3222127375288755}
2022-11-28 03:38:26,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:26,668 INFO:     Epoch: 39
2022-11-28 03:38:27,402 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41650419838206715, 'Total loss': 0.41650419838206715} | train loss {'Reaction outcome loss': 0.31952675217341003, 'Total loss': 0.31952675217341003}
2022-11-28 03:38:27,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:27,403 INFO:     Epoch: 40
2022-11-28 03:38:28,137 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4313686063816381, 'Total loss': 0.4313686063816381} | train loss {'Reaction outcome loss': 0.31901779816842374, 'Total loss': 0.31901779816842374}
2022-11-28 03:38:28,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:28,137 INFO:     Epoch: 41
2022-11-28 03:38:28,871 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4227810897106348, 'Total loss': 0.4227810897106348} | train loss {'Reaction outcome loss': 0.3218798871638844, 'Total loss': 0.3218798871638844}
2022-11-28 03:38:28,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:28,871 INFO:     Epoch: 42
2022-11-28 03:38:29,607 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4521333284156267, 'Total loss': 0.4521333284156267} | train loss {'Reaction outcome loss': 0.32272233924380056, 'Total loss': 0.32272233924380056}
2022-11-28 03:38:29,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:29,607 INFO:     Epoch: 43
2022-11-28 03:38:30,341 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4353925036483033, 'Total loss': 0.4353925036483033} | train loss {'Reaction outcome loss': 0.32034770276688745, 'Total loss': 0.32034770276688745}
2022-11-28 03:38:30,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:30,341 INFO:     Epoch: 44
2022-11-28 03:38:31,080 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43617912832387656, 'Total loss': 0.43617912832387656} | train loss {'Reaction outcome loss': 0.31530738680205717, 'Total loss': 0.31530738680205717}
2022-11-28 03:38:31,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:31,080 INFO:     Epoch: 45
2022-11-28 03:38:31,811 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.400745369320692, 'Total loss': 0.400745369320692} | train loss {'Reaction outcome loss': 0.3223607321825538, 'Total loss': 0.3223607321825538}
2022-11-28 03:38:31,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:31,811 INFO:     Epoch: 46
2022-11-28 03:38:32,546 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4472218051899311, 'Total loss': 0.4472218051899311} | train loss {'Reaction outcome loss': 0.3067502409771637, 'Total loss': 0.3067502409771637}
2022-11-28 03:38:32,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:32,546 INFO:     Epoch: 47
2022-11-28 03:38:33,284 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41228048953899116, 'Total loss': 0.41228048953899116} | train loss {'Reaction outcome loss': 0.3177683779609547, 'Total loss': 0.3177683779609547}
2022-11-28 03:38:33,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:33,284 INFO:     Epoch: 48
2022-11-28 03:38:34,020 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41142884000789287, 'Total loss': 0.41142884000789287} | train loss {'Reaction outcome loss': 0.3217795367195528, 'Total loss': 0.3217795367195528}
2022-11-28 03:38:34,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:34,021 INFO:     Epoch: 49
2022-11-28 03:38:34,759 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40931977296984473, 'Total loss': 0.40931977296984473} | train loss {'Reaction outcome loss': 0.32425340528718727, 'Total loss': 0.32425340528718727}
2022-11-28 03:38:34,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:34,760 INFO:     Epoch: 50
2022-11-28 03:38:35,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41404406864975773, 'Total loss': 0.41404406864975773} | train loss {'Reaction outcome loss': 0.30772119052248237, 'Total loss': 0.30772119052248237}
2022-11-28 03:38:35,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:35,495 INFO:     Epoch: 51
2022-11-28 03:38:36,229 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4006397388009138, 'Total loss': 0.4006397388009138} | train loss {'Reaction outcome loss': 0.3168977109002478, 'Total loss': 0.3168977109002478}
2022-11-28 03:38:36,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:36,229 INFO:     Epoch: 52
2022-11-28 03:38:36,963 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44846248765324437, 'Total loss': 0.44846248765324437} | train loss {'Reaction outcome loss': 0.3069682705978798, 'Total loss': 0.3069682705978798}
2022-11-28 03:38:36,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:36,963 INFO:     Epoch: 53
2022-11-28 03:38:37,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4380948186613793, 'Total loss': 0.4380948186613793} | train loss {'Reaction outcome loss': 0.3124935535001166, 'Total loss': 0.3124935535001166}
2022-11-28 03:38:37,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:37,699 INFO:     Epoch: 54
2022-11-28 03:38:38,437 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4282121086536452, 'Total loss': 0.4282121086536452} | train loss {'Reaction outcome loss': 0.3114655153373632, 'Total loss': 0.3114655153373632}
2022-11-28 03:38:38,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:38,437 INFO:     Epoch: 55
2022-11-28 03:38:39,173 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42015016737372374, 'Total loss': 0.42015016737372374} | train loss {'Reaction outcome loss': 0.30757656488031027, 'Total loss': 0.30757656488031027}
2022-11-28 03:38:39,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:39,173 INFO:     Epoch: 56
2022-11-28 03:38:39,911 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45140753409197165, 'Total loss': 0.45140753409197165} | train loss {'Reaction outcome loss': 0.3077616717344449, 'Total loss': 0.3077616717344449}
2022-11-28 03:38:39,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:39,911 INFO:     Epoch: 57
2022-11-28 03:38:40,648 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4035295760908792, 'Total loss': 0.4035295760908792} | train loss {'Reaction outcome loss': 0.3027720825570356, 'Total loss': 0.3027720825570356}
2022-11-28 03:38:40,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:40,649 INFO:     Epoch: 58
2022-11-28 03:38:41,385 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43779767044754914, 'Total loss': 0.43779767044754914} | train loss {'Reaction outcome loss': 0.30952874957411375, 'Total loss': 0.30952874957411375}
2022-11-28 03:38:41,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:41,386 INFO:     Epoch: 59
2022-11-28 03:38:42,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41751291585523026, 'Total loss': 0.41751291585523026} | train loss {'Reaction outcome loss': 0.3110452716855846, 'Total loss': 0.3110452716855846}
2022-11-28 03:38:42,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:42,123 INFO:     Epoch: 60
2022-11-28 03:38:42,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40736875665742295, 'Total loss': 0.40736875665742295} | train loss {'Reaction outcome loss': 0.31599655048346814, 'Total loss': 0.31599655048346814}
2022-11-28 03:38:42,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:42,859 INFO:     Epoch: 61
2022-11-28 03:38:43,596 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44381606717442357, 'Total loss': 0.44381606717442357} | train loss {'Reaction outcome loss': 0.3052716483381182, 'Total loss': 0.3052716483381182}
2022-11-28 03:38:43,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:43,596 INFO:     Epoch: 62
2022-11-28 03:38:44,333 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39651046831940495, 'Total loss': 0.39651046831940495} | train loss {'Reaction outcome loss': 0.3112736775466996, 'Total loss': 0.3112736775466996}
2022-11-28 03:38:44,333 INFO:     Found new best model at epoch 62
2022-11-28 03:38:44,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:44,334 INFO:     Epoch: 63
2022-11-28 03:38:45,070 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43338297099568124, 'Total loss': 0.43338297099568124} | train loss {'Reaction outcome loss': 0.29913042786190047, 'Total loss': 0.29913042786190047}
2022-11-28 03:38:45,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:45,070 INFO:     Epoch: 64
2022-11-28 03:38:45,804 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3928232286558595, 'Total loss': 0.3928232286558595} | train loss {'Reaction outcome loss': 0.31019887975091304, 'Total loss': 0.31019887975091304}
2022-11-28 03:38:45,804 INFO:     Found new best model at epoch 64
2022-11-28 03:38:45,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:45,805 INFO:     Epoch: 65
2022-11-28 03:38:46,542 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4043731634006944, 'Total loss': 0.4043731634006944} | train loss {'Reaction outcome loss': 0.30970534427789015, 'Total loss': 0.30970534427789015}
2022-11-28 03:38:46,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:46,542 INFO:     Epoch: 66
2022-11-28 03:38:47,278 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41509068809276406, 'Total loss': 0.41509068809276406} | train loss {'Reaction outcome loss': 0.3104032377708596, 'Total loss': 0.3104032377708596}
2022-11-28 03:38:47,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:47,279 INFO:     Epoch: 67
2022-11-28 03:38:48,012 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.439894582989604, 'Total loss': 0.439894582989604} | train loss {'Reaction outcome loss': 0.30872327540023825, 'Total loss': 0.30872327540023825}
2022-11-28 03:38:48,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:48,013 INFO:     Epoch: 68
2022-11-28 03:38:48,750 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39468254842037376, 'Total loss': 0.39468254842037376} | train loss {'Reaction outcome loss': 0.31095813113598175, 'Total loss': 0.31095813113598175}
2022-11-28 03:38:48,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:48,751 INFO:     Epoch: 69
2022-11-28 03:38:49,486 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41424927912479226, 'Total loss': 0.41424927912479226} | train loss {'Reaction outcome loss': 0.3007974228495924, 'Total loss': 0.3007974228495924}
2022-11-28 03:38:49,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:49,486 INFO:     Epoch: 70
2022-11-28 03:38:50,223 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4419799228740293, 'Total loss': 0.4419799228740293} | train loss {'Reaction outcome loss': 0.30834981037204157, 'Total loss': 0.30834981037204157}
2022-11-28 03:38:50,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:50,223 INFO:     Epoch: 71
2022-11-28 03:38:50,959 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4200038251488708, 'Total loss': 0.4200038251488708} | train loss {'Reaction outcome loss': 0.3123680760647044, 'Total loss': 0.3123680760647044}
2022-11-28 03:38:50,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:50,960 INFO:     Epoch: 72
2022-11-28 03:38:51,699 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4015195671209069, 'Total loss': 0.4015195671209069} | train loss {'Reaction outcome loss': 0.3194111880880815, 'Total loss': 0.3194111880880815}
2022-11-28 03:38:51,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:51,700 INFO:     Epoch: 73
2022-11-28 03:38:52,438 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4084004527607629, 'Total loss': 0.4084004527607629} | train loss {'Reaction outcome loss': 0.30061191394005293, 'Total loss': 0.30061191394005293}
2022-11-28 03:38:52,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:52,438 INFO:     Epoch: 74
2022-11-28 03:38:53,178 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41719623863003974, 'Total loss': 0.41719623863003974} | train loss {'Reaction outcome loss': 0.2910350483263471, 'Total loss': 0.2910350483263471}
2022-11-28 03:38:53,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:53,179 INFO:     Epoch: 75
2022-11-28 03:38:53,914 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40996702396592427, 'Total loss': 0.40996702396592427} | train loss {'Reaction outcome loss': 0.30551458754166655, 'Total loss': 0.30551458754166655}
2022-11-28 03:38:53,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:53,914 INFO:     Epoch: 76
2022-11-28 03:38:54,646 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43856111792630925, 'Total loss': 0.43856111792630925} | train loss {'Reaction outcome loss': 0.2964272873299848, 'Total loss': 0.2964272873299848}
2022-11-28 03:38:54,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:54,646 INFO:     Epoch: 77
2022-11-28 03:38:55,379 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4491066894558973, 'Total loss': 0.4491066894558973} | train loss {'Reaction outcome loss': 0.3100257505482607, 'Total loss': 0.3100257505482607}
2022-11-28 03:38:55,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:55,379 INFO:     Epoch: 78
2022-11-28 03:38:56,109 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45389409709808437, 'Total loss': 0.45389409709808437} | train loss {'Reaction outcome loss': 0.30108938962527754, 'Total loss': 0.30108938962527754}
2022-11-28 03:38:56,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:56,109 INFO:     Epoch: 79
2022-11-28 03:38:56,838 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4380916000105614, 'Total loss': 0.4380916000105614} | train loss {'Reaction outcome loss': 0.3089187294244766, 'Total loss': 0.3089187294244766}
2022-11-28 03:38:56,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:56,839 INFO:     Epoch: 80
2022-11-28 03:38:57,571 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42439613473969834, 'Total loss': 0.42439613473969834} | train loss {'Reaction outcome loss': 0.3032304132702174, 'Total loss': 0.3032304132702174}
2022-11-28 03:38:57,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:57,571 INFO:     Epoch: 81
2022-11-28 03:38:58,305 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4342248678900475, 'Total loss': 0.4342248678900475} | train loss {'Reaction outcome loss': 0.3200679551733374, 'Total loss': 0.3200679551733374}
2022-11-28 03:38:58,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:58,305 INFO:     Epoch: 82
2022-11-28 03:38:59,035 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41190848638151967, 'Total loss': 0.41190848638151967} | train loss {'Reaction outcome loss': 0.29305781543622783, 'Total loss': 0.29305781543622783}
2022-11-28 03:38:59,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:59,036 INFO:     Epoch: 83
2022-11-28 03:38:59,765 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4139346428388773, 'Total loss': 0.4139346428388773} | train loss {'Reaction outcome loss': 0.31163787397214904, 'Total loss': 0.31163787397214904}
2022-11-28 03:38:59,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:38:59,766 INFO:     Epoch: 84
2022-11-28 03:39:00,497 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4075134840122489, 'Total loss': 0.4075134840122489} | train loss {'Reaction outcome loss': 0.3110296852856016, 'Total loss': 0.3110296852856016}
2022-11-28 03:39:00,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:00,497 INFO:     Epoch: 85
2022-11-28 03:39:01,228 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41313051553659663, 'Total loss': 0.41313051553659663} | train loss {'Reaction outcome loss': 0.30609533540260647, 'Total loss': 0.30609533540260647}
2022-11-28 03:39:01,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:01,228 INFO:     Epoch: 86
2022-11-28 03:39:01,958 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41609476541363916, 'Total loss': 0.41609476541363916} | train loss {'Reaction outcome loss': 0.30705846358596545, 'Total loss': 0.30705846358596545}
2022-11-28 03:39:01,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:01,958 INFO:     Epoch: 87
2022-11-28 03:39:02,688 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3810321556967358, 'Total loss': 0.3810321556967358} | train loss {'Reaction outcome loss': 0.30988118757681593, 'Total loss': 0.30988118757681593}
2022-11-28 03:39:02,688 INFO:     Found new best model at epoch 87
2022-11-28 03:39:02,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:02,689 INFO:     Epoch: 88
2022-11-28 03:39:03,423 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41873531909876094, 'Total loss': 0.41873531909876094} | train loss {'Reaction outcome loss': 0.3124603141145206, 'Total loss': 0.3124603141145206}
2022-11-28 03:39:03,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:03,423 INFO:     Epoch: 89
2022-11-28 03:39:04,157 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4186835971682571, 'Total loss': 0.4186835971682571} | train loss {'Reaction outcome loss': 0.3035947046407456, 'Total loss': 0.3035947046407456}
2022-11-28 03:39:04,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:04,158 INFO:     Epoch: 90
2022-11-28 03:39:04,890 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41761696234691975, 'Total loss': 0.41761696234691975} | train loss {'Reaction outcome loss': 0.3080235877890646, 'Total loss': 0.3080235877890646}
2022-11-28 03:39:04,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:04,891 INFO:     Epoch: 91
2022-11-28 03:39:05,624 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43029546356478404, 'Total loss': 0.43029546356478404} | train loss {'Reaction outcome loss': 0.30551346555474856, 'Total loss': 0.30551346555474856}
2022-11-28 03:39:05,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:05,624 INFO:     Epoch: 92
2022-11-28 03:39:06,357 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4297494954148004, 'Total loss': 0.4297494954148004} | train loss {'Reaction outcome loss': 0.3034615675792282, 'Total loss': 0.3034615675792282}
2022-11-28 03:39:06,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:06,357 INFO:     Epoch: 93
2022-11-28 03:39:07,091 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4351017755824466, 'Total loss': 0.4351017755824466} | train loss {'Reaction outcome loss': 0.29713981802510137, 'Total loss': 0.29713981802510137}
2022-11-28 03:39:07,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:07,091 INFO:     Epoch: 94
2022-11-28 03:39:07,828 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4071022071117579, 'Total loss': 0.4071022071117579} | train loss {'Reaction outcome loss': 0.301186003649431, 'Total loss': 0.301186003649431}
2022-11-28 03:39:07,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:07,828 INFO:     Epoch: 95
2022-11-28 03:39:08,560 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43033218175865884, 'Total loss': 0.43033218175865884} | train loss {'Reaction outcome loss': 0.3064126172122151, 'Total loss': 0.3064126172122151}
2022-11-28 03:39:08,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:08,560 INFO:     Epoch: 96
2022-11-28 03:39:09,293 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45269115217203315, 'Total loss': 0.45269115217203315} | train loss {'Reaction outcome loss': 0.3097329159332401, 'Total loss': 0.3097329159332401}
2022-11-28 03:39:09,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:09,293 INFO:     Epoch: 97
2022-11-28 03:39:10,027 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40522207943506017, 'Total loss': 0.40522207943506017} | train loss {'Reaction outcome loss': 0.3096859427820508, 'Total loss': 0.3096859427820508}
2022-11-28 03:39:10,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:10,027 INFO:     Epoch: 98
2022-11-28 03:39:10,758 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3916207021752069, 'Total loss': 0.3916207021752069} | train loss {'Reaction outcome loss': 0.31082241551437007, 'Total loss': 0.31082241551437007}
2022-11-28 03:39:10,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:10,758 INFO:     Epoch: 99
2022-11-28 03:39:11,492 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4074474122635154, 'Total loss': 0.4074474122635154} | train loss {'Reaction outcome loss': 0.30257660058545477, 'Total loss': 0.30257660058545477}
2022-11-28 03:39:11,492 INFO:     Best model found after epoch 88 of 100.
2022-11-28 03:39:11,492 INFO:   Done with stage: TRAINING
2022-11-28 03:39:11,493 INFO:   Starting stage: EVALUATION
2022-11-28 03:39:11,630 INFO:   Done with stage: EVALUATION
2022-11-28 03:39:11,631 INFO:   Leaving out SEQ value Fold_3
2022-11-28 03:39:11,644 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 03:39:11,644 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:39:12,271 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:39:12,271 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:39:12,338 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:39:12,338 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:39:12,338 INFO:     No hyperparam tuning for this model
2022-11-28 03:39:12,338 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:39:12,338 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:39:12,339 INFO:     None feature selector for col prot
2022-11-28 03:39:12,339 INFO:     None feature selector for col prot
2022-11-28 03:39:12,339 INFO:     None feature selector for col prot
2022-11-28 03:39:12,339 INFO:     None feature selector for col chem
2022-11-28 03:39:12,340 INFO:     None feature selector for col chem
2022-11-28 03:39:12,340 INFO:     None feature selector for col chem
2022-11-28 03:39:12,340 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:39:12,340 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:39:12,341 INFO:     Number of params in model 169741
2022-11-28 03:39:12,344 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:39:12,344 INFO:   Starting stage: TRAINING
2022-11-28 03:39:12,397 INFO:     Val loss before train {'Reaction outcome loss': 1.0727835602538531, 'Total loss': 1.0727835602538531}
2022-11-28 03:39:12,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:12,397 INFO:     Epoch: 0
2022-11-28 03:39:13,131 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5749583542346954, 'Total loss': 0.5749583542346954} | train loss {'Reaction outcome loss': 0.626999595160347, 'Total loss': 0.626999595160347}
2022-11-28 03:39:13,131 INFO:     Found new best model at epoch 0
2022-11-28 03:39:13,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:13,132 INFO:     Epoch: 1
2022-11-28 03:39:13,865 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5008517146803612, 'Total loss': 0.5008517146803612} | train loss {'Reaction outcome loss': 0.48354268435833386, 'Total loss': 0.48354268435833386}
2022-11-28 03:39:13,865 INFO:     Found new best model at epoch 1
2022-11-28 03:39:13,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:13,866 INFO:     Epoch: 2
2022-11-28 03:39:14,600 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5257888637309851, 'Total loss': 0.5257888637309851} | train loss {'Reaction outcome loss': 0.4548913541828654, 'Total loss': 0.4548913541828654}
2022-11-28 03:39:14,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:14,601 INFO:     Epoch: 3
2022-11-28 03:39:15,333 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4889665204425191, 'Total loss': 0.4889665204425191} | train loss {'Reaction outcome loss': 0.43690986367164814, 'Total loss': 0.43690986367164814}
2022-11-28 03:39:15,333 INFO:     Found new best model at epoch 3
2022-11-28 03:39:15,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:15,334 INFO:     Epoch: 4
2022-11-28 03:39:16,063 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4714010503402976, 'Total loss': 0.4714010503402976} | train loss {'Reaction outcome loss': 0.42033109976430977, 'Total loss': 0.42033109976430977}
2022-11-28 03:39:16,063 INFO:     Found new best model at epoch 4
2022-11-28 03:39:16,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:16,064 INFO:     Epoch: 5
2022-11-28 03:39:16,798 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5142152517340904, 'Total loss': 0.5142152517340904} | train loss {'Reaction outcome loss': 0.4075810758419979, 'Total loss': 0.4075810758419979}
2022-11-28 03:39:16,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:16,799 INFO:     Epoch: 6
2022-11-28 03:39:17,534 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5074221200721208, 'Total loss': 0.5074221200721208} | train loss {'Reaction outcome loss': 0.3921486905818123, 'Total loss': 0.3921486905818123}
2022-11-28 03:39:17,535 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:17,535 INFO:     Epoch: 7
2022-11-28 03:39:18,269 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45797958762146707, 'Total loss': 0.45797958762146707} | train loss {'Reaction outcome loss': 0.38293513134428503, 'Total loss': 0.38293513134428503}
2022-11-28 03:39:18,269 INFO:     Found new best model at epoch 7
2022-11-28 03:39:18,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:18,270 INFO:     Epoch: 8
2022-11-28 03:39:19,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.450579428049021, 'Total loss': 0.450579428049021} | train loss {'Reaction outcome loss': 0.38163013931041884, 'Total loss': 0.38163013931041884}
2022-11-28 03:39:19,000 INFO:     Found new best model at epoch 8
2022-11-28 03:39:19,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:19,001 INFO:     Epoch: 9
2022-11-28 03:39:19,736 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49504179108974544, 'Total loss': 0.49504179108974544} | train loss {'Reaction outcome loss': 0.3655030618847152, 'Total loss': 0.3655030618847152}
2022-11-28 03:39:19,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:19,736 INFO:     Epoch: 10
2022-11-28 03:39:20,474 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4764417759900869, 'Total loss': 0.4764417759900869} | train loss {'Reaction outcome loss': 0.36865746493570106, 'Total loss': 0.36865746493570106}
2022-11-28 03:39:20,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:20,475 INFO:     Epoch: 11
2022-11-28 03:39:21,210 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46159872135450675, 'Total loss': 0.46159872135450675} | train loss {'Reaction outcome loss': 0.36978671810141317, 'Total loss': 0.36978671810141317}
2022-11-28 03:39:21,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:21,210 INFO:     Epoch: 12
2022-11-28 03:39:21,942 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4697573632001877, 'Total loss': 0.4697573632001877} | train loss {'Reaction outcome loss': 0.3627127744104146, 'Total loss': 0.3627127744104146}
2022-11-28 03:39:21,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:21,942 INFO:     Epoch: 13
2022-11-28 03:39:22,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4657001727542212, 'Total loss': 0.4657001727542212} | train loss {'Reaction outcome loss': 0.35653234895610025, 'Total loss': 0.35653234895610025}
2022-11-28 03:39:22,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:22,675 INFO:     Epoch: 14
2022-11-28 03:39:23,407 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44200751289378765, 'Total loss': 0.44200751289378765} | train loss {'Reaction outcome loss': 0.3496958510068709, 'Total loss': 0.3496958510068709}
2022-11-28 03:39:23,407 INFO:     Found new best model at epoch 14
2022-11-28 03:39:23,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:23,408 INFO:     Epoch: 15
2022-11-28 03:39:24,141 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4594983652580616, 'Total loss': 0.4594983652580616} | train loss {'Reaction outcome loss': 0.3593026695796001, 'Total loss': 0.3593026695796001}
2022-11-28 03:39:24,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:24,141 INFO:     Epoch: 16
2022-11-28 03:39:24,871 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4570214121147644, 'Total loss': 0.4570214121147644} | train loss {'Reaction outcome loss': 0.347893725298805, 'Total loss': 0.347893725298805}
2022-11-28 03:39:24,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:24,871 INFO:     Epoch: 17
2022-11-28 03:39:25,604 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43043165844540265, 'Total loss': 0.43043165844540265} | train loss {'Reaction outcome loss': 0.3460569770186526, 'Total loss': 0.3460569770186526}
2022-11-28 03:39:25,604 INFO:     Found new best model at epoch 17
2022-11-28 03:39:25,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:25,605 INFO:     Epoch: 18
2022-11-28 03:39:26,338 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.477168949537499, 'Total loss': 0.477168949537499} | train loss {'Reaction outcome loss': 0.3365857210546855, 'Total loss': 0.3365857210546855}
2022-11-28 03:39:26,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:26,339 INFO:     Epoch: 19
2022-11-28 03:39:27,071 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44496271707290824, 'Total loss': 0.44496271707290824} | train loss {'Reaction outcome loss': 0.33980743522629325, 'Total loss': 0.33980743522629325}
2022-11-28 03:39:27,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:27,071 INFO:     Epoch: 20
2022-11-28 03:39:27,803 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42145271495331166, 'Total loss': 0.42145271495331166} | train loss {'Reaction outcome loss': 0.33971642460597395, 'Total loss': 0.33971642460597395}
2022-11-28 03:39:27,804 INFO:     Found new best model at epoch 20
2022-11-28 03:39:27,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:27,804 INFO:     Epoch: 21
2022-11-28 03:39:28,535 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45497455153354377, 'Total loss': 0.45497455153354377} | train loss {'Reaction outcome loss': 0.3416672113194387, 'Total loss': 0.3416672113194387}
2022-11-28 03:39:28,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:28,536 INFO:     Epoch: 22
2022-11-28 03:39:29,268 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45273434492044673, 'Total loss': 0.45273434492044673} | train loss {'Reaction outcome loss': 0.32913898633708677, 'Total loss': 0.32913898633708677}
2022-11-28 03:39:29,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:29,269 INFO:     Epoch: 23
2022-11-28 03:39:30,000 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43993832968002144, 'Total loss': 0.43993832968002144} | train loss {'Reaction outcome loss': 0.3399892667818186, 'Total loss': 0.3399892667818186}
2022-11-28 03:39:30,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:30,001 INFO:     Epoch: 24
2022-11-28 03:39:30,728 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4354307147306065, 'Total loss': 0.4354307147306065} | train loss {'Reaction outcome loss': 0.3292496806248225, 'Total loss': 0.3292496806248225}
2022-11-28 03:39:30,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:30,728 INFO:     Epoch: 25
2022-11-28 03:39:31,461 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4412806716769241, 'Total loss': 0.4412806716769241} | train loss {'Reaction outcome loss': 0.3405499618975714, 'Total loss': 0.3405499618975714}
2022-11-28 03:39:31,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:31,461 INFO:     Epoch: 26
2022-11-28 03:39:32,192 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.435459156369054, 'Total loss': 0.435459156369054} | train loss {'Reaction outcome loss': 0.33397700291111637, 'Total loss': 0.33397700291111637}
2022-11-28 03:39:32,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:32,192 INFO:     Epoch: 27
2022-11-28 03:39:32,928 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43347081888553707, 'Total loss': 0.43347081888553707} | train loss {'Reaction outcome loss': 0.32460593352469885, 'Total loss': 0.32460593352469885}
2022-11-28 03:39:32,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:32,928 INFO:     Epoch: 28
2022-11-28 03:39:33,660 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.467481522366058, 'Total loss': 0.467481522366058} | train loss {'Reaction outcome loss': 0.3355426496132411, 'Total loss': 0.3355426496132411}
2022-11-28 03:39:33,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:33,660 INFO:     Epoch: 29
2022-11-28 03:39:34,389 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46059094126834427, 'Total loss': 0.46059094126834427} | train loss {'Reaction outcome loss': 0.32774830226299695, 'Total loss': 0.32774830226299695}
2022-11-28 03:39:34,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:34,389 INFO:     Epoch: 30
2022-11-28 03:39:35,118 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42329908248990084, 'Total loss': 0.42329908248990084} | train loss {'Reaction outcome loss': 0.3252095856661659, 'Total loss': 0.3252095856661659}
2022-11-28 03:39:35,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:35,118 INFO:     Epoch: 31
2022-11-28 03:39:35,847 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4522047725527786, 'Total loss': 0.4522047725527786} | train loss {'Reaction outcome loss': 0.31960755972950544, 'Total loss': 0.31960755972950544}
2022-11-28 03:39:35,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:35,848 INFO:     Epoch: 32
2022-11-28 03:39:36,581 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45906169019466225, 'Total loss': 0.45906169019466225} | train loss {'Reaction outcome loss': 0.31819879245242955, 'Total loss': 0.31819879245242955}
2022-11-28 03:39:36,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:36,581 INFO:     Epoch: 33
2022-11-28 03:39:37,313 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4961464328821315, 'Total loss': 0.4961464328821315} | train loss {'Reaction outcome loss': 0.3264226700359411, 'Total loss': 0.3264226700359411}
2022-11-28 03:39:37,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:37,313 INFO:     Epoch: 34
2022-11-28 03:39:38,044 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44886285517104835, 'Total loss': 0.44886285517104835} | train loss {'Reaction outcome loss': 0.33169550801255576, 'Total loss': 0.33169550801255576}
2022-11-28 03:39:38,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:38,044 INFO:     Epoch: 35
2022-11-28 03:39:38,783 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42950874047223914, 'Total loss': 0.42950874047223914} | train loss {'Reaction outcome loss': 0.3101536277451633, 'Total loss': 0.3101536277451633}
2022-11-28 03:39:38,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:38,783 INFO:     Epoch: 36
2022-11-28 03:39:39,517 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44501176580440166, 'Total loss': 0.44501176580440166} | train loss {'Reaction outcome loss': 0.32370808082843516, 'Total loss': 0.32370808082843516}
2022-11-28 03:39:39,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:39,517 INFO:     Epoch: 37
2022-11-28 03:39:40,253 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42572472677674406, 'Total loss': 0.42572472677674406} | train loss {'Reaction outcome loss': 0.3169821018483413, 'Total loss': 0.3169821018483413}
2022-11-28 03:39:40,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:40,254 INFO:     Epoch: 38
2022-11-28 03:39:40,988 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4588295058455578, 'Total loss': 0.4588295058455578} | train loss {'Reaction outcome loss': 0.31265499616049447, 'Total loss': 0.31265499616049447}
2022-11-28 03:39:40,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:40,988 INFO:     Epoch: 39
2022-11-28 03:39:41,721 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4570733475130658, 'Total loss': 0.4570733475130658} | train loss {'Reaction outcome loss': 0.314196482546045, 'Total loss': 0.314196482546045}
2022-11-28 03:39:41,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:41,721 INFO:     Epoch: 40
2022-11-28 03:39:42,452 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4311211129953695, 'Total loss': 0.4311211129953695} | train loss {'Reaction outcome loss': 0.3155021610144725, 'Total loss': 0.3155021610144725}
2022-11-28 03:39:42,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:42,453 INFO:     Epoch: 41
2022-11-28 03:39:43,184 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45040708641673244, 'Total loss': 0.45040708641673244} | train loss {'Reaction outcome loss': 0.3146375391341041, 'Total loss': 0.3146375391341041}
2022-11-28 03:39:43,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:43,185 INFO:     Epoch: 42
2022-11-28 03:39:43,924 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5072886975005616, 'Total loss': 0.5072886975005616} | train loss {'Reaction outcome loss': 0.3026099469620014, 'Total loss': 0.3026099469620014}
2022-11-28 03:39:43,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:43,924 INFO:     Epoch: 43
2022-11-28 03:39:44,664 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44887394128843794, 'Total loss': 0.44887394128843794} | train loss {'Reaction outcome loss': 0.31743889231495404, 'Total loss': 0.31743889231495404}
2022-11-28 03:39:44,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:44,664 INFO:     Epoch: 44
2022-11-28 03:39:45,397 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44016085980936537, 'Total loss': 0.44016085980936537} | train loss {'Reaction outcome loss': 0.3147548269403815, 'Total loss': 0.3147548269403815}
2022-11-28 03:39:45,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:45,398 INFO:     Epoch: 45
2022-11-28 03:39:46,134 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4530662166517834, 'Total loss': 0.4530662166517834} | train loss {'Reaction outcome loss': 0.31148901440724425, 'Total loss': 0.31148901440724425}
2022-11-28 03:39:46,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:46,134 INFO:     Epoch: 46
2022-11-28 03:39:46,870 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42374508810597794, 'Total loss': 0.42374508810597794} | train loss {'Reaction outcome loss': 0.31593830949423735, 'Total loss': 0.31593830949423735}
2022-11-28 03:39:46,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:46,870 INFO:     Epoch: 47
2022-11-28 03:39:47,606 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44547896710939183, 'Total loss': 0.44547896710939183} | train loss {'Reaction outcome loss': 0.3092180580023385, 'Total loss': 0.3092180580023385}
2022-11-28 03:39:47,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:47,606 INFO:     Epoch: 48
2022-11-28 03:39:48,342 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43072639717612154, 'Total loss': 0.43072639717612154} | train loss {'Reaction outcome loss': 0.3073869380072802, 'Total loss': 0.3073869380072802}
2022-11-28 03:39:48,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:48,342 INFO:     Epoch: 49
2022-11-28 03:39:49,075 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4438302922387456, 'Total loss': 0.4438302922387456} | train loss {'Reaction outcome loss': 0.30957825929539684, 'Total loss': 0.30957825929539684}
2022-11-28 03:39:49,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:49,076 INFO:     Epoch: 50
2022-11-28 03:39:49,809 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.422727839544762, 'Total loss': 0.422727839544762} | train loss {'Reaction outcome loss': 0.31296874962961724, 'Total loss': 0.31296874962961724}
2022-11-28 03:39:49,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:49,809 INFO:     Epoch: 51
2022-11-28 03:39:50,542 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45891657748887704, 'Total loss': 0.45891657748887704} | train loss {'Reaction outcome loss': 0.3028913992207973, 'Total loss': 0.3028913992207973}
2022-11-28 03:39:50,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:50,542 INFO:     Epoch: 52
2022-11-28 03:39:51,279 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46386860588262246, 'Total loss': 0.46386860588262246} | train loss {'Reaction outcome loss': 0.3095122934184938, 'Total loss': 0.3095122934184938}
2022-11-28 03:39:51,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:51,279 INFO:     Epoch: 53
2022-11-28 03:39:52,016 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44647969582746194, 'Total loss': 0.44647969582746194} | train loss {'Reaction outcome loss': 0.3086380405129229, 'Total loss': 0.3086380405129229}
2022-11-28 03:39:52,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:52,017 INFO:     Epoch: 54
2022-11-28 03:39:52,749 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48126478389252064, 'Total loss': 0.48126478389252064} | train loss {'Reaction outcome loss': 0.29569530257104354, 'Total loss': 0.29569530257104354}
2022-11-28 03:39:52,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:52,749 INFO:     Epoch: 55
2022-11-28 03:39:53,482 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4747224585261456, 'Total loss': 0.4747224585261456} | train loss {'Reaction outcome loss': 0.3065454842745031, 'Total loss': 0.3065454842745031}
2022-11-28 03:39:53,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:53,483 INFO:     Epoch: 56
2022-11-28 03:39:54,214 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4644945021285567, 'Total loss': 0.4644945021285567} | train loss {'Reaction outcome loss': 0.31086844377556944, 'Total loss': 0.31086844377556944}
2022-11-28 03:39:54,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:54,214 INFO:     Epoch: 57
2022-11-28 03:39:54,948 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4398351207722065, 'Total loss': 0.4398351207722065} | train loss {'Reaction outcome loss': 0.2971380955612463, 'Total loss': 0.2971380955612463}
2022-11-28 03:39:54,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:54,949 INFO:     Epoch: 58
2022-11-28 03:39:55,682 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4474588961795319, 'Total loss': 0.4474588961795319} | train loss {'Reaction outcome loss': 0.31074548856098466, 'Total loss': 0.31074548856098466}
2022-11-28 03:39:55,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:55,682 INFO:     Epoch: 59
2022-11-28 03:39:56,416 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43204255610011344, 'Total loss': 0.43204255610011344} | train loss {'Reaction outcome loss': 0.30204036822657526, 'Total loss': 0.30204036822657526}
2022-11-28 03:39:56,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:56,416 INFO:     Epoch: 60
2022-11-28 03:39:57,149 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46550834768040233, 'Total loss': 0.46550834768040233} | train loss {'Reaction outcome loss': 0.2961228868996901, 'Total loss': 0.2961228868996901}
2022-11-28 03:39:57,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:57,149 INFO:     Epoch: 61
2022-11-28 03:39:57,885 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45609970875950745, 'Total loss': 0.45609970875950745} | train loss {'Reaction outcome loss': 0.30823604170800234, 'Total loss': 0.30823604170800234}
2022-11-28 03:39:57,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:57,885 INFO:     Epoch: 62
2022-11-28 03:39:58,620 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4722545363528784, 'Total loss': 0.4722545363528784} | train loss {'Reaction outcome loss': 0.30379052579770854, 'Total loss': 0.30379052579770854}
2022-11-28 03:39:58,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:58,621 INFO:     Epoch: 63
2022-11-28 03:39:59,356 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46642057043175367, 'Total loss': 0.46642057043175367} | train loss {'Reaction outcome loss': 0.2978678901254395, 'Total loss': 0.2978678901254395}
2022-11-28 03:39:59,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:39:59,357 INFO:     Epoch: 64
2022-11-28 03:40:00,092 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46799243640067967, 'Total loss': 0.46799243640067967} | train loss {'Reaction outcome loss': 0.30932075818502364, 'Total loss': 0.30932075818502364}
2022-11-28 03:40:00,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:00,092 INFO:     Epoch: 65
2022-11-28 03:40:00,823 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4552464665368546, 'Total loss': 0.4552464665368546} | train loss {'Reaction outcome loss': 0.2900643379354673, 'Total loss': 0.2900643379354673}
2022-11-28 03:40:00,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:00,823 INFO:     Epoch: 66
2022-11-28 03:40:01,558 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46520783180414244, 'Total loss': 0.46520783180414244} | train loss {'Reaction outcome loss': 0.3050668087055899, 'Total loss': 0.3050668087055899}
2022-11-28 03:40:01,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:01,558 INFO:     Epoch: 67
2022-11-28 03:40:02,294 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4611863230550012, 'Total loss': 0.4611863230550012} | train loss {'Reaction outcome loss': 0.30523885753572966, 'Total loss': 0.30523885753572966}
2022-11-28 03:40:02,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:02,295 INFO:     Epoch: 68
2022-11-28 03:40:03,031 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46956842756548595, 'Total loss': 0.46956842756548595} | train loss {'Reaction outcome loss': 0.29457504213346863, 'Total loss': 0.29457504213346863}
2022-11-28 03:40:03,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:03,031 INFO:     Epoch: 69
2022-11-28 03:40:03,767 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4477106720902199, 'Total loss': 0.4477106720902199} | train loss {'Reaction outcome loss': 0.2913624236797109, 'Total loss': 0.2913624236797109}
2022-11-28 03:40:03,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:03,767 INFO:     Epoch: 70
2022-11-28 03:40:04,504 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44387190615714983, 'Total loss': 0.44387190615714983} | train loss {'Reaction outcome loss': 0.29467464330387705, 'Total loss': 0.29467464330387705}
2022-11-28 03:40:04,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:04,505 INFO:     Epoch: 71
2022-11-28 03:40:05,242 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45923157694727873, 'Total loss': 0.45923157694727873} | train loss {'Reaction outcome loss': 0.2932873462698587, 'Total loss': 0.2932873462698587}
2022-11-28 03:40:05,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:05,242 INFO:     Epoch: 72
2022-11-28 03:40:05,977 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4753097326949585, 'Total loss': 0.4753097326949585} | train loss {'Reaction outcome loss': 0.29712646883824234, 'Total loss': 0.29712646883824234}
2022-11-28 03:40:05,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:05,977 INFO:     Epoch: 73
2022-11-28 03:40:06,713 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46437423277732937, 'Total loss': 0.46437423277732937} | train loss {'Reaction outcome loss': 0.30396816606629534, 'Total loss': 0.30396816606629534}
2022-11-28 03:40:06,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:06,713 INFO:     Epoch: 74
2022-11-28 03:40:07,449 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4608577888372333, 'Total loss': 0.4608577888372333} | train loss {'Reaction outcome loss': 0.29762876423175444, 'Total loss': 0.29762876423175444}
2022-11-28 03:40:07,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:07,450 INFO:     Epoch: 75
2022-11-28 03:40:08,187 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4647724947264028, 'Total loss': 0.4647724947264028} | train loss {'Reaction outcome loss': 0.3004859009213408, 'Total loss': 0.3004859009213408}
2022-11-28 03:40:08,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:08,187 INFO:     Epoch: 76
2022-11-28 03:40:08,923 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44494841265123947, 'Total loss': 0.44494841265123947} | train loss {'Reaction outcome loss': 0.30410124444299275, 'Total loss': 0.30410124444299275}
2022-11-28 03:40:08,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:08,923 INFO:     Epoch: 77
2022-11-28 03:40:09,659 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5072598485059516, 'Total loss': 0.5072598485059516} | train loss {'Reaction outcome loss': 0.2965203536820019, 'Total loss': 0.2965203536820019}
2022-11-28 03:40:09,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:09,660 INFO:     Epoch: 78
2022-11-28 03:40:10,399 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43449117659136305, 'Total loss': 0.43449117659136305} | train loss {'Reaction outcome loss': 0.2958998784476531, 'Total loss': 0.2958998784476531}
2022-11-28 03:40:10,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:10,399 INFO:     Epoch: 79
2022-11-28 03:40:11,135 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4360335004884143, 'Total loss': 0.4360335004884143} | train loss {'Reaction outcome loss': 0.2950759450655906, 'Total loss': 0.2950759450655906}
2022-11-28 03:40:11,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:11,135 INFO:     Epoch: 80
2022-11-28 03:40:11,871 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46332064582857974, 'Total loss': 0.46332064582857974} | train loss {'Reaction outcome loss': 0.2945190381733969, 'Total loss': 0.2945190381733969}
2022-11-28 03:40:11,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:11,871 INFO:     Epoch: 81
2022-11-28 03:40:12,609 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47563884701839715, 'Total loss': 0.47563884701839715} | train loss {'Reaction outcome loss': 0.30386173176299397, 'Total loss': 0.30386173176299397}
2022-11-28 03:40:12,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:12,609 INFO:     Epoch: 82
2022-11-28 03:40:13,340 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4465080925891566, 'Total loss': 0.4465080925891566} | train loss {'Reaction outcome loss': 0.29746805784510977, 'Total loss': 0.29746805784510977}
2022-11-28 03:40:13,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:13,340 INFO:     Epoch: 83
2022-11-28 03:40:14,076 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.459649465111799, 'Total loss': 0.459649465111799} | train loss {'Reaction outcome loss': 0.29774037682654436, 'Total loss': 0.29774037682654436}
2022-11-28 03:40:14,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:14,077 INFO:     Epoch: 84
2022-11-28 03:40:14,815 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46248580064884454, 'Total loss': 0.46248580064884454} | train loss {'Reaction outcome loss': 0.29674736020986925, 'Total loss': 0.29674736020986925}
2022-11-28 03:40:14,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:14,815 INFO:     Epoch: 85
2022-11-28 03:40:15,548 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44947289138339286, 'Total loss': 0.44947289138339286} | train loss {'Reaction outcome loss': 0.2955018609547566, 'Total loss': 0.2955018609547566}
2022-11-28 03:40:15,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:15,549 INFO:     Epoch: 86
2022-11-28 03:40:16,291 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.421979148720586, 'Total loss': 0.421979148720586} | train loss {'Reaction outcome loss': 0.2971637380681165, 'Total loss': 0.2971637380681165}
2022-11-28 03:40:16,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:16,291 INFO:     Epoch: 87
2022-11-28 03:40:17,034 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4351046681404114, 'Total loss': 0.4351046681404114} | train loss {'Reaction outcome loss': 0.2893429201387574, 'Total loss': 0.2893429201387574}
2022-11-28 03:40:17,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:17,034 INFO:     Epoch: 88
2022-11-28 03:40:17,779 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.470918845645217, 'Total loss': 0.470918845645217} | train loss {'Reaction outcome loss': 0.300296492935944, 'Total loss': 0.300296492935944}
2022-11-28 03:40:17,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:17,779 INFO:     Epoch: 89
2022-11-28 03:40:18,523 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4489025352306144, 'Total loss': 0.4489025352306144} | train loss {'Reaction outcome loss': 0.3088734188948762, 'Total loss': 0.3088734188948762}
2022-11-28 03:40:18,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:18,523 INFO:     Epoch: 90
2022-11-28 03:40:19,269 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4647218862245249, 'Total loss': 0.4647218862245249} | train loss {'Reaction outcome loss': 0.2840171357455813, 'Total loss': 0.2840171357455813}
2022-11-28 03:40:19,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:19,269 INFO:     Epoch: 91
2022-11-28 03:40:20,012 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49781437391458555, 'Total loss': 0.49781437391458555} | train loss {'Reaction outcome loss': 0.2868563443299674, 'Total loss': 0.2868563443299674}
2022-11-28 03:40:20,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:20,013 INFO:     Epoch: 92
2022-11-28 03:40:20,757 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45896355426588725, 'Total loss': 0.45896355426588725} | train loss {'Reaction outcome loss': 0.2995384294738985, 'Total loss': 0.2995384294738985}
2022-11-28 03:40:20,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:20,757 INFO:     Epoch: 93
2022-11-28 03:40:21,504 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4554315788108249, 'Total loss': 0.4554315788108249} | train loss {'Reaction outcome loss': 0.2950571434947934, 'Total loss': 0.2950571434947934}
2022-11-28 03:40:21,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:21,504 INFO:     Epoch: 94
2022-11-28 03:40:22,251 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47687565379364544, 'Total loss': 0.47687565379364544} | train loss {'Reaction outcome loss': 0.2903628622952067, 'Total loss': 0.2903628622952067}
2022-11-28 03:40:22,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:22,252 INFO:     Epoch: 95
2022-11-28 03:40:22,999 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4510772872802823, 'Total loss': 0.4510772872802823} | train loss {'Reaction outcome loss': 0.2901655226915216, 'Total loss': 0.2901655226915216}
2022-11-28 03:40:22,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:22,999 INFO:     Epoch: 96
2022-11-28 03:40:23,744 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4509829447366471, 'Total loss': 0.4509829447366471} | train loss {'Reaction outcome loss': 0.2988427916212092, 'Total loss': 0.2988427916212092}
2022-11-28 03:40:23,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:23,744 INFO:     Epoch: 97
2022-11-28 03:40:24,490 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4633476917826852, 'Total loss': 0.4633476917826852} | train loss {'Reaction outcome loss': 0.2843188451825346, 'Total loss': 0.2843188451825346}
2022-11-28 03:40:24,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:24,490 INFO:     Epoch: 98
2022-11-28 03:40:25,236 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4615869043871414, 'Total loss': 0.4615869043871414} | train loss {'Reaction outcome loss': 0.29358002080470935, 'Total loss': 0.29358002080470935}
2022-11-28 03:40:25,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:25,236 INFO:     Epoch: 99
2022-11-28 03:40:25,980 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4536854357913483, 'Total loss': 0.4536854357913483} | train loss {'Reaction outcome loss': 0.29277311348252827, 'Total loss': 0.29277311348252827}
2022-11-28 03:40:25,980 INFO:     Best model found after epoch 21 of 100.
2022-11-28 03:40:25,980 INFO:   Done with stage: TRAINING
2022-11-28 03:40:25,980 INFO:   Starting stage: EVALUATION
2022-11-28 03:40:26,118 INFO:   Done with stage: EVALUATION
2022-11-28 03:40:26,119 INFO:   Leaving out SEQ value Fold_4
2022-11-28 03:40:26,132 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:40:26,132 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:40:26,790 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:40:26,790 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:40:26,859 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:40:26,859 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:40:26,859 INFO:     No hyperparam tuning for this model
2022-11-28 03:40:26,859 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:40:26,859 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:40:26,860 INFO:     None feature selector for col prot
2022-11-28 03:40:26,860 INFO:     None feature selector for col prot
2022-11-28 03:40:26,860 INFO:     None feature selector for col prot
2022-11-28 03:40:26,861 INFO:     None feature selector for col chem
2022-11-28 03:40:26,861 INFO:     None feature selector for col chem
2022-11-28 03:40:26,861 INFO:     None feature selector for col chem
2022-11-28 03:40:26,861 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:40:26,861 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:40:26,862 INFO:     Number of params in model 169741
2022-11-28 03:40:26,866 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:40:26,866 INFO:   Starting stage: TRAINING
2022-11-28 03:40:26,920 INFO:     Val loss before train {'Reaction outcome loss': 0.9646551270376552, 'Total loss': 0.9646551270376552}
2022-11-28 03:40:26,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:26,920 INFO:     Epoch: 0
2022-11-28 03:40:27,677 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5510130334984172, 'Total loss': 0.5510130334984172} | train loss {'Reaction outcome loss': 0.6388761511132601, 'Total loss': 0.6388761511132601}
2022-11-28 03:40:27,678 INFO:     Found new best model at epoch 0
2022-11-28 03:40:27,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:27,678 INFO:     Epoch: 1
2022-11-28 03:40:28,434 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5033146115866575, 'Total loss': 0.5033146115866575} | train loss {'Reaction outcome loss': 0.49414276091321824, 'Total loss': 0.49414276091321824}
2022-11-28 03:40:28,434 INFO:     Found new best model at epoch 1
2022-11-28 03:40:28,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:28,435 INFO:     Epoch: 2
2022-11-28 03:40:29,195 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4773517183282159, 'Total loss': 0.4773517183282159} | train loss {'Reaction outcome loss': 0.4650258731938178, 'Total loss': 0.4650258731938178}
2022-11-28 03:40:29,195 INFO:     Found new best model at epoch 2
2022-11-28 03:40:29,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:29,196 INFO:     Epoch: 3
2022-11-28 03:40:29,955 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.444026037373326, 'Total loss': 0.444026037373326} | train loss {'Reaction outcome loss': 0.4434209220832394, 'Total loss': 0.4434209220832394}
2022-11-28 03:40:29,955 INFO:     Found new best model at epoch 3
2022-11-28 03:40:29,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:29,956 INFO:     Epoch: 4
2022-11-28 03:40:30,714 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4460216266187755, 'Total loss': 0.4460216266187755} | train loss {'Reaction outcome loss': 0.43381330412962743, 'Total loss': 0.43381330412962743}
2022-11-28 03:40:30,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:30,715 INFO:     Epoch: 5
2022-11-28 03:40:31,468 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45039741931991145, 'Total loss': 0.45039741931991145} | train loss {'Reaction outcome loss': 0.42128338310266694, 'Total loss': 0.42128338310266694}
2022-11-28 03:40:31,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:31,469 INFO:     Epoch: 6
2022-11-28 03:40:32,225 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4497304809364406, 'Total loss': 0.4497304809364406} | train loss {'Reaction outcome loss': 0.3992424491913088, 'Total loss': 0.3992424491913088}
2022-11-28 03:40:32,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:32,225 INFO:     Epoch: 7
2022-11-28 03:40:32,984 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44507527723908424, 'Total loss': 0.44507527723908424} | train loss {'Reaction outcome loss': 0.4047010138991379, 'Total loss': 0.4047010138991379}
2022-11-28 03:40:32,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:32,984 INFO:     Epoch: 8
2022-11-28 03:40:33,742 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45161916146224196, 'Total loss': 0.45161916146224196} | train loss {'Reaction outcome loss': 0.39114980883295497, 'Total loss': 0.39114980883295497}
2022-11-28 03:40:33,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:33,742 INFO:     Epoch: 9
2022-11-28 03:40:34,499 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4279284710911187, 'Total loss': 0.4279284710911187} | train loss {'Reaction outcome loss': 0.39173866231595317, 'Total loss': 0.39173866231595317}
2022-11-28 03:40:34,499 INFO:     Found new best model at epoch 9
2022-11-28 03:40:34,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:34,500 INFO:     Epoch: 10
2022-11-28 03:40:35,252 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42217837037010625, 'Total loss': 0.42217837037010625} | train loss {'Reaction outcome loss': 0.38529633006621755, 'Total loss': 0.38529633006621755}
2022-11-28 03:40:35,252 INFO:     Found new best model at epoch 10
2022-11-28 03:40:35,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:35,253 INFO:     Epoch: 11
2022-11-28 03:40:36,009 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43231035938317125, 'Total loss': 0.43231035938317125} | train loss {'Reaction outcome loss': 0.3738336336889094, 'Total loss': 0.3738336336889094}
2022-11-28 03:40:36,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:36,009 INFO:     Epoch: 12
2022-11-28 03:40:36,767 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43100195310332556, 'Total loss': 0.43100195310332556} | train loss {'Reaction outcome loss': 0.3734490402463463, 'Total loss': 0.3734490402463463}
2022-11-28 03:40:36,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:36,767 INFO:     Epoch: 13
2022-11-28 03:40:37,522 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42987123876810074, 'Total loss': 0.42987123876810074} | train loss {'Reaction outcome loss': 0.37289330195034703, 'Total loss': 0.37289330195034703}
2022-11-28 03:40:37,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:37,523 INFO:     Epoch: 14
2022-11-28 03:40:38,281 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43641765314069664, 'Total loss': 0.43641765314069664} | train loss {'Reaction outcome loss': 0.36071063331778974, 'Total loss': 0.36071063331778974}
2022-11-28 03:40:38,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:38,281 INFO:     Epoch: 15
2022-11-28 03:40:39,036 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43121816421096976, 'Total loss': 0.43121816421096976} | train loss {'Reaction outcome loss': 0.3551292300464646, 'Total loss': 0.3551292300464646}
2022-11-28 03:40:39,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:39,036 INFO:     Epoch: 16
2022-11-28 03:40:39,788 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4499029071832245, 'Total loss': 0.4499029071832245} | train loss {'Reaction outcome loss': 0.36062002455395076, 'Total loss': 0.36062002455395076}
2022-11-28 03:40:39,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:39,789 INFO:     Epoch: 17
2022-11-28 03:40:40,546 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41982090879570355, 'Total loss': 0.41982090879570355} | train loss {'Reaction outcome loss': 0.3535046919339126, 'Total loss': 0.3535046919339126}
2022-11-28 03:40:40,547 INFO:     Found new best model at epoch 17
2022-11-28 03:40:40,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:40,547 INFO:     Epoch: 18
2022-11-28 03:40:41,304 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4425488270141862, 'Total loss': 0.4425488270141862} | train loss {'Reaction outcome loss': 0.35544798466106575, 'Total loss': 0.35544798466106575}
2022-11-28 03:40:41,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:41,304 INFO:     Epoch: 19
2022-11-28 03:40:42,059 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47921922328797256, 'Total loss': 0.47921922328797256} | train loss {'Reaction outcome loss': 0.3517260230897415, 'Total loss': 0.3517260230897415}
2022-11-28 03:40:42,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:42,059 INFO:     Epoch: 20
2022-11-28 03:40:42,814 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4430989426645366, 'Total loss': 0.4430989426645366} | train loss {'Reaction outcome loss': 0.34721114758342025, 'Total loss': 0.34721114758342025}
2022-11-28 03:40:42,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:42,814 INFO:     Epoch: 21
2022-11-28 03:40:43,569 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44122105599804357, 'Total loss': 0.44122105599804357} | train loss {'Reaction outcome loss': 0.34830386095469995, 'Total loss': 0.34830386095469995}
2022-11-28 03:40:43,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:43,570 INFO:     Epoch: 22
2022-11-28 03:40:44,329 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4090780253437432, 'Total loss': 0.4090780253437432} | train loss {'Reaction outcome loss': 0.3489942595122322, 'Total loss': 0.3489942595122322}
2022-11-28 03:40:44,330 INFO:     Found new best model at epoch 22
2022-11-28 03:40:44,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:44,330 INFO:     Epoch: 23
2022-11-28 03:40:45,090 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.465626722201705, 'Total loss': 0.465626722201705} | train loss {'Reaction outcome loss': 0.33823645592577034, 'Total loss': 0.33823645592577034}
2022-11-28 03:40:45,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:45,090 INFO:     Epoch: 24
2022-11-28 03:40:45,845 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4270087450065396, 'Total loss': 0.4270087450065396} | train loss {'Reaction outcome loss': 0.34861291929959287, 'Total loss': 0.34861291929959287}
2022-11-28 03:40:45,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:45,845 INFO:     Epoch: 25
2022-11-28 03:40:46,601 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42692547460848634, 'Total loss': 0.42692547460848634} | train loss {'Reaction outcome loss': 0.3361265154014672, 'Total loss': 0.3361265154014672}
2022-11-28 03:40:46,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:46,601 INFO:     Epoch: 26
2022-11-28 03:40:47,354 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4295670132745396, 'Total loss': 0.4295670132745396} | train loss {'Reaction outcome loss': 0.3373928871606627, 'Total loss': 0.3373928871606627}
2022-11-28 03:40:47,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:47,354 INFO:     Epoch: 27
2022-11-28 03:40:48,112 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42956131019375543, 'Total loss': 0.42956131019375543} | train loss {'Reaction outcome loss': 0.3376111709362557, 'Total loss': 0.3376111709362557}
2022-11-28 03:40:48,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:48,112 INFO:     Epoch: 28
2022-11-28 03:40:48,870 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4107146866788918, 'Total loss': 0.4107146866788918} | train loss {'Reaction outcome loss': 0.32940963214083063, 'Total loss': 0.32940963214083063}
2022-11-28 03:40:48,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:48,870 INFO:     Epoch: 29
2022-11-28 03:40:49,628 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.404866957698356, 'Total loss': 0.404866957698356} | train loss {'Reaction outcome loss': 0.33539186039518926, 'Total loss': 0.33539186039518926}
2022-11-28 03:40:49,628 INFO:     Found new best model at epoch 29
2022-11-28 03:40:49,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:49,629 INFO:     Epoch: 30
2022-11-28 03:40:50,385 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.430527038872242, 'Total loss': 0.430527038872242} | train loss {'Reaction outcome loss': 0.33873978915113595, 'Total loss': 0.33873978915113595}
2022-11-28 03:40:50,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:50,385 INFO:     Epoch: 31
2022-11-28 03:40:51,142 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41248293830589816, 'Total loss': 0.41248293830589816} | train loss {'Reaction outcome loss': 0.33319966936664236, 'Total loss': 0.33319966936664236}
2022-11-28 03:40:51,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:51,142 INFO:     Epoch: 32
2022-11-28 03:40:51,900 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4239706728946079, 'Total loss': 0.4239706728946079} | train loss {'Reaction outcome loss': 0.32484617474819383, 'Total loss': 0.32484617474819383}
2022-11-28 03:40:51,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:51,900 INFO:     Epoch: 33
2022-11-28 03:40:52,657 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4396007237109271, 'Total loss': 0.4396007237109271} | train loss {'Reaction outcome loss': 0.3275098093755303, 'Total loss': 0.3275098093755303}
2022-11-28 03:40:52,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:52,658 INFO:     Epoch: 34
2022-11-28 03:40:53,411 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40002011677080934, 'Total loss': 0.40002011677080934} | train loss {'Reaction outcome loss': 0.3341690650990894, 'Total loss': 0.3341690650990894}
2022-11-28 03:40:53,411 INFO:     Found new best model at epoch 34
2022-11-28 03:40:53,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:53,412 INFO:     Epoch: 35
2022-11-28 03:40:54,171 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40618258105082944, 'Total loss': 0.40618258105082944} | train loss {'Reaction outcome loss': 0.3228408672035702, 'Total loss': 0.3228408672035702}
2022-11-28 03:40:54,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:54,171 INFO:     Epoch: 36
2022-11-28 03:40:54,930 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4144056219268929, 'Total loss': 0.4144056219268929} | train loss {'Reaction outcome loss': 0.3280987066907748, 'Total loss': 0.3280987066907748}
2022-11-28 03:40:54,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:54,930 INFO:     Epoch: 37
2022-11-28 03:40:55,688 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43075209856033325, 'Total loss': 0.43075209856033325} | train loss {'Reaction outcome loss': 0.32685772816260017, 'Total loss': 0.32685772816260017}
2022-11-28 03:40:55,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:55,688 INFO:     Epoch: 38
2022-11-28 03:40:56,447 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41603223979473114, 'Total loss': 0.41603223979473114} | train loss {'Reaction outcome loss': 0.3250758352599317, 'Total loss': 0.3250758352599317}
2022-11-28 03:40:56,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:56,447 INFO:     Epoch: 39
2022-11-28 03:40:57,204 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43672897057099774, 'Total loss': 0.43672897057099774} | train loss {'Reaction outcome loss': 0.3266811855137348, 'Total loss': 0.3266811855137348}
2022-11-28 03:40:57,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:57,204 INFO:     Epoch: 40
2022-11-28 03:40:57,962 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4219995486465367, 'Total loss': 0.4219995486465367} | train loss {'Reaction outcome loss': 0.32666313864531055, 'Total loss': 0.32666313864531055}
2022-11-28 03:40:57,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:57,963 INFO:     Epoch: 41
2022-11-28 03:40:58,721 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4069947437806563, 'Total loss': 0.4069947437806563} | train loss {'Reaction outcome loss': 0.3235284218624715, 'Total loss': 0.3235284218624715}
2022-11-28 03:40:58,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:58,721 INFO:     Epoch: 42
2022-11-28 03:40:59,480 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4060196183960546, 'Total loss': 0.4060196183960546} | train loss {'Reaction outcome loss': 0.31827040299052195, 'Total loss': 0.31827040299052195}
2022-11-28 03:40:59,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:40:59,481 INFO:     Epoch: 43
2022-11-28 03:41:00,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4178347230296243, 'Total loss': 0.4178347230296243} | train loss {'Reaction outcome loss': 0.3163285715986163, 'Total loss': 0.3163285715986163}
2022-11-28 03:41:00,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:00,235 INFO:     Epoch: 44
2022-11-28 03:41:00,992 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4347891922701489, 'Total loss': 0.4347891922701489} | train loss {'Reaction outcome loss': 0.31827489695241373, 'Total loss': 0.31827489695241373}
2022-11-28 03:41:00,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:00,992 INFO:     Epoch: 45
2022-11-28 03:41:01,751 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4384954852814024, 'Total loss': 0.4384954852814024} | train loss {'Reaction outcome loss': 0.3366101434634578, 'Total loss': 0.3366101434634578}
2022-11-28 03:41:01,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:01,751 INFO:     Epoch: 46
2022-11-28 03:41:02,506 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4173897687684406, 'Total loss': 0.4173897687684406} | train loss {'Reaction outcome loss': 0.32090733900305723, 'Total loss': 0.32090733900305723}
2022-11-28 03:41:02,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:02,507 INFO:     Epoch: 47
2022-11-28 03:41:03,263 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4044759862802245, 'Total loss': 0.4044759862802245} | train loss {'Reaction outcome loss': 0.32210218395677304, 'Total loss': 0.32210218395677304}
2022-11-28 03:41:03,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:03,263 INFO:     Epoch: 48
2022-11-28 03:41:04,022 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4099607430398464, 'Total loss': 0.4099607430398464} | train loss {'Reaction outcome loss': 0.3204972734975238, 'Total loss': 0.3204972734975238}
2022-11-28 03:41:04,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:04,022 INFO:     Epoch: 49
2022-11-28 03:41:04,778 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42479818856174295, 'Total loss': 0.42479818856174295} | train loss {'Reaction outcome loss': 0.3196697990680414, 'Total loss': 0.3196697990680414}
2022-11-28 03:41:04,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:04,778 INFO:     Epoch: 50
2022-11-28 03:41:05,538 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4180532924153588, 'Total loss': 0.4180532924153588} | train loss {'Reaction outcome loss': 0.3140213211938258, 'Total loss': 0.3140213211938258}
2022-11-28 03:41:05,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:05,538 INFO:     Epoch: 51
2022-11-28 03:41:06,295 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4266663671217181, 'Total loss': 0.4266663671217181} | train loss {'Reaction outcome loss': 0.31105450055592004, 'Total loss': 0.31105450055592004}
2022-11-28 03:41:06,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:06,295 INFO:     Epoch: 52
2022-11-28 03:41:07,049 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42234426973895595, 'Total loss': 0.42234426973895595} | train loss {'Reaction outcome loss': 0.3155119818064474, 'Total loss': 0.3155119818064474}
2022-11-28 03:41:07,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:07,050 INFO:     Epoch: 53
2022-11-28 03:41:07,805 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41196882216767833, 'Total loss': 0.41196882216767833} | train loss {'Reaction outcome loss': 0.32407395803039113, 'Total loss': 0.32407395803039113}
2022-11-28 03:41:07,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:07,805 INFO:     Epoch: 54
2022-11-28 03:41:08,566 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4358006361871958, 'Total loss': 0.4358006361871958} | train loss {'Reaction outcome loss': 0.3239171475232128, 'Total loss': 0.3239171475232128}
2022-11-28 03:41:08,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:08,567 INFO:     Epoch: 55
2022-11-28 03:41:09,328 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42552031170238147, 'Total loss': 0.42552031170238147} | train loss {'Reaction outcome loss': 0.32236542720948497, 'Total loss': 0.32236542720948497}
2022-11-28 03:41:09,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:09,328 INFO:     Epoch: 56
2022-11-28 03:41:10,088 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4570160958577286, 'Total loss': 0.4570160958577286} | train loss {'Reaction outcome loss': 0.3176875307915672, 'Total loss': 0.3176875307915672}
2022-11-28 03:41:10,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:10,088 INFO:     Epoch: 57
2022-11-28 03:41:10,847 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4258119243789803, 'Total loss': 0.4258119243789803} | train loss {'Reaction outcome loss': 0.3176032855145393, 'Total loss': 0.3176032855145393}
2022-11-28 03:41:10,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:10,847 INFO:     Epoch: 58
2022-11-28 03:41:11,603 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3993263662877408, 'Total loss': 0.3993263662877408} | train loss {'Reaction outcome loss': 0.31966883523930467, 'Total loss': 0.31966883523930467}
2022-11-28 03:41:11,604 INFO:     Found new best model at epoch 58
2022-11-28 03:41:11,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:11,605 INFO:     Epoch: 59
2022-11-28 03:41:12,362 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4356478970836509, 'Total loss': 0.4356478970836509} | train loss {'Reaction outcome loss': 0.3113217026656193, 'Total loss': 0.3113217026656193}
2022-11-28 03:41:12,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:12,362 INFO:     Epoch: 60
2022-11-28 03:41:13,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4229257374324582, 'Total loss': 0.4229257374324582} | train loss {'Reaction outcome loss': 0.32059243237299306, 'Total loss': 0.32059243237299306}
2022-11-28 03:41:13,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:13,117 INFO:     Epoch: 61
2022-11-28 03:41:13,871 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3940068496899171, 'Total loss': 0.3940068496899171} | train loss {'Reaction outcome loss': 0.31594266805557475, 'Total loss': 0.31594266805557475}
2022-11-28 03:41:13,871 INFO:     Found new best model at epoch 61
2022-11-28 03:41:13,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:13,872 INFO:     Epoch: 62
2022-11-28 03:41:14,628 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4368400485678153, 'Total loss': 0.4368400485678153} | train loss {'Reaction outcome loss': 0.32152366496983076, 'Total loss': 0.32152366496983076}
2022-11-28 03:41:14,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:14,629 INFO:     Epoch: 63
2022-11-28 03:41:15,384 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43173141608184035, 'Total loss': 0.43173141608184035} | train loss {'Reaction outcome loss': 0.31246304163529026, 'Total loss': 0.31246304163529026}
2022-11-28 03:41:15,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:15,384 INFO:     Epoch: 64
2022-11-28 03:41:16,139 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44514773921533063, 'Total loss': 0.44514773921533063} | train loss {'Reaction outcome loss': 0.3162257290715652, 'Total loss': 0.3162257290715652}
2022-11-28 03:41:16,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:16,139 INFO:     Epoch: 65
2022-11-28 03:41:16,892 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4408659758892926, 'Total loss': 0.4408659758892926} | train loss {'Reaction outcome loss': 0.32407332208728595, 'Total loss': 0.32407332208728595}
2022-11-28 03:41:16,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:16,892 INFO:     Epoch: 66
2022-11-28 03:41:17,643 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4265792430801825, 'Total loss': 0.4265792430801825} | train loss {'Reaction outcome loss': 0.31662603165774095, 'Total loss': 0.31662603165774095}
2022-11-28 03:41:17,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:17,644 INFO:     Epoch: 67
2022-11-28 03:41:18,393 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41902724890546367, 'Total loss': 0.41902724890546367} | train loss {'Reaction outcome loss': 0.31450524172114747, 'Total loss': 0.31450524172114747}
2022-11-28 03:41:18,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:18,393 INFO:     Epoch: 68
2022-11-28 03:41:19,147 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40542737834832887, 'Total loss': 0.40542737834832887} | train loss {'Reaction outcome loss': 0.30424405311444597, 'Total loss': 0.30424405311444597}
2022-11-28 03:41:19,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:19,148 INFO:     Epoch: 69
2022-11-28 03:41:19,899 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42286153069951316, 'Total loss': 0.42286153069951316} | train loss {'Reaction outcome loss': 0.31274739631091153, 'Total loss': 0.31274739631091153}
2022-11-28 03:41:19,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:19,899 INFO:     Epoch: 70
2022-11-28 03:41:20,651 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42828760973431845, 'Total loss': 0.42828760973431845} | train loss {'Reaction outcome loss': 0.3145460361584781, 'Total loss': 0.3145460361584781}
2022-11-28 03:41:20,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:20,651 INFO:     Epoch: 71
2022-11-28 03:41:21,403 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41365341876040806, 'Total loss': 0.41365341876040806} | train loss {'Reaction outcome loss': 0.31516134585704536, 'Total loss': 0.31516134585704536}
2022-11-28 03:41:21,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:21,403 INFO:     Epoch: 72
2022-11-28 03:41:22,149 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39003346589478577, 'Total loss': 0.39003346589478577} | train loss {'Reaction outcome loss': 0.3143103658071449, 'Total loss': 0.3143103658071449}
2022-11-28 03:41:22,150 INFO:     Found new best model at epoch 72
2022-11-28 03:41:22,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:22,150 INFO:     Epoch: 73
2022-11-28 03:41:22,897 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4242772876539014, 'Total loss': 0.4242772876539014} | train loss {'Reaction outcome loss': 0.3076361823045919, 'Total loss': 0.3076361823045919}
2022-11-28 03:41:22,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:22,897 INFO:     Epoch: 74
2022-11-28 03:41:23,649 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42619242722337897, 'Total loss': 0.42619242722337897} | train loss {'Reaction outcome loss': 0.31054033553828636, 'Total loss': 0.31054033553828636}
2022-11-28 03:41:23,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:23,649 INFO:     Epoch: 75
2022-11-28 03:41:24,402 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.422532952983271, 'Total loss': 0.422532952983271} | train loss {'Reaction outcome loss': 0.323027005959903, 'Total loss': 0.323027005959903}
2022-11-28 03:41:24,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:24,402 INFO:     Epoch: 76
2022-11-28 03:41:25,156 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42651107941161504, 'Total loss': 0.42651107941161504} | train loss {'Reaction outcome loss': 0.3193918817316092, 'Total loss': 0.3193918817316092}
2022-11-28 03:41:25,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:25,157 INFO:     Epoch: 77
2022-11-28 03:41:25,907 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4217208664525639, 'Total loss': 0.4217208664525639} | train loss {'Reaction outcome loss': 0.30685960414308694, 'Total loss': 0.30685960414308694}
2022-11-28 03:41:25,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:25,907 INFO:     Epoch: 78
2022-11-28 03:41:26,659 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43549454652450303, 'Total loss': 0.43549454652450303} | train loss {'Reaction outcome loss': 0.3157592654348381, 'Total loss': 0.3157592654348381}
2022-11-28 03:41:26,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:26,660 INFO:     Epoch: 79
2022-11-28 03:41:27,411 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.427379060536623, 'Total loss': 0.427379060536623} | train loss {'Reaction outcome loss': 0.31676940794192976, 'Total loss': 0.31676940794192976}
2022-11-28 03:41:27,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:27,412 INFO:     Epoch: 80
2022-11-28 03:41:28,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42774111371148715, 'Total loss': 0.42774111371148715} | train loss {'Reaction outcome loss': 0.3175525706892292, 'Total loss': 0.3175525706892292}
2022-11-28 03:41:28,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:28,167 INFO:     Epoch: 81
2022-11-28 03:41:28,922 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42329979806461115, 'Total loss': 0.42329979806461115} | train loss {'Reaction outcome loss': 0.3180755015102125, 'Total loss': 0.3180755015102125}
2022-11-28 03:41:28,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:28,922 INFO:     Epoch: 82
2022-11-28 03:41:29,682 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.436148253692822, 'Total loss': 0.436148253692822} | train loss {'Reaction outcome loss': 0.31347839134715255, 'Total loss': 0.31347839134715255}
2022-11-28 03:41:29,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:29,682 INFO:     Epoch: 83
2022-11-28 03:41:30,439 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4345700148154389, 'Total loss': 0.4345700148154389} | train loss {'Reaction outcome loss': 0.31180432495931465, 'Total loss': 0.31180432495931465}
2022-11-28 03:41:30,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:30,439 INFO:     Epoch: 84
2022-11-28 03:41:31,200 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42502638502893125, 'Total loss': 0.42502638502893125} | train loss {'Reaction outcome loss': 0.31437081182675974, 'Total loss': 0.31437081182675974}
2022-11-28 03:41:31,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:31,200 INFO:     Epoch: 85
2022-11-28 03:41:31,959 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41269072314554994, 'Total loss': 0.41269072314554994} | train loss {'Reaction outcome loss': 0.31165534729558614, 'Total loss': 0.31165534729558614}
2022-11-28 03:41:31,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:31,959 INFO:     Epoch: 86
2022-11-28 03:41:32,720 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41797697713429277, 'Total loss': 0.41797697713429277} | train loss {'Reaction outcome loss': 0.31171299348915776, 'Total loss': 0.31171299348915776}
2022-11-28 03:41:32,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:32,720 INFO:     Epoch: 87
2022-11-28 03:41:33,480 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42527035742320796, 'Total loss': 0.42527035742320796} | train loss {'Reaction outcome loss': 0.32140255322860134, 'Total loss': 0.32140255322860134}
2022-11-28 03:41:33,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:33,481 INFO:     Epoch: 88
2022-11-28 03:41:34,236 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43903411382978613, 'Total loss': 0.43903411382978613} | train loss {'Reaction outcome loss': 0.3109933782308813, 'Total loss': 0.3109933782308813}
2022-11-28 03:41:34,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:34,236 INFO:     Epoch: 89
2022-11-28 03:41:34,994 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40195837345990265, 'Total loss': 0.40195837345990265} | train loss {'Reaction outcome loss': 0.31413812615397957, 'Total loss': 0.31413812615397957}
2022-11-28 03:41:34,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:34,994 INFO:     Epoch: 90
2022-11-28 03:41:35,756 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4217568122866479, 'Total loss': 0.4217568122866479} | train loss {'Reaction outcome loss': 0.3100406111428334, 'Total loss': 0.3100406111428334}
2022-11-28 03:41:35,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:35,757 INFO:     Epoch: 91
2022-11-28 03:41:36,515 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4235298156060956, 'Total loss': 0.4235298156060956} | train loss {'Reaction outcome loss': 0.3108601460473672, 'Total loss': 0.3108601460473672}
2022-11-28 03:41:36,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:36,515 INFO:     Epoch: 92
2022-11-28 03:41:37,274 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4445474144410003, 'Total loss': 0.4445474144410003} | train loss {'Reaction outcome loss': 0.3098068830046442, 'Total loss': 0.3098068830046442}
2022-11-28 03:41:37,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:37,274 INFO:     Epoch: 93
2022-11-28 03:41:38,030 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4263054813173684, 'Total loss': 0.4263054813173684} | train loss {'Reaction outcome loss': 0.3015414722143642, 'Total loss': 0.3015414722143642}
2022-11-28 03:41:38,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:38,030 INFO:     Epoch: 94
2022-11-28 03:41:38,793 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4241722751070153, 'Total loss': 0.4241722751070153} | train loss {'Reaction outcome loss': 0.30903670080606976, 'Total loss': 0.30903670080606976}
2022-11-28 03:41:38,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:38,793 INFO:     Epoch: 95
2022-11-28 03:41:39,555 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42972123114900157, 'Total loss': 0.42972123114900157} | train loss {'Reaction outcome loss': 0.31494501468935804, 'Total loss': 0.31494501468935804}
2022-11-28 03:41:39,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:39,556 INFO:     Epoch: 96
2022-11-28 03:41:40,316 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44947386465289374, 'Total loss': 0.44947386465289374} | train loss {'Reaction outcome loss': 0.3122836847399031, 'Total loss': 0.3122836847399031}
2022-11-28 03:41:40,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:40,316 INFO:     Epoch: 97
2022-11-28 03:41:41,073 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4098368818787011, 'Total loss': 0.4098368818787011} | train loss {'Reaction outcome loss': 0.3117680442970126, 'Total loss': 0.3117680442970126}
2022-11-28 03:41:41,073 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:41,073 INFO:     Epoch: 98
2022-11-28 03:41:41,836 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4209806438196789, 'Total loss': 0.4209806438196789} | train loss {'Reaction outcome loss': 0.31112550766838176, 'Total loss': 0.31112550766838176}
2022-11-28 03:41:41,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:41,836 INFO:     Epoch: 99
2022-11-28 03:41:42,594 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41929563744501636, 'Total loss': 0.41929563744501636} | train loss {'Reaction outcome loss': 0.30355723107594157, 'Total loss': 0.30355723107594157}
2022-11-28 03:41:42,595 INFO:     Best model found after epoch 73 of 100.
2022-11-28 03:41:42,595 INFO:   Done with stage: TRAINING
2022-11-28 03:41:42,595 INFO:   Starting stage: EVALUATION
2022-11-28 03:41:42,711 INFO:   Done with stage: EVALUATION
2022-11-28 03:41:42,712 INFO:   Leaving out SEQ value Fold_5
2022-11-28 03:41:42,725 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:41:42,725 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:41:43,369 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:41:43,369 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:41:43,437 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:41:43,438 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:41:43,438 INFO:     No hyperparam tuning for this model
2022-11-28 03:41:43,438 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:41:43,438 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:41:43,438 INFO:     None feature selector for col prot
2022-11-28 03:41:43,439 INFO:     None feature selector for col prot
2022-11-28 03:41:43,439 INFO:     None feature selector for col prot
2022-11-28 03:41:43,439 INFO:     None feature selector for col chem
2022-11-28 03:41:43,439 INFO:     None feature selector for col chem
2022-11-28 03:41:43,439 INFO:     None feature selector for col chem
2022-11-28 03:41:43,440 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:41:43,440 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:41:43,441 INFO:     Number of params in model 169741
2022-11-28 03:41:43,444 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:41:43,444 INFO:   Starting stage: TRAINING
2022-11-28 03:41:43,499 INFO:     Val loss before train {'Reaction outcome loss': 1.0524302544918926, 'Total loss': 1.0524302544918926}
2022-11-28 03:41:43,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:43,499 INFO:     Epoch: 0
2022-11-28 03:41:44,247 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5645540620792996, 'Total loss': 0.5645540620792996} | train loss {'Reaction outcome loss': 0.6501311088703117, 'Total loss': 0.6501311088703117}
2022-11-28 03:41:44,247 INFO:     Found new best model at epoch 0
2022-11-28 03:41:44,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:44,248 INFO:     Epoch: 1
2022-11-28 03:41:44,997 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5274903201921419, 'Total loss': 0.5274903201921419} | train loss {'Reaction outcome loss': 0.4922109914677484, 'Total loss': 0.4922109914677484}
2022-11-28 03:41:44,997 INFO:     Found new best model at epoch 1
2022-11-28 03:41:44,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:44,998 INFO:     Epoch: 2
2022-11-28 03:41:45,746 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49753734973174607, 'Total loss': 0.49753734973174607} | train loss {'Reaction outcome loss': 0.45785252956711514, 'Total loss': 0.45785252956711514}
2022-11-28 03:41:45,747 INFO:     Found new best model at epoch 2
2022-11-28 03:41:45,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:45,747 INFO:     Epoch: 3
2022-11-28 03:41:46,500 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49713286859068, 'Total loss': 0.49713286859068} | train loss {'Reaction outcome loss': 0.43460889376547873, 'Total loss': 0.43460889376547873}
2022-11-28 03:41:46,500 INFO:     Found new best model at epoch 3
2022-11-28 03:41:46,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:46,501 INFO:     Epoch: 4
2022-11-28 03:41:47,249 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49627369168129837, 'Total loss': 0.49627369168129837} | train loss {'Reaction outcome loss': 0.4221998995360063, 'Total loss': 0.4221998995360063}
2022-11-28 03:41:47,249 INFO:     Found new best model at epoch 4
2022-11-28 03:41:47,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:47,250 INFO:     Epoch: 5
2022-11-28 03:41:48,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5041156925938346, 'Total loss': 0.5041156925938346} | train loss {'Reaction outcome loss': 0.395368384037699, 'Total loss': 0.395368384037699}
2022-11-28 03:41:48,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:48,001 INFO:     Epoch: 6
2022-11-28 03:41:48,749 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47325205481187865, 'Total loss': 0.47325205481187865} | train loss {'Reaction outcome loss': 0.39705807992390224, 'Total loss': 0.39705807992390224}
2022-11-28 03:41:48,749 INFO:     Found new best model at epoch 6
2022-11-28 03:41:48,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:48,750 INFO:     Epoch: 7
2022-11-28 03:41:49,503 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4413357292386619, 'Total loss': 0.4413357292386619} | train loss {'Reaction outcome loss': 0.3894958947234008, 'Total loss': 0.3894958947234008}
2022-11-28 03:41:49,504 INFO:     Found new best model at epoch 7
2022-11-28 03:41:49,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:49,504 INFO:     Epoch: 8
2022-11-28 03:41:50,258 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4989366399293596, 'Total loss': 0.4989366399293596} | train loss {'Reaction outcome loss': 0.37202318435420795, 'Total loss': 0.37202318435420795}
2022-11-28 03:41:50,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:50,258 INFO:     Epoch: 9
2022-11-28 03:41:51,008 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46860074726018036, 'Total loss': 0.46860074726018036} | train loss {'Reaction outcome loss': 0.3709967319758571, 'Total loss': 0.3709967319758571}
2022-11-28 03:41:51,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:51,009 INFO:     Epoch: 10
2022-11-28 03:41:51,763 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4901384575800462, 'Total loss': 0.4901384575800462} | train loss {'Reaction outcome loss': 0.3674532173239455, 'Total loss': 0.3674532173239455}
2022-11-28 03:41:51,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:51,764 INFO:     Epoch: 11
2022-11-28 03:41:52,515 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4651521671224724, 'Total loss': 0.4651521671224724} | train loss {'Reaction outcome loss': 0.35901182144880295, 'Total loss': 0.35901182144880295}
2022-11-28 03:41:52,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:52,515 INFO:     Epoch: 12
2022-11-28 03:41:53,264 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4775214744308455, 'Total loss': 0.4775214744308455} | train loss {'Reaction outcome loss': 0.35947296795796374, 'Total loss': 0.35947296795796374}
2022-11-28 03:41:53,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:53,264 INFO:     Epoch: 13
2022-11-28 03:41:54,014 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4643680985001, 'Total loss': 0.4643680985001} | train loss {'Reaction outcome loss': 0.3484418800746908, 'Total loss': 0.3484418800746908}
2022-11-28 03:41:54,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:54,015 INFO:     Epoch: 14
2022-11-28 03:41:54,769 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4535028104755012, 'Total loss': 0.4535028104755012} | train loss {'Reaction outcome loss': 0.35234626975594735, 'Total loss': 0.35234626975594735}
2022-11-28 03:41:54,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:54,770 INFO:     Epoch: 15
2022-11-28 03:41:55,522 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44444136694073677, 'Total loss': 0.44444136694073677} | train loss {'Reaction outcome loss': 0.3378429982735186, 'Total loss': 0.3378429982735186}
2022-11-28 03:41:55,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:55,523 INFO:     Epoch: 16
2022-11-28 03:41:56,272 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47566131654788146, 'Total loss': 0.47566131654788146} | train loss {'Reaction outcome loss': 0.3334631686307946, 'Total loss': 0.3334631686307946}
2022-11-28 03:41:56,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:56,273 INFO:     Epoch: 17
2022-11-28 03:41:57,023 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4940940827469934, 'Total loss': 0.4940940827469934} | train loss {'Reaction outcome loss': 0.32911773436531727, 'Total loss': 0.32911773436531727}
2022-11-28 03:41:57,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:57,024 INFO:     Epoch: 18
2022-11-28 03:41:57,773 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4710470194166357, 'Total loss': 0.4710470194166357} | train loss {'Reaction outcome loss': 0.340675087333942, 'Total loss': 0.340675087333942}
2022-11-28 03:41:57,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:57,774 INFO:     Epoch: 19
2022-11-28 03:41:58,522 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4984054006636143, 'Total loss': 0.4984054006636143} | train loss {'Reaction outcome loss': 0.3317183414284064, 'Total loss': 0.3317183414284064}
2022-11-28 03:41:58,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:58,522 INFO:     Epoch: 20
2022-11-28 03:41:59,269 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4382554837925868, 'Total loss': 0.4382554837925868} | train loss {'Reaction outcome loss': 0.33047543213683733, 'Total loss': 0.33047543213683733}
2022-11-28 03:41:59,269 INFO:     Found new best model at epoch 20
2022-11-28 03:41:59,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:41:59,270 INFO:     Epoch: 21
2022-11-28 03:42:00,018 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45851953742517665, 'Total loss': 0.45851953742517665} | train loss {'Reaction outcome loss': 0.32571862102771293, 'Total loss': 0.32571862102771293}
2022-11-28 03:42:00,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:00,019 INFO:     Epoch: 22
2022-11-28 03:42:00,770 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44180898571556265, 'Total loss': 0.44180898571556265} | train loss {'Reaction outcome loss': 0.32700469618549155, 'Total loss': 0.32700469618549155}
2022-11-28 03:42:00,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:00,770 INFO:     Epoch: 23
2022-11-28 03:42:01,522 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49909728663888847, 'Total loss': 0.49909728663888847} | train loss {'Reaction outcome loss': 0.3339803997655304, 'Total loss': 0.3339803997655304}
2022-11-28 03:42:01,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:01,522 INFO:     Epoch: 24
2022-11-28 03:42:02,270 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5103482935916294, 'Total loss': 0.5103482935916294} | train loss {'Reaction outcome loss': 0.33668448179960253, 'Total loss': 0.33668448179960253}
2022-11-28 03:42:02,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:02,270 INFO:     Epoch: 25
2022-11-28 03:42:03,018 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4455339297313582, 'Total loss': 0.4455339297313582} | train loss {'Reaction outcome loss': 0.3200076599206243, 'Total loss': 0.3200076599206243}
2022-11-28 03:42:03,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:03,019 INFO:     Epoch: 26
2022-11-28 03:42:03,767 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4552314355969429, 'Total loss': 0.4552314355969429} | train loss {'Reaction outcome loss': 0.3167069378403985, 'Total loss': 0.3167069378403985}
2022-11-28 03:42:03,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:03,767 INFO:     Epoch: 27
2022-11-28 03:42:04,516 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4754344727844, 'Total loss': 0.4754344727844} | train loss {'Reaction outcome loss': 0.3090453852652287, 'Total loss': 0.3090453852652287}
2022-11-28 03:42:04,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:04,517 INFO:     Epoch: 28
2022-11-28 03:42:05,268 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4618480823172087, 'Total loss': 0.4618480823172087} | train loss {'Reaction outcome loss': 0.31060141516583306, 'Total loss': 0.31060141516583306}
2022-11-28 03:42:05,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:05,268 INFO:     Epoch: 29
2022-11-28 03:42:06,019 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4469356465746056, 'Total loss': 0.4469356465746056} | train loss {'Reaction outcome loss': 0.32072923451053853, 'Total loss': 0.32072923451053853}
2022-11-28 03:42:06,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:06,019 INFO:     Epoch: 30
2022-11-28 03:42:06,767 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4428122107955543, 'Total loss': 0.4428122107955543} | train loss {'Reaction outcome loss': 0.30200534820252534, 'Total loss': 0.30200534820252534}
2022-11-28 03:42:06,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:06,767 INFO:     Epoch: 31
2022-11-28 03:42:07,516 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45889490707354114, 'Total loss': 0.45889490707354114} | train loss {'Reaction outcome loss': 0.304486811830073, 'Total loss': 0.304486811830073}
2022-11-28 03:42:07,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:07,517 INFO:     Epoch: 32
2022-11-28 03:42:08,266 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4745937040583654, 'Total loss': 0.4745937040583654} | train loss {'Reaction outcome loss': 0.3103147524808134, 'Total loss': 0.3103147524808134}
2022-11-28 03:42:08,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:08,267 INFO:     Epoch: 33
2022-11-28 03:42:09,017 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5212621878493916, 'Total loss': 0.5212621878493916} | train loss {'Reaction outcome loss': 0.3102329470977491, 'Total loss': 0.3102329470977491}
2022-11-28 03:42:09,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:09,017 INFO:     Epoch: 34
2022-11-28 03:42:09,768 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4431449135088108, 'Total loss': 0.4431449135088108} | train loss {'Reaction outcome loss': 0.3071461454642062, 'Total loss': 0.3071461454642062}
2022-11-28 03:42:09,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:09,769 INFO:     Epoch: 35
2022-11-28 03:42:10,520 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4565782255747102, 'Total loss': 0.4565782255747102} | train loss {'Reaction outcome loss': 0.30708149172821825, 'Total loss': 0.30708149172821825}
2022-11-28 03:42:10,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:10,521 INFO:     Epoch: 36
2022-11-28 03:42:11,274 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4714578378268264, 'Total loss': 0.4714578378268264} | train loss {'Reaction outcome loss': 0.310179524655853, 'Total loss': 0.310179524655853}
2022-11-28 03:42:11,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:11,274 INFO:     Epoch: 37
2022-11-28 03:42:12,026 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46368697929111397, 'Total loss': 0.46368697929111397} | train loss {'Reaction outcome loss': 0.30191239301039247, 'Total loss': 0.30191239301039247}
2022-11-28 03:42:12,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:12,026 INFO:     Epoch: 38
2022-11-28 03:42:12,776 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4479609839618206, 'Total loss': 0.4479609839618206} | train loss {'Reaction outcome loss': 0.3063328147390667, 'Total loss': 0.3063328147390667}
2022-11-28 03:42:12,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:12,776 INFO:     Epoch: 39
2022-11-28 03:42:13,526 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4578509757464582, 'Total loss': 0.4578509757464582} | train loss {'Reaction outcome loss': 0.2929512442070611, 'Total loss': 0.2929512442070611}
2022-11-28 03:42:13,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:13,526 INFO:     Epoch: 40
2022-11-28 03:42:14,277 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46745221757076005, 'Total loss': 0.46745221757076005} | train loss {'Reaction outcome loss': 0.3098764617224129, 'Total loss': 0.3098764617224129}
2022-11-28 03:42:14,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:14,277 INFO:     Epoch: 41
2022-11-28 03:42:15,028 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47664637762037193, 'Total loss': 0.47664637762037193} | train loss {'Reaction outcome loss': 0.3109527214145174, 'Total loss': 0.3109527214145174}
2022-11-28 03:42:15,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:15,028 INFO:     Epoch: 42
2022-11-28 03:42:15,778 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4504317690364339, 'Total loss': 0.4504317690364339} | train loss {'Reaction outcome loss': 0.3052117969308581, 'Total loss': 0.3052117969308581}
2022-11-28 03:42:15,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:15,778 INFO:     Epoch: 43
2022-11-28 03:42:16,530 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44793884574689646, 'Total loss': 0.44793884574689646} | train loss {'Reaction outcome loss': 0.30156351847916235, 'Total loss': 0.30156351847916235}
2022-11-28 03:42:16,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:16,531 INFO:     Epoch: 44
2022-11-28 03:42:17,282 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45479960773478856, 'Total loss': 0.45479960773478856} | train loss {'Reaction outcome loss': 0.2970867645375583, 'Total loss': 0.2970867645375583}
2022-11-28 03:42:17,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:17,282 INFO:     Epoch: 45
2022-11-28 03:42:18,034 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4346682293848558, 'Total loss': 0.4346682293848558} | train loss {'Reaction outcome loss': 0.30125148685611025, 'Total loss': 0.30125148685611025}
2022-11-28 03:42:18,034 INFO:     Found new best model at epoch 45
2022-11-28 03:42:18,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:18,035 INFO:     Epoch: 46
2022-11-28 03:42:18,783 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46216551993380894, 'Total loss': 0.46216551993380894} | train loss {'Reaction outcome loss': 0.2985406278043377, 'Total loss': 0.2985406278043377}
2022-11-28 03:42:18,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:18,783 INFO:     Epoch: 47
2022-11-28 03:42:19,533 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43715965368425136, 'Total loss': 0.43715965368425136} | train loss {'Reaction outcome loss': 0.3007317379117012, 'Total loss': 0.3007317379117012}
2022-11-28 03:42:19,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:19,533 INFO:     Epoch: 48
2022-11-28 03:42:20,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5110927718606862, 'Total loss': 0.5110927718606862} | train loss {'Reaction outcome loss': 0.29777498392730345, 'Total loss': 0.29777498392730345}
2022-11-28 03:42:20,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:20,281 INFO:     Epoch: 49
2022-11-28 03:42:21,034 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4855794224210761, 'Total loss': 0.4855794224210761} | train loss {'Reaction outcome loss': 0.2991687632945119, 'Total loss': 0.2991687632945119}
2022-11-28 03:42:21,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:21,034 INFO:     Epoch: 50
2022-11-28 03:42:21,788 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4466472567821091, 'Total loss': 0.4466472567821091} | train loss {'Reaction outcome loss': 0.30066606457136114, 'Total loss': 0.30066606457136114}
2022-11-28 03:42:21,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:21,788 INFO:     Epoch: 51
2022-11-28 03:42:22,540 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4835061742500825, 'Total loss': 0.4835061742500825} | train loss {'Reaction outcome loss': 0.30599480072150426, 'Total loss': 0.30599480072150426}
2022-11-28 03:42:22,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:22,541 INFO:     Epoch: 52
2022-11-28 03:42:23,293 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.462564178827134, 'Total loss': 0.462564178827134} | train loss {'Reaction outcome loss': 0.2984472991404485, 'Total loss': 0.2984472991404485}
2022-11-28 03:42:23,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:23,293 INFO:     Epoch: 53
2022-11-28 03:42:24,044 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47011626240882004, 'Total loss': 0.47011626240882004} | train loss {'Reaction outcome loss': 0.2942903633628573, 'Total loss': 0.2942903633628573}
2022-11-28 03:42:24,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:24,044 INFO:     Epoch: 54
2022-11-28 03:42:24,799 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45626718855716963, 'Total loss': 0.45626718855716963} | train loss {'Reaction outcome loss': 0.29910694540155175, 'Total loss': 0.29910694540155175}
2022-11-28 03:42:24,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:24,799 INFO:     Epoch: 55
2022-11-28 03:42:25,551 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5106675049120729, 'Total loss': 0.5106675049120729} | train loss {'Reaction outcome loss': 0.2932553276875798, 'Total loss': 0.2932553276875798}
2022-11-28 03:42:25,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:25,552 INFO:     Epoch: 56
2022-11-28 03:42:26,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4741629897193475, 'Total loss': 0.4741629897193475} | train loss {'Reaction outcome loss': 0.2874303362199238, 'Total loss': 0.2874303362199238}
2022-11-28 03:42:26,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:26,305 INFO:     Epoch: 57
2022-11-28 03:42:27,058 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46862644431265915, 'Total loss': 0.46862644431265915} | train loss {'Reaction outcome loss': 0.29232654903008015, 'Total loss': 0.29232654903008015}
2022-11-28 03:42:27,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:27,058 INFO:     Epoch: 58
2022-11-28 03:42:27,808 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4909819151190194, 'Total loss': 0.4909819151190194} | train loss {'Reaction outcome loss': 0.29420944021976725, 'Total loss': 0.29420944021976725}
2022-11-28 03:42:27,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:27,808 INFO:     Epoch: 59
2022-11-28 03:42:28,561 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4691432357173074, 'Total loss': 0.4691432357173074} | train loss {'Reaction outcome loss': 0.3018167181282627, 'Total loss': 0.3018167181282627}
2022-11-28 03:42:28,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:28,562 INFO:     Epoch: 60
2022-11-28 03:42:29,313 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.464490011673082, 'Total loss': 0.464490011673082} | train loss {'Reaction outcome loss': 0.29882852514179387, 'Total loss': 0.29882852514179387}
2022-11-28 03:42:29,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:29,314 INFO:     Epoch: 61
2022-11-28 03:42:30,070 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46220984479243105, 'Total loss': 0.46220984479243105} | train loss {'Reaction outcome loss': 0.289081078342029, 'Total loss': 0.289081078342029}
2022-11-28 03:42:30,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:30,070 INFO:     Epoch: 62
2022-11-28 03:42:30,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45825651017102326, 'Total loss': 0.45825651017102326} | train loss {'Reaction outcome loss': 0.29865262608747095, 'Total loss': 0.29865262608747095}
2022-11-28 03:42:30,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:30,823 INFO:     Epoch: 63
2022-11-28 03:42:31,576 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46187229962511495, 'Total loss': 0.46187229962511495} | train loss {'Reaction outcome loss': 0.2830627968724893, 'Total loss': 0.2830627968724893}
2022-11-28 03:42:31,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:31,576 INFO:     Epoch: 64
2022-11-28 03:42:32,335 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44807344945994293, 'Total loss': 0.44807344945994293} | train loss {'Reaction outcome loss': 0.2922391239325611, 'Total loss': 0.2922391239325611}
2022-11-28 03:42:32,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:32,335 INFO:     Epoch: 65
2022-11-28 03:42:33,086 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4762015240690248, 'Total loss': 0.4762015240690248} | train loss {'Reaction outcome loss': 0.2905216041420187, 'Total loss': 0.2905216041420187}
2022-11-28 03:42:33,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:33,086 INFO:     Epoch: 66
2022-11-28 03:42:33,837 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46721387265080755, 'Total loss': 0.46721387265080755} | train loss {'Reaction outcome loss': 0.29607851012628905, 'Total loss': 0.29607851012628905}
2022-11-28 03:42:33,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:33,837 INFO:     Epoch: 67
2022-11-28 03:42:34,587 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4719636768779971, 'Total loss': 0.4719636768779971} | train loss {'Reaction outcome loss': 0.2821116791087754, 'Total loss': 0.2821116791087754}
2022-11-28 03:42:34,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:34,587 INFO:     Epoch: 68
2022-11-28 03:42:35,340 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47561501169746573, 'Total loss': 0.47561501169746573} | train loss {'Reaction outcome loss': 0.2949658170342445, 'Total loss': 0.2949658170342445}
2022-11-28 03:42:35,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:35,340 INFO:     Epoch: 69
2022-11-28 03:42:36,091 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4709796675226905, 'Total loss': 0.4709796675226905} | train loss {'Reaction outcome loss': 0.2924104490146345, 'Total loss': 0.2924104490146345}
2022-11-28 03:42:36,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:36,091 INFO:     Epoch: 70
2022-11-28 03:42:36,842 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4770521336997097, 'Total loss': 0.4770521336997097} | train loss {'Reaction outcome loss': 0.2977596049710196, 'Total loss': 0.2977596049710196}
2022-11-28 03:42:36,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:36,842 INFO:     Epoch: 71
2022-11-28 03:42:37,595 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.440202593464743, 'Total loss': 0.440202593464743} | train loss {'Reaction outcome loss': 0.28577640807750276, 'Total loss': 0.28577640807750276}
2022-11-28 03:42:37,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:37,595 INFO:     Epoch: 72
2022-11-28 03:42:38,347 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4656278629871932, 'Total loss': 0.4656278629871932} | train loss {'Reaction outcome loss': 0.29327157671962467, 'Total loss': 0.29327157671962467}
2022-11-28 03:42:38,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:38,347 INFO:     Epoch: 73
2022-11-28 03:42:39,101 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44355588211593305, 'Total loss': 0.44355588211593305} | train loss {'Reaction outcome loss': 0.28387043917057464, 'Total loss': 0.28387043917057464}
2022-11-28 03:42:39,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:39,101 INFO:     Epoch: 74
2022-11-28 03:42:39,853 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4729146486656232, 'Total loss': 0.4729146486656232} | train loss {'Reaction outcome loss': 0.29938665181398394, 'Total loss': 0.29938665181398394}
2022-11-28 03:42:39,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:39,853 INFO:     Epoch: 75
2022-11-28 03:42:40,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44925209507346153, 'Total loss': 0.44925209507346153} | train loss {'Reaction outcome loss': 0.28627087195612944, 'Total loss': 0.28627087195612944}
2022-11-28 03:42:40,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:40,605 INFO:     Epoch: 76
2022-11-28 03:42:41,356 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5048337334936316, 'Total loss': 0.5048337334936316} | train loss {'Reaction outcome loss': 0.2879649982768662, 'Total loss': 0.2879649982768662}
2022-11-28 03:42:41,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:41,357 INFO:     Epoch: 77
2022-11-28 03:42:42,104 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46844667331738904, 'Total loss': 0.46844667331738904} | train loss {'Reaction outcome loss': 0.2974553363055599, 'Total loss': 0.2974553363055599}
2022-11-28 03:42:42,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:42,105 INFO:     Epoch: 78
2022-11-28 03:42:42,851 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4636615314944224, 'Total loss': 0.4636615314944224} | train loss {'Reaction outcome loss': 0.29345853614563844, 'Total loss': 0.29345853614563844}
2022-11-28 03:42:42,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:42,851 INFO:     Epoch: 79
2022-11-28 03:42:43,599 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4400664766065099, 'Total loss': 0.4400664766065099} | train loss {'Reaction outcome loss': 0.285478685233666, 'Total loss': 0.285478685233666}
2022-11-28 03:42:43,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:43,599 INFO:     Epoch: 80
2022-11-28 03:42:44,348 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44438182054595515, 'Total loss': 0.44438182054595515} | train loss {'Reaction outcome loss': 0.2943598907516927, 'Total loss': 0.2943598907516927}
2022-11-28 03:42:44,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:44,348 INFO:     Epoch: 81
2022-11-28 03:42:45,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45347399059127463, 'Total loss': 0.45347399059127463} | train loss {'Reaction outcome loss': 0.2976065701672009, 'Total loss': 0.2976065701672009}
2022-11-28 03:42:45,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:45,095 INFO:     Epoch: 82
2022-11-28 03:42:45,841 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44983245127580385, 'Total loss': 0.44983245127580385} | train loss {'Reaction outcome loss': 0.2714638343270944, 'Total loss': 0.2714638343270944}
2022-11-28 03:42:45,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:45,841 INFO:     Epoch: 83
2022-11-28 03:42:46,588 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4543558562343771, 'Total loss': 0.4543558562343771} | train loss {'Reaction outcome loss': 0.2905889238630022, 'Total loss': 0.2905889238630022}
2022-11-28 03:42:46,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:46,588 INFO:     Epoch: 84
2022-11-28 03:42:47,334 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47290770370851865, 'Total loss': 0.47290770370851865} | train loss {'Reaction outcome loss': 0.2895487790205041, 'Total loss': 0.2895487790205041}
2022-11-28 03:42:47,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:47,335 INFO:     Epoch: 85
2022-11-28 03:42:48,081 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4687258790839802, 'Total loss': 0.4687258790839802} | train loss {'Reaction outcome loss': 0.29413692291293825, 'Total loss': 0.29413692291293825}
2022-11-28 03:42:48,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:48,081 INFO:     Epoch: 86
2022-11-28 03:42:48,827 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4822768924588507, 'Total loss': 0.4822768924588507} | train loss {'Reaction outcome loss': 0.2856042376130211, 'Total loss': 0.2856042376130211}
2022-11-28 03:42:48,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:48,828 INFO:     Epoch: 87
2022-11-28 03:42:49,573 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5102896751327948, 'Total loss': 0.5102896751327948} | train loss {'Reaction outcome loss': 0.29325461002941033, 'Total loss': 0.29325461002941033}
2022-11-28 03:42:49,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:49,573 INFO:     Epoch: 88
2022-11-28 03:42:50,320 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4484111988408999, 'Total loss': 0.4484111988408999} | train loss {'Reaction outcome loss': 0.2913468714271273, 'Total loss': 0.2913468714271273}
2022-11-28 03:42:50,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:50,320 INFO:     Epoch: 89
2022-11-28 03:42:51,069 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4877933595668186, 'Total loss': 0.4877933595668186} | train loss {'Reaction outcome loss': 0.2950238094950209, 'Total loss': 0.2950238094950209}
2022-11-28 03:42:51,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:51,069 INFO:     Epoch: 90
2022-11-28 03:42:51,813 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.444729832932353, 'Total loss': 0.444729832932353} | train loss {'Reaction outcome loss': 0.3010612767721925, 'Total loss': 0.3010612767721925}
2022-11-28 03:42:51,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:51,813 INFO:     Epoch: 91
2022-11-28 03:42:52,560 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4947275197641416, 'Total loss': 0.4947275197641416} | train loss {'Reaction outcome loss': 0.28965741210446067, 'Total loss': 0.28965741210446067}
2022-11-28 03:42:52,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:52,560 INFO:     Epoch: 92
2022-11-28 03:42:53,307 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42542242572050204, 'Total loss': 0.42542242572050204} | train loss {'Reaction outcome loss': 0.28612553094114573, 'Total loss': 0.28612553094114573}
2022-11-28 03:42:53,307 INFO:     Found new best model at epoch 92
2022-11-28 03:42:53,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:53,308 INFO:     Epoch: 93
2022-11-28 03:42:54,052 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4377289732748812, 'Total loss': 0.4377289732748812} | train loss {'Reaction outcome loss': 0.2823777667873976, 'Total loss': 0.2823777667873976}
2022-11-28 03:42:54,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:54,053 INFO:     Epoch: 94
2022-11-28 03:42:54,799 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4305124430155212, 'Total loss': 0.4305124430155212} | train loss {'Reaction outcome loss': 0.29066925722421433, 'Total loss': 0.29066925722421433}
2022-11-28 03:42:54,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:54,799 INFO:     Epoch: 95
2022-11-28 03:42:55,547 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49492949281226506, 'Total loss': 0.49492949281226506} | train loss {'Reaction outcome loss': 0.2902348671792721, 'Total loss': 0.2902348671792721}
2022-11-28 03:42:55,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:55,547 INFO:     Epoch: 96
2022-11-28 03:42:56,293 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43558269925415516, 'Total loss': 0.43558269925415516} | train loss {'Reaction outcome loss': 0.28941289045828944, 'Total loss': 0.28941289045828944}
2022-11-28 03:42:56,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:56,293 INFO:     Epoch: 97
2022-11-28 03:42:57,040 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4703578583218835, 'Total loss': 0.4703578583218835} | train loss {'Reaction outcome loss': 0.28595319408543257, 'Total loss': 0.28595319408543257}
2022-11-28 03:42:57,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:57,041 INFO:     Epoch: 98
2022-11-28 03:42:57,788 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4545385116203265, 'Total loss': 0.4545385116203265} | train loss {'Reaction outcome loss': 0.2905616432846505, 'Total loss': 0.2905616432846505}
2022-11-28 03:42:57,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:57,788 INFO:     Epoch: 99
2022-11-28 03:42:58,534 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45198462742634793, 'Total loss': 0.45198462742634793} | train loss {'Reaction outcome loss': 0.2848163627544228, 'Total loss': 0.2848163627544228}
2022-11-28 03:42:58,535 INFO:     Best model found after epoch 93 of 100.
2022-11-28 03:42:58,535 INFO:   Done with stage: TRAINING
2022-11-28 03:42:58,535 INFO:   Starting stage: EVALUATION
2022-11-28 03:42:58,661 INFO:   Done with stage: EVALUATION
2022-11-28 03:42:58,662 INFO:   Leaving out SEQ value Fold_6
2022-11-28 03:42:58,675 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:42:58,675 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:42:59,327 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:42:59,327 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:42:59,397 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:42:59,397 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:42:59,397 INFO:     No hyperparam tuning for this model
2022-11-28 03:42:59,397 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:42:59,397 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:42:59,398 INFO:     None feature selector for col prot
2022-11-28 03:42:59,398 INFO:     None feature selector for col prot
2022-11-28 03:42:59,398 INFO:     None feature selector for col prot
2022-11-28 03:42:59,399 INFO:     None feature selector for col chem
2022-11-28 03:42:59,399 INFO:     None feature selector for col chem
2022-11-28 03:42:59,399 INFO:     None feature selector for col chem
2022-11-28 03:42:59,399 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:42:59,399 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:42:59,400 INFO:     Number of params in model 169741
2022-11-28 03:42:59,404 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:42:59,404 INFO:   Starting stage: TRAINING
2022-11-28 03:42:59,461 INFO:     Val loss before train {'Reaction outcome loss': 1.0143084824085236, 'Total loss': 1.0143084824085236}
2022-11-28 03:42:59,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:42:59,461 INFO:     Epoch: 0
2022-11-28 03:43:00,220 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5541142543608492, 'Total loss': 0.5541142543608492} | train loss {'Reaction outcome loss': 0.6513322821307567, 'Total loss': 0.6513322821307567}
2022-11-28 03:43:00,220 INFO:     Found new best model at epoch 0
2022-11-28 03:43:00,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:00,221 INFO:     Epoch: 1
2022-11-28 03:43:00,975 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5289969688112085, 'Total loss': 0.5289969688112085} | train loss {'Reaction outcome loss': 0.5135496463025769, 'Total loss': 0.5135496463025769}
2022-11-28 03:43:00,976 INFO:     Found new best model at epoch 1
2022-11-28 03:43:00,977 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:00,977 INFO:     Epoch: 2
2022-11-28 03:43:01,728 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46754317730665207, 'Total loss': 0.46754317730665207} | train loss {'Reaction outcome loss': 0.4689961730111991, 'Total loss': 0.4689961730111991}
2022-11-28 03:43:01,728 INFO:     Found new best model at epoch 2
2022-11-28 03:43:01,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:01,729 INFO:     Epoch: 3
2022-11-28 03:43:02,484 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5124650726264174, 'Total loss': 0.5124650726264174} | train loss {'Reaction outcome loss': 0.45091555513922243, 'Total loss': 0.45091555513922243}
2022-11-28 03:43:02,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:02,485 INFO:     Epoch: 4
2022-11-28 03:43:03,239 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45873643593354657, 'Total loss': 0.45873643593354657} | train loss {'Reaction outcome loss': 0.4290300326481942, 'Total loss': 0.4290300326481942}
2022-11-28 03:43:03,239 INFO:     Found new best model at epoch 4
2022-11-28 03:43:03,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:03,240 INFO:     Epoch: 5
2022-11-28 03:43:03,992 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4521308961239728, 'Total loss': 0.4521308961239728} | train loss {'Reaction outcome loss': 0.4224346586533131, 'Total loss': 0.4224346586533131}
2022-11-28 03:43:03,992 INFO:     Found new best model at epoch 5
2022-11-28 03:43:03,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:03,993 INFO:     Epoch: 6
2022-11-28 03:43:04,748 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4619091044772755, 'Total loss': 0.4619091044772755} | train loss {'Reaction outcome loss': 0.40405038437776025, 'Total loss': 0.40405038437776025}
2022-11-28 03:43:04,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:04,748 INFO:     Epoch: 7
2022-11-28 03:43:05,500 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5130034190687266, 'Total loss': 0.5130034190687266} | train loss {'Reaction outcome loss': 0.4045359855217318, 'Total loss': 0.4045359855217318}
2022-11-28 03:43:05,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:05,500 INFO:     Epoch: 8
2022-11-28 03:43:06,255 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45020327446135605, 'Total loss': 0.45020327446135605} | train loss {'Reaction outcome loss': 0.4016548777900396, 'Total loss': 0.4016548777900396}
2022-11-28 03:43:06,255 INFO:     Found new best model at epoch 8
2022-11-28 03:43:06,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:06,256 INFO:     Epoch: 9
2022-11-28 03:43:07,007 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42571478709578514, 'Total loss': 0.42571478709578514} | train loss {'Reaction outcome loss': 0.38869900941368074, 'Total loss': 0.38869900941368074}
2022-11-28 03:43:07,007 INFO:     Found new best model at epoch 9
2022-11-28 03:43:07,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:07,008 INFO:     Epoch: 10
2022-11-28 03:43:07,764 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42491770975969057, 'Total loss': 0.42491770975969057} | train loss {'Reaction outcome loss': 0.378458165293259, 'Total loss': 0.378458165293259}
2022-11-28 03:43:07,764 INFO:     Found new best model at epoch 10
2022-11-28 03:43:07,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:07,765 INFO:     Epoch: 11
2022-11-28 03:43:08,522 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42536814443089743, 'Total loss': 0.42536814443089743} | train loss {'Reaction outcome loss': 0.3902272576946885, 'Total loss': 0.3902272576946885}
2022-11-28 03:43:08,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:08,522 INFO:     Epoch: 12
2022-11-28 03:43:09,279 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4360126009718938, 'Total loss': 0.4360126009718938} | train loss {'Reaction outcome loss': 0.3714523467595779, 'Total loss': 0.3714523467595779}
2022-11-28 03:43:09,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:09,279 INFO:     Epoch: 13
2022-11-28 03:43:10,033 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4149184582585638, 'Total loss': 0.4149184582585638} | train loss {'Reaction outcome loss': 0.3662907514540899, 'Total loss': 0.3662907514540899}
2022-11-28 03:43:10,033 INFO:     Found new best model at epoch 13
2022-11-28 03:43:10,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:10,034 INFO:     Epoch: 14
2022-11-28 03:43:10,789 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4495843814855272, 'Total loss': 0.4495843814855272} | train loss {'Reaction outcome loss': 0.3615258600142214, 'Total loss': 0.3615258600142214}
2022-11-28 03:43:10,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:10,790 INFO:     Epoch: 15
2022-11-28 03:43:11,542 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4637170373038812, 'Total loss': 0.4637170373038812} | train loss {'Reaction outcome loss': 0.3623113350401963, 'Total loss': 0.3623113350401963}
2022-11-28 03:43:11,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:11,542 INFO:     Epoch: 16
2022-11-28 03:43:12,293 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4130231768570163, 'Total loss': 0.4130231768570163} | train loss {'Reaction outcome loss': 0.3593038363502391, 'Total loss': 0.3593038363502391}
2022-11-28 03:43:12,293 INFO:     Found new best model at epoch 16
2022-11-28 03:43:12,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:12,294 INFO:     Epoch: 17
2022-11-28 03:43:13,048 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44163128902966325, 'Total loss': 0.44163128902966325} | train loss {'Reaction outcome loss': 0.3560568324380344, 'Total loss': 0.3560568324380344}
2022-11-28 03:43:13,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:13,049 INFO:     Epoch: 18
2022-11-28 03:43:13,804 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4242191023447297, 'Total loss': 0.4242191023447297} | train loss {'Reaction outcome loss': 0.36142867872671736, 'Total loss': 0.36142867872671736}
2022-11-28 03:43:13,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:13,805 INFO:     Epoch: 19
2022-11-28 03:43:14,560 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.437862464311448, 'Total loss': 0.437862464311448} | train loss {'Reaction outcome loss': 0.35500554418972424, 'Total loss': 0.35500554418972424}
2022-11-28 03:43:14,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:14,561 INFO:     Epoch: 20
2022-11-28 03:43:15,317 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4179368804801594, 'Total loss': 0.4179368804801594} | train loss {'Reaction outcome loss': 0.353517135605216, 'Total loss': 0.353517135605216}
2022-11-28 03:43:15,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:15,317 INFO:     Epoch: 21
2022-11-28 03:43:16,073 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40963980149139056, 'Total loss': 0.40963980149139056} | train loss {'Reaction outcome loss': 0.345083090897289, 'Total loss': 0.345083090897289}
2022-11-28 03:43:16,073 INFO:     Found new best model at epoch 21
2022-11-28 03:43:16,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:16,074 INFO:     Epoch: 22
2022-11-28 03:43:16,828 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3979779141531749, 'Total loss': 0.3979779141531749} | train loss {'Reaction outcome loss': 0.34118744340394774, 'Total loss': 0.34118744340394774}
2022-11-28 03:43:16,828 INFO:     Found new best model at epoch 22
2022-11-28 03:43:16,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:16,829 INFO:     Epoch: 23
2022-11-28 03:43:17,583 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4324638613245704, 'Total loss': 0.4324638613245704} | train loss {'Reaction outcome loss': 0.3417662234165736, 'Total loss': 0.3417662234165736}
2022-11-28 03:43:17,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:17,583 INFO:     Epoch: 24
2022-11-28 03:43:18,344 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4002609039572152, 'Total loss': 0.4002609039572152} | train loss {'Reaction outcome loss': 0.3395581538338334, 'Total loss': 0.3395581538338334}
2022-11-28 03:43:18,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:18,345 INFO:     Epoch: 25
2022-11-28 03:43:19,105 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42921682277863676, 'Total loss': 0.42921682277863676} | train loss {'Reaction outcome loss': 0.33477356435070116, 'Total loss': 0.33477356435070116}
2022-11-28 03:43:19,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:19,106 INFO:     Epoch: 26
2022-11-28 03:43:19,863 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44658921320330014, 'Total loss': 0.44658921320330014} | train loss {'Reaction outcome loss': 0.3426280575053346, 'Total loss': 0.3426280575053346}
2022-11-28 03:43:19,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:19,863 INFO:     Epoch: 27
2022-11-28 03:43:20,618 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44098890911449085, 'Total loss': 0.44098890911449085} | train loss {'Reaction outcome loss': 0.33219531349717607, 'Total loss': 0.33219531349717607}
2022-11-28 03:43:20,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:20,618 INFO:     Epoch: 28
2022-11-28 03:43:21,373 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4309451300650835, 'Total loss': 0.4309451300650835} | train loss {'Reaction outcome loss': 0.34875267479688893, 'Total loss': 0.34875267479688893}
2022-11-28 03:43:21,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:21,373 INFO:     Epoch: 29
2022-11-28 03:43:22,128 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4210341650653969, 'Total loss': 0.4210341650653969} | train loss {'Reaction outcome loss': 0.33493265347375023, 'Total loss': 0.33493265347375023}
2022-11-28 03:43:22,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:22,128 INFO:     Epoch: 30
2022-11-28 03:43:22,882 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44610955515368417, 'Total loss': 0.44610955515368417} | train loss {'Reaction outcome loss': 0.32820536235287306, 'Total loss': 0.32820536235287306}
2022-11-28 03:43:22,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:22,882 INFO:     Epoch: 31
2022-11-28 03:43:23,639 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44541495394977654, 'Total loss': 0.44541495394977654} | train loss {'Reaction outcome loss': 0.3411511456774127, 'Total loss': 0.3411511456774127}
2022-11-28 03:43:23,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:23,640 INFO:     Epoch: 32
2022-11-28 03:43:24,396 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4116256193003871, 'Total loss': 0.4116256193003871} | train loss {'Reaction outcome loss': 0.3329739464266646, 'Total loss': 0.3329739464266646}
2022-11-28 03:43:24,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:24,397 INFO:     Epoch: 33
2022-11-28 03:43:25,152 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4097749790684743, 'Total loss': 0.4097749790684743} | train loss {'Reaction outcome loss': 0.32910601223909086, 'Total loss': 0.32910601223909086}
2022-11-28 03:43:25,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:25,152 INFO:     Epoch: 34
2022-11-28 03:43:25,908 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4362483170222152, 'Total loss': 0.4362483170222152} | train loss {'Reaction outcome loss': 0.32228534984131973, 'Total loss': 0.32228534984131973}
2022-11-28 03:43:25,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:25,908 INFO:     Epoch: 35
2022-11-28 03:43:26,662 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41859070279381494, 'Total loss': 0.41859070279381494} | train loss {'Reaction outcome loss': 0.32679207103266833, 'Total loss': 0.32679207103266833}
2022-11-28 03:43:26,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:26,663 INFO:     Epoch: 36
2022-11-28 03:43:27,420 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40649172020229424, 'Total loss': 0.40649172020229424} | train loss {'Reaction outcome loss': 0.3266654607629584, 'Total loss': 0.3266654607629584}
2022-11-28 03:43:27,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:27,420 INFO:     Epoch: 37
2022-11-28 03:43:28,179 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41177639907056635, 'Total loss': 0.41177639907056635} | train loss {'Reaction outcome loss': 0.33228606219974255, 'Total loss': 0.33228606219974255}
2022-11-28 03:43:28,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:28,180 INFO:     Epoch: 38
2022-11-28 03:43:28,940 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4235087775371291, 'Total loss': 0.4235087775371291} | train loss {'Reaction outcome loss': 0.3245263157051898, 'Total loss': 0.3245263157051898}
2022-11-28 03:43:28,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:28,940 INFO:     Epoch: 39
2022-11-28 03:43:29,696 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3977151135490699, 'Total loss': 0.3977151135490699} | train loss {'Reaction outcome loss': 0.3191419875910205, 'Total loss': 0.3191419875910205}
2022-11-28 03:43:29,696 INFO:     Found new best model at epoch 39
2022-11-28 03:43:29,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:29,697 INFO:     Epoch: 40
2022-11-28 03:43:30,453 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4182309205220504, 'Total loss': 0.4182309205220504} | train loss {'Reaction outcome loss': 0.3207799281113811, 'Total loss': 0.3207799281113811}
2022-11-28 03:43:30,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:30,453 INFO:     Epoch: 41
2022-11-28 03:43:31,210 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39071776176040823, 'Total loss': 0.39071776176040823} | train loss {'Reaction outcome loss': 0.32027350552380085, 'Total loss': 0.32027350552380085}
2022-11-28 03:43:31,211 INFO:     Found new best model at epoch 41
2022-11-28 03:43:31,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:31,212 INFO:     Epoch: 42
2022-11-28 03:43:31,975 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43837453492663125, 'Total loss': 0.43837453492663125} | train loss {'Reaction outcome loss': 0.3207039376119933, 'Total loss': 0.3207039376119933}
2022-11-28 03:43:31,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:31,975 INFO:     Epoch: 43
2022-11-28 03:43:32,733 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4298107068647038, 'Total loss': 0.4298107068647038} | train loss {'Reaction outcome loss': 0.3223215881134233, 'Total loss': 0.3223215881134233}
2022-11-28 03:43:32,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:32,734 INFO:     Epoch: 44
2022-11-28 03:43:33,495 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45996536331420596, 'Total loss': 0.45996536331420596} | train loss {'Reaction outcome loss': 0.31239221085824315, 'Total loss': 0.31239221085824315}
2022-11-28 03:43:33,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:33,495 INFO:     Epoch: 45
2022-11-28 03:43:34,257 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41215788505294104, 'Total loss': 0.41215788505294104} | train loss {'Reaction outcome loss': 0.3216145388902195, 'Total loss': 0.3216145388902195}
2022-11-28 03:43:34,257 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:34,258 INFO:     Epoch: 46
2022-11-28 03:43:35,019 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4601230404593728, 'Total loss': 0.4601230404593728} | train loss {'Reaction outcome loss': 0.3222588245726882, 'Total loss': 0.3222588245726882}
2022-11-28 03:43:35,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:35,019 INFO:     Epoch: 47
2022-11-28 03:43:35,779 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3987853449176658, 'Total loss': 0.3987853449176658} | train loss {'Reaction outcome loss': 0.327131716384282, 'Total loss': 0.327131716384282}
2022-11-28 03:43:35,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:35,779 INFO:     Epoch: 48
2022-11-28 03:43:36,541 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43736334229734813, 'Total loss': 0.43736334229734813} | train loss {'Reaction outcome loss': 0.32072677472305877, 'Total loss': 0.32072677472305877}
2022-11-28 03:43:36,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:36,541 INFO:     Epoch: 49
2022-11-28 03:43:37,298 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4515619000250643, 'Total loss': 0.4515619000250643} | train loss {'Reaction outcome loss': 0.31106877804643684, 'Total loss': 0.31106877804643684}
2022-11-28 03:43:37,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:37,298 INFO:     Epoch: 50
2022-11-28 03:43:38,053 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4197364197197286, 'Total loss': 0.4197364197197286} | train loss {'Reaction outcome loss': 0.3252690793766129, 'Total loss': 0.3252690793766129}
2022-11-28 03:43:38,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:38,054 INFO:     Epoch: 51
2022-11-28 03:43:38,808 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4301689961417155, 'Total loss': 0.4301689961417155} | train loss {'Reaction outcome loss': 0.31276659120715433, 'Total loss': 0.31276659120715433}
2022-11-28 03:43:38,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:38,809 INFO:     Epoch: 52
2022-11-28 03:43:39,565 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4064919254319234, 'Total loss': 0.4064919254319234} | train loss {'Reaction outcome loss': 0.3116866973559222, 'Total loss': 0.3116866973559222}
2022-11-28 03:43:39,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:39,566 INFO:     Epoch: 53
2022-11-28 03:43:40,322 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41477082060141995, 'Total loss': 0.41477082060141995} | train loss {'Reaction outcome loss': 0.32032859448583856, 'Total loss': 0.32032859448583856}
2022-11-28 03:43:40,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:40,323 INFO:     Epoch: 54
2022-11-28 03:43:41,080 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41356655718250707, 'Total loss': 0.41356655718250707} | train loss {'Reaction outcome loss': 0.3231301007552012, 'Total loss': 0.3231301007552012}
2022-11-28 03:43:41,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:41,080 INFO:     Epoch: 55
2022-11-28 03:43:41,834 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4098790718073195, 'Total loss': 0.4098790718073195} | train loss {'Reaction outcome loss': 0.3121854009767694, 'Total loss': 0.3121854009767694}
2022-11-28 03:43:41,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:41,834 INFO:     Epoch: 56
2022-11-28 03:43:42,591 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4141239713538777, 'Total loss': 0.4141239713538777} | train loss {'Reaction outcome loss': 0.31914107498502536, 'Total loss': 0.31914107498502536}
2022-11-28 03:43:42,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:42,591 INFO:     Epoch: 57
2022-11-28 03:43:43,347 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4108522581783208, 'Total loss': 0.4108522581783208} | train loss {'Reaction outcome loss': 0.3134089834807861, 'Total loss': 0.3134089834807861}
2022-11-28 03:43:43,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:43,347 INFO:     Epoch: 58
2022-11-28 03:43:44,102 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43069703030315315, 'Total loss': 0.43069703030315315} | train loss {'Reaction outcome loss': 0.31835315752053456, 'Total loss': 0.31835315752053456}
2022-11-28 03:43:44,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:44,103 INFO:     Epoch: 59
2022-11-28 03:43:44,855 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4245875007049604, 'Total loss': 0.4245875007049604} | train loss {'Reaction outcome loss': 0.31232330425372046, 'Total loss': 0.31232330425372046}
2022-11-28 03:43:44,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:44,855 INFO:     Epoch: 60
2022-11-28 03:43:45,609 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44344699213450606, 'Total loss': 0.44344699213450606} | train loss {'Reaction outcome loss': 0.31976359824259437, 'Total loss': 0.31976359824259437}
2022-11-28 03:43:45,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:45,609 INFO:     Epoch: 61
2022-11-28 03:43:46,378 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39379055527123535, 'Total loss': 0.39379055527123535} | train loss {'Reaction outcome loss': 0.314215702425328, 'Total loss': 0.314215702425328}
2022-11-28 03:43:46,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:46,378 INFO:     Epoch: 62
2022-11-28 03:43:47,134 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42466383427381516, 'Total loss': 0.42466383427381516} | train loss {'Reaction outcome loss': 0.3196047247657853, 'Total loss': 0.3196047247657853}
2022-11-28 03:43:47,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:47,134 INFO:     Epoch: 63
2022-11-28 03:43:47,889 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4198596894063733, 'Total loss': 0.4198596894063733} | train loss {'Reaction outcome loss': 0.30585781746213475, 'Total loss': 0.30585781746213475}
2022-11-28 03:43:47,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:47,889 INFO:     Epoch: 64
2022-11-28 03:43:48,646 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40429088033058425, 'Total loss': 0.40429088033058425} | train loss {'Reaction outcome loss': 0.3153521369902357, 'Total loss': 0.3153521369902357}
2022-11-28 03:43:48,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:48,646 INFO:     Epoch: 65
2022-11-28 03:43:49,400 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41384235447780654, 'Total loss': 0.41384235447780654} | train loss {'Reaction outcome loss': 0.3119722699686404, 'Total loss': 0.3119722699686404}
2022-11-28 03:43:49,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:49,400 INFO:     Epoch: 66
2022-11-28 03:43:50,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42860441214658995, 'Total loss': 0.42860441214658995} | train loss {'Reaction outcome loss': 0.30819275746903113, 'Total loss': 0.30819275746903113}
2022-11-28 03:43:50,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:50,160 INFO:     Epoch: 67
2022-11-28 03:43:50,912 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4070707695050673, 'Total loss': 0.4070707695050673} | train loss {'Reaction outcome loss': 0.32306996738958743, 'Total loss': 0.32306996738958743}
2022-11-28 03:43:50,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:50,912 INFO:     Epoch: 68
2022-11-28 03:43:51,670 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41638499396768486, 'Total loss': 0.41638499396768486} | train loss {'Reaction outcome loss': 0.31934101726379127, 'Total loss': 0.31934101726379127}
2022-11-28 03:43:51,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:51,670 INFO:     Epoch: 69
2022-11-28 03:43:52,428 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41408743523061275, 'Total loss': 0.41408743523061275} | train loss {'Reaction outcome loss': 0.3149048807850528, 'Total loss': 0.3149048807850528}
2022-11-28 03:43:52,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:52,428 INFO:     Epoch: 70
2022-11-28 03:43:53,183 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41306707432324236, 'Total loss': 0.41306707432324236} | train loss {'Reaction outcome loss': 0.31693885736768285, 'Total loss': 0.31693885736768285}
2022-11-28 03:43:53,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:53,183 INFO:     Epoch: 71
2022-11-28 03:43:53,938 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4308033958077431, 'Total loss': 0.4308033958077431} | train loss {'Reaction outcome loss': 0.31409718465781017, 'Total loss': 0.31409718465781017}
2022-11-28 03:43:53,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:53,938 INFO:     Epoch: 72
2022-11-28 03:43:54,690 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4160290814258836, 'Total loss': 0.4160290814258836} | train loss {'Reaction outcome loss': 0.3122926880755732, 'Total loss': 0.3122926880755732}
2022-11-28 03:43:54,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:54,690 INFO:     Epoch: 73
2022-11-28 03:43:55,449 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3943136844106696, 'Total loss': 0.3943136844106696} | train loss {'Reaction outcome loss': 0.3118815863084409, 'Total loss': 0.3118815863084409}
2022-11-28 03:43:55,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:55,449 INFO:     Epoch: 74
2022-11-28 03:43:56,204 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3871491788463159, 'Total loss': 0.3871491788463159} | train loss {'Reaction outcome loss': 0.3097614681107863, 'Total loss': 0.3097614681107863}
2022-11-28 03:43:56,204 INFO:     Found new best model at epoch 74
2022-11-28 03:43:56,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:56,205 INFO:     Epoch: 75
2022-11-28 03:43:56,961 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4074485991150141, 'Total loss': 0.4074485991150141} | train loss {'Reaction outcome loss': 0.31334204431022367, 'Total loss': 0.31334204431022367}
2022-11-28 03:43:56,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:56,961 INFO:     Epoch: 76
2022-11-28 03:43:57,714 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41994876837865874, 'Total loss': 0.41994876837865874} | train loss {'Reaction outcome loss': 0.3129765308732467, 'Total loss': 0.3129765308732467}
2022-11-28 03:43:57,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:57,715 INFO:     Epoch: 77
2022-11-28 03:43:58,471 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42106308618729765, 'Total loss': 0.42106308618729765} | train loss {'Reaction outcome loss': 0.31274923195521676, 'Total loss': 0.31274923195521676}
2022-11-28 03:43:58,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:58,471 INFO:     Epoch: 78
2022-11-28 03:43:59,223 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39988457242196257, 'Total loss': 0.39988457242196257} | train loss {'Reaction outcome loss': 0.321062589905435, 'Total loss': 0.321062589905435}
2022-11-28 03:43:59,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:59,224 INFO:     Epoch: 79
2022-11-28 03:43:59,979 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42230288515036757, 'Total loss': 0.42230288515036757} | train loss {'Reaction outcome loss': 0.3173800417552552, 'Total loss': 0.3173800417552552}
2022-11-28 03:43:59,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:43:59,979 INFO:     Epoch: 80
2022-11-28 03:44:00,733 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40344963290474634, 'Total loss': 0.40344963290474634} | train loss {'Reaction outcome loss': 0.3147388325343209, 'Total loss': 0.3147388325343209}
2022-11-28 03:44:00,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:00,733 INFO:     Epoch: 81
2022-11-28 03:44:01,490 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4233080707490444, 'Total loss': 0.4233080707490444} | train loss {'Reaction outcome loss': 0.31343687663695985, 'Total loss': 0.31343687663695985}
2022-11-28 03:44:01,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:01,490 INFO:     Epoch: 82
2022-11-28 03:44:02,248 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43161444111981173, 'Total loss': 0.43161444111981173} | train loss {'Reaction outcome loss': 0.3168319424373969, 'Total loss': 0.3168319424373969}
2022-11-28 03:44:02,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:02,249 INFO:     Epoch: 83
2022-11-28 03:44:03,007 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4618356475098567, 'Total loss': 0.4618356475098567} | train loss {'Reaction outcome loss': 0.31395761115897086, 'Total loss': 0.31395761115897086}
2022-11-28 03:44:03,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:03,007 INFO:     Epoch: 84
2022-11-28 03:44:03,761 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42082169550386345, 'Total loss': 0.42082169550386345} | train loss {'Reaction outcome loss': 0.3104872264028076, 'Total loss': 0.3104872264028076}
2022-11-28 03:44:03,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:03,761 INFO:     Epoch: 85
2022-11-28 03:44:04,515 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41954643990505824, 'Total loss': 0.41954643990505824} | train loss {'Reaction outcome loss': 0.320139926798161, 'Total loss': 0.320139926798161}
2022-11-28 03:44:04,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:04,516 INFO:     Epoch: 86
2022-11-28 03:44:05,271 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42220932109789416, 'Total loss': 0.42220932109789416} | train loss {'Reaction outcome loss': 0.31981187457999877, 'Total loss': 0.31981187457999877}
2022-11-28 03:44:05,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:05,272 INFO:     Epoch: 87
2022-11-28 03:44:06,027 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4233533211729743, 'Total loss': 0.4233533211729743} | train loss {'Reaction outcome loss': 0.31549665241712527, 'Total loss': 0.31549665241712527}
2022-11-28 03:44:06,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:06,027 INFO:     Epoch: 88
2022-11-28 03:44:06,782 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.420341146601872, 'Total loss': 0.420341146601872} | train loss {'Reaction outcome loss': 0.3164294273292105, 'Total loss': 0.3164294273292105}
2022-11-28 03:44:06,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:06,782 INFO:     Epoch: 89
2022-11-28 03:44:07,540 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4067397832193158, 'Total loss': 0.4067397832193158} | train loss {'Reaction outcome loss': 0.32010275783437875, 'Total loss': 0.32010275783437875}
2022-11-28 03:44:07,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:07,540 INFO:     Epoch: 90
2022-11-28 03:44:08,292 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43215522898191755, 'Total loss': 0.43215522898191755} | train loss {'Reaction outcome loss': 0.31912635794029603, 'Total loss': 0.31912635794029603}
2022-11-28 03:44:08,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:08,293 INFO:     Epoch: 91
2022-11-28 03:44:09,050 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4004377973350612, 'Total loss': 0.4004377973350612} | train loss {'Reaction outcome loss': 0.3093992567230617, 'Total loss': 0.3093992567230617}
2022-11-28 03:44:09,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:09,050 INFO:     Epoch: 92
2022-11-28 03:44:09,803 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4521865776994012, 'Total loss': 0.4521865776994012} | train loss {'Reaction outcome loss': 0.30719456235848125, 'Total loss': 0.30719456235848125}
2022-11-28 03:44:09,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:09,803 INFO:     Epoch: 93
2022-11-28 03:44:10,559 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4221779036928307, 'Total loss': 0.4221779036928307} | train loss {'Reaction outcome loss': 0.3158023880584346, 'Total loss': 0.3158023880584346}
2022-11-28 03:44:10,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:10,559 INFO:     Epoch: 94
2022-11-28 03:44:11,313 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42128836261955177, 'Total loss': 0.42128836261955177} | train loss {'Reaction outcome loss': 0.3136708113935686, 'Total loss': 0.3136708113935686}
2022-11-28 03:44:11,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:11,313 INFO:     Epoch: 95
2022-11-28 03:44:12,070 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39691355722871696, 'Total loss': 0.39691355722871696} | train loss {'Reaction outcome loss': 0.31250823418339413, 'Total loss': 0.31250823418339413}
2022-11-28 03:44:12,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:12,071 INFO:     Epoch: 96
2022-11-28 03:44:12,824 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4391493353654038, 'Total loss': 0.4391493353654038} | train loss {'Reaction outcome loss': 0.3180243605747819, 'Total loss': 0.3180243605747819}
2022-11-28 03:44:12,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:12,824 INFO:     Epoch: 97
2022-11-28 03:44:13,578 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4231471832502972, 'Total loss': 0.4231471832502972} | train loss {'Reaction outcome loss': 0.3115042870443675, 'Total loss': 0.3115042870443675}
2022-11-28 03:44:13,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:13,578 INFO:     Epoch: 98
2022-11-28 03:44:14,333 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4095758291130716, 'Total loss': 0.4095758291130716} | train loss {'Reaction outcome loss': 0.30620667530644324, 'Total loss': 0.30620667530644324}
2022-11-28 03:44:14,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:14,333 INFO:     Epoch: 99
2022-11-28 03:44:15,090 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41745415634729643, 'Total loss': 0.41745415634729643} | train loss {'Reaction outcome loss': 0.31919216562903696, 'Total loss': 0.31919216562903696}
2022-11-28 03:44:15,091 INFO:     Best model found after epoch 75 of 100.
2022-11-28 03:44:15,091 INFO:   Done with stage: TRAINING
2022-11-28 03:44:15,091 INFO:   Starting stage: EVALUATION
2022-11-28 03:44:15,208 INFO:   Done with stage: EVALUATION
2022-11-28 03:44:15,208 INFO:   Leaving out SEQ value Fold_7
2022-11-28 03:44:15,221 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:44:15,221 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:44:15,872 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:44:15,873 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:44:15,941 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:44:15,942 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:44:15,942 INFO:     No hyperparam tuning for this model
2022-11-28 03:44:15,942 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:44:15,942 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:44:15,943 INFO:     None feature selector for col prot
2022-11-28 03:44:15,943 INFO:     None feature selector for col prot
2022-11-28 03:44:15,943 INFO:     None feature selector for col prot
2022-11-28 03:44:15,943 INFO:     None feature selector for col chem
2022-11-28 03:44:15,943 INFO:     None feature selector for col chem
2022-11-28 03:44:15,943 INFO:     None feature selector for col chem
2022-11-28 03:44:15,943 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:44:15,944 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:44:15,945 INFO:     Number of params in model 169741
2022-11-28 03:44:15,948 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:44:15,948 INFO:   Starting stage: TRAINING
2022-11-28 03:44:16,002 INFO:     Val loss before train {'Reaction outcome loss': 1.0053172158924015, 'Total loss': 1.0053172158924015}
2022-11-28 03:44:16,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:16,002 INFO:     Epoch: 0
2022-11-28 03:44:16,755 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5417048328302123, 'Total loss': 0.5417048328302123} | train loss {'Reaction outcome loss': 0.6237807448713049, 'Total loss': 0.6237807448713049}
2022-11-28 03:44:16,755 INFO:     Found new best model at epoch 0
2022-11-28 03:44:16,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:16,756 INFO:     Epoch: 1
2022-11-28 03:44:17,507 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45902511883865704, 'Total loss': 0.45902511883865704} | train loss {'Reaction outcome loss': 0.4958799290320566, 'Total loss': 0.4958799290320566}
2022-11-28 03:44:17,507 INFO:     Found new best model at epoch 1
2022-11-28 03:44:17,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:17,508 INFO:     Epoch: 2
2022-11-28 03:44:18,263 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48514902794902975, 'Total loss': 0.48514902794902975} | train loss {'Reaction outcome loss': 0.4599525438201043, 'Total loss': 0.4599525438201043}
2022-11-28 03:44:18,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:18,263 INFO:     Epoch: 3
2022-11-28 03:44:19,014 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4552684737877412, 'Total loss': 0.4552684737877412} | train loss {'Reaction outcome loss': 0.43753974307929316, 'Total loss': 0.43753974307929316}
2022-11-28 03:44:19,014 INFO:     Found new best model at epoch 3
2022-11-28 03:44:19,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:19,015 INFO:     Epoch: 4
2022-11-28 03:44:19,768 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4722329510206526, 'Total loss': 0.4722329510206526} | train loss {'Reaction outcome loss': 0.43158247928705906, 'Total loss': 0.43158247928705906}
2022-11-28 03:44:19,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:19,768 INFO:     Epoch: 5
2022-11-28 03:44:20,523 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48443362218412483, 'Total loss': 0.48443362218412483} | train loss {'Reaction outcome loss': 0.41182960083167397, 'Total loss': 0.41182960083167397}
2022-11-28 03:44:20,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:20,523 INFO:     Epoch: 6
2022-11-28 03:44:21,275 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4212189760397781, 'Total loss': 0.4212189760397781} | train loss {'Reaction outcome loss': 0.40638707046427075, 'Total loss': 0.40638707046427075}
2022-11-28 03:44:21,276 INFO:     Found new best model at epoch 6
2022-11-28 03:44:21,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:21,277 INFO:     Epoch: 7
2022-11-28 03:44:22,031 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4429577700793743, 'Total loss': 0.4429577700793743} | train loss {'Reaction outcome loss': 0.4003750127289564, 'Total loss': 0.4003750127289564}
2022-11-28 03:44:22,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:22,031 INFO:     Epoch: 8
2022-11-28 03:44:22,787 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42547609690915456, 'Total loss': 0.42547609690915456} | train loss {'Reaction outcome loss': 0.3893841937064163, 'Total loss': 0.3893841937064163}
2022-11-28 03:44:22,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:22,788 INFO:     Epoch: 9
2022-11-28 03:44:23,541 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45649766820398247, 'Total loss': 0.45649766820398247} | train loss {'Reaction outcome loss': 0.3894551494909871, 'Total loss': 0.3894551494909871}
2022-11-28 03:44:23,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:23,542 INFO:     Epoch: 10
2022-11-28 03:44:24,293 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4819023792039264, 'Total loss': 0.4819023792039264} | train loss {'Reaction outcome loss': 0.379466054720744, 'Total loss': 0.379466054720744}
2022-11-28 03:44:24,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:24,293 INFO:     Epoch: 11
2022-11-28 03:44:25,048 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42998847500844434, 'Total loss': 0.42998847500844434} | train loss {'Reaction outcome loss': 0.37894831372485044, 'Total loss': 0.37894831372485044}
2022-11-28 03:44:25,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:25,048 INFO:     Epoch: 12
2022-11-28 03:44:25,807 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4368489721620625, 'Total loss': 0.4368489721620625} | train loss {'Reaction outcome loss': 0.3761882375505182, 'Total loss': 0.3761882375505182}
2022-11-28 03:44:25,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:25,807 INFO:     Epoch: 13
2022-11-28 03:44:26,563 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49588674713264813, 'Total loss': 0.49588674713264813} | train loss {'Reaction outcome loss': 0.3642512181653611, 'Total loss': 0.3642512181653611}
2022-11-28 03:44:26,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:26,563 INFO:     Epoch: 14
2022-11-28 03:44:27,316 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41600358418442984, 'Total loss': 0.41600358418442984} | train loss {'Reaction outcome loss': 0.3675958824854705, 'Total loss': 0.3675958824854705}
2022-11-28 03:44:27,317 INFO:     Found new best model at epoch 14
2022-11-28 03:44:27,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:27,317 INFO:     Epoch: 15
2022-11-28 03:44:28,075 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4477712911638347, 'Total loss': 0.4477712911638347} | train loss {'Reaction outcome loss': 0.3705799392754993, 'Total loss': 0.3705799392754993}
2022-11-28 03:44:28,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:28,075 INFO:     Epoch: 16
2022-11-28 03:44:28,832 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.413508569652384, 'Total loss': 0.413508569652384} | train loss {'Reaction outcome loss': 0.3517905705488257, 'Total loss': 0.3517905705488257}
2022-11-28 03:44:28,832 INFO:     Found new best model at epoch 16
2022-11-28 03:44:28,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:28,833 INFO:     Epoch: 17
2022-11-28 03:44:29,585 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4348809377036311, 'Total loss': 0.4348809377036311} | train loss {'Reaction outcome loss': 0.35860331098158515, 'Total loss': 0.35860331098158515}
2022-11-28 03:44:29,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:29,585 INFO:     Epoch: 18
2022-11-28 03:44:30,339 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41345354135740886, 'Total loss': 0.41345354135740886} | train loss {'Reaction outcome loss': 0.3561627619689511, 'Total loss': 0.3561627619689511}
2022-11-28 03:44:30,339 INFO:     Found new best model at epoch 18
2022-11-28 03:44:30,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:30,340 INFO:     Epoch: 19
2022-11-28 03:44:31,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42451782152056694, 'Total loss': 0.42451782152056694} | train loss {'Reaction outcome loss': 0.3524707522723944, 'Total loss': 0.3524707522723944}
2022-11-28 03:44:31,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:31,094 INFO:     Epoch: 20
2022-11-28 03:44:31,850 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40338369662111456, 'Total loss': 0.40338369662111456} | train loss {'Reaction outcome loss': 0.3539491129678584, 'Total loss': 0.3539491129678584}
2022-11-28 03:44:31,850 INFO:     Found new best model at epoch 20
2022-11-28 03:44:31,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:31,851 INFO:     Epoch: 21
2022-11-28 03:44:32,605 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.450097465549003, 'Total loss': 0.450097465549003} | train loss {'Reaction outcome loss': 0.35332462561106487, 'Total loss': 0.35332462561106487}
2022-11-28 03:44:32,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:32,605 INFO:     Epoch: 22
2022-11-28 03:44:33,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41403718529777095, 'Total loss': 0.41403718529777095} | train loss {'Reaction outcome loss': 0.3530521937796185, 'Total loss': 0.3530521937796185}
2022-11-28 03:44:33,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:33,360 INFO:     Epoch: 23
2022-11-28 03:44:34,117 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4461021088063717, 'Total loss': 0.4461021088063717} | train loss {'Reaction outcome loss': 0.34411417993326343, 'Total loss': 0.34411417993326343}
2022-11-28 03:44:34,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:34,117 INFO:     Epoch: 24
2022-11-28 03:44:34,872 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42641849375583907, 'Total loss': 0.42641849375583907} | train loss {'Reaction outcome loss': 0.34262864351753264, 'Total loss': 0.34262864351753264}
2022-11-28 03:44:34,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:34,872 INFO:     Epoch: 25
2022-11-28 03:44:35,627 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43508369712667033, 'Total loss': 0.43508369712667033} | train loss {'Reaction outcome loss': 0.34536007154853116, 'Total loss': 0.34536007154853116}
2022-11-28 03:44:35,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:35,628 INFO:     Epoch: 26
2022-11-28 03:44:36,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4332198619165204, 'Total loss': 0.4332198619165204} | train loss {'Reaction outcome loss': 0.3375022476238589, 'Total loss': 0.3375022476238589}
2022-11-28 03:44:36,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:36,382 INFO:     Epoch: 27
2022-11-28 03:44:37,139 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42012075876647775, 'Total loss': 0.42012075876647775} | train loss {'Reaction outcome loss': 0.3405584670423019, 'Total loss': 0.3405584670423019}
2022-11-28 03:44:37,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:37,139 INFO:     Epoch: 28
2022-11-28 03:44:37,893 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43513825264844025, 'Total loss': 0.43513825264844025} | train loss {'Reaction outcome loss': 0.3455071009304975, 'Total loss': 0.3455071009304975}
2022-11-28 03:44:37,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:37,893 INFO:     Epoch: 29
2022-11-28 03:44:38,651 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4583010107956149, 'Total loss': 0.4583010107956149} | train loss {'Reaction outcome loss': 0.34107152712080746, 'Total loss': 0.34107152712080746}
2022-11-28 03:44:38,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:38,651 INFO:     Epoch: 30
2022-11-28 03:44:39,406 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42372218654914334, 'Total loss': 0.42372218654914334} | train loss {'Reaction outcome loss': 0.3472642984782015, 'Total loss': 0.3472642984782015}
2022-11-28 03:44:39,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:39,406 INFO:     Epoch: 31
2022-11-28 03:44:40,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4317641271786256, 'Total loss': 0.4317641271786256} | train loss {'Reaction outcome loss': 0.33585282409143064, 'Total loss': 0.33585282409143064}
2022-11-28 03:44:40,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:40,160 INFO:     Epoch: 32
2022-11-28 03:44:40,919 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44262081452391366, 'Total loss': 0.44262081452391366} | train loss {'Reaction outcome loss': 0.3389254447463299, 'Total loss': 0.3389254447463299}
2022-11-28 03:44:40,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:40,919 INFO:     Epoch: 33
2022-11-28 03:44:41,684 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40191893584348937, 'Total loss': 0.40191893584348937} | train loss {'Reaction outcome loss': 0.33530965222105863, 'Total loss': 0.33530965222105863}
2022-11-28 03:44:41,684 INFO:     Found new best model at epoch 33
2022-11-28 03:44:41,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:41,685 INFO:     Epoch: 34
2022-11-28 03:44:42,439 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4387946780771017, 'Total loss': 0.4387946780771017} | train loss {'Reaction outcome loss': 0.32751498909126364, 'Total loss': 0.32751498909126364}
2022-11-28 03:44:42,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:42,440 INFO:     Epoch: 35
2022-11-28 03:44:43,192 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4300241908905181, 'Total loss': 0.4300241908905181} | train loss {'Reaction outcome loss': 0.3329833912693204, 'Total loss': 0.3329833912693204}
2022-11-28 03:44:43,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:43,192 INFO:     Epoch: 36
2022-11-28 03:44:43,946 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4353546683083881, 'Total loss': 0.4353546683083881} | train loss {'Reaction outcome loss': 0.33473000672435566, 'Total loss': 0.33473000672435566}
2022-11-28 03:44:43,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:43,946 INFO:     Epoch: 37
2022-11-28 03:44:44,703 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41063635694709694, 'Total loss': 0.41063635694709694} | train loss {'Reaction outcome loss': 0.32163133243879966, 'Total loss': 0.32163133243879966}
2022-11-28 03:44:44,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:44,704 INFO:     Epoch: 38
2022-11-28 03:44:45,459 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41022093255411496, 'Total loss': 0.41022093255411496} | train loss {'Reaction outcome loss': 0.33663034240805334, 'Total loss': 0.33663034240805334}
2022-11-28 03:44:45,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:45,459 INFO:     Epoch: 39
2022-11-28 03:44:46,220 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.429281798614697, 'Total loss': 0.429281798614697} | train loss {'Reaction outcome loss': 0.32895691924157644, 'Total loss': 0.32895691924157644}
2022-11-28 03:44:46,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:46,221 INFO:     Epoch: 40
2022-11-28 03:44:46,971 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4230015232143077, 'Total loss': 0.4230015232143077} | train loss {'Reaction outcome loss': 0.3323740360417193, 'Total loss': 0.3323740360417193}
2022-11-28 03:44:46,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:46,972 INFO:     Epoch: 41
2022-11-28 03:44:47,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4268568171696229, 'Total loss': 0.4268568171696229} | train loss {'Reaction outcome loss': 0.3301083567672439, 'Total loss': 0.3301083567672439}
2022-11-28 03:44:47,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:47,727 INFO:     Epoch: 42
2022-11-28 03:44:48,478 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4021955742077394, 'Total loss': 0.4021955742077394} | train loss {'Reaction outcome loss': 0.3306752144989948, 'Total loss': 0.3306752144989948}
2022-11-28 03:44:48,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:48,479 INFO:     Epoch: 43
2022-11-28 03:44:49,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4131769405847246, 'Total loss': 0.4131769405847246} | train loss {'Reaction outcome loss': 0.3364628395366092, 'Total loss': 0.3364628395366092}
2022-11-28 03:44:49,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:49,234 INFO:     Epoch: 44
2022-11-28 03:44:49,985 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4313128729435531, 'Total loss': 0.4313128729435531} | train loss {'Reaction outcome loss': 0.3288267934694886, 'Total loss': 0.3288267934694886}
2022-11-28 03:44:49,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:49,985 INFO:     Epoch: 45
2022-11-28 03:44:50,741 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4293571123006669, 'Total loss': 0.4293571123006669} | train loss {'Reaction outcome loss': 0.3266568385785626, 'Total loss': 0.3266568385785626}
2022-11-28 03:44:50,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:50,742 INFO:     Epoch: 46
2022-11-28 03:44:51,493 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3900478749789975, 'Total loss': 0.3900478749789975} | train loss {'Reaction outcome loss': 0.32482970214539, 'Total loss': 0.32482970214539}
2022-11-28 03:44:51,493 INFO:     Found new best model at epoch 46
2022-11-28 03:44:51,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:51,494 INFO:     Epoch: 47
2022-11-28 03:44:52,248 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45249697227369656, 'Total loss': 0.45249697227369656} | train loss {'Reaction outcome loss': 0.3270364626040382, 'Total loss': 0.3270364626040382}
2022-11-28 03:44:52,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:52,249 INFO:     Epoch: 48
2022-11-28 03:44:53,005 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4094945275309411, 'Total loss': 0.4094945275309411} | train loss {'Reaction outcome loss': 0.32780733327531525, 'Total loss': 0.32780733327531525}
2022-11-28 03:44:53,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:53,005 INFO:     Epoch: 49
2022-11-28 03:44:53,762 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3917960832742127, 'Total loss': 0.3917960832742127} | train loss {'Reaction outcome loss': 0.3254147062919313, 'Total loss': 0.3254147062919313}
2022-11-28 03:44:53,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:53,762 INFO:     Epoch: 50
2022-11-28 03:44:54,517 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4731553064828569, 'Total loss': 0.4731553064828569} | train loss {'Reaction outcome loss': 0.3234775464741453, 'Total loss': 0.3234775464741453}
2022-11-28 03:44:54,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:54,518 INFO:     Epoch: 51
2022-11-28 03:44:55,273 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4412242861633951, 'Total loss': 0.4412242861633951} | train loss {'Reaction outcome loss': 0.3266973645696717, 'Total loss': 0.3266973645696717}
2022-11-28 03:44:55,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:55,274 INFO:     Epoch: 52
2022-11-28 03:44:56,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39715816927227104, 'Total loss': 0.39715816927227104} | train loss {'Reaction outcome loss': 0.3204301517877367, 'Total loss': 0.3204301517877367}
2022-11-28 03:44:56,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:56,030 INFO:     Epoch: 53
2022-11-28 03:44:56,786 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4332736987959255, 'Total loss': 0.4332736987959255} | train loss {'Reaction outcome loss': 0.3278427724576285, 'Total loss': 0.3278427724576285}
2022-11-28 03:44:56,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:56,786 INFO:     Epoch: 54
2022-11-28 03:44:57,541 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.408464178442955, 'Total loss': 0.408464178442955} | train loss {'Reaction outcome loss': 0.32744317937401995, 'Total loss': 0.32744317937401995}
2022-11-28 03:44:57,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:57,541 INFO:     Epoch: 55
2022-11-28 03:44:58,296 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4441398355093869, 'Total loss': 0.4441398355093869} | train loss {'Reaction outcome loss': 0.3251082827337086, 'Total loss': 0.3251082827337086}
2022-11-28 03:44:58,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:58,296 INFO:     Epoch: 56
2022-11-28 03:44:59,053 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39350638606331567, 'Total loss': 0.39350638606331567} | train loss {'Reaction outcome loss': 0.3240725919454088, 'Total loss': 0.3240725919454088}
2022-11-28 03:44:59,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:59,053 INFO:     Epoch: 57
2022-11-28 03:44:59,808 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4133567371490327, 'Total loss': 0.4133567371490327} | train loss {'Reaction outcome loss': 0.3146933868767754, 'Total loss': 0.3146933868767754}
2022-11-28 03:44:59,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:44:59,808 INFO:     Epoch: 58
2022-11-28 03:45:00,563 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4103957258842208, 'Total loss': 0.4103957258842208} | train loss {'Reaction outcome loss': 0.3209648373867235, 'Total loss': 0.3209648373867235}
2022-11-28 03:45:00,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:00,563 INFO:     Epoch: 59
2022-11-28 03:45:01,316 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3818948929282752, 'Total loss': 0.3818948929282752} | train loss {'Reaction outcome loss': 0.31907975469385425, 'Total loss': 0.31907975469385425}
2022-11-28 03:45:01,316 INFO:     Found new best model at epoch 59
2022-11-28 03:45:01,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:01,317 INFO:     Epoch: 60
2022-11-28 03:45:02,069 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45292394337328995, 'Total loss': 0.45292394337328995} | train loss {'Reaction outcome loss': 0.32149013570479806, 'Total loss': 0.32149013570479806}
2022-11-28 03:45:02,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:02,070 INFO:     Epoch: 61
2022-11-28 03:45:02,823 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.415044550021941, 'Total loss': 0.415044550021941} | train loss {'Reaction outcome loss': 0.3175567895654709, 'Total loss': 0.3175567895654709}
2022-11-28 03:45:02,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:02,824 INFO:     Epoch: 62
2022-11-28 03:45:03,577 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41786760091781616, 'Total loss': 0.41786760091781616} | train loss {'Reaction outcome loss': 0.32584227705674784, 'Total loss': 0.32584227705674784}
2022-11-28 03:45:03,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:03,577 INFO:     Epoch: 63
2022-11-28 03:45:04,326 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4069845246320421, 'Total loss': 0.4069845246320421} | train loss {'Reaction outcome loss': 0.3213998145393787, 'Total loss': 0.3213998145393787}
2022-11-28 03:45:04,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:04,327 INFO:     Epoch: 64
2022-11-28 03:45:05,083 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.393391675400463, 'Total loss': 0.393391675400463} | train loss {'Reaction outcome loss': 0.31774426325254385, 'Total loss': 0.31774426325254385}
2022-11-28 03:45:05,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:05,083 INFO:     Epoch: 65
2022-11-28 03:45:05,839 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4159169894727794, 'Total loss': 0.4159169894727794} | train loss {'Reaction outcome loss': 0.31573922697815204, 'Total loss': 0.31573922697815204}
2022-11-28 03:45:05,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:05,839 INFO:     Epoch: 66
2022-11-28 03:45:06,593 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4207138928838752, 'Total loss': 0.4207138928838752} | train loss {'Reaction outcome loss': 0.3226657194355803, 'Total loss': 0.3226657194355803}
2022-11-28 03:45:06,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:06,593 INFO:     Epoch: 67
2022-11-28 03:45:07,349 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44018706239082595, 'Total loss': 0.44018706239082595} | train loss {'Reaction outcome loss': 0.31668649980377767, 'Total loss': 0.31668649980377767}
2022-11-28 03:45:07,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:07,349 INFO:     Epoch: 68
2022-11-28 03:45:08,103 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43268462795425544, 'Total loss': 0.43268462795425544} | train loss {'Reaction outcome loss': 0.3228915858292772, 'Total loss': 0.3228915858292772}
2022-11-28 03:45:08,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:08,104 INFO:     Epoch: 69
2022-11-28 03:45:08,859 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39388824559070845, 'Total loss': 0.39388824559070845} | train loss {'Reaction outcome loss': 0.31812306694806586, 'Total loss': 0.31812306694806586}
2022-11-28 03:45:08,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:08,860 INFO:     Epoch: 70
2022-11-28 03:45:09,614 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.405620740218596, 'Total loss': 0.405620740218596} | train loss {'Reaction outcome loss': 0.3121226467192173, 'Total loss': 0.3121226467192173}
2022-11-28 03:45:09,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:09,614 INFO:     Epoch: 71
2022-11-28 03:45:10,367 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40704964338378474, 'Total loss': 0.40704964338378474} | train loss {'Reaction outcome loss': 0.3199400393622777, 'Total loss': 0.3199400393622777}
2022-11-28 03:45:10,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:10,367 INFO:     Epoch: 72
2022-11-28 03:45:11,122 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4060464616526257, 'Total loss': 0.4060464616526257} | train loss {'Reaction outcome loss': 0.320011941175307, 'Total loss': 0.320011941175307}
2022-11-28 03:45:11,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:11,123 INFO:     Epoch: 73
2022-11-28 03:45:11,877 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3895904310894283, 'Total loss': 0.3895904310894283} | train loss {'Reaction outcome loss': 0.31901167627544175, 'Total loss': 0.31901167627544175}
2022-11-28 03:45:11,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:11,877 INFO:     Epoch: 74
2022-11-28 03:45:12,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40660074522549455, 'Total loss': 0.40660074522549455} | train loss {'Reaction outcome loss': 0.31745802313690225, 'Total loss': 0.31745802313690225}
2022-11-28 03:45:12,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:12,631 INFO:     Epoch: 75
2022-11-28 03:45:13,389 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4123337143524127, 'Total loss': 0.4123337143524127} | train loss {'Reaction outcome loss': 0.31085206551717653, 'Total loss': 0.31085206551717653}
2022-11-28 03:45:13,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:13,389 INFO:     Epoch: 76
2022-11-28 03:45:14,145 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4185590085319497, 'Total loss': 0.4185590085319497} | train loss {'Reaction outcome loss': 0.32543800831321745, 'Total loss': 0.32543800831321745}
2022-11-28 03:45:14,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:14,146 INFO:     Epoch: 77
2022-11-28 03:45:14,905 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4076016142287038, 'Total loss': 0.4076016142287038} | train loss {'Reaction outcome loss': 0.3149729786560901, 'Total loss': 0.3149729786560901}
2022-11-28 03:45:14,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:14,905 INFO:     Epoch: 78
2022-11-28 03:45:15,663 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39843031052838673, 'Total loss': 0.39843031052838673} | train loss {'Reaction outcome loss': 0.31908015101667375, 'Total loss': 0.31908015101667375}
2022-11-28 03:45:15,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:15,663 INFO:     Epoch: 79
2022-11-28 03:45:16,423 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42892001230608334, 'Total loss': 0.42892001230608334} | train loss {'Reaction outcome loss': 0.32205500863792913, 'Total loss': 0.32205500863792913}
2022-11-28 03:45:16,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:16,424 INFO:     Epoch: 80
2022-11-28 03:45:17,185 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41425275040621107, 'Total loss': 0.41425275040621107} | train loss {'Reaction outcome loss': 0.3240501852030115, 'Total loss': 0.3240501852030115}
2022-11-28 03:45:17,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:17,187 INFO:     Epoch: 81
2022-11-28 03:45:17,943 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4013091518797658, 'Total loss': 0.4013091518797658} | train loss {'Reaction outcome loss': 0.32321768764766956, 'Total loss': 0.32321768764766956}
2022-11-28 03:45:17,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:17,943 INFO:     Epoch: 82
2022-11-28 03:45:18,704 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41357998380606825, 'Total loss': 0.41357998380606825} | train loss {'Reaction outcome loss': 0.3164785744382008, 'Total loss': 0.3164785744382008}
2022-11-28 03:45:18,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:18,704 INFO:     Epoch: 83
2022-11-28 03:45:19,462 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41688860478726303, 'Total loss': 0.41688860478726303} | train loss {'Reaction outcome loss': 0.31674798588538844, 'Total loss': 0.31674798588538844}
2022-11-28 03:45:19,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:19,462 INFO:     Epoch: 84
2022-11-28 03:45:20,219 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40485722182149236, 'Total loss': 0.40485722182149236} | train loss {'Reaction outcome loss': 0.31981049306810866, 'Total loss': 0.31981049306810866}
2022-11-28 03:45:20,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:20,219 INFO:     Epoch: 85
2022-11-28 03:45:20,973 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4121745848520236, 'Total loss': 0.4121745848520236} | train loss {'Reaction outcome loss': 0.31559951597404096, 'Total loss': 0.31559951597404096}
2022-11-28 03:45:20,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:20,974 INFO:     Epoch: 86
2022-11-28 03:45:21,728 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4168821945786476, 'Total loss': 0.4168821945786476} | train loss {'Reaction outcome loss': 0.31393687144642873, 'Total loss': 0.31393687144642873}
2022-11-28 03:45:21,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:21,728 INFO:     Epoch: 87
2022-11-28 03:45:22,482 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3922032341361046, 'Total loss': 0.3922032341361046} | train loss {'Reaction outcome loss': 0.31901211096274273, 'Total loss': 0.31901211096274273}
2022-11-28 03:45:22,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:22,482 INFO:     Epoch: 88
2022-11-28 03:45:23,235 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47622256370430643, 'Total loss': 0.47622256370430643} | train loss {'Reaction outcome loss': 0.3168739040171908, 'Total loss': 0.3168739040171908}
2022-11-28 03:45:23,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:23,236 INFO:     Epoch: 89
2022-11-28 03:45:23,992 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41817453571341257, 'Total loss': 0.41817453571341257} | train loss {'Reaction outcome loss': 0.32018861329303155, 'Total loss': 0.32018861329303155}
2022-11-28 03:45:23,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:23,992 INFO:     Epoch: 90
2022-11-28 03:45:24,744 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38166777179999783, 'Total loss': 0.38166777179999783} | train loss {'Reaction outcome loss': 0.3162801643653262, 'Total loss': 0.3162801643653262}
2022-11-28 03:45:24,745 INFO:     Found new best model at epoch 90
2022-11-28 03:45:24,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:24,745 INFO:     Epoch: 91
2022-11-28 03:45:25,502 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40182786739685317, 'Total loss': 0.40182786739685317} | train loss {'Reaction outcome loss': 0.31584502696510286, 'Total loss': 0.31584502696510286}
2022-11-28 03:45:25,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:25,502 INFO:     Epoch: 92
2022-11-28 03:45:26,254 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41639050164005975, 'Total loss': 0.41639050164005975} | train loss {'Reaction outcome loss': 0.303063235425901, 'Total loss': 0.303063235425901}
2022-11-28 03:45:26,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:26,255 INFO:     Epoch: 93
2022-11-28 03:45:27,011 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4110462755303491, 'Total loss': 0.4110462755303491} | train loss {'Reaction outcome loss': 0.3192611185293044, 'Total loss': 0.3192611185293044}
2022-11-28 03:45:27,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:27,011 INFO:     Epoch: 94
2022-11-28 03:45:27,765 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4233474877070297, 'Total loss': 0.4233474877070297} | train loss {'Reaction outcome loss': 0.3120606022496377, 'Total loss': 0.3120606022496377}
2022-11-28 03:45:27,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:27,766 INFO:     Epoch: 95
2022-11-28 03:45:28,520 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43594796650789003, 'Total loss': 0.43594796650789003} | train loss {'Reaction outcome loss': 0.32168310296331204, 'Total loss': 0.32168310296331204}
2022-11-28 03:45:28,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:28,520 INFO:     Epoch: 96
2022-11-28 03:45:29,280 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.391695230521939, 'Total loss': 0.391695230521939} | train loss {'Reaction outcome loss': 0.3140767386423484, 'Total loss': 0.3140767386423484}
2022-11-28 03:45:29,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:29,281 INFO:     Epoch: 97
2022-11-28 03:45:30,039 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39532252959907055, 'Total loss': 0.39532252959907055} | train loss {'Reaction outcome loss': 0.30874518166866993, 'Total loss': 0.30874518166866993}
2022-11-28 03:45:30,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:30,039 INFO:     Epoch: 98
2022-11-28 03:45:30,796 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42079348218711937, 'Total loss': 0.42079348218711937} | train loss {'Reaction outcome loss': 0.31560994250579705, 'Total loss': 0.31560994250579705}
2022-11-28 03:45:30,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:30,796 INFO:     Epoch: 99
2022-11-28 03:45:31,551 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3801392943344333, 'Total loss': 0.3801392943344333} | train loss {'Reaction outcome loss': 0.308484208439627, 'Total loss': 0.308484208439627}
2022-11-28 03:45:31,551 INFO:     Found new best model at epoch 99
2022-11-28 03:45:31,552 INFO:     Best model found after epoch 100 of 100.
2022-11-28 03:45:31,552 INFO:   Done with stage: TRAINING
2022-11-28 03:45:31,552 INFO:   Starting stage: EVALUATION
2022-11-28 03:45:31,668 INFO:   Done with stage: EVALUATION
2022-11-28 03:45:31,668 INFO:   Leaving out SEQ value Fold_8
2022-11-28 03:45:31,681 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 03:45:31,681 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:45:32,313 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:45:32,313 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:45:32,381 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:45:32,381 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:45:32,381 INFO:     No hyperparam tuning for this model
2022-11-28 03:45:32,381 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:45:32,381 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:45:32,382 INFO:     None feature selector for col prot
2022-11-28 03:45:32,382 INFO:     None feature selector for col prot
2022-11-28 03:45:32,382 INFO:     None feature selector for col prot
2022-11-28 03:45:32,383 INFO:     None feature selector for col chem
2022-11-28 03:45:32,383 INFO:     None feature selector for col chem
2022-11-28 03:45:32,383 INFO:     None feature selector for col chem
2022-11-28 03:45:32,383 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:45:32,383 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:45:32,384 INFO:     Number of params in model 169741
2022-11-28 03:45:32,388 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:45:32,388 INFO:   Starting stage: TRAINING
2022-11-28 03:45:32,441 INFO:     Val loss before train {'Reaction outcome loss': 0.983740548518571, 'Total loss': 0.983740548518571}
2022-11-28 03:45:32,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:32,441 INFO:     Epoch: 0
2022-11-28 03:45:33,186 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5371491969986395, 'Total loss': 0.5371491969986395} | train loss {'Reaction outcome loss': 0.6190145765640298, 'Total loss': 0.6190145765640298}
2022-11-28 03:45:33,186 INFO:     Found new best model at epoch 0
2022-11-28 03:45:33,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:33,187 INFO:     Epoch: 1
2022-11-28 03:45:33,937 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.50169742310589, 'Total loss': 0.50169742310589} | train loss {'Reaction outcome loss': 0.4859931563844486, 'Total loss': 0.4859931563844486}
2022-11-28 03:45:33,937 INFO:     Found new best model at epoch 1
2022-11-28 03:45:33,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:33,938 INFO:     Epoch: 2
2022-11-28 03:45:34,683 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47000970149582083, 'Total loss': 0.47000970149582083} | train loss {'Reaction outcome loss': 0.450528405454694, 'Total loss': 0.450528405454694}
2022-11-28 03:45:34,683 INFO:     Found new best model at epoch 2
2022-11-28 03:45:34,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:34,684 INFO:     Epoch: 3
2022-11-28 03:45:35,428 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4376092641191049, 'Total loss': 0.4376092641191049} | train loss {'Reaction outcome loss': 0.42428380275259214, 'Total loss': 0.42428380275259214}
2022-11-28 03:45:35,429 INFO:     Found new best model at epoch 3
2022-11-28 03:45:35,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:35,430 INFO:     Epoch: 4
2022-11-28 03:45:36,175 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44067273153500125, 'Total loss': 0.44067273153500125} | train loss {'Reaction outcome loss': 0.41252627737668096, 'Total loss': 0.41252627737668096}
2022-11-28 03:45:36,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:36,175 INFO:     Epoch: 5
2022-11-28 03:45:36,917 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4409354857423089, 'Total loss': 0.4409354857423089} | train loss {'Reaction outcome loss': 0.4007589261750786, 'Total loss': 0.4007589261750786}
2022-11-28 03:45:36,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:36,918 INFO:     Epoch: 6
2022-11-28 03:45:37,661 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44655174914408813, 'Total loss': 0.44655174914408813} | train loss {'Reaction outcome loss': 0.40152132766587395, 'Total loss': 0.40152132766587395}
2022-11-28 03:45:37,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:37,661 INFO:     Epoch: 7
2022-11-28 03:45:38,406 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4687387337061492, 'Total loss': 0.4687387337061492} | train loss {'Reaction outcome loss': 0.3806613494242941, 'Total loss': 0.3806613494242941}
2022-11-28 03:45:38,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:38,407 INFO:     Epoch: 8
2022-11-28 03:45:39,150 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4115133556452664, 'Total loss': 0.4115133556452664} | train loss {'Reaction outcome loss': 0.37163949602720686, 'Total loss': 0.37163949602720686}
2022-11-28 03:45:39,151 INFO:     Found new best model at epoch 8
2022-11-28 03:45:39,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:39,151 INFO:     Epoch: 9
2022-11-28 03:45:39,894 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.462145729159767, 'Total loss': 0.462145729159767} | train loss {'Reaction outcome loss': 0.36769339113819355, 'Total loss': 0.36769339113819355}
2022-11-28 03:45:39,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:39,894 INFO:     Epoch: 10
2022-11-28 03:45:40,637 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42425433139909396, 'Total loss': 0.42425433139909396} | train loss {'Reaction outcome loss': 0.3660419800755929, 'Total loss': 0.3660419800755929}
2022-11-28 03:45:40,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:40,637 INFO:     Epoch: 11
2022-11-28 03:45:41,381 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43591365353627637, 'Total loss': 0.43591365353627637} | train loss {'Reaction outcome loss': 0.36099251429645385, 'Total loss': 0.36099251429645385}
2022-11-28 03:45:41,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:41,381 INFO:     Epoch: 12
2022-11-28 03:45:42,123 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4711136875504797, 'Total loss': 0.4711136875504797} | train loss {'Reaction outcome loss': 0.3593120556400747, 'Total loss': 0.3593120556400747}
2022-11-28 03:45:42,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:42,123 INFO:     Epoch: 13
2022-11-28 03:45:42,867 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41789889259433205, 'Total loss': 0.41789889259433205} | train loss {'Reaction outcome loss': 0.34522451475566746, 'Total loss': 0.34522451475566746}
2022-11-28 03:45:42,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:42,867 INFO:     Epoch: 14
2022-11-28 03:45:43,610 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46564586054195056, 'Total loss': 0.46564586054195056} | train loss {'Reaction outcome loss': 0.34888550718219913, 'Total loss': 0.34888550718219913}
2022-11-28 03:45:43,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:43,611 INFO:     Epoch: 15
2022-11-28 03:45:44,353 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44359495626254514, 'Total loss': 0.44359495626254514} | train loss {'Reaction outcome loss': 0.3487977788156393, 'Total loss': 0.3487977788156393}
2022-11-28 03:45:44,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:44,354 INFO:     Epoch: 16
2022-11-28 03:45:45,095 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4525605892254548, 'Total loss': 0.4525605892254548} | train loss {'Reaction outcome loss': 0.34841223970359686, 'Total loss': 0.34841223970359686}
2022-11-28 03:45:45,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:45,096 INFO:     Epoch: 17
2022-11-28 03:45:45,838 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4153535979037935, 'Total loss': 0.4153535979037935} | train loss {'Reaction outcome loss': 0.34093763772018104, 'Total loss': 0.34093763772018104}
2022-11-28 03:45:45,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:45,838 INFO:     Epoch: 18
2022-11-28 03:45:46,587 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40734348039735446, 'Total loss': 0.40734348039735446} | train loss {'Reaction outcome loss': 0.3392487763142099, 'Total loss': 0.3392487763142099}
2022-11-28 03:45:46,587 INFO:     Found new best model at epoch 18
2022-11-28 03:45:46,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:46,588 INFO:     Epoch: 19
2022-11-28 03:45:47,332 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4474176754328338, 'Total loss': 0.4474176754328338} | train loss {'Reaction outcome loss': 0.33018510572764337, 'Total loss': 0.33018510572764337}
2022-11-28 03:45:47,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:47,332 INFO:     Epoch: 20
2022-11-28 03:45:48,074 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39493111961267213, 'Total loss': 0.39493111961267213} | train loss {'Reaction outcome loss': 0.3374086270831069, 'Total loss': 0.3374086270831069}
2022-11-28 03:45:48,075 INFO:     Found new best model at epoch 20
2022-11-28 03:45:48,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:48,076 INFO:     Epoch: 21
2022-11-28 03:45:48,819 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4266785881058736, 'Total loss': 0.4266785881058736} | train loss {'Reaction outcome loss': 0.3299342913591132, 'Total loss': 0.3299342913591132}
2022-11-28 03:45:48,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:48,819 INFO:     Epoch: 22
2022-11-28 03:45:49,563 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4298918572339145, 'Total loss': 0.4298918572339145} | train loss {'Reaction outcome loss': 0.33490616136363577, 'Total loss': 0.33490616136363577}
2022-11-28 03:45:49,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:49,563 INFO:     Epoch: 23
2022-11-28 03:45:50,307 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4134063808755441, 'Total loss': 0.4134063808755441} | train loss {'Reaction outcome loss': 0.32231327118922254, 'Total loss': 0.32231327118922254}
2022-11-28 03:45:50,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:50,307 INFO:     Epoch: 24
2022-11-28 03:45:51,055 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41268509321592073, 'Total loss': 0.41268509321592073} | train loss {'Reaction outcome loss': 0.33402317826237, 'Total loss': 0.33402317826237}
2022-11-28 03:45:51,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:51,055 INFO:     Epoch: 25
2022-11-28 03:45:51,798 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38465544259683654, 'Total loss': 0.38465544259683654} | train loss {'Reaction outcome loss': 0.32081916382422254, 'Total loss': 0.32081916382422254}
2022-11-28 03:45:51,798 INFO:     Found new best model at epoch 25
2022-11-28 03:45:51,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:51,799 INFO:     Epoch: 26
2022-11-28 03:45:52,544 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4251374483785846, 'Total loss': 0.4251374483785846} | train loss {'Reaction outcome loss': 0.32205350189184656, 'Total loss': 0.32205350189184656}
2022-11-28 03:45:52,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:52,544 INFO:     Epoch: 27
2022-11-28 03:45:53,288 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4350898072800853, 'Total loss': 0.4350898072800853} | train loss {'Reaction outcome loss': 0.32096733545162237, 'Total loss': 0.32096733545162237}
2022-11-28 03:45:53,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:53,288 INFO:     Epoch: 28
2022-11-28 03:45:54,036 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41942052864892915, 'Total loss': 0.41942052864892915} | train loss {'Reaction outcome loss': 0.3256184156147801, 'Total loss': 0.3256184156147801}
2022-11-28 03:45:54,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:54,036 INFO:     Epoch: 29
2022-11-28 03:45:54,780 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40993106983263383, 'Total loss': 0.40993106983263383} | train loss {'Reaction outcome loss': 0.31656941120721854, 'Total loss': 0.31656941120721854}
2022-11-28 03:45:54,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:54,781 INFO:     Epoch: 30
2022-11-28 03:45:55,526 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40990052558481693, 'Total loss': 0.40990052558481693} | train loss {'Reaction outcome loss': 0.32832344049701884, 'Total loss': 0.32832344049701884}
2022-11-28 03:45:55,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:55,526 INFO:     Epoch: 31
2022-11-28 03:45:56,270 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.401643146422099, 'Total loss': 0.401643146422099} | train loss {'Reaction outcome loss': 0.31746643955002024, 'Total loss': 0.31746643955002024}
2022-11-28 03:45:56,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:56,271 INFO:     Epoch: 32
2022-11-28 03:45:57,014 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4288353093645789, 'Total loss': 0.4288353093645789} | train loss {'Reaction outcome loss': 0.3241111566217578, 'Total loss': 0.3241111566217578}
2022-11-28 03:45:57,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:57,014 INFO:     Epoch: 33
2022-11-28 03:45:57,757 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4010263369842009, 'Total loss': 0.4010263369842009} | train loss {'Reaction outcome loss': 0.3144149348747974, 'Total loss': 0.3144149348747974}
2022-11-28 03:45:57,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:57,757 INFO:     Epoch: 34
2022-11-28 03:45:58,502 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4041359897025607, 'Total loss': 0.4041359897025607} | train loss {'Reaction outcome loss': 0.3073611304468038, 'Total loss': 0.3073611304468038}
2022-11-28 03:45:58,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:58,502 INFO:     Epoch: 35
2022-11-28 03:45:59,245 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4063804725354368, 'Total loss': 0.4063804725354368} | train loss {'Reaction outcome loss': 0.31486186826107454, 'Total loss': 0.31486186826107454}
2022-11-28 03:45:59,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:59,245 INFO:     Epoch: 36
2022-11-28 03:45:59,992 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3849796127866615, 'Total loss': 0.3849796127866615} | train loss {'Reaction outcome loss': 0.30870380465473446, 'Total loss': 0.30870380465473446}
2022-11-28 03:45:59,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:45:59,992 INFO:     Epoch: 37
2022-11-28 03:46:00,737 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41761039807037875, 'Total loss': 0.41761039807037875} | train loss {'Reaction outcome loss': 0.31574313880837696, 'Total loss': 0.31574313880837696}
2022-11-28 03:46:00,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:00,737 INFO:     Epoch: 38
2022-11-28 03:46:01,485 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39557272907007823, 'Total loss': 0.39557272907007823} | train loss {'Reaction outcome loss': 0.31232222431168266, 'Total loss': 0.31232222431168266}
2022-11-28 03:46:01,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:01,485 INFO:     Epoch: 39
2022-11-28 03:46:02,231 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4605393074452877, 'Total loss': 0.4605393074452877} | train loss {'Reaction outcome loss': 0.3084276599847541, 'Total loss': 0.3084276599847541}
2022-11-28 03:46:02,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:02,231 INFO:     Epoch: 40
2022-11-28 03:46:02,977 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4161760045046156, 'Total loss': 0.4161760045046156} | train loss {'Reaction outcome loss': 0.30758285105836636, 'Total loss': 0.30758285105836636}
2022-11-28 03:46:02,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:02,978 INFO:     Epoch: 41
2022-11-28 03:46:03,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4139237447895787, 'Total loss': 0.4139237447895787} | train loss {'Reaction outcome loss': 0.30746141857638654, 'Total loss': 0.30746141857638654}
2022-11-28 03:46:03,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:03,727 INFO:     Epoch: 42
2022-11-28 03:46:04,472 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43329478766430507, 'Total loss': 0.43329478766430507} | train loss {'Reaction outcome loss': 0.3089006291968482, 'Total loss': 0.3089006291968482}
2022-11-28 03:46:04,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:04,472 INFO:     Epoch: 43
2022-11-28 03:46:05,217 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40720348940654233, 'Total loss': 0.40720348940654233} | train loss {'Reaction outcome loss': 0.30758684304903966, 'Total loss': 0.30758684304903966}
2022-11-28 03:46:05,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:05,217 INFO:     Epoch: 44
2022-11-28 03:46:05,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40785306387326936, 'Total loss': 0.40785306387326936} | train loss {'Reaction outcome loss': 0.30629052361663506, 'Total loss': 0.30629052361663506}
2022-11-28 03:46:05,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:05,965 INFO:     Epoch: 45
2022-11-28 03:46:06,712 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4079269716008143, 'Total loss': 0.4079269716008143} | train loss {'Reaction outcome loss': 0.3053482000012787, 'Total loss': 0.3053482000012787}
2022-11-28 03:46:06,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:06,713 INFO:     Epoch: 46
2022-11-28 03:46:07,460 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.375037284059958, 'Total loss': 0.375037284059958} | train loss {'Reaction outcome loss': 0.3065248285933417, 'Total loss': 0.3065248285933417}
2022-11-28 03:46:07,461 INFO:     Found new best model at epoch 46
2022-11-28 03:46:07,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:07,462 INFO:     Epoch: 47
2022-11-28 03:46:08,209 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41802386372265493, 'Total loss': 0.41802386372265493} | train loss {'Reaction outcome loss': 0.303788270071453, 'Total loss': 0.303788270071453}
2022-11-28 03:46:08,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:08,209 INFO:     Epoch: 48
2022-11-28 03:46:08,957 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39183776114474644, 'Total loss': 0.39183776114474644} | train loss {'Reaction outcome loss': 0.305578169774036, 'Total loss': 0.305578169774036}
2022-11-28 03:46:08,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:08,957 INFO:     Epoch: 49
2022-11-28 03:46:09,700 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4020295387811281, 'Total loss': 0.4020295387811281} | train loss {'Reaction outcome loss': 0.30370250414220656, 'Total loss': 0.30370250414220656}
2022-11-28 03:46:09,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:09,700 INFO:     Epoch: 50
2022-11-28 03:46:10,446 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4300448081710122, 'Total loss': 0.4300448081710122} | train loss {'Reaction outcome loss': 0.30881554067743067, 'Total loss': 0.30881554067743067}
2022-11-28 03:46:10,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:10,446 INFO:     Epoch: 51
2022-11-28 03:46:11,193 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4082798548042774, 'Total loss': 0.4082798548042774} | train loss {'Reaction outcome loss': 0.309377685523763, 'Total loss': 0.309377685523763}
2022-11-28 03:46:11,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:11,194 INFO:     Epoch: 52
2022-11-28 03:46:11,939 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4061576913703572, 'Total loss': 0.4061576913703572} | train loss {'Reaction outcome loss': 0.29426188268223585, 'Total loss': 0.29426188268223585}
2022-11-28 03:46:11,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:11,939 INFO:     Epoch: 53
2022-11-28 03:46:12,682 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37749861587177624, 'Total loss': 0.37749861587177624} | train loss {'Reaction outcome loss': 0.30504972043694284, 'Total loss': 0.30504972043694284}
2022-11-28 03:46:12,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:12,682 INFO:     Epoch: 54
2022-11-28 03:46:13,430 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.391900510950522, 'Total loss': 0.391900510950522} | train loss {'Reaction outcome loss': 0.30564240919692176, 'Total loss': 0.30564240919692176}
2022-11-28 03:46:13,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:13,430 INFO:     Epoch: 55
2022-11-28 03:46:14,178 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4090093848380176, 'Total loss': 0.4090093848380176} | train loss {'Reaction outcome loss': 0.3009416535344659, 'Total loss': 0.3009416535344659}
2022-11-28 03:46:14,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:14,178 INFO:     Epoch: 56
2022-11-28 03:46:14,923 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41022655401717534, 'Total loss': 0.41022655401717534} | train loss {'Reaction outcome loss': 0.2973134672459291, 'Total loss': 0.2973134672459291}
2022-11-28 03:46:14,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:14,924 INFO:     Epoch: 57
2022-11-28 03:46:15,666 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41885575431991706, 'Total loss': 0.41885575431991706} | train loss {'Reaction outcome loss': 0.30185103966873517, 'Total loss': 0.30185103966873517}
2022-11-28 03:46:15,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:15,666 INFO:     Epoch: 58
2022-11-28 03:46:16,409 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4216710247776725, 'Total loss': 0.4216710247776725} | train loss {'Reaction outcome loss': 0.29838006295719927, 'Total loss': 0.29838006295719927}
2022-11-28 03:46:16,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:16,410 INFO:     Epoch: 59
2022-11-28 03:46:17,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4155733830888163, 'Total loss': 0.4155733830888163} | train loss {'Reaction outcome loss': 0.3008134644098428, 'Total loss': 0.3008134644098428}
2022-11-28 03:46:17,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:17,155 INFO:     Epoch: 60
2022-11-28 03:46:17,899 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4299332479184324, 'Total loss': 0.4299332479184324} | train loss {'Reaction outcome loss': 0.3038246606989783, 'Total loss': 0.3038246606989783}
2022-11-28 03:46:17,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:17,899 INFO:     Epoch: 61
2022-11-28 03:46:18,645 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41243555396795273, 'Total loss': 0.41243555396795273} | train loss {'Reaction outcome loss': 0.3067827050479091, 'Total loss': 0.3067827050479091}
2022-11-28 03:46:18,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:18,646 INFO:     Epoch: 62
2022-11-28 03:46:19,391 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39981867508454755, 'Total loss': 0.39981867508454755} | train loss {'Reaction outcome loss': 0.29332890495353814, 'Total loss': 0.29332890495353814}
2022-11-28 03:46:19,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:19,392 INFO:     Epoch: 63
2022-11-28 03:46:20,138 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3963301429017024, 'Total loss': 0.3963301429017024} | train loss {'Reaction outcome loss': 0.29974169500020087, 'Total loss': 0.29974169500020087}
2022-11-28 03:46:20,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:20,139 INFO:     Epoch: 64
2022-11-28 03:46:20,887 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3991975506598299, 'Total loss': 0.3991975506598299} | train loss {'Reaction outcome loss': 0.29779056511363206, 'Total loss': 0.29779056511363206}
2022-11-28 03:46:20,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:20,887 INFO:     Epoch: 65
2022-11-28 03:46:21,633 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3986187262291258, 'Total loss': 0.3986187262291258} | train loss {'Reaction outcome loss': 0.29321451912425, 'Total loss': 0.29321451912425}
2022-11-28 03:46:21,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:21,633 INFO:     Epoch: 66
2022-11-28 03:46:22,377 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41970262270082126, 'Total loss': 0.41970262270082126} | train loss {'Reaction outcome loss': 0.29272375953744867, 'Total loss': 0.29272375953744867}
2022-11-28 03:46:22,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:22,377 INFO:     Epoch: 67
2022-11-28 03:46:23,120 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38608052175153384, 'Total loss': 0.38608052175153384} | train loss {'Reaction outcome loss': 0.2968460229890687, 'Total loss': 0.2968460229890687}
2022-11-28 03:46:23,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:23,120 INFO:     Epoch: 68
2022-11-28 03:46:23,865 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3795207205482505, 'Total loss': 0.3795207205482505} | train loss {'Reaction outcome loss': 0.3007547667440103, 'Total loss': 0.3007547667440103}
2022-11-28 03:46:23,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:23,865 INFO:     Epoch: 69
2022-11-28 03:46:24,609 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41551983254877006, 'Total loss': 0.41551983254877006} | train loss {'Reaction outcome loss': 0.29954746164837665, 'Total loss': 0.29954746164837665}
2022-11-28 03:46:24,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:24,610 INFO:     Epoch: 70
2022-11-28 03:46:25,353 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4167127497494221, 'Total loss': 0.4167127497494221} | train loss {'Reaction outcome loss': 0.2943254382330544, 'Total loss': 0.2943254382330544}
2022-11-28 03:46:25,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:25,353 INFO:     Epoch: 71
2022-11-28 03:46:26,097 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4229616912251169, 'Total loss': 0.4229616912251169} | train loss {'Reaction outcome loss': 0.3046562727920863, 'Total loss': 0.3046562727920863}
2022-11-28 03:46:26,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:26,098 INFO:     Epoch: 72
2022-11-28 03:46:26,840 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39898111242589285, 'Total loss': 0.39898111242589285} | train loss {'Reaction outcome loss': 0.30173300275084924, 'Total loss': 0.30173300275084924}
2022-11-28 03:46:26,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:26,840 INFO:     Epoch: 73
2022-11-28 03:46:27,584 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39486559040167113, 'Total loss': 0.39486559040167113} | train loss {'Reaction outcome loss': 0.3005428284406662, 'Total loss': 0.3005428284406662}
2022-11-28 03:46:27,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:27,585 INFO:     Epoch: 74
2022-11-28 03:46:28,328 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39584205028685654, 'Total loss': 0.39584205028685654} | train loss {'Reaction outcome loss': 0.29798299487756225, 'Total loss': 0.29798299487756225}
2022-11-28 03:46:28,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:28,328 INFO:     Epoch: 75
2022-11-28 03:46:29,072 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4253718395802108, 'Total loss': 0.4253718395802108} | train loss {'Reaction outcome loss': 0.29097446350722894, 'Total loss': 0.29097446350722894}
2022-11-28 03:46:29,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:29,072 INFO:     Epoch: 76
2022-11-28 03:46:29,817 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38853471827777947, 'Total loss': 0.38853471827777947} | train loss {'Reaction outcome loss': 0.2919038819871387, 'Total loss': 0.2919038819871387}
2022-11-28 03:46:29,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:29,818 INFO:     Epoch: 77
2022-11-28 03:46:30,564 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40319111244753003, 'Total loss': 0.40319111244753003} | train loss {'Reaction outcome loss': 0.297893262487285, 'Total loss': 0.297893262487285}
2022-11-28 03:46:30,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:30,565 INFO:     Epoch: 78
2022-11-28 03:46:31,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4260958507657051, 'Total loss': 0.4260958507657051} | train loss {'Reaction outcome loss': 0.2995568877580215, 'Total loss': 0.2995568877580215}
2022-11-28 03:46:31,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:31,311 INFO:     Epoch: 79
2022-11-28 03:46:32,055 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39804781071672385, 'Total loss': 0.39804781071672385} | train loss {'Reaction outcome loss': 0.30019300783775293, 'Total loss': 0.30019300783775293}
2022-11-28 03:46:32,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:32,056 INFO:     Epoch: 80
2022-11-28 03:46:32,800 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4201407141306184, 'Total loss': 0.4201407141306184} | train loss {'Reaction outcome loss': 0.2942226926891171, 'Total loss': 0.2942226926891171}
2022-11-28 03:46:32,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:32,800 INFO:     Epoch: 81
2022-11-28 03:46:33,545 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42294061150063167, 'Total loss': 0.42294061150063167} | train loss {'Reaction outcome loss': 0.29091268513275653, 'Total loss': 0.29091268513275653}
2022-11-28 03:46:33,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:33,546 INFO:     Epoch: 82
2022-11-28 03:46:34,293 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41775230182842776, 'Total loss': 0.41775230182842776} | train loss {'Reaction outcome loss': 0.3022760428336202, 'Total loss': 0.3022760428336202}
2022-11-28 03:46:34,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:34,294 INFO:     Epoch: 83
2022-11-28 03:46:35,039 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4001671299338341, 'Total loss': 0.4001671299338341} | train loss {'Reaction outcome loss': 0.2927350526865648, 'Total loss': 0.2927350526865648}
2022-11-28 03:46:35,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:35,039 INFO:     Epoch: 84
2022-11-28 03:46:35,785 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41941420192068274, 'Total loss': 0.41941420192068274} | train loss {'Reaction outcome loss': 0.30354410875208526, 'Total loss': 0.30354410875208526}
2022-11-28 03:46:35,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:35,786 INFO:     Epoch: 85
2022-11-28 03:46:36,531 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.401390114756809, 'Total loss': 0.401390114756809} | train loss {'Reaction outcome loss': 0.2865827637971664, 'Total loss': 0.2865827637971664}
2022-11-28 03:46:36,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:36,531 INFO:     Epoch: 86
2022-11-28 03:46:37,274 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.423669544133273, 'Total loss': 0.423669544133273} | train loss {'Reaction outcome loss': 0.30403301092434903, 'Total loss': 0.30403301092434903}
2022-11-28 03:46:37,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:37,274 INFO:     Epoch: 87
2022-11-28 03:46:38,024 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.412910345941782, 'Total loss': 0.412910345941782} | train loss {'Reaction outcome loss': 0.2926101199218205, 'Total loss': 0.2926101199218205}
2022-11-28 03:46:38,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:38,025 INFO:     Epoch: 88
2022-11-28 03:46:38,778 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40772338448600337, 'Total loss': 0.40772338448600337} | train loss {'Reaction outcome loss': 0.295099217201374, 'Total loss': 0.295099217201374}
2022-11-28 03:46:38,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:38,779 INFO:     Epoch: 89
2022-11-28 03:46:39,524 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.394281201233918, 'Total loss': 0.394281201233918} | train loss {'Reaction outcome loss': 0.2905501418271843, 'Total loss': 0.2905501418271843}
2022-11-28 03:46:39,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:39,525 INFO:     Epoch: 90
2022-11-28 03:46:40,269 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40992765162478795, 'Total loss': 0.40992765162478795} | train loss {'Reaction outcome loss': 0.2974672302907827, 'Total loss': 0.2974672302907827}
2022-11-28 03:46:40,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:40,269 INFO:     Epoch: 91
2022-11-28 03:46:41,013 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42604685710235074, 'Total loss': 0.42604685710235074} | train loss {'Reaction outcome loss': 0.29739388574142844, 'Total loss': 0.29739388574142844}
2022-11-28 03:46:41,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:41,013 INFO:     Epoch: 92
2022-11-28 03:46:41,757 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45077346807176416, 'Total loss': 0.45077346807176416} | train loss {'Reaction outcome loss': 0.3041143304535321, 'Total loss': 0.3041143304535321}
2022-11-28 03:46:41,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:41,757 INFO:     Epoch: 93
2022-11-28 03:46:42,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41011622988364915, 'Total loss': 0.41011622988364915} | train loss {'Reaction outcome loss': 0.28912903152558267, 'Total loss': 0.28912903152558267}
2022-11-28 03:46:42,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:42,502 INFO:     Epoch: 94
2022-11-28 03:46:43,244 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4177229863337495, 'Total loss': 0.4177229863337495} | train loss {'Reaction outcome loss': 0.2936611301436716, 'Total loss': 0.2936611301436716}
2022-11-28 03:46:43,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:43,244 INFO:     Epoch: 95
2022-11-28 03:46:43,988 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41038097508928995, 'Total loss': 0.41038097508928995} | train loss {'Reaction outcome loss': 0.28802625108130125, 'Total loss': 0.28802625108130125}
2022-11-28 03:46:43,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:43,988 INFO:     Epoch: 96
2022-11-28 03:46:44,732 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.456696956333789, 'Total loss': 0.456696956333789} | train loss {'Reaction outcome loss': 0.2956206297996093, 'Total loss': 0.2956206297996093}
2022-11-28 03:46:44,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:44,732 INFO:     Epoch: 97
2022-11-28 03:46:45,475 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4319451632486148, 'Total loss': 0.4319451632486148} | train loss {'Reaction outcome loss': 0.30161727329297944, 'Total loss': 0.30161727329297944}
2022-11-28 03:46:45,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:45,475 INFO:     Epoch: 98
2022-11-28 03:46:46,219 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4521907567977905, 'Total loss': 0.4521907567977905} | train loss {'Reaction outcome loss': 0.29070012925230726, 'Total loss': 0.29070012925230726}
2022-11-28 03:46:46,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:46,219 INFO:     Epoch: 99
2022-11-28 03:46:46,962 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3878243723884225, 'Total loss': 0.3878243723884225} | train loss {'Reaction outcome loss': 0.2996745504438877, 'Total loss': 0.2996745504438877}
2022-11-28 03:46:46,962 INFO:     Best model found after epoch 47 of 100.
2022-11-28 03:46:46,962 INFO:   Done with stage: TRAINING
2022-11-28 03:46:46,962 INFO:   Starting stage: EVALUATION
2022-11-28 03:46:47,090 INFO:   Done with stage: EVALUATION
2022-11-28 03:46:47,090 INFO:   Leaving out SEQ value Fold_9
2022-11-28 03:46:47,103 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 03:46:47,103 INFO:   Starting stage: FEATURE SCALING
2022-11-28 03:46:47,745 INFO:   Done with stage: FEATURE SCALING
2022-11-28 03:46:47,745 INFO:   Starting stage: SCALING TARGETS
2022-11-28 03:46:47,815 INFO:   Done with stage: SCALING TARGETS
2022-11-28 03:46:47,815 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:46:47,815 INFO:     No hyperparam tuning for this model
2022-11-28 03:46:47,815 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 03:46:47,815 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 03:46:47,816 INFO:     None feature selector for col prot
2022-11-28 03:46:47,816 INFO:     None feature selector for col prot
2022-11-28 03:46:47,816 INFO:     None feature selector for col prot
2022-11-28 03:46:47,817 INFO:     None feature selector for col chem
2022-11-28 03:46:47,817 INFO:     None feature selector for col chem
2022-11-28 03:46:47,817 INFO:     None feature selector for col chem
2022-11-28 03:46:47,817 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 03:46:47,817 INFO:   Starting stage: BUILD MODEL
2022-11-28 03:46:47,818 INFO:     Number of params in model 169741
2022-11-28 03:46:47,822 INFO:   Done with stage: BUILD MODEL
2022-11-28 03:46:47,822 INFO:   Starting stage: TRAINING
2022-11-28 03:46:47,876 INFO:     Val loss before train {'Reaction outcome loss': 0.9760227027264509, 'Total loss': 0.9760227027264509}
2022-11-28 03:46:47,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:47,876 INFO:     Epoch: 0
2022-11-28 03:46:48,634 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5217809433286841, 'Total loss': 0.5217809433286841} | train loss {'Reaction outcome loss': 0.6376016538349851, 'Total loss': 0.6376016538349851}
2022-11-28 03:46:48,634 INFO:     Found new best model at epoch 0
2022-11-28 03:46:48,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:48,635 INFO:     Epoch: 1
2022-11-28 03:46:49,387 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46896113523028116, 'Total loss': 0.46896113523028116} | train loss {'Reaction outcome loss': 0.5152714770407446, 'Total loss': 0.5152714770407446}
2022-11-28 03:46:49,387 INFO:     Found new best model at epoch 1
2022-11-28 03:46:49,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:49,388 INFO:     Epoch: 2
2022-11-28 03:46:50,139 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4389794191176241, 'Total loss': 0.4389794191176241} | train loss {'Reaction outcome loss': 0.476340412192287, 'Total loss': 0.476340412192287}
2022-11-28 03:46:50,139 INFO:     Found new best model at epoch 2
2022-11-28 03:46:50,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:50,140 INFO:     Epoch: 3
2022-11-28 03:46:50,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4564881616018035, 'Total loss': 0.4564881616018035} | train loss {'Reaction outcome loss': 0.4605627931774624, 'Total loss': 0.4605627931774624}
2022-11-28 03:46:50,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:50,890 INFO:     Epoch: 4
2022-11-28 03:46:51,639 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4371599206192927, 'Total loss': 0.4371599206192927} | train loss {'Reaction outcome loss': 0.43669183696469954, 'Total loss': 0.43669183696469954}
2022-11-28 03:46:51,639 INFO:     Found new best model at epoch 4
2022-11-28 03:46:51,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:51,640 INFO:     Epoch: 5
2022-11-28 03:46:52,393 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43373642523180356, 'Total loss': 0.43373642523180356} | train loss {'Reaction outcome loss': 0.42397505441500294, 'Total loss': 0.42397505441500294}
2022-11-28 03:46:52,394 INFO:     Found new best model at epoch 5
2022-11-28 03:46:52,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:52,395 INFO:     Epoch: 6
2022-11-28 03:46:53,148 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4237137653610923, 'Total loss': 0.4237137653610923} | train loss {'Reaction outcome loss': 0.41078170977773204, 'Total loss': 0.41078170977773204}
2022-11-28 03:46:53,148 INFO:     Found new best model at epoch 6
2022-11-28 03:46:53,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:53,149 INFO:     Epoch: 7
2022-11-28 03:46:53,903 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42784853279590607, 'Total loss': 0.42784853279590607} | train loss {'Reaction outcome loss': 0.4121711260729259, 'Total loss': 0.4121711260729259}
2022-11-28 03:46:53,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:53,903 INFO:     Epoch: 8
2022-11-28 03:46:54,656 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4169616194611246, 'Total loss': 0.4169616194611246} | train loss {'Reaction outcome loss': 0.41042922725600584, 'Total loss': 0.41042922725600584}
2022-11-28 03:46:54,657 INFO:     Found new best model at epoch 8
2022-11-28 03:46:54,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:54,657 INFO:     Epoch: 9
2022-11-28 03:46:55,411 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4203828038139777, 'Total loss': 0.4203828038139777} | train loss {'Reaction outcome loss': 0.39545177073488313, 'Total loss': 0.39545177073488313}
2022-11-28 03:46:55,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:55,411 INFO:     Epoch: 10
2022-11-28 03:46:56,163 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3994019614024596, 'Total loss': 0.3994019614024596} | train loss {'Reaction outcome loss': 0.3914210410908826, 'Total loss': 0.3914210410908826}
2022-11-28 03:46:56,163 INFO:     Found new best model at epoch 10
2022-11-28 03:46:56,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:56,164 INFO:     Epoch: 11
2022-11-28 03:46:56,916 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42948859235779807, 'Total loss': 0.42948859235779807} | train loss {'Reaction outcome loss': 0.38794820205939395, 'Total loss': 0.38794820205939395}
2022-11-28 03:46:56,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:56,917 INFO:     Epoch: 12
2022-11-28 03:46:57,669 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3984528563239358, 'Total loss': 0.3984528563239358} | train loss {'Reaction outcome loss': 0.3935653642120381, 'Total loss': 0.3935653642120381}
2022-11-28 03:46:57,669 INFO:     Found new best model at epoch 12
2022-11-28 03:46:57,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:57,670 INFO:     Epoch: 13
2022-11-28 03:46:58,422 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39475086432966316, 'Total loss': 0.39475086432966316} | train loss {'Reaction outcome loss': 0.38490419128849623, 'Total loss': 0.38490419128849623}
2022-11-28 03:46:58,423 INFO:     Found new best model at epoch 13
2022-11-28 03:46:58,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:58,423 INFO:     Epoch: 14
2022-11-28 03:46:59,175 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3993184431032701, 'Total loss': 0.3993184431032701} | train loss {'Reaction outcome loss': 0.3703200350846014, 'Total loss': 0.3703200350846014}
2022-11-28 03:46:59,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:59,175 INFO:     Epoch: 15
2022-11-28 03:46:59,928 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3994778630916368, 'Total loss': 0.3994778630916368} | train loss {'Reaction outcome loss': 0.3788301755463885, 'Total loss': 0.3788301755463885}
2022-11-28 03:46:59,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:46:59,928 INFO:     Epoch: 16
2022-11-28 03:47:00,679 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40977177972143347, 'Total loss': 0.40977177972143347} | train loss {'Reaction outcome loss': 0.37587488229356464, 'Total loss': 0.37587488229356464}
2022-11-28 03:47:00,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:00,679 INFO:     Epoch: 17
2022-11-28 03:47:01,437 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4289680252021009, 'Total loss': 0.4289680252021009} | train loss {'Reaction outcome loss': 0.36015905932553355, 'Total loss': 0.36015905932553355}
2022-11-28 03:47:01,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:01,437 INFO:     Epoch: 18
2022-11-28 03:47:02,188 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3867651190270077, 'Total loss': 0.3867651190270077} | train loss {'Reaction outcome loss': 0.36935204721146053, 'Total loss': 0.36935204721146053}
2022-11-28 03:47:02,189 INFO:     Found new best model at epoch 18
2022-11-28 03:47:02,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:02,189 INFO:     Epoch: 19
2022-11-28 03:47:02,940 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4355759160085158, 'Total loss': 0.4355759160085158} | train loss {'Reaction outcome loss': 0.35575219357927, 'Total loss': 0.35575219357927}
2022-11-28 03:47:02,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:02,940 INFO:     Epoch: 20
2022-11-28 03:47:03,687 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39359743893146515, 'Total loss': 0.39359743893146515} | train loss {'Reaction outcome loss': 0.36150821298360825, 'Total loss': 0.36150821298360825}
2022-11-28 03:47:03,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:03,687 INFO:     Epoch: 21
2022-11-28 03:47:04,436 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4212957901710814, 'Total loss': 0.4212957901710814} | train loss {'Reaction outcome loss': 0.3620487837301147, 'Total loss': 0.3620487837301147}
2022-11-28 03:47:04,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:04,437 INFO:     Epoch: 22
2022-11-28 03:47:05,187 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40535495938225224, 'Total loss': 0.40535495938225224} | train loss {'Reaction outcome loss': 0.3627792983466098, 'Total loss': 0.3627792983466098}
2022-11-28 03:47:05,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:05,187 INFO:     Epoch: 23
2022-11-28 03:47:05,936 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4012259261851961, 'Total loss': 0.4012259261851961} | train loss {'Reaction outcome loss': 0.35359332788615455, 'Total loss': 0.35359332788615455}
2022-11-28 03:47:05,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:05,936 INFO:     Epoch: 24
2022-11-28 03:47:06,688 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4091587561098012, 'Total loss': 0.4091587561098012} | train loss {'Reaction outcome loss': 0.362009790635878, 'Total loss': 0.362009790635878}
2022-11-28 03:47:06,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:06,688 INFO:     Epoch: 25
2022-11-28 03:47:07,435 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3823194784874266, 'Total loss': 0.3823194784874266} | train loss {'Reaction outcome loss': 0.3610119286984686, 'Total loss': 0.3610119286984686}
2022-11-28 03:47:07,435 INFO:     Found new best model at epoch 25
2022-11-28 03:47:07,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:07,436 INFO:     Epoch: 26
2022-11-28 03:47:08,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3931369307366284, 'Total loss': 0.3931369307366284} | train loss {'Reaction outcome loss': 0.35444838872119305, 'Total loss': 0.35444838872119305}
2022-11-28 03:47:08,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:08,190 INFO:     Epoch: 27
2022-11-28 03:47:08,940 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3861923051828688, 'Total loss': 0.3861923051828688} | train loss {'Reaction outcome loss': 0.35817631790714877, 'Total loss': 0.35817631790714877}
2022-11-28 03:47:08,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:08,941 INFO:     Epoch: 28
2022-11-28 03:47:09,693 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40934838354587555, 'Total loss': 0.40934838354587555} | train loss {'Reaction outcome loss': 0.3466302560822618, 'Total loss': 0.3466302560822618}
2022-11-28 03:47:09,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:09,693 INFO:     Epoch: 29
2022-11-28 03:47:10,447 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40571805936369026, 'Total loss': 0.40571805936369026} | train loss {'Reaction outcome loss': 0.34813487103148816, 'Total loss': 0.34813487103148816}
2022-11-28 03:47:10,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:10,447 INFO:     Epoch: 30
2022-11-28 03:47:11,202 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41997891054912045, 'Total loss': 0.41997891054912045} | train loss {'Reaction outcome loss': 0.3352131125547232, 'Total loss': 0.3352131125547232}
2022-11-28 03:47:11,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:11,203 INFO:     Epoch: 31
2022-11-28 03:47:11,957 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4054808474399827, 'Total loss': 0.4054808474399827} | train loss {'Reaction outcome loss': 0.3522442917850229, 'Total loss': 0.3522442917850229}
2022-11-28 03:47:11,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:11,957 INFO:     Epoch: 32
2022-11-28 03:47:12,710 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43684441393071954, 'Total loss': 0.43684441393071954} | train loss {'Reaction outcome loss': 0.3458353069520766, 'Total loss': 0.3458353069520766}
2022-11-28 03:47:12,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:12,711 INFO:     Epoch: 33
2022-11-28 03:47:13,463 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4186347651888024, 'Total loss': 0.4186347651888024} | train loss {'Reaction outcome loss': 0.3513842577475213, 'Total loss': 0.3513842577475213}
2022-11-28 03:47:13,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:13,463 INFO:     Epoch: 34
2022-11-28 03:47:14,213 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40354561365463515, 'Total loss': 0.40354561365463515} | train loss {'Reaction outcome loss': 0.3429789406157309, 'Total loss': 0.3429789406157309}
2022-11-28 03:47:14,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:14,213 INFO:     Epoch: 35
2022-11-28 03:47:14,965 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.409739377823743, 'Total loss': 0.409739377823743} | train loss {'Reaction outcome loss': 0.3427419550116024, 'Total loss': 0.3427419550116024}
2022-11-28 03:47:14,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:14,966 INFO:     Epoch: 36
2022-11-28 03:47:15,718 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38437694853002374, 'Total loss': 0.38437694853002374} | train loss {'Reaction outcome loss': 0.34064521406206394, 'Total loss': 0.34064521406206394}
2022-11-28 03:47:15,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:15,719 INFO:     Epoch: 37
2022-11-28 03:47:16,471 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3976635242050344, 'Total loss': 0.3976635242050344} | train loss {'Reaction outcome loss': 0.34311787002990324, 'Total loss': 0.34311787002990324}
2022-11-28 03:47:16,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:16,471 INFO:     Epoch: 38
2022-11-28 03:47:17,223 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4309990023347465, 'Total loss': 0.4309990023347465} | train loss {'Reaction outcome loss': 0.3455843209258972, 'Total loss': 0.3455843209258972}
2022-11-28 03:47:17,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:17,223 INFO:     Epoch: 39
2022-11-28 03:47:17,977 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38476587053049693, 'Total loss': 0.38476587053049693} | train loss {'Reaction outcome loss': 0.33195204819522556, 'Total loss': 0.33195204819522556}
2022-11-28 03:47:17,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:17,978 INFO:     Epoch: 40
2022-11-28 03:47:18,731 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39667408066717064, 'Total loss': 0.39667408066717064} | train loss {'Reaction outcome loss': 0.3375854442316678, 'Total loss': 0.3375854442316678}
2022-11-28 03:47:18,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:18,731 INFO:     Epoch: 41
2022-11-28 03:47:19,484 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37479383092034946, 'Total loss': 0.37479383092034946} | train loss {'Reaction outcome loss': 0.3362104761143846, 'Total loss': 0.3362104761143846}
2022-11-28 03:47:19,485 INFO:     Found new best model at epoch 41
2022-11-28 03:47:19,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:19,485 INFO:     Epoch: 42
2022-11-28 03:47:20,235 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.404887027699839, 'Total loss': 0.404887027699839} | train loss {'Reaction outcome loss': 0.33402316682341116, 'Total loss': 0.33402316682341116}
2022-11-28 03:47:20,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:20,236 INFO:     Epoch: 43
2022-11-28 03:47:20,987 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38790000162341376, 'Total loss': 0.38790000162341376} | train loss {'Reaction outcome loss': 0.335105680860579, 'Total loss': 0.335105680860579}
2022-11-28 03:47:20,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:20,988 INFO:     Epoch: 44
2022-11-28 03:47:21,738 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42389752106233075, 'Total loss': 0.42389752106233075} | train loss {'Reaction outcome loss': 0.3366530471811852, 'Total loss': 0.3366530471811852}
2022-11-28 03:47:21,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:21,739 INFO:     Epoch: 45
2022-11-28 03:47:22,494 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37296429174867546, 'Total loss': 0.37296429174867546} | train loss {'Reaction outcome loss': 0.33229674987735286, 'Total loss': 0.33229674987735286}
2022-11-28 03:47:22,494 INFO:     Found new best model at epoch 45
2022-11-28 03:47:22,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:22,495 INFO:     Epoch: 46
2022-11-28 03:47:23,247 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38326083902608266, 'Total loss': 0.38326083902608266} | train loss {'Reaction outcome loss': 0.3322552495726174, 'Total loss': 0.3322552495726174}
2022-11-28 03:47:23,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:23,248 INFO:     Epoch: 47
2022-11-28 03:47:24,000 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3858418610285629, 'Total loss': 0.3858418610285629} | train loss {'Reaction outcome loss': 0.3335210020623861, 'Total loss': 0.3335210020623861}
2022-11-28 03:47:24,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:24,001 INFO:     Epoch: 48
2022-11-28 03:47:24,752 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38843018595467915, 'Total loss': 0.38843018595467915} | train loss {'Reaction outcome loss': 0.33182969328857237, 'Total loss': 0.33182969328857237}
2022-11-28 03:47:24,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:24,753 INFO:     Epoch: 49
2022-11-28 03:47:25,507 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3841328515925191, 'Total loss': 0.3841328515925191} | train loss {'Reaction outcome loss': 0.3286330332799304, 'Total loss': 0.3286330332799304}
2022-11-28 03:47:25,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:25,507 INFO:     Epoch: 50
2022-11-28 03:47:26,261 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3922826236283237, 'Total loss': 0.3922826236283237} | train loss {'Reaction outcome loss': 0.33392997034975597, 'Total loss': 0.33392997034975597}
2022-11-28 03:47:26,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:26,261 INFO:     Epoch: 51
2022-11-28 03:47:27,016 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37880407324568793, 'Total loss': 0.37880407324568793} | train loss {'Reaction outcome loss': 0.32452985446058935, 'Total loss': 0.32452985446058935}
2022-11-28 03:47:27,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:27,016 INFO:     Epoch: 52
2022-11-28 03:47:27,772 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4005419652570378, 'Total loss': 0.4005419652570378} | train loss {'Reaction outcome loss': 0.3412503530121138, 'Total loss': 0.3412503530121138}
2022-11-28 03:47:27,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:27,773 INFO:     Epoch: 53
2022-11-28 03:47:28,525 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40305857394229283, 'Total loss': 0.40305857394229283} | train loss {'Reaction outcome loss': 0.3348119059096902, 'Total loss': 0.3348119059096902}
2022-11-28 03:47:28,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:28,525 INFO:     Epoch: 54
2022-11-28 03:47:29,276 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40111267498948355, 'Total loss': 0.40111267498948355} | train loss {'Reaction outcome loss': 0.3285429794040899, 'Total loss': 0.3285429794040899}
2022-11-28 03:47:29,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:29,276 INFO:     Epoch: 55
2022-11-28 03:47:30,028 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3912221443924037, 'Total loss': 0.3912221443924037} | train loss {'Reaction outcome loss': 0.3237072350907951, 'Total loss': 0.3237072350907951}
2022-11-28 03:47:30,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:30,029 INFO:     Epoch: 56
2022-11-28 03:47:30,780 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37002054919404065, 'Total loss': 0.37002054919404065} | train loss {'Reaction outcome loss': 0.32779087408656077, 'Total loss': 0.32779087408656077}
2022-11-28 03:47:30,780 INFO:     Found new best model at epoch 56
2022-11-28 03:47:30,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:30,781 INFO:     Epoch: 57
2022-11-28 03:47:31,532 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4021611234850504, 'Total loss': 0.4021611234850504} | train loss {'Reaction outcome loss': 0.3228331578655108, 'Total loss': 0.3228331578655108}
2022-11-28 03:47:31,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:31,532 INFO:     Epoch: 58
2022-11-28 03:47:32,283 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3606811717829921, 'Total loss': 0.3606811717829921} | train loss {'Reaction outcome loss': 0.3279577912161908, 'Total loss': 0.3279577912161908}
2022-11-28 03:47:32,283 INFO:     Found new best model at epoch 58
2022-11-28 03:47:32,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:32,284 INFO:     Epoch: 59
2022-11-28 03:47:33,039 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36774813095954334, 'Total loss': 0.36774813095954334} | train loss {'Reaction outcome loss': 0.32521573599848536, 'Total loss': 0.32521573599848536}
2022-11-28 03:47:33,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:33,039 INFO:     Epoch: 60
2022-11-28 03:47:33,795 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40119992128827353, 'Total loss': 0.40119992128827353} | train loss {'Reaction outcome loss': 0.32918037326946376, 'Total loss': 0.32918037326946376}
2022-11-28 03:47:33,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:33,796 INFO:     Epoch: 61
2022-11-28 03:47:34,549 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3918867009607228, 'Total loss': 0.3918867009607228} | train loss {'Reaction outcome loss': 0.32257257924685556, 'Total loss': 0.32257257924685556}
2022-11-28 03:47:34,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:34,549 INFO:     Epoch: 62
2022-11-28 03:47:35,303 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4016139381988482, 'Total loss': 0.4016139381988482} | train loss {'Reaction outcome loss': 0.32645518014267566, 'Total loss': 0.32645518014267566}
2022-11-28 03:47:35,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:35,303 INFO:     Epoch: 63
2022-11-28 03:47:36,057 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39416388439183886, 'Total loss': 0.39416388439183886} | train loss {'Reaction outcome loss': 0.31840841841673656, 'Total loss': 0.31840841841673656}
2022-11-28 03:47:36,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:36,057 INFO:     Epoch: 64
2022-11-28 03:47:36,814 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38029044527899136, 'Total loss': 0.38029044527899136} | train loss {'Reaction outcome loss': 0.32067246656985054, 'Total loss': 0.32067246656985054}
2022-11-28 03:47:36,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:36,814 INFO:     Epoch: 65
2022-11-28 03:47:37,570 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3983298133720051, 'Total loss': 0.3983298133720051} | train loss {'Reaction outcome loss': 0.3237377822609438, 'Total loss': 0.3237377822609438}
2022-11-28 03:47:37,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:37,570 INFO:     Epoch: 66
2022-11-28 03:47:38,329 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3982985835861076, 'Total loss': 0.3982985835861076} | train loss {'Reaction outcome loss': 0.3177495985141685, 'Total loss': 0.3177495985141685}
2022-11-28 03:47:38,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:38,329 INFO:     Epoch: 67
2022-11-28 03:47:39,084 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4202295772053979, 'Total loss': 0.4202295772053979} | train loss {'Reaction outcome loss': 0.32852270424125657, 'Total loss': 0.32852270424125657}
2022-11-28 03:47:39,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:39,085 INFO:     Epoch: 68
2022-11-28 03:47:39,836 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40104282325641677, 'Total loss': 0.40104282325641677} | train loss {'Reaction outcome loss': 0.3241953093618635, 'Total loss': 0.3241953093618635}
2022-11-28 03:47:39,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:39,836 INFO:     Epoch: 69
2022-11-28 03:47:40,588 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3781992155550556, 'Total loss': 0.3781992155550556} | train loss {'Reaction outcome loss': 0.32328353861286757, 'Total loss': 0.32328353861286757}
2022-11-28 03:47:40,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:40,588 INFO:     Epoch: 70
2022-11-28 03:47:41,343 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3918970179828731, 'Total loss': 0.3918970179828731} | train loss {'Reaction outcome loss': 0.321436483322853, 'Total loss': 0.321436483322853}
2022-11-28 03:47:41,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:41,343 INFO:     Epoch: 71
2022-11-28 03:47:42,097 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4255550480024381, 'Total loss': 0.4255550480024381} | train loss {'Reaction outcome loss': 0.32203482557088137, 'Total loss': 0.32203482557088137}
2022-11-28 03:47:42,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:42,098 INFO:     Epoch: 72
2022-11-28 03:47:42,852 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3913224183700301, 'Total loss': 0.3913224183700301} | train loss {'Reaction outcome loss': 0.32554869290681615, 'Total loss': 0.32554869290681615}
2022-11-28 03:47:42,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:42,852 INFO:     Epoch: 73
2022-11-28 03:47:43,607 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3910273980687965, 'Total loss': 0.3910273980687965} | train loss {'Reaction outcome loss': 0.31760712848195144, 'Total loss': 0.31760712848195144}
2022-11-28 03:47:43,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:43,607 INFO:     Epoch: 74
2022-11-28 03:47:44,361 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4022108136930249, 'Total loss': 0.4022108136930249} | train loss {'Reaction outcome loss': 0.3277750387487392, 'Total loss': 0.3277750387487392}
2022-11-28 03:47:44,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:44,361 INFO:     Epoch: 75
2022-11-28 03:47:45,119 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3725959953259338, 'Total loss': 0.3725959953259338} | train loss {'Reaction outcome loss': 0.31850155527072566, 'Total loss': 0.31850155527072566}
2022-11-28 03:47:45,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:45,119 INFO:     Epoch: 76
2022-11-28 03:47:45,871 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4098566274412654, 'Total loss': 0.4098566274412654} | train loss {'Reaction outcome loss': 0.3215658040717244, 'Total loss': 0.3215658040717244}
2022-11-28 03:47:45,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:45,871 INFO:     Epoch: 77
2022-11-28 03:47:46,624 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3775049867955121, 'Total loss': 0.3775049867955121} | train loss {'Reaction outcome loss': 0.31645125223534004, 'Total loss': 0.31645125223534004}
2022-11-28 03:47:46,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:46,624 INFO:     Epoch: 78
2022-11-28 03:47:47,381 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38434905457225715, 'Total loss': 0.38434905457225715} | train loss {'Reaction outcome loss': 0.3184364686209348, 'Total loss': 0.3184364686209348}
2022-11-28 03:47:47,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:47,381 INFO:     Epoch: 79
2022-11-28 03:47:48,136 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37154747816649353, 'Total loss': 0.37154747816649353} | train loss {'Reaction outcome loss': 0.32179442925318597, 'Total loss': 0.32179442925318597}
2022-11-28 03:47:48,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:48,136 INFO:     Epoch: 80
2022-11-28 03:47:48,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37919427623802965, 'Total loss': 0.37919427623802965} | train loss {'Reaction outcome loss': 0.32127038146098774, 'Total loss': 0.32127038146098774}
2022-11-28 03:47:48,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:48,893 INFO:     Epoch: 81
2022-11-28 03:47:49,648 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42243312841111963, 'Total loss': 0.42243312841111963} | train loss {'Reaction outcome loss': 0.31758493407359045, 'Total loss': 0.31758493407359045}
2022-11-28 03:47:49,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:49,649 INFO:     Epoch: 82
2022-11-28 03:47:50,404 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39359884573654697, 'Total loss': 0.39359884573654697} | train loss {'Reaction outcome loss': 0.3161517702373526, 'Total loss': 0.3161517702373526}
2022-11-28 03:47:50,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:50,404 INFO:     Epoch: 83
2022-11-28 03:47:51,165 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.395205538042567, 'Total loss': 0.395205538042567} | train loss {'Reaction outcome loss': 0.32702785051397737, 'Total loss': 0.32702785051397737}
2022-11-28 03:47:51,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:51,166 INFO:     Epoch: 84
2022-11-28 03:47:51,918 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41347022490067914, 'Total loss': 0.41347022490067914} | train loss {'Reaction outcome loss': 0.3225806245820657, 'Total loss': 0.3225806245820657}
2022-11-28 03:47:51,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:51,918 INFO:     Epoch: 85
2022-11-28 03:47:52,673 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3800270472737876, 'Total loss': 0.3800270472737876} | train loss {'Reaction outcome loss': 0.32517810998063895, 'Total loss': 0.32517810998063895}
2022-11-28 03:47:52,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:52,674 INFO:     Epoch: 86
2022-11-28 03:47:53,428 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4049618325450204, 'Total loss': 0.4049618325450204} | train loss {'Reaction outcome loss': 0.3176030258257543, 'Total loss': 0.3176030258257543}
2022-11-28 03:47:53,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:53,429 INFO:     Epoch: 87
2022-11-28 03:47:54,185 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.407134987752546, 'Total loss': 0.407134987752546} | train loss {'Reaction outcome loss': 0.3207413598354305, 'Total loss': 0.3207413598354305}
2022-11-28 03:47:54,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:54,186 INFO:     Epoch: 88
2022-11-28 03:47:54,942 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39385311694985087, 'Total loss': 0.39385311694985087} | train loss {'Reaction outcome loss': 0.3237041459088364, 'Total loss': 0.3237041459088364}
2022-11-28 03:47:54,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:54,942 INFO:     Epoch: 89
2022-11-28 03:47:55,696 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3790093934671445, 'Total loss': 0.3790093934671445} | train loss {'Reaction outcome loss': 0.3250625092956808, 'Total loss': 0.3250625092956808}
2022-11-28 03:47:55,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:55,697 INFO:     Epoch: 90
2022-11-28 03:47:56,451 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3978314826434309, 'Total loss': 0.3978314826434309} | train loss {'Reaction outcome loss': 0.3183323590445422, 'Total loss': 0.3183323590445422}
2022-11-28 03:47:56,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:56,452 INFO:     Epoch: 91
2022-11-28 03:47:57,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39356704530390824, 'Total loss': 0.39356704530390824} | train loss {'Reaction outcome loss': 0.31752509194155853, 'Total loss': 0.31752509194155853}
2022-11-28 03:47:57,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:57,208 INFO:     Epoch: 92
2022-11-28 03:47:57,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.384789907627485, 'Total loss': 0.384789907627485} | train loss {'Reaction outcome loss': 0.3228612651808127, 'Total loss': 0.3228612651808127}
2022-11-28 03:47:57,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:57,962 INFO:     Epoch: 93
2022-11-28 03:47:58,716 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40188460052013397, 'Total loss': 0.40188460052013397} | train loss {'Reaction outcome loss': 0.3204254315445019, 'Total loss': 0.3204254315445019}
2022-11-28 03:47:58,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:58,717 INFO:     Epoch: 94
2022-11-28 03:47:59,472 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4028421108695594, 'Total loss': 0.4028421108695594} | train loss {'Reaction outcome loss': 0.31904285563336265, 'Total loss': 0.31904285563336265}
2022-11-28 03:47:59,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:47:59,472 INFO:     Epoch: 95
2022-11-28 03:48:00,229 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4018036438660188, 'Total loss': 0.4018036438660188} | train loss {'Reaction outcome loss': 0.3296169461982866, 'Total loss': 0.3296169461982866}
2022-11-28 03:48:00,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:48:00,229 INFO:     Epoch: 96
2022-11-28 03:48:00,989 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3851384222507477, 'Total loss': 0.3851384222507477} | train loss {'Reaction outcome loss': 0.32265783990583113, 'Total loss': 0.32265783990583113}
2022-11-28 03:48:00,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:48:00,989 INFO:     Epoch: 97
2022-11-28 03:48:01,745 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.397868464616212, 'Total loss': 0.397868464616212} | train loss {'Reaction outcome loss': 0.31712377642191225, 'Total loss': 0.31712377642191225}
2022-11-28 03:48:01,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:48:01,745 INFO:     Epoch: 98
2022-11-28 03:48:02,501 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3763464398004792, 'Total loss': 0.3763464398004792} | train loss {'Reaction outcome loss': 0.3191214329112441, 'Total loss': 0.3191214329112441}
2022-11-28 03:48:02,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 03:48:02,501 INFO:     Epoch: 99
2022-11-28 03:48:03,257 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36743084476752713, 'Total loss': 0.36743084476752713} | train loss {'Reaction outcome loss': 0.31633573728463343, 'Total loss': 0.31633573728463343}
2022-11-28 03:48:03,257 INFO:     Best model found after epoch 59 of 100.
2022-11-28 03:48:03,257 INFO:   Done with stage: TRAINING
2022-11-28 03:48:03,257 INFO:   Starting stage: EVALUATION
2022-11-28 03:48:03,373 INFO:   Done with stage: EVALUATION
2022-11-28 03:48:03,373 INFO: Done with stage: RUNNING SPLITS
2022-11-28 03:48:03,373 INFO: Starting stage: COMPUTE METRICS
2022-11-28 03:48:04,533 INFO: Done with stage: COMPUTE METRICS
2022-11-28 03:48:04,533 INFO: Starting stage: EXPORT RESULTS
2022-11-28 03:48:04,551 INFO:   Final results averaged over 50 folds: 
2022-11-28 03:48:04,554 INFO:   
                     mae  neg-spearman     rmse  spearman
dataset_split                                           
test           0.172893           NaN  0.30648       NaN
2022-11-28 03:48:06,305 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 03:48:06,312 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 03:48:06,313 DEBUG:   interactive is False
2022-11-28 03:48:06,313 DEBUG:   platform is linux
2022-11-28 03:48:06,313 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 03:48:06,483 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 03:48:06,485 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 03:48:06,911 DEBUG:   Loaded backend agg version unknown.
2022-11-28 03:48:06,913 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 03:48:06,913 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,913 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,913 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,913 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,914 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,915 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,916 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,916 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 03:48:06,952 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 03:48:06,952 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,953 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,954 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,955 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,955 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 03:48:06,963 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,964 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 03:48:06,966 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 03:48:06,966 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 03:48:07,387 INFO: Done with stage: EXPORT RESULTS
2022-11-28 03:48:07,387 INFO: Starting stage: SAVE MODEL
2022-11-28 03:48:07,436 INFO: Done with stage: SAVE MODEL
2022-11-28 03:48:07,436 INFO: Wall time for program:  3786.23 seconds
