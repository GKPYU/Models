2023-01-05 03:58:19,257 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/8d442588c1d7d0862ab2ec51a815ff3e/2023_01_04-214451",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-05 03:58:19,265 INFO: Starting stage: BUILD FEATURIZERS
2023-01-05 03:58:19,267 INFO:   Creating esm representation model
2023-01-05 03:58:19,267 INFO:   Done esm representation model
2023-01-05 03:58:19,267 INFO: Done with stage: BUILD FEATURIZERS
2023-01-05 03:58:19,267 INFO: Starting stage: BUILDING DATASET
2023-01-05 03:58:19,321 INFO: Done with stage: BUILDING DATASET
2023-01-05 03:58:19,321 INFO: Starting stage: FEATURIZING DATA
2023-01-05 03:58:19,321 INFO:   Featurizing proteins
2023-01-05 03:58:19,322 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-05 03:58:19,327 INFO:   Loaded feature cache of size 489
2023-01-05 03:58:19,328 INFO:   Starting to pool ESM Embeddings
2023-01-05 03:58:19,434 INFO:   Featurizing molecules
2023-01-05 03:58:19,436 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-05 03:58:19,439 INFO:   Loaded feature cache of size 498
2023-01-05 03:58:20,786 INFO: Done with stage: FEATURIZING DATA
2023-01-05 03:58:20,786 INFO: Starting stage: RUNNING SPLITS
2023-01-05 03:58:20,795 INFO:   Leaving out SEQ value Fold_0
2023-01-05 03:58:20,809 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 03:58:20,809 INFO:   Starting stage: FEATURE SCALING
2023-01-05 03:58:21,475 INFO:   Done with stage: FEATURE SCALING
2023-01-05 03:58:21,476 INFO:   Starting stage: SCALING TARGETS
2023-01-05 03:58:21,546 INFO:   Done with stage: SCALING TARGETS
2023-01-05 03:58:21,546 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:58:21,546 INFO:     No hyperparam tuning for this model
2023-01-05 03:58:21,546 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 03:58:21,546 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 03:58:21,547 INFO:     None feature selector for col prot
2023-01-05 03:58:21,547 INFO:     None feature selector for col prot
2023-01-05 03:58:21,547 INFO:     None feature selector for col prot
2023-01-05 03:58:21,548 INFO:     None feature selector for col chem
2023-01-05 03:58:21,548 INFO:     None feature selector for col chem
2023-01-05 03:58:21,548 INFO:     None feature selector for col chem
2023-01-05 03:58:21,548 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 03:58:21,548 INFO:   Starting stage: BUILD MODEL
2023-01-05 03:58:21,549 INFO:     Number of params in model 72931
2023-01-05 03:58:21,549 INFO:   Done with stage: BUILD MODEL
2023-01-05 03:58:21,550 INFO:   Starting stage: TRAINING
2023-01-05 03:58:23,185 INFO:     Val loss before train {'Reaction outcome loss': 1.0296780943870545, 'Total loss': 1.0296780943870545}
2023-01-05 03:58:23,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:23,185 INFO:     Epoch: 0
2023-01-05 03:58:25,169 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7986316521962483, 'Total loss': 0.7986316521962483} | train loss {'Reaction outcome loss': 0.9297645893289056, 'Total loss': 0.9297645893289056}
2023-01-05 03:58:25,169 INFO:     Found new best model at epoch 0
2023-01-05 03:58:25,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:25,171 INFO:     Epoch: 1
2023-01-05 03:58:27,339 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5806519468625386, 'Total loss': 0.5806519468625386} | train loss {'Reaction outcome loss': 0.6400058426153965, 'Total loss': 0.6400058426153965}
2023-01-05 03:58:27,339 INFO:     Found new best model at epoch 1
2023-01-05 03:58:27,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:27,340 INFO:     Epoch: 2
2023-01-05 03:58:29,551 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.524345862865448, 'Total loss': 0.524345862865448} | train loss {'Reaction outcome loss': 0.5462079573791105, 'Total loss': 0.5462079573791105}
2023-01-05 03:58:29,551 INFO:     Found new best model at epoch 2
2023-01-05 03:58:29,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:29,553 INFO:     Epoch: 3
2023-01-05 03:58:31,684 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.496260271469752, 'Total loss': 0.496260271469752} | train loss {'Reaction outcome loss': 0.49939800116605376, 'Total loss': 0.49939800116605376}
2023-01-05 03:58:31,684 INFO:     Found new best model at epoch 3
2023-01-05 03:58:31,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:31,686 INFO:     Epoch: 4
2023-01-05 03:58:33,895 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4504254808028539, 'Total loss': 0.4504254808028539} | train loss {'Reaction outcome loss': 0.46739920520738804, 'Total loss': 0.46739920520738804}
2023-01-05 03:58:33,895 INFO:     Found new best model at epoch 4
2023-01-05 03:58:33,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:33,897 INFO:     Epoch: 5
2023-01-05 03:58:36,087 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45214764078458153, 'Total loss': 0.45214764078458153} | train loss {'Reaction outcome loss': 0.4437289338408809, 'Total loss': 0.4437289338408809}
2023-01-05 03:58:36,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:36,087 INFO:     Epoch: 6
2023-01-05 03:58:38,228 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4314078211784363, 'Total loss': 0.4314078211784363} | train loss {'Reaction outcome loss': 0.4196213634186612, 'Total loss': 0.4196213634186612}
2023-01-05 03:58:38,228 INFO:     Found new best model at epoch 6
2023-01-05 03:58:38,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:38,230 INFO:     Epoch: 7
2023-01-05 03:58:40,413 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4350539435942968, 'Total loss': 0.4350539435942968} | train loss {'Reaction outcome loss': 0.40707145887853463, 'Total loss': 0.40707145887853463}
2023-01-05 03:58:40,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:40,413 INFO:     Epoch: 8
2023-01-05 03:58:42,571 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4190491179625193, 'Total loss': 0.4190491179625193} | train loss {'Reaction outcome loss': 0.39329975106558956, 'Total loss': 0.39329975106558956}
2023-01-05 03:58:42,572 INFO:     Found new best model at epoch 8
2023-01-05 03:58:42,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:42,573 INFO:     Epoch: 9
2023-01-05 03:58:44,783 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.453136670589447, 'Total loss': 0.453136670589447} | train loss {'Reaction outcome loss': 0.37813763647944065, 'Total loss': 0.37813763647944065}
2023-01-05 03:58:44,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:44,783 INFO:     Epoch: 10
2023-01-05 03:58:46,982 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43676754931608835, 'Total loss': 0.43676754931608835} | train loss {'Reaction outcome loss': 0.37764036884674657, 'Total loss': 0.37764036884674657}
2023-01-05 03:58:46,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:46,982 INFO:     Epoch: 11
2023-01-05 03:58:49,159 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4423797786235809, 'Total loss': 0.4423797786235809} | train loss {'Reaction outcome loss': 0.35709763099968217, 'Total loss': 0.35709763099968217}
2023-01-05 03:58:49,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:49,159 INFO:     Epoch: 12
2023-01-05 03:58:51,325 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42063140074412025, 'Total loss': 0.42063140074412025} | train loss {'Reaction outcome loss': 0.35268322078190445, 'Total loss': 0.35268322078190445}
2023-01-05 03:58:51,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:51,325 INFO:     Epoch: 13
2023-01-05 03:58:53,542 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44795723954836525, 'Total loss': 0.44795723954836525} | train loss {'Reaction outcome loss': 0.3423872143985369, 'Total loss': 0.3423872143985369}
2023-01-05 03:58:53,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:53,542 INFO:     Epoch: 14
2023-01-05 03:58:55,747 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4426261246204376, 'Total loss': 0.4426261246204376} | train loss {'Reaction outcome loss': 0.33964930497955925, 'Total loss': 0.33964930497955925}
2023-01-05 03:58:55,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:55,747 INFO:     Epoch: 15
2023-01-05 03:58:57,873 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4246233602364858, 'Total loss': 0.4246233602364858} | train loss {'Reaction outcome loss': 0.3277728236911498, 'Total loss': 0.3277728236911498}
2023-01-05 03:58:57,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:58:57,874 INFO:     Epoch: 16
2023-01-05 03:59:00,062 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45072715878486636, 'Total loss': 0.45072715878486636} | train loss {'Reaction outcome loss': 0.319111088652423, 'Total loss': 0.319111088652423}
2023-01-05 03:59:00,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:00,062 INFO:     Epoch: 17
2023-01-05 03:59:02,257 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4503553052743276, 'Total loss': 0.4503553052743276} | train loss {'Reaction outcome loss': 0.3134269804690347, 'Total loss': 0.3134269804690347}
2023-01-05 03:59:02,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:02,257 INFO:     Epoch: 18
2023-01-05 03:59:04,431 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43039874037106834, 'Total loss': 0.43039874037106834} | train loss {'Reaction outcome loss': 0.30850157743463147, 'Total loss': 0.30850157743463147}
2023-01-05 03:59:04,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:04,431 INFO:     Epoch: 19
2023-01-05 03:59:06,596 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.463637101650238, 'Total loss': 0.463637101650238} | train loss {'Reaction outcome loss': 0.30121731487931785, 'Total loss': 0.30121731487931785}
2023-01-05 03:59:06,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:06,596 INFO:     Epoch: 20
2023-01-05 03:59:08,807 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46068726579348246, 'Total loss': 0.46068726579348246} | train loss {'Reaction outcome loss': 0.29420288237350767, 'Total loss': 0.29420288237350767}
2023-01-05 03:59:08,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:08,807 INFO:     Epoch: 21
2023-01-05 03:59:10,966 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4743088980515798, 'Total loss': 0.4743088980515798} | train loss {'Reaction outcome loss': 0.2921526203471007, 'Total loss': 0.2921526203471007}
2023-01-05 03:59:10,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:10,966 INFO:     Epoch: 22
2023-01-05 03:59:13,114 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46697816749413806, 'Total loss': 0.46697816749413806} | train loss {'Reaction outcome loss': 0.2854541093111038, 'Total loss': 0.2854541093111038}
2023-01-05 03:59:13,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:13,114 INFO:     Epoch: 23
2023-01-05 03:59:15,279 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4907303601503372, 'Total loss': 0.4907303601503372} | train loss {'Reaction outcome loss': 0.2795500820263838, 'Total loss': 0.2795500820263838}
2023-01-05 03:59:15,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:15,279 INFO:     Epoch: 24
2023-01-05 03:59:17,484 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45022551019986473, 'Total loss': 0.45022551019986473} | train loss {'Reaction outcome loss': 0.2776112833602743, 'Total loss': 0.2776112833602743}
2023-01-05 03:59:17,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:17,485 INFO:     Epoch: 25
2023-01-05 03:59:19,704 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4496580352385839, 'Total loss': 0.4496580352385839} | train loss {'Reaction outcome loss': 0.2746478176331182, 'Total loss': 0.2746478176331182}
2023-01-05 03:59:19,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:19,704 INFO:     Epoch: 26
2023-01-05 03:59:21,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45879876911640166, 'Total loss': 0.45879876911640166} | train loss {'Reaction outcome loss': 0.2659564807519808, 'Total loss': 0.2659564807519808}
2023-01-05 03:59:21,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:21,898 INFO:     Epoch: 27
2023-01-05 03:59:24,079 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4671818772951762, 'Total loss': 0.4671818772951762} | train loss {'Reaction outcome loss': 0.263587170700123, 'Total loss': 0.263587170700123}
2023-01-05 03:59:24,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:24,080 INFO:     Epoch: 28
2023-01-05 03:59:26,269 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4741526852051417, 'Total loss': 0.4741526852051417} | train loss {'Reaction outcome loss': 0.26196587817136185, 'Total loss': 0.26196587817136185}
2023-01-05 03:59:26,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:26,270 INFO:     Epoch: 29
2023-01-05 03:59:28,467 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46163746813933054, 'Total loss': 0.46163746813933054} | train loss {'Reaction outcome loss': 0.2575925427451457, 'Total loss': 0.2575925427451457}
2023-01-05 03:59:28,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:28,467 INFO:     Epoch: 30
2023-01-05 03:59:30,644 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4867039680480957, 'Total loss': 0.4867039680480957} | train loss {'Reaction outcome loss': 0.2526659461577515, 'Total loss': 0.2526659461577515}
2023-01-05 03:59:30,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:30,645 INFO:     Epoch: 31
2023-01-05 03:59:32,849 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4394837811589241, 'Total loss': 0.4394837811589241} | train loss {'Reaction outcome loss': 0.25129666107096077, 'Total loss': 0.25129666107096077}
2023-01-05 03:59:32,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:32,849 INFO:     Epoch: 32
2023-01-05 03:59:35,031 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4662119120359421, 'Total loss': 0.4662119120359421} | train loss {'Reaction outcome loss': 0.24748575306691967, 'Total loss': 0.24748575306691967}
2023-01-05 03:59:35,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:35,032 INFO:     Epoch: 33
2023-01-05 03:59:37,243 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4464672346909841, 'Total loss': 0.4464672346909841} | train loss {'Reaction outcome loss': 0.24389396056587442, 'Total loss': 0.24389396056587442}
2023-01-05 03:59:37,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:37,243 INFO:     Epoch: 34
2023-01-05 03:59:39,449 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46112344165643054, 'Total loss': 0.46112344165643054} | train loss {'Reaction outcome loss': 0.23975259394490675, 'Total loss': 0.23975259394490675}
2023-01-05 03:59:39,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:39,449 INFO:     Epoch: 35
2023-01-05 03:59:41,642 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4484510987997055, 'Total loss': 0.4484510987997055} | train loss {'Reaction outcome loss': 0.24119791499724536, 'Total loss': 0.24119791499724536}
2023-01-05 03:59:41,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:41,642 INFO:     Epoch: 36
2023-01-05 03:59:43,852 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44594282408555347, 'Total loss': 0.44594282408555347} | train loss {'Reaction outcome loss': 0.2342228991262642, 'Total loss': 0.2342228991262642}
2023-01-05 03:59:43,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:43,853 INFO:     Epoch: 37
2023-01-05 03:59:46,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4569521536429723, 'Total loss': 0.4569521536429723} | train loss {'Reaction outcome loss': 0.23383591590183123, 'Total loss': 0.23383591590183123}
2023-01-05 03:59:46,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:46,052 INFO:     Epoch: 38
2023-01-05 03:59:48,326 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45399282276630404, 'Total loss': 0.45399282276630404} | train loss {'Reaction outcome loss': 0.2267391980922484, 'Total loss': 0.2267391980922484}
2023-01-05 03:59:48,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:48,326 INFO:     Epoch: 39
2023-01-05 03:59:50,603 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48066975275675455, 'Total loss': 0.48066975275675455} | train loss {'Reaction outcome loss': 0.23187823760435805, 'Total loss': 0.23187823760435805}
2023-01-05 03:59:50,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:50,603 INFO:     Epoch: 40
2023-01-05 03:59:52,868 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48888710637887317, 'Total loss': 0.48888710637887317} | train loss {'Reaction outcome loss': 0.22501312302691595, 'Total loss': 0.22501312302691595}
2023-01-05 03:59:52,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:52,868 INFO:     Epoch: 41
2023-01-05 03:59:55,133 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46446894605954486, 'Total loss': 0.46446894605954486} | train loss {'Reaction outcome loss': 0.2150022511680921, 'Total loss': 0.2150022511680921}
2023-01-05 03:59:55,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:55,134 INFO:     Epoch: 42
2023-01-05 03:59:57,371 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49742552439371746, 'Total loss': 0.49742552439371746} | train loss {'Reaction outcome loss': 0.22021149522573738, 'Total loss': 0.22021149522573738}
2023-01-05 03:59:57,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:57,371 INFO:     Epoch: 43
2023-01-05 03:59:59,640 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4474244977037112, 'Total loss': 0.4474244977037112} | train loss {'Reaction outcome loss': 0.21798757707270291, 'Total loss': 0.21798757707270291}
2023-01-05 03:59:59,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 03:59:59,641 INFO:     Epoch: 44
2023-01-05 04:00:01,917 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44917070468266806, 'Total loss': 0.44917070468266806} | train loss {'Reaction outcome loss': 0.22187339730779113, 'Total loss': 0.22187339730779113}
2023-01-05 04:00:01,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:01,917 INFO:     Epoch: 45
2023-01-05 04:00:04,173 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46048618455727897, 'Total loss': 0.46048618455727897} | train loss {'Reaction outcome loss': 0.21779476067276446, 'Total loss': 0.21779476067276446}
2023-01-05 04:00:04,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:04,175 INFO:     Epoch: 46
2023-01-05 04:00:06,456 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4769621590773265, 'Total loss': 0.4769621590773265} | train loss {'Reaction outcome loss': 0.2099344181681509, 'Total loss': 0.2099344181681509}
2023-01-05 04:00:06,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:06,456 INFO:     Epoch: 47
2023-01-05 04:00:08,680 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48991761207580564, 'Total loss': 0.48991761207580564} | train loss {'Reaction outcome loss': 0.2153163879986975, 'Total loss': 0.2153163879986975}
2023-01-05 04:00:08,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:08,680 INFO:     Epoch: 48
2023-01-05 04:00:10,858 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5157590687274933, 'Total loss': 0.5157590687274933} | train loss {'Reaction outcome loss': 0.21242761495949586, 'Total loss': 0.21242761495949586}
2023-01-05 04:00:10,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:10,859 INFO:     Epoch: 49
2023-01-05 04:00:13,080 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46023018211126326, 'Total loss': 0.46023018211126326} | train loss {'Reaction outcome loss': 0.20582220044273597, 'Total loss': 0.20582220044273597}
2023-01-05 04:00:13,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:13,080 INFO:     Epoch: 50
2023-01-05 04:00:15,261 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48902866343657175, 'Total loss': 0.48902866343657175} | train loss {'Reaction outcome loss': 0.2014563000750738, 'Total loss': 0.2014563000750738}
2023-01-05 04:00:15,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:15,262 INFO:     Epoch: 51
2023-01-05 04:00:17,438 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5071017111341158, 'Total loss': 0.5071017111341158} | train loss {'Reaction outcome loss': 0.20984535445305671, 'Total loss': 0.20984535445305671}
2023-01-05 04:00:17,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:17,439 INFO:     Epoch: 52
2023-01-05 04:00:19,609 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49506062467892964, 'Total loss': 0.49506062467892964} | train loss {'Reaction outcome loss': 0.21668331417333567, 'Total loss': 0.21668331417333567}
2023-01-05 04:00:19,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:19,609 INFO:     Epoch: 53
2023-01-05 04:00:21,761 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4725818485021591, 'Total loss': 0.4725818485021591} | train loss {'Reaction outcome loss': 0.20254817830173524, 'Total loss': 0.20254817830173524}
2023-01-05 04:00:21,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:21,761 INFO:     Epoch: 54
2023-01-05 04:00:23,970 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4816945473353068, 'Total loss': 0.4816945473353068} | train loss {'Reaction outcome loss': 0.19891477389186074, 'Total loss': 0.19891477389186074}
2023-01-05 04:00:23,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:23,971 INFO:     Epoch: 55
2023-01-05 04:00:26,129 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4919479618469874, 'Total loss': 0.4919479618469874} | train loss {'Reaction outcome loss': 0.19527313452309522, 'Total loss': 0.19527313452309522}
2023-01-05 04:00:26,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:26,129 INFO:     Epoch: 56
2023-01-05 04:00:28,329 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4737749735514323, 'Total loss': 0.4737749735514323} | train loss {'Reaction outcome loss': 0.19640140767267225, 'Total loss': 0.19640140767267225}
2023-01-05 04:00:28,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:28,330 INFO:     Epoch: 57
2023-01-05 04:00:30,494 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4758130612472693, 'Total loss': 0.4758130612472693} | train loss {'Reaction outcome loss': 0.19144336144003213, 'Total loss': 0.19144336144003213}
2023-01-05 04:00:30,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:30,495 INFO:     Epoch: 58
2023-01-05 04:00:32,675 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5132149616877238, 'Total loss': 0.5132149616877238} | train loss {'Reaction outcome loss': 0.19089543149421068, 'Total loss': 0.19089543149421068}
2023-01-05 04:00:32,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:32,676 INFO:     Epoch: 59
2023-01-05 04:00:34,876 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4494668483734131, 'Total loss': 0.4494668483734131} | train loss {'Reaction outcome loss': 0.18654391421568017, 'Total loss': 0.18654391421568017}
2023-01-05 04:00:34,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:34,877 INFO:     Epoch: 60
2023-01-05 04:00:37,042 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46987464527289075, 'Total loss': 0.46987464527289075} | train loss {'Reaction outcome loss': 0.1871811363832418, 'Total loss': 0.1871811363832418}
2023-01-05 04:00:37,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:37,042 INFO:     Epoch: 61
2023-01-05 04:00:39,216 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46169371604919435, 'Total loss': 0.46169371604919435} | train loss {'Reaction outcome loss': 0.18826551569605265, 'Total loss': 0.18826551569605265}
2023-01-05 04:00:39,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:39,216 INFO:     Epoch: 62
2023-01-05 04:00:41,457 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5094837161401907, 'Total loss': 0.5094837161401907} | train loss {'Reaction outcome loss': 0.18683809893471853, 'Total loss': 0.18683809893471853}
2023-01-05 04:00:41,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:41,458 INFO:     Epoch: 63
2023-01-05 04:00:43,650 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49892501533031464, 'Total loss': 0.49892501533031464} | train loss {'Reaction outcome loss': 0.18720275906491138, 'Total loss': 0.18720275906491138}
2023-01-05 04:00:43,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:43,650 INFO:     Epoch: 64
2023-01-05 04:00:45,861 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5013621330261231, 'Total loss': 0.5013621330261231} | train loss {'Reaction outcome loss': 0.1850222251122142, 'Total loss': 0.1850222251122142}
2023-01-05 04:00:45,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:45,861 INFO:     Epoch: 65
2023-01-05 04:00:48,058 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.515360701084137, 'Total loss': 0.515360701084137} | train loss {'Reaction outcome loss': 0.18866517864706697, 'Total loss': 0.18866517864706697}
2023-01-05 04:00:48,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:48,058 INFO:     Epoch: 66
2023-01-05 04:00:50,240 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4840653029580911, 'Total loss': 0.4840653029580911} | train loss {'Reaction outcome loss': 0.17917391254597312, 'Total loss': 0.17917391254597312}
2023-01-05 04:00:50,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:50,241 INFO:     Epoch: 67
2023-01-05 04:00:52,423 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4913967132568359, 'Total loss': 0.4913967132568359} | train loss {'Reaction outcome loss': 0.18018551092362883, 'Total loss': 0.18018551092362883}
2023-01-05 04:00:52,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:52,423 INFO:     Epoch: 68
2023-01-05 04:00:54,605 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5066544433434804, 'Total loss': 0.5066544433434804} | train loss {'Reaction outcome loss': 0.1828095138605152, 'Total loss': 0.1828095138605152}
2023-01-05 04:00:54,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:54,605 INFO:     Epoch: 69
2023-01-05 04:00:56,795 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5023564577102662, 'Total loss': 0.5023564577102662} | train loss {'Reaction outcome loss': 0.18257252971604193, 'Total loss': 0.18257252971604193}
2023-01-05 04:00:56,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:56,795 INFO:     Epoch: 70
2023-01-05 04:00:58,958 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5384896556536357, 'Total loss': 0.5384896556536357} | train loss {'Reaction outcome loss': 0.18421833223455172, 'Total loss': 0.18421833223455172}
2023-01-05 04:00:58,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:00:58,959 INFO:     Epoch: 71
2023-01-05 04:01:01,116 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49389055371284485, 'Total loss': 0.49389055371284485} | train loss {'Reaction outcome loss': 0.1778723776848789, 'Total loss': 0.1778723776848789}
2023-01-05 04:01:01,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:01,117 INFO:     Epoch: 72
2023-01-05 04:01:03,305 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5028072436650594, 'Total loss': 0.5028072436650594} | train loss {'Reaction outcome loss': 0.18112765407298892, 'Total loss': 0.18112765407298892}
2023-01-05 04:01:03,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:03,306 INFO:     Epoch: 73
2023-01-05 04:01:05,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.55416459441185, 'Total loss': 0.55416459441185} | train loss {'Reaction outcome loss': 0.18463559413069497, 'Total loss': 0.18463559413069497}
2023-01-05 04:01:05,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:05,494 INFO:     Epoch: 74
2023-01-05 04:01:07,680 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5032064552108447, 'Total loss': 0.5032064552108447} | train loss {'Reaction outcome loss': 0.17929380102212722, 'Total loss': 0.17929380102212722}
2023-01-05 04:01:07,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:07,680 INFO:     Epoch: 75
2023-01-05 04:01:09,863 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5483721236387888, 'Total loss': 0.5483721236387888} | train loss {'Reaction outcome loss': 0.17693703353828016, 'Total loss': 0.17693703353828016}
2023-01-05 04:01:09,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:09,863 INFO:     Epoch: 76
2023-01-05 04:01:12,044 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5016106237967809, 'Total loss': 0.5016106237967809} | train loss {'Reaction outcome loss': 0.17396175628186855, 'Total loss': 0.17396175628186855}
2023-01-05 04:01:12,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:12,045 INFO:     Epoch: 77
2023-01-05 04:01:14,231 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47820329666137695, 'Total loss': 0.47820329666137695} | train loss {'Reaction outcome loss': 0.17569166988188967, 'Total loss': 0.17569166988188967}
2023-01-05 04:01:14,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:14,231 INFO:     Epoch: 78
2023-01-05 04:01:16,416 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47395600775877633, 'Total loss': 0.47395600775877633} | train loss {'Reaction outcome loss': 0.17823226871003053, 'Total loss': 0.17823226871003053}
2023-01-05 04:01:16,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:16,416 INFO:     Epoch: 79
2023-01-05 04:01:18,598 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5045044700304667, 'Total loss': 0.5045044700304667} | train loss {'Reaction outcome loss': 0.17517464974427752, 'Total loss': 0.17517464974427752}
2023-01-05 04:01:18,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:18,599 INFO:     Epoch: 80
2023-01-05 04:01:20,770 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4730757157007853, 'Total loss': 0.4730757157007853} | train loss {'Reaction outcome loss': 0.16946132852603774, 'Total loss': 0.16946132852603774}
2023-01-05 04:01:20,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:20,770 INFO:     Epoch: 81
2023-01-05 04:01:22,966 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48998796542485556, 'Total loss': 0.48998796542485556} | train loss {'Reaction outcome loss': 0.17347300620988393, 'Total loss': 0.17347300620988393}
2023-01-05 04:01:22,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:22,966 INFO:     Epoch: 82
2023-01-05 04:01:25,154 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4885915021101634, 'Total loss': 0.4885915021101634} | train loss {'Reaction outcome loss': 0.1707129374610417, 'Total loss': 0.1707129374610417}
2023-01-05 04:01:25,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:25,154 INFO:     Epoch: 83
2023-01-05 04:01:27,343 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5397531668345134, 'Total loss': 0.5397531668345134} | train loss {'Reaction outcome loss': 0.17605495502858426, 'Total loss': 0.17605495502858426}
2023-01-05 04:01:27,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:27,344 INFO:     Epoch: 84
2023-01-05 04:01:29,520 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5136338988939921, 'Total loss': 0.5136338988939921} | train loss {'Reaction outcome loss': 0.1698203571123709, 'Total loss': 0.1698203571123709}
2023-01-05 04:01:29,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:29,520 INFO:     Epoch: 85
2023-01-05 04:01:31,697 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5094975541035335, 'Total loss': 0.5094975541035335} | train loss {'Reaction outcome loss': 0.16809995611617853, 'Total loss': 0.16809995611617853}
2023-01-05 04:01:31,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:31,698 INFO:     Epoch: 86
2023-01-05 04:01:33,802 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.528469646970431, 'Total loss': 0.528469646970431} | train loss {'Reaction outcome loss': 0.17068897052105148, 'Total loss': 0.17068897052105148}
2023-01-05 04:01:33,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:33,802 INFO:     Epoch: 87
2023-01-05 04:01:36,028 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5037854313850403, 'Total loss': 0.5037854313850403} | train loss {'Reaction outcome loss': 0.16502174511620085, 'Total loss': 0.16502174511620085}
2023-01-05 04:01:36,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:36,028 INFO:     Epoch: 88
2023-01-05 04:01:38,199 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4930094798405965, 'Total loss': 0.4930094798405965} | train loss {'Reaction outcome loss': 0.16793981266136354, 'Total loss': 0.16793981266136354}
2023-01-05 04:01:38,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:38,199 INFO:     Epoch: 89
2023-01-05 04:01:40,325 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5165726323922475, 'Total loss': 0.5165726323922475} | train loss {'Reaction outcome loss': 0.16742990864270227, 'Total loss': 0.16742990864270227}
2023-01-05 04:01:40,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:40,325 INFO:     Epoch: 90
2023-01-05 04:01:42,481 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4994105279445648, 'Total loss': 0.4994105279445648} | train loss {'Reaction outcome loss': 0.16968794761825995, 'Total loss': 0.16968794761825995}
2023-01-05 04:01:42,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:42,482 INFO:     Epoch: 91
2023-01-05 04:01:44,657 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5129321167866389, 'Total loss': 0.5129321167866389} | train loss {'Reaction outcome loss': 0.16945588880904264, 'Total loss': 0.16945588880904264}
2023-01-05 04:01:44,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:44,657 INFO:     Epoch: 92
2023-01-05 04:01:46,845 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.506151286760966, 'Total loss': 0.506151286760966} | train loss {'Reaction outcome loss': 0.16897015643200322, 'Total loss': 0.16897015643200322}
2023-01-05 04:01:46,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:46,845 INFO:     Epoch: 93
2023-01-05 04:01:49,018 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49480615854263305, 'Total loss': 0.49480615854263305} | train loss {'Reaction outcome loss': 0.16681470647931862, 'Total loss': 0.16681470647931862}
2023-01-05 04:01:49,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:49,019 INFO:     Epoch: 94
2023-01-05 04:01:51,210 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5162824461857478, 'Total loss': 0.5162824461857478} | train loss {'Reaction outcome loss': 0.16536913928490526, 'Total loss': 0.16536913928490526}
2023-01-05 04:01:51,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:51,210 INFO:     Epoch: 95
2023-01-05 04:01:53,428 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5270727356274922, 'Total loss': 0.5270727356274922} | train loss {'Reaction outcome loss': 0.16452318269950458, 'Total loss': 0.16452318269950458}
2023-01-05 04:01:53,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:53,428 INFO:     Epoch: 96
2023-01-05 04:01:55,634 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49903629620869955, 'Total loss': 0.49903629620869955} | train loss {'Reaction outcome loss': 0.16534363575307004, 'Total loss': 0.16534363575307004}
2023-01-05 04:01:55,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:55,634 INFO:     Epoch: 97
2023-01-05 04:01:57,844 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5342181026935577, 'Total loss': 0.5342181026935577} | train loss {'Reaction outcome loss': 0.16873426977954395, 'Total loss': 0.16873426977954395}
2023-01-05 04:01:57,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:01:57,845 INFO:     Epoch: 98
2023-01-05 04:02:00,075 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48528404558698335, 'Total loss': 0.48528404558698335} | train loss {'Reaction outcome loss': 0.1619383449539979, 'Total loss': 0.1619383449539979}
2023-01-05 04:02:00,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:00,075 INFO:     Epoch: 99
2023-01-05 04:02:02,246 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48353357911109923, 'Total loss': 0.48353357911109923} | train loss {'Reaction outcome loss': 0.16859382974843568, 'Total loss': 0.16859382974843568}
2023-01-05 04:02:02,246 INFO:     Best model found after epoch 9 of 100.
2023-01-05 04:02:02,247 INFO:   Done with stage: TRAINING
2023-01-05 04:02:02,247 INFO:   Starting stage: EVALUATION
2023-01-05 04:02:02,394 INFO:   Done with stage: EVALUATION
2023-01-05 04:02:02,395 INFO:   Leaving out SEQ value Fold_1
2023-01-05 04:02:02,407 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:02:02,407 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:02:03,069 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:02:03,069 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:02:03,142 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:02:03,142 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:02:03,142 INFO:     No hyperparam tuning for this model
2023-01-05 04:02:03,142 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:02:03,142 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:02:03,143 INFO:     None feature selector for col prot
2023-01-05 04:02:03,143 INFO:     None feature selector for col prot
2023-01-05 04:02:03,143 INFO:     None feature selector for col prot
2023-01-05 04:02:03,143 INFO:     None feature selector for col chem
2023-01-05 04:02:03,144 INFO:     None feature selector for col chem
2023-01-05 04:02:03,144 INFO:     None feature selector for col chem
2023-01-05 04:02:03,144 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:02:03,144 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:02:03,145 INFO:     Number of params in model 72931
2023-01-05 04:02:03,148 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:02:03,148 INFO:   Starting stage: TRAINING
2023-01-05 04:02:03,210 INFO:     Val loss before train {'Reaction outcome loss': 1.0435903867085774, 'Total loss': 1.0435903867085774}
2023-01-05 04:02:03,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:03,211 INFO:     Epoch: 0
2023-01-05 04:02:05,424 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8824829896291096, 'Total loss': 0.8824829896291096} | train loss {'Reaction outcome loss': 0.9495419342124808, 'Total loss': 0.9495419342124808}
2023-01-05 04:02:05,424 INFO:     Found new best model at epoch 0
2023-01-05 04:02:05,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:05,425 INFO:     Epoch: 1
2023-01-05 04:02:07,641 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5966724634170533, 'Total loss': 0.5966724634170533} | train loss {'Reaction outcome loss': 0.7007666733925757, 'Total loss': 0.7007666733925757}
2023-01-05 04:02:07,641 INFO:     Found new best model at epoch 1
2023-01-05 04:02:07,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:07,642 INFO:     Epoch: 2
2023-01-05 04:02:09,898 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5526153246561686, 'Total loss': 0.5526153246561686} | train loss {'Reaction outcome loss': 0.5475983573106941, 'Total loss': 0.5475983573106941}
2023-01-05 04:02:09,898 INFO:     Found new best model at epoch 2
2023-01-05 04:02:09,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:09,899 INFO:     Epoch: 3
2023-01-05 04:02:12,153 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5195119589567184, 'Total loss': 0.5195119589567184} | train loss {'Reaction outcome loss': 0.5054556395676311, 'Total loss': 0.5054556395676311}
2023-01-05 04:02:12,154 INFO:     Found new best model at epoch 3
2023-01-05 04:02:12,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:12,156 INFO:     Epoch: 4
2023-01-05 04:02:14,392 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5135407706101736, 'Total loss': 0.5135407706101736} | train loss {'Reaction outcome loss': 0.4822388384761154, 'Total loss': 0.4822388384761154}
2023-01-05 04:02:14,393 INFO:     Found new best model at epoch 4
2023-01-05 04:02:14,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:14,394 INFO:     Epoch: 5
2023-01-05 04:02:16,617 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5109919299681981, 'Total loss': 0.5109919299681981} | train loss {'Reaction outcome loss': 0.4327473626725133, 'Total loss': 0.4327473626725133}
2023-01-05 04:02:16,617 INFO:     Found new best model at epoch 5
2023-01-05 04:02:16,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:16,619 INFO:     Epoch: 6
2023-01-05 04:02:18,784 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49125524759292605, 'Total loss': 0.49125524759292605} | train loss {'Reaction outcome loss': 0.4076261842029466, 'Total loss': 0.4076261842029466}
2023-01-05 04:02:18,785 INFO:     Found new best model at epoch 6
2023-01-05 04:02:18,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:18,786 INFO:     Epoch: 7
2023-01-05 04:02:21,015 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4988412956396739, 'Total loss': 0.4988412956396739} | train loss {'Reaction outcome loss': 0.3873482244959988, 'Total loss': 0.3873482244959988}
2023-01-05 04:02:21,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:21,015 INFO:     Epoch: 8
2023-01-05 04:02:23,212 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48410283823808037, 'Total loss': 0.48410283823808037} | train loss {'Reaction outcome loss': 0.3800516304816457, 'Total loss': 0.3800516304816457}
2023-01-05 04:02:23,212 INFO:     Found new best model at epoch 8
2023-01-05 04:02:23,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:23,214 INFO:     Epoch: 9
2023-01-05 04:02:25,389 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5114100118478139, 'Total loss': 0.5114100118478139} | train loss {'Reaction outcome loss': 0.37188602223128936, 'Total loss': 0.37188602223128936}
2023-01-05 04:02:25,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:25,389 INFO:     Epoch: 10
2023-01-05 04:02:27,560 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5037659446398417, 'Total loss': 0.5037659446398417} | train loss {'Reaction outcome loss': 0.3582118082676839, 'Total loss': 0.3582118082676839}
2023-01-05 04:02:27,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:27,560 INFO:     Epoch: 11
2023-01-05 04:02:29,764 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4824914445479711, 'Total loss': 0.4824914445479711} | train loss {'Reaction outcome loss': 0.34953318565975927, 'Total loss': 0.34953318565975927}
2023-01-05 04:02:29,765 INFO:     Found new best model at epoch 11
2023-01-05 04:02:29,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:29,766 INFO:     Epoch: 12
2023-01-05 04:02:31,788 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49982501765092213, 'Total loss': 0.49982501765092213} | train loss {'Reaction outcome loss': 0.3403672099018982, 'Total loss': 0.3403672099018982}
2023-01-05 04:02:31,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:31,789 INFO:     Epoch: 13
2023-01-05 04:02:33,953 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4664005786180496, 'Total loss': 0.4664005786180496} | train loss {'Reaction outcome loss': 0.32680645190935204, 'Total loss': 0.32680645190935204}
2023-01-05 04:02:33,953 INFO:     Found new best model at epoch 13
2023-01-05 04:02:33,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:33,955 INFO:     Epoch: 14
2023-01-05 04:02:36,090 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48828962743282317, 'Total loss': 0.48828962743282317} | train loss {'Reaction outcome loss': 0.321174082359758, 'Total loss': 0.321174082359758}
2023-01-05 04:02:36,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:36,090 INFO:     Epoch: 15
2023-01-05 04:02:38,338 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46066422065099083, 'Total loss': 0.46066422065099083} | train loss {'Reaction outcome loss': 0.3093746516550301, 'Total loss': 0.3093746516550301}
2023-01-05 04:02:38,338 INFO:     Found new best model at epoch 15
2023-01-05 04:02:38,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:38,339 INFO:     Epoch: 16
2023-01-05 04:02:40,479 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4714259018500646, 'Total loss': 0.4714259018500646} | train loss {'Reaction outcome loss': 0.301965508211836, 'Total loss': 0.301965508211836}
2023-01-05 04:02:40,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:40,479 INFO:     Epoch: 17
2023-01-05 04:02:42,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47202144463857015, 'Total loss': 0.47202144463857015} | train loss {'Reaction outcome loss': 0.29898304832887085, 'Total loss': 0.29898304832887085}
2023-01-05 04:02:42,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:42,687 INFO:     Epoch: 18
2023-01-05 04:02:44,917 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4582778720806042, 'Total loss': 0.4582778720806042} | train loss {'Reaction outcome loss': 0.29289486886451827, 'Total loss': 0.29289486886451827}
2023-01-05 04:02:44,917 INFO:     Found new best model at epoch 18
2023-01-05 04:02:44,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:44,918 INFO:     Epoch: 19
2023-01-05 04:02:47,076 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45356166660785674, 'Total loss': 0.45356166660785674} | train loss {'Reaction outcome loss': 0.2818846508280199, 'Total loss': 0.2818846508280199}
2023-01-05 04:02:47,076 INFO:     Found new best model at epoch 19
2023-01-05 04:02:47,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:47,077 INFO:     Epoch: 20
2023-01-05 04:02:49,295 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47507844467957816, 'Total loss': 0.47507844467957816} | train loss {'Reaction outcome loss': 0.2724936556921381, 'Total loss': 0.2724936556921381}
2023-01-05 04:02:49,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:49,297 INFO:     Epoch: 21
2023-01-05 04:02:51,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45706430872281395, 'Total loss': 0.45706430872281395} | train loss {'Reaction outcome loss': 0.27514246936492703, 'Total loss': 0.27514246936492703}
2023-01-05 04:02:51,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:51,484 INFO:     Epoch: 22
2023-01-05 04:02:53,639 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44833607524633406, 'Total loss': 0.44833607524633406} | train loss {'Reaction outcome loss': 0.26655887632016634, 'Total loss': 0.26655887632016634}
2023-01-05 04:02:53,640 INFO:     Found new best model at epoch 22
2023-01-05 04:02:53,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:53,641 INFO:     Epoch: 23
2023-01-05 04:02:55,816 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46115745703379313, 'Total loss': 0.46115745703379313} | train loss {'Reaction outcome loss': 0.2630026193434352, 'Total loss': 0.2630026193434352}
2023-01-05 04:02:55,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:55,817 INFO:     Epoch: 24
2023-01-05 04:02:58,060 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4738943596680959, 'Total loss': 0.4738943596680959} | train loss {'Reaction outcome loss': 0.2667485267882222, 'Total loss': 0.2667485267882222}
2023-01-05 04:02:58,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:02:58,061 INFO:     Epoch: 25
2023-01-05 04:03:00,200 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48941184878349303, 'Total loss': 0.48941184878349303} | train loss {'Reaction outcome loss': 0.2629925484631541, 'Total loss': 0.2629925484631541}
2023-01-05 04:03:00,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:00,200 INFO:     Epoch: 26
2023-01-05 04:03:02,466 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4852358957131704, 'Total loss': 0.4852358957131704} | train loss {'Reaction outcome loss': 0.2505540818815791, 'Total loss': 0.2505540818815791}
2023-01-05 04:03:02,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:02,467 INFO:     Epoch: 27
2023-01-05 04:03:04,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4865366915861766, 'Total loss': 0.4865366915861766} | train loss {'Reaction outcome loss': 0.24348052609165924, 'Total loss': 0.24348052609165924}
2023-01-05 04:03:04,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:04,663 INFO:     Epoch: 28
2023-01-05 04:03:06,850 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4781156321366628, 'Total loss': 0.4781156321366628} | train loss {'Reaction outcome loss': 0.2405441493653031, 'Total loss': 0.2405441493653031}
2023-01-05 04:03:06,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:06,850 INFO:     Epoch: 29
2023-01-05 04:03:09,072 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48357213735580445, 'Total loss': 0.48357213735580445} | train loss {'Reaction outcome loss': 0.23704077944537436, 'Total loss': 0.23704077944537436}
2023-01-05 04:03:09,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:09,073 INFO:     Epoch: 30
2023-01-05 04:03:11,227 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48005618949731194, 'Total loss': 0.48005618949731194} | train loss {'Reaction outcome loss': 0.23196118480658354, 'Total loss': 0.23196118480658354}
2023-01-05 04:03:11,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:11,228 INFO:     Epoch: 31
2023-01-05 04:03:13,429 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48656915699442227, 'Total loss': 0.48656915699442227} | train loss {'Reaction outcome loss': 0.22618992398018078, 'Total loss': 0.22618992398018078}
2023-01-05 04:03:13,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:13,429 INFO:     Epoch: 32
2023-01-05 04:03:15,664 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47211579283078514, 'Total loss': 0.47211579283078514} | train loss {'Reaction outcome loss': 0.22603397695870692, 'Total loss': 0.22603397695870692}
2023-01-05 04:03:15,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:15,664 INFO:     Epoch: 33
2023-01-05 04:03:17,903 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48215607007344563, 'Total loss': 0.48215607007344563} | train loss {'Reaction outcome loss': 0.21988856199027065, 'Total loss': 0.21988856199027065}
2023-01-05 04:03:17,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:17,903 INFO:     Epoch: 34
2023-01-05 04:03:20,166 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4724628950158755, 'Total loss': 0.4724628950158755} | train loss {'Reaction outcome loss': 0.2178814854013963, 'Total loss': 0.2178814854013963}
2023-01-05 04:03:20,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:20,167 INFO:     Epoch: 35
2023-01-05 04:03:22,440 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47559645076592766, 'Total loss': 0.47559645076592766} | train loss {'Reaction outcome loss': 0.21732900311505637, 'Total loss': 0.21732900311505637}
2023-01-05 04:03:22,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:22,440 INFO:     Epoch: 36
2023-01-05 04:03:24,712 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4679361830155055, 'Total loss': 0.4679361830155055} | train loss {'Reaction outcome loss': 0.22184690062388562, 'Total loss': 0.22184690062388562}
2023-01-05 04:03:24,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:24,713 INFO:     Epoch: 37
2023-01-05 04:03:26,959 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4721423516670863, 'Total loss': 0.4721423516670863} | train loss {'Reaction outcome loss': 0.2292663101916728, 'Total loss': 0.2292663101916728}
2023-01-05 04:03:26,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:26,960 INFO:     Epoch: 38
2023-01-05 04:03:29,199 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5151218930880229, 'Total loss': 0.5151218930880229} | train loss {'Reaction outcome loss': 0.23029032631682744, 'Total loss': 0.23029032631682744}
2023-01-05 04:03:29,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:29,199 INFO:     Epoch: 39
2023-01-05 04:03:31,447 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4755638708670934, 'Total loss': 0.4755638708670934} | train loss {'Reaction outcome loss': 0.21258143902472829, 'Total loss': 0.21258143902472829}
2023-01-05 04:03:31,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:31,447 INFO:     Epoch: 40
2023-01-05 04:03:33,615 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48346753815809884, 'Total loss': 0.48346753815809884} | train loss {'Reaction outcome loss': 0.20871098511481145, 'Total loss': 0.20871098511481145}
2023-01-05 04:03:33,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:33,616 INFO:     Epoch: 41
2023-01-05 04:03:35,862 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.487211271127065, 'Total loss': 0.487211271127065} | train loss {'Reaction outcome loss': 0.20557913860724564, 'Total loss': 0.20557913860724564}
2023-01-05 04:03:35,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:35,862 INFO:     Epoch: 42
2023-01-05 04:03:38,055 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4792925705512365, 'Total loss': 0.4792925705512365} | train loss {'Reaction outcome loss': 0.19785428693369572, 'Total loss': 0.19785428693369572}
2023-01-05 04:03:38,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:38,055 INFO:     Epoch: 43
2023-01-05 04:03:40,298 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4712765405575434, 'Total loss': 0.4712765405575434} | train loss {'Reaction outcome loss': 0.19788024120835884, 'Total loss': 0.19788024120835884}
2023-01-05 04:03:40,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:40,299 INFO:     Epoch: 44
2023-01-05 04:03:42,426 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4861551026503245, 'Total loss': 0.4861551026503245} | train loss {'Reaction outcome loss': 0.21022463258207386, 'Total loss': 0.21022463258207386}
2023-01-05 04:03:42,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:42,427 INFO:     Epoch: 45
2023-01-05 04:03:44,663 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4734027018149694, 'Total loss': 0.4734027018149694} | train loss {'Reaction outcome loss': 0.23127997244802723, 'Total loss': 0.23127997244802723}
2023-01-05 04:03:44,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:44,663 INFO:     Epoch: 46
2023-01-05 04:03:46,876 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4981059124072393, 'Total loss': 0.4981059124072393} | train loss {'Reaction outcome loss': 0.20822171432276568, 'Total loss': 0.20822171432276568}
2023-01-05 04:03:46,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:46,876 INFO:     Epoch: 47
2023-01-05 04:03:49,102 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4768685797850291, 'Total loss': 0.4768685797850291} | train loss {'Reaction outcome loss': 0.1966409407340098, 'Total loss': 0.1966409407340098}
2023-01-05 04:03:49,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:49,103 INFO:     Epoch: 48
2023-01-05 04:03:51,337 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48449538548787435, 'Total loss': 0.48449538548787435} | train loss {'Reaction outcome loss': 0.1903802743991432, 'Total loss': 0.1903802743991432}
2023-01-05 04:03:51,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:51,338 INFO:     Epoch: 49
2023-01-05 04:03:53,550 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4727065458893776, 'Total loss': 0.4727065458893776} | train loss {'Reaction outcome loss': 0.1934170298526347, 'Total loss': 0.1934170298526347}
2023-01-05 04:03:53,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:53,550 INFO:     Epoch: 50
2023-01-05 04:03:55,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4670758843421936, 'Total loss': 0.4670758843421936} | train loss {'Reaction outcome loss': 0.1893221631501059, 'Total loss': 0.1893221631501059}
2023-01-05 04:03:55,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:55,774 INFO:     Epoch: 51
2023-01-05 04:03:57,996 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.473816113670667, 'Total loss': 0.473816113670667} | train loss {'Reaction outcome loss': 0.1867799181839117, 'Total loss': 0.1867799181839117}
2023-01-05 04:03:57,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:03:57,996 INFO:     Epoch: 52
2023-01-05 04:04:00,160 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4548541843891144, 'Total loss': 0.4548541843891144} | train loss {'Reaction outcome loss': 0.18414099337857898, 'Total loss': 0.18414099337857898}
2023-01-05 04:04:00,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:00,160 INFO:     Epoch: 53
2023-01-05 04:04:02,376 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4467878753940264, 'Total loss': 0.4467878753940264} | train loss {'Reaction outcome loss': 0.1903370774782978, 'Total loss': 0.1903370774782978}
2023-01-05 04:04:02,376 INFO:     Found new best model at epoch 53
2023-01-05 04:04:02,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:02,377 INFO:     Epoch: 54
2023-01-05 04:04:04,609 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4545917203028997, 'Total loss': 0.4545917203028997} | train loss {'Reaction outcome loss': 0.19303545295965244, 'Total loss': 0.19303545295965244}
2023-01-05 04:04:04,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:04,609 INFO:     Epoch: 55
2023-01-05 04:04:06,847 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48263095915317533, 'Total loss': 0.48263095915317533} | train loss {'Reaction outcome loss': 0.182401855489698, 'Total loss': 0.182401855489698}
2023-01-05 04:04:06,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:06,848 INFO:     Epoch: 56
2023-01-05 04:04:09,095 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4924021025498708, 'Total loss': 0.4924021025498708} | train loss {'Reaction outcome loss': 0.18519736514123075, 'Total loss': 0.18519736514123075}
2023-01-05 04:04:09,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:09,096 INFO:     Epoch: 57
2023-01-05 04:04:11,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4693297306696574, 'Total loss': 0.4693297306696574} | train loss {'Reaction outcome loss': 0.18115801598237274, 'Total loss': 0.18115801598237274}
2023-01-05 04:04:11,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:11,293 INFO:     Epoch: 58
2023-01-05 04:04:13,519 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4555604547262192, 'Total loss': 0.4555604547262192} | train loss {'Reaction outcome loss': 0.1837973955856717, 'Total loss': 0.1837973955856717}
2023-01-05 04:04:13,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:13,519 INFO:     Epoch: 59
2023-01-05 04:04:15,682 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4601620336373647, 'Total loss': 0.4601620336373647} | train loss {'Reaction outcome loss': 0.18027800900618668, 'Total loss': 0.18027800900618668}
2023-01-05 04:04:15,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:15,682 INFO:     Epoch: 60
2023-01-05 04:04:17,933 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4756566007932027, 'Total loss': 0.4756566007932027} | train loss {'Reaction outcome loss': 0.18231611427325042, 'Total loss': 0.18231611427325042}
2023-01-05 04:04:17,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:17,933 INFO:     Epoch: 61
2023-01-05 04:04:20,122 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4819038311640422, 'Total loss': 0.4819038311640422} | train loss {'Reaction outcome loss': 0.1822944635363937, 'Total loss': 0.1822944635363937}
2023-01-05 04:04:20,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:20,122 INFO:     Epoch: 62
2023-01-05 04:04:22,384 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4714232087135315, 'Total loss': 0.4714232087135315} | train loss {'Reaction outcome loss': 0.17918551436351676, 'Total loss': 0.17918551436351676}
2023-01-05 04:04:22,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:22,384 INFO:     Epoch: 63
2023-01-05 04:04:24,588 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4416451178180675, 'Total loss': 0.4416451178180675} | train loss {'Reaction outcome loss': 0.17689375189829792, 'Total loss': 0.17689375189829792}
2023-01-05 04:04:24,588 INFO:     Found new best model at epoch 63
2023-01-05 04:04:24,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:24,590 INFO:     Epoch: 64
2023-01-05 04:04:26,762 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4504944011569023, 'Total loss': 0.4504944011569023} | train loss {'Reaction outcome loss': 0.1738160899874039, 'Total loss': 0.1738160899874039}
2023-01-05 04:04:26,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:26,764 INFO:     Epoch: 65
2023-01-05 04:04:28,984 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46107186476389567, 'Total loss': 0.46107186476389567} | train loss {'Reaction outcome loss': 0.17542582773814397, 'Total loss': 0.17542582773814397}
2023-01-05 04:04:28,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:28,984 INFO:     Epoch: 66
2023-01-05 04:04:31,206 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49715655446052553, 'Total loss': 0.49715655446052553} | train loss {'Reaction outcome loss': 0.1738362636432335, 'Total loss': 0.1738362636432335}
2023-01-05 04:04:31,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:31,206 INFO:     Epoch: 67
2023-01-05 04:04:33,452 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48705292443434395, 'Total loss': 0.48705292443434395} | train loss {'Reaction outcome loss': 0.1782214394424691, 'Total loss': 0.1782214394424691}
2023-01-05 04:04:33,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:33,453 INFO:     Epoch: 68
2023-01-05 04:04:35,688 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4539655822018782, 'Total loss': 0.4539655822018782} | train loss {'Reaction outcome loss': 0.1738220025301047, 'Total loss': 0.1738220025301047}
2023-01-05 04:04:35,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:35,689 INFO:     Epoch: 69
2023-01-05 04:04:37,949 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45095892051855724, 'Total loss': 0.45095892051855724} | train loss {'Reaction outcome loss': 0.1961443297703332, 'Total loss': 0.1961443297703332}
2023-01-05 04:04:37,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:37,950 INFO:     Epoch: 70
2023-01-05 04:04:40,201 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45655882731080055, 'Total loss': 0.45655882731080055} | train loss {'Reaction outcome loss': 0.17208690699223644, 'Total loss': 0.17208690699223644}
2023-01-05 04:04:40,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:40,202 INFO:     Epoch: 71
2023-01-05 04:04:42,469 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4819199174642563, 'Total loss': 0.4819199174642563} | train loss {'Reaction outcome loss': 0.16722614214708353, 'Total loss': 0.16722614214708353}
2023-01-05 04:04:42,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:42,469 INFO:     Epoch: 72
2023-01-05 04:04:44,602 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5057303249835968, 'Total loss': 0.5057303249835968} | train loss {'Reaction outcome loss': 0.16880676307356107, 'Total loss': 0.16880676307356107}
2023-01-05 04:04:44,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:44,602 INFO:     Epoch: 73
2023-01-05 04:04:46,842 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4788684993982315, 'Total loss': 0.4788684993982315} | train loss {'Reaction outcome loss': 0.16909833949814682, 'Total loss': 0.16909833949814682}
2023-01-05 04:04:46,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:46,843 INFO:     Epoch: 74
2023-01-05 04:04:49,114 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4646596590677897, 'Total loss': 0.4646596590677897} | train loss {'Reaction outcome loss': 0.17037835988246472, 'Total loss': 0.17037835988246472}
2023-01-05 04:04:49,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:49,115 INFO:     Epoch: 75
2023-01-05 04:04:51,328 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4635764673352242, 'Total loss': 0.4635764673352242} | train loss {'Reaction outcome loss': 0.1755513338746665, 'Total loss': 0.1755513338746665}
2023-01-05 04:04:51,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:51,329 INFO:     Epoch: 76
2023-01-05 04:04:53,590 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45862988630930585, 'Total loss': 0.45862988630930585} | train loss {'Reaction outcome loss': 0.19633196914134937, 'Total loss': 0.19633196914134937}
2023-01-05 04:04:53,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:53,591 INFO:     Epoch: 77
2023-01-05 04:04:55,868 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44856457114219667, 'Total loss': 0.44856457114219667} | train loss {'Reaction outcome loss': 0.16738498442050448, 'Total loss': 0.16738498442050448}
2023-01-05 04:04:55,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:55,869 INFO:     Epoch: 78
2023-01-05 04:04:58,115 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48568272093931836, 'Total loss': 0.48568272093931836} | train loss {'Reaction outcome loss': 0.1680050834176549, 'Total loss': 0.1680050834176549}
2023-01-05 04:04:58,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:04:58,115 INFO:     Epoch: 79
2023-01-05 04:05:00,391 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47323196828365327, 'Total loss': 0.47323196828365327} | train loss {'Reaction outcome loss': 0.19001734445191687, 'Total loss': 0.19001734445191687}
2023-01-05 04:05:00,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:00,391 INFO:     Epoch: 80
2023-01-05 04:05:02,643 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46487810810407004, 'Total loss': 0.46487810810407004} | train loss {'Reaction outcome loss': 0.16364638116953056, 'Total loss': 0.16364638116953056}
2023-01-05 04:05:02,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:02,644 INFO:     Epoch: 81
2023-01-05 04:05:04,874 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47064782107869785, 'Total loss': 0.47064782107869785} | train loss {'Reaction outcome loss': 0.16212148921213287, 'Total loss': 0.16212148921213287}
2023-01-05 04:05:04,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:04,874 INFO:     Epoch: 82
2023-01-05 04:05:07,087 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4752177725235621, 'Total loss': 0.4752177725235621} | train loss {'Reaction outcome loss': 0.16175535164412408, 'Total loss': 0.16175535164412408}
2023-01-05 04:05:07,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:07,087 INFO:     Epoch: 83
2023-01-05 04:05:09,331 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4658709913492203, 'Total loss': 0.4658709913492203} | train loss {'Reaction outcome loss': 0.16273558712935587, 'Total loss': 0.16273558712935587}
2023-01-05 04:05:09,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:09,331 INFO:     Epoch: 84
2023-01-05 04:05:11,560 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47273532847563426, 'Total loss': 0.47273532847563426} | train loss {'Reaction outcome loss': 0.1639926177072216, 'Total loss': 0.1639926177072216}
2023-01-05 04:05:11,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:11,561 INFO:     Epoch: 85
2023-01-05 04:05:13,780 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4755470414956411, 'Total loss': 0.4755470414956411} | train loss {'Reaction outcome loss': 0.16271072377220122, 'Total loss': 0.16271072377220122}
2023-01-05 04:05:13,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:13,781 INFO:     Epoch: 86
2023-01-05 04:05:15,963 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44862488011519114, 'Total loss': 0.44862488011519114} | train loss {'Reaction outcome loss': 0.16028808137111744, 'Total loss': 0.16028808137111744}
2023-01-05 04:05:15,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:15,964 INFO:     Epoch: 87
2023-01-05 04:05:18,210 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45656206806500754, 'Total loss': 0.45656206806500754} | train loss {'Reaction outcome loss': 0.1606755306593318, 'Total loss': 0.1606755306593318}
2023-01-05 04:05:18,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:18,210 INFO:     Epoch: 88
2023-01-05 04:05:20,446 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48763336141904196, 'Total loss': 0.48763336141904196} | train loss {'Reaction outcome loss': 0.15751600295323812, 'Total loss': 0.15751600295323812}
2023-01-05 04:05:20,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:20,446 INFO:     Epoch: 89
2023-01-05 04:05:22,664 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4580436999599139, 'Total loss': 0.4580436999599139} | train loss {'Reaction outcome loss': 0.15750652461344766, 'Total loss': 0.15750652461344766}
2023-01-05 04:05:22,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:22,664 INFO:     Epoch: 90
2023-01-05 04:05:24,910 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45879883468151095, 'Total loss': 0.45879883468151095} | train loss {'Reaction outcome loss': 0.16046350790239175, 'Total loss': 0.16046350790239175}
2023-01-05 04:05:24,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:24,910 INFO:     Epoch: 91
2023-01-05 04:05:27,146 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46065481901168825, 'Total loss': 0.46065481901168825} | train loss {'Reaction outcome loss': 0.15616867615777216, 'Total loss': 0.15616867615777216}
2023-01-05 04:05:27,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:27,147 INFO:     Epoch: 92
2023-01-05 04:05:29,356 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4464778333902359, 'Total loss': 0.4464778333902359} | train loss {'Reaction outcome loss': 0.1581906456284333, 'Total loss': 0.1581906456284333}
2023-01-05 04:05:29,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:29,356 INFO:     Epoch: 93
2023-01-05 04:05:31,579 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.512227463722229, 'Total loss': 0.512227463722229} | train loss {'Reaction outcome loss': 0.1571399602727742, 'Total loss': 0.1571399602727742}
2023-01-05 04:05:31,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:31,580 INFO:     Epoch: 94
2023-01-05 04:05:33,784 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4759742975234985, 'Total loss': 0.4759742975234985} | train loss {'Reaction outcome loss': 0.16174005025359162, 'Total loss': 0.16174005025359162}
2023-01-05 04:05:33,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:33,785 INFO:     Epoch: 95
2023-01-05 04:05:35,999 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47642333110173546, 'Total loss': 0.47642333110173546} | train loss {'Reaction outcome loss': 0.15467808194380664, 'Total loss': 0.15467808194380664}
2023-01-05 04:05:35,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:35,999 INFO:     Epoch: 96
2023-01-05 04:05:38,236 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44539282023906707, 'Total loss': 0.44539282023906707} | train loss {'Reaction outcome loss': 0.15475090003641578, 'Total loss': 0.15475090003641578}
2023-01-05 04:05:38,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:38,237 INFO:     Epoch: 97
2023-01-05 04:05:40,463 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4452680841088295, 'Total loss': 0.4452680841088295} | train loss {'Reaction outcome loss': 0.18690906943368685, 'Total loss': 0.18690906943368685}
2023-01-05 04:05:40,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:40,464 INFO:     Epoch: 98
2023-01-05 04:05:42,694 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4815670490264893, 'Total loss': 0.4815670490264893} | train loss {'Reaction outcome loss': 0.1581321306080824, 'Total loss': 0.1581321306080824}
2023-01-05 04:05:42,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:42,695 INFO:     Epoch: 99
2023-01-05 04:05:44,872 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4454535542676846, 'Total loss': 0.4454535542676846} | train loss {'Reaction outcome loss': 0.15166136408684458, 'Total loss': 0.15166136408684458}
2023-01-05 04:05:44,872 INFO:     Best model found after epoch 64 of 100.
2023-01-05 04:05:44,872 INFO:   Done with stage: TRAINING
2023-01-05 04:05:44,873 INFO:   Starting stage: EVALUATION
2023-01-05 04:05:45,008 INFO:   Done with stage: EVALUATION
2023-01-05 04:05:45,008 INFO:   Leaving out SEQ value Fold_2
2023-01-05 04:05:45,020 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 04:05:45,021 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:05:45,677 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:05:45,677 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:05:45,749 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:05:45,749 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:05:45,749 INFO:     No hyperparam tuning for this model
2023-01-05 04:05:45,749 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:05:45,749 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:05:45,750 INFO:     None feature selector for col prot
2023-01-05 04:05:45,750 INFO:     None feature selector for col prot
2023-01-05 04:05:45,750 INFO:     None feature selector for col prot
2023-01-05 04:05:45,751 INFO:     None feature selector for col chem
2023-01-05 04:05:45,751 INFO:     None feature selector for col chem
2023-01-05 04:05:45,751 INFO:     None feature selector for col chem
2023-01-05 04:05:45,751 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:05:45,751 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:05:45,753 INFO:     Number of params in model 72931
2023-01-05 04:05:45,756 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:05:45,756 INFO:   Starting stage: TRAINING
2023-01-05 04:05:45,814 INFO:     Val loss before train {'Reaction outcome loss': 0.983103084564209, 'Total loss': 0.983103084564209}
2023-01-05 04:05:45,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:45,814 INFO:     Epoch: 0
2023-01-05 04:05:47,968 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7391207595666249, 'Total loss': 0.7391207595666249} | train loss {'Reaction outcome loss': 0.9254170252699336, 'Total loss': 0.9254170252699336}
2023-01-05 04:05:47,969 INFO:     Found new best model at epoch 0
2023-01-05 04:05:47,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:47,970 INFO:     Epoch: 1
2023-01-05 04:05:50,149 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5903736432393392, 'Total loss': 0.5903736432393392} | train loss {'Reaction outcome loss': 0.6465559464234573, 'Total loss': 0.6465559464234573}
2023-01-05 04:05:50,149 INFO:     Found new best model at epoch 1
2023-01-05 04:05:50,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:50,150 INFO:     Epoch: 2
2023-01-05 04:05:52,314 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5331202665964763, 'Total loss': 0.5331202665964763} | train loss {'Reaction outcome loss': 0.5391247581977111, 'Total loss': 0.5391247581977111}
2023-01-05 04:05:52,315 INFO:     Found new best model at epoch 2
2023-01-05 04:05:52,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:52,316 INFO:     Epoch: 3
2023-01-05 04:05:54,540 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5021114408969879, 'Total loss': 0.5021114408969879} | train loss {'Reaction outcome loss': 0.49703969552621735, 'Total loss': 0.49703969552621735}
2023-01-05 04:05:54,540 INFO:     Found new best model at epoch 3
2023-01-05 04:05:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:54,542 INFO:     Epoch: 4
2023-01-05 04:05:56,692 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46928333640098574, 'Total loss': 0.46928333640098574} | train loss {'Reaction outcome loss': 0.46225374331186103, 'Total loss': 0.46225374331186103}
2023-01-05 04:05:56,692 INFO:     Found new best model at epoch 4
2023-01-05 04:05:56,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:56,693 INFO:     Epoch: 5
2023-01-05 04:05:58,930 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46960649887720746, 'Total loss': 0.46960649887720746} | train loss {'Reaction outcome loss': 0.4381050543088616, 'Total loss': 0.4381050543088616}
2023-01-05 04:05:58,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:05:58,930 INFO:     Epoch: 6
2023-01-05 04:06:01,076 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48185230096181236, 'Total loss': 0.48185230096181236} | train loss {'Reaction outcome loss': 0.41578039068271555, 'Total loss': 0.41578039068271555}
2023-01-05 04:06:01,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:01,077 INFO:     Epoch: 7
2023-01-05 04:06:03,173 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45113399624824524, 'Total loss': 0.45113399624824524} | train loss {'Reaction outcome loss': 0.40244672114486657, 'Total loss': 0.40244672114486657}
2023-01-05 04:06:03,173 INFO:     Found new best model at epoch 7
2023-01-05 04:06:03,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:03,174 INFO:     Epoch: 8
2023-01-05 04:06:05,405 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44977531433105467, 'Total loss': 0.44977531433105467} | train loss {'Reaction outcome loss': 0.3898065413651995, 'Total loss': 0.3898065413651995}
2023-01-05 04:06:05,405 INFO:     Found new best model at epoch 8
2023-01-05 04:06:05,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:05,406 INFO:     Epoch: 9
2023-01-05 04:06:07,542 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41846677859624226, 'Total loss': 0.41846677859624226} | train loss {'Reaction outcome loss': 0.37804791429540613, 'Total loss': 0.37804791429540613}
2023-01-05 04:06:07,544 INFO:     Found new best model at epoch 9
2023-01-05 04:06:07,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:07,545 INFO:     Epoch: 10
2023-01-05 04:06:09,751 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43621320724487306, 'Total loss': 0.43621320724487306} | train loss {'Reaction outcome loss': 0.36922722124245577, 'Total loss': 0.36922722124245577}
2023-01-05 04:06:09,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:09,751 INFO:     Epoch: 11
2023-01-05 04:06:11,975 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4265914803991715, 'Total loss': 0.4265914803991715} | train loss {'Reaction outcome loss': 0.3604959385681065, 'Total loss': 0.3604959385681065}
2023-01-05 04:06:11,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:11,975 INFO:     Epoch: 12
2023-01-05 04:06:14,129 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4177451322476069, 'Total loss': 0.4177451322476069} | train loss {'Reaction outcome loss': 0.35048170166683723, 'Total loss': 0.35048170166683723}
2023-01-05 04:06:14,129 INFO:     Found new best model at epoch 12
2023-01-05 04:06:14,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:14,131 INFO:     Epoch: 13
2023-01-05 04:06:16,314 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4014696478843689, 'Total loss': 0.4014696478843689} | train loss {'Reaction outcome loss': 0.3429978428196994, 'Total loss': 0.3429978428196994}
2023-01-05 04:06:16,314 INFO:     Found new best model at epoch 13
2023-01-05 04:06:16,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:16,315 INFO:     Epoch: 14
2023-01-05 04:06:18,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44185958107312523, 'Total loss': 0.44185958107312523} | train loss {'Reaction outcome loss': 0.3393076899505797, 'Total loss': 0.3393076899505797}
2023-01-05 04:06:18,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:18,483 INFO:     Epoch: 15
2023-01-05 04:06:20,698 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44309669037659966, 'Total loss': 0.44309669037659966} | train loss {'Reaction outcome loss': 0.33310845076710316, 'Total loss': 0.33310845076710316}
2023-01-05 04:06:20,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:20,699 INFO:     Epoch: 16
2023-01-05 04:06:22,945 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44401221722364426, 'Total loss': 0.44401221722364426} | train loss {'Reaction outcome loss': 0.325100662507417, 'Total loss': 0.325100662507417}
2023-01-05 04:06:22,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:22,945 INFO:     Epoch: 17
2023-01-05 04:06:25,158 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4531468371550242, 'Total loss': 0.4531468371550242} | train loss {'Reaction outcome loss': 0.3169071347531163, 'Total loss': 0.3169071347531163}
2023-01-05 04:06:25,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:25,158 INFO:     Epoch: 18
2023-01-05 04:06:27,343 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4371016581853231, 'Total loss': 0.4371016581853231} | train loss {'Reaction outcome loss': 0.3107538469094824, 'Total loss': 0.3107538469094824}
2023-01-05 04:06:27,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:27,343 INFO:     Epoch: 19
2023-01-05 04:06:29,508 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48653782308101656, 'Total loss': 0.48653782308101656} | train loss {'Reaction outcome loss': 0.3098601922938675, 'Total loss': 0.3098601922938675}
2023-01-05 04:06:29,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:29,509 INFO:     Epoch: 20
2023-01-05 04:06:31,672 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4473442097504934, 'Total loss': 0.4473442097504934} | train loss {'Reaction outcome loss': 0.3026774179313209, 'Total loss': 0.3026774179313209}
2023-01-05 04:06:31,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:31,672 INFO:     Epoch: 21
2023-01-05 04:06:33,860 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42686514755090077, 'Total loss': 0.42686514755090077} | train loss {'Reaction outcome loss': 0.2992149832020531, 'Total loss': 0.2992149832020531}
2023-01-05 04:06:33,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:33,860 INFO:     Epoch: 22
2023-01-05 04:06:35,882 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4550497382879257, 'Total loss': 0.4550497382879257} | train loss {'Reaction outcome loss': 0.2885884634413562, 'Total loss': 0.2885884634413562}
2023-01-05 04:06:35,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:35,882 INFO:     Epoch: 23
2023-01-05 04:06:37,956 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4393855876599749, 'Total loss': 0.4393855876599749} | train loss {'Reaction outcome loss': 0.28274862132557144, 'Total loss': 0.28274862132557144}
2023-01-05 04:06:37,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:37,957 INFO:     Epoch: 24
2023-01-05 04:06:40,115 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45635737578074137, 'Total loss': 0.45635737578074137} | train loss {'Reaction outcome loss': 0.28298329186690596, 'Total loss': 0.28298329186690596}
2023-01-05 04:06:40,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:40,116 INFO:     Epoch: 25
2023-01-05 04:06:42,299 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4690316339333852, 'Total loss': 0.4690316339333852} | train loss {'Reaction outcome loss': 0.2787539617537142, 'Total loss': 0.2787539617537142}
2023-01-05 04:06:42,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:42,299 INFO:     Epoch: 26
2023-01-05 04:06:44,474 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4623173122604688, 'Total loss': 0.4623173122604688} | train loss {'Reaction outcome loss': 0.27391093297974095, 'Total loss': 0.27391093297974095}
2023-01-05 04:06:44,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:44,475 INFO:     Epoch: 27
2023-01-05 04:06:46,620 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4942639668782552, 'Total loss': 0.4942639668782552} | train loss {'Reaction outcome loss': 0.2674173301447442, 'Total loss': 0.2674173301447442}
2023-01-05 04:06:46,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:46,621 INFO:     Epoch: 28
2023-01-05 04:06:48,835 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4536910831928253, 'Total loss': 0.4536910831928253} | train loss {'Reaction outcome loss': 0.2666942235696447, 'Total loss': 0.2666942235696447}
2023-01-05 04:06:48,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:48,835 INFO:     Epoch: 29
2023-01-05 04:06:51,050 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45151018152634304, 'Total loss': 0.45151018152634304} | train loss {'Reaction outcome loss': 0.262081799851287, 'Total loss': 0.262081799851287}
2023-01-05 04:06:51,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:51,051 INFO:     Epoch: 30
2023-01-05 04:06:53,262 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46880726317564647, 'Total loss': 0.46880726317564647} | train loss {'Reaction outcome loss': 0.25406506125245504, 'Total loss': 0.25406506125245504}
2023-01-05 04:06:53,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:53,262 INFO:     Epoch: 31
2023-01-05 04:06:55,437 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4669559121131897, 'Total loss': 0.4669559121131897} | train loss {'Reaction outcome loss': 0.25367219691529813, 'Total loss': 0.25367219691529813}
2023-01-05 04:06:55,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:55,437 INFO:     Epoch: 32
2023-01-05 04:06:57,566 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.439178511997064, 'Total loss': 0.439178511997064} | train loss {'Reaction outcome loss': 0.2523315165724073, 'Total loss': 0.2523315165724073}
2023-01-05 04:06:57,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:57,566 INFO:     Epoch: 33
2023-01-05 04:06:59,730 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4338517208894094, 'Total loss': 0.4338517208894094} | train loss {'Reaction outcome loss': 0.24710846797395974, 'Total loss': 0.24710846797395974}
2023-01-05 04:06:59,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:06:59,731 INFO:     Epoch: 34
2023-01-05 04:07:01,894 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4573880563179652, 'Total loss': 0.4573880563179652} | train loss {'Reaction outcome loss': 0.24105136773989097, 'Total loss': 0.24105136773989097}
2023-01-05 04:07:01,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:01,894 INFO:     Epoch: 35
2023-01-05 04:07:04,052 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42956979299585024, 'Total loss': 0.42956979299585024} | train loss {'Reaction outcome loss': 0.23768167496546283, 'Total loss': 0.23768167496546283}
2023-01-05 04:07:04,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:04,052 INFO:     Epoch: 36
2023-01-05 04:07:06,260 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4490893751382828, 'Total loss': 0.4490893751382828} | train loss {'Reaction outcome loss': 0.2338494118968291, 'Total loss': 0.2338494118968291}
2023-01-05 04:07:06,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:06,260 INFO:     Epoch: 37
2023-01-05 04:07:08,480 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4532044343650341, 'Total loss': 0.4532044343650341} | train loss {'Reaction outcome loss': 0.23177598917604367, 'Total loss': 0.23177598917604367}
2023-01-05 04:07:08,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:08,480 INFO:     Epoch: 38
2023-01-05 04:07:10,702 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.467890735467275, 'Total loss': 0.467890735467275} | train loss {'Reaction outcome loss': 0.23092089187790513, 'Total loss': 0.23092089187790513}
2023-01-05 04:07:10,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:10,702 INFO:     Epoch: 39
2023-01-05 04:07:12,848 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4832791566848755, 'Total loss': 0.4832791566848755} | train loss {'Reaction outcome loss': 0.23063756425561377, 'Total loss': 0.23063756425561377}
2023-01-05 04:07:12,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:12,849 INFO:     Epoch: 40
2023-01-05 04:07:15,003 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48865428765614827, 'Total loss': 0.48865428765614827} | train loss {'Reaction outcome loss': 0.2267438764291587, 'Total loss': 0.2267438764291587}
2023-01-05 04:07:15,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:15,003 INFO:     Epoch: 41
2023-01-05 04:07:17,188 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48457380135854083, 'Total loss': 0.48457380135854083} | train loss {'Reaction outcome loss': 0.2261739716534213, 'Total loss': 0.2261739716534213}
2023-01-05 04:07:17,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:17,188 INFO:     Epoch: 42
2023-01-05 04:07:19,403 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4334757302577297, 'Total loss': 0.4334757302577297} | train loss {'Reaction outcome loss': 0.2210820151591885, 'Total loss': 0.2210820151591885}
2023-01-05 04:07:19,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:19,404 INFO:     Epoch: 43
2023-01-05 04:07:21,621 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4704199453194936, 'Total loss': 0.4704199453194936} | train loss {'Reaction outcome loss': 0.21371500104693048, 'Total loss': 0.21371500104693048}
2023-01-05 04:07:21,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:21,621 INFO:     Epoch: 44
2023-01-05 04:07:23,831 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45801406502723696, 'Total loss': 0.45801406502723696} | train loss {'Reaction outcome loss': 0.21928558057692626, 'Total loss': 0.21928558057692626}
2023-01-05 04:07:23,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:23,831 INFO:     Epoch: 45
2023-01-05 04:07:26,012 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4529645005861918, 'Total loss': 0.4529645005861918} | train loss {'Reaction outcome loss': 0.2142000010837511, 'Total loss': 0.2142000010837511}
2023-01-05 04:07:26,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:26,013 INFO:     Epoch: 46
2023-01-05 04:07:28,143 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4792302000025908, 'Total loss': 0.4792302000025908} | train loss {'Reaction outcome loss': 0.2144408858178231, 'Total loss': 0.2144408858178231}
2023-01-05 04:07:28,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:28,143 INFO:     Epoch: 47
2023-01-05 04:07:30,338 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4469000924378633, 'Total loss': 0.4469000924378633} | train loss {'Reaction outcome loss': 0.21120422119581764, 'Total loss': 0.21120422119581764}
2023-01-05 04:07:30,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:30,338 INFO:     Epoch: 48
2023-01-05 04:07:32,466 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47055547138055165, 'Total loss': 0.47055547138055165} | train loss {'Reaction outcome loss': 0.20625566331594636, 'Total loss': 0.20625566331594636}
2023-01-05 04:07:32,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:32,466 INFO:     Epoch: 49
2023-01-05 04:07:34,677 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43543935219446817, 'Total loss': 0.43543935219446817} | train loss {'Reaction outcome loss': 0.21710236854987702, 'Total loss': 0.21710236854987702}
2023-01-05 04:07:34,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:34,677 INFO:     Epoch: 50
2023-01-05 04:07:36,778 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44879221320152285, 'Total loss': 0.44879221320152285} | train loss {'Reaction outcome loss': 0.20130304208932778, 'Total loss': 0.20130304208932778}
2023-01-05 04:07:36,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:36,779 INFO:     Epoch: 51
2023-01-05 04:07:38,982 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5040387153625489, 'Total loss': 0.5040387153625489} | train loss {'Reaction outcome loss': 0.19884818341351035, 'Total loss': 0.19884818341351035}
2023-01-05 04:07:38,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:38,983 INFO:     Epoch: 52
2023-01-05 04:07:41,157 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48112137491504353, 'Total loss': 0.48112137491504353} | train loss {'Reaction outcome loss': 0.20222076809804737, 'Total loss': 0.20222076809804737}
2023-01-05 04:07:41,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:41,158 INFO:     Epoch: 53
2023-01-05 04:07:43,308 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4632144351800283, 'Total loss': 0.4632144351800283} | train loss {'Reaction outcome loss': 0.20433291512449364, 'Total loss': 0.20433291512449364}
2023-01-05 04:07:43,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:43,309 INFO:     Epoch: 54
2023-01-05 04:07:45,484 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46438121795654297, 'Total loss': 0.46438121795654297} | train loss {'Reaction outcome loss': 0.19986728481921084, 'Total loss': 0.19986728481921084}
2023-01-05 04:07:45,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:45,485 INFO:     Epoch: 55
2023-01-05 04:07:47,688 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.463310178120931, 'Total loss': 0.463310178120931} | train loss {'Reaction outcome loss': 0.19852043476788114, 'Total loss': 0.19852043476788114}
2023-01-05 04:07:47,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:47,688 INFO:     Epoch: 56
2023-01-05 04:07:49,895 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45953255097071327, 'Total loss': 0.45953255097071327} | train loss {'Reaction outcome loss': 0.19614816849177955, 'Total loss': 0.19614816849177955}
2023-01-05 04:07:49,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:49,895 INFO:     Epoch: 57
2023-01-05 04:07:52,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45176477829615275, 'Total loss': 0.45176477829615275} | train loss {'Reaction outcome loss': 0.1999362489215402, 'Total loss': 0.1999362489215402}
2023-01-05 04:07:52,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:52,087 INFO:     Epoch: 58
2023-01-05 04:07:54,304 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.491460320353508, 'Total loss': 0.491460320353508} | train loss {'Reaction outcome loss': 0.1898117280972869, 'Total loss': 0.1898117280972869}
2023-01-05 04:07:54,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:54,304 INFO:     Epoch: 59
2023-01-05 04:07:56,490 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49501736561457316, 'Total loss': 0.49501736561457316} | train loss {'Reaction outcome loss': 0.19290515868805158, 'Total loss': 0.19290515868805158}
2023-01-05 04:07:56,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:56,491 INFO:     Epoch: 60
2023-01-05 04:07:58,701 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5032617727915446, 'Total loss': 0.5032617727915446} | train loss {'Reaction outcome loss': 0.1935390892605751, 'Total loss': 0.1935390892605751}
2023-01-05 04:07:58,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:07:58,701 INFO:     Epoch: 61
2023-01-05 04:08:00,916 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49648606578509014, 'Total loss': 0.49648606578509014} | train loss {'Reaction outcome loss': 0.1929476634571977, 'Total loss': 0.1929476634571977}
2023-01-05 04:08:00,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:00,917 INFO:     Epoch: 62
2023-01-05 04:08:03,123 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4786687324444453, 'Total loss': 0.4786687324444453} | train loss {'Reaction outcome loss': 0.19493771303486038, 'Total loss': 0.19493771303486038}
2023-01-05 04:08:03,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:03,124 INFO:     Epoch: 63
2023-01-05 04:08:05,319 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4584755678971609, 'Total loss': 0.4584755678971609} | train loss {'Reaction outcome loss': 0.18905706497612018, 'Total loss': 0.18905706497612018}
2023-01-05 04:08:05,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:05,319 INFO:     Epoch: 64
2023-01-05 04:08:07,510 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46176828965544703, 'Total loss': 0.46176828965544703} | train loss {'Reaction outcome loss': 0.1891687550537643, 'Total loss': 0.1891687550537643}
2023-01-05 04:08:07,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:07,510 INFO:     Epoch: 65
2023-01-05 04:08:09,696 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4732843862225612, 'Total loss': 0.4732843862225612} | train loss {'Reaction outcome loss': 0.18358953893116434, 'Total loss': 0.18358953893116434}
2023-01-05 04:08:09,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:09,696 INFO:     Epoch: 66
2023-01-05 04:08:11,913 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46613113979498544, 'Total loss': 0.46613113979498544} | train loss {'Reaction outcome loss': 0.19016116876973882, 'Total loss': 0.19016116876973882}
2023-01-05 04:08:11,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:11,914 INFO:     Epoch: 67
2023-01-05 04:08:14,156 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48799786567687986, 'Total loss': 0.48799786567687986} | train loss {'Reaction outcome loss': 0.18832072576050793, 'Total loss': 0.18832072576050793}
2023-01-05 04:08:14,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:14,157 INFO:     Epoch: 68
2023-01-05 04:08:16,347 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46900368928909303, 'Total loss': 0.46900368928909303} | train loss {'Reaction outcome loss': 0.18710083410914838, 'Total loss': 0.18710083410914838}
2023-01-05 04:08:16,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:16,348 INFO:     Epoch: 69
2023-01-05 04:08:18,455 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.479137380917867, 'Total loss': 0.479137380917867} | train loss {'Reaction outcome loss': 0.1884854944429664, 'Total loss': 0.1884854944429664}
2023-01-05 04:08:18,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:18,456 INFO:     Epoch: 70
2023-01-05 04:08:20,683 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4552974859873454, 'Total loss': 0.4552974859873454} | train loss {'Reaction outcome loss': 0.19158786434284497, 'Total loss': 0.19158786434284497}
2023-01-05 04:08:20,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:20,683 INFO:     Epoch: 71
2023-01-05 04:08:22,847 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4794541875521342, 'Total loss': 0.4794541875521342} | train loss {'Reaction outcome loss': 0.18777035853924443, 'Total loss': 0.18777035853924443}
2023-01-05 04:08:22,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:22,847 INFO:     Epoch: 72
2023-01-05 04:08:25,067 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4624400664741794, 'Total loss': 0.4624400664741794} | train loss {'Reaction outcome loss': 0.18277789741044953, 'Total loss': 0.18277789741044953}
2023-01-05 04:08:25,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:25,068 INFO:     Epoch: 73
2023-01-05 04:08:27,242 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47194256335496904, 'Total loss': 0.47194256335496904} | train loss {'Reaction outcome loss': 0.1801240095653786, 'Total loss': 0.1801240095653786}
2023-01-05 04:08:27,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:27,243 INFO:     Epoch: 74
2023-01-05 04:08:29,471 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4541413267453512, 'Total loss': 0.4541413267453512} | train loss {'Reaction outcome loss': 0.18197603982569643, 'Total loss': 0.18197603982569643}
2023-01-05 04:08:29,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:29,472 INFO:     Epoch: 75
2023-01-05 04:08:31,711 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4633672279616197, 'Total loss': 0.4633672279616197} | train loss {'Reaction outcome loss': 0.18024715550086928, 'Total loss': 0.18024715550086928}
2023-01-05 04:08:31,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:31,711 INFO:     Epoch: 76
2023-01-05 04:08:33,857 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4741586128870646, 'Total loss': 0.4741586128870646} | train loss {'Reaction outcome loss': 0.1809635039878627, 'Total loss': 0.1809635039878627}
2023-01-05 04:08:33,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:33,858 INFO:     Epoch: 77
2023-01-05 04:08:35,694 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4652468672643105, 'Total loss': 0.4652468672643105} | train loss {'Reaction outcome loss': 0.17844715138603917, 'Total loss': 0.17844715138603917}
2023-01-05 04:08:35,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:35,694 INFO:     Epoch: 78
2023-01-05 04:08:37,486 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5096471826235454, 'Total loss': 0.5096471826235454} | train loss {'Reaction outcome loss': 0.18220051061430256, 'Total loss': 0.18220051061430256}
2023-01-05 04:08:37,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:37,487 INFO:     Epoch: 79
2023-01-05 04:08:39,658 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4823832551638285, 'Total loss': 0.4823832551638285} | train loss {'Reaction outcome loss': 0.1798434939658467, 'Total loss': 0.1798434939658467}
2023-01-05 04:08:39,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:39,658 INFO:     Epoch: 80
2023-01-05 04:08:41,890 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47164788146813713, 'Total loss': 0.47164788146813713} | train loss {'Reaction outcome loss': 0.1788278729057847, 'Total loss': 0.1788278729057847}
2023-01-05 04:08:41,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:41,891 INFO:     Epoch: 81
2023-01-05 04:08:44,115 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47566129366556803, 'Total loss': 0.47566129366556803} | train loss {'Reaction outcome loss': 0.1749585973057937, 'Total loss': 0.1749585973057937}
2023-01-05 04:08:44,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:44,116 INFO:     Epoch: 82
2023-01-05 04:08:46,238 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4527614106734594, 'Total loss': 0.4527614106734594} | train loss {'Reaction outcome loss': 0.16992192323517477, 'Total loss': 0.16992192323517477}
2023-01-05 04:08:46,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:46,239 INFO:     Epoch: 83
2023-01-05 04:08:48,401 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4986978014310201, 'Total loss': 0.4986978014310201} | train loss {'Reaction outcome loss': 0.17997982690022105, 'Total loss': 0.17997982690022105}
2023-01-05 04:08:48,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:48,401 INFO:     Epoch: 84
2023-01-05 04:08:50,521 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4571986883878708, 'Total loss': 0.4571986883878708} | train loss {'Reaction outcome loss': 0.17721780350998098, 'Total loss': 0.17721780350998098}
2023-01-05 04:08:50,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:50,521 INFO:     Epoch: 85
2023-01-05 04:08:52,720 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4507669488588969, 'Total loss': 0.4507669488588969} | train loss {'Reaction outcome loss': 0.17686863249038165, 'Total loss': 0.17686863249038165}
2023-01-05 04:08:52,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:52,721 INFO:     Epoch: 86
2023-01-05 04:08:54,903 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46899642546971637, 'Total loss': 0.46899642546971637} | train loss {'Reaction outcome loss': 0.17254047414403914, 'Total loss': 0.17254047414403914}
2023-01-05 04:08:54,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:54,904 INFO:     Epoch: 87
2023-01-05 04:08:57,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43805060895780723, 'Total loss': 0.43805060895780723} | train loss {'Reaction outcome loss': 0.16877793500561528, 'Total loss': 0.16877793500561528}
2023-01-05 04:08:57,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:57,071 INFO:     Epoch: 88
2023-01-05 04:08:59,312 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4645982178548972, 'Total loss': 0.4645982178548972} | train loss {'Reaction outcome loss': 0.1688151159681953, 'Total loss': 0.1688151159681953}
2023-01-05 04:08:59,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:08:59,312 INFO:     Epoch: 89
2023-01-05 04:09:01,458 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4669055938720703, 'Total loss': 0.4669055938720703} | train loss {'Reaction outcome loss': 0.1724694621878857, 'Total loss': 0.1724694621878857}
2023-01-05 04:09:01,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:01,458 INFO:     Epoch: 90
2023-01-05 04:09:03,614 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45678940614064534, 'Total loss': 0.45678940614064534} | train loss {'Reaction outcome loss': 0.1743977030844943, 'Total loss': 0.1743977030844943}
2023-01-05 04:09:03,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:03,615 INFO:     Epoch: 91
2023-01-05 04:09:05,841 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49378637472788495, 'Total loss': 0.49378637472788495} | train loss {'Reaction outcome loss': 0.17223338682661618, 'Total loss': 0.17223338682661618}
2023-01-05 04:09:05,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:05,841 INFO:     Epoch: 92
2023-01-05 04:09:07,997 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46669844885667167, 'Total loss': 0.46669844885667167} | train loss {'Reaction outcome loss': 0.1668545770059739, 'Total loss': 0.1668545770059739}
2023-01-05 04:09:07,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:07,997 INFO:     Epoch: 93
2023-01-05 04:09:10,186 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46935934176047645, 'Total loss': 0.46935934176047645} | train loss {'Reaction outcome loss': 0.16777412246933188, 'Total loss': 0.16777412246933188}
2023-01-05 04:09:10,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:10,187 INFO:     Epoch: 94
2023-01-05 04:09:12,347 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5411635021368663, 'Total loss': 0.5411635021368663} | train loss {'Reaction outcome loss': 0.17431981048688305, 'Total loss': 0.17431981048688305}
2023-01-05 04:09:12,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:12,347 INFO:     Epoch: 95
2023-01-05 04:09:14,545 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5123527685801188, 'Total loss': 0.5123527685801188} | train loss {'Reaction outcome loss': 0.1727635904228922, 'Total loss': 0.1727635904228922}
2023-01-05 04:09:14,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:14,545 INFO:     Epoch: 96
2023-01-05 04:09:16,713 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4614812960227331, 'Total loss': 0.4614812960227331} | train loss {'Reaction outcome loss': 0.16736168949608946, 'Total loss': 0.16736168949608946}
2023-01-05 04:09:16,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:16,714 INFO:     Epoch: 97
2023-01-05 04:09:18,900 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4938839601352811, 'Total loss': 0.4938839601352811} | train loss {'Reaction outcome loss': 0.1672612686842789, 'Total loss': 0.1672612686842789}
2023-01-05 04:09:18,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:18,900 INFO:     Epoch: 98
2023-01-05 04:09:21,071 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4754486342271169, 'Total loss': 0.4754486342271169} | train loss {'Reaction outcome loss': 0.1726307863618619, 'Total loss': 0.1726307863618619}
2023-01-05 04:09:21,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:21,072 INFO:     Epoch: 99
2023-01-05 04:09:23,292 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4562594329317411, 'Total loss': 0.4562594329317411} | train loss {'Reaction outcome loss': 0.16653124598236993, 'Total loss': 0.16653124598236993}
2023-01-05 04:09:23,292 INFO:     Best model found after epoch 14 of 100.
2023-01-05 04:09:23,293 INFO:   Done with stage: TRAINING
2023-01-05 04:09:23,293 INFO:   Starting stage: EVALUATION
2023-01-05 04:09:23,440 INFO:   Done with stage: EVALUATION
2023-01-05 04:09:23,440 INFO:   Leaving out SEQ value Fold_3
2023-01-05 04:09:23,452 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 04:09:23,452 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:09:24,089 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:09:24,089 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:09:24,161 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:09:24,161 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:09:24,161 INFO:     No hyperparam tuning for this model
2023-01-05 04:09:24,161 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:09:24,161 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:09:24,162 INFO:     None feature selector for col prot
2023-01-05 04:09:24,162 INFO:     None feature selector for col prot
2023-01-05 04:09:24,162 INFO:     None feature selector for col prot
2023-01-05 04:09:24,163 INFO:     None feature selector for col chem
2023-01-05 04:09:24,163 INFO:     None feature selector for col chem
2023-01-05 04:09:24,163 INFO:     None feature selector for col chem
2023-01-05 04:09:24,163 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:09:24,163 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:09:24,164 INFO:     Number of params in model 72931
2023-01-05 04:09:24,167 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:09:24,167 INFO:   Starting stage: TRAINING
2023-01-05 04:09:24,227 INFO:     Val loss before train {'Reaction outcome loss': 1.0203010320663453, 'Total loss': 1.0203010320663453}
2023-01-05 04:09:24,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:24,227 INFO:     Epoch: 0
2023-01-05 04:09:26,365 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7674255609512329, 'Total loss': 0.7674255609512329} | train loss {'Reaction outcome loss': 0.9601029809770549, 'Total loss': 0.9601029809770549}
2023-01-05 04:09:26,365 INFO:     Found new best model at epoch 0
2023-01-05 04:09:26,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:26,367 INFO:     Epoch: 1
2023-01-05 04:09:28,521 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5079174518585206, 'Total loss': 0.5079174518585206} | train loss {'Reaction outcome loss': 0.6434317853617932, 'Total loss': 0.6434317853617932}
2023-01-05 04:09:28,521 INFO:     Found new best model at epoch 1
2023-01-05 04:09:28,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:28,523 INFO:     Epoch: 2
2023-01-05 04:09:30,740 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4839271227518717, 'Total loss': 0.4839271227518717} | train loss {'Reaction outcome loss': 0.5224907563731239, 'Total loss': 0.5224907563731239}
2023-01-05 04:09:30,740 INFO:     Found new best model at epoch 2
2023-01-05 04:09:30,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:30,741 INFO:     Epoch: 3
2023-01-05 04:09:32,951 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4604288637638092, 'Total loss': 0.4604288637638092} | train loss {'Reaction outcome loss': 0.4733979831212561, 'Total loss': 0.4733979831212561}
2023-01-05 04:09:32,952 INFO:     Found new best model at epoch 3
2023-01-05 04:09:32,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:32,953 INFO:     Epoch: 4
2023-01-05 04:09:35,150 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42975990573565165, 'Total loss': 0.42975990573565165} | train loss {'Reaction outcome loss': 0.4541140743067344, 'Total loss': 0.4541140743067344}
2023-01-05 04:09:35,150 INFO:     Found new best model at epoch 4
2023-01-05 04:09:35,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:35,152 INFO:     Epoch: 5
2023-01-05 04:09:37,356 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42553379833698274, 'Total loss': 0.42553379833698274} | train loss {'Reaction outcome loss': 0.4290234679665513, 'Total loss': 0.4290234679665513}
2023-01-05 04:09:37,356 INFO:     Found new best model at epoch 5
2023-01-05 04:09:37,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:37,357 INFO:     Epoch: 6
2023-01-05 04:09:39,545 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44129234552383423, 'Total loss': 0.44129234552383423} | train loss {'Reaction outcome loss': 0.4163251831247798, 'Total loss': 0.4163251831247798}
2023-01-05 04:09:39,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:39,546 INFO:     Epoch: 7
2023-01-05 04:09:41,675 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43914740085601806, 'Total loss': 0.43914740085601806} | train loss {'Reaction outcome loss': 0.4018623194901266, 'Total loss': 0.4018623194901266}
2023-01-05 04:09:41,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:41,675 INFO:     Epoch: 8
2023-01-05 04:09:43,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42635989288489023, 'Total loss': 0.42635989288489023} | train loss {'Reaction outcome loss': 0.39021997907064937, 'Total loss': 0.39021997907064937}
2023-01-05 04:09:43,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:43,872 INFO:     Epoch: 9
2023-01-05 04:09:46,061 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45710322658220925, 'Total loss': 0.45710322658220925} | train loss {'Reaction outcome loss': 0.3863651149552247, 'Total loss': 0.3863651149552247}
2023-01-05 04:09:46,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:46,061 INFO:     Epoch: 10
2023-01-05 04:09:48,217 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4391266773144404, 'Total loss': 0.4391266773144404} | train loss {'Reaction outcome loss': 0.37682351843897266, 'Total loss': 0.37682351843897266}
2023-01-05 04:09:48,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:48,217 INFO:     Epoch: 11
2023-01-05 04:09:50,375 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39369613379240037, 'Total loss': 0.39369613379240037} | train loss {'Reaction outcome loss': 0.36766360276739535, 'Total loss': 0.36766360276739535}
2023-01-05 04:09:50,375 INFO:     Found new best model at epoch 11
2023-01-05 04:09:50,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:50,377 INFO:     Epoch: 12
2023-01-05 04:09:52,493 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41206209858258563, 'Total loss': 0.41206209858258563} | train loss {'Reaction outcome loss': 0.36269838167732493, 'Total loss': 0.36269838167732493}
2023-01-05 04:09:52,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:52,494 INFO:     Epoch: 13
2023-01-05 04:09:54,701 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4034672329823176, 'Total loss': 0.4034672329823176} | train loss {'Reaction outcome loss': 0.3527349089633165, 'Total loss': 0.3527349089633165}
2023-01-05 04:09:54,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:54,701 INFO:     Epoch: 14
2023-01-05 04:09:56,870 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38801443378130596, 'Total loss': 0.38801443378130596} | train loss {'Reaction outcome loss': 0.34522846921233674, 'Total loss': 0.34522846921233674}
2023-01-05 04:09:56,870 INFO:     Found new best model at epoch 14
2023-01-05 04:09:56,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:56,871 INFO:     Epoch: 15
2023-01-05 04:09:59,058 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3996575885141889, 'Total loss': 0.3996575885141889} | train loss {'Reaction outcome loss': 0.3397008462695618, 'Total loss': 0.3397008462695618}
2023-01-05 04:09:59,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:09:59,058 INFO:     Epoch: 16
2023-01-05 04:10:01,265 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4024526799718539, 'Total loss': 0.4024526799718539} | train loss {'Reaction outcome loss': 0.332630257778612, 'Total loss': 0.332630257778612}
2023-01-05 04:10:01,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:01,265 INFO:     Epoch: 17
2023-01-05 04:10:03,475 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4339599182208379, 'Total loss': 0.4339599182208379} | train loss {'Reaction outcome loss': 0.32687874989261045, 'Total loss': 0.32687874989261045}
2023-01-05 04:10:03,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:03,476 INFO:     Epoch: 18
2023-01-05 04:10:05,658 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4147407442331314, 'Total loss': 0.4147407442331314} | train loss {'Reaction outcome loss': 0.316543492141465, 'Total loss': 0.316543492141465}
2023-01-05 04:10:05,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:05,658 INFO:     Epoch: 19
2023-01-05 04:10:07,874 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3590942839781443, 'Total loss': 0.3590942839781443} | train loss {'Reaction outcome loss': 0.3126435457175508, 'Total loss': 0.3126435457175508}
2023-01-05 04:10:07,874 INFO:     Found new best model at epoch 19
2023-01-05 04:10:07,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:07,876 INFO:     Epoch: 20
2023-01-05 04:10:10,087 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37838399509588877, 'Total loss': 0.37838399509588877} | train loss {'Reaction outcome loss': 0.305151272523887, 'Total loss': 0.305151272523887}
2023-01-05 04:10:10,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:10,088 INFO:     Epoch: 21
2023-01-05 04:10:12,299 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35985075930754346, 'Total loss': 0.35985075930754346} | train loss {'Reaction outcome loss': 0.29974818254418917, 'Total loss': 0.29974818254418917}
2023-01-05 04:10:12,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:12,300 INFO:     Epoch: 22
2023-01-05 04:10:14,522 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38980467319488527, 'Total loss': 0.38980467319488527} | train loss {'Reaction outcome loss': 0.2891379930010251, 'Total loss': 0.2891379930010251}
2023-01-05 04:10:14,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:14,522 INFO:     Epoch: 23
2023-01-05 04:10:16,733 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40890540182590485, 'Total loss': 0.40890540182590485} | train loss {'Reaction outcome loss': 0.28721164117440084, 'Total loss': 0.28721164117440084}
2023-01-05 04:10:16,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:16,734 INFO:     Epoch: 24
2023-01-05 04:10:18,953 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36760267019271853, 'Total loss': 0.36760267019271853} | train loss {'Reaction outcome loss': 0.28297577904214277, 'Total loss': 0.28297577904214277}
2023-01-05 04:10:18,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:18,953 INFO:     Epoch: 25
2023-01-05 04:10:21,129 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38271517157554624, 'Total loss': 0.38271517157554624} | train loss {'Reaction outcome loss': 0.2768436561431392, 'Total loss': 0.2768436561431392}
2023-01-05 04:10:21,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:21,130 INFO:     Epoch: 26
2023-01-05 04:10:23,306 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36884118219216666, 'Total loss': 0.36884118219216666} | train loss {'Reaction outcome loss': 0.2737060689893156, 'Total loss': 0.2737060689893156}
2023-01-05 04:10:23,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:23,306 INFO:     Epoch: 27
2023-01-05 04:10:25,475 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41718076169490814, 'Total loss': 0.41718076169490814} | train loss {'Reaction outcome loss': 0.2625909590220759, 'Total loss': 0.2625909590220759}
2023-01-05 04:10:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:25,475 INFO:     Epoch: 28
2023-01-05 04:10:27,658 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35579321601738534, 'Total loss': 0.35579321601738534} | train loss {'Reaction outcome loss': 0.2582677688683311, 'Total loss': 0.2582677688683311}
2023-01-05 04:10:27,658 INFO:     Found new best model at epoch 28
2023-01-05 04:10:27,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:27,660 INFO:     Epoch: 29
2023-01-05 04:10:29,879 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3626240278283755, 'Total loss': 0.3626240278283755} | train loss {'Reaction outcome loss': 0.2531372403100518, 'Total loss': 0.2531372403100518}
2023-01-05 04:10:29,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:29,880 INFO:     Epoch: 30
2023-01-05 04:10:32,091 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3746491104364395, 'Total loss': 0.3746491104364395} | train loss {'Reaction outcome loss': 0.2518742169593753, 'Total loss': 0.2518742169593753}
2023-01-05 04:10:32,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:32,092 INFO:     Epoch: 31
2023-01-05 04:10:34,291 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36123159031073254, 'Total loss': 0.36123159031073254} | train loss {'Reaction outcome loss': 0.24874869978735809, 'Total loss': 0.24874869978735809}
2023-01-05 04:10:34,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:34,291 INFO:     Epoch: 32
2023-01-05 04:10:36,487 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40921128491560615, 'Total loss': 0.40921128491560615} | train loss {'Reaction outcome loss': 0.2475447927969353, 'Total loss': 0.2475447927969353}
2023-01-05 04:10:36,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:36,487 INFO:     Epoch: 33
2023-01-05 04:10:38,703 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38923298915227256, 'Total loss': 0.38923298915227256} | train loss {'Reaction outcome loss': 0.2406212960084646, 'Total loss': 0.2406212960084646}
2023-01-05 04:10:38,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:38,705 INFO:     Epoch: 34
2023-01-05 04:10:40,728 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35701397409041724, 'Total loss': 0.35701397409041724} | train loss {'Reaction outcome loss': 0.236386717767953, 'Total loss': 0.236386717767953}
2023-01-05 04:10:40,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:40,729 INFO:     Epoch: 35
2023-01-05 04:10:42,857 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3721858968337377, 'Total loss': 0.3721858968337377} | train loss {'Reaction outcome loss': 0.23574070312165246, 'Total loss': 0.23574070312165246}
2023-01-05 04:10:42,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:42,857 INFO:     Epoch: 36
2023-01-05 04:10:45,053 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3464828411427637, 'Total loss': 0.3464828411427637} | train loss {'Reaction outcome loss': 0.23555022418650204, 'Total loss': 0.23555022418650204}
2023-01-05 04:10:45,054 INFO:     Found new best model at epoch 36
2023-01-05 04:10:45,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:45,055 INFO:     Epoch: 37
2023-01-05 04:10:47,258 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36037453413009646, 'Total loss': 0.36037453413009646} | train loss {'Reaction outcome loss': 0.2258201216199741, 'Total loss': 0.2258201216199741}
2023-01-05 04:10:47,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:47,259 INFO:     Epoch: 38
2023-01-05 04:10:49,465 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3569340962916613, 'Total loss': 0.3569340962916613} | train loss {'Reaction outcome loss': 0.22565457552698925, 'Total loss': 0.22565457552698925}
2023-01-05 04:10:49,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:49,466 INFO:     Epoch: 39
2023-01-05 04:10:51,678 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3449613809585571, 'Total loss': 0.3449613809585571} | train loss {'Reaction outcome loss': 0.21935185545374986, 'Total loss': 0.21935185545374986}
2023-01-05 04:10:51,678 INFO:     Found new best model at epoch 39
2023-01-05 04:10:51,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:51,679 INFO:     Epoch: 40
2023-01-05 04:10:53,888 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.360067651172479, 'Total loss': 0.360067651172479} | train loss {'Reaction outcome loss': 0.22295297580561516, 'Total loss': 0.22295297580561516}
2023-01-05 04:10:53,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:53,888 INFO:     Epoch: 41
2023-01-05 04:10:56,085 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3849507927894592, 'Total loss': 0.3849507927894592} | train loss {'Reaction outcome loss': 0.21750442454130886, 'Total loss': 0.21750442454130886}
2023-01-05 04:10:56,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:56,085 INFO:     Epoch: 42
2023-01-05 04:10:58,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3501725301146507, 'Total loss': 0.3501725301146507} | train loss {'Reaction outcome loss': 0.2182848350973147, 'Total loss': 0.2182848350973147}
2023-01-05 04:10:58,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:10:58,270 INFO:     Epoch: 43
2023-01-05 04:11:00,447 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4078065752983093, 'Total loss': 0.4078065752983093} | train loss {'Reaction outcome loss': 0.2170689854705603, 'Total loss': 0.2170689854705603}
2023-01-05 04:11:00,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:00,447 INFO:     Epoch: 44
2023-01-05 04:11:02,636 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4200701614220937, 'Total loss': 0.4200701614220937} | train loss {'Reaction outcome loss': 0.2067629199447557, 'Total loss': 0.2067629199447557}
2023-01-05 04:11:02,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:02,637 INFO:     Epoch: 45
2023-01-05 04:11:04,860 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3808503667513529, 'Total loss': 0.3808503667513529} | train loss {'Reaction outcome loss': 0.209391270087159, 'Total loss': 0.209391270087159}
2023-01-05 04:11:04,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:04,860 INFO:     Epoch: 46
2023-01-05 04:11:07,045 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36798178652922314, 'Total loss': 0.36798178652922314} | train loss {'Reaction outcome loss': 0.20838247799156473, 'Total loss': 0.20838247799156473}
2023-01-05 04:11:07,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:07,045 INFO:     Epoch: 47
2023-01-05 04:11:09,218 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3808958972493807, 'Total loss': 0.3808958972493807} | train loss {'Reaction outcome loss': 0.2022716107733575, 'Total loss': 0.2022716107733575}
2023-01-05 04:11:09,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:09,219 INFO:     Epoch: 48
2023-01-05 04:11:11,386 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3799393037954966, 'Total loss': 0.3799393037954966} | train loss {'Reaction outcome loss': 0.20074766787023343, 'Total loss': 0.20074766787023343}
2023-01-05 04:11:11,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:11,386 INFO:     Epoch: 49
2023-01-05 04:11:13,567 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4101645678281784, 'Total loss': 0.4101645678281784} | train loss {'Reaction outcome loss': 0.20227741195246357, 'Total loss': 0.20227741195246357}
2023-01-05 04:11:13,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:13,567 INFO:     Epoch: 50
2023-01-05 04:11:15,738 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3818948689227303, 'Total loss': 0.3818948689227303} | train loss {'Reaction outcome loss': 0.19725862217936457, 'Total loss': 0.19725862217936457}
2023-01-05 04:11:15,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:15,739 INFO:     Epoch: 51
2023-01-05 04:11:17,911 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38924335936705273, 'Total loss': 0.38924335936705273} | train loss {'Reaction outcome loss': 0.19639867070952355, 'Total loss': 0.19639867070952355}
2023-01-05 04:11:17,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:17,911 INFO:     Epoch: 52
2023-01-05 04:11:20,061 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4018299752225479, 'Total loss': 0.4018299752225479} | train loss {'Reaction outcome loss': 0.19458025341296767, 'Total loss': 0.19458025341296767}
2023-01-05 04:11:20,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:20,061 INFO:     Epoch: 53
2023-01-05 04:11:22,242 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3586529612541199, 'Total loss': 0.3586529612541199} | train loss {'Reaction outcome loss': 0.19241794301678058, 'Total loss': 0.19241794301678058}
2023-01-05 04:11:22,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:22,243 INFO:     Epoch: 54
2023-01-05 04:11:24,433 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.410921123623848, 'Total loss': 0.410921123623848} | train loss {'Reaction outcome loss': 0.19527893016850267, 'Total loss': 0.19527893016850267}
2023-01-05 04:11:24,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:24,433 INFO:     Epoch: 55
2023-01-05 04:11:26,624 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36222425022472937, 'Total loss': 0.36222425022472937} | train loss {'Reaction outcome loss': 0.19202946142956778, 'Total loss': 0.19202946142956778}
2023-01-05 04:11:26,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:26,624 INFO:     Epoch: 56
2023-01-05 04:11:28,813 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38762378493944805, 'Total loss': 0.38762378493944805} | train loss {'Reaction outcome loss': 0.18801575605980914, 'Total loss': 0.18801575605980914}
2023-01-05 04:11:28,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:28,814 INFO:     Epoch: 57
2023-01-05 04:11:30,989 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38122209211190544, 'Total loss': 0.38122209211190544} | train loss {'Reaction outcome loss': 0.18897878331548063, 'Total loss': 0.18897878331548063}
2023-01-05 04:11:30,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:30,989 INFO:     Epoch: 58
2023-01-05 04:11:33,148 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3675970812638601, 'Total loss': 0.3675970812638601} | train loss {'Reaction outcome loss': 0.18395299627359724, 'Total loss': 0.18395299627359724}
2023-01-05 04:11:33,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:33,148 INFO:     Epoch: 59
2023-01-05 04:11:35,320 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38611083015178643, 'Total loss': 0.38611083015178643} | train loss {'Reaction outcome loss': 0.18417628082821344, 'Total loss': 0.18417628082821344}
2023-01-05 04:11:35,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:35,321 INFO:     Epoch: 60
2023-01-05 04:11:37,530 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38126205491522946, 'Total loss': 0.38126205491522946} | train loss {'Reaction outcome loss': 0.18488106847572316, 'Total loss': 0.18488106847572316}
2023-01-05 04:11:37,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:37,531 INFO:     Epoch: 61
2023-01-05 04:11:39,738 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39328116973241173, 'Total loss': 0.39328116973241173} | train loss {'Reaction outcome loss': 0.18349873666338815, 'Total loss': 0.18349873666338815}
2023-01-05 04:11:39,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:39,739 INFO:     Epoch: 62
2023-01-05 04:11:41,935 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3681581672281027, 'Total loss': 0.3681581672281027} | train loss {'Reaction outcome loss': 0.1861029904390723, 'Total loss': 0.1861029904390723}
2023-01-05 04:11:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:41,935 INFO:     Epoch: 63
2023-01-05 04:11:44,168 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39375568069517614, 'Total loss': 0.39375568069517614} | train loss {'Reaction outcome loss': 0.18082823400897732, 'Total loss': 0.18082823400897732}
2023-01-05 04:11:44,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:44,168 INFO:     Epoch: 64
2023-01-05 04:11:46,393 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.389063253502051, 'Total loss': 0.389063253502051} | train loss {'Reaction outcome loss': 0.18321004376241531, 'Total loss': 0.18321004376241531}
2023-01-05 04:11:46,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:46,393 INFO:     Epoch: 65
2023-01-05 04:11:48,652 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38558995152513187, 'Total loss': 0.38558995152513187} | train loss {'Reaction outcome loss': 0.17987813330444463, 'Total loss': 0.17987813330444463}
2023-01-05 04:11:48,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:48,652 INFO:     Epoch: 66
2023-01-05 04:11:50,859 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3800928797572851, 'Total loss': 0.3800928797572851} | train loss {'Reaction outcome loss': 0.1794988846705326, 'Total loss': 0.1794988846705326}
2023-01-05 04:11:50,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:50,861 INFO:     Epoch: 67
2023-01-05 04:11:53,070 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3607670895755291, 'Total loss': 0.3607670895755291} | train loss {'Reaction outcome loss': 0.17495693264329784, 'Total loss': 0.17495693264329784}
2023-01-05 04:11:53,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:53,070 INFO:     Epoch: 68
2023-01-05 04:11:55,240 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3557901905073474, 'Total loss': 0.3557901905073474} | train loss {'Reaction outcome loss': 0.1755812788138173, 'Total loss': 0.1755812788138173}
2023-01-05 04:11:55,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:55,240 INFO:     Epoch: 69
2023-01-05 04:11:57,435 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3685521041353544, 'Total loss': 0.3685521041353544} | train loss {'Reaction outcome loss': 0.17852735265443356, 'Total loss': 0.17852735265443356}
2023-01-05 04:11:57,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:57,436 INFO:     Epoch: 70
2023-01-05 04:11:59,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3883091611166795, 'Total loss': 0.3883091611166795} | train loss {'Reaction outcome loss': 0.17556113003997126, 'Total loss': 0.17556113003997126}
2023-01-05 04:11:59,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:11:59,644 INFO:     Epoch: 71
2023-01-05 04:12:01,820 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3943658004204432, 'Total loss': 0.3943658004204432} | train loss {'Reaction outcome loss': 0.17024864121666694, 'Total loss': 0.17024864121666694}
2023-01-05 04:12:01,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:01,820 INFO:     Epoch: 72
2023-01-05 04:12:04,000 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43003297845522565, 'Total loss': 0.43003297845522565} | train loss {'Reaction outcome loss': 0.1702407822940787, 'Total loss': 0.1702407822940787}
2023-01-05 04:12:04,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:04,001 INFO:     Epoch: 73
2023-01-05 04:12:06,159 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41266315629084904, 'Total loss': 0.41266315629084904} | train loss {'Reaction outcome loss': 0.1725353358959525, 'Total loss': 0.1725353358959525}
2023-01-05 04:12:06,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:06,159 INFO:     Epoch: 74
2023-01-05 04:12:08,341 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.364721011929214, 'Total loss': 0.364721011929214} | train loss {'Reaction outcome loss': 0.1702871093512736, 'Total loss': 0.1702871093512736}
2023-01-05 04:12:08,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:08,341 INFO:     Epoch: 75
2023-01-05 04:12:10,539 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.434280655781428, 'Total loss': 0.434280655781428} | train loss {'Reaction outcome loss': 0.16559308193404076, 'Total loss': 0.16559308193404076}
2023-01-05 04:12:10,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:10,540 INFO:     Epoch: 76
2023-01-05 04:12:12,743 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4076085239648819, 'Total loss': 0.4076085239648819} | train loss {'Reaction outcome loss': 0.16784155696829803, 'Total loss': 0.16784155696829803}
2023-01-05 04:12:12,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:12,743 INFO:     Epoch: 77
2023-01-05 04:12:14,966 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3784263297915459, 'Total loss': 0.3784263297915459} | train loss {'Reaction outcome loss': 0.16996937185848937, 'Total loss': 0.16996937185848937}
2023-01-05 04:12:14,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:14,967 INFO:     Epoch: 78
2023-01-05 04:12:17,189 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4400485634803772, 'Total loss': 0.4400485634803772} | train loss {'Reaction outcome loss': 0.1744966378583267, 'Total loss': 0.1744966378583267}
2023-01-05 04:12:17,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:17,189 INFO:     Epoch: 79
2023-01-05 04:12:19,414 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41186658839384716, 'Total loss': 0.41186658839384716} | train loss {'Reaction outcome loss': 0.1684281810502972, 'Total loss': 0.1684281810502972}
2023-01-05 04:12:19,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:19,414 INFO:     Epoch: 80
2023-01-05 04:12:21,630 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4005625396966934, 'Total loss': 0.4005625396966934} | train loss {'Reaction outcome loss': 0.16578701133341478, 'Total loss': 0.16578701133341478}
2023-01-05 04:12:21,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:21,630 INFO:     Epoch: 81
2023-01-05 04:12:23,866 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41506330283979576, 'Total loss': 0.41506330283979576} | train loss {'Reaction outcome loss': 0.16865636918666288, 'Total loss': 0.16865636918666288}
2023-01-05 04:12:23,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:23,867 INFO:     Epoch: 82
2023-01-05 04:12:26,090 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4442678133646647, 'Total loss': 0.4442678133646647} | train loss {'Reaction outcome loss': 0.16399823919254805, 'Total loss': 0.16399823919254805}
2023-01-05 04:12:26,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:26,090 INFO:     Epoch: 83
2023-01-05 04:12:28,307 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41123024225234983, 'Total loss': 0.41123024225234983} | train loss {'Reaction outcome loss': 0.16132550422322156, 'Total loss': 0.16132550422322156}
2023-01-05 04:12:28,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:28,308 INFO:     Epoch: 84
2023-01-05 04:12:30,516 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43577771782875063, 'Total loss': 0.43577771782875063} | train loss {'Reaction outcome loss': 0.15834173609457938, 'Total loss': 0.15834173609457938}
2023-01-05 04:12:30,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:30,516 INFO:     Epoch: 85
2023-01-05 04:12:32,742 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4726753483215968, 'Total loss': 0.4726753483215968} | train loss {'Reaction outcome loss': 0.1608934930123636, 'Total loss': 0.1608934930123636}
2023-01-05 04:12:32,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:32,742 INFO:     Epoch: 86
2023-01-05 04:12:34,941 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4178320035338402, 'Total loss': 0.4178320035338402} | train loss {'Reaction outcome loss': 0.16421479818229032, 'Total loss': 0.16421479818229032}
2023-01-05 04:12:34,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:34,942 INFO:     Epoch: 87
2023-01-05 04:12:37,171 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42403755386670433, 'Total loss': 0.42403755386670433} | train loss {'Reaction outcome loss': 0.1613583392197287, 'Total loss': 0.1613583392197287}
2023-01-05 04:12:37,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:37,171 INFO:     Epoch: 88
2023-01-05 04:12:39,399 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38105684649199245, 'Total loss': 0.38105684649199245} | train loss {'Reaction outcome loss': 0.16182790923953003, 'Total loss': 0.16182790923953003}
2023-01-05 04:12:39,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:39,399 INFO:     Epoch: 89
2023-01-05 04:12:41,617 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.399750069125245, 'Total loss': 0.399750069125245} | train loss {'Reaction outcome loss': 0.1590019628281853, 'Total loss': 0.1590019628281853}
2023-01-05 04:12:41,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:41,618 INFO:     Epoch: 90
2023-01-05 04:12:43,843 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4393481304248174, 'Total loss': 0.4393481304248174} | train loss {'Reaction outcome loss': 0.15782514464873065, 'Total loss': 0.15782514464873065}
2023-01-05 04:12:43,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:43,843 INFO:     Epoch: 91
2023-01-05 04:12:46,059 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48273864686489104, 'Total loss': 0.48273864686489104} | train loss {'Reaction outcome loss': 0.1569316509794925, 'Total loss': 0.1569316509794925}
2023-01-05 04:12:46,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:46,059 INFO:     Epoch: 92
2023-01-05 04:12:48,289 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3982508569955826, 'Total loss': 0.3982508569955826} | train loss {'Reaction outcome loss': 0.15811692866431445, 'Total loss': 0.15811692866431445}
2023-01-05 04:12:48,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:48,290 INFO:     Epoch: 93
2023-01-05 04:12:50,508 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44174006978670755, 'Total loss': 0.44174006978670755} | train loss {'Reaction outcome loss': 0.1556983423140931, 'Total loss': 0.1556983423140931}
2023-01-05 04:12:50,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:50,508 INFO:     Epoch: 94
2023-01-05 04:12:52,701 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40806364367405573, 'Total loss': 0.40806364367405573} | train loss {'Reaction outcome loss': 0.15914771821851606, 'Total loss': 0.15914771821851606}
2023-01-05 04:12:52,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:52,701 INFO:     Epoch: 95
2023-01-05 04:12:54,923 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42444997529188794, 'Total loss': 0.42444997529188794} | train loss {'Reaction outcome loss': 0.15652618653955438, 'Total loss': 0.15652618653955438}
2023-01-05 04:12:54,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:54,923 INFO:     Epoch: 96
2023-01-05 04:12:57,138 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4194989969333013, 'Total loss': 0.4194989969333013} | train loss {'Reaction outcome loss': 0.15365309386455706, 'Total loss': 0.15365309386455706}
2023-01-05 04:12:57,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:57,139 INFO:     Epoch: 97
2023-01-05 04:12:59,363 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3987575610478719, 'Total loss': 0.3987575610478719} | train loss {'Reaction outcome loss': 0.15661632865014385, 'Total loss': 0.15661632865014385}
2023-01-05 04:12:59,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:12:59,363 INFO:     Epoch: 98
2023-01-05 04:13:01,575 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4273051237066587, 'Total loss': 0.4273051237066587} | train loss {'Reaction outcome loss': 0.15749694344096188, 'Total loss': 0.15749694344096188}
2023-01-05 04:13:01,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:01,575 INFO:     Epoch: 99
2023-01-05 04:13:03,791 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.430803777774175, 'Total loss': 0.430803777774175} | train loss {'Reaction outcome loss': 0.15325220433541495, 'Total loss': 0.15325220433541495}
2023-01-05 04:13:03,791 INFO:     Best model found after epoch 40 of 100.
2023-01-05 04:13:03,792 INFO:   Done with stage: TRAINING
2023-01-05 04:13:03,792 INFO:   Starting stage: EVALUATION
2023-01-05 04:13:03,944 INFO:   Done with stage: EVALUATION
2023-01-05 04:13:03,944 INFO:   Leaving out SEQ value Fold_4
2023-01-05 04:13:03,957 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:13:03,957 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:13:04,596 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:13:04,596 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:13:04,669 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:13:04,669 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:13:04,669 INFO:     No hyperparam tuning for this model
2023-01-05 04:13:04,669 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:13:04,669 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:13:04,670 INFO:     None feature selector for col prot
2023-01-05 04:13:04,670 INFO:     None feature selector for col prot
2023-01-05 04:13:04,670 INFO:     None feature selector for col prot
2023-01-05 04:13:04,671 INFO:     None feature selector for col chem
2023-01-05 04:13:04,671 INFO:     None feature selector for col chem
2023-01-05 04:13:04,671 INFO:     None feature selector for col chem
2023-01-05 04:13:04,671 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:13:04,671 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:13:04,672 INFO:     Number of params in model 72931
2023-01-05 04:13:04,675 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:13:04,675 INFO:   Starting stage: TRAINING
2023-01-05 04:13:04,736 INFO:     Val loss before train {'Reaction outcome loss': 1.093651250998179, 'Total loss': 1.093651250998179}
2023-01-05 04:13:04,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:04,736 INFO:     Epoch: 0
2023-01-05 04:13:06,928 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7635130564371745, 'Total loss': 0.7635130564371745} | train loss {'Reaction outcome loss': 0.9239471367411856, 'Total loss': 0.9239471367411856}
2023-01-05 04:13:06,928 INFO:     Found new best model at epoch 0
2023-01-05 04:13:06,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:06,930 INFO:     Epoch: 1
2023-01-05 04:13:09,110 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5023335516452789, 'Total loss': 0.5023335516452789} | train loss {'Reaction outcome loss': 0.6195699246465296, 'Total loss': 0.6195699246465296}
2023-01-05 04:13:09,110 INFO:     Found new best model at epoch 1
2023-01-05 04:13:09,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:09,111 INFO:     Epoch: 2
2023-01-05 04:13:11,303 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4686266561349233, 'Total loss': 0.4686266561349233} | train loss {'Reaction outcome loss': 0.5332612251066535, 'Total loss': 0.5332612251066535}
2023-01-05 04:13:11,304 INFO:     Found new best model at epoch 2
2023-01-05 04:13:11,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:11,305 INFO:     Epoch: 3
2023-01-05 04:13:13,463 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45436100562413534, 'Total loss': 0.45436100562413534} | train loss {'Reaction outcome loss': 0.4887511230046874, 'Total loss': 0.4887511230046874}
2023-01-05 04:13:13,463 INFO:     Found new best model at epoch 3
2023-01-05 04:13:13,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:13,465 INFO:     Epoch: 4
2023-01-05 04:13:15,702 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4399464468161265, 'Total loss': 0.4399464468161265} | train loss {'Reaction outcome loss': 0.46670851759288623, 'Total loss': 0.46670851759288623}
2023-01-05 04:13:15,702 INFO:     Found new best model at epoch 4
2023-01-05 04:13:15,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:15,704 INFO:     Epoch: 5
2023-01-05 04:13:17,956 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4476072947184245, 'Total loss': 0.4476072947184245} | train loss {'Reaction outcome loss': 0.4377799116841018, 'Total loss': 0.4377799116841018}
2023-01-05 04:13:17,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:17,957 INFO:     Epoch: 6
2023-01-05 04:13:20,175 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4362999528646469, 'Total loss': 0.4362999528646469} | train loss {'Reaction outcome loss': 0.4356621296779401, 'Total loss': 0.4356621296779401}
2023-01-05 04:13:20,175 INFO:     Found new best model at epoch 6
2023-01-05 04:13:20,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:20,177 INFO:     Epoch: 7
2023-01-05 04:13:22,401 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.406500310699145, 'Total loss': 0.406500310699145} | train loss {'Reaction outcome loss': 0.41043163119035814, 'Total loss': 0.41043163119035814}
2023-01-05 04:13:22,401 INFO:     Found new best model at epoch 7
2023-01-05 04:13:22,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:22,403 INFO:     Epoch: 8
2023-01-05 04:13:24,651 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4409626454114914, 'Total loss': 0.4409626454114914} | train loss {'Reaction outcome loss': 0.3895779631802461, 'Total loss': 0.3895779631802461}
2023-01-05 04:13:24,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:24,651 INFO:     Epoch: 9
2023-01-05 04:13:26,890 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4166060129801432, 'Total loss': 0.4166060129801432} | train loss {'Reaction outcome loss': 0.386774352900144, 'Total loss': 0.386774352900144}
2023-01-05 04:13:26,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:26,890 INFO:     Epoch: 10
2023-01-05 04:13:28,702 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39891715049743653, 'Total loss': 0.39891715049743653} | train loss {'Reaction outcome loss': 0.3854969956277721, 'Total loss': 0.3854969956277721}
2023-01-05 04:13:28,702 INFO:     Found new best model at epoch 10
2023-01-05 04:13:28,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:28,703 INFO:     Epoch: 11
2023-01-05 04:13:30,540 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4095438301563263, 'Total loss': 0.4095438301563263} | train loss {'Reaction outcome loss': 0.35567998612110596, 'Total loss': 0.35567998612110596}
2023-01-05 04:13:30,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:30,540 INFO:     Epoch: 12
2023-01-05 04:13:32,637 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40821077674627304, 'Total loss': 0.40821077674627304} | train loss {'Reaction outcome loss': 0.3445646852715467, 'Total loss': 0.3445646852715467}
2023-01-05 04:13:32,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:32,637 INFO:     Epoch: 13
2023-01-05 04:13:34,868 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41227877338727315, 'Total loss': 0.41227877338727315} | train loss {'Reaction outcome loss': 0.33474842005196714, 'Total loss': 0.33474842005196714}
2023-01-05 04:13:34,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:34,870 INFO:     Epoch: 14
2023-01-05 04:13:37,046 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42684224744637805, 'Total loss': 0.42684224744637805} | train loss {'Reaction outcome loss': 0.327650788251945, 'Total loss': 0.327650788251945}
2023-01-05 04:13:37,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:37,046 INFO:     Epoch: 15
2023-01-05 04:13:39,300 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4248304118712743, 'Total loss': 0.4248304118712743} | train loss {'Reaction outcome loss': 0.3176283797357177, 'Total loss': 0.3176283797357177}
2023-01-05 04:13:39,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:39,300 INFO:     Epoch: 16
2023-01-05 04:13:41,496 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41294041126966474, 'Total loss': 0.41294041126966474} | train loss {'Reaction outcome loss': 0.3122556936688088, 'Total loss': 0.3122556936688088}
2023-01-05 04:13:41,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:41,497 INFO:     Epoch: 17
2023-01-05 04:13:43,666 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3989558388789495, 'Total loss': 0.3989558388789495} | train loss {'Reaction outcome loss': 0.3034849328029415, 'Total loss': 0.3034849328029415}
2023-01-05 04:13:43,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:43,667 INFO:     Epoch: 18
2023-01-05 04:13:45,915 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40624647388855617, 'Total loss': 0.40624647388855617} | train loss {'Reaction outcome loss': 0.2960314386137474, 'Total loss': 0.2960314386137474}
2023-01-05 04:13:45,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:45,915 INFO:     Epoch: 19
2023-01-05 04:13:48,097 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.419328910112381, 'Total loss': 0.419328910112381} | train loss {'Reaction outcome loss': 0.29029784689117916, 'Total loss': 0.29029784689117916}
2023-01-05 04:13:48,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:48,098 INFO:     Epoch: 20
2023-01-05 04:13:50,251 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40586432019869484, 'Total loss': 0.40586432019869484} | train loss {'Reaction outcome loss': 0.2848239959866328, 'Total loss': 0.2848239959866328}
2023-01-05 04:13:50,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:50,251 INFO:     Epoch: 21
2023-01-05 04:13:52,402 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40485443075497946, 'Total loss': 0.40485443075497946} | train loss {'Reaction outcome loss': 0.2775549410160739, 'Total loss': 0.2775549410160739}
2023-01-05 04:13:52,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:52,402 INFO:     Epoch: 22
2023-01-05 04:13:54,625 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4061473955710729, 'Total loss': 0.4061473955710729} | train loss {'Reaction outcome loss': 0.2711257688604984, 'Total loss': 0.2711257688604984}
2023-01-05 04:13:54,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:54,626 INFO:     Epoch: 23
2023-01-05 04:13:56,868 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39719935804605483, 'Total loss': 0.39719935804605483} | train loss {'Reaction outcome loss': 0.26716940117636323, 'Total loss': 0.26716940117636323}
2023-01-05 04:13:56,868 INFO:     Found new best model at epoch 23
2023-01-05 04:13:56,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:56,870 INFO:     Epoch: 24
2023-01-05 04:13:59,056 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4136505504449209, 'Total loss': 0.4136505504449209} | train loss {'Reaction outcome loss': 0.2621038946482535, 'Total loss': 0.2621038946482535}
2023-01-05 04:13:59,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:13:59,056 INFO:     Epoch: 25
2023-01-05 04:14:01,289 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4026296824216843, 'Total loss': 0.4026296824216843} | train loss {'Reaction outcome loss': 0.25774527623223653, 'Total loss': 0.25774527623223653}
2023-01-05 04:14:01,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:01,290 INFO:     Epoch: 26
2023-01-05 04:14:03,542 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3992874483267466, 'Total loss': 0.3992874483267466} | train loss {'Reaction outcome loss': 0.25366954708948947, 'Total loss': 0.25366954708948947}
2023-01-05 04:14:03,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:03,542 INFO:     Epoch: 27
2023-01-05 04:14:05,764 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4231848845879237, 'Total loss': 0.4231848845879237} | train loss {'Reaction outcome loss': 0.25056215228908946, 'Total loss': 0.25056215228908946}
2023-01-05 04:14:05,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:05,764 INFO:     Epoch: 28
2023-01-05 04:14:07,943 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38770158439874647, 'Total loss': 0.38770158439874647} | train loss {'Reaction outcome loss': 0.24534577350794384, 'Total loss': 0.24534577350794384}
2023-01-05 04:14:07,943 INFO:     Found new best model at epoch 28
2023-01-05 04:14:07,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:07,944 INFO:     Epoch: 29
2023-01-05 04:14:10,109 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4050101488828659, 'Total loss': 0.4050101488828659} | train loss {'Reaction outcome loss': 0.23952675995416736, 'Total loss': 0.23952675995416736}
2023-01-05 04:14:10,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:10,110 INFO:     Epoch: 30
2023-01-05 04:14:12,349 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3793069064617157, 'Total loss': 0.3793069064617157} | train loss {'Reaction outcome loss': 0.23729896810086296, 'Total loss': 0.23729896810086296}
2023-01-05 04:14:12,350 INFO:     Found new best model at epoch 30
2023-01-05 04:14:12,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:12,351 INFO:     Epoch: 31
2023-01-05 04:14:14,599 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43340030014514924, 'Total loss': 0.43340030014514924} | train loss {'Reaction outcome loss': 0.23774656227222926, 'Total loss': 0.23774656227222926}
2023-01-05 04:14:14,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:14,599 INFO:     Epoch: 32
2023-01-05 04:14:16,830 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39708571632703143, 'Total loss': 0.39708571632703143} | train loss {'Reaction outcome loss': 0.23416504974332292, 'Total loss': 0.23416504974332292}
2023-01-05 04:14:16,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:16,831 INFO:     Epoch: 33
2023-01-05 04:14:18,982 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41232886364062626, 'Total loss': 0.41232886364062626} | train loss {'Reaction outcome loss': 0.22720026946293123, 'Total loss': 0.22720026946293123}
2023-01-05 04:14:18,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:18,982 INFO:     Epoch: 34
2023-01-05 04:14:21,234 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.403539385398229, 'Total loss': 0.403539385398229} | train loss {'Reaction outcome loss': 0.2280702728198578, 'Total loss': 0.2280702728198578}
2023-01-05 04:14:21,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:21,235 INFO:     Epoch: 35
2023-01-05 04:14:23,441 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3892106502006451, 'Total loss': 0.3892106502006451} | train loss {'Reaction outcome loss': 0.22406416992518077, 'Total loss': 0.22406416992518077}
2023-01-05 04:14:23,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:23,441 INFO:     Epoch: 36
2023-01-05 04:14:25,621 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39704494227965675, 'Total loss': 0.39704494227965675} | train loss {'Reaction outcome loss': 0.2227599806746171, 'Total loss': 0.2227599806746171}
2023-01-05 04:14:25,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:25,621 INFO:     Epoch: 37
2023-01-05 04:14:27,793 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42244358559449513, 'Total loss': 0.42244358559449513} | train loss {'Reaction outcome loss': 0.21683540896333728, 'Total loss': 0.21683540896333728}
2023-01-05 04:14:27,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:27,794 INFO:     Epoch: 38
2023-01-05 04:14:30,022 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39673286030689875, 'Total loss': 0.39673286030689875} | train loss {'Reaction outcome loss': 0.22080665001746072, 'Total loss': 0.22080665001746072}
2023-01-05 04:14:30,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:30,023 INFO:     Epoch: 39
2023-01-05 04:14:32,271 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4246329843997955, 'Total loss': 0.4246329843997955} | train loss {'Reaction outcome loss': 0.21541684429425717, 'Total loss': 0.21541684429425717}
2023-01-05 04:14:32,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:32,271 INFO:     Epoch: 40
2023-01-05 04:14:34,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4132638186216354, 'Total loss': 0.4132638186216354} | train loss {'Reaction outcome loss': 0.2116679452136969, 'Total loss': 0.2116679452136969}
2023-01-05 04:14:34,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:34,487 INFO:     Epoch: 41
2023-01-05 04:14:36,698 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4148346891005834, 'Total loss': 0.4148346891005834} | train loss {'Reaction outcome loss': 0.21311231456043653, 'Total loss': 0.21311231456043653}
2023-01-05 04:14:36,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:36,698 INFO:     Epoch: 42
2023-01-05 04:14:38,842 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.414278448621432, 'Total loss': 0.414278448621432} | train loss {'Reaction outcome loss': 0.20600972036644952, 'Total loss': 0.20600972036644952}
2023-01-05 04:14:38,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:38,843 INFO:     Epoch: 43
2023-01-05 04:14:41,074 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4138956035176913, 'Total loss': 0.4138956035176913} | train loss {'Reaction outcome loss': 0.20257203459682321, 'Total loss': 0.20257203459682321}
2023-01-05 04:14:41,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:41,075 INFO:     Epoch: 44
2023-01-05 04:14:43,317 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43772830367088317, 'Total loss': 0.43772830367088317} | train loss {'Reaction outcome loss': 0.2057356413032049, 'Total loss': 0.2057356413032049}
2023-01-05 04:14:43,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:43,318 INFO:     Epoch: 45
2023-01-05 04:14:45,575 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4290845980246862, 'Total loss': 0.4290845980246862} | train loss {'Reaction outcome loss': 0.20405905623741, 'Total loss': 0.20405905623741}
2023-01-05 04:14:45,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:45,575 INFO:     Epoch: 46
2023-01-05 04:14:47,638 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40987517635027565, 'Total loss': 0.40987517635027565} | train loss {'Reaction outcome loss': 0.2004738175985066, 'Total loss': 0.2004738175985066}
2023-01-05 04:14:47,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:47,639 INFO:     Epoch: 47
2023-01-05 04:14:49,792 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4157898743947347, 'Total loss': 0.4157898743947347} | train loss {'Reaction outcome loss': 0.20089861542056905, 'Total loss': 0.20089861542056905}
2023-01-05 04:14:49,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:49,792 INFO:     Epoch: 48
2023-01-05 04:14:52,030 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4236081540584564, 'Total loss': 0.4236081540584564} | train loss {'Reaction outcome loss': 0.1942035855313736, 'Total loss': 0.1942035855313736}
2023-01-05 04:14:52,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:52,031 INFO:     Epoch: 49
2023-01-05 04:14:54,165 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3946528951327006, 'Total loss': 0.3946528951327006} | train loss {'Reaction outcome loss': 0.19485679713471799, 'Total loss': 0.19485679713471799}
2023-01-05 04:14:54,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:54,165 INFO:     Epoch: 50
2023-01-05 04:14:56,280 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4629046440124512, 'Total loss': 0.4629046440124512} | train loss {'Reaction outcome loss': 0.19480889166394869, 'Total loss': 0.19480889166394869}
2023-01-05 04:14:56,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:56,280 INFO:     Epoch: 51
2023-01-05 04:14:58,537 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41050449311733245, 'Total loss': 0.41050449311733245} | train loss {'Reaction outcome loss': 0.19035355531040282, 'Total loss': 0.19035355531040282}
2023-01-05 04:14:58,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:14:58,537 INFO:     Epoch: 52
2023-01-05 04:15:00,785 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4125471959511439, 'Total loss': 0.4125471959511439} | train loss {'Reaction outcome loss': 0.18589262568148907, 'Total loss': 0.18589262568148907}
2023-01-05 04:15:00,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:00,786 INFO:     Epoch: 53
2023-01-05 04:15:03,028 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44213912487030027, 'Total loss': 0.44213912487030027} | train loss {'Reaction outcome loss': 0.1885747408926271, 'Total loss': 0.1885747408926271}
2023-01-05 04:15:03,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:03,028 INFO:     Epoch: 54
2023-01-05 04:15:05,213 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4273316065470378, 'Total loss': 0.4273316065470378} | train loss {'Reaction outcome loss': 0.19136609676417615, 'Total loss': 0.19136609676417615}
2023-01-05 04:15:05,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:05,213 INFO:     Epoch: 55
2023-01-05 04:15:07,477 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43087328256418306, 'Total loss': 0.43087328256418306} | train loss {'Reaction outcome loss': 0.19061015355164537, 'Total loss': 0.19061015355164537}
2023-01-05 04:15:07,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:07,477 INFO:     Epoch: 56
2023-01-05 04:15:09,737 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.391524084409078, 'Total loss': 0.391524084409078} | train loss {'Reaction outcome loss': 0.21954665997106096, 'Total loss': 0.21954665997106096}
2023-01-05 04:15:09,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:09,738 INFO:     Epoch: 57
2023-01-05 04:15:11,972 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4142201741536458, 'Total loss': 0.4142201741536458} | train loss {'Reaction outcome loss': 0.18878942528691908, 'Total loss': 0.18878942528691908}
2023-01-05 04:15:11,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:11,973 INFO:     Epoch: 58
2023-01-05 04:15:14,230 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4316052496433258, 'Total loss': 0.4316052496433258} | train loss {'Reaction outcome loss': 0.18119047379814615, 'Total loss': 0.18119047379814615}
2023-01-05 04:15:14,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:14,230 INFO:     Epoch: 59
2023-01-05 04:15:16,465 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40539789696534473, 'Total loss': 0.40539789696534473} | train loss {'Reaction outcome loss': 0.18415061396339555, 'Total loss': 0.18415061396339555}
2023-01-05 04:15:16,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:16,465 INFO:     Epoch: 60
2023-01-05 04:15:18,717 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4250129381815592, 'Total loss': 0.4250129381815592} | train loss {'Reaction outcome loss': 0.18125784851651153, 'Total loss': 0.18125784851651153}
2023-01-05 04:15:18,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:18,718 INFO:     Epoch: 61
2023-01-05 04:15:20,978 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4400078356266022, 'Total loss': 0.4400078356266022} | train loss {'Reaction outcome loss': 0.1877131971403656, 'Total loss': 0.1877131971403656}
2023-01-05 04:15:20,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:20,979 INFO:     Epoch: 62
2023-01-05 04:15:23,230 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3997009469817082, 'Total loss': 0.3997009469817082} | train loss {'Reaction outcome loss': 0.1805073264092072, 'Total loss': 0.1805073264092072}
2023-01-05 04:15:23,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:23,231 INFO:     Epoch: 63
2023-01-05 04:15:25,492 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42068180392185844, 'Total loss': 0.42068180392185844} | train loss {'Reaction outcome loss': 0.18295599107185137, 'Total loss': 0.18295599107185137}
2023-01-05 04:15:25,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:25,492 INFO:     Epoch: 64
2023-01-05 04:15:27,729 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40767959468066695, 'Total loss': 0.40767959468066695} | train loss {'Reaction outcome loss': 0.17903162009568643, 'Total loss': 0.17903162009568643}
2023-01-05 04:15:27,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:27,729 INFO:     Epoch: 65
2023-01-05 04:15:29,993 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4311560442050298, 'Total loss': 0.4311560442050298} | train loss {'Reaction outcome loss': 0.1754833907420423, 'Total loss': 0.1754833907420423}
2023-01-05 04:15:29,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:29,994 INFO:     Epoch: 66
2023-01-05 04:15:32,207 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4330234636863073, 'Total loss': 0.4330234636863073} | train loss {'Reaction outcome loss': 0.17408230415363188, 'Total loss': 0.17408230415363188}
2023-01-05 04:15:32,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:32,208 INFO:     Epoch: 67
2023-01-05 04:15:34,469 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4488811622063319, 'Total loss': 0.4488811622063319} | train loss {'Reaction outcome loss': 0.1704520684822152, 'Total loss': 0.1704520684822152}
2023-01-05 04:15:34,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:34,469 INFO:     Epoch: 68
2023-01-05 04:15:36,709 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44750731190045673, 'Total loss': 0.44750731190045673} | train loss {'Reaction outcome loss': 0.1723964994889684, 'Total loss': 0.1723964994889684}
2023-01-05 04:15:36,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:36,709 INFO:     Epoch: 69
2023-01-05 04:15:38,941 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42531001965204873, 'Total loss': 0.42531001965204873} | train loss {'Reaction outcome loss': 0.1706831172020917, 'Total loss': 0.1706831172020917}
2023-01-05 04:15:38,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:38,941 INFO:     Epoch: 70
2023-01-05 04:15:41,192 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44697444637616474, 'Total loss': 0.44697444637616474} | train loss {'Reaction outcome loss': 0.17246101458753718, 'Total loss': 0.17246101458753718}
2023-01-05 04:15:41,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:41,194 INFO:     Epoch: 71
2023-01-05 04:15:43,462 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4294471780459086, 'Total loss': 0.4294471780459086} | train loss {'Reaction outcome loss': 0.18316624221135525, 'Total loss': 0.18316624221135525}
2023-01-05 04:15:43,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:43,462 INFO:     Epoch: 72
2023-01-05 04:15:45,723 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46364206572373706, 'Total loss': 0.46364206572373706} | train loss {'Reaction outcome loss': 0.18948864619892117, 'Total loss': 0.18948864619892117}
2023-01-05 04:15:45,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:45,723 INFO:     Epoch: 73
2023-01-05 04:15:47,985 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43339003225167594, 'Total loss': 0.43339003225167594} | train loss {'Reaction outcome loss': 0.18004645220935345, 'Total loss': 0.18004645220935345}
2023-01-05 04:15:47,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:47,986 INFO:     Epoch: 74
2023-01-05 04:15:50,240 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40787647614876427, 'Total loss': 0.40787647614876427} | train loss {'Reaction outcome loss': 0.18512912905366713, 'Total loss': 0.18512912905366713}
2023-01-05 04:15:50,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:50,241 INFO:     Epoch: 75
2023-01-05 04:15:52,463 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46126625140508015, 'Total loss': 0.46126625140508015} | train loss {'Reaction outcome loss': 0.16892249463126063, 'Total loss': 0.16892249463126063}
2023-01-05 04:15:52,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:52,463 INFO:     Epoch: 76
2023-01-05 04:15:54,707 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4200493931770325, 'Total loss': 0.4200493931770325} | train loss {'Reaction outcome loss': 0.17061961215475333, 'Total loss': 0.17061961215475333}
2023-01-05 04:15:54,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:54,707 INFO:     Epoch: 77
2023-01-05 04:15:56,899 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.435108545422554, 'Total loss': 0.435108545422554} | train loss {'Reaction outcome loss': 0.16680411592571306, 'Total loss': 0.16680411592571306}
2023-01-05 04:15:56,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:56,900 INFO:     Epoch: 78
2023-01-05 04:15:59,156 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4537013163169225, 'Total loss': 0.4537013163169225} | train loss {'Reaction outcome loss': 0.16382918590713508, 'Total loss': 0.16382918590713508}
2023-01-05 04:15:59,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:15:59,156 INFO:     Epoch: 79
2023-01-05 04:16:01,383 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4212979407360156, 'Total loss': 0.4212979407360156} | train loss {'Reaction outcome loss': 0.1622023425812401, 'Total loss': 0.1622023425812401}
2023-01-05 04:16:01,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:01,384 INFO:     Epoch: 80
2023-01-05 04:16:03,597 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42994086345036825, 'Total loss': 0.42994086345036825} | train loss {'Reaction outcome loss': 0.1875013154661418, 'Total loss': 0.1875013154661418}
2023-01-05 04:16:03,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:03,597 INFO:     Epoch: 81
2023-01-05 04:16:05,741 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4539490779240926, 'Total loss': 0.4539490779240926} | train loss {'Reaction outcome loss': 0.16749831389361003, 'Total loss': 0.16749831389361003}
2023-01-05 04:16:05,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:05,741 INFO:     Epoch: 82
2023-01-05 04:16:07,982 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41381857537974914, 'Total loss': 0.41381857537974914} | train loss {'Reaction outcome loss': 0.1662467989405833, 'Total loss': 0.1662467989405833}
2023-01-05 04:16:07,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:07,982 INFO:     Epoch: 83
2023-01-05 04:16:10,124 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45946186582247417, 'Total loss': 0.45946186582247417} | train loss {'Reaction outcome loss': 0.16097021591891805, 'Total loss': 0.16097021591891805}
2023-01-05 04:16:10,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:10,124 INFO:     Epoch: 84
2023-01-05 04:16:12,338 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4503448168436686, 'Total loss': 0.4503448168436686} | train loss {'Reaction outcome loss': 0.1666391126929106, 'Total loss': 0.1666391126929106}
2023-01-05 04:16:12,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:12,339 INFO:     Epoch: 85
2023-01-05 04:16:14,518 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.435922842224439, 'Total loss': 0.435922842224439} | train loss {'Reaction outcome loss': 0.16205002241970404, 'Total loss': 0.16205002241970404}
2023-01-05 04:16:14,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:14,518 INFO:     Epoch: 86
2023-01-05 04:16:16,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4440398506820202, 'Total loss': 0.4440398506820202} | train loss {'Reaction outcome loss': 0.163907935893487, 'Total loss': 0.163907935893487}
2023-01-05 04:16:16,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:16,728 INFO:     Epoch: 87
2023-01-05 04:16:18,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4482217192649841, 'Total loss': 0.4482217192649841} | train loss {'Reaction outcome loss': 0.15519303554901853, 'Total loss': 0.15519303554901853}
2023-01-05 04:16:18,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:18,899 INFO:     Epoch: 88
2023-01-05 04:16:21,164 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4718072851498922, 'Total loss': 0.4718072851498922} | train loss {'Reaction outcome loss': 0.16050082278957564, 'Total loss': 0.16050082278957564}
2023-01-05 04:16:21,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:21,164 INFO:     Epoch: 89
2023-01-05 04:16:23,379 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42105625569820404, 'Total loss': 0.42105625569820404} | train loss {'Reaction outcome loss': 0.1563765637802662, 'Total loss': 0.1563765637802662}
2023-01-05 04:16:23,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:23,380 INFO:     Epoch: 90
2023-01-05 04:16:25,529 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.446123165388902, 'Total loss': 0.446123165388902} | train loss {'Reaction outcome loss': 0.15469779061706926, 'Total loss': 0.15469779061706926}
2023-01-05 04:16:25,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:25,530 INFO:     Epoch: 91
2023-01-05 04:16:27,740 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4657393962144852, 'Total loss': 0.4657393962144852} | train loss {'Reaction outcome loss': 0.16124035276732393, 'Total loss': 0.16124035276732393}
2023-01-05 04:16:27,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:27,740 INFO:     Epoch: 92
2023-01-05 04:16:29,969 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4318933844566345, 'Total loss': 0.4318933844566345} | train loss {'Reaction outcome loss': 0.15552894188811583, 'Total loss': 0.15552894188811583}
2023-01-05 04:16:29,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:29,969 INFO:     Epoch: 93
2023-01-05 04:16:32,216 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4486359020074209, 'Total loss': 0.4486359020074209} | train loss {'Reaction outcome loss': 0.15982564429050664, 'Total loss': 0.15982564429050664}
2023-01-05 04:16:32,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:32,217 INFO:     Epoch: 94
2023-01-05 04:16:34,426 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4307177389661471, 'Total loss': 0.4307177389661471} | train loss {'Reaction outcome loss': 0.16020948073381316, 'Total loss': 0.16020948073381316}
2023-01-05 04:16:34,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:34,426 INFO:     Epoch: 95
2023-01-05 04:16:36,621 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.453632108370463, 'Total loss': 0.453632108370463} | train loss {'Reaction outcome loss': 0.1595185220573077, 'Total loss': 0.1595185220573077}
2023-01-05 04:16:36,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:36,622 INFO:     Epoch: 96
2023-01-05 04:16:38,770 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4243912319342295, 'Total loss': 0.4243912319342295} | train loss {'Reaction outcome loss': 0.15644215022347044, 'Total loss': 0.15644215022347044}
2023-01-05 04:16:38,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:38,770 INFO:     Epoch: 97
2023-01-05 04:16:41,020 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4637501686811447, 'Total loss': 0.4637501686811447} | train loss {'Reaction outcome loss': 0.14963428479319008, 'Total loss': 0.14963428479319008}
2023-01-05 04:16:41,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:41,020 INFO:     Epoch: 98
2023-01-05 04:16:43,249 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4451851705710093, 'Total loss': 0.4451851705710093} | train loss {'Reaction outcome loss': 0.1497547439882866, 'Total loss': 0.1497547439882866}
2023-01-05 04:16:43,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:43,249 INFO:     Epoch: 99
2023-01-05 04:16:45,493 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4683537681897481, 'Total loss': 0.4683537681897481} | train loss {'Reaction outcome loss': 0.15583623830647464, 'Total loss': 0.15583623830647464}
2023-01-05 04:16:45,493 INFO:     Best model found after epoch 31 of 100.
2023-01-05 04:16:45,494 INFO:   Done with stage: TRAINING
2023-01-05 04:16:45,494 INFO:   Starting stage: EVALUATION
2023-01-05 04:16:45,631 INFO:   Done with stage: EVALUATION
2023-01-05 04:16:45,631 INFO:   Leaving out SEQ value Fold_5
2023-01-05 04:16:45,643 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:16:45,643 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:16:46,286 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:16:46,286 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:16:46,359 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:16:46,359 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:16:46,359 INFO:     No hyperparam tuning for this model
2023-01-05 04:16:46,359 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:16:46,359 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:16:46,360 INFO:     None feature selector for col prot
2023-01-05 04:16:46,360 INFO:     None feature selector for col prot
2023-01-05 04:16:46,360 INFO:     None feature selector for col prot
2023-01-05 04:16:46,360 INFO:     None feature selector for col chem
2023-01-05 04:16:46,360 INFO:     None feature selector for col chem
2023-01-05 04:16:46,361 INFO:     None feature selector for col chem
2023-01-05 04:16:46,361 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:16:46,361 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:16:46,362 INFO:     Number of params in model 72931
2023-01-05 04:16:46,365 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:16:46,365 INFO:   Starting stage: TRAINING
2023-01-05 04:16:46,426 INFO:     Val loss before train {'Reaction outcome loss': 1.0920196851094564, 'Total loss': 1.0920196851094564}
2023-01-05 04:16:46,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:46,426 INFO:     Epoch: 0
2023-01-05 04:16:48,549 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.973273245493571, 'Total loss': 0.973273245493571} | train loss {'Reaction outcome loss': 0.986222584988328, 'Total loss': 0.986222584988328}
2023-01-05 04:16:48,549 INFO:     Found new best model at epoch 0
2023-01-05 04:16:48,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:48,551 INFO:     Epoch: 1
2023-01-05 04:16:50,718 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6548494398593903, 'Total loss': 0.6548494398593903} | train loss {'Reaction outcome loss': 0.7351043240329169, 'Total loss': 0.7351043240329169}
2023-01-05 04:16:50,718 INFO:     Found new best model at epoch 1
2023-01-05 04:16:50,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:50,720 INFO:     Epoch: 2
2023-01-05 04:16:52,946 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5582321008046468, 'Total loss': 0.5582321008046468} | train loss {'Reaction outcome loss': 0.5783104777228141, 'Total loss': 0.5783104777228141}
2023-01-05 04:16:52,947 INFO:     Found new best model at epoch 2
2023-01-05 04:16:52,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:52,948 INFO:     Epoch: 3
2023-01-05 04:16:55,179 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5388253132502238, 'Total loss': 0.5388253132502238} | train loss {'Reaction outcome loss': 0.5376663199909355, 'Total loss': 0.5376663199909355}
2023-01-05 04:16:55,179 INFO:     Found new best model at epoch 3
2023-01-05 04:16:55,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:55,180 INFO:     Epoch: 4
2023-01-05 04:16:57,380 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5327527364095052, 'Total loss': 0.5327527364095052} | train loss {'Reaction outcome loss': 0.4914072942447619, 'Total loss': 0.4914072942447619}
2023-01-05 04:16:57,380 INFO:     Found new best model at epoch 4
2023-01-05 04:16:57,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:57,381 INFO:     Epoch: 5
2023-01-05 04:16:59,546 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5465566962957382, 'Total loss': 0.5465566962957382} | train loss {'Reaction outcome loss': 0.4687724437402642, 'Total loss': 0.4687724437402642}
2023-01-05 04:16:59,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:16:59,547 INFO:     Epoch: 6
2023-01-05 04:17:01,729 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5302779455979665, 'Total loss': 0.5302779455979665} | train loss {'Reaction outcome loss': 0.4491671609314348, 'Total loss': 0.4491671609314348}
2023-01-05 04:17:01,729 INFO:     Found new best model at epoch 6
2023-01-05 04:17:01,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:01,730 INFO:     Epoch: 7
2023-01-05 04:17:03,979 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5060402154922485, 'Total loss': 0.5060402154922485} | train loss {'Reaction outcome loss': 0.4384118884369947, 'Total loss': 0.4384118884369947}
2023-01-05 04:17:03,979 INFO:     Found new best model at epoch 7
2023-01-05 04:17:03,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:03,981 INFO:     Epoch: 8
2023-01-05 04:17:06,222 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49288865526517234, 'Total loss': 0.49288865526517234} | train loss {'Reaction outcome loss': 0.4209691227676914, 'Total loss': 0.4209691227676914}
2023-01-05 04:17:06,222 INFO:     Found new best model at epoch 8
2023-01-05 04:17:06,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:06,223 INFO:     Epoch: 9
2023-01-05 04:17:08,475 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5061729729175568, 'Total loss': 0.5061729729175568} | train loss {'Reaction outcome loss': 0.41286456159930135, 'Total loss': 0.41286456159930135}
2023-01-05 04:17:08,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:08,475 INFO:     Epoch: 10
2023-01-05 04:17:10,715 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5018785019715627, 'Total loss': 0.5018785019715627} | train loss {'Reaction outcome loss': 0.3960954675187721, 'Total loss': 0.3960954675187721}
2023-01-05 04:17:10,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:10,716 INFO:     Epoch: 11
2023-01-05 04:17:12,922 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49370305637518563, 'Total loss': 0.49370305637518563} | train loss {'Reaction outcome loss': 0.3992931498484551, 'Total loss': 0.3992931498484551}
2023-01-05 04:17:12,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:12,923 INFO:     Epoch: 12
2023-01-05 04:17:15,162 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5043132762114207, 'Total loss': 0.5043132762114207} | train loss {'Reaction outcome loss': 0.4105659086743127, 'Total loss': 0.4105659086743127}
2023-01-05 04:17:15,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:15,163 INFO:     Epoch: 13
2023-01-05 04:17:17,407 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48434353470802305, 'Total loss': 0.48434353470802305} | train loss {'Reaction outcome loss': 0.3788479950036044, 'Total loss': 0.3788479950036044}
2023-01-05 04:17:17,408 INFO:     Found new best model at epoch 13
2023-01-05 04:17:17,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:17,409 INFO:     Epoch: 14
2023-01-05 04:17:19,583 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4812424898147583, 'Total loss': 0.4812424898147583} | train loss {'Reaction outcome loss': 0.36915718557893473, 'Total loss': 0.36915718557893473}
2023-01-05 04:17:19,583 INFO:     Found new best model at epoch 14
2023-01-05 04:17:19,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:19,585 INFO:     Epoch: 15
2023-01-05 04:17:21,776 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4745547443628311, 'Total loss': 0.4745547443628311} | train loss {'Reaction outcome loss': 0.3613864569992259, 'Total loss': 0.3613864569992259}
2023-01-05 04:17:21,776 INFO:     Found new best model at epoch 15
2023-01-05 04:17:21,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:21,778 INFO:     Epoch: 16
2023-01-05 04:17:23,996 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4802404542764028, 'Total loss': 0.4802404542764028} | train loss {'Reaction outcome loss': 0.3523758372499103, 'Total loss': 0.3523758372499103}
2023-01-05 04:17:23,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:23,996 INFO:     Epoch: 17
2023-01-05 04:17:26,190 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4835501253604889, 'Total loss': 0.4835501253604889} | train loss {'Reaction outcome loss': 0.3445302620104116, 'Total loss': 0.3445302620104116}
2023-01-05 04:17:26,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:26,190 INFO:     Epoch: 18
2023-01-05 04:17:28,382 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4800459126631419, 'Total loss': 0.4800459126631419} | train loss {'Reaction outcome loss': 0.33719957900651987, 'Total loss': 0.33719957900651987}
2023-01-05 04:17:28,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:28,383 INFO:     Epoch: 19
2023-01-05 04:17:30,609 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4955034931500753, 'Total loss': 0.4955034931500753} | train loss {'Reaction outcome loss': 0.33426959850433946, 'Total loss': 0.33426959850433946}
2023-01-05 04:17:30,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:30,609 INFO:     Epoch: 20
2023-01-05 04:17:32,904 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.459136160214742, 'Total loss': 0.459136160214742} | train loss {'Reaction outcome loss': 0.32509894340161566, 'Total loss': 0.32509894340161566}
2023-01-05 04:17:32,904 INFO:     Found new best model at epoch 20
2023-01-05 04:17:32,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:32,906 INFO:     Epoch: 21
2023-01-05 04:17:35,098 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46931129892667134, 'Total loss': 0.46931129892667134} | train loss {'Reaction outcome loss': 0.3207674846076454, 'Total loss': 0.3207674846076454}
2023-01-05 04:17:35,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:35,098 INFO:     Epoch: 22
2023-01-05 04:17:37,275 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4892388800779978, 'Total loss': 0.4892388800779978} | train loss {'Reaction outcome loss': 0.31588964252833923, 'Total loss': 0.31588964252833923}
2023-01-05 04:17:37,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:37,275 INFO:     Epoch: 23
2023-01-05 04:17:39,469 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48446728388468424, 'Total loss': 0.48446728388468424} | train loss {'Reaction outcome loss': 0.3218189880143905, 'Total loss': 0.3218189880143905}
2023-01-05 04:17:39,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:39,469 INFO:     Epoch: 24
2023-01-05 04:17:41,719 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47556074857711794, 'Total loss': 0.47556074857711794} | train loss {'Reaction outcome loss': 0.32249145409117397, 'Total loss': 0.32249145409117397}
2023-01-05 04:17:41,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:41,719 INFO:     Epoch: 25
2023-01-05 04:17:43,946 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49277722934881846, 'Total loss': 0.49277722934881846} | train loss {'Reaction outcome loss': 0.3005618875828551, 'Total loss': 0.3005618875828551}
2023-01-05 04:17:43,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:43,946 INFO:     Epoch: 26
2023-01-05 04:17:46,209 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48572375377019245, 'Total loss': 0.48572375377019245} | train loss {'Reaction outcome loss': 0.29484803779421886, 'Total loss': 0.29484803779421886}
2023-01-05 04:17:46,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:46,210 INFO:     Epoch: 27
2023-01-05 04:17:48,456 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5144723589221637, 'Total loss': 0.5144723589221637} | train loss {'Reaction outcome loss': 0.28943563783558196, 'Total loss': 0.28943563783558196}
2023-01-05 04:17:48,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:48,456 INFO:     Epoch: 28
2023-01-05 04:17:50,730 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4802314653992653, 'Total loss': 0.4802314653992653} | train loss {'Reaction outcome loss': 0.2893117103454458, 'Total loss': 0.2893117103454458}
2023-01-05 04:17:50,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:50,730 INFO:     Epoch: 29
2023-01-05 04:17:52,998 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4805974354346593, 'Total loss': 0.4805974354346593} | train loss {'Reaction outcome loss': 0.2838065718651574, 'Total loss': 0.2838065718651574}
2023-01-05 04:17:52,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:52,998 INFO:     Epoch: 30
2023-01-05 04:17:55,265 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4816135913133621, 'Total loss': 0.4816135913133621} | train loss {'Reaction outcome loss': 0.279737886203372, 'Total loss': 0.279737886203372}
2023-01-05 04:17:55,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:55,265 INFO:     Epoch: 31
2023-01-05 04:17:57,529 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49559499820073444, 'Total loss': 0.49559499820073444} | train loss {'Reaction outcome loss': 0.2787104602113482, 'Total loss': 0.2787104602113482}
2023-01-05 04:17:57,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:57,529 INFO:     Epoch: 32
2023-01-05 04:17:59,814 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5049237221479416, 'Total loss': 0.5049237221479416} | train loss {'Reaction outcome loss': 0.30159621700590505, 'Total loss': 0.30159621700590505}
2023-01-05 04:17:59,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:17:59,814 INFO:     Epoch: 33
2023-01-05 04:18:02,110 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4781443099180857, 'Total loss': 0.4781443099180857} | train loss {'Reaction outcome loss': 0.26767509158504993, 'Total loss': 0.26767509158504993}
2023-01-05 04:18:02,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:02,110 INFO:     Epoch: 34
2023-01-05 04:18:04,398 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47943691710631053, 'Total loss': 0.47943691710631053} | train loss {'Reaction outcome loss': 0.2659948669357961, 'Total loss': 0.2659948669357961}
2023-01-05 04:18:04,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:04,399 INFO:     Epoch: 35
2023-01-05 04:18:06,696 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4814637819925944, 'Total loss': 0.4814637819925944} | train loss {'Reaction outcome loss': 0.26110754586388, 'Total loss': 0.26110754586388}
2023-01-05 04:18:06,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:06,696 INFO:     Epoch: 36
2023-01-05 04:18:09,006 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.503969011704127, 'Total loss': 0.503969011704127} | train loss {'Reaction outcome loss': 0.259495665267805, 'Total loss': 0.259495665267805}
2023-01-05 04:18:09,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:09,006 INFO:     Epoch: 37
2023-01-05 04:18:11,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47242213288942975, 'Total loss': 0.47242213288942975} | train loss {'Reaction outcome loss': 0.2541051213891056, 'Total loss': 0.2541051213891056}
2023-01-05 04:18:11,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:11,256 INFO:     Epoch: 38
2023-01-05 04:18:13,411 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49439119597276054, 'Total loss': 0.49439119597276054} | train loss {'Reaction outcome loss': 0.2563193452719977, 'Total loss': 0.2563193452719977}
2023-01-05 04:18:13,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:13,412 INFO:     Epoch: 39
2023-01-05 04:18:15,617 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.503235266606013, 'Total loss': 0.503235266606013} | train loss {'Reaction outcome loss': 0.2539389440857306, 'Total loss': 0.2539389440857306}
2023-01-05 04:18:15,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:15,617 INFO:     Epoch: 40
2023-01-05 04:18:17,824 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5240639706452688, 'Total loss': 0.5240639706452688} | train loss {'Reaction outcome loss': 0.2442755837438871, 'Total loss': 0.2442755837438871}
2023-01-05 04:18:17,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:17,824 INFO:     Epoch: 41
2023-01-05 04:18:20,056 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49719998637835183, 'Total loss': 0.49719998637835183} | train loss {'Reaction outcome loss': 0.24092127322848905, 'Total loss': 0.24092127322848905}
2023-01-05 04:18:20,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:20,056 INFO:     Epoch: 42
2023-01-05 04:18:22,241 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.515423126022021, 'Total loss': 0.515423126022021} | train loss {'Reaction outcome loss': 0.23756766428667345, 'Total loss': 0.23756766428667345}
2023-01-05 04:18:22,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:22,241 INFO:     Epoch: 43
2023-01-05 04:18:24,490 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5034300923347473, 'Total loss': 0.5034300923347473} | train loss {'Reaction outcome loss': 0.23710783840784722, 'Total loss': 0.23710783840784722}
2023-01-05 04:18:24,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:24,491 INFO:     Epoch: 44
2023-01-05 04:18:26,729 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49490641554196674, 'Total loss': 0.49490641554196674} | train loss {'Reaction outcome loss': 0.23404600734711098, 'Total loss': 0.23404600734711098}
2023-01-05 04:18:26,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:26,729 INFO:     Epoch: 45
2023-01-05 04:18:28,910 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5307688256104787, 'Total loss': 0.5307688256104787} | train loss {'Reaction outcome loss': 0.23599427299062803, 'Total loss': 0.23599427299062803}
2023-01-05 04:18:28,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:28,910 INFO:     Epoch: 46
2023-01-05 04:18:31,140 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5110831995805104, 'Total loss': 0.5110831995805104} | train loss {'Reaction outcome loss': 0.2283094907694855, 'Total loss': 0.2283094907694855}
2023-01-05 04:18:31,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:31,140 INFO:     Epoch: 47
2023-01-05 04:18:33,342 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.495887557665507, 'Total loss': 0.495887557665507} | train loss {'Reaction outcome loss': 0.22895280821205852, 'Total loss': 0.22895280821205852}
2023-01-05 04:18:33,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:33,343 INFO:     Epoch: 48
2023-01-05 04:18:35,569 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5237652758757273, 'Total loss': 0.5237652758757273} | train loss {'Reaction outcome loss': 0.22746492315596645, 'Total loss': 0.22746492315596645}
2023-01-05 04:18:35,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:35,570 INFO:     Epoch: 49
2023-01-05 04:18:37,811 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5339796662330627, 'Total loss': 0.5339796662330627} | train loss {'Reaction outcome loss': 0.22202463217410326, 'Total loss': 0.22202463217410326}
2023-01-05 04:18:37,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:37,811 INFO:     Epoch: 50
2023-01-05 04:18:40,047 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5330112626155218, 'Total loss': 0.5330112626155218} | train loss {'Reaction outcome loss': 0.22476616506359579, 'Total loss': 0.22476616506359579}
2023-01-05 04:18:40,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:40,048 INFO:     Epoch: 51
2023-01-05 04:18:42,287 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5140776534875234, 'Total loss': 0.5140776534875234} | train loss {'Reaction outcome loss': 0.22100919264019045, 'Total loss': 0.22100919264019045}
2023-01-05 04:18:42,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:42,287 INFO:     Epoch: 52
2023-01-05 04:18:44,455 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5067990253369014, 'Total loss': 0.5067990253369014} | train loss {'Reaction outcome loss': 0.21811830956131165, 'Total loss': 0.21811830956131165}
2023-01-05 04:18:44,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:44,456 INFO:     Epoch: 53
2023-01-05 04:18:46,630 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5164959947268168, 'Total loss': 0.5164959947268168} | train loss {'Reaction outcome loss': 0.21666152647863465, 'Total loss': 0.21666152647863465}
2023-01-05 04:18:46,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:46,631 INFO:     Epoch: 54
2023-01-05 04:18:48,884 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.518807464838028, 'Total loss': 0.518807464838028} | train loss {'Reaction outcome loss': 0.21250966239629476, 'Total loss': 0.21250966239629476}
2023-01-05 04:18:48,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:48,885 INFO:     Epoch: 55
2023-01-05 04:18:51,078 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5228275040785472, 'Total loss': 0.5228275040785472} | train loss {'Reaction outcome loss': 0.21424920292085278, 'Total loss': 0.21424920292085278}
2023-01-05 04:18:51,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:51,078 INFO:     Epoch: 56
2023-01-05 04:18:53,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.553817430138588, 'Total loss': 0.553817430138588} | train loss {'Reaction outcome loss': 0.22087613744720264, 'Total loss': 0.22087613744720264}
2023-01-05 04:18:53,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:53,155 INFO:     Epoch: 57
2023-01-05 04:18:55,263 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5432391544183095, 'Total loss': 0.5432391544183095} | train loss {'Reaction outcome loss': 0.21633040893742134, 'Total loss': 0.21633040893742134}
2023-01-05 04:18:55,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:55,264 INFO:     Epoch: 58
2023-01-05 04:18:57,469 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5162771787494421, 'Total loss': 0.5162771787494421} | train loss {'Reaction outcome loss': 0.23482613884371475, 'Total loss': 0.23482613884371475}
2023-01-05 04:18:57,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:57,470 INFO:     Epoch: 59
2023-01-05 04:18:59,627 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5172248070438703, 'Total loss': 0.5172248070438703} | train loss {'Reaction outcome loss': 0.20860918764736963, 'Total loss': 0.20860918764736963}
2023-01-05 04:18:59,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:18:59,628 INFO:     Epoch: 60
2023-01-05 04:19:01,858 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5195600251356761, 'Total loss': 0.5195600251356761} | train loss {'Reaction outcome loss': 0.2154904676473065, 'Total loss': 0.2154904676473065}
2023-01-05 04:19:01,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:01,859 INFO:     Epoch: 61
2023-01-05 04:19:04,053 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5178546806176504, 'Total loss': 0.5178546806176504} | train loss {'Reaction outcome loss': 0.22787786918132147, 'Total loss': 0.22787786918132147}
2023-01-05 04:19:04,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:04,053 INFO:     Epoch: 62
2023-01-05 04:19:06,238 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5138173003991445, 'Total loss': 0.5138173003991445} | train loss {'Reaction outcome loss': 0.21307144668189457, 'Total loss': 0.21307144668189457}
2023-01-05 04:19:06,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:06,238 INFO:     Epoch: 63
2023-01-05 04:19:08,433 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5093067616224289, 'Total loss': 0.5093067616224289} | train loss {'Reaction outcome loss': 0.20621944313102902, 'Total loss': 0.20621944313102902}
2023-01-05 04:19:08,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:08,434 INFO:     Epoch: 64
2023-01-05 04:19:10,629 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5308385133743286, 'Total loss': 0.5308385133743286} | train loss {'Reaction outcome loss': 0.20848636287163294, 'Total loss': 0.20848636287163294}
2023-01-05 04:19:10,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:10,630 INFO:     Epoch: 65
2023-01-05 04:19:12,782 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5300306657950083, 'Total loss': 0.5300306657950083} | train loss {'Reaction outcome loss': 0.20454281471967883, 'Total loss': 0.20454281471967883}
2023-01-05 04:19:12,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:12,782 INFO:     Epoch: 66
2023-01-05 04:19:15,031 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5281561623016994, 'Total loss': 0.5281561623016994} | train loss {'Reaction outcome loss': 0.2101092374699268, 'Total loss': 0.2101092374699268}
2023-01-05 04:19:15,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:15,031 INFO:     Epoch: 67
2023-01-05 04:19:17,281 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5134115348259608, 'Total loss': 0.5134115348259608} | train loss {'Reaction outcome loss': 0.20277959729234377, 'Total loss': 0.20277959729234377}
2023-01-05 04:19:17,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:17,282 INFO:     Epoch: 68
2023-01-05 04:19:19,513 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5250620404879253, 'Total loss': 0.5250620404879253} | train loss {'Reaction outcome loss': 0.20711559035639832, 'Total loss': 0.20711559035639832}
2023-01-05 04:19:19,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:19,513 INFO:     Epoch: 69
2023-01-05 04:19:21,661 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5484690229098003, 'Total loss': 0.5484690229098003} | train loss {'Reaction outcome loss': 0.19580922150846058, 'Total loss': 0.19580922150846058}
2023-01-05 04:19:21,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:21,661 INFO:     Epoch: 70
2023-01-05 04:19:23,886 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.508304304877917, 'Total loss': 0.508304304877917} | train loss {'Reaction outcome loss': 0.1988059237052727, 'Total loss': 0.1988059237052727}
2023-01-05 04:19:23,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:23,887 INFO:     Epoch: 71
2023-01-05 04:19:26,137 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5524765412012737, 'Total loss': 0.5524765412012737} | train loss {'Reaction outcome loss': 0.1985038718212045, 'Total loss': 0.1985038718212045}
2023-01-05 04:19:26,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:26,137 INFO:     Epoch: 72
2023-01-05 04:19:28,316 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5233607590198517, 'Total loss': 0.5233607590198517} | train loss {'Reaction outcome loss': 0.19831835264314734, 'Total loss': 0.19831835264314734}
2023-01-05 04:19:28,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:28,316 INFO:     Epoch: 73
2023-01-05 04:19:30,551 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5124967202544213, 'Total loss': 0.5124967202544213} | train loss {'Reaction outcome loss': 0.19547922793603706, 'Total loss': 0.19547922793603706}
2023-01-05 04:19:30,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:30,551 INFO:     Epoch: 74
2023-01-05 04:19:32,741 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5650871753692627, 'Total loss': 0.5650871753692627} | train loss {'Reaction outcome loss': 0.19236067604894438, 'Total loss': 0.19236067604894438}
2023-01-05 04:19:32,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:32,741 INFO:     Epoch: 75
2023-01-05 04:19:34,963 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5514538655678431, 'Total loss': 0.5514538655678431} | train loss {'Reaction outcome loss': 0.19534039644834897, 'Total loss': 0.19534039644834897}
2023-01-05 04:19:34,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:34,963 INFO:     Epoch: 76
2023-01-05 04:19:37,144 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5590259581804276, 'Total loss': 0.5590259581804276} | train loss {'Reaction outcome loss': 0.1941231927046539, 'Total loss': 0.1941231927046539}
2023-01-05 04:19:37,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:37,145 INFO:     Epoch: 77
2023-01-05 04:19:39,461 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5624536991119384, 'Total loss': 0.5624536991119384} | train loss {'Reaction outcome loss': 0.18869623012521872, 'Total loss': 0.18869623012521872}
2023-01-05 04:19:39,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:39,462 INFO:     Epoch: 78
2023-01-05 04:19:41,748 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.535125466187795, 'Total loss': 0.535125466187795} | train loss {'Reaction outcome loss': 0.19082782763702646, 'Total loss': 0.19082782763702646}
2023-01-05 04:19:41,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:41,748 INFO:     Epoch: 79
2023-01-05 04:19:43,986 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5696311930815379, 'Total loss': 0.5696311930815379} | train loss {'Reaction outcome loss': 0.18888982361439022, 'Total loss': 0.18888982361439022}
2023-01-05 04:19:43,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:43,986 INFO:     Epoch: 80
2023-01-05 04:19:46,237 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5749720017115275, 'Total loss': 0.5749720017115275} | train loss {'Reaction outcome loss': 0.1864833834967441, 'Total loss': 0.1864833834967441}
2023-01-05 04:19:46,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:46,237 INFO:     Epoch: 81
2023-01-05 04:19:48,430 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5493095338344574, 'Total loss': 0.5493095338344574} | train loss {'Reaction outcome loss': 0.2130891057473702, 'Total loss': 0.2130891057473702}
2023-01-05 04:19:48,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:48,430 INFO:     Epoch: 82
2023-01-05 04:19:50,640 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5190817723671596, 'Total loss': 0.5190817723671596} | train loss {'Reaction outcome loss': 0.2002423736165561, 'Total loss': 0.2002423736165561}
2023-01-05 04:19:50,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:50,640 INFO:     Epoch: 83
2023-01-05 04:19:52,822 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5256953014681737, 'Total loss': 0.5256953014681737} | train loss {'Reaction outcome loss': 0.1899464317003562, 'Total loss': 0.1899464317003562}
2023-01-05 04:19:52,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:52,823 INFO:     Epoch: 84
2023-01-05 04:19:55,049 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5346997524301211, 'Total loss': 0.5346997524301211} | train loss {'Reaction outcome loss': 0.1861645399923504, 'Total loss': 0.1861645399923504}
2023-01-05 04:19:55,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:55,049 INFO:     Epoch: 85
2023-01-05 04:19:57,278 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5601474742094675, 'Total loss': 0.5601474742094675} | train loss {'Reaction outcome loss': 0.1807465153304266, 'Total loss': 0.1807465153304266}
2023-01-05 04:19:57,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:57,278 INFO:     Epoch: 86
2023-01-05 04:19:59,508 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.556047010421753, 'Total loss': 0.556047010421753} | train loss {'Reaction outcome loss': 0.18479828193169628, 'Total loss': 0.18479828193169628}
2023-01-05 04:19:59,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:19:59,509 INFO:     Epoch: 87
2023-01-05 04:20:01,690 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.54851460258166, 'Total loss': 0.54851460258166} | train loss {'Reaction outcome loss': 0.18120863572345325, 'Total loss': 0.18120863572345325}
2023-01-05 04:20:01,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:01,690 INFO:     Epoch: 88
2023-01-05 04:20:03,955 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5605533599853516, 'Total loss': 0.5605533599853516} | train loss {'Reaction outcome loss': 0.18059025000313036, 'Total loss': 0.18059025000313036}
2023-01-05 04:20:03,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:03,955 INFO:     Epoch: 89
2023-01-05 04:20:06,204 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5667552471160888, 'Total loss': 0.5667552471160888} | train loss {'Reaction outcome loss': 0.1843359105785013, 'Total loss': 0.1843359105785013}
2023-01-05 04:20:06,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:06,204 INFO:     Epoch: 90
2023-01-05 04:20:08,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5432777336798609, 'Total loss': 0.5432777336798609} | train loss {'Reaction outcome loss': 0.1829971461860544, 'Total loss': 0.1829971461860544}
2023-01-05 04:20:08,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:08,441 INFO:     Epoch: 91
2023-01-05 04:20:10,650 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5465366810560226, 'Total loss': 0.5465366810560226} | train loss {'Reaction outcome loss': 0.18551676335050285, 'Total loss': 0.18551676335050285}
2023-01-05 04:20:10,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:10,650 INFO:     Epoch: 92
2023-01-05 04:20:12,878 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5327182208498319, 'Total loss': 0.5327182208498319} | train loss {'Reaction outcome loss': 0.18058647306916892, 'Total loss': 0.18058647306916892}
2023-01-05 04:20:12,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:12,879 INFO:     Epoch: 93
2023-01-05 04:20:15,107 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5512277166048686, 'Total loss': 0.5512277166048686} | train loss {'Reaction outcome loss': 0.1785981667011702, 'Total loss': 0.1785981667011702}
2023-01-05 04:20:15,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:15,107 INFO:     Epoch: 94
2023-01-05 04:20:17,351 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5622082769870758, 'Total loss': 0.5622082769870758} | train loss {'Reaction outcome loss': 0.17840493298844312, 'Total loss': 0.17840493298844312}
2023-01-05 04:20:17,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:17,352 INFO:     Epoch: 95
2023-01-05 04:20:19,557 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.527791743973891, 'Total loss': 0.527791743973891} | train loss {'Reaction outcome loss': 0.17994132438384375, 'Total loss': 0.17994132438384375}
2023-01-05 04:20:19,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:19,558 INFO:     Epoch: 96
2023-01-05 04:20:21,740 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5750567058722178, 'Total loss': 0.5750567058722178} | train loss {'Reaction outcome loss': 0.17868875148976088, 'Total loss': 0.17868875148976088}
2023-01-05 04:20:21,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:21,740 INFO:     Epoch: 97
2023-01-05 04:20:23,922 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5348086963097255, 'Total loss': 0.5348086963097255} | train loss {'Reaction outcome loss': 0.18127820409026227, 'Total loss': 0.18127820409026227}
2023-01-05 04:20:23,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:23,922 INFO:     Epoch: 98
2023-01-05 04:20:26,151 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5529502073923747, 'Total loss': 0.5529502073923747} | train loss {'Reaction outcome loss': 0.18189065809786806, 'Total loss': 0.18189065809786806}
2023-01-05 04:20:26,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:26,151 INFO:     Epoch: 99
2023-01-05 04:20:28,274 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5549631069103876, 'Total loss': 0.5549631069103876} | train loss {'Reaction outcome loss': 0.17782346845669436, 'Total loss': 0.17782346845669436}
2023-01-05 04:20:28,275 INFO:     Best model found after epoch 21 of 100.
2023-01-05 04:20:28,276 INFO:   Done with stage: TRAINING
2023-01-05 04:20:28,276 INFO:   Starting stage: EVALUATION
2023-01-05 04:20:28,410 INFO:   Done with stage: EVALUATION
2023-01-05 04:20:28,410 INFO:   Leaving out SEQ value Fold_6
2023-01-05 04:20:28,423 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 04:20:28,423 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:20:29,078 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:20:29,078 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:20:29,151 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:20:29,152 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:20:29,152 INFO:     No hyperparam tuning for this model
2023-01-05 04:20:29,152 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:20:29,152 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:20:29,152 INFO:     None feature selector for col prot
2023-01-05 04:20:29,153 INFO:     None feature selector for col prot
2023-01-05 04:20:29,153 INFO:     None feature selector for col prot
2023-01-05 04:20:29,153 INFO:     None feature selector for col chem
2023-01-05 04:20:29,153 INFO:     None feature selector for col chem
2023-01-05 04:20:29,153 INFO:     None feature selector for col chem
2023-01-05 04:20:29,153 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:20:29,154 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:20:29,155 INFO:     Number of params in model 72931
2023-01-05 04:20:29,158 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:20:29,158 INFO:   Starting stage: TRAINING
2023-01-05 04:20:29,216 INFO:     Val loss before train {'Reaction outcome loss': 1.073284371693929, 'Total loss': 1.073284371693929}
2023-01-05 04:20:29,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:29,216 INFO:     Epoch: 0
2023-01-05 04:20:31,462 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.85680597225825, 'Total loss': 0.85680597225825} | train loss {'Reaction outcome loss': 0.9434659214226347, 'Total loss': 0.9434659214226347}
2023-01-05 04:20:31,463 INFO:     Found new best model at epoch 0
2023-01-05 04:20:31,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:31,464 INFO:     Epoch: 1
2023-01-05 04:20:33,665 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5753883977731069, 'Total loss': 0.5753883977731069} | train loss {'Reaction outcome loss': 0.6748989975409387, 'Total loss': 0.6748989975409387}
2023-01-05 04:20:33,665 INFO:     Found new best model at epoch 1
2023-01-05 04:20:33,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:33,667 INFO:     Epoch: 2
2023-01-05 04:20:35,938 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5319234907627106, 'Total loss': 0.5319234907627106} | train loss {'Reaction outcome loss': 0.5546015528995638, 'Total loss': 0.5546015528995638}
2023-01-05 04:20:35,939 INFO:     Found new best model at epoch 2
2023-01-05 04:20:35,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:35,940 INFO:     Epoch: 3
2023-01-05 04:20:38,187 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.500206301609675, 'Total loss': 0.500206301609675} | train loss {'Reaction outcome loss': 0.5039609247811865, 'Total loss': 0.5039609247811865}
2023-01-05 04:20:38,187 INFO:     Found new best model at epoch 3
2023-01-05 04:20:38,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:38,188 INFO:     Epoch: 4
2023-01-05 04:20:40,448 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5058153669039408, 'Total loss': 0.5058153669039408} | train loss {'Reaction outcome loss': 0.4746493995727615, 'Total loss': 0.4746493995727615}
2023-01-05 04:20:40,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:40,448 INFO:     Epoch: 5
2023-01-05 04:20:42,643 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48961347341537476, 'Total loss': 0.48961347341537476} | train loss {'Reaction outcome loss': 0.45367172511045684, 'Total loss': 0.45367172511045684}
2023-01-05 04:20:42,644 INFO:     Found new best model at epoch 5
2023-01-05 04:20:42,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:42,645 INFO:     Epoch: 6
2023-01-05 04:20:44,875 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49328001340230304, 'Total loss': 0.49328001340230304} | train loss {'Reaction outcome loss': 0.4336244562634062, 'Total loss': 0.4336244562634062}
2023-01-05 04:20:44,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:44,876 INFO:     Epoch: 7
2023-01-05 04:20:47,043 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4869818886121114, 'Total loss': 0.4869818886121114} | train loss {'Reaction outcome loss': 0.41739201548405075, 'Total loss': 0.41739201548405075}
2023-01-05 04:20:47,043 INFO:     Found new best model at epoch 7
2023-01-05 04:20:47,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:47,044 INFO:     Epoch: 8
2023-01-05 04:20:49,257 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46381612320741017, 'Total loss': 0.46381612320741017} | train loss {'Reaction outcome loss': 0.40404275861242617, 'Total loss': 0.40404275861242617}
2023-01-05 04:20:49,257 INFO:     Found new best model at epoch 8
2023-01-05 04:20:49,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:49,259 INFO:     Epoch: 9
2023-01-05 04:20:51,508 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49854666988054913, 'Total loss': 0.49854666988054913} | train loss {'Reaction outcome loss': 0.3871920477020611, 'Total loss': 0.3871920477020611}
2023-01-05 04:20:51,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:51,508 INFO:     Epoch: 10
2023-01-05 04:20:53,694 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4918382187684377, 'Total loss': 0.4918382187684377} | train loss {'Reaction outcome loss': 0.3746381747378339, 'Total loss': 0.3746381747378339}
2023-01-05 04:20:53,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:53,695 INFO:     Epoch: 11
2023-01-05 04:20:55,928 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49169450302918755, 'Total loss': 0.49169450302918755} | train loss {'Reaction outcome loss': 0.36617418268312185, 'Total loss': 0.36617418268312185}
2023-01-05 04:20:55,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:55,929 INFO:     Epoch: 12
2023-01-05 04:20:58,177 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4716832002003988, 'Total loss': 0.4716832002003988} | train loss {'Reaction outcome loss': 0.35510191944047864, 'Total loss': 0.35510191944047864}
2023-01-05 04:20:58,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:20:58,177 INFO:     Epoch: 13
2023-01-05 04:21:00,360 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4867790063222249, 'Total loss': 0.4867790063222249} | train loss {'Reaction outcome loss': 0.34860577689826705, 'Total loss': 0.34860577689826705}
2023-01-05 04:21:00,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:00,361 INFO:     Epoch: 14
2023-01-05 04:21:02,494 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4988905727863312, 'Total loss': 0.4988905727863312} | train loss {'Reaction outcome loss': 0.3376328395108023, 'Total loss': 0.3376328395108023}
2023-01-05 04:21:02,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:02,494 INFO:     Epoch: 15
2023-01-05 04:21:04,724 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4971105655034383, 'Total loss': 0.4971105655034383} | train loss {'Reaction outcome loss': 0.3317175533366978, 'Total loss': 0.3317175533366978}
2023-01-05 04:21:04,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:04,725 INFO:     Epoch: 16
2023-01-05 04:21:06,941 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49047292868296305, 'Total loss': 0.49047292868296305} | train loss {'Reaction outcome loss': 0.3163994245284946, 'Total loss': 0.3163994245284946}
2023-01-05 04:21:06,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:06,942 INFO:     Epoch: 17
2023-01-05 04:21:09,179 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4831792195638021, 'Total loss': 0.4831792195638021} | train loss {'Reaction outcome loss': 0.31214332755399526, 'Total loss': 0.31214332755399526}
2023-01-05 04:21:09,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:09,179 INFO:     Epoch: 18
2023-01-05 04:21:11,394 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.503928882877032, 'Total loss': 0.503928882877032} | train loss {'Reaction outcome loss': 0.3058405799071711, 'Total loss': 0.3058405799071711}
2023-01-05 04:21:11,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:11,395 INFO:     Epoch: 19
2023-01-05 04:21:13,598 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48623995780944823, 'Total loss': 0.48623995780944823} | train loss {'Reaction outcome loss': 0.3039471001939223, 'Total loss': 0.3039471001939223}
2023-01-05 04:21:13,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:13,598 INFO:     Epoch: 20
2023-01-05 04:21:15,823 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4972143888473511, 'Total loss': 0.4972143888473511} | train loss {'Reaction outcome loss': 0.29630904327338353, 'Total loss': 0.29630904327338353}
2023-01-05 04:21:15,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:15,823 INFO:     Epoch: 21
2023-01-05 04:21:18,035 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48163572549819944, 'Total loss': 0.48163572549819944} | train loss {'Reaction outcome loss': 0.2916626226600757, 'Total loss': 0.2916626226600757}
2023-01-05 04:21:18,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:18,035 INFO:     Epoch: 22
2023-01-05 04:21:20,236 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45418070554733275, 'Total loss': 0.45418070554733275} | train loss {'Reaction outcome loss': 0.2851942402952845, 'Total loss': 0.2851942402952845}
2023-01-05 04:21:20,236 INFO:     Found new best model at epoch 22
2023-01-05 04:21:20,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:20,237 INFO:     Epoch: 23
2023-01-05 04:21:22,478 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4974562883377075, 'Total loss': 0.4974562883377075} | train loss {'Reaction outcome loss': 0.282898884824736, 'Total loss': 0.282898884824736}
2023-01-05 04:21:22,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:22,478 INFO:     Epoch: 24
2023-01-05 04:21:24,731 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5008535196383794, 'Total loss': 0.5008535196383794} | train loss {'Reaction outcome loss': 0.27665804169184466, 'Total loss': 0.27665804169184466}
2023-01-05 04:21:24,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:24,732 INFO:     Epoch: 25
2023-01-05 04:21:26,959 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49806744952996573, 'Total loss': 0.49806744952996573} | train loss {'Reaction outcome loss': 0.27023760047119233, 'Total loss': 0.27023760047119233}
2023-01-05 04:21:26,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:26,959 INFO:     Epoch: 26
2023-01-05 04:21:29,184 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49315268198649087, 'Total loss': 0.49315268198649087} | train loss {'Reaction outcome loss': 0.2677000466774517, 'Total loss': 0.2677000466774517}
2023-01-05 04:21:29,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:29,184 INFO:     Epoch: 27
2023-01-05 04:21:31,330 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4973614240686099, 'Total loss': 0.4973614240686099} | train loss {'Reaction outcome loss': 0.25862652950984044, 'Total loss': 0.25862652950984044}
2023-01-05 04:21:31,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:31,330 INFO:     Epoch: 28
2023-01-05 04:21:33,596 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5021557927131652, 'Total loss': 0.5021557927131652} | train loss {'Reaction outcome loss': 0.25803169772526524, 'Total loss': 0.25803169772526524}
2023-01-05 04:21:33,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:33,596 INFO:     Epoch: 29
2023-01-05 04:21:35,868 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4930187145868937, 'Total loss': 0.4930187145868937} | train loss {'Reaction outcome loss': 0.25884090489052264, 'Total loss': 0.25884090489052264}
2023-01-05 04:21:35,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:35,869 INFO:     Epoch: 30
2023-01-05 04:21:38,102 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48793900907039645, 'Total loss': 0.48793900907039645} | train loss {'Reaction outcome loss': 0.2549617982701489, 'Total loss': 0.2549617982701489}
2023-01-05 04:21:38,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:38,103 INFO:     Epoch: 31
2023-01-05 04:21:40,298 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4963712347050508, 'Total loss': 0.4963712347050508} | train loss {'Reaction outcome loss': 0.24778495634156228, 'Total loss': 0.24778495634156228}
2023-01-05 04:21:40,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:40,298 INFO:     Epoch: 32
2023-01-05 04:21:42,470 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49815996587276457, 'Total loss': 0.49815996587276457} | train loss {'Reaction outcome loss': 0.24720838901314496, 'Total loss': 0.24720838901314496}
2023-01-05 04:21:42,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:42,471 INFO:     Epoch: 33
2023-01-05 04:21:44,683 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4729061295588811, 'Total loss': 0.4729061295588811} | train loss {'Reaction outcome loss': 0.23919983201455122, 'Total loss': 0.23919983201455122}
2023-01-05 04:21:44,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:44,683 INFO:     Epoch: 34
2023-01-05 04:21:46,931 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4793095737695694, 'Total loss': 0.4793095737695694} | train loss {'Reaction outcome loss': 0.24186246123312827, 'Total loss': 0.24186246123312827}
2023-01-05 04:21:46,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:46,931 INFO:     Epoch: 35
2023-01-05 04:21:49,211 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49483220477898915, 'Total loss': 0.49483220477898915} | train loss {'Reaction outcome loss': 0.2418664745744385, 'Total loss': 0.2418664745744385}
2023-01-05 04:21:49,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:49,211 INFO:     Epoch: 36
2023-01-05 04:21:51,442 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48075854976971943, 'Total loss': 0.48075854976971943} | train loss {'Reaction outcome loss': 0.23682467094101414, 'Total loss': 0.23682467094101414}
2023-01-05 04:21:51,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:51,442 INFO:     Epoch: 37
2023-01-05 04:21:53,732 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49145929515361786, 'Total loss': 0.49145929515361786} | train loss {'Reaction outcome loss': 0.23210633304037342, 'Total loss': 0.23210633304037342}
2023-01-05 04:21:53,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:53,732 INFO:     Epoch: 38
2023-01-05 04:21:55,997 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4997808635234833, 'Total loss': 0.4997808635234833} | train loss {'Reaction outcome loss': 0.23218686005188025, 'Total loss': 0.23218686005188025}
2023-01-05 04:21:55,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:55,998 INFO:     Epoch: 39
2023-01-05 04:21:58,265 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4645818700393041, 'Total loss': 0.4645818700393041} | train loss {'Reaction outcome loss': 0.23050312957447358, 'Total loss': 0.23050312957447358}
2023-01-05 04:21:58,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:21:58,265 INFO:     Epoch: 40
2023-01-05 04:22:00,535 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47708295385042826, 'Total loss': 0.47708295385042826} | train loss {'Reaction outcome loss': 0.22781476082569424, 'Total loss': 0.22781476082569424}
2023-01-05 04:22:00,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:00,536 INFO:     Epoch: 41
2023-01-05 04:22:02,792 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4717379331588745, 'Total loss': 0.4717379331588745} | train loss {'Reaction outcome loss': 0.22398959900444165, 'Total loss': 0.22398959900444165}
2023-01-05 04:22:02,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:02,792 INFO:     Epoch: 42
2023-01-05 04:22:05,042 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5026864260435104, 'Total loss': 0.5026864260435104} | train loss {'Reaction outcome loss': 0.22216012392744475, 'Total loss': 0.22216012392744475}
2023-01-05 04:22:05,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:05,043 INFO:     Epoch: 43
2023-01-05 04:22:07,277 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4560668269793193, 'Total loss': 0.4560668269793193} | train loss {'Reaction outcome loss': 0.2226038445728673, 'Total loss': 0.2226038445728673}
2023-01-05 04:22:07,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:07,277 INFO:     Epoch: 44
2023-01-05 04:22:09,545 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48978601694107055, 'Total loss': 0.48978601694107055} | train loss {'Reaction outcome loss': 0.22031295816632598, 'Total loss': 0.22031295816632598}
2023-01-05 04:22:09,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:09,545 INFO:     Epoch: 45
2023-01-05 04:22:11,778 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4856155335903168, 'Total loss': 0.4856155335903168} | train loss {'Reaction outcome loss': 0.21951120270126995, 'Total loss': 0.21951120270126995}
2023-01-05 04:22:11,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:11,779 INFO:     Epoch: 46
2023-01-05 04:22:14,025 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47453686396280925, 'Total loss': 0.47453686396280925} | train loss {'Reaction outcome loss': 0.21377625473058826, 'Total loss': 0.21377625473058826}
2023-01-05 04:22:14,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:14,025 INFO:     Epoch: 47
2023-01-05 04:22:16,222 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4786943266789118, 'Total loss': 0.4786943266789118} | train loss {'Reaction outcome loss': 0.2130659833779081, 'Total loss': 0.2130659833779081}
2023-01-05 04:22:16,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:16,222 INFO:     Epoch: 48
2023-01-05 04:22:18,411 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4691350072622299, 'Total loss': 0.4691350072622299} | train loss {'Reaction outcome loss': 0.21130252517894288, 'Total loss': 0.21130252517894288}
2023-01-05 04:22:18,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:18,412 INFO:     Epoch: 49
2023-01-05 04:22:20,649 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45991867731014885, 'Total loss': 0.45991867731014885} | train loss {'Reaction outcome loss': 0.21208161435725456, 'Total loss': 0.21208161435725456}
2023-01-05 04:22:20,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:20,650 INFO:     Epoch: 50
2023-01-05 04:22:22,864 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5017236262559891, 'Total loss': 0.5017236262559891} | train loss {'Reaction outcome loss': 0.20959559946391557, 'Total loss': 0.20959559946391557}
2023-01-05 04:22:22,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:22,864 INFO:     Epoch: 51
2023-01-05 04:22:25,140 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47445101141929624, 'Total loss': 0.47445101141929624} | train loss {'Reaction outcome loss': 0.2077060166194981, 'Total loss': 0.2077060166194981}
2023-01-05 04:22:25,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:25,141 INFO:     Epoch: 52
2023-01-05 04:22:27,292 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.499875541528066, 'Total loss': 0.499875541528066} | train loss {'Reaction outcome loss': 0.2075500935282464, 'Total loss': 0.2075500935282464}
2023-01-05 04:22:27,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:27,292 INFO:     Epoch: 53
2023-01-05 04:22:29,521 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48169571757316587, 'Total loss': 0.48169571757316587} | train loss {'Reaction outcome loss': 0.20461513229144823, 'Total loss': 0.20461513229144823}
2023-01-05 04:22:29,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:29,521 INFO:     Epoch: 54
2023-01-05 04:22:31,786 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47563916047414145, 'Total loss': 0.47563916047414145} | train loss {'Reaction outcome loss': 0.20575427859920725, 'Total loss': 0.20575427859920725}
2023-01-05 04:22:31,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:31,786 INFO:     Epoch: 55
2023-01-05 04:22:34,061 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47797755897045135, 'Total loss': 0.47797755897045135} | train loss {'Reaction outcome loss': 0.19763434012269177, 'Total loss': 0.19763434012269177}
2023-01-05 04:22:34,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:34,062 INFO:     Epoch: 56
2023-01-05 04:22:36,341 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4638061245282491, 'Total loss': 0.4638061245282491} | train loss {'Reaction outcome loss': 0.20011457531554927, 'Total loss': 0.20011457531554927}
2023-01-05 04:22:36,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:36,342 INFO:     Epoch: 57
2023-01-05 04:22:38,614 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.521582109729449, 'Total loss': 0.521582109729449} | train loss {'Reaction outcome loss': 0.20587103828680214, 'Total loss': 0.20587103828680214}
2023-01-05 04:22:38,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:38,615 INFO:     Epoch: 58
2023-01-05 04:22:40,891 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49455768465995786, 'Total loss': 0.49455768465995786} | train loss {'Reaction outcome loss': 0.20137637362408617, 'Total loss': 0.20137637362408617}
2023-01-05 04:22:40,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:40,892 INFO:     Epoch: 59
2023-01-05 04:22:43,151 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48699403802553815, 'Total loss': 0.48699403802553815} | train loss {'Reaction outcome loss': 0.19971942345339416, 'Total loss': 0.19971942345339416}
2023-01-05 04:22:43,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:43,152 INFO:     Epoch: 60
2023-01-05 04:22:45,438 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49314488768577575, 'Total loss': 0.49314488768577575} | train loss {'Reaction outcome loss': 0.20152773547056888, 'Total loss': 0.20152773547056888}
2023-01-05 04:22:45,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:45,438 INFO:     Epoch: 61
2023-01-05 04:22:47,727 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48589580655097964, 'Total loss': 0.48589580655097964} | train loss {'Reaction outcome loss': 0.1958425129471273, 'Total loss': 0.1958425129471273}
2023-01-05 04:22:47,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:47,728 INFO:     Epoch: 62
2023-01-05 04:22:49,997 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5057880779107412, 'Total loss': 0.5057880779107412} | train loss {'Reaction outcome loss': 0.1931998633581217, 'Total loss': 0.1931998633581217}
2023-01-05 04:22:49,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:49,997 INFO:     Epoch: 63
2023-01-05 04:22:52,286 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4709949091076851, 'Total loss': 0.4709949091076851} | train loss {'Reaction outcome loss': 0.19252514567508594, 'Total loss': 0.19252514567508594}
2023-01-05 04:22:52,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:52,286 INFO:     Epoch: 64
2023-01-05 04:22:54,549 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4782578726609548, 'Total loss': 0.4782578726609548} | train loss {'Reaction outcome loss': 0.19157741759443112, 'Total loss': 0.19157741759443112}
2023-01-05 04:22:54,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:54,549 INFO:     Epoch: 65
2023-01-05 04:22:56,842 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5008580545584361, 'Total loss': 0.5008580545584361} | train loss {'Reaction outcome loss': 0.19232537038960504, 'Total loss': 0.19232537038960504}
2023-01-05 04:22:56,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:56,843 INFO:     Epoch: 66
2023-01-05 04:22:58,959 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4635186970233917, 'Total loss': 0.4635186970233917} | train loss {'Reaction outcome loss': 0.19585942808666437, 'Total loss': 0.19585942808666437}
2023-01-05 04:22:58,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:22:58,960 INFO:     Epoch: 67
2023-01-05 04:23:01,224 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5018888453642527, 'Total loss': 0.5018888453642527} | train loss {'Reaction outcome loss': 0.18900607147048956, 'Total loss': 0.18900607147048956}
2023-01-05 04:23:01,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:01,224 INFO:     Epoch: 68
2023-01-05 04:23:03,513 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4497062176465988, 'Total loss': 0.4497062176465988} | train loss {'Reaction outcome loss': 0.18732366493368516, 'Total loss': 0.18732366493368516}
2023-01-05 04:23:03,513 INFO:     Found new best model at epoch 68
2023-01-05 04:23:03,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:03,515 INFO:     Epoch: 69
2023-01-05 04:23:05,777 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4910212422410647, 'Total loss': 0.4910212422410647} | train loss {'Reaction outcome loss': 0.18734486940037795, 'Total loss': 0.18734486940037795}
2023-01-05 04:23:05,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:05,778 INFO:     Epoch: 70
2023-01-05 04:23:08,076 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48769192496935526, 'Total loss': 0.48769192496935526} | train loss {'Reaction outcome loss': 0.1886604368226058, 'Total loss': 0.1886604368226058}
2023-01-05 04:23:08,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:08,076 INFO:     Epoch: 71
2023-01-05 04:23:10,367 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4644841680924098, 'Total loss': 0.4644841680924098} | train loss {'Reaction outcome loss': 0.18518834143191146, 'Total loss': 0.18518834143191146}
2023-01-05 04:23:10,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:10,367 INFO:     Epoch: 72
2023-01-05 04:23:12,636 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45677827994028725, 'Total loss': 0.45677827994028725} | train loss {'Reaction outcome loss': 0.18249937289794538, 'Total loss': 0.18249937289794538}
2023-01-05 04:23:12,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:12,637 INFO:     Epoch: 73
2023-01-05 04:23:14,900 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46516705950101217, 'Total loss': 0.46516705950101217} | train loss {'Reaction outcome loss': 0.18833288092448608, 'Total loss': 0.18833288092448608}
2023-01-05 04:23:14,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:14,901 INFO:     Epoch: 74
2023-01-05 04:23:17,195 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4558050165573756, 'Total loss': 0.4558050165573756} | train loss {'Reaction outcome loss': 0.18020597443535977, 'Total loss': 0.18020597443535977}
2023-01-05 04:23:17,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:17,195 INFO:     Epoch: 75
2023-01-05 04:23:19,447 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4934856563806534, 'Total loss': 0.4934856563806534} | train loss {'Reaction outcome loss': 0.18235602839227888, 'Total loss': 0.18235602839227888}
2023-01-05 04:23:19,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:19,448 INFO:     Epoch: 76
2023-01-05 04:23:21,691 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47540862758954366, 'Total loss': 0.47540862758954366} | train loss {'Reaction outcome loss': 0.1823169465650828, 'Total loss': 0.1823169465650828}
2023-01-05 04:23:21,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:21,692 INFO:     Epoch: 77
2023-01-05 04:23:23,944 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47444742619991304, 'Total loss': 0.47444742619991304} | train loss {'Reaction outcome loss': 0.18547706646400938, 'Total loss': 0.18547706646400938}
2023-01-05 04:23:23,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:23,944 INFO:     Epoch: 78
2023-01-05 04:23:26,207 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47656757235527036, 'Total loss': 0.47656757235527036} | train loss {'Reaction outcome loss': 0.1765642167280835, 'Total loss': 0.1765642167280835}
2023-01-05 04:23:26,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:26,207 INFO:     Epoch: 79
2023-01-05 04:23:28,467 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.482324563463529, 'Total loss': 0.482324563463529} | train loss {'Reaction outcome loss': 0.17826218908780425, 'Total loss': 0.17826218908780425}
2023-01-05 04:23:28,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:28,468 INFO:     Epoch: 80
2023-01-05 04:23:30,720 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47622443238894147, 'Total loss': 0.47622443238894147} | train loss {'Reaction outcome loss': 0.18077768548139597, 'Total loss': 0.18077768548139597}
2023-01-05 04:23:30,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:30,720 INFO:     Epoch: 81
2023-01-05 04:23:32,981 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4764750753839811, 'Total loss': 0.4764750753839811} | train loss {'Reaction outcome loss': 0.1734070770445848, 'Total loss': 0.1734070770445848}
2023-01-05 04:23:32,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:32,982 INFO:     Epoch: 82
2023-01-05 04:23:35,235 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4659888645013173, 'Total loss': 0.4659888645013173} | train loss {'Reaction outcome loss': 0.1811809623311358, 'Total loss': 0.1811809623311358}
2023-01-05 04:23:35,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:35,236 INFO:     Epoch: 83
2023-01-05 04:23:37,491 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.467976192633311, 'Total loss': 0.467976192633311} | train loss {'Reaction outcome loss': 0.17952284760544554, 'Total loss': 0.17952284760544554}
2023-01-05 04:23:37,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:37,491 INFO:     Epoch: 84
2023-01-05 04:23:39,758 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48121208846569063, 'Total loss': 0.48121208846569063} | train loss {'Reaction outcome loss': 0.1729857518971437, 'Total loss': 0.1729857518971437}
2023-01-05 04:23:39,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:39,758 INFO:     Epoch: 85
2023-01-05 04:23:42,011 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4987037082513173, 'Total loss': 0.4987037082513173} | train loss {'Reaction outcome loss': 0.1755206373550455, 'Total loss': 0.1755206373550455}
2023-01-05 04:23:42,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:42,011 INFO:     Epoch: 86
2023-01-05 04:23:44,285 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4922585686047872, 'Total loss': 0.4922585686047872} | train loss {'Reaction outcome loss': 0.17022221685061062, 'Total loss': 0.17022221685061062}
2023-01-05 04:23:44,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:44,286 INFO:     Epoch: 87
2023-01-05 04:23:46,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4604197223981222, 'Total loss': 0.4604197223981222} | train loss {'Reaction outcome loss': 0.17855477678868584, 'Total loss': 0.17855477678868584}
2023-01-05 04:23:46,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:46,507 INFO:     Epoch: 88
2023-01-05 04:23:48,748 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4712125241756439, 'Total loss': 0.4712125241756439} | train loss {'Reaction outcome loss': 0.1711713919510211, 'Total loss': 0.1711713919510211}
2023-01-05 04:23:48,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:48,749 INFO:     Epoch: 89
2023-01-05 04:23:51,008 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4716327418883642, 'Total loss': 0.4716327418883642} | train loss {'Reaction outcome loss': 0.16951333429993867, 'Total loss': 0.16951333429993867}
2023-01-05 04:23:51,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:51,008 INFO:     Epoch: 90
2023-01-05 04:23:53,217 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4751569827397664, 'Total loss': 0.4751569827397664} | train loss {'Reaction outcome loss': 0.16601102808591262, 'Total loss': 0.16601102808591262}
2023-01-05 04:23:53,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:53,217 INFO:     Epoch: 91
2023-01-05 04:23:55,472 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4839063545068105, 'Total loss': 0.4839063545068105} | train loss {'Reaction outcome loss': 0.1720822285692668, 'Total loss': 0.1720822285692668}
2023-01-05 04:23:55,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:55,473 INFO:     Epoch: 92
2023-01-05 04:23:57,711 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4628601978222529, 'Total loss': 0.4628601978222529} | train loss {'Reaction outcome loss': 0.17366011862034508, 'Total loss': 0.17366011862034508}
2023-01-05 04:23:57,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:57,711 INFO:     Epoch: 93
2023-01-05 04:23:59,898 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4849951773881912, 'Total loss': 0.4849951773881912} | train loss {'Reaction outcome loss': 0.17318877568703803, 'Total loss': 0.17318877568703803}
2023-01-05 04:23:59,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:23:59,898 INFO:     Epoch: 94
2023-01-05 04:24:02,147 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4732467698554198, 'Total loss': 0.4732467698554198} | train loss {'Reaction outcome loss': 0.17006412532099854, 'Total loss': 0.17006412532099854}
2023-01-05 04:24:02,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:02,147 INFO:     Epoch: 95
2023-01-05 04:24:04,325 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46805965503056846, 'Total loss': 0.46805965503056846} | train loss {'Reaction outcome loss': 0.17189447939503494, 'Total loss': 0.17189447939503494}
2023-01-05 04:24:04,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:04,325 INFO:     Epoch: 96
2023-01-05 04:24:06,549 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4701677769422531, 'Total loss': 0.4701677769422531} | train loss {'Reaction outcome loss': 0.1660620035496053, 'Total loss': 0.1660620035496053}
2023-01-05 04:24:06,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:06,550 INFO:     Epoch: 97
2023-01-05 04:24:08,809 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4890255630016327, 'Total loss': 0.4890255630016327} | train loss {'Reaction outcome loss': 0.17008552152918996, 'Total loss': 0.17008552152918996}
2023-01-05 04:24:08,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:08,810 INFO:     Epoch: 98
2023-01-05 04:24:10,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49703187346458433, 'Total loss': 0.49703187346458433} | train loss {'Reaction outcome loss': 0.16848353297863197, 'Total loss': 0.16848353297863197}
2023-01-05 04:24:10,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:10,971 INFO:     Epoch: 99
2023-01-05 04:24:13,134 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4690559536218643, 'Total loss': 0.4690559536218643} | train loss {'Reaction outcome loss': 0.1654285587242633, 'Total loss': 0.1654285587242633}
2023-01-05 04:24:13,135 INFO:     Best model found after epoch 69 of 100.
2023-01-05 04:24:13,135 INFO:   Done with stage: TRAINING
2023-01-05 04:24:13,135 INFO:   Starting stage: EVALUATION
2023-01-05 04:24:13,263 INFO:   Done with stage: EVALUATION
2023-01-05 04:24:13,264 INFO:   Leaving out SEQ value Fold_7
2023-01-05 04:24:13,276 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:24:13,276 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:24:13,923 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:24:13,924 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:24:13,996 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:24:13,997 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:24:13,997 INFO:     No hyperparam tuning for this model
2023-01-05 04:24:13,997 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:24:13,997 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:24:13,997 INFO:     None feature selector for col prot
2023-01-05 04:24:13,998 INFO:     None feature selector for col prot
2023-01-05 04:24:13,998 INFO:     None feature selector for col prot
2023-01-05 04:24:13,998 INFO:     None feature selector for col chem
2023-01-05 04:24:13,998 INFO:     None feature selector for col chem
2023-01-05 04:24:13,998 INFO:     None feature selector for col chem
2023-01-05 04:24:13,998 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:24:13,998 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:24:14,000 INFO:     Number of params in model 72931
2023-01-05 04:24:14,003 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:24:14,003 INFO:   Starting stage: TRAINING
2023-01-05 04:24:14,064 INFO:     Val loss before train {'Reaction outcome loss': 0.9621288498242696, 'Total loss': 0.9621288498242696}
2023-01-05 04:24:14,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:14,064 INFO:     Epoch: 0
2023-01-05 04:24:16,261 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7239514708518981, 'Total loss': 0.7239514708518981} | train loss {'Reaction outcome loss': 0.9205261708196738, 'Total loss': 0.9205261708196738}
2023-01-05 04:24:16,261 INFO:     Found new best model at epoch 0
2023-01-05 04:24:16,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:16,262 INFO:     Epoch: 1
2023-01-05 04:24:18,496 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5369846959908803, 'Total loss': 0.5369846959908803} | train loss {'Reaction outcome loss': 0.6126711168663873, 'Total loss': 0.6126711168663873}
2023-01-05 04:24:18,496 INFO:     Found new best model at epoch 1
2023-01-05 04:24:18,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:18,498 INFO:     Epoch: 2
2023-01-05 04:24:20,745 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4921523630619049, 'Total loss': 0.4921523630619049} | train loss {'Reaction outcome loss': 0.5225879556458929, 'Total loss': 0.5225879556458929}
2023-01-05 04:24:20,745 INFO:     Found new best model at epoch 2
2023-01-05 04:24:20,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:20,747 INFO:     Epoch: 3
2023-01-05 04:24:23,006 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4599107563495636, 'Total loss': 0.4599107563495636} | train loss {'Reaction outcome loss': 0.489983257567645, 'Total loss': 0.489983257567645}
2023-01-05 04:24:23,006 INFO:     Found new best model at epoch 3
2023-01-05 04:24:23,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:23,007 INFO:     Epoch: 4
2023-01-05 04:24:25,267 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45221416155497235, 'Total loss': 0.45221416155497235} | train loss {'Reaction outcome loss': 0.45776768248069327, 'Total loss': 0.45776768248069327}
2023-01-05 04:24:25,268 INFO:     Found new best model at epoch 4
2023-01-05 04:24:25,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:25,270 INFO:     Epoch: 5
2023-01-05 04:24:27,520 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4155982812245687, 'Total loss': 0.4155982812245687} | train loss {'Reaction outcome loss': 0.43964448367393966, 'Total loss': 0.43964448367393966}
2023-01-05 04:24:27,520 INFO:     Found new best model at epoch 5
2023-01-05 04:24:27,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:27,521 INFO:     Epoch: 6
2023-01-05 04:24:29,759 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4197179079055786, 'Total loss': 0.4197179079055786} | train loss {'Reaction outcome loss': 0.4176424614818551, 'Total loss': 0.4176424614818551}
2023-01-05 04:24:29,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:29,760 INFO:     Epoch: 7
2023-01-05 04:24:31,903 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4150011718273163, 'Total loss': 0.4150011718273163} | train loss {'Reaction outcome loss': 0.40423678371893323, 'Total loss': 0.40423678371893323}
2023-01-05 04:24:31,904 INFO:     Found new best model at epoch 7
2023-01-05 04:24:31,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:31,905 INFO:     Epoch: 8
2023-01-05 04:24:34,016 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3799479107062022, 'Total loss': 0.3799479107062022} | train loss {'Reaction outcome loss': 0.3964752287948099, 'Total loss': 0.3964752287948099}
2023-01-05 04:24:34,016 INFO:     Found new best model at epoch 8
2023-01-05 04:24:34,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:34,017 INFO:     Epoch: 9
2023-01-05 04:24:36,277 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3881416807572047, 'Total loss': 0.3881416807572047} | train loss {'Reaction outcome loss': 0.3786542857022774, 'Total loss': 0.3786542857022774}
2023-01-05 04:24:36,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:36,277 INFO:     Epoch: 10
2023-01-05 04:24:38,502 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38807734151681267, 'Total loss': 0.38807734151681267} | train loss {'Reaction outcome loss': 0.3637442332137784, 'Total loss': 0.3637442332137784}
2023-01-05 04:24:38,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:38,503 INFO:     Epoch: 11
2023-01-05 04:24:40,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39747766256332395, 'Total loss': 0.39747766256332395} | train loss {'Reaction outcome loss': 0.358767018621396, 'Total loss': 0.358767018621396}
2023-01-05 04:24:40,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:40,716 INFO:     Epoch: 12
2023-01-05 04:24:42,956 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3958543101946513, 'Total loss': 0.3958543101946513} | train loss {'Reaction outcome loss': 0.3511529527064683, 'Total loss': 0.3511529527064683}
2023-01-05 04:24:42,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:42,956 INFO:     Epoch: 13
2023-01-05 04:24:45,167 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4259526073932648, 'Total loss': 0.4259526073932648} | train loss {'Reaction outcome loss': 0.3464359404330236, 'Total loss': 0.3464359404330236}
2023-01-05 04:24:45,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:45,168 INFO:     Epoch: 14
2023-01-05 04:24:47,416 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39994973738988243, 'Total loss': 0.39994973738988243} | train loss {'Reaction outcome loss': 0.33992676200358657, 'Total loss': 0.33992676200358657}
2023-01-05 04:24:47,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:47,416 INFO:     Epoch: 15
2023-01-05 04:24:49,627 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40297648509343464, 'Total loss': 0.40297648509343464} | train loss {'Reaction outcome loss': 0.32008570065532904, 'Total loss': 0.32008570065532904}
2023-01-05 04:24:49,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:49,627 INFO:     Epoch: 16
2023-01-05 04:24:51,856 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42854801615079247, 'Total loss': 0.42854801615079247} | train loss {'Reaction outcome loss': 0.327590408883449, 'Total loss': 0.327590408883449}
2023-01-05 04:24:51,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:51,857 INFO:     Epoch: 17
2023-01-05 04:24:54,116 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3969560921192169, 'Total loss': 0.3969560921192169} | train loss {'Reaction outcome loss': 0.32959069457202544, 'Total loss': 0.32959069457202544}
2023-01-05 04:24:54,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:54,117 INFO:     Epoch: 18
2023-01-05 04:24:56,353 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42535254259904226, 'Total loss': 0.42535254259904226} | train loss {'Reaction outcome loss': 0.30834325110418315, 'Total loss': 0.30834325110418315}
2023-01-05 04:24:56,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:56,354 INFO:     Epoch: 19
2023-01-05 04:24:58,613 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42275820175806683, 'Total loss': 0.42275820175806683} | train loss {'Reaction outcome loss': 0.3029354589803995, 'Total loss': 0.3029354589803995}
2023-01-05 04:24:58,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:24:58,613 INFO:     Epoch: 20
2023-01-05 04:25:00,873 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42999632308880487, 'Total loss': 0.42999632308880487} | train loss {'Reaction outcome loss': 0.2929577631116642, 'Total loss': 0.2929577631116642}
2023-01-05 04:25:00,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:00,873 INFO:     Epoch: 21
2023-01-05 04:25:03,125 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4370755627130469, 'Total loss': 0.4370755627130469} | train loss {'Reaction outcome loss': 0.29093461968949524, 'Total loss': 0.29093461968949524}
2023-01-05 04:25:03,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:03,126 INFO:     Epoch: 22
2023-01-05 04:25:05,371 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42874934275945026, 'Total loss': 0.42874934275945026} | train loss {'Reaction outcome loss': 0.2893812624760081, 'Total loss': 0.2893812624760081}
2023-01-05 04:25:05,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:05,371 INFO:     Epoch: 23
2023-01-05 04:25:07,619 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41446778426567715, 'Total loss': 0.41446778426567715} | train loss {'Reaction outcome loss': 0.2825399096245351, 'Total loss': 0.2825399096245351}
2023-01-05 04:25:07,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:07,619 INFO:     Epoch: 24
2023-01-05 04:25:09,879 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.438195342818896, 'Total loss': 0.438195342818896} | train loss {'Reaction outcome loss': 0.2779497229696616, 'Total loss': 0.2779497229696616}
2023-01-05 04:25:09,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:09,879 INFO:     Epoch: 25
2023-01-05 04:25:12,129 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42311045626799265, 'Total loss': 0.42311045626799265} | train loss {'Reaction outcome loss': 0.27539046655621624, 'Total loss': 0.27539046655621624}
2023-01-05 04:25:12,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:12,129 INFO:     Epoch: 26
2023-01-05 04:25:14,281 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44968461493651074, 'Total loss': 0.44968461493651074} | train loss {'Reaction outcome loss': 0.2724459666363976, 'Total loss': 0.2724459666363976}
2023-01-05 04:25:14,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:14,281 INFO:     Epoch: 27
2023-01-05 04:25:16,455 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45264182090759275, 'Total loss': 0.45264182090759275} | train loss {'Reaction outcome loss': 0.2668350445649897, 'Total loss': 0.2668350445649897}
2023-01-05 04:25:16,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:16,456 INFO:     Epoch: 28
2023-01-05 04:25:18,704 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4312389853099982, 'Total loss': 0.4312389853099982} | train loss {'Reaction outcome loss': 0.26561842524055124, 'Total loss': 0.26561842524055124}
2023-01-05 04:25:18,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:18,704 INFO:     Epoch: 29
2023-01-05 04:25:20,961 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4383418758710225, 'Total loss': 0.4383418758710225} | train loss {'Reaction outcome loss': 0.2608701952495207, 'Total loss': 0.2608701952495207}
2023-01-05 04:25:20,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:20,961 INFO:     Epoch: 30
2023-01-05 04:25:23,226 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4598925153414408, 'Total loss': 0.4598925153414408} | train loss {'Reaction outcome loss': 0.2597785686944996, 'Total loss': 0.2597785686944996}
2023-01-05 04:25:23,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:23,226 INFO:     Epoch: 31
2023-01-05 04:25:25,485 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42445240964492165, 'Total loss': 0.42445240964492165} | train loss {'Reaction outcome loss': 0.26820644456893206, 'Total loss': 0.26820644456893206}
2023-01-05 04:25:25,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:25,486 INFO:     Epoch: 32
2023-01-05 04:25:27,727 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4399121329188347, 'Total loss': 0.4399121329188347} | train loss {'Reaction outcome loss': 0.2752922426747239, 'Total loss': 0.2752922426747239}
2023-01-05 04:25:27,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:27,727 INFO:     Epoch: 33
2023-01-05 04:25:29,974 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43935123284657795, 'Total loss': 0.43935123284657795} | train loss {'Reaction outcome loss': 0.2538210108853201, 'Total loss': 0.2538210108853201}
2023-01-05 04:25:29,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:29,975 INFO:     Epoch: 34
2023-01-05 04:25:32,213 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43517452776432036, 'Total loss': 0.43517452776432036} | train loss {'Reaction outcome loss': 0.2452509000600464, 'Total loss': 0.2452509000600464}
2023-01-05 04:25:32,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:32,214 INFO:     Epoch: 35
2023-01-05 04:25:34,472 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4293797572453817, 'Total loss': 0.4293797572453817} | train loss {'Reaction outcome loss': 0.24244787151236896, 'Total loss': 0.24244787151236896}
2023-01-05 04:25:34,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:34,473 INFO:     Epoch: 36
2023-01-05 04:25:36,738 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4265331566333771, 'Total loss': 0.4265331566333771} | train loss {'Reaction outcome loss': 0.2442887246851688, 'Total loss': 0.2442887246851688}
2023-01-05 04:25:36,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:36,738 INFO:     Epoch: 37
2023-01-05 04:25:38,981 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4678524394830068, 'Total loss': 0.4678524394830068} | train loss {'Reaction outcome loss': 0.24160146711232222, 'Total loss': 0.24160146711232222}
2023-01-05 04:25:38,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:38,981 INFO:     Epoch: 38
2023-01-05 04:25:41,239 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43138422270615895, 'Total loss': 0.43138422270615895} | train loss {'Reaction outcome loss': 0.23518200292449404, 'Total loss': 0.23518200292449404}
2023-01-05 04:25:41,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:41,240 INFO:     Epoch: 39
2023-01-05 04:25:43,387 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48691150148709617, 'Total loss': 0.48691150148709617} | train loss {'Reaction outcome loss': 0.22841172265158832, 'Total loss': 0.22841172265158832}
2023-01-05 04:25:43,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:43,387 INFO:     Epoch: 40
2023-01-05 04:25:45,631 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43382163643836974, 'Total loss': 0.43382163643836974} | train loss {'Reaction outcome loss': 0.23256505501753502, 'Total loss': 0.23256505501753502}
2023-01-05 04:25:45,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:45,632 INFO:     Epoch: 41
2023-01-05 04:25:47,812 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4541025360425313, 'Total loss': 0.4541025360425313} | train loss {'Reaction outcome loss': 0.2314832413915386, 'Total loss': 0.2314832413915386}
2023-01-05 04:25:47,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:47,813 INFO:     Epoch: 42
2023-01-05 04:25:50,031 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44211714118719103, 'Total loss': 0.44211714118719103} | train loss {'Reaction outcome loss': 0.22922991517175367, 'Total loss': 0.22922991517175367}
2023-01-05 04:25:50,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:50,032 INFO:     Epoch: 43
2023-01-05 04:25:52,287 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4561920593182246, 'Total loss': 0.4561920593182246} | train loss {'Reaction outcome loss': 0.22655172967959358, 'Total loss': 0.22655172967959358}
2023-01-05 04:25:52,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:52,288 INFO:     Epoch: 44
2023-01-05 04:25:54,521 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45818997621536256, 'Total loss': 0.45818997621536256} | train loss {'Reaction outcome loss': 0.22340150757913035, 'Total loss': 0.22340150757913035}
2023-01-05 04:25:54,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:54,521 INFO:     Epoch: 45
2023-01-05 04:25:56,742 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47985660135746, 'Total loss': 0.47985660135746} | train loss {'Reaction outcome loss': 0.21747630607822668, 'Total loss': 0.21747630607822668}
2023-01-05 04:25:56,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:56,742 INFO:     Epoch: 46
2023-01-05 04:25:58,987 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.449664656072855, 'Total loss': 0.449664656072855} | train loss {'Reaction outcome loss': 0.21924640595292053, 'Total loss': 0.21924640595292053}
2023-01-05 04:25:58,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:25:58,987 INFO:     Epoch: 47
2023-01-05 04:26:01,238 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47089480559031166, 'Total loss': 0.47089480559031166} | train loss {'Reaction outcome loss': 0.22464147939314463, 'Total loss': 0.22464147939314463}
2023-01-05 04:26:01,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:01,239 INFO:     Epoch: 48
2023-01-05 04:26:03,475 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4630320916573207, 'Total loss': 0.4630320916573207} | train loss {'Reaction outcome loss': 0.21661915060341952, 'Total loss': 0.21661915060341952}
2023-01-05 04:26:03,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:03,475 INFO:     Epoch: 49
2023-01-05 04:26:05,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4407440299789111, 'Total loss': 0.4407440299789111} | train loss {'Reaction outcome loss': 0.210283289277077, 'Total loss': 0.210283289277077}
2023-01-05 04:26:05,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:05,715 INFO:     Epoch: 50
2023-01-05 04:26:07,918 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4735838741064072, 'Total loss': 0.4735838741064072} | train loss {'Reaction outcome loss': 0.2102251412445738, 'Total loss': 0.2102251412445738}
2023-01-05 04:26:07,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:07,919 INFO:     Epoch: 51
2023-01-05 04:26:10,164 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47804287473360696, 'Total loss': 0.47804287473360696} | train loss {'Reaction outcome loss': 0.2111326619975127, 'Total loss': 0.2111326619975127}
2023-01-05 04:26:10,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:10,165 INFO:     Epoch: 52
2023-01-05 04:26:12,412 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4331794988984863, 'Total loss': 0.4331794988984863} | train loss {'Reaction outcome loss': 0.2061409711756784, 'Total loss': 0.2061409711756784}
2023-01-05 04:26:12,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:12,412 INFO:     Epoch: 53
2023-01-05 04:26:14,625 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46424840688705443, 'Total loss': 0.46424840688705443} | train loss {'Reaction outcome loss': 0.2047118800505089, 'Total loss': 0.2047118800505089}
2023-01-05 04:26:14,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:14,625 INFO:     Epoch: 54
2023-01-05 04:26:16,826 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46857270896434783, 'Total loss': 0.46857270896434783} | train loss {'Reaction outcome loss': 0.20236866749431667, 'Total loss': 0.20236866749431667}
2023-01-05 04:26:16,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:16,826 INFO:     Epoch: 55
2023-01-05 04:26:19,079 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4791040599346161, 'Total loss': 0.4791040599346161} | train loss {'Reaction outcome loss': 0.20290823384572793, 'Total loss': 0.20290823384572793}
2023-01-05 04:26:19,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:19,080 INFO:     Epoch: 56
2023-01-05 04:26:21,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4625885864098867, 'Total loss': 0.4625885864098867} | train loss {'Reaction outcome loss': 0.2017269924559725, 'Total loss': 0.2017269924559725}
2023-01-05 04:26:21,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:21,337 INFO:     Epoch: 57
2023-01-05 04:26:23,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4809042861064275, 'Total loss': 0.4809042861064275} | train loss {'Reaction outcome loss': 0.20744072423532497, 'Total loss': 0.20744072423532497}
2023-01-05 04:26:23,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:23,593 INFO:     Epoch: 58
2023-01-05 04:26:25,823 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.475554617245992, 'Total loss': 0.475554617245992} | train loss {'Reaction outcome loss': 0.2244375082866653, 'Total loss': 0.2244375082866653}
2023-01-05 04:26:25,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:25,824 INFO:     Epoch: 59
2023-01-05 04:26:28,043 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4721317450205485, 'Total loss': 0.4721317450205485} | train loss {'Reaction outcome loss': 0.20084580140984684, 'Total loss': 0.20084580140984684}
2023-01-05 04:26:28,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:28,043 INFO:     Epoch: 60
2023-01-05 04:26:30,184 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.473665119210879, 'Total loss': 0.473665119210879} | train loss {'Reaction outcome loss': 0.20104360505196173, 'Total loss': 0.20104360505196173}
2023-01-05 04:26:30,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:30,184 INFO:     Epoch: 61
2023-01-05 04:26:32,435 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47153254797061284, 'Total loss': 0.47153254797061284} | train loss {'Reaction outcome loss': 0.1977445255809774, 'Total loss': 0.1977445255809774}
2023-01-05 04:26:32,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:32,435 INFO:     Epoch: 62
2023-01-05 04:26:34,591 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.501811296492815, 'Total loss': 0.501811296492815} | train loss {'Reaction outcome loss': 0.19541937662027034, 'Total loss': 0.19541937662027034}
2023-01-05 04:26:34,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:34,591 INFO:     Epoch: 63
2023-01-05 04:26:36,737 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4712288071711858, 'Total loss': 0.4712288071711858} | train loss {'Reaction outcome loss': 0.18777727296406554, 'Total loss': 0.18777727296406554}
2023-01-05 04:26:36,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:36,738 INFO:     Epoch: 64
2023-01-05 04:26:38,960 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4883086134990056, 'Total loss': 0.4883086134990056} | train loss {'Reaction outcome loss': 0.19020930570305622, 'Total loss': 0.19020930570305622}
2023-01-05 04:26:38,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:38,960 INFO:     Epoch: 65
2023-01-05 04:26:41,151 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48367298568288486, 'Total loss': 0.48367298568288486} | train loss {'Reaction outcome loss': 0.1898543714239128, 'Total loss': 0.1898543714239128}
2023-01-05 04:26:41,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:41,152 INFO:     Epoch: 66
2023-01-05 04:26:43,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47847130596637727, 'Total loss': 0.47847130596637727} | train loss {'Reaction outcome loss': 0.1899613046334114, 'Total loss': 0.1899613046334114}
2023-01-05 04:26:43,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:43,386 INFO:     Epoch: 67
2023-01-05 04:26:45,626 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5025739252567292, 'Total loss': 0.5025739252567292} | train loss {'Reaction outcome loss': 0.19102084498930103, 'Total loss': 0.19102084498930103}
2023-01-05 04:26:45,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:45,626 INFO:     Epoch: 68
2023-01-05 04:26:47,843 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5106045504411062, 'Total loss': 0.5106045504411062} | train loss {'Reaction outcome loss': 0.1815174230630847, 'Total loss': 0.1815174230630847}
2023-01-05 04:26:47,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:47,843 INFO:     Epoch: 69
2023-01-05 04:26:50,041 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4919986993074417, 'Total loss': 0.4919986993074417} | train loss {'Reaction outcome loss': 0.18599152106532751, 'Total loss': 0.18599152106532751}
2023-01-05 04:26:50,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:50,042 INFO:     Epoch: 70
2023-01-05 04:26:52,195 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48964441021283467, 'Total loss': 0.48964441021283467} | train loss {'Reaction outcome loss': 0.19171720019210994, 'Total loss': 0.19171720019210994}
2023-01-05 04:26:52,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:52,195 INFO:     Epoch: 71
2023-01-05 04:26:54,438 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5045463154713313, 'Total loss': 0.5045463154713313} | train loss {'Reaction outcome loss': 0.26504850713704864, 'Total loss': 0.26504850713704864}
2023-01-05 04:26:54,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:54,438 INFO:     Epoch: 72
2023-01-05 04:26:56,682 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47264179289340974, 'Total loss': 0.47264179289340974} | train loss {'Reaction outcome loss': 0.19716840529598403, 'Total loss': 0.19716840529598403}
2023-01-05 04:26:56,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:56,683 INFO:     Epoch: 73
2023-01-05 04:26:58,936 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4816852599382401, 'Total loss': 0.4816852599382401} | train loss {'Reaction outcome loss': 0.18284411814596935, 'Total loss': 0.18284411814596935}
2023-01-05 04:26:58,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:26:58,937 INFO:     Epoch: 74
2023-01-05 04:27:01,125 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5408810461560886, 'Total loss': 0.5408810461560886} | train loss {'Reaction outcome loss': 0.18051622877913137, 'Total loss': 0.18051622877913137}
2023-01-05 04:27:01,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:01,125 INFO:     Epoch: 75
2023-01-05 04:27:03,347 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48770541648070015, 'Total loss': 0.48770541648070015} | train loss {'Reaction outcome loss': 0.1975007435252917, 'Total loss': 0.1975007435252917}
2023-01-05 04:27:03,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:03,347 INFO:     Epoch: 76
2023-01-05 04:27:05,370 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5170234123865763, 'Total loss': 0.5170234123865763} | train loss {'Reaction outcome loss': 0.19108801491497812, 'Total loss': 0.19108801491497812}
2023-01-05 04:27:05,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:05,370 INFO:     Epoch: 77
2023-01-05 04:27:07,513 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5239193091789881, 'Total loss': 0.5239193091789881} | train loss {'Reaction outcome loss': 0.21521167080188036, 'Total loss': 0.21521167080188036}
2023-01-05 04:27:07,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:07,514 INFO:     Epoch: 78
2023-01-05 04:27:09,755 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5090026979645094, 'Total loss': 0.5090026979645094} | train loss {'Reaction outcome loss': 0.18470969985819596, 'Total loss': 0.18470969985819596}
2023-01-05 04:27:09,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:09,756 INFO:     Epoch: 79
2023-01-05 04:27:11,953 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5152536153793335, 'Total loss': 0.5152536153793335} | train loss {'Reaction outcome loss': 0.18031358584804644, 'Total loss': 0.18031358584804644}
2023-01-05 04:27:11,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:11,953 INFO:     Epoch: 80
2023-01-05 04:27:14,178 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5237199490269026, 'Total loss': 0.5237199490269026} | train loss {'Reaction outcome loss': 0.1792673405725509, 'Total loss': 0.1792673405725509}
2023-01-05 04:27:14,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:14,179 INFO:     Epoch: 81
2023-01-05 04:27:16,384 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.531952761610349, 'Total loss': 0.531952761610349} | train loss {'Reaction outcome loss': 0.1802509583699841, 'Total loss': 0.1802509583699841}
2023-01-05 04:27:16,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:16,385 INFO:     Epoch: 82
2023-01-05 04:27:18,608 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5454999506473541, 'Total loss': 0.5454999506473541} | train loss {'Reaction outcome loss': 0.17940634015945578, 'Total loss': 0.17940634015945578}
2023-01-05 04:27:18,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:18,609 INFO:     Epoch: 83
2023-01-05 04:27:20,843 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5420790255069733, 'Total loss': 0.5420790255069733} | train loss {'Reaction outcome loss': 0.17919432925249357, 'Total loss': 0.17919432925249357}
2023-01-05 04:27:20,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:20,844 INFO:     Epoch: 84
2023-01-05 04:27:23,059 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5148107786973317, 'Total loss': 0.5148107786973317} | train loss {'Reaction outcome loss': 0.1836906518488515, 'Total loss': 0.1836906518488515}
2023-01-05 04:27:23,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:23,059 INFO:     Epoch: 85
2023-01-05 04:27:25,277 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49992424845695493, 'Total loss': 0.49992424845695493} | train loss {'Reaction outcome loss': 0.17756889234389772, 'Total loss': 0.17756889234389772}
2023-01-05 04:27:25,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:25,277 INFO:     Epoch: 86
2023-01-05 04:27:27,436 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5029408077398936, 'Total loss': 0.5029408077398936} | train loss {'Reaction outcome loss': 0.1756938359433569, 'Total loss': 0.1756938359433569}
2023-01-05 04:27:27,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:27,437 INFO:     Epoch: 87
2023-01-05 04:27:29,666 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5212556990484397, 'Total loss': 0.5212556990484397} | train loss {'Reaction outcome loss': 0.1782406771781625, 'Total loss': 0.1782406771781625}
2023-01-05 04:27:29,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:29,667 INFO:     Epoch: 88
2023-01-05 04:27:31,914 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5000434199968974, 'Total loss': 0.5000434199968974} | train loss {'Reaction outcome loss': 0.17728576431577298, 'Total loss': 0.17728576431577298}
2023-01-05 04:27:31,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:31,914 INFO:     Epoch: 89
2023-01-05 04:27:34,158 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5324582467476527, 'Total loss': 0.5324582467476527} | train loss {'Reaction outcome loss': 0.1785367116858454, 'Total loss': 0.1785367116858454}
2023-01-05 04:27:34,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:34,159 INFO:     Epoch: 90
2023-01-05 04:27:36,385 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5201428552468618, 'Total loss': 0.5201428552468618} | train loss {'Reaction outcome loss': 0.18040492676880313, 'Total loss': 0.18040492676880313}
2023-01-05 04:27:36,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:36,385 INFO:     Epoch: 91
2023-01-05 04:27:38,622 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5087905665238698, 'Total loss': 0.5087905665238698} | train loss {'Reaction outcome loss': 0.1827146546928671, 'Total loss': 0.1827146546928671}
2023-01-05 04:27:38,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:38,622 INFO:     Epoch: 92
2023-01-05 04:27:40,839 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5190808922052383, 'Total loss': 0.5190808922052383} | train loss {'Reaction outcome loss': 0.1797083126026354, 'Total loss': 0.1797083126026354}
2023-01-05 04:27:40,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:40,839 INFO:     Epoch: 93
2023-01-05 04:27:43,085 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5314493616422017, 'Total loss': 0.5314493616422017} | train loss {'Reaction outcome loss': 0.17558695954790313, 'Total loss': 0.17558695954790313}
2023-01-05 04:27:43,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:43,086 INFO:     Epoch: 94
2023-01-05 04:27:45,333 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5135861068964005, 'Total loss': 0.5135861068964005} | train loss {'Reaction outcome loss': 0.17475228412313035, 'Total loss': 0.17475228412313035}
2023-01-05 04:27:45,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:45,335 INFO:     Epoch: 95
2023-01-05 04:27:47,570 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5115932191411654, 'Total loss': 0.5115932191411654} | train loss {'Reaction outcome loss': 0.1705034956728073, 'Total loss': 0.1705034956728073}
2023-01-05 04:27:47,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:47,570 INFO:     Epoch: 96
2023-01-05 04:27:49,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5231704930464427, 'Total loss': 0.5231704930464427} | train loss {'Reaction outcome loss': 0.17199328713615905, 'Total loss': 0.17199328713615905}
2023-01-05 04:27:49,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:49,795 INFO:     Epoch: 97
2023-01-05 04:27:52,000 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5228086392084758, 'Total loss': 0.5228086392084758} | train loss {'Reaction outcome loss': 0.17391466849738313, 'Total loss': 0.17391466849738313}
2023-01-05 04:27:52,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:52,001 INFO:     Epoch: 98
2023-01-05 04:27:54,253 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5131828924020131, 'Total loss': 0.5131828924020131} | train loss {'Reaction outcome loss': 0.1627491920354668, 'Total loss': 0.1627491920354668}
2023-01-05 04:27:54,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:54,253 INFO:     Epoch: 99
2023-01-05 04:27:56,415 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5333579361438752, 'Total loss': 0.5333579361438752} | train loss {'Reaction outcome loss': 0.16720906280481385, 'Total loss': 0.16720906280481385}
2023-01-05 04:27:56,415 INFO:     Best model found after epoch 9 of 100.
2023-01-05 04:27:56,416 INFO:   Done with stage: TRAINING
2023-01-05 04:27:56,416 INFO:   Starting stage: EVALUATION
2023-01-05 04:27:56,551 INFO:   Done with stage: EVALUATION
2023-01-05 04:27:56,551 INFO:   Leaving out SEQ value Fold_8
2023-01-05 04:27:56,563 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 04:27:56,563 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:27:57,214 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:27:57,215 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:27:57,288 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:27:57,288 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:27:57,288 INFO:     No hyperparam tuning for this model
2023-01-05 04:27:57,288 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:27:57,288 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:27:57,289 INFO:     None feature selector for col prot
2023-01-05 04:27:57,289 INFO:     None feature selector for col prot
2023-01-05 04:27:57,289 INFO:     None feature selector for col prot
2023-01-05 04:27:57,289 INFO:     None feature selector for col chem
2023-01-05 04:27:57,289 INFO:     None feature selector for col chem
2023-01-05 04:27:57,290 INFO:     None feature selector for col chem
2023-01-05 04:27:57,290 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:27:57,290 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:27:57,291 INFO:     Number of params in model 72931
2023-01-05 04:27:57,294 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:27:57,294 INFO:   Starting stage: TRAINING
2023-01-05 04:27:57,355 INFO:     Val loss before train {'Reaction outcome loss': 1.0677475929260254, 'Total loss': 1.0677475929260254}
2023-01-05 04:27:57,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:57,355 INFO:     Epoch: 0
2023-01-05 04:27:59,581 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7275527437527974, 'Total loss': 0.7275527437527974} | train loss {'Reaction outcome loss': 0.9041872146112394, 'Total loss': 0.9041872146112394}
2023-01-05 04:27:59,581 INFO:     Found new best model at epoch 0
2023-01-05 04:27:59,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:27:59,582 INFO:     Epoch: 1
2023-01-05 04:28:01,830 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5696593085924785, 'Total loss': 0.5696593085924785} | train loss {'Reaction outcome loss': 0.6049342603029327, 'Total loss': 0.6049342603029327}
2023-01-05 04:28:01,830 INFO:     Found new best model at epoch 1
2023-01-05 04:28:01,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:01,832 INFO:     Epoch: 2
2023-01-05 04:28:04,075 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5564304292201996, 'Total loss': 0.5564304292201996} | train loss {'Reaction outcome loss': 0.5178487458491584, 'Total loss': 0.5178487458491584}
2023-01-05 04:28:04,076 INFO:     Found new best model at epoch 2
2023-01-05 04:28:04,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:04,077 INFO:     Epoch: 3
2023-01-05 04:28:06,227 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5269704937934876, 'Total loss': 0.5269704937934876} | train loss {'Reaction outcome loss': 0.47516238485002343, 'Total loss': 0.47516238485002343}
2023-01-05 04:28:06,227 INFO:     Found new best model at epoch 3
2023-01-05 04:28:06,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:06,228 INFO:     Epoch: 4
2023-01-05 04:28:08,470 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49682266314824425, 'Total loss': 0.49682266314824425} | train loss {'Reaction outcome loss': 0.44548961041421237, 'Total loss': 0.44548961041421237}
2023-01-05 04:28:08,471 INFO:     Found new best model at epoch 4
2023-01-05 04:28:08,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:08,472 INFO:     Epoch: 5
2023-01-05 04:28:10,618 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4908958375453949, 'Total loss': 0.4908958375453949} | train loss {'Reaction outcome loss': 0.42410647780348676, 'Total loss': 0.42410647780348676}
2023-01-05 04:28:10,618 INFO:     Found new best model at epoch 5
2023-01-05 04:28:10,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:10,620 INFO:     Epoch: 6
2023-01-05 04:28:12,436 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5051561077435811, 'Total loss': 0.5051561077435811} | train loss {'Reaction outcome loss': 0.4045403525771217, 'Total loss': 0.4045403525771217}
2023-01-05 04:28:12,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:12,436 INFO:     Epoch: 7
2023-01-05 04:28:14,275 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5229756474494934, 'Total loss': 0.5229756474494934} | train loss {'Reaction outcome loss': 0.38871335581160193, 'Total loss': 0.38871335581160193}
2023-01-05 04:28:14,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:14,277 INFO:     Epoch: 8
2023-01-05 04:28:16,370 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.523091580470403, 'Total loss': 0.523091580470403} | train loss {'Reaction outcome loss': 0.3749059657112356, 'Total loss': 0.3749059657112356}
2023-01-05 04:28:16,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:16,370 INFO:     Epoch: 9
2023-01-05 04:28:18,606 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4897953003644943, 'Total loss': 0.4897953003644943} | train loss {'Reaction outcome loss': 0.36250225874168346, 'Total loss': 0.36250225874168346}
2023-01-05 04:28:18,606 INFO:     Found new best model at epoch 9
2023-01-05 04:28:18,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:18,607 INFO:     Epoch: 10
2023-01-05 04:28:20,850 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5246440132459005, 'Total loss': 0.5246440132459005} | train loss {'Reaction outcome loss': 0.3535546333081886, 'Total loss': 0.3535546333081886}
2023-01-05 04:28:20,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:20,851 INFO:     Epoch: 11
2023-01-05 04:28:23,087 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.508248574535052, 'Total loss': 0.508248574535052} | train loss {'Reaction outcome loss': 0.3395070544164964, 'Total loss': 0.3395070544164964}
2023-01-05 04:28:23,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:23,087 INFO:     Epoch: 12
2023-01-05 04:28:25,314 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5396476417779923, 'Total loss': 0.5396476417779923} | train loss {'Reaction outcome loss': 0.3355826714247573, 'Total loss': 0.3355826714247573}
2023-01-05 04:28:25,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:25,315 INFO:     Epoch: 13
2023-01-05 04:28:27,540 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.517260483900706, 'Total loss': 0.517260483900706} | train loss {'Reaction outcome loss': 0.32478196286875416, 'Total loss': 0.32478196286875416}
2023-01-05 04:28:27,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:27,540 INFO:     Epoch: 14
2023-01-05 04:28:29,789 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5189670523007711, 'Total loss': 0.5189670523007711} | train loss {'Reaction outcome loss': 0.31781284010797634, 'Total loss': 0.31781284010797634}
2023-01-05 04:28:29,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:29,790 INFO:     Epoch: 15
2023-01-05 04:28:32,013 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5378837585449219, 'Total loss': 0.5378837585449219} | train loss {'Reaction outcome loss': 0.3079051224629156, 'Total loss': 0.3079051224629156}
2023-01-05 04:28:32,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:32,013 INFO:     Epoch: 16
2023-01-05 04:28:34,252 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5413433293501536, 'Total loss': 0.5413433293501536} | train loss {'Reaction outcome loss': 0.3050834974711122, 'Total loss': 0.3050834974711122}
2023-01-05 04:28:34,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:34,253 INFO:     Epoch: 17
2023-01-05 04:28:36,512 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5265359868605931, 'Total loss': 0.5265359868605931} | train loss {'Reaction outcome loss': 0.2982005433915755, 'Total loss': 0.2982005433915755}
2023-01-05 04:28:36,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:36,512 INFO:     Epoch: 18
2023-01-05 04:28:38,795 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5185686886310578, 'Total loss': 0.5185686886310578} | train loss {'Reaction outcome loss': 0.29196398541169905, 'Total loss': 0.29196398541169905}
2023-01-05 04:28:38,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:38,795 INFO:     Epoch: 19
2023-01-05 04:28:41,087 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5335710247357687, 'Total loss': 0.5335710247357687} | train loss {'Reaction outcome loss': 0.28239795711523574, 'Total loss': 0.28239795711523574}
2023-01-05 04:28:41,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:41,087 INFO:     Epoch: 20
2023-01-05 04:28:43,321 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5044831395149231, 'Total loss': 0.5044831395149231} | train loss {'Reaction outcome loss': 0.277730766071901, 'Total loss': 0.277730766071901}
2023-01-05 04:28:43,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:43,322 INFO:     Epoch: 21
2023-01-05 04:28:45,602 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5361412266890208, 'Total loss': 0.5361412266890208} | train loss {'Reaction outcome loss': 0.2704035961993765, 'Total loss': 0.2704035961993765}
2023-01-05 04:28:45,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:45,602 INFO:     Epoch: 22
2023-01-05 04:28:47,786 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5264860461155574, 'Total loss': 0.5264860461155574} | train loss {'Reaction outcome loss': 0.26556444671072255, 'Total loss': 0.26556444671072255}
2023-01-05 04:28:47,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:47,787 INFO:     Epoch: 23
2023-01-05 04:28:49,969 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5268070459365845, 'Total loss': 0.5268070459365845} | train loss {'Reaction outcome loss': 0.25443304753744644, 'Total loss': 0.25443304753744644}
2023-01-05 04:28:49,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:49,970 INFO:     Epoch: 24
2023-01-05 04:28:52,218 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5573952535788218, 'Total loss': 0.5573952535788218} | train loss {'Reaction outcome loss': 0.2587923135151179, 'Total loss': 0.2587923135151179}
2023-01-05 04:28:52,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:52,218 INFO:     Epoch: 25
2023-01-05 04:28:54,400 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5291529834270478, 'Total loss': 0.5291529834270478} | train loss {'Reaction outcome loss': 0.2511238337020366, 'Total loss': 0.2511238337020366}
2023-01-05 04:28:54,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:54,400 INFO:     Epoch: 26
2023-01-05 04:28:56,670 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.505313777923584, 'Total loss': 0.505313777923584} | train loss {'Reaction outcome loss': 0.2508025375675639, 'Total loss': 0.2508025375675639}
2023-01-05 04:28:56,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:56,672 INFO:     Epoch: 27
2023-01-05 04:28:58,905 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5305942644675573, 'Total loss': 0.5305942644675573} | train loss {'Reaction outcome loss': 0.2476464958612669, 'Total loss': 0.2476464958612669}
2023-01-05 04:28:58,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:28:58,905 INFO:     Epoch: 28
2023-01-05 04:29:01,168 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5540176192919414, 'Total loss': 0.5540176192919414} | train loss {'Reaction outcome loss': 0.23818163284594832, 'Total loss': 0.23818163284594832}
2023-01-05 04:29:01,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:01,169 INFO:     Epoch: 29
2023-01-05 04:29:03,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5335263997316361, 'Total loss': 0.5335263997316361} | train loss {'Reaction outcome loss': 0.2385018093222315, 'Total loss': 0.2385018093222315}
2023-01-05 04:29:03,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:03,364 INFO:     Epoch: 30
2023-01-05 04:29:05,628 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5509580473105112, 'Total loss': 0.5509580473105112} | train loss {'Reaction outcome loss': 0.23359898093832313, 'Total loss': 0.23359898093832313}
2023-01-05 04:29:05,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:05,628 INFO:     Epoch: 31
2023-01-05 04:29:07,886 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.509104436635971, 'Total loss': 0.509104436635971} | train loss {'Reaction outcome loss': 0.23247013908444436, 'Total loss': 0.23247013908444436}
2023-01-05 04:29:07,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:07,886 INFO:     Epoch: 32
2023-01-05 04:29:10,124 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5100220779577891, 'Total loss': 0.5100220779577891} | train loss {'Reaction outcome loss': 0.2288311588097135, 'Total loss': 0.2288311588097135}
2023-01-05 04:29:10,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:10,125 INFO:     Epoch: 33
2023-01-05 04:29:12,380 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5418948034445444, 'Total loss': 0.5418948034445444} | train loss {'Reaction outcome loss': 0.22500484840883891, 'Total loss': 0.22500484840883891}
2023-01-05 04:29:12,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:12,380 INFO:     Epoch: 34
2023-01-05 04:29:14,607 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.526666962603728, 'Total loss': 0.526666962603728} | train loss {'Reaction outcome loss': 0.2289693751221099, 'Total loss': 0.2289693751221099}
2023-01-05 04:29:14,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:14,608 INFO:     Epoch: 35
2023-01-05 04:29:16,818 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5341756900151571, 'Total loss': 0.5341756900151571} | train loss {'Reaction outcome loss': 0.22076185388551076, 'Total loss': 0.22076185388551076}
2023-01-05 04:29:16,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:16,819 INFO:     Epoch: 36
2023-01-05 04:29:18,973 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5359098643064499, 'Total loss': 0.5359098643064499} | train loss {'Reaction outcome loss': 0.2214987238428626, 'Total loss': 0.2214987238428626}
2023-01-05 04:29:18,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:18,973 INFO:     Epoch: 37
2023-01-05 04:29:21,150 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.51505905687809, 'Total loss': 0.51505905687809} | train loss {'Reaction outcome loss': 0.21938018204933468, 'Total loss': 0.21938018204933468}
2023-01-05 04:29:21,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:21,150 INFO:     Epoch: 38
2023-01-05 04:29:23,301 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5210185090700785, 'Total loss': 0.5210185090700785} | train loss {'Reaction outcome loss': 0.21531324453369483, 'Total loss': 0.21531324453369483}
2023-01-05 04:29:23,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:23,302 INFO:     Epoch: 39
2023-01-05 04:29:25,464 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5348541378974915, 'Total loss': 0.5348541378974915} | train loss {'Reaction outcome loss': 0.21424644573554666, 'Total loss': 0.21424644573554666}
2023-01-05 04:29:25,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:25,464 INFO:     Epoch: 40
2023-01-05 04:29:27,716 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5140529026587805, 'Total loss': 0.5140529026587805} | train loss {'Reaction outcome loss': 0.21118780532481976, 'Total loss': 0.21118780532481976}
2023-01-05 04:29:27,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:27,718 INFO:     Epoch: 41
2023-01-05 04:29:29,966 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5284600347280503, 'Total loss': 0.5284600347280503} | train loss {'Reaction outcome loss': 0.20808901188942178, 'Total loss': 0.20808901188942178}
2023-01-05 04:29:29,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:29,966 INFO:     Epoch: 42
2023-01-05 04:29:32,199 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.52642040848732, 'Total loss': 0.52642040848732} | train loss {'Reaction outcome loss': 0.20606165437787663, 'Total loss': 0.20606165437787663}
2023-01-05 04:29:32,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:32,200 INFO:     Epoch: 43
2023-01-05 04:29:34,358 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5437428931395213, 'Total loss': 0.5437428931395213} | train loss {'Reaction outcome loss': 0.20883214140196568, 'Total loss': 0.20883214140196568}
2023-01-05 04:29:34,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:34,359 INFO:     Epoch: 44
2023-01-05 04:29:36,539 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5226415236790974, 'Total loss': 0.5226415236790974} | train loss {'Reaction outcome loss': 0.20393904257525391, 'Total loss': 0.20393904257525391}
2023-01-05 04:29:36,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:36,540 INFO:     Epoch: 45
2023-01-05 04:29:38,731 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5508363276720047, 'Total loss': 0.5508363276720047} | train loss {'Reaction outcome loss': 0.20323119963441946, 'Total loss': 0.20323119963441946}
2023-01-05 04:29:38,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:38,732 INFO:     Epoch: 46
2023-01-05 04:29:40,985 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5686880668004354, 'Total loss': 0.5686880668004354} | train loss {'Reaction outcome loss': 0.20171442248989635, 'Total loss': 0.20171442248989635}
2023-01-05 04:29:40,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:40,985 INFO:     Epoch: 47
2023-01-05 04:29:43,223 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5288909415404002, 'Total loss': 0.5288909415404002} | train loss {'Reaction outcome loss': 0.20087506402525984, 'Total loss': 0.20087506402525984}
2023-01-05 04:29:43,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:43,223 INFO:     Epoch: 48
2023-01-05 04:29:45,449 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5144656419754028, 'Total loss': 0.5144656419754028} | train loss {'Reaction outcome loss': 0.1987313437897591, 'Total loss': 0.1987313437897591}
2023-01-05 04:29:45,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:45,449 INFO:     Epoch: 49
2023-01-05 04:29:47,721 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5246273120244344, 'Total loss': 0.5246273120244344} | train loss {'Reaction outcome loss': 0.19518658401787498, 'Total loss': 0.19518658401787498}
2023-01-05 04:29:47,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:47,722 INFO:     Epoch: 50
2023-01-05 04:29:49,915 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5275846620400747, 'Total loss': 0.5275846620400747} | train loss {'Reaction outcome loss': 0.19545293851194076, 'Total loss': 0.19545293851194076}
2023-01-05 04:29:49,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:49,915 INFO:     Epoch: 51
2023-01-05 04:29:52,144 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5257118572791417, 'Total loss': 0.5257118572791417} | train loss {'Reaction outcome loss': 0.19329112461879042, 'Total loss': 0.19329112461879042}
2023-01-05 04:29:52,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:52,145 INFO:     Epoch: 52
2023-01-05 04:29:54,325 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5425963461399078, 'Total loss': 0.5425963461399078} | train loss {'Reaction outcome loss': 0.19072118038412467, 'Total loss': 0.19072118038412467}
2023-01-05 04:29:54,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:54,326 INFO:     Epoch: 53
2023-01-05 04:29:56,562 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5498646120230357, 'Total loss': 0.5498646120230357} | train loss {'Reaction outcome loss': 0.1951246424359589, 'Total loss': 0.1951246424359589}
2023-01-05 04:29:56,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:56,563 INFO:     Epoch: 54
2023-01-05 04:29:58,808 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5412315646807353, 'Total loss': 0.5412315646807353} | train loss {'Reaction outcome loss': 0.19563911812857385, 'Total loss': 0.19563911812857385}
2023-01-05 04:29:58,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:29:58,808 INFO:     Epoch: 55
2023-01-05 04:30:01,080 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5640055229266484, 'Total loss': 0.5640055229266484} | train loss {'Reaction outcome loss': 0.1908689881153808, 'Total loss': 0.1908689881153808}
2023-01-05 04:30:01,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:01,081 INFO:     Epoch: 56
2023-01-05 04:30:03,307 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5646404226620992, 'Total loss': 0.5646404226620992} | train loss {'Reaction outcome loss': 0.19124860297350568, 'Total loss': 0.19124860297350568}
2023-01-05 04:30:03,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:03,308 INFO:     Epoch: 57
2023-01-05 04:30:05,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5350167175134023, 'Total loss': 0.5350167175134023} | train loss {'Reaction outcome loss': 0.1864242483609581, 'Total loss': 0.1864242483609581}
2023-01-05 04:30:05,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:05,544 INFO:     Epoch: 58
2023-01-05 04:30:07,753 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5469191104173661, 'Total loss': 0.5469191104173661} | train loss {'Reaction outcome loss': 0.18505178876927236, 'Total loss': 0.18505178876927236}
2023-01-05 04:30:07,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:07,754 INFO:     Epoch: 59
2023-01-05 04:30:10,001 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5461798787117005, 'Total loss': 0.5461798787117005} | train loss {'Reaction outcome loss': 0.18261441061380806, 'Total loss': 0.18261441061380806}
2023-01-05 04:30:10,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:10,002 INFO:     Epoch: 60
2023-01-05 04:30:12,233 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5563705195983251, 'Total loss': 0.5563705195983251} | train loss {'Reaction outcome loss': 0.18586573824084732, 'Total loss': 0.18586573824084732}
2023-01-05 04:30:12,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:12,233 INFO:     Epoch: 61
2023-01-05 04:30:14,497 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5198081977665424, 'Total loss': 0.5198081977665424} | train loss {'Reaction outcome loss': 0.1836311294502219, 'Total loss': 0.1836311294502219}
2023-01-05 04:30:14,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:14,498 INFO:     Epoch: 62
2023-01-05 04:30:16,669 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5214559654394786, 'Total loss': 0.5214559654394786} | train loss {'Reaction outcome loss': 0.18800125757924915, 'Total loss': 0.18800125757924915}
2023-01-05 04:30:16,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:16,670 INFO:     Epoch: 63
2023-01-05 04:30:18,894 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5444327175617218, 'Total loss': 0.5444327175617218} | train loss {'Reaction outcome loss': 0.18272576552213907, 'Total loss': 0.18272576552213907}
2023-01-05 04:30:18,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:18,894 INFO:     Epoch: 64
2023-01-05 04:30:21,123 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.548515111207962, 'Total loss': 0.548515111207962} | train loss {'Reaction outcome loss': 0.18158358504276198, 'Total loss': 0.18158358504276198}
2023-01-05 04:30:21,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:21,123 INFO:     Epoch: 65
2023-01-05 04:30:23,379 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5277279704809189, 'Total loss': 0.5277279704809189} | train loss {'Reaction outcome loss': 0.18138467370186148, 'Total loss': 0.18138467370186148}
2023-01-05 04:30:23,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:23,379 INFO:     Epoch: 66
2023-01-05 04:30:25,604 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5512425363063812, 'Total loss': 0.5512425363063812} | train loss {'Reaction outcome loss': 0.17921360676254175, 'Total loss': 0.17921360676254175}
2023-01-05 04:30:25,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:25,604 INFO:     Epoch: 67
2023-01-05 04:30:27,831 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5348429729541143, 'Total loss': 0.5348429729541143} | train loss {'Reaction outcome loss': 0.17782703292848617, 'Total loss': 0.17782703292848617}
2023-01-05 04:30:27,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:27,832 INFO:     Epoch: 68
2023-01-05 04:30:30,060 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5589407960573832, 'Total loss': 0.5589407960573832} | train loss {'Reaction outcome loss': 0.1804921891748744, 'Total loss': 0.1804921891748744}
2023-01-05 04:30:30,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:30,060 INFO:     Epoch: 69
2023-01-05 04:30:32,292 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5487429678440094, 'Total loss': 0.5487429678440094} | train loss {'Reaction outcome loss': 0.17582350973517294, 'Total loss': 0.17582350973517294}
2023-01-05 04:30:32,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:32,294 INFO:     Epoch: 70
2023-01-05 04:30:34,544 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5287052015463511, 'Total loss': 0.5287052015463511} | train loss {'Reaction outcome loss': 0.17434451872455997, 'Total loss': 0.17434451872455997}
2023-01-05 04:30:34,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:34,544 INFO:     Epoch: 71
2023-01-05 04:30:36,794 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5357007761796315, 'Total loss': 0.5357007761796315} | train loss {'Reaction outcome loss': 0.17093784474710588, 'Total loss': 0.17093784474710588}
2023-01-05 04:30:36,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:36,794 INFO:     Epoch: 72
2023-01-05 04:30:39,069 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.536683464050293, 'Total loss': 0.536683464050293} | train loss {'Reaction outcome loss': 0.17465543756362334, 'Total loss': 0.17465543756362334}
2023-01-05 04:30:39,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:39,070 INFO:     Epoch: 73
2023-01-05 04:30:41,266 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5354800542195638, 'Total loss': 0.5354800542195638} | train loss {'Reaction outcome loss': 0.17340266202586546, 'Total loss': 0.17340266202586546}
2023-01-05 04:30:41,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:41,266 INFO:     Epoch: 74
2023-01-05 04:30:43,469 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5115113298098246, 'Total loss': 0.5115113298098246} | train loss {'Reaction outcome loss': 0.17640383978330595, 'Total loss': 0.17640383978330595}
2023-01-05 04:30:43,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:43,469 INFO:     Epoch: 75
2023-01-05 04:30:45,711 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5559505860010783, 'Total loss': 0.5559505860010783} | train loss {'Reaction outcome loss': 0.17285194772292292, 'Total loss': 0.17285194772292292}
2023-01-05 04:30:45,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:45,711 INFO:     Epoch: 76
2023-01-05 04:30:47,907 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5256534477074941, 'Total loss': 0.5256534477074941} | train loss {'Reaction outcome loss': 0.17153923820018338, 'Total loss': 0.17153923820018338}
2023-01-05 04:30:47,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:47,907 INFO:     Epoch: 77
2023-01-05 04:30:50,121 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5055849015712738, 'Total loss': 0.5055849015712738} | train loss {'Reaction outcome loss': 0.17075319718804868, 'Total loss': 0.17075319718804868}
2023-01-05 04:30:50,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:50,122 INFO:     Epoch: 78
2023-01-05 04:30:52,299 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5314023564259212, 'Total loss': 0.5314023564259212} | train loss {'Reaction outcome loss': 0.17026292361379583, 'Total loss': 0.17026292361379583}
2023-01-05 04:30:52,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:52,300 INFO:     Epoch: 79
2023-01-05 04:30:54,418 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5501098940769832, 'Total loss': 0.5501098940769832} | train loss {'Reaction outcome loss': 0.1734185138858505, 'Total loss': 0.1734185138858505}
2023-01-05 04:30:54,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:54,418 INFO:     Epoch: 80
2023-01-05 04:30:56,571 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.526828995347023, 'Total loss': 0.526828995347023} | train loss {'Reaction outcome loss': 0.16632949162883154, 'Total loss': 0.16632949162883154}
2023-01-05 04:30:56,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:56,571 INFO:     Epoch: 81
2023-01-05 04:30:58,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5109770789742469, 'Total loss': 0.5109770789742469} | train loss {'Reaction outcome loss': 0.16717636387623738, 'Total loss': 0.16717636387623738}
2023-01-05 04:30:58,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:30:58,767 INFO:     Epoch: 82
2023-01-05 04:31:00,996 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5246706068515777, 'Total loss': 0.5246706068515777} | train loss {'Reaction outcome loss': 0.16736261903338592, 'Total loss': 0.16736261903338592}
2023-01-05 04:31:00,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:00,997 INFO:     Epoch: 83
2023-01-05 04:31:03,153 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5312436203161875, 'Total loss': 0.5312436203161875} | train loss {'Reaction outcome loss': 0.1649596467269551, 'Total loss': 0.1649596467269551}
2023-01-05 04:31:03,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:03,153 INFO:     Epoch: 84
2023-01-05 04:31:05,308 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5281086444854737, 'Total loss': 0.5281086444854737} | train loss {'Reaction outcome loss': 0.17374949495977174, 'Total loss': 0.17374949495977174}
2023-01-05 04:31:05,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:05,308 INFO:     Epoch: 85
2023-01-05 04:31:07,452 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5162396411101023, 'Total loss': 0.5162396411101023} | train loss {'Reaction outcome loss': 0.1655500204863854, 'Total loss': 0.1655500204863854}
2023-01-05 04:31:07,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:07,452 INFO:     Epoch: 86
2023-01-05 04:31:09,495 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5591489990552266, 'Total loss': 0.5591489990552266} | train loss {'Reaction outcome loss': 0.16936522359129325, 'Total loss': 0.16936522359129325}
2023-01-05 04:31:09,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:09,496 INFO:     Epoch: 87
2023-01-05 04:31:11,693 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5422008107105891, 'Total loss': 0.5422008107105891} | train loss {'Reaction outcome loss': 0.1656946111378001, 'Total loss': 0.1656946111378001}
2023-01-05 04:31:11,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:11,693 INFO:     Epoch: 88
2023-01-05 04:31:13,924 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5394797007242839, 'Total loss': 0.5394797007242839} | train loss {'Reaction outcome loss': 0.1649264613543015, 'Total loss': 0.1649264613543015}
2023-01-05 04:31:13,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:13,925 INFO:     Epoch: 89
2023-01-05 04:31:16,122 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5553930977980296, 'Total loss': 0.5553930977980296} | train loss {'Reaction outcome loss': 0.1697724738665974, 'Total loss': 0.1697724738665974}
2023-01-05 04:31:16,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:16,123 INFO:     Epoch: 90
2023-01-05 04:31:18,299 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5455814376473427, 'Total loss': 0.5455814376473427} | train loss {'Reaction outcome loss': 0.17016317877272943, 'Total loss': 0.17016317877272943}
2023-01-05 04:31:18,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:18,299 INFO:     Epoch: 91
2023-01-05 04:31:20,467 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5253664801518122, 'Total loss': 0.5253664801518122} | train loss {'Reaction outcome loss': 0.16202196747985825, 'Total loss': 0.16202196747985825}
2023-01-05 04:31:20,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:20,467 INFO:     Epoch: 92
2023-01-05 04:31:22,636 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5244292636712392, 'Total loss': 0.5244292636712392} | train loss {'Reaction outcome loss': 0.16320528348719546, 'Total loss': 0.16320528348719546}
2023-01-05 04:31:22,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:22,636 INFO:     Epoch: 93
2023-01-05 04:31:24,778 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.533838231364886, 'Total loss': 0.533838231364886} | train loss {'Reaction outcome loss': 0.1633077164782406, 'Total loss': 0.1633077164782406}
2023-01-05 04:31:24,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:24,779 INFO:     Epoch: 94
2023-01-05 04:31:26,974 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5272983233133952, 'Total loss': 0.5272983233133952} | train loss {'Reaction outcome loss': 0.16041538890094803, 'Total loss': 0.16041538890094803}
2023-01-05 04:31:26,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:26,975 INFO:     Epoch: 95
2023-01-05 04:31:29,209 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5581280489762624, 'Total loss': 0.5581280489762624} | train loss {'Reaction outcome loss': 0.1595707600751374, 'Total loss': 0.1595707600751374}
2023-01-05 04:31:29,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:29,210 INFO:     Epoch: 96
2023-01-05 04:31:31,380 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5584150989850362, 'Total loss': 0.5584150989850362} | train loss {'Reaction outcome loss': 0.1622104435261433, 'Total loss': 0.1622104435261433}
2023-01-05 04:31:31,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:31,380 INFO:     Epoch: 97
2023-01-05 04:31:33,575 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5721375768383344, 'Total loss': 0.5721375768383344} | train loss {'Reaction outcome loss': 0.16234691671368123, 'Total loss': 0.16234691671368123}
2023-01-05 04:31:33,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:33,575 INFO:     Epoch: 98
2023-01-05 04:31:35,749 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5421987116336823, 'Total loss': 0.5421987116336823} | train loss {'Reaction outcome loss': 0.16299180497855809, 'Total loss': 0.16299180497855809}
2023-01-05 04:31:35,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:35,749 INFO:     Epoch: 99
2023-01-05 04:31:37,887 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5245416278640429, 'Total loss': 0.5245416278640429} | train loss {'Reaction outcome loss': 0.16024887678801797, 'Total loss': 0.16024887678801797}
2023-01-05 04:31:37,887 INFO:     Best model found after epoch 10 of 100.
2023-01-05 04:31:37,888 INFO:   Done with stage: TRAINING
2023-01-05 04:31:37,888 INFO:   Starting stage: EVALUATION
2023-01-05 04:31:38,015 INFO:   Done with stage: EVALUATION
2023-01-05 04:31:38,015 INFO:   Leaving out SEQ value Fold_9
2023-01-05 04:31:38,028 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 04:31:38,028 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:31:38,665 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:31:38,666 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:31:38,739 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:31:38,740 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:31:38,740 INFO:     No hyperparam tuning for this model
2023-01-05 04:31:38,740 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:31:38,740 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:31:38,741 INFO:     None feature selector for col prot
2023-01-05 04:31:38,741 INFO:     None feature selector for col prot
2023-01-05 04:31:38,741 INFO:     None feature selector for col prot
2023-01-05 04:31:38,741 INFO:     None feature selector for col chem
2023-01-05 04:31:38,741 INFO:     None feature selector for col chem
2023-01-05 04:31:38,742 INFO:     None feature selector for col chem
2023-01-05 04:31:38,742 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:31:38,742 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:31:38,744 INFO:     Number of params in model 72931
2023-01-05 04:31:38,747 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:31:38,747 INFO:   Starting stage: TRAINING
2023-01-05 04:31:38,806 INFO:     Val loss before train {'Reaction outcome loss': 0.9424171884854634, 'Total loss': 0.9424171884854634}
2023-01-05 04:31:38,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:38,807 INFO:     Epoch: 0
2023-01-05 04:31:40,947 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7131798466046652, 'Total loss': 0.7131798466046652} | train loss {'Reaction outcome loss': 0.9720334473069394, 'Total loss': 0.9720334473069394}
2023-01-05 04:31:40,947 INFO:     Found new best model at epoch 0
2023-01-05 04:31:40,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:40,948 INFO:     Epoch: 1
2023-01-05 04:31:43,167 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5019220193227132, 'Total loss': 0.5019220193227132} | train loss {'Reaction outcome loss': 0.6895276512479954, 'Total loss': 0.6895276512479954}
2023-01-05 04:31:43,167 INFO:     Found new best model at epoch 1
2023-01-05 04:31:43,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:43,168 INFO:     Epoch: 2
2023-01-05 04:31:45,317 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47858214378356934, 'Total loss': 0.47858214378356934} | train loss {'Reaction outcome loss': 0.5521839533256709, 'Total loss': 0.5521839533256709}
2023-01-05 04:31:45,318 INFO:     Found new best model at epoch 2
2023-01-05 04:31:45,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:45,319 INFO:     Epoch: 3
2023-01-05 04:31:47,541 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4755059023698171, 'Total loss': 0.4755059023698171} | train loss {'Reaction outcome loss': 0.5098333470657844, 'Total loss': 0.5098333470657844}
2023-01-05 04:31:47,541 INFO:     Found new best model at epoch 3
2023-01-05 04:31:47,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:47,543 INFO:     Epoch: 4
2023-01-05 04:31:49,766 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4448887348175049, 'Total loss': 0.4448887348175049} | train loss {'Reaction outcome loss': 0.48110712252369, 'Total loss': 0.48110712252369}
2023-01-05 04:31:49,766 INFO:     Found new best model at epoch 4
2023-01-05 04:31:49,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:49,767 INFO:     Epoch: 5
2023-01-05 04:31:51,916 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4454506039619446, 'Total loss': 0.4454506039619446} | train loss {'Reaction outcome loss': 0.45992136453463284, 'Total loss': 0.45992136453463284}
2023-01-05 04:31:51,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:51,916 INFO:     Epoch: 6
2023-01-05 04:31:54,180 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41946492294470467, 'Total loss': 0.41946492294470467} | train loss {'Reaction outcome loss': 0.44724933094334945, 'Total loss': 0.44724933094334945}
2023-01-05 04:31:54,180 INFO:     Found new best model at epoch 6
2023-01-05 04:31:54,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:54,181 INFO:     Epoch: 7
2023-01-05 04:31:56,332 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4211313585440318, 'Total loss': 0.4211313585440318} | train loss {'Reaction outcome loss': 0.42874123355111493, 'Total loss': 0.42874123355111493}
2023-01-05 04:31:56,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:56,332 INFO:     Epoch: 8
2023-01-05 04:31:58,552 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.396855096022288, 'Total loss': 0.396855096022288} | train loss {'Reaction outcome loss': 0.4141588461205417, 'Total loss': 0.4141588461205417}
2023-01-05 04:31:58,553 INFO:     Found new best model at epoch 8
2023-01-05 04:31:58,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:31:58,554 INFO:     Epoch: 9
2023-01-05 04:32:00,791 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42103302478790283, 'Total loss': 0.42103302478790283} | train loss {'Reaction outcome loss': 0.40461720526218414, 'Total loss': 0.40461720526218414}
2023-01-05 04:32:00,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:00,791 INFO:     Epoch: 10
2023-01-05 04:32:02,987 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4159725179274877, 'Total loss': 0.4159725179274877} | train loss {'Reaction outcome loss': 0.38988931477069855, 'Total loss': 0.38988931477069855}
2023-01-05 04:32:02,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:02,987 INFO:     Epoch: 11
2023-01-05 04:32:05,190 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40420958573619525, 'Total loss': 0.40420958573619525} | train loss {'Reaction outcome loss': 0.38168937301377526, 'Total loss': 0.38168937301377526}
2023-01-05 04:32:05,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:05,190 INFO:     Epoch: 12
2023-01-05 04:32:07,458 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4465428739786148, 'Total loss': 0.4465428739786148} | train loss {'Reaction outcome loss': 0.3704500687628016, 'Total loss': 0.3704500687628016}
2023-01-05 04:32:07,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:07,458 INFO:     Epoch: 13
2023-01-05 04:32:09,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4182190537452698, 'Total loss': 0.4182190537452698} | train loss {'Reaction outcome loss': 0.3656808698704527, 'Total loss': 0.3656808698704527}
2023-01-05 04:32:09,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:09,709 INFO:     Epoch: 14
2023-01-05 04:32:11,970 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4242614527543386, 'Total loss': 0.4242614527543386} | train loss {'Reaction outcome loss': 0.3591837250637664, 'Total loss': 0.3591837250637664}
2023-01-05 04:32:11,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:11,970 INFO:     Epoch: 15
2023-01-05 04:32:14,133 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4168776303529739, 'Total loss': 0.4168776303529739} | train loss {'Reaction outcome loss': 0.34926800136639324, 'Total loss': 0.34926800136639324}
2023-01-05 04:32:14,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:14,134 INFO:     Epoch: 16
2023-01-05 04:32:16,289 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40812215209007263, 'Total loss': 0.40812215209007263} | train loss {'Reaction outcome loss': 0.3381654924649194, 'Total loss': 0.3381654924649194}
2023-01-05 04:32:16,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:16,290 INFO:     Epoch: 17
2023-01-05 04:32:18,487 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4088224242130915, 'Total loss': 0.4088224242130915} | train loss {'Reaction outcome loss': 0.33294353990509623, 'Total loss': 0.33294353990509623}
2023-01-05 04:32:18,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:18,487 INFO:     Epoch: 18
2023-01-05 04:32:20,725 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4037894358237584, 'Total loss': 0.4037894358237584} | train loss {'Reaction outcome loss': 0.3259339222704676, 'Total loss': 0.3259339222704676}
2023-01-05 04:32:20,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:20,725 INFO:     Epoch: 19
2023-01-05 04:32:22,941 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40553129216035205, 'Total loss': 0.40553129216035205} | train loss {'Reaction outcome loss': 0.31853157046523334, 'Total loss': 0.31853157046523334}
2023-01-05 04:32:22,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:22,942 INFO:     Epoch: 20
2023-01-05 04:32:25,135 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3920944501956304, 'Total loss': 0.3920944501956304} | train loss {'Reaction outcome loss': 0.31161619211792513, 'Total loss': 0.31161619211792513}
2023-01-05 04:32:25,135 INFO:     Found new best model at epoch 20
2023-01-05 04:32:25,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:25,137 INFO:     Epoch: 21
2023-01-05 04:32:27,347 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4085770597060521, 'Total loss': 0.4085770597060521} | train loss {'Reaction outcome loss': 0.305318133387755, 'Total loss': 0.305318133387755}
2023-01-05 04:32:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:27,348 INFO:     Epoch: 22
2023-01-05 04:32:29,576 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38278668622175854, 'Total loss': 0.38278668622175854} | train loss {'Reaction outcome loss': 0.2994225948833817, 'Total loss': 0.2994225948833817}
2023-01-05 04:32:29,577 INFO:     Found new best model at epoch 22
2023-01-05 04:32:29,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:29,578 INFO:     Epoch: 23
2023-01-05 04:32:31,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36953145762284595, 'Total loss': 0.36953145762284595} | train loss {'Reaction outcome loss': 0.2921577557679333, 'Total loss': 0.2921577557679333}
2023-01-05 04:32:31,799 INFO:     Found new best model at epoch 23
2023-01-05 04:32:31,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:31,800 INFO:     Epoch: 24
2023-01-05 04:32:33,992 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41850527276595434, 'Total loss': 0.41850527276595434} | train loss {'Reaction outcome loss': 0.2888789093289995, 'Total loss': 0.2888789093289995}
2023-01-05 04:32:33,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:33,992 INFO:     Epoch: 25
2023-01-05 04:32:36,201 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40189548830191296, 'Total loss': 0.40189548830191296} | train loss {'Reaction outcome loss': 0.2841014661338678, 'Total loss': 0.2841014661338678}
2023-01-05 04:32:36,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:36,201 INFO:     Epoch: 26
2023-01-05 04:32:38,419 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41178348461786907, 'Total loss': 0.41178348461786907} | train loss {'Reaction outcome loss': 0.2833563561823609, 'Total loss': 0.2833563561823609}
2023-01-05 04:32:38,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:38,419 INFO:     Epoch: 27
2023-01-05 04:32:40,673 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40363227725028994, 'Total loss': 0.40363227725028994} | train loss {'Reaction outcome loss': 0.27713081974280657, 'Total loss': 0.27713081974280657}
2023-01-05 04:32:40,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:40,673 INFO:     Epoch: 28
2023-01-05 04:32:42,956 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41088518798351287, 'Total loss': 0.41088518798351287} | train loss {'Reaction outcome loss': 0.2696974663743043, 'Total loss': 0.2696974663743043}
2023-01-05 04:32:42,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:42,956 INFO:     Epoch: 29
2023-01-05 04:32:45,223 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41500870088736214, 'Total loss': 0.41500870088736214} | train loss {'Reaction outcome loss': 0.2681995587900873, 'Total loss': 0.2681995587900873}
2023-01-05 04:32:45,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:45,224 INFO:     Epoch: 30
2023-01-05 04:32:47,472 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39044644037882487, 'Total loss': 0.39044644037882487} | train loss {'Reaction outcome loss': 0.26576759416058604, 'Total loss': 0.26576759416058604}
2023-01-05 04:32:47,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:47,473 INFO:     Epoch: 31
2023-01-05 04:32:49,743 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38809373676776887, 'Total loss': 0.38809373676776887} | train loss {'Reaction outcome loss': 0.25668889927654276, 'Total loss': 0.25668889927654276}
2023-01-05 04:32:49,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:49,743 INFO:     Epoch: 32
2023-01-05 04:32:51,658 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4168922995527585, 'Total loss': 0.4168922995527585} | train loss {'Reaction outcome loss': 0.25851467713740545, 'Total loss': 0.25851467713740545}
2023-01-05 04:32:51,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:51,658 INFO:     Epoch: 33
2023-01-05 04:32:53,544 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3750849256912867, 'Total loss': 0.3750849256912867} | train loss {'Reaction outcome loss': 0.2535169633367647, 'Total loss': 0.2535169633367647}
2023-01-05 04:32:53,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:53,545 INFO:     Epoch: 34
2023-01-05 04:32:55,694 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38476463258266447, 'Total loss': 0.38476463258266447} | train loss {'Reaction outcome loss': 0.24872768414795182, 'Total loss': 0.24872768414795182}
2023-01-05 04:32:55,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:55,694 INFO:     Epoch: 35
2023-01-05 04:32:57,941 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38557627896467844, 'Total loss': 0.38557627896467844} | train loss {'Reaction outcome loss': 0.24365569616160238, 'Total loss': 0.24365569616160238}
2023-01-05 04:32:57,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:32:57,941 INFO:     Epoch: 36
2023-01-05 04:33:00,216 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41736299892266593, 'Total loss': 0.41736299892266593} | train loss {'Reaction outcome loss': 0.24675193020152703, 'Total loss': 0.24675193020152703}
2023-01-05 04:33:00,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:00,217 INFO:     Epoch: 37
2023-01-05 04:33:02,371 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4258679270744324, 'Total loss': 0.4258679270744324} | train loss {'Reaction outcome loss': 0.23690639530385874, 'Total loss': 0.23690639530385874}
2023-01-05 04:33:02,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:02,371 INFO:     Epoch: 38
2023-01-05 04:33:04,637 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3936277190844218, 'Total loss': 0.3936277190844218} | train loss {'Reaction outcome loss': 0.23408470825974692, 'Total loss': 0.23408470825974692}
2023-01-05 04:33:04,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:04,637 INFO:     Epoch: 39
2023-01-05 04:33:06,878 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43731030225753786, 'Total loss': 0.43731030225753786} | train loss {'Reaction outcome loss': 0.23587447157405345, 'Total loss': 0.23587447157405345}
2023-01-05 04:33:06,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:06,879 INFO:     Epoch: 40
2023-01-05 04:33:09,116 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42847742736339567, 'Total loss': 0.42847742736339567} | train loss {'Reaction outcome loss': 0.23676482762045326, 'Total loss': 0.23676482762045326}
2023-01-05 04:33:09,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:09,117 INFO:     Epoch: 41
2023-01-05 04:33:11,385 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4295774141947428, 'Total loss': 0.4295774141947428} | train loss {'Reaction outcome loss': 0.2324149895489673, 'Total loss': 0.2324149895489673}
2023-01-05 04:33:11,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:11,385 INFO:     Epoch: 42
2023-01-05 04:33:13,667 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3908303956190745, 'Total loss': 0.3908303956190745} | train loss {'Reaction outcome loss': 0.22988297990338358, 'Total loss': 0.22988297990338358}
2023-01-05 04:33:13,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:13,667 INFO:     Epoch: 43
2023-01-05 04:33:15,929 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4140024403731028, 'Total loss': 0.4140024403731028} | train loss {'Reaction outcome loss': 0.2331966625119724, 'Total loss': 0.2331966625119724}
2023-01-05 04:33:15,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:15,929 INFO:     Epoch: 44
2023-01-05 04:33:18,125 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4190629988908768, 'Total loss': 0.4190629988908768} | train loss {'Reaction outcome loss': 0.22956114723632912, 'Total loss': 0.22956114723632912}
2023-01-05 04:33:18,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:18,126 INFO:     Epoch: 45
2023-01-05 04:33:20,301 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43098170806964237, 'Total loss': 0.43098170806964237} | train loss {'Reaction outcome loss': 0.2264394597738766, 'Total loss': 0.2264394597738766}
2023-01-05 04:33:20,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:20,302 INFO:     Epoch: 46
2023-01-05 04:33:22,560 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3957357719540596, 'Total loss': 0.3957357719540596} | train loss {'Reaction outcome loss': 0.2215042515214035, 'Total loss': 0.2215042515214035}
2023-01-05 04:33:22,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:22,560 INFO:     Epoch: 47
2023-01-05 04:33:24,827 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38700934052467345, 'Total loss': 0.38700934052467345} | train loss {'Reaction outcome loss': 0.22332564752132023, 'Total loss': 0.22332564752132023}
2023-01-05 04:33:24,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:24,828 INFO:     Epoch: 48
2023-01-05 04:33:27,088 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41237666408220924, 'Total loss': 0.41237666408220924} | train loss {'Reaction outcome loss': 0.2138810303223585, 'Total loss': 0.2138810303223585}
2023-01-05 04:33:27,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:27,089 INFO:     Epoch: 49
2023-01-05 04:33:29,321 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39458740055561065, 'Total loss': 0.39458740055561065} | train loss {'Reaction outcome loss': 0.21862911774914726, 'Total loss': 0.21862911774914726}
2023-01-05 04:33:29,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:29,321 INFO:     Epoch: 50
2023-01-05 04:33:31,554 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4061815728743871, 'Total loss': 0.4061815728743871} | train loss {'Reaction outcome loss': 0.21488897276652258, 'Total loss': 0.21488897276652258}
2023-01-05 04:33:31,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:31,554 INFO:     Epoch: 51
2023-01-05 04:33:33,783 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41476422200600305, 'Total loss': 0.41476422200600305} | train loss {'Reaction outcome loss': 0.21522876551704287, 'Total loss': 0.21522876551704287}
2023-01-05 04:33:33,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:33,784 INFO:     Epoch: 52
2023-01-05 04:33:36,047 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.424043690909942, 'Total loss': 0.424043690909942} | train loss {'Reaction outcome loss': 0.21816142945002348, 'Total loss': 0.21816142945002348}
2023-01-05 04:33:36,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:36,048 INFO:     Epoch: 53
2023-01-05 04:33:38,293 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4268324539065361, 'Total loss': 0.4268324539065361} | train loss {'Reaction outcome loss': 0.21517275896474772, 'Total loss': 0.21517275896474772}
2023-01-05 04:33:38,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:38,294 INFO:     Epoch: 54
2023-01-05 04:33:40,512 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40471994479497275, 'Total loss': 0.40471994479497275} | train loss {'Reaction outcome loss': 0.20977555070448975, 'Total loss': 0.20977555070448975}
2023-01-05 04:33:40,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:40,512 INFO:     Epoch: 55
2023-01-05 04:33:42,746 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40477085212866465, 'Total loss': 0.40477085212866465} | train loss {'Reaction outcome loss': 0.2103733053256082, 'Total loss': 0.2103733053256082}
2023-01-05 04:33:42,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:42,746 INFO:     Epoch: 56
2023-01-05 04:33:45,010 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41447992076476414, 'Total loss': 0.41447992076476414} | train loss {'Reaction outcome loss': 0.21134900528809816, 'Total loss': 0.21134900528809816}
2023-01-05 04:33:45,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:45,010 INFO:     Epoch: 57
2023-01-05 04:33:47,241 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4522354379296303, 'Total loss': 0.4522354379296303} | train loss {'Reaction outcome loss': 0.20534448523666132, 'Total loss': 0.20534448523666132}
2023-01-05 04:33:47,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:47,242 INFO:     Epoch: 58
2023-01-05 04:33:49,461 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4481731573740641, 'Total loss': 0.4481731573740641} | train loss {'Reaction outcome loss': 0.20950205719421217, 'Total loss': 0.20950205719421217}
2023-01-05 04:33:49,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:49,461 INFO:     Epoch: 59
2023-01-05 04:33:51,714 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4122597346703211, 'Total loss': 0.4122597346703211} | train loss {'Reaction outcome loss': 0.20257882852719203, 'Total loss': 0.20257882852719203}
2023-01-05 04:33:51,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:51,714 INFO:     Epoch: 60
2023-01-05 04:33:53,940 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3870212356249491, 'Total loss': 0.3870212356249491} | train loss {'Reaction outcome loss': 0.20278054143601376, 'Total loss': 0.20278054143601376}
2023-01-05 04:33:53,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:53,941 INFO:     Epoch: 61
2023-01-05 04:33:56,183 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41151050726572674, 'Total loss': 0.41151050726572674} | train loss {'Reaction outcome loss': 0.2035816470194702, 'Total loss': 0.2035816470194702}
2023-01-05 04:33:56,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:56,184 INFO:     Epoch: 62
2023-01-05 04:33:58,443 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43066827654838563, 'Total loss': 0.43066827654838563} | train loss {'Reaction outcome loss': 0.20271118021560058, 'Total loss': 0.20271118021560058}
2023-01-05 04:33:58,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:33:58,444 INFO:     Epoch: 63
2023-01-05 04:34:00,680 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40656321148077645, 'Total loss': 0.40656321148077645} | train loss {'Reaction outcome loss': 0.19774835941714608, 'Total loss': 0.19774835941714608}
2023-01-05 04:34:00,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:00,681 INFO:     Epoch: 64
2023-01-05 04:34:02,927 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4492950032154719, 'Total loss': 0.4492950032154719} | train loss {'Reaction outcome loss': 0.19929040991953348, 'Total loss': 0.19929040991953348}
2023-01-05 04:34:02,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:02,928 INFO:     Epoch: 65
2023-01-05 04:34:05,178 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4181902584930261, 'Total loss': 0.4181902584930261} | train loss {'Reaction outcome loss': 0.20282024103435367, 'Total loss': 0.20282024103435367}
2023-01-05 04:34:05,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:05,179 INFO:     Epoch: 66
2023-01-05 04:34:07,419 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4102233958741029, 'Total loss': 0.4102233958741029} | train loss {'Reaction outcome loss': 0.20029959023765387, 'Total loss': 0.20029959023765387}
2023-01-05 04:34:07,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:07,420 INFO:     Epoch: 67
2023-01-05 04:34:09,679 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4104821672042211, 'Total loss': 0.4104821672042211} | train loss {'Reaction outcome loss': 0.1985868127707271, 'Total loss': 0.1985868127707271}
2023-01-05 04:34:09,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:09,679 INFO:     Epoch: 68
2023-01-05 04:34:11,937 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4276343991359075, 'Total loss': 0.4276343991359075} | train loss {'Reaction outcome loss': 0.1975882712159884, 'Total loss': 0.1975882712159884}
2023-01-05 04:34:11,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:11,937 INFO:     Epoch: 69
2023-01-05 04:34:14,196 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40488362510999043, 'Total loss': 0.40488362510999043} | train loss {'Reaction outcome loss': 0.19403153111559712, 'Total loss': 0.19403153111559712}
2023-01-05 04:34:14,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:14,196 INFO:     Epoch: 70
2023-01-05 04:34:16,407 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.429372168580691, 'Total loss': 0.429372168580691} | train loss {'Reaction outcome loss': 0.1975266300074568, 'Total loss': 0.1975266300074568}
2023-01-05 04:34:16,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:16,407 INFO:     Epoch: 71
2023-01-05 04:34:18,578 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41154327321176726, 'Total loss': 0.41154327321176726} | train loss {'Reaction outcome loss': 0.19762224248788632, 'Total loss': 0.19762224248788632}
2023-01-05 04:34:18,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:18,579 INFO:     Epoch: 72
2023-01-05 04:34:20,827 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42873015205065407, 'Total loss': 0.42873015205065407} | train loss {'Reaction outcome loss': 0.1979241349872215, 'Total loss': 0.1979241349872215}
2023-01-05 04:34:20,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:20,827 INFO:     Epoch: 73
2023-01-05 04:34:23,059 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46177284022172294, 'Total loss': 0.46177284022172294} | train loss {'Reaction outcome loss': 0.19556291358854744, 'Total loss': 0.19556291358854744}
2023-01-05 04:34:23,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:23,060 INFO:     Epoch: 74
2023-01-05 04:34:25,293 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4259054154157639, 'Total loss': 0.4259054154157639} | train loss {'Reaction outcome loss': 0.1909598831645472, 'Total loss': 0.1909598831645472}
2023-01-05 04:34:25,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:25,293 INFO:     Epoch: 75
2023-01-05 04:34:27,512 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43858472307523094, 'Total loss': 0.43858472307523094} | train loss {'Reaction outcome loss': 0.19000198435213161, 'Total loss': 0.19000198435213161}
2023-01-05 04:34:27,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:27,512 INFO:     Epoch: 76
2023-01-05 04:34:29,731 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4388286759455999, 'Total loss': 0.4388286759455999} | train loss {'Reaction outcome loss': 0.19089869760810682, 'Total loss': 0.19089869760810682}
2023-01-05 04:34:29,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:29,732 INFO:     Epoch: 77
2023-01-05 04:34:31,967 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4599370966355006, 'Total loss': 0.4599370966355006} | train loss {'Reaction outcome loss': 0.1895556331331428, 'Total loss': 0.1895556331331428}
2023-01-05 04:34:31,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:31,967 INFO:     Epoch: 78
2023-01-05 04:34:34,172 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4226539134979248, 'Total loss': 0.4226539134979248} | train loss {'Reaction outcome loss': 0.19162608321339214, 'Total loss': 0.19162608321339214}
2023-01-05 04:34:34,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:34,173 INFO:     Epoch: 79
2023-01-05 04:34:36,432 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43829146027565, 'Total loss': 0.43829146027565} | train loss {'Reaction outcome loss': 0.1847982045854795, 'Total loss': 0.1847982045854795}
2023-01-05 04:34:36,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:36,433 INFO:     Epoch: 80
2023-01-05 04:34:38,605 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4188011147081852, 'Total loss': 0.4188011147081852} | train loss {'Reaction outcome loss': 0.18672594625085914, 'Total loss': 0.18672594625085914}
2023-01-05 04:34:38,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:38,606 INFO:     Epoch: 81
2023-01-05 04:34:40,869 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4304628809293111, 'Total loss': 0.4304628809293111} | train loss {'Reaction outcome loss': 0.18629671033599585, 'Total loss': 0.18629671033599585}
2023-01-05 04:34:40,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:40,869 INFO:     Epoch: 82
2023-01-05 04:34:43,005 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4036227449774742, 'Total loss': 0.4036227449774742} | train loss {'Reaction outcome loss': 0.18673838020070366, 'Total loss': 0.18673838020070366}
2023-01-05 04:34:43,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:43,006 INFO:     Epoch: 83
2023-01-05 04:34:45,214 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41429702440897626, 'Total loss': 0.41429702440897626} | train loss {'Reaction outcome loss': 0.1895861188185129, 'Total loss': 0.1895861188185129}
2023-01-05 04:34:45,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:45,215 INFO:     Epoch: 84
2023-01-05 04:34:47,469 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40582841634750366, 'Total loss': 0.40582841634750366} | train loss {'Reaction outcome loss': 0.1918204663630696, 'Total loss': 0.1918204663630696}
2023-01-05 04:34:47,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:47,470 INFO:     Epoch: 85
2023-01-05 04:34:49,743 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4148998369773229, 'Total loss': 0.4148998369773229} | train loss {'Reaction outcome loss': 0.18583254032812016, 'Total loss': 0.18583254032812016}
2023-01-05 04:34:49,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:49,744 INFO:     Epoch: 86
2023-01-05 04:34:51,949 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42136476735274, 'Total loss': 0.42136476735274} | train loss {'Reaction outcome loss': 0.18214669933841843, 'Total loss': 0.18214669933841843}
2023-01-05 04:34:51,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:51,949 INFO:     Epoch: 87
2023-01-05 04:34:54,127 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.423617218931516, 'Total loss': 0.423617218931516} | train loss {'Reaction outcome loss': 0.1800561980361166, 'Total loss': 0.1800561980361166}
2023-01-05 04:34:54,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:54,127 INFO:     Epoch: 88
2023-01-05 04:34:56,328 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40391391403973104, 'Total loss': 0.40391391403973104} | train loss {'Reaction outcome loss': 0.1858710092576456, 'Total loss': 0.1858710092576456}
2023-01-05 04:34:56,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:56,329 INFO:     Epoch: 89
2023-01-05 04:34:58,525 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4164710094531377, 'Total loss': 0.4164710094531377} | train loss {'Reaction outcome loss': 0.18244406020618464, 'Total loss': 0.18244406020618464}
2023-01-05 04:34:58,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:34:58,526 INFO:     Epoch: 90
2023-01-05 04:35:00,717 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4303949246803919, 'Total loss': 0.4303949246803919} | train loss {'Reaction outcome loss': 0.18411900415774501, 'Total loss': 0.18411900415774501}
2023-01-05 04:35:00,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:00,718 INFO:     Epoch: 91
2023-01-05 04:35:02,916 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45017745196819303, 'Total loss': 0.45017745196819303} | train loss {'Reaction outcome loss': 0.18452123172971208, 'Total loss': 0.18452123172971208}
2023-01-05 04:35:02,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:02,916 INFO:     Epoch: 92
2023-01-05 04:35:05,166 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3952972948551178, 'Total loss': 0.3952972948551178} | train loss {'Reaction outcome loss': 0.18418099285382442, 'Total loss': 0.18418099285382442}
2023-01-05 04:35:05,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:05,167 INFO:     Epoch: 93
2023-01-05 04:35:07,440 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43160603841145834, 'Total loss': 0.43160603841145834} | train loss {'Reaction outcome loss': 0.18284016986804533, 'Total loss': 0.18284016986804533}
2023-01-05 04:35:07,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:07,440 INFO:     Epoch: 94
2023-01-05 04:35:09,665 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4007109006245931, 'Total loss': 0.4007109006245931} | train loss {'Reaction outcome loss': 0.1800860237172176, 'Total loss': 0.1800860237172176}
2023-01-05 04:35:09,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:09,665 INFO:     Epoch: 95
2023-01-05 04:35:11,860 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4174543797969818, 'Total loss': 0.4174543797969818} | train loss {'Reaction outcome loss': 0.1782646743927003, 'Total loss': 0.1782646743927003}
2023-01-05 04:35:11,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:11,860 INFO:     Epoch: 96
2023-01-05 04:35:13,863 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4397795631395032, 'Total loss': 0.4397795631395032} | train loss {'Reaction outcome loss': 0.17695463422874144, 'Total loss': 0.17695463422874144}
2023-01-05 04:35:13,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:13,863 INFO:     Epoch: 97
2023-01-05 04:35:16,096 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4178373023867607, 'Total loss': 0.4178373023867607} | train loss {'Reaction outcome loss': 0.17478674135106995, 'Total loss': 0.17478674135106995}
2023-01-05 04:35:16,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:16,096 INFO:     Epoch: 98
2023-01-05 04:35:18,326 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40763021806875865, 'Total loss': 0.40763021806875865} | train loss {'Reaction outcome loss': 0.1782084723315891, 'Total loss': 0.1782084723315891}
2023-01-05 04:35:18,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:18,327 INFO:     Epoch: 99
2023-01-05 04:35:20,475 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3879687706629435, 'Total loss': 0.3879687706629435} | train loss {'Reaction outcome loss': 0.17691424697139957, 'Total loss': 0.17691424697139957}
2023-01-05 04:35:20,476 INFO:     Best model found after epoch 24 of 100.
2023-01-05 04:35:20,476 INFO:   Done with stage: TRAINING
2023-01-05 04:35:20,476 INFO:   Starting stage: EVALUATION
2023-01-05 04:35:20,607 INFO:   Done with stage: EVALUATION
2023-01-05 04:35:20,615 INFO:   Leaving out SEQ value Fold_0
2023-01-05 04:35:20,628 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 04:35:20,628 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:35:21,269 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:35:21,269 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:35:21,341 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:35:21,341 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:35:21,341 INFO:     No hyperparam tuning for this model
2023-01-05 04:35:21,341 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:35:21,341 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:35:21,342 INFO:     None feature selector for col prot
2023-01-05 04:35:21,342 INFO:     None feature selector for col prot
2023-01-05 04:35:21,342 INFO:     None feature selector for col prot
2023-01-05 04:35:21,343 INFO:     None feature selector for col chem
2023-01-05 04:35:21,343 INFO:     None feature selector for col chem
2023-01-05 04:35:21,343 INFO:     None feature selector for col chem
2023-01-05 04:35:21,343 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:35:21,343 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:35:21,344 INFO:     Number of params in model 72931
2023-01-05 04:35:21,347 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:35:21,348 INFO:   Starting stage: TRAINING
2023-01-05 04:35:21,407 INFO:     Val loss before train {'Reaction outcome loss': 1.02509818871816, 'Total loss': 1.02509818871816}
2023-01-05 04:35:21,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:21,407 INFO:     Epoch: 0
2023-01-05 04:35:23,624 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8837087909380595, 'Total loss': 0.8837087909380595} | train loss {'Reaction outcome loss': 0.9697727872072345, 'Total loss': 0.9697727872072345}
2023-01-05 04:35:23,624 INFO:     Found new best model at epoch 0
2023-01-05 04:35:23,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:23,626 INFO:     Epoch: 1
2023-01-05 04:35:25,806 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5843894342581432, 'Total loss': 0.5843894342581432} | train loss {'Reaction outcome loss': 0.6936905111057045, 'Total loss': 0.6936905111057045}
2023-01-05 04:35:25,806 INFO:     Found new best model at epoch 1
2023-01-05 04:35:25,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:25,808 INFO:     Epoch: 2
2023-01-05 04:35:27,980 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5368076622486114, 'Total loss': 0.5368076622486114} | train loss {'Reaction outcome loss': 0.5632622148433741, 'Total loss': 0.5632622148433741}
2023-01-05 04:35:27,980 INFO:     Found new best model at epoch 2
2023-01-05 04:35:27,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:27,982 INFO:     Epoch: 3
2023-01-05 04:35:30,228 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5253787100315094, 'Total loss': 0.5253787100315094} | train loss {'Reaction outcome loss': 0.5150943409896245, 'Total loss': 0.5150943409896245}
2023-01-05 04:35:30,229 INFO:     Found new best model at epoch 3
2023-01-05 04:35:30,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:30,230 INFO:     Epoch: 4
2023-01-05 04:35:32,454 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4934025496244431, 'Total loss': 0.4934025496244431} | train loss {'Reaction outcome loss': 0.4836830843212831, 'Total loss': 0.4836830843212831}
2023-01-05 04:35:32,454 INFO:     Found new best model at epoch 4
2023-01-05 04:35:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:32,456 INFO:     Epoch: 5
2023-01-05 04:35:34,620 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4996397435665131, 'Total loss': 0.4996397435665131} | train loss {'Reaction outcome loss': 0.4619433128812017, 'Total loss': 0.4619433128812017}
2023-01-05 04:35:34,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:34,621 INFO:     Epoch: 6
2023-01-05 04:35:36,810 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46468644638856255, 'Total loss': 0.46468644638856255} | train loss {'Reaction outcome loss': 0.44583897727684385, 'Total loss': 0.44583897727684385}
2023-01-05 04:35:36,810 INFO:     Found new best model at epoch 6
2023-01-05 04:35:36,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:36,811 INFO:     Epoch: 7
2023-01-05 04:35:39,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46691279808680214, 'Total loss': 0.46691279808680214} | train loss {'Reaction outcome loss': 0.4347121878153216, 'Total loss': 0.4347121878153216}
2023-01-05 04:35:39,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:39,035 INFO:     Epoch: 8
2023-01-05 04:35:41,244 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4496174732844035, 'Total loss': 0.4496174732844035} | train loss {'Reaction outcome loss': 0.42334344594256723, 'Total loss': 0.42334344594256723}
2023-01-05 04:35:41,244 INFO:     Found new best model at epoch 8
2023-01-05 04:35:41,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:41,246 INFO:     Epoch: 9
2023-01-05 04:35:43,470 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45186836322148644, 'Total loss': 0.45186836322148644} | train loss {'Reaction outcome loss': 0.4111140485662613, 'Total loss': 0.4111140485662613}
2023-01-05 04:35:43,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:43,470 INFO:     Epoch: 10
2023-01-05 04:35:45,705 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4409281035264333, 'Total loss': 0.4409281035264333} | train loss {'Reaction outcome loss': 0.3958523671013595, 'Total loss': 0.3958523671013595}
2023-01-05 04:35:45,705 INFO:     Found new best model at epoch 10
2023-01-05 04:35:45,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:45,706 INFO:     Epoch: 11
2023-01-05 04:35:47,886 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46000531514485676, 'Total loss': 0.46000531514485676} | train loss {'Reaction outcome loss': 0.3882666923323252, 'Total loss': 0.3882666923323252}
2023-01-05 04:35:47,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:47,886 INFO:     Epoch: 12
2023-01-05 04:35:50,073 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44483559131622313, 'Total loss': 0.44483559131622313} | train loss {'Reaction outcome loss': 0.3849615798923221, 'Total loss': 0.3849615798923221}
2023-01-05 04:35:50,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:50,073 INFO:     Epoch: 13
2023-01-05 04:35:52,289 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40808429519335426, 'Total loss': 0.40808429519335426} | train loss {'Reaction outcome loss': 0.3749457347023226, 'Total loss': 0.3749457347023226}
2023-01-05 04:35:52,289 INFO:     Found new best model at epoch 13
2023-01-05 04:35:52,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:52,290 INFO:     Epoch: 14
2023-01-05 04:35:54,462 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43072930673758186, 'Total loss': 0.43072930673758186} | train loss {'Reaction outcome loss': 0.3640216926969316, 'Total loss': 0.3640216926969316}
2023-01-05 04:35:54,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:54,463 INFO:     Epoch: 15
2023-01-05 04:35:56,684 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42682072122891745, 'Total loss': 0.42682072122891745} | train loss {'Reaction outcome loss': 0.3540624780240503, 'Total loss': 0.3540624780240503}
2023-01-05 04:35:56,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:56,685 INFO:     Epoch: 16
2023-01-05 04:35:58,888 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41316956977049507, 'Total loss': 0.41316956977049507} | train loss {'Reaction outcome loss': 0.34635860589842726, 'Total loss': 0.34635860589842726}
2023-01-05 04:35:58,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:35:58,888 INFO:     Epoch: 17
2023-01-05 04:36:01,101 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40865684350331627, 'Total loss': 0.40865684350331627} | train loss {'Reaction outcome loss': 0.3399006498664835, 'Total loss': 0.3399006498664835}
2023-01-05 04:36:01,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:01,101 INFO:     Epoch: 18
2023-01-05 04:36:03,267 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39845394492149355, 'Total loss': 0.39845394492149355} | train loss {'Reaction outcome loss': 0.32845165110091223, 'Total loss': 0.32845165110091223}
2023-01-05 04:36:03,268 INFO:     Found new best model at epoch 18
2023-01-05 04:36:03,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:03,269 INFO:     Epoch: 19
2023-01-05 04:36:05,456 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3948246031999588, 'Total loss': 0.3948246031999588} | train loss {'Reaction outcome loss': 0.3250144058226669, 'Total loss': 0.3250144058226669}
2023-01-05 04:36:05,456 INFO:     Found new best model at epoch 19
2023-01-05 04:36:05,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:05,457 INFO:     Epoch: 20
2023-01-05 04:36:07,667 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39352820018927254, 'Total loss': 0.39352820018927254} | train loss {'Reaction outcome loss': 0.3197603172139965, 'Total loss': 0.3197603172139965}
2023-01-05 04:36:07,668 INFO:     Found new best model at epoch 20
2023-01-05 04:36:07,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:07,669 INFO:     Epoch: 21
2023-01-05 04:36:09,899 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40507199267546334, 'Total loss': 0.40507199267546334} | train loss {'Reaction outcome loss': 0.31531049452558924, 'Total loss': 0.31531049452558924}
2023-01-05 04:36:09,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:09,900 INFO:     Epoch: 22
2023-01-05 04:36:12,098 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39068035657207173, 'Total loss': 0.39068035657207173} | train loss {'Reaction outcome loss': 0.3029645585665738, 'Total loss': 0.3029645585665738}
2023-01-05 04:36:12,099 INFO:     Found new best model at epoch 22
2023-01-05 04:36:12,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:12,100 INFO:     Epoch: 23
2023-01-05 04:36:14,299 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40655992130438484, 'Total loss': 0.40655992130438484} | train loss {'Reaction outcome loss': 0.30361975011599324, 'Total loss': 0.30361975011599324}
2023-01-05 04:36:14,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:14,299 INFO:     Epoch: 24
2023-01-05 04:36:16,514 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40937521755695344, 'Total loss': 0.40937521755695344} | train loss {'Reaction outcome loss': 0.29757087902050383, 'Total loss': 0.29757087902050383}
2023-01-05 04:36:16,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:16,515 INFO:     Epoch: 25
2023-01-05 04:36:18,718 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4247372478246689, 'Total loss': 0.4247372478246689} | train loss {'Reaction outcome loss': 0.29372444524545305, 'Total loss': 0.29372444524545305}
2023-01-05 04:36:18,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:18,719 INFO:     Epoch: 26
2023-01-05 04:36:20,947 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38013014594713845, 'Total loss': 0.38013014594713845} | train loss {'Reaction outcome loss': 0.28627610377912976, 'Total loss': 0.28627610377912976}
2023-01-05 04:36:20,947 INFO:     Found new best model at epoch 26
2023-01-05 04:36:20,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:20,948 INFO:     Epoch: 27
2023-01-05 04:36:23,125 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3832186500231425, 'Total loss': 0.3832186500231425} | train loss {'Reaction outcome loss': 0.28492512718441276, 'Total loss': 0.28492512718441276}
2023-01-05 04:36:23,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:23,126 INFO:     Epoch: 28
2023-01-05 04:36:25,340 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41066434383392336, 'Total loss': 0.41066434383392336} | train loss {'Reaction outcome loss': 0.2834244787312337, 'Total loss': 0.2834244787312337}
2023-01-05 04:36:25,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:25,340 INFO:     Epoch: 29
2023-01-05 04:36:27,520 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39311061302820843, 'Total loss': 0.39311061302820843} | train loss {'Reaction outcome loss': 0.2726975085662447, 'Total loss': 0.2726975085662447}
2023-01-05 04:36:27,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:27,520 INFO:     Epoch: 30
2023-01-05 04:36:29,753 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3948361774285634, 'Total loss': 0.3948361774285634} | train loss {'Reaction outcome loss': 0.2687749645815496, 'Total loss': 0.2687749645815496}
2023-01-05 04:36:29,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:29,753 INFO:     Epoch: 31
2023-01-05 04:36:31,984 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37634431272745134, 'Total loss': 0.37634431272745134} | train loss {'Reaction outcome loss': 0.2659220489788882, 'Total loss': 0.2659220489788882}
2023-01-05 04:36:31,984 INFO:     Found new best model at epoch 31
2023-01-05 04:36:31,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:31,986 INFO:     Epoch: 32
2023-01-05 04:36:34,206 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3842767139275869, 'Total loss': 0.3842767139275869} | train loss {'Reaction outcome loss': 0.2629590142572666, 'Total loss': 0.2629590142572666}
2023-01-05 04:36:34,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:34,206 INFO:     Epoch: 33
2023-01-05 04:36:36,328 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3683929661909739, 'Total loss': 0.3683929661909739} | train loss {'Reaction outcome loss': 0.2554895720940872, 'Total loss': 0.2554895720940872}
2023-01-05 04:36:36,329 INFO:     Found new best model at epoch 33
2023-01-05 04:36:36,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:36,330 INFO:     Epoch: 34
2023-01-05 04:36:38,543 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38888411447405813, 'Total loss': 0.38888411447405813} | train loss {'Reaction outcome loss': 0.2561289206568668, 'Total loss': 0.2561289206568668}
2023-01-05 04:36:38,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:38,544 INFO:     Epoch: 35
2023-01-05 04:36:40,828 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3725738282004992, 'Total loss': 0.3725738282004992} | train loss {'Reaction outcome loss': 0.24951913671391288, 'Total loss': 0.24951913671391288}
2023-01-05 04:36:40,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:40,829 INFO:     Epoch: 36
2023-01-05 04:36:42,967 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38035548478364944, 'Total loss': 0.38035548478364944} | train loss {'Reaction outcome loss': 0.24598882520013918, 'Total loss': 0.24598882520013918}
2023-01-05 04:36:42,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:42,967 INFO:     Epoch: 37
2023-01-05 04:36:45,195 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39708592693010963, 'Total loss': 0.39708592693010963} | train loss {'Reaction outcome loss': 0.23977990301638624, 'Total loss': 0.23977990301638624}
2023-01-05 04:36:45,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:45,195 INFO:     Epoch: 38
2023-01-05 04:36:47,362 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3986152956883113, 'Total loss': 0.3986152956883113} | train loss {'Reaction outcome loss': 0.24125088216315438, 'Total loss': 0.24125088216315438}
2023-01-05 04:36:47,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:47,363 INFO:     Epoch: 39
2023-01-05 04:36:49,558 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37460761790474256, 'Total loss': 0.37460761790474256} | train loss {'Reaction outcome loss': 0.23865144914627945, 'Total loss': 0.23865144914627945}
2023-01-05 04:36:49,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:49,558 INFO:     Epoch: 40
2023-01-05 04:36:51,752 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4174382428328196, 'Total loss': 0.4174382428328196} | train loss {'Reaction outcome loss': 0.23212959843748895, 'Total loss': 0.23212959843748895}
2023-01-05 04:36:51,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:51,753 INFO:     Epoch: 41
2023-01-05 04:36:53,895 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38665109177430473, 'Total loss': 0.38665109177430473} | train loss {'Reaction outcome loss': 0.23196024848080246, 'Total loss': 0.23196024848080246}
2023-01-05 04:36:53,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:53,895 INFO:     Epoch: 42
2023-01-05 04:36:56,106 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3778283968567848, 'Total loss': 0.3778283968567848} | train loss {'Reaction outcome loss': 0.23232621763472575, 'Total loss': 0.23232621763472575}
2023-01-05 04:36:56,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:56,106 INFO:     Epoch: 43
2023-01-05 04:36:58,314 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38171195940425, 'Total loss': 0.38171195940425} | train loss {'Reaction outcome loss': 0.22915181802096266, 'Total loss': 0.22915181802096266}
2023-01-05 04:36:58,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:36:58,315 INFO:     Epoch: 44
2023-01-05 04:37:00,543 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4372658481200536, 'Total loss': 0.4372658481200536} | train loss {'Reaction outcome loss': 0.22367007990306528, 'Total loss': 0.22367007990306528}
2023-01-05 04:37:00,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:00,544 INFO:     Epoch: 45
2023-01-05 04:37:02,700 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45157736241817475, 'Total loss': 0.45157736241817475} | train loss {'Reaction outcome loss': 0.22507534469103943, 'Total loss': 0.22507534469103943}
2023-01-05 04:37:02,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:02,700 INFO:     Epoch: 46
2023-01-05 04:37:04,854 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4182215169072151, 'Total loss': 0.4182215169072151} | train loss {'Reaction outcome loss': 0.2208558249059575, 'Total loss': 0.2208558249059575}
2023-01-05 04:37:04,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:04,854 INFO:     Epoch: 47
2023-01-05 04:37:07,089 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4641938477754593, 'Total loss': 0.4641938477754593} | train loss {'Reaction outcome loss': 0.22457240015458668, 'Total loss': 0.22457240015458668}
2023-01-05 04:37:07,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:07,089 INFO:     Epoch: 48
2023-01-05 04:37:09,260 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.417539600096643, 'Total loss': 0.417539600096643} | train loss {'Reaction outcome loss': 0.2184397729086506, 'Total loss': 0.2184397729086506}
2023-01-05 04:37:09,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:09,261 INFO:     Epoch: 49
2023-01-05 04:37:11,493 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4292931978901227, 'Total loss': 0.4292931978901227} | train loss {'Reaction outcome loss': 0.21756660997405322, 'Total loss': 0.21756660997405322}
2023-01-05 04:37:11,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:11,493 INFO:     Epoch: 50
2023-01-05 04:37:13,722 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4243258702258269, 'Total loss': 0.4243258702258269} | train loss {'Reaction outcome loss': 0.21004212977038356, 'Total loss': 0.21004212977038356}
2023-01-05 04:37:13,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:13,723 INFO:     Epoch: 51
2023-01-05 04:37:15,925 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41125526229540504, 'Total loss': 0.41125526229540504} | train loss {'Reaction outcome loss': 0.21220922858257146, 'Total loss': 0.21220922858257146}
2023-01-05 04:37:15,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:15,925 INFO:     Epoch: 52
2023-01-05 04:37:18,156 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4417971948782603, 'Total loss': 0.4417971948782603} | train loss {'Reaction outcome loss': 0.20698089937740652, 'Total loss': 0.20698089937740652}
2023-01-05 04:37:18,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:18,157 INFO:     Epoch: 53
2023-01-05 04:37:20,400 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4259381463130315, 'Total loss': 0.4259381463130315} | train loss {'Reaction outcome loss': 0.20597843118997658, 'Total loss': 0.20597843118997658}
2023-01-05 04:37:20,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:20,400 INFO:     Epoch: 54
2023-01-05 04:37:22,576 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3946799387534459, 'Total loss': 0.3946799387534459} | train loss {'Reaction outcome loss': 0.20539761746954852, 'Total loss': 0.20539761746954852}
2023-01-05 04:37:22,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:22,576 INFO:     Epoch: 55
2023-01-05 04:37:24,828 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4109211888940384, 'Total loss': 0.4109211888940384} | train loss {'Reaction outcome loss': 0.20423508305646423, 'Total loss': 0.20423508305646423}
2023-01-05 04:37:24,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:24,829 INFO:     Epoch: 56
2023-01-05 04:37:27,038 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3952845166126887, 'Total loss': 0.3952845166126887} | train loss {'Reaction outcome loss': 0.2014151220651765, 'Total loss': 0.2014151220651765}
2023-01-05 04:37:27,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:27,038 INFO:     Epoch: 57
2023-01-05 04:37:29,264 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.424859873453776, 'Total loss': 0.424859873453776} | train loss {'Reaction outcome loss': 0.1973869681195186, 'Total loss': 0.1973869681195186}
2023-01-05 04:37:29,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:29,264 INFO:     Epoch: 58
2023-01-05 04:37:31,466 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40801527897516887, 'Total loss': 0.40801527897516887} | train loss {'Reaction outcome loss': 0.20141768748837993, 'Total loss': 0.20141768748837993}
2023-01-05 04:37:31,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:31,466 INFO:     Epoch: 59
2023-01-05 04:37:33,703 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3966391156117121, 'Total loss': 0.3966391156117121} | train loss {'Reaction outcome loss': 0.193595368758415, 'Total loss': 0.193595368758415}
2023-01-05 04:37:33,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:33,703 INFO:     Epoch: 60
2023-01-05 04:37:35,913 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4332616319259008, 'Total loss': 0.4332616319259008} | train loss {'Reaction outcome loss': 0.19601309032308578, 'Total loss': 0.19601309032308578}
2023-01-05 04:37:35,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:35,914 INFO:     Epoch: 61
2023-01-05 04:37:38,106 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4411831962565581, 'Total loss': 0.4411831962565581} | train loss {'Reaction outcome loss': 0.1910233334451234, 'Total loss': 0.1910233334451234}
2023-01-05 04:37:38,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:38,106 INFO:     Epoch: 62
2023-01-05 04:37:40,334 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43711541493733724, 'Total loss': 0.43711541493733724} | train loss {'Reaction outcome loss': 0.19198195469722043, 'Total loss': 0.19198195469722043}
2023-01-05 04:37:40,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:40,334 INFO:     Epoch: 63
2023-01-05 04:37:42,618 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4247413764397303, 'Total loss': 0.4247413764397303} | train loss {'Reaction outcome loss': 0.19248614196808342, 'Total loss': 0.19248614196808342}
2023-01-05 04:37:42,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:42,618 INFO:     Epoch: 64
2023-01-05 04:37:44,804 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41703437715768815, 'Total loss': 0.41703437715768815} | train loss {'Reaction outcome loss': 0.19676507153228795, 'Total loss': 0.19676507153228795}
2023-01-05 04:37:44,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:44,804 INFO:     Epoch: 65
2023-01-05 04:37:47,045 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4349968358874321, 'Total loss': 0.4349968358874321} | train loss {'Reaction outcome loss': 0.18655404332943643, 'Total loss': 0.18655404332943643}
2023-01-05 04:37:47,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:47,045 INFO:     Epoch: 66
2023-01-05 04:37:49,211 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41433419783910114, 'Total loss': 0.41433419783910114} | train loss {'Reaction outcome loss': 0.19141064482625492, 'Total loss': 0.19141064482625492}
2023-01-05 04:37:49,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:49,212 INFO:     Epoch: 67
2023-01-05 04:37:51,444 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4501575561861197, 'Total loss': 0.4501575561861197} | train loss {'Reaction outcome loss': 0.18106283845012858, 'Total loss': 0.18106283845012858}
2023-01-05 04:37:51,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:51,444 INFO:     Epoch: 68
2023-01-05 04:37:53,671 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42677606008946894, 'Total loss': 0.42677606008946894} | train loss {'Reaction outcome loss': 0.1907413753946006, 'Total loss': 0.1907413753946006}
2023-01-05 04:37:53,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:53,671 INFO:     Epoch: 69
2023-01-05 04:37:55,923 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46130097409089404, 'Total loss': 0.46130097409089404} | train loss {'Reaction outcome loss': 0.18859725698733526, 'Total loss': 0.18859725698733526}
2023-01-05 04:37:55,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:55,924 INFO:     Epoch: 70
2023-01-05 04:37:58,176 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4485804249842962, 'Total loss': 0.4485804249842962} | train loss {'Reaction outcome loss': 0.18318069810863502, 'Total loss': 0.18318069810863502}
2023-01-05 04:37:58,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:37:58,176 INFO:     Epoch: 71
2023-01-05 04:38:00,427 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4644723971684774, 'Total loss': 0.4644723971684774} | train loss {'Reaction outcome loss': 0.18315109121103357, 'Total loss': 0.18315109121103357}
2023-01-05 04:38:00,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:00,427 INFO:     Epoch: 72
2023-01-05 04:38:02,656 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43736341993014016, 'Total loss': 0.43736341993014016} | train loss {'Reaction outcome loss': 0.18834943262465897, 'Total loss': 0.18834943262465897}
2023-01-05 04:38:02,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:02,656 INFO:     Epoch: 73
2023-01-05 04:38:04,900 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47542757789293927, 'Total loss': 0.47542757789293927} | train loss {'Reaction outcome loss': 0.18208319131781203, 'Total loss': 0.18208319131781203}
2023-01-05 04:38:04,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:04,900 INFO:     Epoch: 74
2023-01-05 04:38:07,141 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4347828507423401, 'Total loss': 0.4347828507423401} | train loss {'Reaction outcome loss': 0.18079274904703463, 'Total loss': 0.18079274904703463}
2023-01-05 04:38:07,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:07,141 INFO:     Epoch: 75
2023-01-05 04:38:09,357 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44607614080111185, 'Total loss': 0.44607614080111185} | train loss {'Reaction outcome loss': 0.17804139121911441, 'Total loss': 0.17804139121911441}
2023-01-05 04:38:09,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:09,357 INFO:     Epoch: 76
2023-01-05 04:38:11,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46029804944992064, 'Total loss': 0.46029804944992064} | train loss {'Reaction outcome loss': 0.17740264625703223, 'Total loss': 0.17740264625703223}
2023-01-05 04:38:11,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:11,603 INFO:     Epoch: 77
2023-01-05 04:38:13,818 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43469420398275055, 'Total loss': 0.43469420398275055} | train loss {'Reaction outcome loss': 0.18232842690114232, 'Total loss': 0.18232842690114232}
2023-01-05 04:38:13,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:13,819 INFO:     Epoch: 78
2023-01-05 04:38:16,073 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42859130203723905, 'Total loss': 0.42859130203723905} | train loss {'Reaction outcome loss': 0.17708996165353452, 'Total loss': 0.17708996165353452}
2023-01-05 04:38:16,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:16,073 INFO:     Epoch: 79
2023-01-05 04:38:18,322 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44717651704947153, 'Total loss': 0.44717651704947153} | train loss {'Reaction outcome loss': 0.17656015138563286, 'Total loss': 0.17656015138563286}
2023-01-05 04:38:18,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:18,323 INFO:     Epoch: 80
2023-01-05 04:38:20,585 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4334939459959666, 'Total loss': 0.4334939459959666} | train loss {'Reaction outcome loss': 0.17461144674678136, 'Total loss': 0.17461144674678136}
2023-01-05 04:38:20,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:20,586 INFO:     Epoch: 81
2023-01-05 04:38:22,864 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4116020287076632, 'Total loss': 0.4116020287076632} | train loss {'Reaction outcome loss': 0.1761093873897717, 'Total loss': 0.1761093873897717}
2023-01-05 04:38:22,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:22,865 INFO:     Epoch: 82
2023-01-05 04:38:25,110 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42367644906044005, 'Total loss': 0.42367644906044005} | train loss {'Reaction outcome loss': 0.17437784092324057, 'Total loss': 0.17437784092324057}
2023-01-05 04:38:25,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:25,111 INFO:     Epoch: 83
2023-01-05 04:38:27,350 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4343913808465004, 'Total loss': 0.4343913808465004} | train loss {'Reaction outcome loss': 0.17787265768750524, 'Total loss': 0.17787265768750524}
2023-01-05 04:38:27,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:27,351 INFO:     Epoch: 84
2023-01-05 04:38:29,587 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43184493978818256, 'Total loss': 0.43184493978818256} | train loss {'Reaction outcome loss': 0.1717666804528775, 'Total loss': 0.1717666804528775}
2023-01-05 04:38:29,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:29,587 INFO:     Epoch: 85
2023-01-05 04:38:31,829 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4853771368662516, 'Total loss': 0.4853771368662516} | train loss {'Reaction outcome loss': 0.16790206530165389, 'Total loss': 0.16790206530165389}
2023-01-05 04:38:31,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:31,829 INFO:     Epoch: 86
2023-01-05 04:38:34,080 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4627288381258647, 'Total loss': 0.4627288381258647} | train loss {'Reaction outcome loss': 0.16717989840306832, 'Total loss': 0.16717989840306832}
2023-01-05 04:38:34,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:34,080 INFO:     Epoch: 87
2023-01-05 04:38:36,321 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.442566658059756, 'Total loss': 0.442566658059756} | train loss {'Reaction outcome loss': 0.165663649056134, 'Total loss': 0.165663649056134}
2023-01-05 04:38:36,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:36,321 INFO:     Epoch: 88
2023-01-05 04:38:38,557 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4355366624891758, 'Total loss': 0.4355366624891758} | train loss {'Reaction outcome loss': 0.17511315888854384, 'Total loss': 0.17511315888854384}
2023-01-05 04:38:38,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:38,558 INFO:     Epoch: 89
2023-01-05 04:38:40,759 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43549654334783555, 'Total loss': 0.43549654334783555} | train loss {'Reaction outcome loss': 0.17064486795791636, 'Total loss': 0.17064486795791636}
2023-01-05 04:38:40,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:40,759 INFO:     Epoch: 90
2023-01-05 04:38:42,919 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44571637908617656, 'Total loss': 0.44571637908617656} | train loss {'Reaction outcome loss': 0.167061318405462, 'Total loss': 0.167061318405462}
2023-01-05 04:38:42,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:42,920 INFO:     Epoch: 91
2023-01-05 04:38:45,103 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43430838187535603, 'Total loss': 0.43430838187535603} | train loss {'Reaction outcome loss': 0.17099429077271672, 'Total loss': 0.17099429077271672}
2023-01-05 04:38:45,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:45,103 INFO:     Epoch: 92
2023-01-05 04:38:47,221 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44390914440155027, 'Total loss': 0.44390914440155027} | train loss {'Reaction outcome loss': 0.17306410990329119, 'Total loss': 0.17306410990329119}
2023-01-05 04:38:47,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:47,221 INFO:     Epoch: 93
2023-01-05 04:38:49,437 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43370503187179565, 'Total loss': 0.43370503187179565} | train loss {'Reaction outcome loss': 0.1662164988764392, 'Total loss': 0.1662164988764392}
2023-01-05 04:38:49,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:49,437 INFO:     Epoch: 94
2023-01-05 04:38:51,573 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4508006831010183, 'Total loss': 0.4508006831010183} | train loss {'Reaction outcome loss': 0.1702997242355461, 'Total loss': 0.1702997242355461}
2023-01-05 04:38:51,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:51,573 INFO:     Epoch: 95
2023-01-05 04:38:53,731 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45249132414658866, 'Total loss': 0.45249132414658866} | train loss {'Reaction outcome loss': 0.1663462653973677, 'Total loss': 0.1663462653973677}
2023-01-05 04:38:53,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:53,731 INFO:     Epoch: 96
2023-01-05 04:38:55,955 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45418607592582705, 'Total loss': 0.45418607592582705} | train loss {'Reaction outcome loss': 0.16656783667909675, 'Total loss': 0.16656783667909675}
2023-01-05 04:38:55,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:55,957 INFO:     Epoch: 97
2023-01-05 04:38:58,072 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40867246030829846, 'Total loss': 0.40867246030829846} | train loss {'Reaction outcome loss': 0.16358341818954117, 'Total loss': 0.16358341818954117}
2023-01-05 04:38:58,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:38:58,072 INFO:     Epoch: 98
2023-01-05 04:39:00,290 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4176874101161957, 'Total loss': 0.4176874101161957} | train loss {'Reaction outcome loss': 0.15981149336622252, 'Total loss': 0.15981149336622252}
2023-01-05 04:39:00,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:00,290 INFO:     Epoch: 99
2023-01-05 04:39:02,482 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3853502864638964, 'Total loss': 0.3853502864638964} | train loss {'Reaction outcome loss': 0.16409989773554143, 'Total loss': 0.16409989773554143}
2023-01-05 04:39:02,483 INFO:     Best model found after epoch 34 of 100.
2023-01-05 04:39:02,483 INFO:   Done with stage: TRAINING
2023-01-05 04:39:02,483 INFO:   Starting stage: EVALUATION
2023-01-05 04:39:02,624 INFO:   Done with stage: EVALUATION
2023-01-05 04:39:02,624 INFO:   Leaving out SEQ value Fold_1
2023-01-05 04:39:02,637 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 04:39:02,637 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:39:03,280 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:39:03,280 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:39:03,352 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:39:03,352 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:39:03,352 INFO:     No hyperparam tuning for this model
2023-01-05 04:39:03,352 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:39:03,352 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:39:03,353 INFO:     None feature selector for col prot
2023-01-05 04:39:03,353 INFO:     None feature selector for col prot
2023-01-05 04:39:03,353 INFO:     None feature selector for col prot
2023-01-05 04:39:03,354 INFO:     None feature selector for col chem
2023-01-05 04:39:03,354 INFO:     None feature selector for col chem
2023-01-05 04:39:03,354 INFO:     None feature selector for col chem
2023-01-05 04:39:03,354 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:39:03,354 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:39:03,355 INFO:     Number of params in model 72931
2023-01-05 04:39:03,359 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:39:03,359 INFO:   Starting stage: TRAINING
2023-01-05 04:39:03,419 INFO:     Val loss before train {'Reaction outcome loss': 1.0391451597213746, 'Total loss': 1.0391451597213746}
2023-01-05 04:39:03,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:03,420 INFO:     Epoch: 0
2023-01-05 04:39:05,656 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8336507141590118, 'Total loss': 0.8336507141590118} | train loss {'Reaction outcome loss': 0.9630097242167396, 'Total loss': 0.9630097242167396}
2023-01-05 04:39:05,656 INFO:     Found new best model at epoch 0
2023-01-05 04:39:05,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:05,657 INFO:     Epoch: 1
2023-01-05 04:39:07,877 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5959279378255208, 'Total loss': 0.5959279378255208} | train loss {'Reaction outcome loss': 0.7005842594552214, 'Total loss': 0.7005842594552214}
2023-01-05 04:39:07,878 INFO:     Found new best model at epoch 1
2023-01-05 04:39:07,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:07,879 INFO:     Epoch: 2
2023-01-05 04:39:10,114 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5497410992781321, 'Total loss': 0.5497410992781321} | train loss {'Reaction outcome loss': 0.5535378868344927, 'Total loss': 0.5535378868344927}
2023-01-05 04:39:10,114 INFO:     Found new best model at epoch 2
2023-01-05 04:39:10,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:10,115 INFO:     Epoch: 3
2023-01-05 04:39:12,341 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49054251462221143, 'Total loss': 0.49054251462221143} | train loss {'Reaction outcome loss': 0.5155483831780671, 'Total loss': 0.5155483831780671}
2023-01-05 04:39:12,341 INFO:     Found new best model at epoch 3
2023-01-05 04:39:12,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:12,343 INFO:     Epoch: 4
2023-01-05 04:39:14,580 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47982295155525206, 'Total loss': 0.47982295155525206} | train loss {'Reaction outcome loss': 0.4823570198712558, 'Total loss': 0.4823570198712558}
2023-01-05 04:39:14,581 INFO:     Found new best model at epoch 4
2023-01-05 04:39:14,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:14,582 INFO:     Epoch: 5
2023-01-05 04:39:16,811 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5096670866012574, 'Total loss': 0.5096670866012574} | train loss {'Reaction outcome loss': 0.4537336494039445, 'Total loss': 0.4537336494039445}
2023-01-05 04:39:16,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:16,812 INFO:     Epoch: 6
2023-01-05 04:39:18,896 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4641043096780777, 'Total loss': 0.4641043096780777} | train loss {'Reaction outcome loss': 0.4373015858178591, 'Total loss': 0.4373015858178591}
2023-01-05 04:39:18,896 INFO:     Found new best model at epoch 6
2023-01-05 04:39:18,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:18,898 INFO:     Epoch: 7
2023-01-05 04:39:21,072 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4411673188209534, 'Total loss': 0.4411673188209534} | train loss {'Reaction outcome loss': 0.4175375580352588, 'Total loss': 0.4175375580352588}
2023-01-05 04:39:21,072 INFO:     Found new best model at epoch 7
2023-01-05 04:39:21,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:21,073 INFO:     Epoch: 8
2023-01-05 04:39:23,220 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4657087683677673, 'Total loss': 0.4657087683677673} | train loss {'Reaction outcome loss': 0.4043588812605743, 'Total loss': 0.4043588812605743}
2023-01-05 04:39:23,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:23,221 INFO:     Epoch: 9
2023-01-05 04:39:25,458 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47954085369904836, 'Total loss': 0.47954085369904836} | train loss {'Reaction outcome loss': 0.38702695778686635, 'Total loss': 0.38702695778686635}
2023-01-05 04:39:25,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:25,459 INFO:     Epoch: 10
2023-01-05 04:39:27,661 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4715769867102305, 'Total loss': 0.4715769867102305} | train loss {'Reaction outcome loss': 0.37543658439042793, 'Total loss': 0.37543658439042793}
2023-01-05 04:39:27,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:27,662 INFO:     Epoch: 11
2023-01-05 04:39:29,896 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4577132314443588, 'Total loss': 0.4577132314443588} | train loss {'Reaction outcome loss': 0.368958945039415, 'Total loss': 0.368958945039415}
2023-01-05 04:39:29,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:29,896 INFO:     Epoch: 12
2023-01-05 04:39:32,065 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45142749349276223, 'Total loss': 0.45142749349276223} | train loss {'Reaction outcome loss': 0.3566267239949564, 'Total loss': 0.3566267239949564}
2023-01-05 04:39:32,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:32,066 INFO:     Epoch: 13
2023-01-05 04:39:34,234 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4737064639727275, 'Total loss': 0.4737064639727275} | train loss {'Reaction outcome loss': 0.34830580616410634, 'Total loss': 0.34830580616410634}
2023-01-05 04:39:34,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:34,234 INFO:     Epoch: 14
2023-01-05 04:39:36,433 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4505776703357697, 'Total loss': 0.4505776703357697} | train loss {'Reaction outcome loss': 0.33954812363333947, 'Total loss': 0.33954812363333947}
2023-01-05 04:39:36,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:36,433 INFO:     Epoch: 15
2023-01-05 04:39:38,670 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4528279691934586, 'Total loss': 0.4528279691934586} | train loss {'Reaction outcome loss': 0.32832572581994274, 'Total loss': 0.32832572581994274}
2023-01-05 04:39:38,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:38,670 INFO:     Epoch: 16
2023-01-05 04:39:40,790 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4573799322048823, 'Total loss': 0.4573799322048823} | train loss {'Reaction outcome loss': 0.32242745441133086, 'Total loss': 0.32242745441133086}
2023-01-05 04:39:40,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:40,790 INFO:     Epoch: 17
2023-01-05 04:39:42,956 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4541923224925995, 'Total loss': 0.4541923224925995} | train loss {'Reaction outcome loss': 0.3133190050177331, 'Total loss': 0.3133190050177331}
2023-01-05 04:39:42,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:42,956 INFO:     Epoch: 18
2023-01-05 04:39:45,128 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44891499082247416, 'Total loss': 0.44891499082247416} | train loss {'Reaction outcome loss': 0.30632417908713333, 'Total loss': 0.30632417908713333}
2023-01-05 04:39:45,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:45,129 INFO:     Epoch: 19
2023-01-05 04:39:47,330 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4399629155794779, 'Total loss': 0.4399629155794779} | train loss {'Reaction outcome loss': 0.30346543494149714, 'Total loss': 0.30346543494149714}
2023-01-05 04:39:47,330 INFO:     Found new best model at epoch 19
2023-01-05 04:39:47,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:47,331 INFO:     Epoch: 20
2023-01-05 04:39:49,546 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4737984259923299, 'Total loss': 0.4737984259923299} | train loss {'Reaction outcome loss': 0.29875161376421466, 'Total loss': 0.29875161376421466}
2023-01-05 04:39:49,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:49,547 INFO:     Epoch: 21
2023-01-05 04:39:51,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45484789510567986, 'Total loss': 0.45484789510567986} | train loss {'Reaction outcome loss': 0.2896682479194481, 'Total loss': 0.2896682479194481}
2023-01-05 04:39:51,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:51,760 INFO:     Epoch: 22
2023-01-05 04:39:54,005 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45914055705070494, 'Total loss': 0.45914055705070494} | train loss {'Reaction outcome loss': 0.28681593252359516, 'Total loss': 0.28681593252359516}
2023-01-05 04:39:54,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:54,006 INFO:     Epoch: 23
2023-01-05 04:39:56,249 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45894969354073206, 'Total loss': 0.45894969354073206} | train loss {'Reaction outcome loss': 0.2814545161940538, 'Total loss': 0.2814545161940538}
2023-01-05 04:39:56,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:56,249 INFO:     Epoch: 24
2023-01-05 04:39:58,466 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4503438373406728, 'Total loss': 0.4503438373406728} | train loss {'Reaction outcome loss': 0.2772651288767148, 'Total loss': 0.2772651288767148}
2023-01-05 04:39:58,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:39:58,466 INFO:     Epoch: 25
2023-01-05 04:40:00,700 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44941220929225284, 'Total loss': 0.44941220929225284} | train loss {'Reaction outcome loss': 0.2734169368598148, 'Total loss': 0.2734169368598148}
2023-01-05 04:40:00,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:00,702 INFO:     Epoch: 26
2023-01-05 04:40:02,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4350445295373599, 'Total loss': 0.4350445295373599} | train loss {'Reaction outcome loss': 0.2668543330250974, 'Total loss': 0.2668543330250974}
2023-01-05 04:40:02,898 INFO:     Found new best model at epoch 26
2023-01-05 04:40:02,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:02,899 INFO:     Epoch: 27
2023-01-05 04:40:05,109 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44420893291632335, 'Total loss': 0.44420893291632335} | train loss {'Reaction outcome loss': 0.26448977753574393, 'Total loss': 0.26448977753574393}
2023-01-05 04:40:05,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:05,109 INFO:     Epoch: 28
2023-01-05 04:40:07,280 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4713111529747645, 'Total loss': 0.4713111529747645} | train loss {'Reaction outcome loss': 0.2649340000900909, 'Total loss': 0.2649340000900909}
2023-01-05 04:40:07,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:07,281 INFO:     Epoch: 29
2023-01-05 04:40:09,477 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43537588020165763, 'Total loss': 0.43537588020165763} | train loss {'Reaction outcome loss': 0.2605296489068844, 'Total loss': 0.2605296489068844}
2023-01-05 04:40:09,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:09,477 INFO:     Epoch: 30
2023-01-05 04:40:11,698 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4624973773956299, 'Total loss': 0.4624973773956299} | train loss {'Reaction outcome loss': 0.25678424662944394, 'Total loss': 0.25678424662944394}
2023-01-05 04:40:11,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:11,698 INFO:     Epoch: 31
2023-01-05 04:40:13,845 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4594533572594325, 'Total loss': 0.4594533572594325} | train loss {'Reaction outcome loss': 0.2542745806038869, 'Total loss': 0.2542745806038869}
2023-01-05 04:40:13,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:13,845 INFO:     Epoch: 32
2023-01-05 04:40:16,044 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44545957098404565, 'Total loss': 0.44545957098404565} | train loss {'Reaction outcome loss': 0.2519224741679691, 'Total loss': 0.2519224741679691}
2023-01-05 04:40:16,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:16,045 INFO:     Epoch: 33
2023-01-05 04:40:18,276 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4634558280309041, 'Total loss': 0.4634558280309041} | train loss {'Reaction outcome loss': 0.24763237506858188, 'Total loss': 0.24763237506858188}
2023-01-05 04:40:18,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:18,276 INFO:     Epoch: 34
2023-01-05 04:40:20,462 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47810058991114296, 'Total loss': 0.47810058991114296} | train loss {'Reaction outcome loss': 0.24706433478226192, 'Total loss': 0.24706433478226192}
2023-01-05 04:40:20,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:20,463 INFO:     Epoch: 35
2023-01-05 04:40:22,681 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4459554443756739, 'Total loss': 0.4459554443756739} | train loss {'Reaction outcome loss': 0.2414375913200261, 'Total loss': 0.2414375913200261}
2023-01-05 04:40:22,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:22,681 INFO:     Epoch: 36
2023-01-05 04:40:24,822 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4479318469762802, 'Total loss': 0.4479318469762802} | train loss {'Reaction outcome loss': 0.23863274090155198, 'Total loss': 0.23863274090155198}
2023-01-05 04:40:24,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:24,823 INFO:     Epoch: 37
2023-01-05 04:40:26,948 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4410611420869827, 'Total loss': 0.4410611420869827} | train loss {'Reaction outcome loss': 0.2381612158033752, 'Total loss': 0.2381612158033752}
2023-01-05 04:40:26,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:26,949 INFO:     Epoch: 38
2023-01-05 04:40:29,114 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4693272769451141, 'Total loss': 0.4693272769451141} | train loss {'Reaction outcome loss': 0.2354276959995066, 'Total loss': 0.2354276959995066}
2023-01-05 04:40:29,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:29,114 INFO:     Epoch: 39
2023-01-05 04:40:31,312 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43755027651786804, 'Total loss': 0.43755027651786804} | train loss {'Reaction outcome loss': 0.23199355360256493, 'Total loss': 0.23199355360256493}
2023-01-05 04:40:31,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:31,312 INFO:     Epoch: 40
2023-01-05 04:40:33,541 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4596138517061869, 'Total loss': 0.4596138517061869} | train loss {'Reaction outcome loss': 0.235241727978263, 'Total loss': 0.235241727978263}
2023-01-05 04:40:33,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:33,541 INFO:     Epoch: 41
2023-01-05 04:40:35,739 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4432345260555545, 'Total loss': 0.4432345260555545} | train loss {'Reaction outcome loss': 0.2270459386989148, 'Total loss': 0.2270459386989148}
2023-01-05 04:40:35,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:35,739 INFO:     Epoch: 42
2023-01-05 04:40:37,959 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.443715767065684, 'Total loss': 0.443715767065684} | train loss {'Reaction outcome loss': 0.22966821616461133, 'Total loss': 0.22966821616461133}
2023-01-05 04:40:37,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:37,961 INFO:     Epoch: 43
2023-01-05 04:40:40,117 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4640057682991028, 'Total loss': 0.4640057682991028} | train loss {'Reaction outcome loss': 0.22372540506962552, 'Total loss': 0.22372540506962552}
2023-01-05 04:40:40,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:40,117 INFO:     Epoch: 44
2023-01-05 04:40:42,367 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4822879135608673, 'Total loss': 0.4822879135608673} | train loss {'Reaction outcome loss': 0.22177499225431116, 'Total loss': 0.22177499225431116}
2023-01-05 04:40:42,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:42,368 INFO:     Epoch: 45
2023-01-05 04:40:44,493 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4770381967226664, 'Total loss': 0.4770381967226664} | train loss {'Reaction outcome loss': 0.22259150786719617, 'Total loss': 0.22259150786719617}
2023-01-05 04:40:44,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:44,494 INFO:     Epoch: 46
2023-01-05 04:40:46,709 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49240305622418723, 'Total loss': 0.49240305622418723} | train loss {'Reaction outcome loss': 0.2151537066441111, 'Total loss': 0.2151537066441111}
2023-01-05 04:40:46,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:46,709 INFO:     Epoch: 47
2023-01-05 04:40:48,845 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46044178307056427, 'Total loss': 0.46044178307056427} | train loss {'Reaction outcome loss': 0.2144414062856486, 'Total loss': 0.2144414062856486}
2023-01-05 04:40:48,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:48,845 INFO:     Epoch: 48
2023-01-05 04:40:51,071 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46487146193782486, 'Total loss': 0.46487146193782486} | train loss {'Reaction outcome loss': 0.21608376670220908, 'Total loss': 0.21608376670220908}
2023-01-05 04:40:51,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:51,072 INFO:     Epoch: 49
2023-01-05 04:40:53,292 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47512757082780205, 'Total loss': 0.47512757082780205} | train loss {'Reaction outcome loss': 0.21291359287965364, 'Total loss': 0.21291359287965364}
2023-01-05 04:40:53,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:53,292 INFO:     Epoch: 50
2023-01-05 04:40:55,506 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46006362040837606, 'Total loss': 0.46006362040837606} | train loss {'Reaction outcome loss': 0.2110551701770266, 'Total loss': 0.2110551701770266}
2023-01-05 04:40:55,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:55,506 INFO:     Epoch: 51
2023-01-05 04:40:57,723 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4619477917750677, 'Total loss': 0.4619477917750677} | train loss {'Reaction outcome loss': 0.20664132272240018, 'Total loss': 0.20664132272240018}
2023-01-05 04:40:57,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:57,724 INFO:     Epoch: 52
2023-01-05 04:40:59,970 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48411166965961455, 'Total loss': 0.48411166965961455} | train loss {'Reaction outcome loss': 0.21117993256240322, 'Total loss': 0.21117993256240322}
2023-01-05 04:40:59,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:40:59,971 INFO:     Epoch: 53
2023-01-05 04:41:02,128 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4734780212243398, 'Total loss': 0.4734780212243398} | train loss {'Reaction outcome loss': 0.2058415484655458, 'Total loss': 0.2058415484655458}
2023-01-05 04:41:02,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:02,128 INFO:     Epoch: 54
2023-01-05 04:41:04,278 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4768798033396403, 'Total loss': 0.4768798033396403} | train loss {'Reaction outcome loss': 0.20348089213489834, 'Total loss': 0.20348089213489834}
2023-01-05 04:41:04,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:04,278 INFO:     Epoch: 55
2023-01-05 04:41:06,526 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48554584582646687, 'Total loss': 0.48554584582646687} | train loss {'Reaction outcome loss': 0.21104049034090372, 'Total loss': 0.21104049034090372}
2023-01-05 04:41:06,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:06,526 INFO:     Epoch: 56
2023-01-05 04:41:08,760 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4827624946832657, 'Total loss': 0.4827624946832657} | train loss {'Reaction outcome loss': 0.19799609843430782, 'Total loss': 0.19799609843430782}
2023-01-05 04:41:08,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:08,761 INFO:     Epoch: 57
2023-01-05 04:41:10,890 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4940462738275528, 'Total loss': 0.4940462738275528} | train loss {'Reaction outcome loss': 0.19801701245027303, 'Total loss': 0.19801701245027303}
2023-01-05 04:41:10,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:10,891 INFO:     Epoch: 58
2023-01-05 04:41:13,089 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4830433249473572, 'Total loss': 0.4830433249473572} | train loss {'Reaction outcome loss': 0.1989858088382676, 'Total loss': 0.1989858088382676}
2023-01-05 04:41:13,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:13,089 INFO:     Epoch: 59
2023-01-05 04:41:15,330 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5102085789044698, 'Total loss': 0.5102085789044698} | train loss {'Reaction outcome loss': 0.195684211236853, 'Total loss': 0.195684211236853}
2023-01-05 04:41:15,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:15,331 INFO:     Epoch: 60
2023-01-05 04:41:17,548 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48985662559668225, 'Total loss': 0.48985662559668225} | train loss {'Reaction outcome loss': 0.19419595316888588, 'Total loss': 0.19419595316888588}
2023-01-05 04:41:17,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:17,548 INFO:     Epoch: 61
2023-01-05 04:41:19,777 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4899833162625631, 'Total loss': 0.4899833162625631} | train loss {'Reaction outcome loss': 0.19928335378721465, 'Total loss': 0.19928335378721465}
2023-01-05 04:41:19,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:19,777 INFO:     Epoch: 62
2023-01-05 04:41:21,916 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45386785666147866, 'Total loss': 0.45386785666147866} | train loss {'Reaction outcome loss': 0.1967887445251002, 'Total loss': 0.1967887445251002}
2023-01-05 04:41:21,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:21,916 INFO:     Epoch: 63
2023-01-05 04:41:24,139 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4975783089796702, 'Total loss': 0.4975783089796702} | train loss {'Reaction outcome loss': 0.19383800699695075, 'Total loss': 0.19383800699695075}
2023-01-05 04:41:24,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:24,140 INFO:     Epoch: 64
2023-01-05 04:41:26,379 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5223220974206925, 'Total loss': 0.5223220974206925} | train loss {'Reaction outcome loss': 0.1914282178057589, 'Total loss': 0.1914282178057589}
2023-01-05 04:41:26,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:26,380 INFO:     Epoch: 65
2023-01-05 04:41:28,613 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4622722456852595, 'Total loss': 0.4622722456852595} | train loss {'Reaction outcome loss': 0.19073650270809223, 'Total loss': 0.19073650270809223}
2023-01-05 04:41:28,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:28,614 INFO:     Epoch: 66
2023-01-05 04:41:30,841 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4781572158137957, 'Total loss': 0.4781572158137957} | train loss {'Reaction outcome loss': 0.18914054579230666, 'Total loss': 0.18914054579230666}
2023-01-05 04:41:30,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:30,841 INFO:     Epoch: 67
2023-01-05 04:41:33,043 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48001175274451574, 'Total loss': 0.48001175274451574} | train loss {'Reaction outcome loss': 0.19007293544165846, 'Total loss': 0.19007293544165846}
2023-01-05 04:41:33,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:33,043 INFO:     Epoch: 68
2023-01-05 04:41:35,152 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48574966887633003, 'Total loss': 0.48574966887633003} | train loss {'Reaction outcome loss': 0.18745357598973453, 'Total loss': 0.18745357598973453}
2023-01-05 04:41:35,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:35,153 INFO:     Epoch: 69
2023-01-05 04:41:37,339 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5182061890761057, 'Total loss': 0.5182061890761057} | train loss {'Reaction outcome loss': 0.18847766218802137, 'Total loss': 0.18847766218802137}
2023-01-05 04:41:37,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:37,340 INFO:     Epoch: 70
2023-01-05 04:41:39,572 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4924005856116613, 'Total loss': 0.4924005856116613} | train loss {'Reaction outcome loss': 0.1913031958057171, 'Total loss': 0.1913031958057171}
2023-01-05 04:41:39,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:39,573 INFO:     Epoch: 71
2023-01-05 04:41:41,820 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4622021441037456, 'Total loss': 0.4622021441037456} | train loss {'Reaction outcome loss': 0.18542182988004527, 'Total loss': 0.18542182988004527}
2023-01-05 04:41:41,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:41,820 INFO:     Epoch: 72
2023-01-05 04:41:43,984 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4744840224583944, 'Total loss': 0.4744840224583944} | train loss {'Reaction outcome loss': 0.1887591906490117, 'Total loss': 0.1887591906490117}
2023-01-05 04:41:43,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:43,984 INFO:     Epoch: 73
2023-01-05 04:41:46,219 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5084763705730438, 'Total loss': 0.5084763705730438} | train loss {'Reaction outcome loss': 0.1819178852895071, 'Total loss': 0.1819178852895071}
2023-01-05 04:41:46,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:46,220 INFO:     Epoch: 74
2023-01-05 04:41:48,444 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5090943813323975, 'Total loss': 0.5090943813323975} | train loss {'Reaction outcome loss': 0.18419109495615002, 'Total loss': 0.18419109495615002}
2023-01-05 04:41:48,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:48,444 INFO:     Epoch: 75
2023-01-05 04:41:50,691 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44862004766861596, 'Total loss': 0.44862004766861596} | train loss {'Reaction outcome loss': 0.18613666176530838, 'Total loss': 0.18613666176530838}
2023-01-05 04:41:50,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:50,691 INFO:     Epoch: 76
2023-01-05 04:41:52,915 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5034772853056589, 'Total loss': 0.5034772853056589} | train loss {'Reaction outcome loss': 0.18385653072002814, 'Total loss': 0.18385653072002814}
2023-01-05 04:41:52,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:52,915 INFO:     Epoch: 77
2023-01-05 04:41:55,056 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46290433009465537, 'Total loss': 0.46290433009465537} | train loss {'Reaction outcome loss': 0.1830569637912142, 'Total loss': 0.1830569637912142}
2023-01-05 04:41:55,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:55,056 INFO:     Epoch: 78
2023-01-05 04:41:57,270 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46574850877126056, 'Total loss': 0.46574850877126056} | train loss {'Reaction outcome loss': 0.17943474331388018, 'Total loss': 0.17943474331388018}
2023-01-05 04:41:57,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:57,270 INFO:     Epoch: 79
2023-01-05 04:41:59,456 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49269337750350434, 'Total loss': 0.49269337750350434} | train loss {'Reaction outcome loss': 0.17834672813106628, 'Total loss': 0.17834672813106628}
2023-01-05 04:41:59,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:41:59,457 INFO:     Epoch: 80
2023-01-05 04:42:01,654 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48468901713689166, 'Total loss': 0.48468901713689166} | train loss {'Reaction outcome loss': 0.18247340556852737, 'Total loss': 0.18247340556852737}
2023-01-05 04:42:01,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:01,654 INFO:     Epoch: 81
2023-01-05 04:42:03,799 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4980906158685684, 'Total loss': 0.4980906158685684} | train loss {'Reaction outcome loss': 0.17945149883349173, 'Total loss': 0.17945149883349173}
2023-01-05 04:42:03,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:03,799 INFO:     Epoch: 82
2023-01-05 04:42:06,035 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4877722842618823, 'Total loss': 0.4877722842618823} | train loss {'Reaction outcome loss': 0.17434120485491125, 'Total loss': 0.17434120485491125}
2023-01-05 04:42:06,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:06,035 INFO:     Epoch: 83
2023-01-05 04:42:08,248 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5039418280124665, 'Total loss': 0.5039418280124665} | train loss {'Reaction outcome loss': 0.17860843393489392, 'Total loss': 0.17860843393489392}
2023-01-05 04:42:08,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:08,248 INFO:     Epoch: 84
2023-01-05 04:42:10,426 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49504118065039315, 'Total loss': 0.49504118065039315} | train loss {'Reaction outcome loss': 0.17840893455801438, 'Total loss': 0.17840893455801438}
2023-01-05 04:42:10,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:10,427 INFO:     Epoch: 85
2023-01-05 04:42:12,624 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5131001154581706, 'Total loss': 0.5131001154581706} | train loss {'Reaction outcome loss': 0.17518471772306646, 'Total loss': 0.17518471772306646}
2023-01-05 04:42:12,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:12,625 INFO:     Epoch: 86
2023-01-05 04:42:14,752 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49604812959829964, 'Total loss': 0.49604812959829964} | train loss {'Reaction outcome loss': 0.17790165489512313, 'Total loss': 0.17790165489512313}
2023-01-05 04:42:14,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:14,752 INFO:     Epoch: 87
2023-01-05 04:42:16,877 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5209570497274398, 'Total loss': 0.5209570497274398} | train loss {'Reaction outcome loss': 0.1748754064226183, 'Total loss': 0.1748754064226183}
2023-01-05 04:42:16,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:16,878 INFO:     Epoch: 88
2023-01-05 04:42:19,044 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4642759730418523, 'Total loss': 0.4642759730418523} | train loss {'Reaction outcome loss': 0.17662618681788445, 'Total loss': 0.17662618681788445}
2023-01-05 04:42:19,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:19,044 INFO:     Epoch: 89
2023-01-05 04:42:21,258 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5072883009910584, 'Total loss': 0.5072883009910584} | train loss {'Reaction outcome loss': 0.1767830223518077, 'Total loss': 0.1767830223518077}
2023-01-05 04:42:21,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:21,258 INFO:     Epoch: 90
2023-01-05 04:42:23,437 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49256335496902465, 'Total loss': 0.49256335496902465} | train loss {'Reaction outcome loss': 0.17180154211887153, 'Total loss': 0.17180154211887153}
2023-01-05 04:42:23,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:23,437 INFO:     Epoch: 91
2023-01-05 04:42:25,629 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48684602975845337, 'Total loss': 0.48684602975845337} | train loss {'Reaction outcome loss': 0.17059670345871336, 'Total loss': 0.17059670345871336}
2023-01-05 04:42:25,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:25,630 INFO:     Epoch: 92
2023-01-05 04:42:27,868 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5396519134442012, 'Total loss': 0.5396519134442012} | train loss {'Reaction outcome loss': 0.1714695806506287, 'Total loss': 0.1714695806506287}
2023-01-05 04:42:27,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:27,868 INFO:     Epoch: 93
2023-01-05 04:42:30,079 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4855547746022542, 'Total loss': 0.4855547746022542} | train loss {'Reaction outcome loss': 0.17079009663612738, 'Total loss': 0.17079009663612738}
2023-01-05 04:42:30,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:30,080 INFO:     Epoch: 94
2023-01-05 04:42:32,301 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.524248410264651, 'Total loss': 0.524248410264651} | train loss {'Reaction outcome loss': 0.1736270376654464, 'Total loss': 0.1736270376654464}
2023-01-05 04:42:32,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:32,301 INFO:     Epoch: 95
2023-01-05 04:42:34,496 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4889355053504308, 'Total loss': 0.4889355053504308} | train loss {'Reaction outcome loss': 0.16739396611398535, 'Total loss': 0.16739396611398535}
2023-01-05 04:42:34,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:34,496 INFO:     Epoch: 96
2023-01-05 04:42:36,739 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47548846937716005, 'Total loss': 0.47548846937716005} | train loss {'Reaction outcome loss': 0.1758004767296795, 'Total loss': 0.1758004767296795}
2023-01-05 04:42:36,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:36,740 INFO:     Epoch: 97
2023-01-05 04:42:38,854 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5001605014006297, 'Total loss': 0.5001605014006297} | train loss {'Reaction outcome loss': 0.17213642069675628, 'Total loss': 0.17213642069675628}
2023-01-05 04:42:38,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:38,855 INFO:     Epoch: 98
2023-01-05 04:42:40,997 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49933662712574006, 'Total loss': 0.49933662712574006} | train loss {'Reaction outcome loss': 0.17002680111102025, 'Total loss': 0.17002680111102025}
2023-01-05 04:42:40,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:40,998 INFO:     Epoch: 99
2023-01-05 04:42:43,116 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49803479115168253, 'Total loss': 0.49803479115168253} | train loss {'Reaction outcome loss': 0.16880130581217853, 'Total loss': 0.16880130581217853}
2023-01-05 04:42:43,117 INFO:     Best model found after epoch 27 of 100.
2023-01-05 04:42:43,117 INFO:   Done with stage: TRAINING
2023-01-05 04:42:43,117 INFO:   Starting stage: EVALUATION
2023-01-05 04:42:43,260 INFO:   Done with stage: EVALUATION
2023-01-05 04:42:43,260 INFO:   Leaving out SEQ value Fold_2
2023-01-05 04:42:43,273 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 04:42:43,273 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:42:43,905 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:42:43,905 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:42:43,976 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:42:43,976 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:42:43,976 INFO:     No hyperparam tuning for this model
2023-01-05 04:42:43,976 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:42:43,976 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:42:43,977 INFO:     None feature selector for col prot
2023-01-05 04:42:43,977 INFO:     None feature selector for col prot
2023-01-05 04:42:43,977 INFO:     None feature selector for col prot
2023-01-05 04:42:43,978 INFO:     None feature selector for col chem
2023-01-05 04:42:43,978 INFO:     None feature selector for col chem
2023-01-05 04:42:43,978 INFO:     None feature selector for col chem
2023-01-05 04:42:43,978 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:42:43,978 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:42:43,979 INFO:     Number of params in model 72931
2023-01-05 04:42:43,983 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:42:43,983 INFO:   Starting stage: TRAINING
2023-01-05 04:42:44,043 INFO:     Val loss before train {'Reaction outcome loss': 0.8206469496091207, 'Total loss': 0.8206469496091207}
2023-01-05 04:42:44,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:44,043 INFO:     Epoch: 0
2023-01-05 04:42:46,209 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.687544846534729, 'Total loss': 0.687544846534729} | train loss {'Reaction outcome loss': 0.9652188659369291, 'Total loss': 0.9652188659369291}
2023-01-05 04:42:46,209 INFO:     Found new best model at epoch 0
2023-01-05 04:42:46,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:46,210 INFO:     Epoch: 1
2023-01-05 04:42:48,412 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5178307731946309, 'Total loss': 0.5178307731946309} | train loss {'Reaction outcome loss': 0.658969814032862, 'Total loss': 0.658969814032862}
2023-01-05 04:42:48,412 INFO:     Found new best model at epoch 1
2023-01-05 04:42:48,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:48,414 INFO:     Epoch: 2
2023-01-05 04:42:50,641 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4832492599884669, 'Total loss': 0.4832492599884669} | train loss {'Reaction outcome loss': 0.5372539495046322, 'Total loss': 0.5372539495046322}
2023-01-05 04:42:50,641 INFO:     Found new best model at epoch 2
2023-01-05 04:42:50,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:50,643 INFO:     Epoch: 3
2023-01-05 04:42:52,864 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5045187552769979, 'Total loss': 0.5045187552769979} | train loss {'Reaction outcome loss': 0.49188593537597863, 'Total loss': 0.49188593537597863}
2023-01-05 04:42:52,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:52,864 INFO:     Epoch: 4
2023-01-05 04:42:55,037 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4644574801127116, 'Total loss': 0.4644574801127116} | train loss {'Reaction outcome loss': 0.46767577004956673, 'Total loss': 0.46767577004956673}
2023-01-05 04:42:55,037 INFO:     Found new best model at epoch 4
2023-01-05 04:42:55,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:55,039 INFO:     Epoch: 5
2023-01-05 04:42:57,234 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45776494493087133, 'Total loss': 0.45776494493087133} | train loss {'Reaction outcome loss': 0.4433084155395354, 'Total loss': 0.4433084155395354}
2023-01-05 04:42:57,234 INFO:     Found new best model at epoch 5
2023-01-05 04:42:57,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:57,236 INFO:     Epoch: 6
2023-01-05 04:42:59,440 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48083029985427855, 'Total loss': 0.48083029985427855} | train loss {'Reaction outcome loss': 0.42891166151770743, 'Total loss': 0.42891166151770743}
2023-01-05 04:42:59,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:42:59,440 INFO:     Epoch: 7
2023-01-05 04:43:01,646 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4390927811463674, 'Total loss': 0.4390927811463674} | train loss {'Reaction outcome loss': 0.41411080203213535, 'Total loss': 0.41411080203213535}
2023-01-05 04:43:01,647 INFO:     Found new best model at epoch 7
2023-01-05 04:43:01,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:01,649 INFO:     Epoch: 8
2023-01-05 04:43:03,837 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46119781931241355, 'Total loss': 0.46119781931241355} | train loss {'Reaction outcome loss': 0.4001740690443542, 'Total loss': 0.4001740690443542}
2023-01-05 04:43:03,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:03,837 INFO:     Epoch: 9
2023-01-05 04:43:06,018 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42900414715210594, 'Total loss': 0.42900414715210594} | train loss {'Reaction outcome loss': 0.3855533662078145, 'Total loss': 0.3855533662078145}
2023-01-05 04:43:06,018 INFO:     Found new best model at epoch 9
2023-01-05 04:43:06,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:06,020 INFO:     Epoch: 10
2023-01-05 04:43:08,219 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4420045892397563, 'Total loss': 0.4420045892397563} | train loss {'Reaction outcome loss': 0.3787123572640803, 'Total loss': 0.3787123572640803}
2023-01-05 04:43:08,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:08,219 INFO:     Epoch: 11
2023-01-05 04:43:10,405 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44157667259375255, 'Total loss': 0.44157667259375255} | train loss {'Reaction outcome loss': 0.3642049170075319, 'Total loss': 0.3642049170075319}
2023-01-05 04:43:10,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:10,406 INFO:     Epoch: 12
2023-01-05 04:43:12,550 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.452058944106102, 'Total loss': 0.452058944106102} | train loss {'Reaction outcome loss': 0.3505098437378695, 'Total loss': 0.3505098437378695}
2023-01-05 04:43:12,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:12,550 INFO:     Epoch: 13
2023-01-05 04:43:14,702 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43021538158257805, 'Total loss': 0.43021538158257805} | train loss {'Reaction outcome loss': 0.3468511423894337, 'Total loss': 0.3468511423894337}
2023-01-05 04:43:14,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:14,702 INFO:     Epoch: 14
2023-01-05 04:43:16,818 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46442000766595204, 'Total loss': 0.46442000766595204} | train loss {'Reaction outcome loss': 0.33803937221184754, 'Total loss': 0.33803937221184754}
2023-01-05 04:43:16,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:16,819 INFO:     Epoch: 15
2023-01-05 04:43:19,014 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4265464802583059, 'Total loss': 0.4265464802583059} | train loss {'Reaction outcome loss': 0.33199298228972995, 'Total loss': 0.33199298228972995}
2023-01-05 04:43:19,015 INFO:     Found new best model at epoch 15
2023-01-05 04:43:19,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:19,016 INFO:     Epoch: 16
2023-01-05 04:43:21,214 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4637628177801768, 'Total loss': 0.4637628177801768} | train loss {'Reaction outcome loss': 0.322978794110782, 'Total loss': 0.322978794110782}
2023-01-05 04:43:21,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:21,214 INFO:     Epoch: 17
2023-01-05 04:43:23,250 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42742520769437153, 'Total loss': 0.42742520769437153} | train loss {'Reaction outcome loss': 0.31979038125593146, 'Total loss': 0.31979038125593146}
2023-01-05 04:43:23,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:23,250 INFO:     Epoch: 18
2023-01-05 04:43:25,446 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4257864716773232, 'Total loss': 0.4257864716773232} | train loss {'Reaction outcome loss': 0.3120138217241336, 'Total loss': 0.3120138217241336}
2023-01-05 04:43:25,446 INFO:     Found new best model at epoch 18
2023-01-05 04:43:25,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:25,447 INFO:     Epoch: 19
2023-01-05 04:43:27,678 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4470299353202184, 'Total loss': 0.4470299353202184} | train loss {'Reaction outcome loss': 0.30723912697353645, 'Total loss': 0.30723912697353645}
2023-01-05 04:43:27,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:27,678 INFO:     Epoch: 20
2023-01-05 04:43:29,881 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4349573974808057, 'Total loss': 0.4349573974808057} | train loss {'Reaction outcome loss': 0.2995060869107098, 'Total loss': 0.2995060869107098}
2023-01-05 04:43:29,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:29,882 INFO:     Epoch: 21
2023-01-05 04:43:32,107 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4520817498366038, 'Total loss': 0.4520817498366038} | train loss {'Reaction outcome loss': 0.2924996945365663, 'Total loss': 0.2924996945365663}
2023-01-05 04:43:32,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:32,107 INFO:     Epoch: 22
2023-01-05 04:43:34,338 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44299009442329407, 'Total loss': 0.44299009442329407} | train loss {'Reaction outcome loss': 0.28802860668781916, 'Total loss': 0.28802860668781916}
2023-01-05 04:43:34,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:34,338 INFO:     Epoch: 23
2023-01-05 04:43:36,494 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4583171268304189, 'Total loss': 0.4583171268304189} | train loss {'Reaction outcome loss': 0.28688933054879034, 'Total loss': 0.28688933054879034}
2023-01-05 04:43:36,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:36,494 INFO:     Epoch: 24
2023-01-05 04:43:38,717 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4469106356302897, 'Total loss': 0.4469106356302897} | train loss {'Reaction outcome loss': 0.27769232994361676, 'Total loss': 0.27769232994361676}
2023-01-05 04:43:38,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:38,717 INFO:     Epoch: 25
2023-01-05 04:43:40,918 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4631307045618693, 'Total loss': 0.4631307045618693} | train loss {'Reaction outcome loss': 0.27531507461171445, 'Total loss': 0.27531507461171445}
2023-01-05 04:43:40,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:40,918 INFO:     Epoch: 26
2023-01-05 04:43:43,114 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44848458766937255, 'Total loss': 0.44848458766937255} | train loss {'Reaction outcome loss': 0.2674026751529166, 'Total loss': 0.2674026751529166}
2023-01-05 04:43:43,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:43,114 INFO:     Epoch: 27
2023-01-05 04:43:45,329 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46487929224967955, 'Total loss': 0.46487929224967955} | train loss {'Reaction outcome loss': 0.2668765078506845, 'Total loss': 0.2668765078506845}
2023-01-05 04:43:45,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:45,329 INFO:     Epoch: 28
2023-01-05 04:43:47,545 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4864869366089503, 'Total loss': 0.4864869366089503} | train loss {'Reaction outcome loss': 0.2612449261854529, 'Total loss': 0.2612449261854529}
2023-01-05 04:43:47,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:47,547 INFO:     Epoch: 29
2023-01-05 04:43:49,776 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5010198324918747, 'Total loss': 0.5010198324918747} | train loss {'Reaction outcome loss': 0.2572673647135714, 'Total loss': 0.2572673647135714}
2023-01-05 04:43:49,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:49,776 INFO:     Epoch: 30
2023-01-05 04:43:51,976 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4662534157435099, 'Total loss': 0.4662534157435099} | train loss {'Reaction outcome loss': 0.25570187231205105, 'Total loss': 0.25570187231205105}
2023-01-05 04:43:51,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:51,976 INFO:     Epoch: 31
2023-01-05 04:43:54,143 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4664570411046346, 'Total loss': 0.4664570411046346} | train loss {'Reaction outcome loss': 0.2562933507351539, 'Total loss': 0.2562933507351539}
2023-01-05 04:43:54,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:54,144 INFO:     Epoch: 32
2023-01-05 04:43:56,318 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4802588830391566, 'Total loss': 0.4802588830391566} | train loss {'Reaction outcome loss': 0.2524800533667589, 'Total loss': 0.2524800533667589}
2023-01-05 04:43:56,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:56,318 INFO:     Epoch: 33
2023-01-05 04:43:58,524 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46333476503690085, 'Total loss': 0.46333476503690085} | train loss {'Reaction outcome loss': 0.2439911512337325, 'Total loss': 0.2439911512337325}
2023-01-05 04:43:58,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:43:58,524 INFO:     Epoch: 34
2023-01-05 04:44:00,730 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48855150043964385, 'Total loss': 0.48855150043964385} | train loss {'Reaction outcome loss': 0.24172374250660666, 'Total loss': 0.24172374250660666}
2023-01-05 04:44:00,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:00,731 INFO:     Epoch: 35
2023-01-05 04:44:02,876 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4746522833903631, 'Total loss': 0.4746522833903631} | train loss {'Reaction outcome loss': 0.24003060733483278, 'Total loss': 0.24003060733483278}
2023-01-05 04:44:02,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:02,876 INFO:     Epoch: 36
2023-01-05 04:44:05,050 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.448838809132576, 'Total loss': 0.448838809132576} | train loss {'Reaction outcome loss': 0.23930551657528232, 'Total loss': 0.23930551657528232}
2023-01-05 04:44:05,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:05,050 INFO:     Epoch: 37
2023-01-05 04:44:07,223 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4987359970808029, 'Total loss': 0.4987359970808029} | train loss {'Reaction outcome loss': 0.2344725966358032, 'Total loss': 0.2344725966358032}
2023-01-05 04:44:07,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:07,223 INFO:     Epoch: 38
2023-01-05 04:44:09,444 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4373334854841232, 'Total loss': 0.4373334854841232} | train loss {'Reaction outcome loss': 0.2356045228043646, 'Total loss': 0.2356045228043646}
2023-01-05 04:44:09,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:09,445 INFO:     Epoch: 39
2023-01-05 04:44:11,676 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4754493733247121, 'Total loss': 0.4754493733247121} | train loss {'Reaction outcome loss': 0.2314034341612742, 'Total loss': 0.2314034341612742}
2023-01-05 04:44:11,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:11,677 INFO:     Epoch: 40
2023-01-05 04:44:13,904 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48556253910064695, 'Total loss': 0.48556253910064695} | train loss {'Reaction outcome loss': 0.22593268347501536, 'Total loss': 0.22593268347501536}
2023-01-05 04:44:13,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:13,904 INFO:     Epoch: 41
2023-01-05 04:44:16,123 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45612741087873776, 'Total loss': 0.45612741087873776} | train loss {'Reaction outcome loss': 0.21779612876856938, 'Total loss': 0.21779612876856938}
2023-01-05 04:44:16,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:16,123 INFO:     Epoch: 42
2023-01-05 04:44:18,334 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48450578122089305, 'Total loss': 0.48450578122089305} | train loss {'Reaction outcome loss': 0.21857367127096697, 'Total loss': 0.21857367127096697}
2023-01-05 04:44:18,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:18,335 INFO:     Epoch: 43
2023-01-05 04:44:20,552 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46814223428567253, 'Total loss': 0.46814223428567253} | train loss {'Reaction outcome loss': 0.216364877397406, 'Total loss': 0.216364877397406}
2023-01-05 04:44:20,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:20,552 INFO:     Epoch: 44
2023-01-05 04:44:22,779 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45752528061469394, 'Total loss': 0.45752528061469394} | train loss {'Reaction outcome loss': 0.21581484781298446, 'Total loss': 0.21581484781298446}
2023-01-05 04:44:22,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:22,779 INFO:     Epoch: 45
2023-01-05 04:44:24,997 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46356886327266694, 'Total loss': 0.46356886327266694} | train loss {'Reaction outcome loss': 0.21691931030225187, 'Total loss': 0.21691931030225187}
2023-01-05 04:44:24,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:24,998 INFO:     Epoch: 46
2023-01-05 04:44:27,143 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47162230213483175, 'Total loss': 0.47162230213483175} | train loss {'Reaction outcome loss': 0.21017304090134828, 'Total loss': 0.21017304090134828}
2023-01-05 04:44:27,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:27,143 INFO:     Epoch: 47
2023-01-05 04:44:29,347 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45595614281482993, 'Total loss': 0.45595614281482993} | train loss {'Reaction outcome loss': 0.20397420373878308, 'Total loss': 0.20397420373878308}
2023-01-05 04:44:29,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:29,347 INFO:     Epoch: 48
2023-01-05 04:44:31,575 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46385444949070614, 'Total loss': 0.46385444949070614} | train loss {'Reaction outcome loss': 0.20884237131752045, 'Total loss': 0.20884237131752045}
2023-01-05 04:44:31,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:31,575 INFO:     Epoch: 49
2023-01-05 04:44:33,812 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.465061761935552, 'Total loss': 0.465061761935552} | train loss {'Reaction outcome loss': 0.20729614904784893, 'Total loss': 0.20729614904784893}
2023-01-05 04:44:33,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:33,812 INFO:     Epoch: 50
2023-01-05 04:44:36,033 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4900322238604228, 'Total loss': 0.4900322238604228} | train loss {'Reaction outcome loss': 0.2086721754295158, 'Total loss': 0.2086721754295158}
2023-01-05 04:44:36,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:36,034 INFO:     Epoch: 51
2023-01-05 04:44:38,241 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43306620901760956, 'Total loss': 0.43306620901760956} | train loss {'Reaction outcome loss': 0.20330425222052922, 'Total loss': 0.20330425222052922}
2023-01-05 04:44:38,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:38,242 INFO:     Epoch: 52
2023-01-05 04:44:40,443 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4639642914136251, 'Total loss': 0.4639642914136251} | train loss {'Reaction outcome loss': 0.2046844253125481, 'Total loss': 0.2046844253125481}
2023-01-05 04:44:40,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:40,443 INFO:     Epoch: 53
2023-01-05 04:44:42,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49315925339857736, 'Total loss': 0.49315925339857736} | train loss {'Reaction outcome loss': 0.20117048073164273, 'Total loss': 0.20117048073164273}
2023-01-05 04:44:42,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:42,660 INFO:     Epoch: 54
2023-01-05 04:44:44,888 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45785358945528665, 'Total loss': 0.45785358945528665} | train loss {'Reaction outcome loss': 0.19876120330581626, 'Total loss': 0.19876120330581626}
2023-01-05 04:44:44,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:44,888 INFO:     Epoch: 55
2023-01-05 04:44:47,103 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4528125872214635, 'Total loss': 0.4528125872214635} | train loss {'Reaction outcome loss': 0.1972210572336565, 'Total loss': 0.1972210572336565}
2023-01-05 04:44:47,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:47,103 INFO:     Epoch: 56
2023-01-05 04:44:49,316 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47238050897916156, 'Total loss': 0.47238050897916156} | train loss {'Reaction outcome loss': 0.19702534951719936, 'Total loss': 0.19702534951719936}
2023-01-05 04:44:49,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:49,317 INFO:     Epoch: 57
2023-01-05 04:44:51,516 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46060281693935395, 'Total loss': 0.46060281693935395} | train loss {'Reaction outcome loss': 0.1951508159918076, 'Total loss': 0.1951508159918076}
2023-01-05 04:44:51,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:51,516 INFO:     Epoch: 58
2023-01-05 04:44:53,702 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4503341168165207, 'Total loss': 0.4503341168165207} | train loss {'Reaction outcome loss': 0.19401998263391437, 'Total loss': 0.19401998263391437}
2023-01-05 04:44:53,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:53,702 INFO:     Epoch: 59
2023-01-05 04:44:55,927 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4858946859836578, 'Total loss': 0.4858946859836578} | train loss {'Reaction outcome loss': 0.19258998819855433, 'Total loss': 0.19258998819855433}
2023-01-05 04:44:55,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:55,928 INFO:     Epoch: 60
2023-01-05 04:44:58,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.463624503215154, 'Total loss': 0.463624503215154} | train loss {'Reaction outcome loss': 0.19650708338852985, 'Total loss': 0.19650708338852985}
2023-01-05 04:44:58,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:44:58,117 INFO:     Epoch: 61
2023-01-05 04:45:00,324 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4691249281167984, 'Total loss': 0.4691249281167984} | train loss {'Reaction outcome loss': 0.19036858601857237, 'Total loss': 0.19036858601857237}
2023-01-05 04:45:00,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:00,325 INFO:     Epoch: 62
2023-01-05 04:45:02,530 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5084417144457499, 'Total loss': 0.5084417144457499} | train loss {'Reaction outcome loss': 0.1871361070766281, 'Total loss': 0.1871361070766281}
2023-01-05 04:45:02,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:02,531 INFO:     Epoch: 63
2023-01-05 04:45:04,722 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4805680463711421, 'Total loss': 0.4805680463711421} | train loss {'Reaction outcome loss': 0.19080626115803317, 'Total loss': 0.19080626115803317}
2023-01-05 04:45:04,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:04,723 INFO:     Epoch: 64
2023-01-05 04:45:06,933 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4591894110043844, 'Total loss': 0.4591894110043844} | train loss {'Reaction outcome loss': 0.1868064028343984, 'Total loss': 0.1868064028343984}
2023-01-05 04:45:06,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:06,933 INFO:     Epoch: 65
2023-01-05 04:45:09,161 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5032020250956217, 'Total loss': 0.5032020250956217} | train loss {'Reaction outcome loss': 0.18882971264817666, 'Total loss': 0.18882971264817666}
2023-01-05 04:45:09,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:09,162 INFO:     Epoch: 66
2023-01-05 04:45:11,378 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49118896424770353, 'Total loss': 0.49118896424770353} | train loss {'Reaction outcome loss': 0.18344523425592663, 'Total loss': 0.18344523425592663}
2023-01-05 04:45:11,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:11,379 INFO:     Epoch: 67
2023-01-05 04:45:13,597 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5147734701633453, 'Total loss': 0.5147734701633453} | train loss {'Reaction outcome loss': 0.18635376824591404, 'Total loss': 0.18635376824591404}
2023-01-05 04:45:13,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:13,597 INFO:     Epoch: 68
2023-01-05 04:45:15,793 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5087072233359019, 'Total loss': 0.5087072233359019} | train loss {'Reaction outcome loss': 0.19223455222999, 'Total loss': 0.19223455222999}
2023-01-05 04:45:15,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:15,793 INFO:     Epoch: 69
2023-01-05 04:45:18,006 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4555790384610494, 'Total loss': 0.4555790384610494} | train loss {'Reaction outcome loss': 0.18156921155682523, 'Total loss': 0.18156921155682523}
2023-01-05 04:45:18,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:18,007 INFO:     Epoch: 70
2023-01-05 04:45:20,199 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4736817578474681, 'Total loss': 0.4736817578474681} | train loss {'Reaction outcome loss': 0.1812958494894848, 'Total loss': 0.1812958494894848}
2023-01-05 04:45:20,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:20,200 INFO:     Epoch: 71
2023-01-05 04:45:22,428 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4681242175400257, 'Total loss': 0.4681242175400257} | train loss {'Reaction outcome loss': 0.18096097706281494, 'Total loss': 0.18096097706281494}
2023-01-05 04:45:22,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:22,429 INFO:     Epoch: 72
2023-01-05 04:45:24,638 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5050165961186092, 'Total loss': 0.5050165961186092} | train loss {'Reaction outcome loss': 0.1861251599612499, 'Total loss': 0.1861251599612499}
2023-01-05 04:45:24,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:24,639 INFO:     Epoch: 73
2023-01-05 04:45:26,869 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4976747343937556, 'Total loss': 0.4976747343937556} | train loss {'Reaction outcome loss': 0.18016354485513855, 'Total loss': 0.18016354485513855}
2023-01-05 04:45:26,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:26,869 INFO:     Epoch: 74
2023-01-05 04:45:28,967 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4877785285313924, 'Total loss': 0.4877785285313924} | train loss {'Reaction outcome loss': 0.18768916658429435, 'Total loss': 0.18768916658429435}
2023-01-05 04:45:28,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:28,967 INFO:     Epoch: 75
2023-01-05 04:45:31,163 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49371474186579384, 'Total loss': 0.49371474186579384} | train loss {'Reaction outcome loss': 0.18021862781282527, 'Total loss': 0.18021862781282527}
2023-01-05 04:45:31,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:31,163 INFO:     Epoch: 76
2023-01-05 04:45:33,330 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4929042716821035, 'Total loss': 0.4929042716821035} | train loss {'Reaction outcome loss': 0.1753144221441759, 'Total loss': 0.1753144221441759}
2023-01-05 04:45:33,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:33,330 INFO:     Epoch: 77
2023-01-05 04:45:35,484 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4864696472883224, 'Total loss': 0.4864696472883224} | train loss {'Reaction outcome loss': 0.1771759871502608, 'Total loss': 0.1771759871502608}
2023-01-05 04:45:35,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:35,484 INFO:     Epoch: 78
2023-01-05 04:45:37,681 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46539783030748366, 'Total loss': 0.46539783030748366} | train loss {'Reaction outcome loss': 0.1723128857633488, 'Total loss': 0.1723128857633488}
2023-01-05 04:45:37,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:37,682 INFO:     Epoch: 79
2023-01-05 04:45:39,879 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5154137164354324, 'Total loss': 0.5154137164354324} | train loss {'Reaction outcome loss': 0.17209505551620882, 'Total loss': 0.17209505551620882}
2023-01-05 04:45:39,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:39,880 INFO:     Epoch: 80
2023-01-05 04:45:42,111 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5016948789358139, 'Total loss': 0.5016948789358139} | train loss {'Reaction outcome loss': 0.1786190170262541, 'Total loss': 0.1786190170262541}
2023-01-05 04:45:42,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:42,111 INFO:     Epoch: 81
2023-01-05 04:45:44,328 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46386653184890747, 'Total loss': 0.46386653184890747} | train loss {'Reaction outcome loss': 0.17490534307503383, 'Total loss': 0.17490534307503383}
2023-01-05 04:45:44,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:44,328 INFO:     Epoch: 82
2023-01-05 04:45:46,537 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5202942132949829, 'Total loss': 0.5202942132949829} | train loss {'Reaction outcome loss': 0.1761682696995281, 'Total loss': 0.1761682696995281}
2023-01-05 04:45:46,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:46,538 INFO:     Epoch: 83
2023-01-05 04:45:48,748 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.507364168142279, 'Total loss': 0.507364168142279} | train loss {'Reaction outcome loss': 0.16974324767303828, 'Total loss': 0.16974324767303828}
2023-01-05 04:45:48,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:48,749 INFO:     Epoch: 84
2023-01-05 04:45:50,832 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4905788739522298, 'Total loss': 0.4905788739522298} | train loss {'Reaction outcome loss': 0.17406135085874644, 'Total loss': 0.17406135085874644}
2023-01-05 04:45:50,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:50,832 INFO:     Epoch: 85
2023-01-05 04:45:53,058 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4621780538931489, 'Total loss': 0.4621780538931489} | train loss {'Reaction outcome loss': 0.17268483380611385, 'Total loss': 0.17268483380611385}
2023-01-05 04:45:53,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:53,058 INFO:     Epoch: 86
2023-01-05 04:45:55,236 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5010857284069061, 'Total loss': 0.5010857284069061} | train loss {'Reaction outcome loss': 0.17182825883464964, 'Total loss': 0.17182825883464964}
2023-01-05 04:45:55,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:55,237 INFO:     Epoch: 87
2023-01-05 04:45:57,459 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5029630839824677, 'Total loss': 0.5029630839824677} | train loss {'Reaction outcome loss': 0.17543489572885462, 'Total loss': 0.17543489572885462}
2023-01-05 04:45:57,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:57,459 INFO:     Epoch: 88
2023-01-05 04:45:59,650 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4602820412721485, 'Total loss': 0.4602820412721485} | train loss {'Reaction outcome loss': 0.17412016044145676, 'Total loss': 0.17412016044145676}
2023-01-05 04:45:59,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:45:59,650 INFO:     Epoch: 89
2023-01-05 04:46:01,846 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48118295272191364, 'Total loss': 0.48118295272191364} | train loss {'Reaction outcome loss': 0.16819506804816997, 'Total loss': 0.16819506804816997}
2023-01-05 04:46:01,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:01,847 INFO:     Epoch: 90
2023-01-05 04:46:03,974 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48616843794782955, 'Total loss': 0.48616843794782955} | train loss {'Reaction outcome loss': 0.16054576414470106, 'Total loss': 0.16054576414470106}
2023-01-05 04:46:03,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:03,975 INFO:     Epoch: 91
2023-01-05 04:46:06,125 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49536743597127497, 'Total loss': 0.49536743597127497} | train loss {'Reaction outcome loss': 0.165620490123992, 'Total loss': 0.165620490123992}
2023-01-05 04:46:06,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:06,126 INFO:     Epoch: 92
2023-01-05 04:46:08,336 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5194609542687734, 'Total loss': 0.5194609542687734} | train loss {'Reaction outcome loss': 0.1667543346588517, 'Total loss': 0.1667543346588517}
2023-01-05 04:46:08,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:08,336 INFO:     Epoch: 93
2023-01-05 04:46:10,550 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5012052064140637, 'Total loss': 0.5012052064140637} | train loss {'Reaction outcome loss': 0.16841796484704202, 'Total loss': 0.16841796484704202}
2023-01-05 04:46:10,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:10,550 INFO:     Epoch: 94
2023-01-05 04:46:12,782 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4893398722012838, 'Total loss': 0.4893398722012838} | train loss {'Reaction outcome loss': 0.16453996099635698, 'Total loss': 0.16453996099635698}
2023-01-05 04:46:12,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:12,782 INFO:     Epoch: 95
2023-01-05 04:46:14,942 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5469923237959544, 'Total loss': 0.5469923237959544} | train loss {'Reaction outcome loss': 0.1650991472014782, 'Total loss': 0.1650991472014782}
2023-01-05 04:46:14,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:14,943 INFO:     Epoch: 96
2023-01-05 04:46:17,160 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5286499192317327, 'Total loss': 0.5286499192317327} | train loss {'Reaction outcome loss': 0.1655257440243776, 'Total loss': 0.1655257440243776}
2023-01-05 04:46:17,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:17,160 INFO:     Epoch: 97
2023-01-05 04:46:19,390 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5185776670773824, 'Total loss': 0.5185776670773824} | train loss {'Reaction outcome loss': 0.1627769747786497, 'Total loss': 0.1627769747786497}
2023-01-05 04:46:19,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:19,390 INFO:     Epoch: 98
2023-01-05 04:46:21,530 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4486444478854537, 'Total loss': 0.4486444478854537} | train loss {'Reaction outcome loss': 0.1574532560455773, 'Total loss': 0.1574532560455773}
2023-01-05 04:46:21,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:21,530 INFO:     Epoch: 99
2023-01-05 04:46:23,697 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5219379246234894, 'Total loss': 0.5219379246234894} | train loss {'Reaction outcome loss': 0.16367987710760817, 'Total loss': 0.16367987710760817}
2023-01-05 04:46:23,697 INFO:     Best model found after epoch 19 of 100.
2023-01-05 04:46:23,697 INFO:   Done with stage: TRAINING
2023-01-05 04:46:23,697 INFO:   Starting stage: EVALUATION
2023-01-05 04:46:23,845 INFO:   Done with stage: EVALUATION
2023-01-05 04:46:23,845 INFO:   Leaving out SEQ value Fold_3
2023-01-05 04:46:23,858 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 04:46:23,858 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:46:24,507 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:46:24,508 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:46:24,580 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:46:24,580 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:46:24,580 INFO:     No hyperparam tuning for this model
2023-01-05 04:46:24,580 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:46:24,580 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:46:24,581 INFO:     None feature selector for col prot
2023-01-05 04:46:24,581 INFO:     None feature selector for col prot
2023-01-05 04:46:24,581 INFO:     None feature selector for col prot
2023-01-05 04:46:24,582 INFO:     None feature selector for col chem
2023-01-05 04:46:24,582 INFO:     None feature selector for col chem
2023-01-05 04:46:24,582 INFO:     None feature selector for col chem
2023-01-05 04:46:24,582 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:46:24,582 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:46:24,584 INFO:     Number of params in model 72931
2023-01-05 04:46:24,587 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:46:24,587 INFO:   Starting stage: TRAINING
2023-01-05 04:46:24,647 INFO:     Val loss before train {'Reaction outcome loss': 1.0771263360977172, 'Total loss': 1.0771263360977172}
2023-01-05 04:46:24,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:24,648 INFO:     Epoch: 0
2023-01-05 04:46:26,847 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7746228754520417, 'Total loss': 0.7746228754520417} | train loss {'Reaction outcome loss': 0.9356962400914985, 'Total loss': 0.9356962400914985}
2023-01-05 04:46:26,847 INFO:     Found new best model at epoch 0
2023-01-05 04:46:26,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:26,848 INFO:     Epoch: 1
2023-01-05 04:46:29,074 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5526677906513214, 'Total loss': 0.5526677906513214} | train loss {'Reaction outcome loss': 0.6179581569446312, 'Total loss': 0.6179581569446312}
2023-01-05 04:46:29,074 INFO:     Found new best model at epoch 1
2023-01-05 04:46:29,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:29,076 INFO:     Epoch: 2
2023-01-05 04:46:31,312 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5208673437436422, 'Total loss': 0.5208673437436422} | train loss {'Reaction outcome loss': 0.5255864858081489, 'Total loss': 0.5255864858081489}
2023-01-05 04:46:31,312 INFO:     Found new best model at epoch 2
2023-01-05 04:46:31,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:31,314 INFO:     Epoch: 3
2023-01-05 04:46:33,536 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5074268519878388, 'Total loss': 0.5074268519878388} | train loss {'Reaction outcome loss': 0.4878592123260428, 'Total loss': 0.4878592123260428}
2023-01-05 04:46:33,536 INFO:     Found new best model at epoch 3
2023-01-05 04:46:33,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:33,537 INFO:     Epoch: 4
2023-01-05 04:46:35,684 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4444287955760956, 'Total loss': 0.4444287955760956} | train loss {'Reaction outcome loss': 0.4498182930898317, 'Total loss': 0.4498182930898317}
2023-01-05 04:46:35,684 INFO:     Found new best model at epoch 4
2023-01-05 04:46:35,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:35,686 INFO:     Epoch: 5
2023-01-05 04:46:37,882 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45136250654856364, 'Total loss': 0.45136250654856364} | train loss {'Reaction outcome loss': 0.4298501075842442, 'Total loss': 0.4298501075842442}
2023-01-05 04:46:37,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:37,883 INFO:     Epoch: 6
2023-01-05 04:46:40,099 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.426925187309583, 'Total loss': 0.426925187309583} | train loss {'Reaction outcome loss': 0.4069457035034131, 'Total loss': 0.4069457035034131}
2023-01-05 04:46:40,100 INFO:     Found new best model at epoch 6
2023-01-05 04:46:40,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:40,101 INFO:     Epoch: 7
2023-01-05 04:46:42,338 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42974184453487396, 'Total loss': 0.42974184453487396} | train loss {'Reaction outcome loss': 0.38617542073567274, 'Total loss': 0.38617542073567274}
2023-01-05 04:46:42,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:42,338 INFO:     Epoch: 8
2023-01-05 04:46:44,562 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41150492628415425, 'Total loss': 0.41150492628415425} | train loss {'Reaction outcome loss': 0.38022520254969927, 'Total loss': 0.38022520254969927}
2023-01-05 04:46:44,562 INFO:     Found new best model at epoch 8
2023-01-05 04:46:44,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:44,564 INFO:     Epoch: 9
2023-01-05 04:46:46,793 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4044958864649137, 'Total loss': 0.4044958864649137} | train loss {'Reaction outcome loss': 0.36443897241201156, 'Total loss': 0.36443897241201156}
2023-01-05 04:46:46,793 INFO:     Found new best model at epoch 9
2023-01-05 04:46:46,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:46,794 INFO:     Epoch: 10
2023-01-05 04:46:48,998 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4300457090139389, 'Total loss': 0.4300457090139389} | train loss {'Reaction outcome loss': 0.35493890756925384, 'Total loss': 0.35493890756925384}
2023-01-05 04:46:48,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:48,998 INFO:     Epoch: 11
2023-01-05 04:46:51,131 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4087295775612195, 'Total loss': 0.4087295775612195} | train loss {'Reaction outcome loss': 0.3458268338125267, 'Total loss': 0.3458268338125267}
2023-01-05 04:46:51,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:51,131 INFO:     Epoch: 12
2023-01-05 04:46:53,277 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42369836966196694, 'Total loss': 0.42369836966196694} | train loss {'Reaction outcome loss': 0.339437688881661, 'Total loss': 0.339437688881661}
2023-01-05 04:46:53,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:53,278 INFO:     Epoch: 13
2023-01-05 04:46:55,448 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3937232166528702, 'Total loss': 0.3937232166528702} | train loss {'Reaction outcome loss': 0.3262637105152939, 'Total loss': 0.3262637105152939}
2023-01-05 04:46:55,449 INFO:     Found new best model at epoch 13
2023-01-05 04:46:55,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:55,451 INFO:     Epoch: 14
2023-01-05 04:46:57,599 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4043877124786377, 'Total loss': 0.4043877124786377} | train loss {'Reaction outcome loss': 0.322194741049529, 'Total loss': 0.322194741049529}
2023-01-05 04:46:57,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:57,600 INFO:     Epoch: 15
2023-01-05 04:46:59,772 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41339989403883615, 'Total loss': 0.41339989403883615} | train loss {'Reaction outcome loss': 0.31265053297683, 'Total loss': 0.31265053297683}
2023-01-05 04:46:59,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:46:59,773 INFO:     Epoch: 16
2023-01-05 04:47:01,961 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41899052063624065, 'Total loss': 0.41899052063624065} | train loss {'Reaction outcome loss': 0.30803670257930355, 'Total loss': 0.30803670257930355}
2023-01-05 04:47:01,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:01,962 INFO:     Epoch: 17
2023-01-05 04:47:04,181 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45110732316970825, 'Total loss': 0.45110732316970825} | train loss {'Reaction outcome loss': 0.3016760397989016, 'Total loss': 0.3016760397989016}
2023-01-05 04:47:04,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:04,182 INFO:     Epoch: 18
2023-01-05 04:47:06,411 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45350938439369204, 'Total loss': 0.45350938439369204} | train loss {'Reaction outcome loss': 0.2948356054777846, 'Total loss': 0.2948356054777846}
2023-01-05 04:47:06,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:06,412 INFO:     Epoch: 19
2023-01-05 04:47:08,644 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4311366483569145, 'Total loss': 0.4311366483569145} | train loss {'Reaction outcome loss': 0.2891224933030841, 'Total loss': 0.2891224933030841}
2023-01-05 04:47:08,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:08,644 INFO:     Epoch: 20
2023-01-05 04:47:10,757 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42883623043696084, 'Total loss': 0.42883623043696084} | train loss {'Reaction outcome loss': 0.2836438708976184, 'Total loss': 0.2836438708976184}
2023-01-05 04:47:10,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:10,758 INFO:     Epoch: 21
2023-01-05 04:47:12,876 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39455369909604393, 'Total loss': 0.39455369909604393} | train loss {'Reaction outcome loss': 0.27814989749874386, 'Total loss': 0.27814989749874386}
2023-01-05 04:47:12,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:12,876 INFO:     Epoch: 22
2023-01-05 04:47:15,097 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.438832089304924, 'Total loss': 0.438832089304924} | train loss {'Reaction outcome loss': 0.27434466957991377, 'Total loss': 0.27434466957991377}
2023-01-05 04:47:15,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:15,098 INFO:     Epoch: 23
2023-01-05 04:47:17,326 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.394708281258742, 'Total loss': 0.394708281258742} | train loss {'Reaction outcome loss': 0.26840105279597826, 'Total loss': 0.26840105279597826}
2023-01-05 04:47:17,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:17,326 INFO:     Epoch: 24
2023-01-05 04:47:19,573 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44093171656131747, 'Total loss': 0.44093171656131747} | train loss {'Reaction outcome loss': 0.26890746197038956, 'Total loss': 0.26890746197038956}
2023-01-05 04:47:19,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:19,573 INFO:     Epoch: 25
2023-01-05 04:47:21,816 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41363478600978854, 'Total loss': 0.41363478600978854} | train loss {'Reaction outcome loss': 0.261353564895553, 'Total loss': 0.261353564895553}
2023-01-05 04:47:21,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:21,817 INFO:     Epoch: 26
2023-01-05 04:47:24,028 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43756379137436546, 'Total loss': 0.43756379137436546} | train loss {'Reaction outcome loss': 0.25886765537244494, 'Total loss': 0.25886765537244494}
2023-01-05 04:47:24,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:24,029 INFO:     Epoch: 27
2023-01-05 04:47:26,245 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41800975799560547, 'Total loss': 0.41800975799560547} | train loss {'Reaction outcome loss': 0.2600183260760137, 'Total loss': 0.2600183260760137}
2023-01-05 04:47:26,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:26,246 INFO:     Epoch: 28
2023-01-05 04:47:28,484 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4070439239343007, 'Total loss': 0.4070439239343007} | train loss {'Reaction outcome loss': 0.25099909111120544, 'Total loss': 0.25099909111120544}
2023-01-05 04:47:28,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:28,484 INFO:     Epoch: 29
2023-01-05 04:47:30,521 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4411034355560938, 'Total loss': 0.4411034355560938} | train loss {'Reaction outcome loss': 0.2481399490378606, 'Total loss': 0.2481399490378606}
2023-01-05 04:47:30,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:30,521 INFO:     Epoch: 30
2023-01-05 04:47:32,754 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40765919809540113, 'Total loss': 0.40765919809540113} | train loss {'Reaction outcome loss': 0.24749809105781626, 'Total loss': 0.24749809105781626}
2023-01-05 04:47:32,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:32,755 INFO:     Epoch: 31
2023-01-05 04:47:34,976 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4303554395834605, 'Total loss': 0.4303554395834605} | train loss {'Reaction outcome loss': 0.23891903344719184, 'Total loss': 0.23891903344719184}
2023-01-05 04:47:34,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:34,976 INFO:     Epoch: 32
2023-01-05 04:47:37,188 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4246109207471212, 'Total loss': 0.4246109207471212} | train loss {'Reaction outcome loss': 0.2376951058369621, 'Total loss': 0.2376951058369621}
2023-01-05 04:47:37,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:37,189 INFO:     Epoch: 33
2023-01-05 04:47:39,418 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45166590561469394, 'Total loss': 0.45166590561469394} | train loss {'Reaction outcome loss': 0.24179676201044423, 'Total loss': 0.24179676201044423}
2023-01-05 04:47:39,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:39,419 INFO:     Epoch: 34
2023-01-05 04:47:41,652 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41600489541888236, 'Total loss': 0.41600489541888236} | train loss {'Reaction outcome loss': 0.2370644268057831, 'Total loss': 0.2370644268057831}
2023-01-05 04:47:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:41,652 INFO:     Epoch: 35
2023-01-05 04:47:43,881 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4178829550743103, 'Total loss': 0.4178829550743103} | train loss {'Reaction outcome loss': 0.2298370018847041, 'Total loss': 0.2298370018847041}
2023-01-05 04:47:43,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:43,881 INFO:     Epoch: 36
2023-01-05 04:47:46,103 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42222927436232566, 'Total loss': 0.42222927436232566} | train loss {'Reaction outcome loss': 0.2249668219873866, 'Total loss': 0.2249668219873866}
2023-01-05 04:47:46,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:46,103 INFO:     Epoch: 37
2023-01-05 04:47:48,186 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43493077804644903, 'Total loss': 0.43493077804644903} | train loss {'Reaction outcome loss': 0.22641054536267133, 'Total loss': 0.22641054536267133}
2023-01-05 04:47:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:48,187 INFO:     Epoch: 38
2023-01-05 04:47:50,025 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41168579378475745, 'Total loss': 0.41168579378475745} | train loss {'Reaction outcome loss': 0.22232989002114686, 'Total loss': 0.22232989002114686}
2023-01-05 04:47:50,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:50,026 INFO:     Epoch: 39
2023-01-05 04:47:51,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4491501063108444, 'Total loss': 0.4491501063108444} | train loss {'Reaction outcome loss': 0.22148898200237707, 'Total loss': 0.22148898200237707}
2023-01-05 04:47:51,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:51,884 INFO:     Epoch: 40
2023-01-05 04:47:54,110 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43565784469246865, 'Total loss': 0.43565784469246865} | train loss {'Reaction outcome loss': 0.2210629029752134, 'Total loss': 0.2210629029752134}
2023-01-05 04:47:54,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:54,111 INFO:     Epoch: 41
2023-01-05 04:47:56,348 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40788714233785867, 'Total loss': 0.40788714233785867} | train loss {'Reaction outcome loss': 0.21410819989434637, 'Total loss': 0.21410819989434637}
2023-01-05 04:47:56,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:56,348 INFO:     Epoch: 42
2023-01-05 04:47:58,529 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40560683330210545, 'Total loss': 0.40560683330210545} | train loss {'Reaction outcome loss': 0.21385972231844844, 'Total loss': 0.21385972231844844}
2023-01-05 04:47:58,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:47:58,530 INFO:     Epoch: 43
2023-01-05 04:48:00,778 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41463817954063414, 'Total loss': 0.41463817954063414} | train loss {'Reaction outcome loss': 0.21030485509611638, 'Total loss': 0.21030485509611638}
2023-01-05 04:48:00,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:00,779 INFO:     Epoch: 44
2023-01-05 04:48:02,912 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44104687770207723, 'Total loss': 0.44104687770207723} | train loss {'Reaction outcome loss': 0.20688479493334616, 'Total loss': 0.20688479493334616}
2023-01-05 04:48:02,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:02,914 INFO:     Epoch: 45
2023-01-05 04:48:05,113 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4177923947572708, 'Total loss': 0.4177923947572708} | train loss {'Reaction outcome loss': 0.20648520892902172, 'Total loss': 0.20648520892902172}
2023-01-05 04:48:05,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:05,113 INFO:     Epoch: 46
2023-01-05 04:48:07,343 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4133111556371053, 'Total loss': 0.4133111556371053} | train loss {'Reaction outcome loss': 0.20130514647750244, 'Total loss': 0.20130514647750244}
2023-01-05 04:48:07,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:07,344 INFO:     Epoch: 47
2023-01-05 04:48:09,548 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4410046249628067, 'Total loss': 0.4410046249628067} | train loss {'Reaction outcome loss': 0.20540062254021837, 'Total loss': 0.20540062254021837}
2023-01-05 04:48:09,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:09,549 INFO:     Epoch: 48
2023-01-05 04:48:11,796 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43355900843938194, 'Total loss': 0.43355900843938194} | train loss {'Reaction outcome loss': 0.19640554798828377, 'Total loss': 0.19640554798828377}
2023-01-05 04:48:11,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:11,796 INFO:     Epoch: 49
2023-01-05 04:48:14,030 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4355845510959625, 'Total loss': 0.4355845510959625} | train loss {'Reaction outcome loss': 0.19293352663039398, 'Total loss': 0.19293352663039398}
2023-01-05 04:48:14,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:14,030 INFO:     Epoch: 50
2023-01-05 04:48:16,248 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4229556987682978, 'Total loss': 0.4229556987682978} | train loss {'Reaction outcome loss': 0.19305590553475277, 'Total loss': 0.19305590553475277}
2023-01-05 04:48:16,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:16,248 INFO:     Epoch: 51
2023-01-05 04:48:18,482 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4304648826519648, 'Total loss': 0.4304648826519648} | train loss {'Reaction outcome loss': 0.19022031267252051, 'Total loss': 0.19022031267252051}
2023-01-05 04:48:18,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:18,483 INFO:     Epoch: 52
2023-01-05 04:48:20,700 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4276507794857025, 'Total loss': 0.4276507794857025} | train loss {'Reaction outcome loss': 0.19313282254083772, 'Total loss': 0.19313282254083772}
2023-01-05 04:48:20,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:20,700 INFO:     Epoch: 53
2023-01-05 04:48:22,932 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4182649552822113, 'Total loss': 0.4182649552822113} | train loss {'Reaction outcome loss': 0.18947221608593678, 'Total loss': 0.18947221608593678}
2023-01-05 04:48:22,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:22,933 INFO:     Epoch: 54
2023-01-05 04:48:25,173 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4205391099055608, 'Total loss': 0.4205391099055608} | train loss {'Reaction outcome loss': 0.18832618915117705, 'Total loss': 0.18832618915117705}
2023-01-05 04:48:25,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:25,174 INFO:     Epoch: 55
2023-01-05 04:48:27,359 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4445139120022456, 'Total loss': 0.4445139120022456} | train loss {'Reaction outcome loss': 0.18396179410441346, 'Total loss': 0.18396179410441346}
2023-01-05 04:48:27,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:27,359 INFO:     Epoch: 56
2023-01-05 04:48:29,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45150657296180724, 'Total loss': 0.45150657296180724} | train loss {'Reaction outcome loss': 0.18688278144819068, 'Total loss': 0.18688278144819068}
2023-01-05 04:48:29,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:29,596 INFO:     Epoch: 57
2023-01-05 04:48:31,829 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43189375996589663, 'Total loss': 0.43189375996589663} | train loss {'Reaction outcome loss': 0.18682417366824253, 'Total loss': 0.18682417366824253}
2023-01-05 04:48:31,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:31,830 INFO:     Epoch: 58
2023-01-05 04:48:34,068 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41643663346767423, 'Total loss': 0.41643663346767423} | train loss {'Reaction outcome loss': 0.18339808412482997, 'Total loss': 0.18339808412482997}
2023-01-05 04:48:34,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:34,068 INFO:     Epoch: 59
2023-01-05 04:48:36,295 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4768711457649867, 'Total loss': 0.4768711457649867} | train loss {'Reaction outcome loss': 0.1816485365503041, 'Total loss': 0.1816485365503041}
2023-01-05 04:48:36,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:36,295 INFO:     Epoch: 60
2023-01-05 04:48:38,511 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4566093613704046, 'Total loss': 0.4566093613704046} | train loss {'Reaction outcome loss': 0.18150890606793238, 'Total loss': 0.18150890606793238}
2023-01-05 04:48:38,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:38,513 INFO:     Epoch: 61
2023-01-05 04:48:40,718 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41000843482712906, 'Total loss': 0.41000843482712906} | train loss {'Reaction outcome loss': 0.18075438459905294, 'Total loss': 0.18075438459905294}
2023-01-05 04:48:40,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:40,718 INFO:     Epoch: 62
2023-01-05 04:48:42,943 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4620682895183563, 'Total loss': 0.4620682895183563} | train loss {'Reaction outcome loss': 0.1830769832529155, 'Total loss': 0.1830769832529155}
2023-01-05 04:48:42,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:42,944 INFO:     Epoch: 63
2023-01-05 04:48:45,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42263899991909665, 'Total loss': 0.42263899991909665} | train loss {'Reaction outcome loss': 0.1763624984279766, 'Total loss': 0.1763624984279766}
2023-01-05 04:48:45,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:45,115 INFO:     Epoch: 64
2023-01-05 04:48:47,317 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4319734046856562, 'Total loss': 0.4319734046856562} | train loss {'Reaction outcome loss': 0.17464359991948356, 'Total loss': 0.17464359991948356}
2023-01-05 04:48:47,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:47,317 INFO:     Epoch: 65
2023-01-05 04:48:49,502 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42462744067112607, 'Total loss': 0.42462744067112607} | train loss {'Reaction outcome loss': 0.18235550947221263, 'Total loss': 0.18235550947221263}
2023-01-05 04:48:49,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:49,503 INFO:     Epoch: 66
2023-01-05 04:48:51,725 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4297621250152588, 'Total loss': 0.4297621250152588} | train loss {'Reaction outcome loss': 0.17655967353014174, 'Total loss': 0.17655967353014174}
2023-01-05 04:48:51,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:51,726 INFO:     Epoch: 67
2023-01-05 04:48:53,856 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4349578519662221, 'Total loss': 0.4349578519662221} | train loss {'Reaction outcome loss': 0.17096609215767228, 'Total loss': 0.17096609215767228}
2023-01-05 04:48:53,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:53,856 INFO:     Epoch: 68
2023-01-05 04:48:56,015 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4559523701667786, 'Total loss': 0.4559523701667786} | train loss {'Reaction outcome loss': 0.176858665331202, 'Total loss': 0.176858665331202}
2023-01-05 04:48:56,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:56,015 INFO:     Epoch: 69
2023-01-05 04:48:58,177 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42963726818561554, 'Total loss': 0.42963726818561554} | train loss {'Reaction outcome loss': 0.1730932404300805, 'Total loss': 0.1730932404300805}
2023-01-05 04:48:58,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:48:58,178 INFO:     Epoch: 70
2023-01-05 04:49:00,337 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4296143094698588, 'Total loss': 0.4296143094698588} | train loss {'Reaction outcome loss': 0.17448075358745652, 'Total loss': 0.17448075358745652}
2023-01-05 04:49:00,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:00,337 INFO:     Epoch: 71
2023-01-05 04:49:02,560 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4324110418558121, 'Total loss': 0.4324110418558121} | train loss {'Reaction outcome loss': 0.1746181769163481, 'Total loss': 0.1746181769163481}
2023-01-05 04:49:02,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:02,561 INFO:     Epoch: 72
2023-01-05 04:49:04,801 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41752365926901497, 'Total loss': 0.41752365926901497} | train loss {'Reaction outcome loss': 0.17096902111301288, 'Total loss': 0.17096902111301288}
2023-01-05 04:49:04,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:04,801 INFO:     Epoch: 73
2023-01-05 04:49:07,027 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42451879049961766, 'Total loss': 0.42451879049961766} | train loss {'Reaction outcome loss': 0.16886049394935862, 'Total loss': 0.16886049394935862}
2023-01-05 04:49:07,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:07,027 INFO:     Epoch: 74
2023-01-05 04:49:09,187 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41821088194847106, 'Total loss': 0.41821088194847106} | train loss {'Reaction outcome loss': 0.17219973167135028, 'Total loss': 0.17219973167135028}
2023-01-05 04:49:09,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:09,187 INFO:     Epoch: 75
2023-01-05 04:49:11,348 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45046314001083376, 'Total loss': 0.45046314001083376} | train loss {'Reaction outcome loss': 0.17037564527666393, 'Total loss': 0.17037564527666393}
2023-01-05 04:49:11,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:11,348 INFO:     Epoch: 76
2023-01-05 04:49:13,586 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4278052394588788, 'Total loss': 0.4278052394588788} | train loss {'Reaction outcome loss': 0.1621145061166077, 'Total loss': 0.1621145061166077}
2023-01-05 04:49:13,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:13,587 INFO:     Epoch: 77
2023-01-05 04:49:15,808 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42431441976999246, 'Total loss': 0.42431441976999246} | train loss {'Reaction outcome loss': 0.1686321802628346, 'Total loss': 0.1686321802628346}
2023-01-05 04:49:15,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:15,809 INFO:     Epoch: 78
2023-01-05 04:49:17,986 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46305316537618635, 'Total loss': 0.46305316537618635} | train loss {'Reaction outcome loss': 0.16558984564207904, 'Total loss': 0.16558984564207904}
2023-01-05 04:49:17,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:17,986 INFO:     Epoch: 79
2023-01-05 04:49:20,208 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44723621010780334, 'Total loss': 0.44723621010780334} | train loss {'Reaction outcome loss': 0.1675872871952452, 'Total loss': 0.1675872871952452}
2023-01-05 04:49:20,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:20,208 INFO:     Epoch: 80
2023-01-05 04:49:22,453 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4631701151529948, 'Total loss': 0.4631701151529948} | train loss {'Reaction outcome loss': 0.16369224198404767, 'Total loss': 0.16369224198404767}
2023-01-05 04:49:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:22,453 INFO:     Epoch: 81
2023-01-05 04:49:24,599 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4481205572684606, 'Total loss': 0.4481205572684606} | train loss {'Reaction outcome loss': 0.160489323018494, 'Total loss': 0.160489323018494}
2023-01-05 04:49:24,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:24,600 INFO:     Epoch: 82
2023-01-05 04:49:26,731 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42686899900436404, 'Total loss': 0.42686899900436404} | train loss {'Reaction outcome loss': 0.16216165041243966, 'Total loss': 0.16216165041243966}
2023-01-05 04:49:26,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:26,731 INFO:     Epoch: 83
2023-01-05 04:49:28,974 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4459223081668218, 'Total loss': 0.4459223081668218} | train loss {'Reaction outcome loss': 0.1600506815397532, 'Total loss': 0.1600506815397532}
2023-01-05 04:49:28,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:28,974 INFO:     Epoch: 84
2023-01-05 04:49:31,094 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4312933435042699, 'Total loss': 0.4312933435042699} | train loss {'Reaction outcome loss': 0.1651179811238369, 'Total loss': 0.1651179811238369}
2023-01-05 04:49:31,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:31,094 INFO:     Epoch: 85
2023-01-05 04:49:33,320 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44316309293111167, 'Total loss': 0.44316309293111167} | train loss {'Reaction outcome loss': 0.16540393299992867, 'Total loss': 0.16540393299992867}
2023-01-05 04:49:33,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:33,321 INFO:     Epoch: 86
2023-01-05 04:49:35,559 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4699590836962064, 'Total loss': 0.4699590836962064} | train loss {'Reaction outcome loss': 0.16251152885426176, 'Total loss': 0.16251152885426176}
2023-01-05 04:49:35,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:35,560 INFO:     Epoch: 87
2023-01-05 04:49:37,707 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4588037515679995, 'Total loss': 0.4588037515679995} | train loss {'Reaction outcome loss': 0.16504630044396051, 'Total loss': 0.16504630044396051}
2023-01-05 04:49:37,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:37,708 INFO:     Epoch: 88
2023-01-05 04:49:39,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.440770427385966, 'Total loss': 0.440770427385966} | train loss {'Reaction outcome loss': 0.16060204842322312, 'Total loss': 0.16060204842322312}
2023-01-05 04:49:39,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:39,911 INFO:     Epoch: 89
2023-01-05 04:49:42,083 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4612384498119354, 'Total loss': 0.4612384498119354} | train loss {'Reaction outcome loss': 0.16076403583362425, 'Total loss': 0.16076403583362425}
2023-01-05 04:49:42,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:42,083 INFO:     Epoch: 90
2023-01-05 04:49:44,288 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46091868449002504, 'Total loss': 0.46091868449002504} | train loss {'Reaction outcome loss': 0.15823013506038286, 'Total loss': 0.15823013506038286}
2023-01-05 04:49:44,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:44,288 INFO:     Epoch: 91
2023-01-05 04:49:46,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4910349736611048, 'Total loss': 0.4910349736611048} | train loss {'Reaction outcome loss': 0.15702255025519665, 'Total loss': 0.15702255025519665}
2023-01-05 04:49:46,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:46,530 INFO:     Epoch: 92
2023-01-05 04:49:48,761 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.445539261897405, 'Total loss': 0.445539261897405} | train loss {'Reaction outcome loss': 0.16070843764645604, 'Total loss': 0.16070843764645604}
2023-01-05 04:49:48,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:48,762 INFO:     Epoch: 93
2023-01-05 04:49:50,904 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.446490411957105, 'Total loss': 0.446490411957105} | train loss {'Reaction outcome loss': 0.15410714988228302, 'Total loss': 0.15410714988228302}
2023-01-05 04:49:50,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:50,905 INFO:     Epoch: 94
2023-01-05 04:49:53,126 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45691466505328815, 'Total loss': 0.45691466505328815} | train loss {'Reaction outcome loss': 0.15881159037160567, 'Total loss': 0.15881159037160567}
2023-01-05 04:49:53,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:53,127 INFO:     Epoch: 95
2023-01-05 04:49:55,373 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46047831773757936, 'Total loss': 0.46047831773757936} | train loss {'Reaction outcome loss': 0.1539530054011106, 'Total loss': 0.1539530054011106}
2023-01-05 04:49:55,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:55,373 INFO:     Epoch: 96
2023-01-05 04:49:57,607 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47807064255078635, 'Total loss': 0.47807064255078635} | train loss {'Reaction outcome loss': 0.1530043488162, 'Total loss': 0.1530043488162}
2023-01-05 04:49:57,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:57,608 INFO:     Epoch: 97
2023-01-05 04:49:59,768 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4822034696737925, 'Total loss': 0.4822034696737925} | train loss {'Reaction outcome loss': 0.15530037336501773, 'Total loss': 0.15530037336501773}
2023-01-05 04:49:59,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:49:59,768 INFO:     Epoch: 98
2023-01-05 04:50:01,968 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4571812868118286, 'Total loss': 0.4571812868118286} | train loss {'Reaction outcome loss': 0.15310768914432862, 'Total loss': 0.15310768914432862}
2023-01-05 04:50:01,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:01,968 INFO:     Epoch: 99
2023-01-05 04:50:04,198 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4926800568898519, 'Total loss': 0.4926800568898519} | train loss {'Reaction outcome loss': 0.15301423778351492, 'Total loss': 0.15301423778351492}
2023-01-05 04:50:04,199 INFO:     Best model found after epoch 14 of 100.
2023-01-05 04:50:04,199 INFO:   Done with stage: TRAINING
2023-01-05 04:50:04,199 INFO:   Starting stage: EVALUATION
2023-01-05 04:50:04,346 INFO:   Done with stage: EVALUATION
2023-01-05 04:50:04,347 INFO:   Leaving out SEQ value Fold_4
2023-01-05 04:50:04,359 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:50:04,359 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:50:05,005 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:50:05,005 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:50:05,078 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:50:05,078 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:50:05,078 INFO:     No hyperparam tuning for this model
2023-01-05 04:50:05,078 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:50:05,078 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:50:05,079 INFO:     None feature selector for col prot
2023-01-05 04:50:05,079 INFO:     None feature selector for col prot
2023-01-05 04:50:05,079 INFO:     None feature selector for col prot
2023-01-05 04:50:05,079 INFO:     None feature selector for col chem
2023-01-05 04:50:05,079 INFO:     None feature selector for col chem
2023-01-05 04:50:05,080 INFO:     None feature selector for col chem
2023-01-05 04:50:05,080 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:50:05,080 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:50:05,081 INFO:     Number of params in model 72931
2023-01-05 04:50:05,084 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:50:05,084 INFO:   Starting stage: TRAINING
2023-01-05 04:50:05,144 INFO:     Val loss before train {'Reaction outcome loss': 0.9909204920132955, 'Total loss': 0.9909204920132955}
2023-01-05 04:50:05,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:05,145 INFO:     Epoch: 0
2023-01-05 04:50:07,308 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7228744347890218, 'Total loss': 0.7228744347890218} | train loss {'Reaction outcome loss': 0.9310669005861965, 'Total loss': 0.9310669005861965}
2023-01-05 04:50:07,308 INFO:     Found new best model at epoch 0
2023-01-05 04:50:07,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:07,310 INFO:     Epoch: 1
2023-01-05 04:50:09,568 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5941291073958079, 'Total loss': 0.5941291073958079} | train loss {'Reaction outcome loss': 0.614588028272155, 'Total loss': 0.614588028272155}
2023-01-05 04:50:09,569 INFO:     Found new best model at epoch 1
2023-01-05 04:50:09,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:09,570 INFO:     Epoch: 2
2023-01-05 04:50:11,834 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5802270402510961, 'Total loss': 0.5802270402510961} | train loss {'Reaction outcome loss': 0.5300463600813047, 'Total loss': 0.5300463600813047}
2023-01-05 04:50:11,835 INFO:     Found new best model at epoch 2
2023-01-05 04:50:11,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:11,836 INFO:     Epoch: 3
2023-01-05 04:50:14,080 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5698939462502798, 'Total loss': 0.5698939462502798} | train loss {'Reaction outcome loss': 0.48620254395232687, 'Total loss': 0.48620254395232687}
2023-01-05 04:50:14,080 INFO:     Found new best model at epoch 3
2023-01-05 04:50:14,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:14,081 INFO:     Epoch: 4
2023-01-05 04:50:16,326 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5195428351561229, 'Total loss': 0.5195428351561229} | train loss {'Reaction outcome loss': 0.45550942105204, 'Total loss': 0.45550942105204}
2023-01-05 04:50:16,326 INFO:     Found new best model at epoch 4
2023-01-05 04:50:16,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:16,327 INFO:     Epoch: 5
2023-01-05 04:50:18,553 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5500413129727045, 'Total loss': 0.5500413129727045} | train loss {'Reaction outcome loss': 0.4314008368908063, 'Total loss': 0.4314008368908063}
2023-01-05 04:50:18,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:18,553 INFO:     Epoch: 6
2023-01-05 04:50:20,714 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5307554543018341, 'Total loss': 0.5307554543018341} | train loss {'Reaction outcome loss': 0.4159336052565039, 'Total loss': 0.4159336052565039}
2023-01-05 04:50:20,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:20,716 INFO:     Epoch: 7
2023-01-05 04:50:22,872 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.507555772860845, 'Total loss': 0.507555772860845} | train loss {'Reaction outcome loss': 0.3939640031186054, 'Total loss': 0.3939640031186054}
2023-01-05 04:50:22,873 INFO:     Found new best model at epoch 7
2023-01-05 04:50:22,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:22,874 INFO:     Epoch: 8
2023-01-05 04:50:25,118 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5216699361801147, 'Total loss': 0.5216699361801147} | train loss {'Reaction outcome loss': 0.38072723741440667, 'Total loss': 0.38072723741440667}
2023-01-05 04:50:25,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:25,118 INFO:     Epoch: 9
2023-01-05 04:50:27,366 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5148422956466675, 'Total loss': 0.5148422956466675} | train loss {'Reaction outcome loss': 0.36701241422417585, 'Total loss': 0.36701241422417585}
2023-01-05 04:50:27,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:27,367 INFO:     Epoch: 10
2023-01-05 04:50:29,627 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.529128885269165, 'Total loss': 0.529128885269165} | train loss {'Reaction outcome loss': 0.35878181953465677, 'Total loss': 0.35878181953465677}
2023-01-05 04:50:29,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:29,627 INFO:     Epoch: 11
2023-01-05 04:50:31,885 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5214819381634395, 'Total loss': 0.5214819381634395} | train loss {'Reaction outcome loss': 0.3516791901024787, 'Total loss': 0.3516791901024787}
2023-01-05 04:50:31,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:31,886 INFO:     Epoch: 12
2023-01-05 04:50:34,109 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49947488903999326, 'Total loss': 0.49947488903999326} | train loss {'Reaction outcome loss': 0.33754088907448604, 'Total loss': 0.33754088907448604}
2023-01-05 04:50:34,110 INFO:     Found new best model at epoch 12
2023-01-05 04:50:34,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:34,111 INFO:     Epoch: 13
2023-01-05 04:50:36,365 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5078608771165212, 'Total loss': 0.5078608771165212} | train loss {'Reaction outcome loss': 0.33013625141651626, 'Total loss': 0.33013625141651626}
2023-01-05 04:50:36,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:36,365 INFO:     Epoch: 14
2023-01-05 04:50:38,645 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5417012125253677, 'Total loss': 0.5417012125253677} | train loss {'Reaction outcome loss': 0.31748207892351143, 'Total loss': 0.31748207892351143}
2023-01-05 04:50:38,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:38,645 INFO:     Epoch: 15
2023-01-05 04:50:40,874 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.512755619486173, 'Total loss': 0.512755619486173} | train loss {'Reaction outcome loss': 0.3106719569347489, 'Total loss': 0.3106719569347489}
2023-01-05 04:50:40,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:40,875 INFO:     Epoch: 16
2023-01-05 04:50:43,034 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5223806043465932, 'Total loss': 0.5223806043465932} | train loss {'Reaction outcome loss': 0.3023969157922851, 'Total loss': 0.3023969157922851}
2023-01-05 04:50:43,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:43,034 INFO:     Epoch: 17
2023-01-05 04:50:45,255 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5238275776306788, 'Total loss': 0.5238275776306788} | train loss {'Reaction outcome loss': 0.2935671436955116, 'Total loss': 0.2935671436955116}
2023-01-05 04:50:45,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:45,256 INFO:     Epoch: 18
2023-01-05 04:50:47,470 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5022163649400075, 'Total loss': 0.5022163649400075} | train loss {'Reaction outcome loss': 0.29143882312042557, 'Total loss': 0.29143882312042557}
2023-01-05 04:50:47,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:47,471 INFO:     Epoch: 19
2023-01-05 04:50:49,708 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5156148811181386, 'Total loss': 0.5156148811181386} | train loss {'Reaction outcome loss': 0.28321044302994275, 'Total loss': 0.28321044302994275}
2023-01-05 04:50:49,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:49,709 INFO:     Epoch: 20
2023-01-05 04:50:51,903 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5318230410416921, 'Total loss': 0.5318230410416921} | train loss {'Reaction outcome loss': 0.27951276819175314, 'Total loss': 0.27951276819175314}
2023-01-05 04:50:51,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:51,903 INFO:     Epoch: 21
2023-01-05 04:50:54,124 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5205475111802419, 'Total loss': 0.5205475111802419} | train loss {'Reaction outcome loss': 0.2732888863361238, 'Total loss': 0.2732888863361238}
2023-01-05 04:50:54,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:54,124 INFO:     Epoch: 22
2023-01-05 04:50:56,330 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5378798266251882, 'Total loss': 0.5378798266251882} | train loss {'Reaction outcome loss': 0.2700335613040227, 'Total loss': 0.2700335613040227}
2023-01-05 04:50:56,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:56,331 INFO:     Epoch: 23
2023-01-05 04:50:58,577 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.544083970785141, 'Total loss': 0.544083970785141} | train loss {'Reaction outcome loss': 0.26203281742840956, 'Total loss': 0.26203281742840956}
2023-01-05 04:50:58,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:50:58,577 INFO:     Epoch: 24
2023-01-05 04:51:00,786 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5353303333123525, 'Total loss': 0.5353303333123525} | train loss {'Reaction outcome loss': 0.2638166679231369, 'Total loss': 0.2638166679231369}
2023-01-05 04:51:00,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:00,787 INFO:     Epoch: 25
2023-01-05 04:51:03,034 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5733745475610097, 'Total loss': 0.5733745475610097} | train loss {'Reaction outcome loss': 0.25877168289500097, 'Total loss': 0.25877168289500097}
2023-01-05 04:51:03,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:03,035 INFO:     Epoch: 26
2023-01-05 04:51:05,300 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.50314233712852, 'Total loss': 0.50314233712852} | train loss {'Reaction outcome loss': 0.25544051305365245, 'Total loss': 0.25544051305365245}
2023-01-05 04:51:05,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:05,301 INFO:     Epoch: 27
2023-01-05 04:51:07,564 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5614974041779836, 'Total loss': 0.5614974041779836} | train loss {'Reaction outcome loss': 0.24777150950462057, 'Total loss': 0.24777150950462057}
2023-01-05 04:51:07,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:07,565 INFO:     Epoch: 28
2023-01-05 04:51:09,828 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5152978042761485, 'Total loss': 0.5152978042761485} | train loss {'Reaction outcome loss': 0.2425371546863892, 'Total loss': 0.2425371546863892}
2023-01-05 04:51:09,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:09,828 INFO:     Epoch: 29
2023-01-05 04:51:12,073 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5394299228986105, 'Total loss': 0.5394299228986105} | train loss {'Reaction outcome loss': 0.24063895404527802, 'Total loss': 0.24063895404527802}
2023-01-05 04:51:12,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:12,073 INFO:     Epoch: 30
2023-01-05 04:51:14,334 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5563914487759273, 'Total loss': 0.5563914487759273} | train loss {'Reaction outcome loss': 0.24565221872720597, 'Total loss': 0.24565221872720597}
2023-01-05 04:51:14,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:14,334 INFO:     Epoch: 31
2023-01-05 04:51:16,605 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5777853488922119, 'Total loss': 0.5777853488922119} | train loss {'Reaction outcome loss': 0.23436696040342844, 'Total loss': 0.23436696040342844}
2023-01-05 04:51:16,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:16,607 INFO:     Epoch: 32
2023-01-05 04:51:18,867 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5411375890175502, 'Total loss': 0.5411375890175502} | train loss {'Reaction outcome loss': 0.2305662058993155, 'Total loss': 0.2305662058993155}
2023-01-05 04:51:18,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:18,868 INFO:     Epoch: 33
2023-01-05 04:51:21,128 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5456564287344615, 'Total loss': 0.5456564287344615} | train loss {'Reaction outcome loss': 0.22904106962791496, 'Total loss': 0.22904106962791496}
2023-01-05 04:51:21,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:21,128 INFO:     Epoch: 34
2023-01-05 04:51:23,358 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5380249043305715, 'Total loss': 0.5380249043305715} | train loss {'Reaction outcome loss': 0.22224500152599608, 'Total loss': 0.22224500152599608}
2023-01-05 04:51:23,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:23,358 INFO:     Epoch: 35
2023-01-05 04:51:25,625 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5360985974470774, 'Total loss': 0.5360985974470774} | train loss {'Reaction outcome loss': 0.22255890816787555, 'Total loss': 0.22255890816787555}
2023-01-05 04:51:25,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:25,625 INFO:     Epoch: 36
2023-01-05 04:51:27,873 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5308745324611663, 'Total loss': 0.5308745324611663} | train loss {'Reaction outcome loss': 0.21855491750698158, 'Total loss': 0.21855491750698158}
2023-01-05 04:51:27,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:27,873 INFO:     Epoch: 37
2023-01-05 04:51:30,132 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5283412386973699, 'Total loss': 0.5283412386973699} | train loss {'Reaction outcome loss': 0.2211636107207896, 'Total loss': 0.2211636107207896}
2023-01-05 04:51:30,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:30,132 INFO:     Epoch: 38
2023-01-05 04:51:32,395 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.546136911213398, 'Total loss': 0.546136911213398} | train loss {'Reaction outcome loss': 0.21543053529508735, 'Total loss': 0.21543053529508735}
2023-01-05 04:51:32,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:32,396 INFO:     Epoch: 39
2023-01-05 04:51:34,508 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5514323631922404, 'Total loss': 0.5514323631922404} | train loss {'Reaction outcome loss': 0.21207712238336265, 'Total loss': 0.21207712238336265}
2023-01-05 04:51:34,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:34,508 INFO:     Epoch: 40
2023-01-05 04:51:36,710 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5536334812641144, 'Total loss': 0.5536334812641144} | train loss {'Reaction outcome loss': 0.2138102972758529, 'Total loss': 0.2138102972758529}
2023-01-05 04:51:36,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:36,710 INFO:     Epoch: 41
2023-01-05 04:51:38,956 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5527091304461161, 'Total loss': 0.5527091304461161} | train loss {'Reaction outcome loss': 0.21112698296682525, 'Total loss': 0.21112698296682525}
2023-01-05 04:51:38,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:38,957 INFO:     Epoch: 42
2023-01-05 04:51:41,222 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5388764063517253, 'Total loss': 0.5388764063517253} | train loss {'Reaction outcome loss': 0.2103190733233158, 'Total loss': 0.2103190733233158}
2023-01-05 04:51:41,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:41,222 INFO:     Epoch: 43
2023-01-05 04:51:43,480 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5502738505601883, 'Total loss': 0.5502738505601883} | train loss {'Reaction outcome loss': 0.2028828186246202, 'Total loss': 0.2028828186246202}
2023-01-05 04:51:43,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:43,481 INFO:     Epoch: 44
2023-01-05 04:51:45,732 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5457523902257283, 'Total loss': 0.5457523902257283} | train loss {'Reaction outcome loss': 0.2035569996577598, 'Total loss': 0.2035569996577598}
2023-01-05 04:51:45,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:45,733 INFO:     Epoch: 45
2023-01-05 04:51:47,951 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5456370125214259, 'Total loss': 0.5456370125214259} | train loss {'Reaction outcome loss': 0.20552132880666119, 'Total loss': 0.20552132880666119}
2023-01-05 04:51:47,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:47,951 INFO:     Epoch: 46
2023-01-05 04:51:50,200 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5226801325877507, 'Total loss': 0.5226801325877507} | train loss {'Reaction outcome loss': 0.19978648518340575, 'Total loss': 0.19978648518340575}
2023-01-05 04:51:50,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:50,200 INFO:     Epoch: 47
2023-01-05 04:51:52,420 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.55609463651975, 'Total loss': 0.55609463651975} | train loss {'Reaction outcome loss': 0.19718261731896494, 'Total loss': 0.19718261731896494}
2023-01-05 04:51:52,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:52,421 INFO:     Epoch: 48
2023-01-05 04:51:54,664 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5510859161615371, 'Total loss': 0.5510859161615371} | train loss {'Reaction outcome loss': 0.19478951306824666, 'Total loss': 0.19478951306824666}
2023-01-05 04:51:54,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:54,664 INFO:     Epoch: 49
2023-01-05 04:51:56,913 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5638688524564107, 'Total loss': 0.5638688524564107} | train loss {'Reaction outcome loss': 0.1921516541033929, 'Total loss': 0.1921516541033929}
2023-01-05 04:51:56,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:56,913 INFO:     Epoch: 50
2023-01-05 04:51:59,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5716600646575292, 'Total loss': 0.5716600646575292} | train loss {'Reaction outcome loss': 0.19606465925766237, 'Total loss': 0.19606465925766237}
2023-01-05 04:51:59,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:51:59,144 INFO:     Epoch: 51
2023-01-05 04:52:01,307 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5778998931248983, 'Total loss': 0.5778998931248983} | train loss {'Reaction outcome loss': 0.18957470592357678, 'Total loss': 0.18957470592357678}
2023-01-05 04:52:01,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:01,308 INFO:     Epoch: 52
2023-01-05 04:52:03,436 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5417467415332794, 'Total loss': 0.5417467415332794} | train loss {'Reaction outcome loss': 0.1939750588380907, 'Total loss': 0.1939750588380907}
2023-01-05 04:52:03,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:03,436 INFO:     Epoch: 53
2023-01-05 04:52:05,689 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5560117870569229, 'Total loss': 0.5560117870569229} | train loss {'Reaction outcome loss': 0.1895461306138305, 'Total loss': 0.1895461306138305}
2023-01-05 04:52:05,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:05,689 INFO:     Epoch: 54
2023-01-05 04:52:07,915 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5568228741486867, 'Total loss': 0.5568228741486867} | train loss {'Reaction outcome loss': 0.189282491867862, 'Total loss': 0.189282491867862}
2023-01-05 04:52:07,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:07,916 INFO:     Epoch: 55
2023-01-05 04:52:10,076 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5618550618489583, 'Total loss': 0.5618550618489583} | train loss {'Reaction outcome loss': 0.1907132601038978, 'Total loss': 0.1907132601038978}
2023-01-05 04:52:10,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:10,077 INFO:     Epoch: 56
2023-01-05 04:52:12,166 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.542185761531194, 'Total loss': 0.542185761531194} | train loss {'Reaction outcome loss': 0.1852648609108629, 'Total loss': 0.1852648609108629}
2023-01-05 04:52:12,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:12,166 INFO:     Epoch: 57
2023-01-05 04:52:14,038 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5357573881745339, 'Total loss': 0.5357573881745339} | train loss {'Reaction outcome loss': 0.1828358273487538, 'Total loss': 0.1828358273487538}
2023-01-05 04:52:14,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:14,039 INFO:     Epoch: 58
2023-01-05 04:52:15,938 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5374430894851685, 'Total loss': 0.5374430894851685} | train loss {'Reaction outcome loss': 0.18156263698925823, 'Total loss': 0.18156263698925823}
2023-01-05 04:52:15,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:15,939 INFO:     Epoch: 59
2023-01-05 04:52:18,180 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5791564166545868, 'Total loss': 0.5791564166545868} | train loss {'Reaction outcome loss': 0.18351348445533788, 'Total loss': 0.18351348445533788}
2023-01-05 04:52:18,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:18,180 INFO:     Epoch: 60
2023-01-05 04:52:20,406 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5710102876027425, 'Total loss': 0.5710102876027425} | train loss {'Reaction outcome loss': 0.18344448355882365, 'Total loss': 0.18344448355882365}
2023-01-05 04:52:20,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:20,407 INFO:     Epoch: 61
2023-01-05 04:52:22,645 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5758577585220337, 'Total loss': 0.5758577585220337} | train loss {'Reaction outcome loss': 0.1796198334997061, 'Total loss': 0.1796198334997061}
2023-01-05 04:52:22,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:22,645 INFO:     Epoch: 62
2023-01-05 04:52:24,885 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5421545147895813, 'Total loss': 0.5421545147895813} | train loss {'Reaction outcome loss': 0.1828185347688344, 'Total loss': 0.1828185347688344}
2023-01-05 04:52:24,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:24,885 INFO:     Epoch: 63
2023-01-05 04:52:27,123 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5834236562252044, 'Total loss': 0.5834236562252044} | train loss {'Reaction outcome loss': 0.17615346771840384, 'Total loss': 0.17615346771840384}
2023-01-05 04:52:27,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:27,124 INFO:     Epoch: 64
2023-01-05 04:52:29,331 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5912382384141286, 'Total loss': 0.5912382384141286} | train loss {'Reaction outcome loss': 0.17462634018021703, 'Total loss': 0.17462634018021703}
2023-01-05 04:52:29,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:29,331 INFO:     Epoch: 65
2023-01-05 04:52:31,584 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5745232164859772, 'Total loss': 0.5745232164859772} | train loss {'Reaction outcome loss': 0.17093605136471815, 'Total loss': 0.17093605136471815}
2023-01-05 04:52:31,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:31,584 INFO:     Epoch: 66
2023-01-05 04:52:33,824 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5605515003204345, 'Total loss': 0.5605515003204345} | train loss {'Reaction outcome loss': 0.17362334474708643, 'Total loss': 0.17362334474708643}
2023-01-05 04:52:33,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:33,824 INFO:     Epoch: 67
2023-01-05 04:52:36,086 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5804227133591969, 'Total loss': 0.5804227133591969} | train loss {'Reaction outcome loss': 0.170893004724243, 'Total loss': 0.170893004724243}
2023-01-05 04:52:36,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:36,086 INFO:     Epoch: 68
2023-01-05 04:52:38,273 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5727618674437205, 'Total loss': 0.5727618674437205} | train loss {'Reaction outcome loss': 0.17267787341826488, 'Total loss': 0.17267787341826488}
2023-01-05 04:52:38,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:38,274 INFO:     Epoch: 69
2023-01-05 04:52:40,502 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5509899357954661, 'Total loss': 0.5509899357954661} | train loss {'Reaction outcome loss': 0.17338862887455447, 'Total loss': 0.17338862887455447}
2023-01-05 04:52:40,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:40,502 INFO:     Epoch: 70
2023-01-05 04:52:42,752 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5809019307295481, 'Total loss': 0.5809019307295481} | train loss {'Reaction outcome loss': 0.1708805398503909, 'Total loss': 0.1708805398503909}
2023-01-05 04:52:42,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:42,752 INFO:     Epoch: 71
2023-01-05 04:52:44,934 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5707359969615936, 'Total loss': 0.5707359969615936} | train loss {'Reaction outcome loss': 0.1733050469302343, 'Total loss': 0.1733050469302343}
2023-01-05 04:52:44,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:44,935 INFO:     Epoch: 72
2023-01-05 04:52:47,141 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6052052934964498, 'Total loss': 0.6052052934964498} | train loss {'Reaction outcome loss': 0.16725593879440884, 'Total loss': 0.16725593879440884}
2023-01-05 04:52:47,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:47,142 INFO:     Epoch: 73
2023-01-05 04:52:49,390 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5687751274555921, 'Total loss': 0.5687751274555921} | train loss {'Reaction outcome loss': 0.17568326761028258, 'Total loss': 0.17568326761028258}
2023-01-05 04:52:49,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:49,390 INFO:     Epoch: 74
2023-01-05 04:52:51,614 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6159364541371664, 'Total loss': 0.6159364541371664} | train loss {'Reaction outcome loss': 0.2000438355523553, 'Total loss': 0.2000438355523553}
2023-01-05 04:52:51,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:51,615 INFO:     Epoch: 75
2023-01-05 04:52:53,856 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5751359055439631, 'Total loss': 0.5751359055439631} | train loss {'Reaction outcome loss': 0.1817859292082637, 'Total loss': 0.1817859292082637}
2023-01-05 04:52:53,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:53,856 INFO:     Epoch: 76
2023-01-05 04:52:56,048 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6135008494059245, 'Total loss': 0.6135008494059245} | train loss {'Reaction outcome loss': 0.1772962813451269, 'Total loss': 0.1772962813451269}
2023-01-05 04:52:56,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:56,048 INFO:     Epoch: 77
2023-01-05 04:52:58,235 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6047402560710907, 'Total loss': 0.6047402560710907} | train loss {'Reaction outcome loss': 0.17759268785543417, 'Total loss': 0.17759268785543417}
2023-01-05 04:52:58,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:52:58,235 INFO:     Epoch: 78
2023-01-05 04:53:00,419 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5797305723031362, 'Total loss': 0.5797305723031362} | train loss {'Reaction outcome loss': 0.17326767381788502, 'Total loss': 0.17326767381788502}
2023-01-05 04:53:00,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:00,419 INFO:     Epoch: 79
2023-01-05 04:53:02,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.565440460263441, 'Total loss': 0.565440460263441} | train loss {'Reaction outcome loss': 0.1613261770100402, 'Total loss': 0.1613261770100402}
2023-01-05 04:53:02,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:02,617 INFO:     Epoch: 80
2023-01-05 04:53:04,850 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5800853927930196, 'Total loss': 0.5800853927930196} | train loss {'Reaction outcome loss': 0.16421644054218262, 'Total loss': 0.16421644054218262}
2023-01-05 04:53:04,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:04,851 INFO:     Epoch: 81
2023-01-05 04:53:07,097 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5955568273862203, 'Total loss': 0.5955568273862203} | train loss {'Reaction outcome loss': 0.1630354254984527, 'Total loss': 0.1630354254984527}
2023-01-05 04:53:07,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:07,097 INFO:     Epoch: 82
2023-01-05 04:53:09,287 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.561486937602361, 'Total loss': 0.561486937602361} | train loss {'Reaction outcome loss': 0.1641038383687914, 'Total loss': 0.1641038383687914}
2023-01-05 04:53:09,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:09,288 INFO:     Epoch: 83
2023-01-05 04:53:11,530 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5699762771526973, 'Total loss': 0.5699762771526973} | train loss {'Reaction outcome loss': 0.16235550943816054, 'Total loss': 0.16235550943816054}
2023-01-05 04:53:11,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:11,530 INFO:     Epoch: 84
2023-01-05 04:53:13,776 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5536840749283631, 'Total loss': 0.5536840749283631} | train loss {'Reaction outcome loss': 0.16644509960863524, 'Total loss': 0.16644509960863524}
2023-01-05 04:53:13,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:13,776 INFO:     Epoch: 85
2023-01-05 04:53:15,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5476072996854782, 'Total loss': 0.5476072996854782} | train loss {'Reaction outcome loss': 0.15998403647529852, 'Total loss': 0.15998403647529852}
2023-01-05 04:53:15,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:15,999 INFO:     Epoch: 86
2023-01-05 04:53:18,236 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.584382951259613, 'Total loss': 0.584382951259613} | train loss {'Reaction outcome loss': 0.15927964929268573, 'Total loss': 0.15927964929268573}
2023-01-05 04:53:18,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:18,237 INFO:     Epoch: 87
2023-01-05 04:53:20,462 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5569149951140085, 'Total loss': 0.5569149951140085} | train loss {'Reaction outcome loss': 0.1593677990682224, 'Total loss': 0.1593677990682224}
2023-01-05 04:53:20,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:20,462 INFO:     Epoch: 88
2023-01-05 04:53:22,701 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5646320770184199, 'Total loss': 0.5646320770184199} | train loss {'Reaction outcome loss': 0.1595428467363767, 'Total loss': 0.1595428467363767}
2023-01-05 04:53:22,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:22,702 INFO:     Epoch: 89
2023-01-05 04:53:24,944 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5863398159543673, 'Total loss': 0.5863398159543673} | train loss {'Reaction outcome loss': 0.1737503359951349, 'Total loss': 0.1737503359951349}
2023-01-05 04:53:24,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:24,944 INFO:     Epoch: 90
2023-01-05 04:53:27,172 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5790230929851532, 'Total loss': 0.5790230929851532} | train loss {'Reaction outcome loss': 0.162856415904505, 'Total loss': 0.162856415904505}
2023-01-05 04:53:27,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:27,172 INFO:     Epoch: 91
2023-01-05 04:53:29,407 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5719895482063293, 'Total loss': 0.5719895482063293} | train loss {'Reaction outcome loss': 0.16813675050819427, 'Total loss': 0.16813675050819427}
2023-01-05 04:53:29,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:29,407 INFO:     Epoch: 92
2023-01-05 04:53:31,637 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5587010490397613, 'Total loss': 0.5587010490397613} | train loss {'Reaction outcome loss': 0.15680031419817722, 'Total loss': 0.15680031419817722}
2023-01-05 04:53:31,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:31,637 INFO:     Epoch: 93
2023-01-05 04:53:33,896 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5729301651318868, 'Total loss': 0.5729301651318868} | train loss {'Reaction outcome loss': 0.15750661532966542, 'Total loss': 0.15750661532966542}
2023-01-05 04:53:33,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:33,897 INFO:     Epoch: 94
2023-01-05 04:53:36,104 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5524611234664917, 'Total loss': 0.5524611234664917} | train loss {'Reaction outcome loss': 0.15852976190364934, 'Total loss': 0.15852976190364934}
2023-01-05 04:53:36,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:36,105 INFO:     Epoch: 95
2023-01-05 04:53:38,312 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5518423626820247, 'Total loss': 0.5518423626820247} | train loss {'Reaction outcome loss': 0.15327882691138034, 'Total loss': 0.15327882691138034}
2023-01-05 04:53:38,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:38,313 INFO:     Epoch: 96
2023-01-05 04:53:40,562 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5350432515144348, 'Total loss': 0.5350432515144348} | train loss {'Reaction outcome loss': 0.15397703019034056, 'Total loss': 0.15397703019034056}
2023-01-05 04:53:40,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:40,562 INFO:     Epoch: 97
2023-01-05 04:53:42,778 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5693164348602295, 'Total loss': 0.5693164348602295} | train loss {'Reaction outcome loss': 0.15263146138243863, 'Total loss': 0.15263146138243863}
2023-01-05 04:53:42,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:42,778 INFO:     Epoch: 98
2023-01-05 04:53:44,904 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5727514088153839, 'Total loss': 0.5727514088153839} | train loss {'Reaction outcome loss': 0.15616736831124517, 'Total loss': 0.15616736831124517}
2023-01-05 04:53:44,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:44,905 INFO:     Epoch: 99
2023-01-05 04:53:47,085 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5561877508958181, 'Total loss': 0.5561877508958181} | train loss {'Reaction outcome loss': 0.1534338226793688, 'Total loss': 0.1534338226793688}
2023-01-05 04:53:47,085 INFO:     Best model found after epoch 13 of 100.
2023-01-05 04:53:47,086 INFO:   Done with stage: TRAINING
2023-01-05 04:53:47,086 INFO:   Starting stage: EVALUATION
2023-01-05 04:53:47,220 INFO:   Done with stage: EVALUATION
2023-01-05 04:53:47,220 INFO:   Leaving out SEQ value Fold_5
2023-01-05 04:53:47,233 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 04:53:47,233 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:53:47,880 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:53:47,880 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:53:47,951 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:53:47,952 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:53:47,952 INFO:     No hyperparam tuning for this model
2023-01-05 04:53:47,952 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:53:47,952 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:53:47,952 INFO:     None feature selector for col prot
2023-01-05 04:53:47,953 INFO:     None feature selector for col prot
2023-01-05 04:53:47,953 INFO:     None feature selector for col prot
2023-01-05 04:53:47,953 INFO:     None feature selector for col chem
2023-01-05 04:53:47,953 INFO:     None feature selector for col chem
2023-01-05 04:53:47,953 INFO:     None feature selector for col chem
2023-01-05 04:53:47,953 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:53:47,953 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:53:47,955 INFO:     Number of params in model 72931
2023-01-05 04:53:47,958 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:53:47,958 INFO:   Starting stage: TRAINING
2023-01-05 04:53:48,019 INFO:     Val loss before train {'Reaction outcome loss': 0.9665698647499085, 'Total loss': 0.9665698647499085}
2023-01-05 04:53:48,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:48,019 INFO:     Epoch: 0
2023-01-05 04:53:50,210 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7516353110472361, 'Total loss': 0.7516353110472361} | train loss {'Reaction outcome loss': 0.9737653196721837, 'Total loss': 0.9737653196721837}
2023-01-05 04:53:50,210 INFO:     Found new best model at epoch 0
2023-01-05 04:53:50,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:50,211 INFO:     Epoch: 1
2023-01-05 04:53:52,345 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5520832637945811, 'Total loss': 0.5520832637945811} | train loss {'Reaction outcome loss': 0.7048668808074318, 'Total loss': 0.7048668808074318}
2023-01-05 04:53:52,346 INFO:     Found new best model at epoch 1
2023-01-05 04:53:52,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:52,348 INFO:     Epoch: 2
2023-01-05 04:53:54,550 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4648158589998881, 'Total loss': 0.4648158589998881} | train loss {'Reaction outcome loss': 0.5659240966062129, 'Total loss': 0.5659240966062129}
2023-01-05 04:53:54,550 INFO:     Found new best model at epoch 2
2023-01-05 04:53:54,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:54,552 INFO:     Epoch: 3
2023-01-05 04:53:56,779 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4580033004283905, 'Total loss': 0.4580033004283905} | train loss {'Reaction outcome loss': 0.5142313884453092, 'Total loss': 0.5142313884453092}
2023-01-05 04:53:56,779 INFO:     Found new best model at epoch 3
2023-01-05 04:53:56,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:56,780 INFO:     Epoch: 4
2023-01-05 04:53:59,025 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42105962137381236, 'Total loss': 0.42105962137381236} | train loss {'Reaction outcome loss': 0.4809351024913487, 'Total loss': 0.4809351024913487}
2023-01-05 04:53:59,025 INFO:     Found new best model at epoch 4
2023-01-05 04:53:59,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:53:59,026 INFO:     Epoch: 5
2023-01-05 04:54:01,253 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4277914504210154, 'Total loss': 0.4277914504210154} | train loss {'Reaction outcome loss': 0.469024834236589, 'Total loss': 0.469024834236589}
2023-01-05 04:54:01,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:01,253 INFO:     Epoch: 6
2023-01-05 04:54:03,497 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4097226450840632, 'Total loss': 0.4097226450840632} | train loss {'Reaction outcome loss': 0.4417766588875025, 'Total loss': 0.4417766588875025}
2023-01-05 04:54:03,497 INFO:     Found new best model at epoch 6
2023-01-05 04:54:03,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:03,499 INFO:     Epoch: 7
2023-01-05 04:54:05,684 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4251638780037562, 'Total loss': 0.4251638780037562} | train loss {'Reaction outcome loss': 0.4244481038007329, 'Total loss': 0.4244481038007329}
2023-01-05 04:54:05,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:05,685 INFO:     Epoch: 8
2023-01-05 04:54:07,953 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43688398599624634, 'Total loss': 0.43688398599624634} | train loss {'Reaction outcome loss': 0.4086769566317831, 'Total loss': 0.4086769566317831}
2023-01-05 04:54:07,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:07,953 INFO:     Epoch: 9
2023-01-05 04:54:10,161 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4129432817300161, 'Total loss': 0.4129432817300161} | train loss {'Reaction outcome loss': 0.3980590397411067, 'Total loss': 0.3980590397411067}
2023-01-05 04:54:10,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:10,161 INFO:     Epoch: 10
2023-01-05 04:54:12,391 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3959535072247187, 'Total loss': 0.3959535072247187} | train loss {'Reaction outcome loss': 0.3881968917039426, 'Total loss': 0.3881968917039426}
2023-01-05 04:54:12,391 INFO:     Found new best model at epoch 10
2023-01-05 04:54:12,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:12,393 INFO:     Epoch: 11
2023-01-05 04:54:14,603 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40620455841223396, 'Total loss': 0.40620455841223396} | train loss {'Reaction outcome loss': 0.3760506561602992, 'Total loss': 0.3760506561602992}
2023-01-05 04:54:14,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:14,603 INFO:     Epoch: 12
2023-01-05 04:54:16,809 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3907298227151235, 'Total loss': 0.3907298227151235} | train loss {'Reaction outcome loss': 0.3629162857389968, 'Total loss': 0.3629162857389968}
2023-01-05 04:54:16,809 INFO:     Found new best model at epoch 12
2023-01-05 04:54:16,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:16,811 INFO:     Epoch: 13
2023-01-05 04:54:18,973 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39929922024408976, 'Total loss': 0.39929922024408976} | train loss {'Reaction outcome loss': 0.35586024884432316, 'Total loss': 0.35586024884432316}
2023-01-05 04:54:18,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:18,973 INFO:     Epoch: 14
2023-01-05 04:54:21,211 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41166363954544066, 'Total loss': 0.41166363954544066} | train loss {'Reaction outcome loss': 0.34344839377571706, 'Total loss': 0.34344839377571706}
2023-01-05 04:54:21,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:21,212 INFO:     Epoch: 15
2023-01-05 04:54:23,448 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4353492309649785, 'Total loss': 0.4353492309649785} | train loss {'Reaction outcome loss': 0.33927252228676336, 'Total loss': 0.33927252228676336}
2023-01-05 04:54:23,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:23,448 INFO:     Epoch: 16
2023-01-05 04:54:25,637 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42318545281887054, 'Total loss': 0.42318545281887054} | train loss {'Reaction outcome loss': 0.3259042325485295, 'Total loss': 0.3259042325485295}
2023-01-05 04:54:25,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:25,637 INFO:     Epoch: 17
2023-01-05 04:54:27,887 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4384197175502777, 'Total loss': 0.4384197175502777} | train loss {'Reaction outcome loss': 0.32221135310828686, 'Total loss': 0.32221135310828686}
2023-01-05 04:54:27,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:27,888 INFO:     Epoch: 18
2023-01-05 04:54:30,147 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43627256552378335, 'Total loss': 0.43627256552378335} | train loss {'Reaction outcome loss': 0.3157143911238814, 'Total loss': 0.3157143911238814}
2023-01-05 04:54:30,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:30,147 INFO:     Epoch: 19
2023-01-05 04:54:32,397 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42259310285250345, 'Total loss': 0.42259310285250345} | train loss {'Reaction outcome loss': 0.30420880543407175, 'Total loss': 0.30420880543407175}
2023-01-05 04:54:32,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:32,397 INFO:     Epoch: 20
2023-01-05 04:54:34,652 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42437531451384225, 'Total loss': 0.42437531451384225} | train loss {'Reaction outcome loss': 0.29784362907378015, 'Total loss': 0.29784362907378015}
2023-01-05 04:54:34,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:34,652 INFO:     Epoch: 21
2023-01-05 04:54:36,859 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43882015645503997, 'Total loss': 0.43882015645503997} | train loss {'Reaction outcome loss': 0.2932248998785972, 'Total loss': 0.2932248998785972}
2023-01-05 04:54:36,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:36,859 INFO:     Epoch: 22
2023-01-05 04:54:39,117 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46019482215245566, 'Total loss': 0.46019482215245566} | train loss {'Reaction outcome loss': 0.29297199718016403, 'Total loss': 0.29297199718016403}
2023-01-05 04:54:39,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:39,117 INFO:     Epoch: 23
2023-01-05 04:54:41,351 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42999742726484935, 'Total loss': 0.42999742726484935} | train loss {'Reaction outcome loss': 0.2864203517885366, 'Total loss': 0.2864203517885366}
2023-01-05 04:54:41,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:41,351 INFO:     Epoch: 24
2023-01-05 04:54:43,517 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44211413860321047, 'Total loss': 0.44211413860321047} | train loss {'Reaction outcome loss': 0.2747433723142013, 'Total loss': 0.2747433723142013}
2023-01-05 04:54:43,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:43,518 INFO:     Epoch: 25
2023-01-05 04:54:45,667 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4518368502457937, 'Total loss': 0.4518368502457937} | train loss {'Reaction outcome loss': 0.2713176615302539, 'Total loss': 0.2713176615302539}
2023-01-05 04:54:45,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:45,668 INFO:     Epoch: 26
2023-01-05 04:54:47,877 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44172770182291665, 'Total loss': 0.44172770182291665} | train loss {'Reaction outcome loss': 0.2707125010944066, 'Total loss': 0.2707125010944066}
2023-01-05 04:54:47,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:47,877 INFO:     Epoch: 27
2023-01-05 04:54:50,134 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4418395737806956, 'Total loss': 0.4418395737806956} | train loss {'Reaction outcome loss': 0.26580421076294547, 'Total loss': 0.26580421076294547}
2023-01-05 04:54:50,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:50,135 INFO:     Epoch: 28
2023-01-05 04:54:52,390 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4552650729815165, 'Total loss': 0.4552650729815165} | train loss {'Reaction outcome loss': 0.2621893749261896, 'Total loss': 0.2621893749261896}
2023-01-05 04:54:52,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:52,390 INFO:     Epoch: 29
2023-01-05 04:54:54,629 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4561958481868108, 'Total loss': 0.4561958481868108} | train loss {'Reaction outcome loss': 0.25987241923998017, 'Total loss': 0.25987241923998017}
2023-01-05 04:54:54,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:54,629 INFO:     Epoch: 30
2023-01-05 04:54:56,879 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4460833802819252, 'Total loss': 0.4460833802819252} | train loss {'Reaction outcome loss': 0.25317895504902127, 'Total loss': 0.25317895504902127}
2023-01-05 04:54:56,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:56,880 INFO:     Epoch: 31
2023-01-05 04:54:59,090 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45675381620725, 'Total loss': 0.45675381620725} | train loss {'Reaction outcome loss': 0.25001478940100863, 'Total loss': 0.25001478940100863}
2023-01-05 04:54:59,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:54:59,091 INFO:     Epoch: 32
2023-01-05 04:55:01,266 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4414245992898941, 'Total loss': 0.4414245992898941} | train loss {'Reaction outcome loss': 0.24838477345790877, 'Total loss': 0.24838477345790877}
2023-01-05 04:55:01,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:01,267 INFO:     Epoch: 33
2023-01-05 04:55:03,458 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4253557155529658, 'Total loss': 0.4253557155529658} | train loss {'Reaction outcome loss': 0.2548965180454695, 'Total loss': 0.2548965180454695}
2023-01-05 04:55:03,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:03,459 INFO:     Epoch: 34
2023-01-05 04:55:05,627 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42967619995276135, 'Total loss': 0.42967619995276135} | train loss {'Reaction outcome loss': 0.2619579383678248, 'Total loss': 0.2619579383678248}
2023-01-05 04:55:05,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:05,628 INFO:     Epoch: 35
2023-01-05 04:55:07,795 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44052964498599373, 'Total loss': 0.44052964498599373} | train loss {'Reaction outcome loss': 0.24401309915887448, 'Total loss': 0.24401309915887448}
2023-01-05 04:55:07,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:07,795 INFO:     Epoch: 36
2023-01-05 04:55:10,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4261788782974084, 'Total loss': 0.4261788782974084} | train loss {'Reaction outcome loss': 0.23724567965584117, 'Total loss': 0.23724567965584117}
2023-01-05 04:55:10,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:10,017 INFO:     Epoch: 37
2023-01-05 04:55:12,251 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43255534370740256, 'Total loss': 0.43255534370740256} | train loss {'Reaction outcome loss': 0.2370713969154378, 'Total loss': 0.2370713969154378}
2023-01-05 04:55:12,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:12,252 INFO:     Epoch: 38
2023-01-05 04:55:14,482 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4685483659307162, 'Total loss': 0.4685483659307162} | train loss {'Reaction outcome loss': 0.23371135384060335, 'Total loss': 0.23371135384060335}
2023-01-05 04:55:14,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:14,483 INFO:     Epoch: 39
2023-01-05 04:55:16,712 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44484110474586486, 'Total loss': 0.44484110474586486} | train loss {'Reaction outcome loss': 0.22998907416932407, 'Total loss': 0.22998907416932407}
2023-01-05 04:55:16,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:16,713 INFO:     Epoch: 40
2023-01-05 04:55:18,846 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.443963897228241, 'Total loss': 0.443963897228241} | train loss {'Reaction outcome loss': 0.22998684924897278, 'Total loss': 0.22998684924897278}
2023-01-05 04:55:18,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:18,847 INFO:     Epoch: 41
2023-01-05 04:55:21,086 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44604297578334806, 'Total loss': 0.44604297578334806} | train loss {'Reaction outcome loss': 0.22414694963600082, 'Total loss': 0.22414694963600082}
2023-01-05 04:55:21,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:21,086 INFO:     Epoch: 42
2023-01-05 04:55:23,315 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44968968828519185, 'Total loss': 0.44968968828519185} | train loss {'Reaction outcome loss': 0.22212073582804936, 'Total loss': 0.22212073582804936}
2023-01-05 04:55:23,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:23,316 INFO:     Epoch: 43
2023-01-05 04:55:25,575 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47136271794637047, 'Total loss': 0.47136271794637047} | train loss {'Reaction outcome loss': 0.2236666993939898, 'Total loss': 0.2236666993939898}
2023-01-05 04:55:25,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:25,575 INFO:     Epoch: 44
2023-01-05 04:55:27,815 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45564628541469576, 'Total loss': 0.45564628541469576} | train loss {'Reaction outcome loss': 0.22048104484902992, 'Total loss': 0.22048104484902992}
2023-01-05 04:55:27,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:27,815 INFO:     Epoch: 45
2023-01-05 04:55:30,074 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4299202481905619, 'Total loss': 0.4299202481905619} | train loss {'Reaction outcome loss': 0.2306084604461448, 'Total loss': 0.2306084604461448}
2023-01-05 04:55:30,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:30,074 INFO:     Epoch: 46
2023-01-05 04:55:32,331 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4269670287768046, 'Total loss': 0.4269670287768046} | train loss {'Reaction outcome loss': 0.27568776751665963, 'Total loss': 0.27568776751665963}
2023-01-05 04:55:32,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:32,332 INFO:     Epoch: 47
2023-01-05 04:55:34,552 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45928119917710625, 'Total loss': 0.45928119917710625} | train loss {'Reaction outcome loss': 0.2182727722570037, 'Total loss': 0.2182727722570037}
2023-01-05 04:55:34,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:34,553 INFO:     Epoch: 48
2023-01-05 04:55:36,826 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43310025334358215, 'Total loss': 0.43310025334358215} | train loss {'Reaction outcome loss': 0.21171102204791986, 'Total loss': 0.21171102204791986}
2023-01-05 04:55:36,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:36,826 INFO:     Epoch: 49
2023-01-05 04:55:38,950 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4578098475933075, 'Total loss': 0.4578098475933075} | train loss {'Reaction outcome loss': 0.20759985604377437, 'Total loss': 0.20759985604377437}
2023-01-05 04:55:38,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:38,951 INFO:     Epoch: 50
2023-01-05 04:55:41,145 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4315590918064117, 'Total loss': 0.4315590918064117} | train loss {'Reaction outcome loss': 0.2072304304253877, 'Total loss': 0.2072304304253877}
2023-01-05 04:55:41,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:41,145 INFO:     Epoch: 51
2023-01-05 04:55:43,373 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4456230382124583, 'Total loss': 0.4456230382124583} | train loss {'Reaction outcome loss': 0.20565023799629314, 'Total loss': 0.20565023799629314}
2023-01-05 04:55:43,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:43,373 INFO:     Epoch: 52
2023-01-05 04:55:45,594 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45467864473660785, 'Total loss': 0.45467864473660785} | train loss {'Reaction outcome loss': 0.20787893555825576, 'Total loss': 0.20787893555825576}
2023-01-05 04:55:45,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:45,594 INFO:     Epoch: 53
2023-01-05 04:55:47,813 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42411184882124264, 'Total loss': 0.42411184882124264} | train loss {'Reaction outcome loss': 0.20623780481780515, 'Total loss': 0.20623780481780515}
2023-01-05 04:55:47,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:47,813 INFO:     Epoch: 54
2023-01-05 04:55:50,034 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4781236449877421, 'Total loss': 0.4781236449877421} | train loss {'Reaction outcome loss': 0.20728523616944058, 'Total loss': 0.20728523616944058}
2023-01-05 04:55:50,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:50,035 INFO:     Epoch: 55
2023-01-05 04:55:52,273 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4425820618867874, 'Total loss': 0.4425820618867874} | train loss {'Reaction outcome loss': 0.199791688930207, 'Total loss': 0.199791688930207}
2023-01-05 04:55:52,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:52,274 INFO:     Epoch: 56
2023-01-05 04:55:54,498 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.453028338154157, 'Total loss': 0.453028338154157} | train loss {'Reaction outcome loss': 0.20326095610937994, 'Total loss': 0.20326095610937994}
2023-01-05 04:55:54,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:54,498 INFO:     Epoch: 57
2023-01-05 04:55:56,613 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43965520163377125, 'Total loss': 0.43965520163377125} | train loss {'Reaction outcome loss': 0.20187601610424294, 'Total loss': 0.20187601610424294}
2023-01-05 04:55:56,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:56,613 INFO:     Epoch: 58
2023-01-05 04:55:58,867 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44657726883888244, 'Total loss': 0.44657726883888244} | train loss {'Reaction outcome loss': 0.19376614545741916, 'Total loss': 0.19376614545741916}
2023-01-05 04:55:58,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:55:58,867 INFO:     Epoch: 59
2023-01-05 04:56:01,082 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4718969206015269, 'Total loss': 0.4718969206015269} | train loss {'Reaction outcome loss': 0.19550045425801174, 'Total loss': 0.19550045425801174}
2023-01-05 04:56:01,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:01,082 INFO:     Epoch: 60
2023-01-05 04:56:03,321 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4723620851834615, 'Total loss': 0.4723620851834615} | train loss {'Reaction outcome loss': 0.19807094595044095, 'Total loss': 0.19807094595044095}
2023-01-05 04:56:03,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:03,321 INFO:     Epoch: 61
2023-01-05 04:56:05,569 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4441938107212385, 'Total loss': 0.4441938107212385} | train loss {'Reaction outcome loss': 0.19428387092109228, 'Total loss': 0.19428387092109228}
2023-01-05 04:56:05,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:05,569 INFO:     Epoch: 62
2023-01-05 04:56:07,817 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4367460757493973, 'Total loss': 0.4367460757493973} | train loss {'Reaction outcome loss': 0.18795999926294535, 'Total loss': 0.18795999926294535}
2023-01-05 04:56:07,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:07,817 INFO:     Epoch: 63
2023-01-05 04:56:10,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4626877094308535, 'Total loss': 0.4626877094308535} | train loss {'Reaction outcome loss': 0.19030418488335377, 'Total loss': 0.19030418488335377}
2023-01-05 04:56:10,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:10,062 INFO:     Epoch: 64
2023-01-05 04:56:12,312 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4808832029501597, 'Total loss': 0.4808832029501597} | train loss {'Reaction outcome loss': 0.18332684282472325, 'Total loss': 0.18332684282472325}
2023-01-05 04:56:12,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:12,313 INFO:     Epoch: 65
2023-01-05 04:56:14,552 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4514946808417638, 'Total loss': 0.4514946808417638} | train loss {'Reaction outcome loss': 0.18751240954799764, 'Total loss': 0.18751240954799764}
2023-01-05 04:56:14,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:14,552 INFO:     Epoch: 66
2023-01-05 04:56:16,814 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46049466530481975, 'Total loss': 0.46049466530481975} | train loss {'Reaction outcome loss': 0.1882388094457818, 'Total loss': 0.1882388094457818}
2023-01-05 04:56:16,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:16,815 INFO:     Epoch: 67
2023-01-05 04:56:19,037 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.464228622118632, 'Total loss': 0.464228622118632} | train loss {'Reaction outcome loss': 0.1873565268183154, 'Total loss': 0.1873565268183154}
2023-01-05 04:56:19,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:19,037 INFO:     Epoch: 68
2023-01-05 04:56:21,257 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4388612022002538, 'Total loss': 0.4388612022002538} | train loss {'Reaction outcome loss': 0.18701487539531797, 'Total loss': 0.18701487539531797}
2023-01-05 04:56:21,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:21,257 INFO:     Epoch: 69
2023-01-05 04:56:23,465 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4481260965267817, 'Total loss': 0.4481260965267817} | train loss {'Reaction outcome loss': 0.18539026728451616, 'Total loss': 0.18539026728451616}
2023-01-05 04:56:23,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:23,465 INFO:     Epoch: 70
2023-01-05 04:56:25,724 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43853511263926825, 'Total loss': 0.43853511263926825} | train loss {'Reaction outcome loss': 0.18169899630036368, 'Total loss': 0.18169899630036368}
2023-01-05 04:56:25,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:25,725 INFO:     Epoch: 71
2023-01-05 04:56:27,921 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4612023070454597, 'Total loss': 0.4612023070454597} | train loss {'Reaction outcome loss': 0.17847425553915947, 'Total loss': 0.17847425553915947}
2023-01-05 04:56:27,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:27,921 INFO:     Epoch: 72
2023-01-05 04:56:30,158 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.468933375676473, 'Total loss': 0.468933375676473} | train loss {'Reaction outcome loss': 0.17818459514982996, 'Total loss': 0.17818459514982996}
2023-01-05 04:56:30,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:30,159 INFO:     Epoch: 73
2023-01-05 04:56:32,394 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.445476974050204, 'Total loss': 0.445476974050204} | train loss {'Reaction outcome loss': 0.18284202478505482, 'Total loss': 0.18284202478505482}
2023-01-05 04:56:32,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:32,395 INFO:     Epoch: 74
2023-01-05 04:56:34,613 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.459995753566424, 'Total loss': 0.459995753566424} | train loss {'Reaction outcome loss': 0.17545003494381925, 'Total loss': 0.17545003494381925}
2023-01-05 04:56:34,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:34,613 INFO:     Epoch: 75
2023-01-05 04:56:36,816 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4378808279832204, 'Total loss': 0.4378808279832204} | train loss {'Reaction outcome loss': 0.182464568777241, 'Total loss': 0.182464568777241}
2023-01-05 04:56:36,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:36,816 INFO:     Epoch: 76
2023-01-05 04:56:39,035 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4535699119170507, 'Total loss': 0.4535699119170507} | train loss {'Reaction outcome loss': 0.1804919060692766, 'Total loss': 0.1804919060692766}
2023-01-05 04:56:39,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:39,036 INFO:     Epoch: 77
2023-01-05 04:56:41,291 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4475148638089498, 'Total loss': 0.4475148638089498} | train loss {'Reaction outcome loss': 0.17730637565461843, 'Total loss': 0.17730637565461843}
2023-01-05 04:56:41,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:41,291 INFO:     Epoch: 78
2023-01-05 04:56:43,451 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4493667234977086, 'Total loss': 0.4493667234977086} | train loss {'Reaction outcome loss': 0.1753206635330571, 'Total loss': 0.1753206635330571}
2023-01-05 04:56:43,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:43,451 INFO:     Epoch: 79
2023-01-05 04:56:45,697 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4507671415805817, 'Total loss': 0.4507671415805817} | train loss {'Reaction outcome loss': 0.1711472388232442, 'Total loss': 0.1711472388232442}
2023-01-05 04:56:45,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:45,698 INFO:     Epoch: 80
2023-01-05 04:56:47,807 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46920635203520455, 'Total loss': 0.46920635203520455} | train loss {'Reaction outcome loss': 0.17384136260986544, 'Total loss': 0.17384136260986544}
2023-01-05 04:56:47,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:47,808 INFO:     Epoch: 81
2023-01-05 04:56:50,039 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.489518341422081, 'Total loss': 0.489518341422081} | train loss {'Reaction outcome loss': 0.1703485817069768, 'Total loss': 0.1703485817069768}
2023-01-05 04:56:50,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:50,040 INFO:     Epoch: 82
2023-01-05 04:56:52,267 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4398829753200213, 'Total loss': 0.4398829753200213} | train loss {'Reaction outcome loss': 0.17284271492204373, 'Total loss': 0.17284271492204373}
2023-01-05 04:56:52,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:52,268 INFO:     Epoch: 83
2023-01-05 04:56:54,468 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47096065785735847, 'Total loss': 0.47096065785735847} | train loss {'Reaction outcome loss': 0.1937275630189106, 'Total loss': 0.1937275630189106}
2023-01-05 04:56:54,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:54,469 INFO:     Epoch: 84
2023-01-05 04:56:56,687 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44076686600844067, 'Total loss': 0.44076686600844067} | train loss {'Reaction outcome loss': 0.21886549002735683, 'Total loss': 0.21886549002735683}
2023-01-05 04:56:56,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:56,687 INFO:     Epoch: 85
2023-01-05 04:56:58,942 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4662153800328573, 'Total loss': 0.4662153800328573} | train loss {'Reaction outcome loss': 0.1736294853081758, 'Total loss': 0.1736294853081758}
2023-01-05 04:56:58,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:56:58,943 INFO:     Epoch: 86
2023-01-05 04:57:01,196 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44128296871980033, 'Total loss': 0.44128296871980033} | train loss {'Reaction outcome loss': 0.16422616429559456, 'Total loss': 0.16422616429559456}
2023-01-05 04:57:01,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:01,197 INFO:     Epoch: 87
2023-01-05 04:57:03,446 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4813912103573481, 'Total loss': 0.4813912103573481} | train loss {'Reaction outcome loss': 0.1636532050233918, 'Total loss': 0.1636532050233918}
2023-01-05 04:57:03,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:03,446 INFO:     Epoch: 88
2023-01-05 04:57:05,706 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48132650752862294, 'Total loss': 0.48132650752862294} | train loss {'Reaction outcome loss': 0.16056368245196043, 'Total loss': 0.16056368245196043}
2023-01-05 04:57:05,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:05,707 INFO:     Epoch: 89
2023-01-05 04:57:07,959 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45926878762741885, 'Total loss': 0.45926878762741885} | train loss {'Reaction outcome loss': 0.16708210581113025, 'Total loss': 0.16708210581113025}
2023-01-05 04:57:07,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:07,959 INFO:     Epoch: 90
2023-01-05 04:57:10,215 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4444724867741267, 'Total loss': 0.4444724867741267} | train loss {'Reaction outcome loss': 0.1637468002702825, 'Total loss': 0.1637468002702825}
2023-01-05 04:57:10,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:10,215 INFO:     Epoch: 91
2023-01-05 04:57:12,406 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47558896485716107, 'Total loss': 0.47558896485716107} | train loss {'Reaction outcome loss': 0.16261163675148238, 'Total loss': 0.16261163675148238}
2023-01-05 04:57:12,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:12,406 INFO:     Epoch: 92
2023-01-05 04:57:14,639 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4574904461701711, 'Total loss': 0.4574904461701711} | train loss {'Reaction outcome loss': 0.16467036202084273, 'Total loss': 0.16467036202084273}
2023-01-05 04:57:14,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:14,640 INFO:     Epoch: 93
2023-01-05 04:57:16,902 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4463943059245745, 'Total loss': 0.4463943059245745} | train loss {'Reaction outcome loss': 0.1653256636193913, 'Total loss': 0.1653256636193913}
2023-01-05 04:57:16,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:16,903 INFO:     Epoch: 94
2023-01-05 04:57:19,041 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4511643429597219, 'Total loss': 0.4511643429597219} | train loss {'Reaction outcome loss': 0.1627560181651474, 'Total loss': 0.1627560181651474}
2023-01-05 04:57:19,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:19,041 INFO:     Epoch: 95
2023-01-05 04:57:21,287 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4324688951174418, 'Total loss': 0.4324688951174418} | train loss {'Reaction outcome loss': 0.16401595799539212, 'Total loss': 0.16401595799539212}
2023-01-05 04:57:21,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:21,287 INFO:     Epoch: 96
2023-01-05 04:57:23,544 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4612312455972036, 'Total loss': 0.4612312455972036} | train loss {'Reaction outcome loss': 0.16293729004024973, 'Total loss': 0.16293729004024973}
2023-01-05 04:57:23,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:23,544 INFO:     Epoch: 97
2023-01-05 04:57:25,761 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.427194352944692, 'Total loss': 0.427194352944692} | train loss {'Reaction outcome loss': 0.159590540418407, 'Total loss': 0.159590540418407}
2023-01-05 04:57:25,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:25,762 INFO:     Epoch: 98
2023-01-05 04:57:28,005 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45922128508488336, 'Total loss': 0.45922128508488336} | train loss {'Reaction outcome loss': 0.163884951487041, 'Total loss': 0.163884951487041}
2023-01-05 04:57:28,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:28,005 INFO:     Epoch: 99
2023-01-05 04:57:30,236 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43832363883654274, 'Total loss': 0.43832363883654274} | train loss {'Reaction outcome loss': 0.16333400200634007, 'Total loss': 0.16333400200634007}
2023-01-05 04:57:30,237 INFO:     Best model found after epoch 13 of 100.
2023-01-05 04:57:30,237 INFO:   Done with stage: TRAINING
2023-01-05 04:57:30,237 INFO:   Starting stage: EVALUATION
2023-01-05 04:57:30,372 INFO:   Done with stage: EVALUATION
2023-01-05 04:57:30,372 INFO:   Leaving out SEQ value Fold_6
2023-01-05 04:57:30,384 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 04:57:30,384 INFO:   Starting stage: FEATURE SCALING
2023-01-05 04:57:31,036 INFO:   Done with stage: FEATURE SCALING
2023-01-05 04:57:31,036 INFO:   Starting stage: SCALING TARGETS
2023-01-05 04:57:31,108 INFO:   Done with stage: SCALING TARGETS
2023-01-05 04:57:31,108 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:57:31,108 INFO:     No hyperparam tuning for this model
2023-01-05 04:57:31,108 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 04:57:31,108 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 04:57:31,109 INFO:     None feature selector for col prot
2023-01-05 04:57:31,109 INFO:     None feature selector for col prot
2023-01-05 04:57:31,109 INFO:     None feature selector for col prot
2023-01-05 04:57:31,109 INFO:     None feature selector for col chem
2023-01-05 04:57:31,110 INFO:     None feature selector for col chem
2023-01-05 04:57:31,110 INFO:     None feature selector for col chem
2023-01-05 04:57:31,110 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 04:57:31,110 INFO:   Starting stage: BUILD MODEL
2023-01-05 04:57:31,111 INFO:     Number of params in model 72931
2023-01-05 04:57:31,114 INFO:   Done with stage: BUILD MODEL
2023-01-05 04:57:31,115 INFO:   Starting stage: TRAINING
2023-01-05 04:57:31,175 INFO:     Val loss before train {'Reaction outcome loss': 1.0215633273124696, 'Total loss': 1.0215633273124696}
2023-01-05 04:57:31,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:31,175 INFO:     Epoch: 0
2023-01-05 04:57:33,411 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7378203968207041, 'Total loss': 0.7378203968207041} | train loss {'Reaction outcome loss': 0.9293523293109577, 'Total loss': 0.9293523293109577}
2023-01-05 04:57:33,411 INFO:     Found new best model at epoch 0
2023-01-05 04:57:33,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:33,412 INFO:     Epoch: 1
2023-01-05 04:57:35,666 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5778049031893412, 'Total loss': 0.5778049031893412} | train loss {'Reaction outcome loss': 0.6297059706832527, 'Total loss': 0.6297059706832527}
2023-01-05 04:57:35,667 INFO:     Found new best model at epoch 1
2023-01-05 04:57:35,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:35,669 INFO:     Epoch: 2
2023-01-05 04:57:37,916 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5579436580340068, 'Total loss': 0.5579436580340068} | train loss {'Reaction outcome loss': 0.5452617585443847, 'Total loss': 0.5452617585443847}
2023-01-05 04:57:37,916 INFO:     Found new best model at epoch 2
2023-01-05 04:57:37,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:37,918 INFO:     Epoch: 3
2023-01-05 04:57:40,179 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.529048216342926, 'Total loss': 0.529048216342926} | train loss {'Reaction outcome loss': 0.5089942874783643, 'Total loss': 0.5089942874783643}
2023-01-05 04:57:40,179 INFO:     Found new best model at epoch 3
2023-01-05 04:57:40,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:40,181 INFO:     Epoch: 4
2023-01-05 04:57:42,428 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5152005096276601, 'Total loss': 0.5152005096276601} | train loss {'Reaction outcome loss': 0.47770412430328585, 'Total loss': 0.47770412430328585}
2023-01-05 04:57:42,428 INFO:     Found new best model at epoch 4
2023-01-05 04:57:42,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:42,430 INFO:     Epoch: 5
2023-01-05 04:57:44,641 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5215537339448929, 'Total loss': 0.5215537339448929} | train loss {'Reaction outcome loss': 0.46061687690579073, 'Total loss': 0.46061687690579073}
2023-01-05 04:57:44,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:44,641 INFO:     Epoch: 6
2023-01-05 04:57:46,790 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5111985276142756, 'Total loss': 0.5111985276142756} | train loss {'Reaction outcome loss': 0.438860864092727, 'Total loss': 0.438860864092727}
2023-01-05 04:57:46,791 INFO:     Found new best model at epoch 6
2023-01-05 04:57:46,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:46,793 INFO:     Epoch: 7
2023-01-05 04:57:49,002 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49486352801322936, 'Total loss': 0.49486352801322936} | train loss {'Reaction outcome loss': 0.42596295691139, 'Total loss': 0.42596295691139}
2023-01-05 04:57:49,003 INFO:     Found new best model at epoch 7
2023-01-05 04:57:49,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:49,004 INFO:     Epoch: 8
2023-01-05 04:57:51,243 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4697556525468826, 'Total loss': 0.4697556525468826} | train loss {'Reaction outcome loss': 0.4195611005655695, 'Total loss': 0.4195611005655695}
2023-01-05 04:57:51,243 INFO:     Found new best model at epoch 8
2023-01-05 04:57:51,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:51,244 INFO:     Epoch: 9
2023-01-05 04:57:53,393 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48726575871308647, 'Total loss': 0.48726575871308647} | train loss {'Reaction outcome loss': 0.4013181617382631, 'Total loss': 0.4013181617382631}
2023-01-05 04:57:53,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:53,394 INFO:     Epoch: 10
2023-01-05 04:57:55,637 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.483013923962911, 'Total loss': 0.483013923962911} | train loss {'Reaction outcome loss': 0.3931609962391079, 'Total loss': 0.3931609962391079}
2023-01-05 04:57:55,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:55,637 INFO:     Epoch: 11
2023-01-05 04:57:57,860 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5048819919427235, 'Total loss': 0.5048819919427235} | train loss {'Reaction outcome loss': 0.38142895047630215, 'Total loss': 0.38142895047630215}
2023-01-05 04:57:57,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:57:57,861 INFO:     Epoch: 12
2023-01-05 04:58:00,102 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4867415646711985, 'Total loss': 0.4867415646711985} | train loss {'Reaction outcome loss': 0.3730296341413195, 'Total loss': 0.3730296341413195}
2023-01-05 04:58:00,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:00,102 INFO:     Epoch: 13
2023-01-05 04:58:02,370 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4865899860858917, 'Total loss': 0.4865899860858917} | train loss {'Reaction outcome loss': 0.3651839829577866, 'Total loss': 0.3651839829577866}
2023-01-05 04:58:02,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:02,371 INFO:     Epoch: 14
2023-01-05 04:58:04,580 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47233996192614236, 'Total loss': 0.47233996192614236} | train loss {'Reaction outcome loss': 0.3586869912242201, 'Total loss': 0.3586869912242201}
2023-01-05 04:58:04,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:04,580 INFO:     Epoch: 15
2023-01-05 04:58:06,842 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.475084133942922, 'Total loss': 0.475084133942922} | train loss {'Reaction outcome loss': 0.349102118681269, 'Total loss': 0.349102118681269}
2023-01-05 04:58:06,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:06,843 INFO:     Epoch: 16
2023-01-05 04:58:09,106 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4602035492658615, 'Total loss': 0.4602035492658615} | train loss {'Reaction outcome loss': 0.33842919581310843, 'Total loss': 0.33842919581310843}
2023-01-05 04:58:09,106 INFO:     Found new best model at epoch 16
2023-01-05 04:58:09,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:09,108 INFO:     Epoch: 17
2023-01-05 04:58:11,336 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47010850509007773, 'Total loss': 0.47010850509007773} | train loss {'Reaction outcome loss': 0.3322564381769848, 'Total loss': 0.3322564381769848}
2023-01-05 04:58:11,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:11,336 INFO:     Epoch: 18
2023-01-05 04:58:13,551 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46865256627400714, 'Total loss': 0.46865256627400714} | train loss {'Reaction outcome loss': 0.32159017389539346, 'Total loss': 0.32159017389539346}
2023-01-05 04:58:13,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:13,551 INFO:     Epoch: 19
2023-01-05 04:58:15,806 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47588036755720775, 'Total loss': 0.47588036755720775} | train loss {'Reaction outcome loss': 0.3139169058402738, 'Total loss': 0.3139169058402738}
2023-01-05 04:58:15,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:15,806 INFO:     Epoch: 20
2023-01-05 04:58:18,042 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4480098158121109, 'Total loss': 0.4480098158121109} | train loss {'Reaction outcome loss': 0.30799325936161226, 'Total loss': 0.30799325936161226}
2023-01-05 04:58:18,042 INFO:     Found new best model at epoch 20
2023-01-05 04:58:18,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:18,044 INFO:     Epoch: 21
2023-01-05 04:58:20,274 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45701988935470583, 'Total loss': 0.45701988935470583} | train loss {'Reaction outcome loss': 0.3009756071634241, 'Total loss': 0.3009756071634241}
2023-01-05 04:58:20,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:20,275 INFO:     Epoch: 22
2023-01-05 04:58:22,516 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44395307650168736, 'Total loss': 0.44395307650168736} | train loss {'Reaction outcome loss': 0.29763721033177654, 'Total loss': 0.29763721033177654}
2023-01-05 04:58:22,517 INFO:     Found new best model at epoch 22
2023-01-05 04:58:22,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:22,519 INFO:     Epoch: 23
2023-01-05 04:58:24,749 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4477857659260432, 'Total loss': 0.4477857659260432} | train loss {'Reaction outcome loss': 0.28978433435789513, 'Total loss': 0.28978433435789513}
2023-01-05 04:58:24,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:24,750 INFO:     Epoch: 24
2023-01-05 04:58:27,003 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4451834018031756, 'Total loss': 0.4451834018031756} | train loss {'Reaction outcome loss': 0.28487047310985814, 'Total loss': 0.28487047310985814}
2023-01-05 04:58:27,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:27,003 INFO:     Epoch: 25
2023-01-05 04:58:29,259 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47061860760053, 'Total loss': 0.47061860760053} | train loss {'Reaction outcome loss': 0.2762694118497389, 'Total loss': 0.2762694118497389}
2023-01-05 04:58:29,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:29,260 INFO:     Epoch: 26
2023-01-05 04:58:31,527 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4585062742233276, 'Total loss': 0.4585062742233276} | train loss {'Reaction outcome loss': 0.27686793788837183, 'Total loss': 0.27686793788837183}
2023-01-05 04:58:31,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:31,528 INFO:     Epoch: 27
2023-01-05 04:58:33,788 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4421726773182551, 'Total loss': 0.4421726773182551} | train loss {'Reaction outcome loss': 0.26770487051147845, 'Total loss': 0.26770487051147845}
2023-01-05 04:58:33,788 INFO:     Found new best model at epoch 27
2023-01-05 04:58:33,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:33,790 INFO:     Epoch: 28
2023-01-05 04:58:36,036 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4485343555609385, 'Total loss': 0.4485343555609385} | train loss {'Reaction outcome loss': 0.26422050506522077, 'Total loss': 0.26422050506522077}
2023-01-05 04:58:36,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:36,037 INFO:     Epoch: 29
2023-01-05 04:58:38,174 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.449549725651741, 'Total loss': 0.449549725651741} | train loss {'Reaction outcome loss': 0.2606393810939918, 'Total loss': 0.2606393810939918}
2023-01-05 04:58:38,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:38,174 INFO:     Epoch: 30
2023-01-05 04:58:40,341 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4334713617960612, 'Total loss': 0.4334713617960612} | train loss {'Reaction outcome loss': 0.25664718582257895, 'Total loss': 0.25664718582257895}
2023-01-05 04:58:40,342 INFO:     Found new best model at epoch 30
2023-01-05 04:58:40,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:40,343 INFO:     Epoch: 31
2023-01-05 04:58:42,616 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44280966073274614, 'Total loss': 0.44280966073274614} | train loss {'Reaction outcome loss': 0.25102070885767575, 'Total loss': 0.25102070885767575}
2023-01-05 04:58:42,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:42,617 INFO:     Epoch: 32
2023-01-05 04:58:44,876 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43489657193422315, 'Total loss': 0.43489657193422315} | train loss {'Reaction outcome loss': 0.24951945483980412, 'Total loss': 0.24951945483980412}
2023-01-05 04:58:44,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:44,876 INFO:     Epoch: 33
2023-01-05 04:58:47,105 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4680221935113271, 'Total loss': 0.4680221935113271} | train loss {'Reaction outcome loss': 0.2385824244025597, 'Total loss': 0.2385824244025597}
2023-01-05 04:58:47,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:47,105 INFO:     Epoch: 34
2023-01-05 04:58:49,444 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4319016228119532, 'Total loss': 0.4319016228119532} | train loss {'Reaction outcome loss': 0.24116312181207247, 'Total loss': 0.24116312181207247}
2023-01-05 04:58:49,444 INFO:     Found new best model at epoch 34
2023-01-05 04:58:49,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:49,446 INFO:     Epoch: 35
2023-01-05 04:58:51,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4296351994077365, 'Total loss': 0.4296351994077365} | train loss {'Reaction outcome loss': 0.23735375721209315, 'Total loss': 0.23735375721209315}
2023-01-05 04:58:51,684 INFO:     Found new best model at epoch 35
2023-01-05 04:58:51,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:51,685 INFO:     Epoch: 36
2023-01-05 04:58:53,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42853745371103286, 'Total loss': 0.42853745371103286} | train loss {'Reaction outcome loss': 0.23926956488982865, 'Total loss': 0.23926956488982865}
2023-01-05 04:58:53,953 INFO:     Found new best model at epoch 36
2023-01-05 04:58:53,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:53,954 INFO:     Epoch: 37
2023-01-05 04:58:56,204 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4337608794371287, 'Total loss': 0.4337608794371287} | train loss {'Reaction outcome loss': 0.23145768972994618, 'Total loss': 0.23145768972994618}
2023-01-05 04:58:56,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:56,204 INFO:     Epoch: 38
2023-01-05 04:58:58,440 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4410469591617584, 'Total loss': 0.4410469591617584} | train loss {'Reaction outcome loss': 0.23039923851724567, 'Total loss': 0.23039923851724567}
2023-01-05 04:58:58,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:58:58,442 INFO:     Epoch: 39
2023-01-05 04:59:00,644 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.429614862985909, 'Total loss': 0.429614862985909} | train loss {'Reaction outcome loss': 0.2238889415933337, 'Total loss': 0.2238889415933337}
2023-01-05 04:59:00,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:00,644 INFO:     Epoch: 40
2023-01-05 04:59:02,849 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47270021537939705, 'Total loss': 0.47270021537939705} | train loss {'Reaction outcome loss': 0.22472871174289433, 'Total loss': 0.22472871174289433}
2023-01-05 04:59:02,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:02,849 INFO:     Epoch: 41
2023-01-05 04:59:05,112 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45841142038504284, 'Total loss': 0.45841142038504284} | train loss {'Reaction outcome loss': 0.21850303530235798, 'Total loss': 0.21850303530235798}
2023-01-05 04:59:05,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:05,113 INFO:     Epoch: 42
2023-01-05 04:59:07,304 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4419639299313227, 'Total loss': 0.4419639299313227} | train loss {'Reaction outcome loss': 0.22348595200449445, 'Total loss': 0.22348595200449445}
2023-01-05 04:59:07,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:07,305 INFO:     Epoch: 43
2023-01-05 04:59:09,559 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47875841955343884, 'Total loss': 0.47875841955343884} | train loss {'Reaction outcome loss': 0.22087694955350906, 'Total loss': 0.22087694955350906}
2023-01-05 04:59:09,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:09,559 INFO:     Epoch: 44
2023-01-05 04:59:11,798 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4377631808320681, 'Total loss': 0.4377631808320681} | train loss {'Reaction outcome loss': 0.213512409555756, 'Total loss': 0.213512409555756}
2023-01-05 04:59:11,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:11,799 INFO:     Epoch: 45
2023-01-05 04:59:14,021 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4663273811340332, 'Total loss': 0.4663273811340332} | train loss {'Reaction outcome loss': 0.20870403811631436, 'Total loss': 0.20870403811631436}
2023-01-05 04:59:14,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:14,022 INFO:     Epoch: 46
2023-01-05 04:59:16,266 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45311873555183413, 'Total loss': 0.45311873555183413} | train loss {'Reaction outcome loss': 0.21305144187533684, 'Total loss': 0.21305144187533684}
2023-01-05 04:59:16,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:16,267 INFO:     Epoch: 47
2023-01-05 04:59:18,498 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4397900919119517, 'Total loss': 0.4397900919119517} | train loss {'Reaction outcome loss': 0.21015110642175167, 'Total loss': 0.21015110642175167}
2023-01-05 04:59:18,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:18,499 INFO:     Epoch: 48
2023-01-05 04:59:20,759 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47721645832061765, 'Total loss': 0.47721645832061765} | train loss {'Reaction outcome loss': 0.20746969574867388, 'Total loss': 0.20746969574867388}
2023-01-05 04:59:20,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:20,759 INFO:     Epoch: 49
2023-01-05 04:59:23,094 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4655535936355591, 'Total loss': 0.4655535936355591} | train loss {'Reaction outcome loss': 0.2076791738553329, 'Total loss': 0.2076791738553329}
2023-01-05 04:59:23,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:23,094 INFO:     Epoch: 50
2023-01-05 04:59:25,377 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47195938527584075, 'Total loss': 0.47195938527584075} | train loss {'Reaction outcome loss': 0.20567641932591257, 'Total loss': 0.20567641932591257}
2023-01-05 04:59:25,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:25,377 INFO:     Epoch: 51
2023-01-05 04:59:27,597 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46795634031295774, 'Total loss': 0.46795634031295774} | train loss {'Reaction outcome loss': 0.20797455359909295, 'Total loss': 0.20797455359909295}
2023-01-05 04:59:27,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:27,597 INFO:     Epoch: 52
2023-01-05 04:59:29,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.467890461285909, 'Total loss': 0.467890461285909} | train loss {'Reaction outcome loss': 0.2011954137712502, 'Total loss': 0.2011954137712502}
2023-01-05 04:59:29,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:29,741 INFO:     Epoch: 53
2023-01-05 04:59:32,001 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44140223066012063, 'Total loss': 0.44140223066012063} | train loss {'Reaction outcome loss': 0.20264595886860515, 'Total loss': 0.20264595886860515}
2023-01-05 04:59:32,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:32,001 INFO:     Epoch: 54
2023-01-05 04:59:34,246 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4906227687994639, 'Total loss': 0.4906227687994639} | train loss {'Reaction outcome loss': 0.19440006285515826, 'Total loss': 0.19440006285515826}
2023-01-05 04:59:34,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:34,248 INFO:     Epoch: 55
2023-01-05 04:59:36,442 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.447231720884641, 'Total loss': 0.447231720884641} | train loss {'Reaction outcome loss': 0.20195721844143977, 'Total loss': 0.20195721844143977}
2023-01-05 04:59:36,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:36,443 INFO:     Epoch: 56
2023-01-05 04:59:38,595 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47174257735411323, 'Total loss': 0.47174257735411323} | train loss {'Reaction outcome loss': 0.19972634581102577, 'Total loss': 0.19972634581102577}
2023-01-05 04:59:38,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:38,595 INFO:     Epoch: 57
2023-01-05 04:59:40,845 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4586389849583308, 'Total loss': 0.4586389849583308} | train loss {'Reaction outcome loss': 0.20177828718568552, 'Total loss': 0.20177828718568552}
2023-01-05 04:59:40,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:40,846 INFO:     Epoch: 58
2023-01-05 04:59:43,098 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4524565408627192, 'Total loss': 0.4524565408627192} | train loss {'Reaction outcome loss': 0.19451418937442805, 'Total loss': 0.19451418937442805}
2023-01-05 04:59:43,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:43,098 INFO:     Epoch: 59
2023-01-05 04:59:45,150 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45805082023143767, 'Total loss': 0.45805082023143767} | train loss {'Reaction outcome loss': 0.18930830231225554, 'Total loss': 0.18930830231225554}
2023-01-05 04:59:45,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:45,150 INFO:     Epoch: 60
2023-01-05 04:59:47,398 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4561644266049067, 'Total loss': 0.4561644266049067} | train loss {'Reaction outcome loss': 0.18711746587259998, 'Total loss': 0.18711746587259998}
2023-01-05 04:59:47,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:47,398 INFO:     Epoch: 61
2023-01-05 04:59:49,617 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45766508380572, 'Total loss': 0.45766508380572} | train loss {'Reaction outcome loss': 0.1845741764716266, 'Total loss': 0.1845741764716266}
2023-01-05 04:59:49,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:49,618 INFO:     Epoch: 62
2023-01-05 04:59:51,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4903910557428996, 'Total loss': 0.4903910557428996} | train loss {'Reaction outcome loss': 0.18970371851031853, 'Total loss': 0.18970371851031853}
2023-01-05 04:59:51,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:51,879 INFO:     Epoch: 63
2023-01-05 04:59:54,137 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46080199877421063, 'Total loss': 0.46080199877421063} | train loss {'Reaction outcome loss': 0.18369910540563536, 'Total loss': 0.18369910540563536}
2023-01-05 04:59:54,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:54,138 INFO:     Epoch: 64
2023-01-05 04:59:56,342 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4619771271944046, 'Total loss': 0.4619771271944046} | train loss {'Reaction outcome loss': 0.1853538986147526, 'Total loss': 0.1853538986147526}
2023-01-05 04:59:56,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:56,343 INFO:     Epoch: 65
2023-01-05 04:59:58,532 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4737966815630595, 'Total loss': 0.4737966815630595} | train loss {'Reaction outcome loss': 0.18206019596186623, 'Total loss': 0.18206019596186623}
2023-01-05 04:59:58,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 04:59:58,533 INFO:     Epoch: 66
2023-01-05 05:00:00,734 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4760616049170494, 'Total loss': 0.4760616049170494} | train loss {'Reaction outcome loss': 0.18139183160509337, 'Total loss': 0.18139183160509337}
2023-01-05 05:00:00,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:00,734 INFO:     Epoch: 67
2023-01-05 05:00:02,929 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4730079094568888, 'Total loss': 0.4730079094568888} | train loss {'Reaction outcome loss': 0.17751808106791672, 'Total loss': 0.17751808106791672}
2023-01-05 05:00:02,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:02,929 INFO:     Epoch: 68
2023-01-05 05:00:05,180 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4581082614759604, 'Total loss': 0.4581082614759604} | train loss {'Reaction outcome loss': 0.18308877654790556, 'Total loss': 0.18308877654790556}
2023-01-05 05:00:05,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:05,180 INFO:     Epoch: 69
2023-01-05 05:00:07,426 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5091877271731694, 'Total loss': 0.5091877271731694} | train loss {'Reaction outcome loss': 0.1756734710744841, 'Total loss': 0.1756734710744841}
2023-01-05 05:00:07,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:07,427 INFO:     Epoch: 70
2023-01-05 05:00:09,624 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44434846291939417, 'Total loss': 0.44434846291939417} | train loss {'Reaction outcome loss': 0.1759407312528563, 'Total loss': 0.1759407312528563}
2023-01-05 05:00:09,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:09,625 INFO:     Epoch: 71
2023-01-05 05:00:11,810 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4805999586979548, 'Total loss': 0.4805999586979548} | train loss {'Reaction outcome loss': 0.17719918748848007, 'Total loss': 0.17719918748848007}
2023-01-05 05:00:11,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:11,811 INFO:     Epoch: 72
2023-01-05 05:00:14,076 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4751858820517858, 'Total loss': 0.4751858820517858} | train loss {'Reaction outcome loss': 0.17443508042580708, 'Total loss': 0.17443508042580708}
2023-01-05 05:00:14,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:14,076 INFO:     Epoch: 73
2023-01-05 05:00:16,244 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4683362305164337, 'Total loss': 0.4683362305164337} | train loss {'Reaction outcome loss': 0.17592966702299373, 'Total loss': 0.17592966702299373}
2023-01-05 05:00:16,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:16,245 INFO:     Epoch: 74
2023-01-05 05:00:18,482 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46873976786931354, 'Total loss': 0.46873976786931354} | train loss {'Reaction outcome loss': 0.1763375377793551, 'Total loss': 0.1763375377793551}
2023-01-05 05:00:18,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:18,483 INFO:     Epoch: 75
2023-01-05 05:00:20,687 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4395228736102581, 'Total loss': 0.4395228736102581} | train loss {'Reaction outcome loss': 0.16953394765753824, 'Total loss': 0.16953394765753824}
2023-01-05 05:00:20,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:20,688 INFO:     Epoch: 76
2023-01-05 05:00:22,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44431332548459374, 'Total loss': 0.44431332548459374} | train loss {'Reaction outcome loss': 0.17214474470660573, 'Total loss': 0.17214474470660573}
2023-01-05 05:00:22,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:22,937 INFO:     Epoch: 77
2023-01-05 05:00:25,138 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4562375495831172, 'Total loss': 0.4562375495831172} | train loss {'Reaction outcome loss': 0.17169398758459553, 'Total loss': 0.17169398758459553}
2023-01-05 05:00:25,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:25,139 INFO:     Epoch: 78
2023-01-05 05:00:27,404 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4454617271820704, 'Total loss': 0.4454617271820704} | train loss {'Reaction outcome loss': 0.17243711754094662, 'Total loss': 0.17243711754094662}
2023-01-05 05:00:27,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:27,404 INFO:     Epoch: 79
2023-01-05 05:00:29,641 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4649495412906011, 'Total loss': 0.4649495412906011} | train loss {'Reaction outcome loss': 0.17282850559236018, 'Total loss': 0.17282850559236018}
2023-01-05 05:00:29,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:29,642 INFO:     Epoch: 80
2023-01-05 05:00:31,891 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4623222490151723, 'Total loss': 0.4623222490151723} | train loss {'Reaction outcome loss': 0.16595782549540758, 'Total loss': 0.16595782549540758}
2023-01-05 05:00:31,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:31,892 INFO:     Epoch: 81
2023-01-05 05:00:34,142 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4310608054200808, 'Total loss': 0.4310608054200808} | train loss {'Reaction outcome loss': 0.16917928850231187, 'Total loss': 0.16917928850231187}
2023-01-05 05:00:34,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:34,142 INFO:     Epoch: 82
2023-01-05 05:00:36,299 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43992959161599476, 'Total loss': 0.43992959161599476} | train loss {'Reaction outcome loss': 0.16385248527670487, 'Total loss': 0.16385248527670487}
2023-01-05 05:00:36,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:36,299 INFO:     Epoch: 83
2023-01-05 05:00:38,581 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45361769463246066, 'Total loss': 0.45361769463246066} | train loss {'Reaction outcome loss': 0.16324096848509048, 'Total loss': 0.16324096848509048}
2023-01-05 05:00:38,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:38,581 INFO:     Epoch: 84
2023-01-05 05:00:40,830 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4517836411794027, 'Total loss': 0.4517836411794027} | train loss {'Reaction outcome loss': 0.16188382263218024, 'Total loss': 0.16188382263218024}
2023-01-05 05:00:40,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:40,830 INFO:     Epoch: 85
2023-01-05 05:00:43,098 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4491435050964355, 'Total loss': 0.4491435050964355} | train loss {'Reaction outcome loss': 0.1615584261079961, 'Total loss': 0.1615584261079961}
2023-01-05 05:00:43,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:43,099 INFO:     Epoch: 86
2023-01-05 05:00:45,350 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47894959449768065, 'Total loss': 0.47894959449768065} | train loss {'Reaction outcome loss': 0.16406019180861808, 'Total loss': 0.16406019180861808}
2023-01-05 05:00:45,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:45,352 INFO:     Epoch: 87
2023-01-05 05:00:47,599 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5076543182134629, 'Total loss': 0.5076543182134629} | train loss {'Reaction outcome loss': 0.16250680881259888, 'Total loss': 0.16250680881259888}
2023-01-05 05:00:47,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:47,600 INFO:     Epoch: 88
2023-01-05 05:00:49,854 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46232661108175915, 'Total loss': 0.46232661108175915} | train loss {'Reaction outcome loss': 0.1594022540308347, 'Total loss': 0.1594022540308347}
2023-01-05 05:00:49,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:49,854 INFO:     Epoch: 89
2023-01-05 05:00:52,082 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46840686202049253, 'Total loss': 0.46840686202049253} | train loss {'Reaction outcome loss': 0.1591971946143905, 'Total loss': 0.1591971946143905}
2023-01-05 05:00:52,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:52,083 INFO:     Epoch: 90
2023-01-05 05:00:54,327 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.482441371679306, 'Total loss': 0.482441371679306} | train loss {'Reaction outcome loss': 0.15500087348243308, 'Total loss': 0.15500087348243308}
2023-01-05 05:00:54,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:54,327 INFO:     Epoch: 91
2023-01-05 05:00:56,580 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5006612837314606, 'Total loss': 0.5006612837314606} | train loss {'Reaction outcome loss': 0.15854407109602586, 'Total loss': 0.15854407109602586}
2023-01-05 05:00:56,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:56,581 INFO:     Epoch: 92
2023-01-05 05:00:58,775 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4807890295982361, 'Total loss': 0.4807890295982361} | train loss {'Reaction outcome loss': 0.15813588090442685, 'Total loss': 0.15813588090442685}
2023-01-05 05:00:58,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:00:58,776 INFO:     Epoch: 93
2023-01-05 05:01:01,031 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4858894467353821, 'Total loss': 0.4858894467353821} | train loss {'Reaction outcome loss': 0.15755662858983777, 'Total loss': 0.15755662858983777}
2023-01-05 05:01:01,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:01,031 INFO:     Epoch: 94
2023-01-05 05:01:03,219 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4829959323008855, 'Total loss': 0.4829959323008855} | train loss {'Reaction outcome loss': 0.15873799632498423, 'Total loss': 0.15873799632498423}
2023-01-05 05:01:03,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:03,220 INFO:     Epoch: 95
2023-01-05 05:01:05,477 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4673924267292023, 'Total loss': 0.4673924267292023} | train loss {'Reaction outcome loss': 0.16720175601135173, 'Total loss': 0.16720175601135173}
2023-01-05 05:01:05,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:05,478 INFO:     Epoch: 96
2023-01-05 05:01:07,681 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4719595576326052, 'Total loss': 0.4719595576326052} | train loss {'Reaction outcome loss': 0.1556683601576176, 'Total loss': 0.1556683601576176}
2023-01-05 05:01:07,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:07,681 INFO:     Epoch: 97
2023-01-05 05:01:09,931 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46881504555543263, 'Total loss': 0.46881504555543263} | train loss {'Reaction outcome loss': 0.15748066428900842, 'Total loss': 0.15748066428900842}
2023-01-05 05:01:09,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:09,931 INFO:     Epoch: 98
2023-01-05 05:01:12,153 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4786335289478302, 'Total loss': 0.4786335289478302} | train loss {'Reaction outcome loss': 0.1546094176386372, 'Total loss': 0.1546094176386372}
2023-01-05 05:01:12,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:12,153 INFO:     Epoch: 99
2023-01-05 05:01:14,367 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.472797221938769, 'Total loss': 0.472797221938769} | train loss {'Reaction outcome loss': 0.15583240535338863, 'Total loss': 0.15583240535338863}
2023-01-05 05:01:14,367 INFO:     Best model found after epoch 37 of 100.
2023-01-05 05:01:14,367 INFO:   Done with stage: TRAINING
2023-01-05 05:01:14,367 INFO:   Starting stage: EVALUATION
2023-01-05 05:01:14,495 INFO:   Done with stage: EVALUATION
2023-01-05 05:01:14,495 INFO:   Leaving out SEQ value Fold_7
2023-01-05 05:01:14,508 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 05:01:14,508 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:01:15,152 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:01:15,152 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:01:15,225 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:01:15,226 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:01:15,226 INFO:     No hyperparam tuning for this model
2023-01-05 05:01:15,226 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:01:15,226 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:01:15,226 INFO:     None feature selector for col prot
2023-01-05 05:01:15,227 INFO:     None feature selector for col prot
2023-01-05 05:01:15,227 INFO:     None feature selector for col prot
2023-01-05 05:01:15,227 INFO:     None feature selector for col chem
2023-01-05 05:01:15,227 INFO:     None feature selector for col chem
2023-01-05 05:01:15,227 INFO:     None feature selector for col chem
2023-01-05 05:01:15,227 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:01:15,227 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:01:15,229 INFO:     Number of params in model 72931
2023-01-05 05:01:15,232 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:01:15,232 INFO:   Starting stage: TRAINING
2023-01-05 05:01:15,292 INFO:     Val loss before train {'Reaction outcome loss': 1.0044055461883545, 'Total loss': 1.0044055461883545}
2023-01-05 05:01:15,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:15,292 INFO:     Epoch: 0
2023-01-05 05:01:17,545 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8297865927219391, 'Total loss': 0.8297865927219391} | train loss {'Reaction outcome loss': 0.9393683027489521, 'Total loss': 0.9393683027489521}
2023-01-05 05:01:17,546 INFO:     Found new best model at epoch 0
2023-01-05 05:01:17,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:17,547 INFO:     Epoch: 1
2023-01-05 05:01:19,750 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6490975519021353, 'Total loss': 0.6490975519021353} | train loss {'Reaction outcome loss': 0.6467704736368751, 'Total loss': 0.6467704736368751}
2023-01-05 05:01:19,750 INFO:     Found new best model at epoch 1
2023-01-05 05:01:19,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:19,751 INFO:     Epoch: 2
2023-01-05 05:01:21,946 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6061489621798197, 'Total loss': 0.6061489621798197} | train loss {'Reaction outcome loss': 0.5430291241794717, 'Total loss': 0.5430291241794717}
2023-01-05 05:01:21,947 INFO:     Found new best model at epoch 2
2023-01-05 05:01:21,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:21,949 INFO:     Epoch: 3
2023-01-05 05:01:24,215 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5705094794432323, 'Total loss': 0.5705094794432323} | train loss {'Reaction outcome loss': 0.5014022955610433, 'Total loss': 0.5014022955610433}
2023-01-05 05:01:24,215 INFO:     Found new best model at epoch 3
2023-01-05 05:01:24,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:24,217 INFO:     Epoch: 4
2023-01-05 05:01:26,474 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5484977344671885, 'Total loss': 0.5484977344671885} | train loss {'Reaction outcome loss': 0.4771191902754539, 'Total loss': 0.4771191902754539}
2023-01-05 05:01:26,474 INFO:     Found new best model at epoch 4
2023-01-05 05:01:26,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:26,475 INFO:     Epoch: 5
2023-01-05 05:01:28,615 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5450890183448791, 'Total loss': 0.5450890183448791} | train loss {'Reaction outcome loss': 0.4469944476435761, 'Total loss': 0.4469944476435761}
2023-01-05 05:01:28,615 INFO:     Found new best model at epoch 5
2023-01-05 05:01:28,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:28,617 INFO:     Epoch: 6
2023-01-05 05:01:30,771 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.558030316233635, 'Total loss': 0.558030316233635} | train loss {'Reaction outcome loss': 0.4297150101257145, 'Total loss': 0.4297150101257145}
2023-01-05 05:01:30,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:30,771 INFO:     Epoch: 7
2023-01-05 05:01:32,922 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5322180916865666, 'Total loss': 0.5322180916865666} | train loss {'Reaction outcome loss': 0.4179132368536632, 'Total loss': 0.4179132368536632}
2023-01-05 05:01:32,922 INFO:     Found new best model at epoch 7
2023-01-05 05:01:32,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:32,924 INFO:     Epoch: 8
2023-01-05 05:01:35,233 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5501238147417704, 'Total loss': 0.5501238147417704} | train loss {'Reaction outcome loss': 0.4072177282094095, 'Total loss': 0.4072177282094095}
2023-01-05 05:01:35,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:35,234 INFO:     Epoch: 9
2023-01-05 05:01:37,572 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5288406739632289, 'Total loss': 0.5288406739632289} | train loss {'Reaction outcome loss': 0.39501778326847925, 'Total loss': 0.39501778326847925}
2023-01-05 05:01:37,572 INFO:     Found new best model at epoch 9
2023-01-05 05:01:37,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:37,574 INFO:     Epoch: 10
2023-01-05 05:01:39,901 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5372236788272857, 'Total loss': 0.5372236788272857} | train loss {'Reaction outcome loss': 0.3832680713452587, 'Total loss': 0.3832680713452587}
2023-01-05 05:01:39,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:39,902 INFO:     Epoch: 11
2023-01-05 05:01:42,247 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5406095564365387, 'Total loss': 0.5406095564365387} | train loss {'Reaction outcome loss': 0.37270289832315934, 'Total loss': 0.37270289832315934}
2023-01-05 05:01:42,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:42,248 INFO:     Epoch: 12
2023-01-05 05:01:44,568 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.539856834212939, 'Total loss': 0.539856834212939} | train loss {'Reaction outcome loss': 0.36520089547987017, 'Total loss': 0.36520089547987017}
2023-01-05 05:01:44,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:44,568 INFO:     Epoch: 13
2023-01-05 05:01:46,903 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5373705605665843, 'Total loss': 0.5373705605665843} | train loss {'Reaction outcome loss': 0.35732175121991644, 'Total loss': 0.35732175121991644}
2023-01-05 05:01:46,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:46,903 INFO:     Epoch: 14
2023-01-05 05:01:49,253 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5515122711658478, 'Total loss': 0.5515122711658478} | train loss {'Reaction outcome loss': 0.3486785536315897, 'Total loss': 0.3486785536315897}
2023-01-05 05:01:49,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:49,253 INFO:     Epoch: 15
2023-01-05 05:01:51,602 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5629534780979156, 'Total loss': 0.5629534780979156} | train loss {'Reaction outcome loss': 0.34240936436808067, 'Total loss': 0.34240936436808067}
2023-01-05 05:01:51,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:51,604 INFO:     Epoch: 16
2023-01-05 05:01:53,943 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5404400090376537, 'Total loss': 0.5404400090376537} | train loss {'Reaction outcome loss': 0.33523608811387945, 'Total loss': 0.33523608811387945}
2023-01-05 05:01:53,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:53,943 INFO:     Epoch: 17
2023-01-05 05:01:56,168 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.530109840631485, 'Total loss': 0.530109840631485} | train loss {'Reaction outcome loss': 0.3262669539569948, 'Total loss': 0.3262669539569948}
2023-01-05 05:01:56,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:56,168 INFO:     Epoch: 18
2023-01-05 05:01:58,411 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.541333457827568, 'Total loss': 0.541333457827568} | train loss {'Reaction outcome loss': 0.32168716588982177, 'Total loss': 0.32168716588982177}
2023-01-05 05:01:58,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:01:58,411 INFO:     Epoch: 19
2023-01-05 05:02:00,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.539321118593216, 'Total loss': 0.539321118593216} | train loss {'Reaction outcome loss': 0.31849576777607097, 'Total loss': 0.31849576777607097}
2023-01-05 05:02:00,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:00,673 INFO:     Epoch: 20
2023-01-05 05:02:02,925 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5233115682999293, 'Total loss': 0.5233115682999293} | train loss {'Reaction outcome loss': 0.3077908184258301, 'Total loss': 0.3077908184258301}
2023-01-05 05:02:02,925 INFO:     Found new best model at epoch 20
2023-01-05 05:02:02,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:02,926 INFO:     Epoch: 21
2023-01-05 05:02:05,125 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5342410514752071, 'Total loss': 0.5342410514752071} | train loss {'Reaction outcome loss': 0.3033955491581656, 'Total loss': 0.3033955491581656}
2023-01-05 05:02:05,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:05,125 INFO:     Epoch: 22
2023-01-05 05:02:07,347 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5447271347045899, 'Total loss': 0.5447271347045899} | train loss {'Reaction outcome loss': 0.30074800216737424, 'Total loss': 0.30074800216737424}
2023-01-05 05:02:07,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:07,348 INFO:     Epoch: 23
2023-01-05 05:02:09,598 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5174232145150502, 'Total loss': 0.5174232145150502} | train loss {'Reaction outcome loss': 0.29546011201633876, 'Total loss': 0.29546011201633876}
2023-01-05 05:02:09,599 INFO:     Found new best model at epoch 23
2023-01-05 05:02:09,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:09,600 INFO:     Epoch: 24
2023-01-05 05:02:11,861 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5436850428581238, 'Total loss': 0.5436850428581238} | train loss {'Reaction outcome loss': 0.29188295393267694, 'Total loss': 0.29188295393267694}
2023-01-05 05:02:11,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:11,862 INFO:     Epoch: 25
2023-01-05 05:02:14,116 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5827689687410991, 'Total loss': 0.5827689687410991} | train loss {'Reaction outcome loss': 0.28672623611475584, 'Total loss': 0.28672623611475584}
2023-01-05 05:02:14,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:14,116 INFO:     Epoch: 26
2023-01-05 05:02:16,352 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5216379423936208, 'Total loss': 0.5216379423936208} | train loss {'Reaction outcome loss': 0.2825213737974098, 'Total loss': 0.2825213737974098}
2023-01-05 05:02:16,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:16,352 INFO:     Epoch: 27
2023-01-05 05:02:18,575 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5223281547427178, 'Total loss': 0.5223281547427178} | train loss {'Reaction outcome loss': 0.27987425799888394, 'Total loss': 0.27987425799888394}
2023-01-05 05:02:18,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:18,575 INFO:     Epoch: 28
2023-01-05 05:02:20,752 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5369228780269623, 'Total loss': 0.5369228780269623} | train loss {'Reaction outcome loss': 0.2777020276224893, 'Total loss': 0.2777020276224893}
2023-01-05 05:02:20,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:20,752 INFO:     Epoch: 29
2023-01-05 05:02:22,925 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5198839545249939, 'Total loss': 0.5198839545249939} | train loss {'Reaction outcome loss': 0.26753415433615985, 'Total loss': 0.26753415433615985}
2023-01-05 05:02:22,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:22,925 INFO:     Epoch: 30
2023-01-05 05:02:25,183 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.538116721312205, 'Total loss': 0.538116721312205} | train loss {'Reaction outcome loss': 0.26603753571583477, 'Total loss': 0.26603753571583477}
2023-01-05 05:02:25,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:25,183 INFO:     Epoch: 31
2023-01-05 05:02:27,371 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5298655331134796, 'Total loss': 0.5298655331134796} | train loss {'Reaction outcome loss': 0.26318517226443394, 'Total loss': 0.26318517226443394}
2023-01-05 05:02:27,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:27,372 INFO:     Epoch: 32
2023-01-05 05:02:29,576 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5282792051633199, 'Total loss': 0.5282792051633199} | train loss {'Reaction outcome loss': 0.261345203461576, 'Total loss': 0.261345203461576}
2023-01-05 05:02:29,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:29,576 INFO:     Epoch: 33
2023-01-05 05:02:31,804 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5550739109516144, 'Total loss': 0.5550739109516144} | train loss {'Reaction outcome loss': 0.25627521550558535, 'Total loss': 0.25627521550558535}
2023-01-05 05:02:31,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:31,805 INFO:     Epoch: 34
2023-01-05 05:02:34,035 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5383268594741821, 'Total loss': 0.5383268594741821} | train loss {'Reaction outcome loss': 0.2604803166785933, 'Total loss': 0.2604803166785933}
2023-01-05 05:02:34,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:34,036 INFO:     Epoch: 35
2023-01-05 05:02:36,269 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5471888780593872, 'Total loss': 0.5471888780593872} | train loss {'Reaction outcome loss': 0.25348084892015166, 'Total loss': 0.25348084892015166}
2023-01-05 05:02:36,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:36,269 INFO:     Epoch: 36
2023-01-05 05:02:38,468 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5443716635306676, 'Total loss': 0.5443716635306676} | train loss {'Reaction outcome loss': 0.24832734915458124, 'Total loss': 0.24832734915458124}
2023-01-05 05:02:38,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:38,468 INFO:     Epoch: 37
2023-01-05 05:02:40,665 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5494960804780324, 'Total loss': 0.5494960804780324} | train loss {'Reaction outcome loss': 0.2452095236884773, 'Total loss': 0.2452095236884773}
2023-01-05 05:02:40,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:40,665 INFO:     Epoch: 38
2023-01-05 05:02:42,817 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5660377303759258, 'Total loss': 0.5660377303759258} | train loss {'Reaction outcome loss': 0.24277080054855518, 'Total loss': 0.24277080054855518}
2023-01-05 05:02:42,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:42,817 INFO:     Epoch: 39
2023-01-05 05:02:45,080 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5483611841996511, 'Total loss': 0.5483611841996511} | train loss {'Reaction outcome loss': 0.24227369516173425, 'Total loss': 0.24227369516173425}
2023-01-05 05:02:45,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:45,080 INFO:     Epoch: 40
2023-01-05 05:02:47,376 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5824360867341359, 'Total loss': 0.5824360867341359} | train loss {'Reaction outcome loss': 0.24060071409690037, 'Total loss': 0.24060071409690037}
2023-01-05 05:02:47,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:47,377 INFO:     Epoch: 41
2023-01-05 05:02:49,683 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5635628382364909, 'Total loss': 0.5635628382364909} | train loss {'Reaction outcome loss': 0.2370197853537458, 'Total loss': 0.2370197853537458}
2023-01-05 05:02:49,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:49,683 INFO:     Epoch: 42
2023-01-05 05:02:51,988 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5828490128119787, 'Total loss': 0.5828490128119787} | train loss {'Reaction outcome loss': 0.23846263597157888, 'Total loss': 0.23846263597157888}
2023-01-05 05:02:51,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:51,989 INFO:     Epoch: 43
2023-01-05 05:02:54,228 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5853945781787236, 'Total loss': 0.5853945781787236} | train loss {'Reaction outcome loss': 0.23106910570756622, 'Total loss': 0.23106910570756622}
2023-01-05 05:02:54,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:54,228 INFO:     Epoch: 44
2023-01-05 05:02:56,492 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.557423307498296, 'Total loss': 0.557423307498296} | train loss {'Reaction outcome loss': 0.23000171352245102, 'Total loss': 0.23000171352245102}
2023-01-05 05:02:56,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:56,492 INFO:     Epoch: 45
2023-01-05 05:02:58,769 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5872909704844157, 'Total loss': 0.5872909704844157} | train loss {'Reaction outcome loss': 0.231498281696697, 'Total loss': 0.231498281696697}
2023-01-05 05:02:58,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:02:58,769 INFO:     Epoch: 46
2023-01-05 05:03:01,040 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5599608411391576, 'Total loss': 0.5599608411391576} | train loss {'Reaction outcome loss': 0.22944736243679528, 'Total loss': 0.22944736243679528}
2023-01-05 05:03:01,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:01,040 INFO:     Epoch: 47
2023-01-05 05:03:03,321 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5681067834297816, 'Total loss': 0.5681067834297816} | train loss {'Reaction outcome loss': 0.22316209219786126, 'Total loss': 0.22316209219786126}
2023-01-05 05:03:03,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:03,322 INFO:     Epoch: 48
2023-01-05 05:03:05,558 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.571537055571874, 'Total loss': 0.571537055571874} | train loss {'Reaction outcome loss': 0.22274432351496676, 'Total loss': 0.22274432351496676}
2023-01-05 05:03:05,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:05,558 INFO:     Epoch: 49
2023-01-05 05:03:07,833 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5622377812862396, 'Total loss': 0.5622377812862396} | train loss {'Reaction outcome loss': 0.22050750280464815, 'Total loss': 0.22050750280464815}
2023-01-05 05:03:07,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:07,834 INFO:     Epoch: 50
2023-01-05 05:03:10,106 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5845407684644063, 'Total loss': 0.5845407684644063} | train loss {'Reaction outcome loss': 0.22431357849779326, 'Total loss': 0.22431357849779326}
2023-01-05 05:03:10,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:10,107 INFO:     Epoch: 51
2023-01-05 05:03:12,380 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5851707994937897, 'Total loss': 0.5851707994937897} | train loss {'Reaction outcome loss': 0.21605489605076153, 'Total loss': 0.21605489605076153}
2023-01-05 05:03:12,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:12,380 INFO:     Epoch: 52
2023-01-05 05:03:14,648 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5831354280312856, 'Total loss': 0.5831354280312856} | train loss {'Reaction outcome loss': 0.2161706054048606, 'Total loss': 0.2161706054048606}
2023-01-05 05:03:14,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:14,649 INFO:     Epoch: 53
2023-01-05 05:03:16,824 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.6036045551300049, 'Total loss': 0.6036045551300049} | train loss {'Reaction outcome loss': 0.2129935109550772, 'Total loss': 0.2129935109550772}
2023-01-05 05:03:16,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:16,825 INFO:     Epoch: 54
2023-01-05 05:03:19,067 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.6029674251874287, 'Total loss': 0.6029674251874287} | train loss {'Reaction outcome loss': 0.21673301906267767, 'Total loss': 0.21673301906267767}
2023-01-05 05:03:19,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:19,067 INFO:     Epoch: 55
2023-01-05 05:03:21,299 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5929651374618212, 'Total loss': 0.5929651374618212} | train loss {'Reaction outcome loss': 0.21457216426703257, 'Total loss': 0.21457216426703257}
2023-01-05 05:03:21,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:21,299 INFO:     Epoch: 56
2023-01-05 05:03:23,553 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5790438771247863, 'Total loss': 0.5790438771247863} | train loss {'Reaction outcome loss': 0.2134748421078178, 'Total loss': 0.2134748421078178}
2023-01-05 05:03:23,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:23,554 INFO:     Epoch: 57
2023-01-05 05:03:25,796 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5692041516304016, 'Total loss': 0.5692041516304016} | train loss {'Reaction outcome loss': 0.20852219439464678, 'Total loss': 0.20852219439464678}
2023-01-05 05:03:25,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:25,796 INFO:     Epoch: 58
2023-01-05 05:03:28,041 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5808177550633749, 'Total loss': 0.5808177550633749} | train loss {'Reaction outcome loss': 0.20931992378415346, 'Total loss': 0.20931992378415346}
2023-01-05 05:03:28,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:28,041 INFO:     Epoch: 59
2023-01-05 05:03:30,292 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5784744374454022, 'Total loss': 0.5784744374454022} | train loss {'Reaction outcome loss': 0.20640605481657526, 'Total loss': 0.20640605481657526}
2023-01-05 05:03:30,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:30,292 INFO:     Epoch: 60
2023-01-05 05:03:32,564 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.6084520677725475, 'Total loss': 0.6084520677725475} | train loss {'Reaction outcome loss': 0.20688533940140683, 'Total loss': 0.20688533940140683}
2023-01-05 05:03:32,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:32,564 INFO:     Epoch: 61
2023-01-05 05:03:34,825 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5961763461430868, 'Total loss': 0.5961763461430868} | train loss {'Reaction outcome loss': 0.20338757372114954, 'Total loss': 0.20338757372114954}
2023-01-05 05:03:34,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:34,825 INFO:     Epoch: 62
2023-01-05 05:03:37,099 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5837150812149048, 'Total loss': 0.5837150812149048} | train loss {'Reaction outcome loss': 0.20074644427248933, 'Total loss': 0.20074644427248933}
2023-01-05 05:03:37,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:37,099 INFO:     Epoch: 63
2023-01-05 05:03:39,323 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5890867859125137, 'Total loss': 0.5890867859125137} | train loss {'Reaction outcome loss': 0.2032079849129926, 'Total loss': 0.2032079849129926}
2023-01-05 05:03:39,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:39,324 INFO:     Epoch: 64
2023-01-05 05:03:41,571 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5898531536261241, 'Total loss': 0.5898531536261241} | train loss {'Reaction outcome loss': 0.20025523811148394, 'Total loss': 0.20025523811148394}
2023-01-05 05:03:41,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:41,571 INFO:     Epoch: 65
2023-01-05 05:03:43,851 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.579510963956515, 'Total loss': 0.579510963956515} | train loss {'Reaction outcome loss': 0.1979807543295977, 'Total loss': 0.1979807543295977}
2023-01-05 05:03:43,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:43,851 INFO:     Epoch: 66
2023-01-05 05:03:46,119 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5944844166437785, 'Total loss': 0.5944844166437785} | train loss {'Reaction outcome loss': 0.20479386037094552, 'Total loss': 0.20479386037094552}
2023-01-05 05:03:46,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:46,120 INFO:     Epoch: 67
2023-01-05 05:03:48,390 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5674325486024221, 'Total loss': 0.5674325486024221} | train loss {'Reaction outcome loss': 0.20160549936903513, 'Total loss': 0.20160549936903513}
2023-01-05 05:03:48,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:48,390 INFO:     Epoch: 68
2023-01-05 05:03:50,500 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5846915721893311, 'Total loss': 0.5846915721893311} | train loss {'Reaction outcome loss': 0.1984728175191888, 'Total loss': 0.1984728175191888}
2023-01-05 05:03:50,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:50,500 INFO:     Epoch: 69
2023-01-05 05:03:52,635 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6014782051245372, 'Total loss': 0.6014782051245372} | train loss {'Reaction outcome loss': 0.19674639774331762, 'Total loss': 0.19674639774331762}
2023-01-05 05:03:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:52,636 INFO:     Epoch: 70
2023-01-05 05:03:54,880 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5858892465631167, 'Total loss': 0.5858892465631167} | train loss {'Reaction outcome loss': 0.19854978249418392, 'Total loss': 0.19854978249418392}
2023-01-05 05:03:54,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:54,880 INFO:     Epoch: 71
2023-01-05 05:03:57,098 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5911083400249482, 'Total loss': 0.5911083400249482} | train loss {'Reaction outcome loss': 0.18949520373582462, 'Total loss': 0.18949520373582462}
2023-01-05 05:03:57,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:57,099 INFO:     Epoch: 72
2023-01-05 05:03:59,308 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6024980507791042, 'Total loss': 0.6024980507791042} | train loss {'Reaction outcome loss': 0.19527626697928896, 'Total loss': 0.19527626697928896}
2023-01-05 05:03:59,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:03:59,309 INFO:     Epoch: 73
2023-01-05 05:04:01,571 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.572960140183568, 'Total loss': 0.572960140183568} | train loss {'Reaction outcome loss': 0.1942918018474906, 'Total loss': 0.1942918018474906}
2023-01-05 05:04:01,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:01,571 INFO:     Epoch: 74
2023-01-05 05:04:03,756 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5969821701447169, 'Total loss': 0.5969821701447169} | train loss {'Reaction outcome loss': 0.18983981010608295, 'Total loss': 0.18983981010608295}
2023-01-05 05:04:03,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:03,756 INFO:     Epoch: 75
2023-01-05 05:04:06,045 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5676512867212296, 'Total loss': 0.5676512867212296} | train loss {'Reaction outcome loss': 0.19385893156899925, 'Total loss': 0.19385893156899925}
2023-01-05 05:04:06,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:06,045 INFO:     Epoch: 76
2023-01-05 05:04:08,294 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6001167277495066, 'Total loss': 0.6001167277495066} | train loss {'Reaction outcome loss': 0.19001449422998226, 'Total loss': 0.19001449422998226}
2023-01-05 05:04:08,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:08,295 INFO:     Epoch: 77
2023-01-05 05:04:10,515 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5932396272818248, 'Total loss': 0.5932396272818248} | train loss {'Reaction outcome loss': 0.18967067756579134, 'Total loss': 0.18967067756579134}
2023-01-05 05:04:10,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:10,515 INFO:     Epoch: 78
2023-01-05 05:04:12,753 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5754419128100078, 'Total loss': 0.5754419128100078} | train loss {'Reaction outcome loss': 0.1916846480348319, 'Total loss': 0.1916846480348319}
2023-01-05 05:04:12,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:12,753 INFO:     Epoch: 79
2023-01-05 05:04:14,984 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6036347031593323, 'Total loss': 0.6036347031593323} | train loss {'Reaction outcome loss': 0.19008752415864477, 'Total loss': 0.19008752415864477}
2023-01-05 05:04:14,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:14,985 INFO:     Epoch: 80
2023-01-05 05:04:17,204 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.622880615790685, 'Total loss': 0.622880615790685} | train loss {'Reaction outcome loss': 0.18352237264440807, 'Total loss': 0.18352237264440807}
2023-01-05 05:04:17,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:17,204 INFO:     Epoch: 81
2023-01-05 05:04:19,428 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5833557844161987, 'Total loss': 0.5833557844161987} | train loss {'Reaction outcome loss': 0.1840852667873436, 'Total loss': 0.1840852667873436}
2023-01-05 05:04:19,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:19,429 INFO:     Epoch: 82
2023-01-05 05:04:21,662 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5812493860721588, 'Total loss': 0.5812493860721588} | train loss {'Reaction outcome loss': 0.18656432262322586, 'Total loss': 0.18656432262322586}
2023-01-05 05:04:21,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:21,663 INFO:     Epoch: 83
2023-01-05 05:04:23,928 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6033584574858347, 'Total loss': 0.6033584574858347} | train loss {'Reaction outcome loss': 0.18861421113598434, 'Total loss': 0.18861421113598434}
2023-01-05 05:04:23,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:23,929 INFO:     Epoch: 84
2023-01-05 05:04:26,177 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6310623784859976, 'Total loss': 0.6310623784859976} | train loss {'Reaction outcome loss': 0.18812042619320243, 'Total loss': 0.18812042619320243}
2023-01-05 05:04:26,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:26,177 INFO:     Epoch: 85
2023-01-05 05:04:28,428 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5404687980810802, 'Total loss': 0.5404687980810802} | train loss {'Reaction outcome loss': 0.18312118432252578, 'Total loss': 0.18312118432252578}
2023-01-05 05:04:28,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:28,428 INFO:     Epoch: 86
2023-01-05 05:04:30,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5939575095971426, 'Total loss': 0.5939575095971426} | train loss {'Reaction outcome loss': 0.1840593019888706, 'Total loss': 0.1840593019888706}
2023-01-05 05:04:30,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:30,702 INFO:     Epoch: 87
2023-01-05 05:04:32,964 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5967451681693395, 'Total loss': 0.5967451681693395} | train loss {'Reaction outcome loss': 0.18836549140633982, 'Total loss': 0.18836549140633982}
2023-01-05 05:04:32,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:32,964 INFO:     Epoch: 88
2023-01-05 05:04:35,229 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5922454833984375, 'Total loss': 0.5922454833984375} | train loss {'Reaction outcome loss': 0.18166059493726044, 'Total loss': 0.18166059493726044}
2023-01-05 05:04:35,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:35,230 INFO:     Epoch: 89
2023-01-05 05:04:37,446 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5658331573009491, 'Total loss': 0.5658331573009491} | train loss {'Reaction outcome loss': 0.18339780532327962, 'Total loss': 0.18339780532327962}
2023-01-05 05:04:37,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:37,446 INFO:     Epoch: 90
2023-01-05 05:04:39,696 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.582449742158254, 'Total loss': 0.582449742158254} | train loss {'Reaction outcome loss': 0.17923404555431557, 'Total loss': 0.17923404555431557}
2023-01-05 05:04:39,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:39,696 INFO:     Epoch: 91
2023-01-05 05:04:41,965 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5760760183135668, 'Total loss': 0.5760760183135668} | train loss {'Reaction outcome loss': 0.180325719696009, 'Total loss': 0.180325719696009}
2023-01-05 05:04:41,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:41,965 INFO:     Epoch: 92
2023-01-05 05:04:44,231 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6023775239785513, 'Total loss': 0.6023775239785513} | train loss {'Reaction outcome loss': 0.1881931549163421, 'Total loss': 0.1881931549163421}
2023-01-05 05:04:44,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:44,232 INFO:     Epoch: 93
2023-01-05 05:04:46,444 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5805766761302948, 'Total loss': 0.5805766761302948} | train loss {'Reaction outcome loss': 0.18218687732303884, 'Total loss': 0.18218687732303884}
2023-01-05 05:04:46,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:46,444 INFO:     Epoch: 94
2023-01-05 05:04:48,704 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5747110327084859, 'Total loss': 0.5747110327084859} | train loss {'Reaction outcome loss': 0.172546753671612, 'Total loss': 0.172546753671612}
2023-01-05 05:04:48,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:48,705 INFO:     Epoch: 95
2023-01-05 05:04:50,953 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5991051773230235, 'Total loss': 0.5991051773230235} | train loss {'Reaction outcome loss': 0.17690553776213785, 'Total loss': 0.17690553776213785}
2023-01-05 05:04:50,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:50,954 INFO:     Epoch: 96
2023-01-05 05:04:53,204 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5942956517140071, 'Total loss': 0.5942956517140071} | train loss {'Reaction outcome loss': 0.1776808132972259, 'Total loss': 0.1776808132972259}
2023-01-05 05:04:53,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:53,204 INFO:     Epoch: 97
2023-01-05 05:04:55,466 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.581508148709933, 'Total loss': 0.581508148709933} | train loss {'Reaction outcome loss': 0.174633811932353, 'Total loss': 0.174633811932353}
2023-01-05 05:04:55,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:55,466 INFO:     Epoch: 98
2023-01-05 05:04:57,677 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6185574034849802, 'Total loss': 0.6185574034849802} | train loss {'Reaction outcome loss': 0.17485528876029952, 'Total loss': 0.17485528876029952}
2023-01-05 05:04:57,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:04:57,678 INFO:     Epoch: 99
2023-01-05 05:04:59,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6178534338871638, 'Total loss': 0.6178534338871638} | train loss {'Reaction outcome loss': 0.1759956474819419, 'Total loss': 0.1759956474819419}
2023-01-05 05:04:59,926 INFO:     Best model found after epoch 24 of 100.
2023-01-05 05:04:59,927 INFO:   Done with stage: TRAINING
2023-01-05 05:04:59,927 INFO:   Starting stage: EVALUATION
2023-01-05 05:05:00,054 INFO:   Done with stage: EVALUATION
2023-01-05 05:05:00,055 INFO:   Leaving out SEQ value Fold_8
2023-01-05 05:05:00,067 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 05:05:00,067 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:05:00,716 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:05:00,716 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:05:00,788 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:05:00,789 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:05:00,789 INFO:     No hyperparam tuning for this model
2023-01-05 05:05:00,789 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:05:00,789 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:05:00,789 INFO:     None feature selector for col prot
2023-01-05 05:05:00,790 INFO:     None feature selector for col prot
2023-01-05 05:05:00,790 INFO:     None feature selector for col prot
2023-01-05 05:05:00,790 INFO:     None feature selector for col chem
2023-01-05 05:05:00,790 INFO:     None feature selector for col chem
2023-01-05 05:05:00,790 INFO:     None feature selector for col chem
2023-01-05 05:05:00,790 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:05:00,791 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:05:00,793 INFO:     Number of params in model 72931
2023-01-05 05:05:00,796 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:05:00,796 INFO:   Starting stage: TRAINING
2023-01-05 05:05:00,856 INFO:     Val loss before train {'Reaction outcome loss': 0.9492722372214, 'Total loss': 0.9492722372214}
2023-01-05 05:05:00,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:00,857 INFO:     Epoch: 0
2023-01-05 05:05:03,113 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7473355074723561, 'Total loss': 0.7473355074723561} | train loss {'Reaction outcome loss': 0.9613355631953564, 'Total loss': 0.9613355631953564}
2023-01-05 05:05:03,113 INFO:     Found new best model at epoch 0
2023-01-05 05:05:03,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:03,114 INFO:     Epoch: 1
2023-01-05 05:05:05,387 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5464034934838613, 'Total loss': 0.5464034934838613} | train loss {'Reaction outcome loss': 0.6189253226770813, 'Total loss': 0.6189253226770813}
2023-01-05 05:05:05,387 INFO:     Found new best model at epoch 1
2023-01-05 05:05:05,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:05,389 INFO:     Epoch: 2
2023-01-05 05:05:07,578 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5242080787817637, 'Total loss': 0.5242080787817637} | train loss {'Reaction outcome loss': 0.5217860824010079, 'Total loss': 0.5217860824010079}
2023-01-05 05:05:07,578 INFO:     Found new best model at epoch 2
2023-01-05 05:05:07,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:07,579 INFO:     Epoch: 3
2023-01-05 05:05:09,738 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5110710620880127, 'Total loss': 0.5110710620880127} | train loss {'Reaction outcome loss': 0.4858116277479195, 'Total loss': 0.4858116277479195}
2023-01-05 05:05:09,739 INFO:     Found new best model at epoch 3
2023-01-05 05:05:09,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:09,740 INFO:     Epoch: 4
2023-01-05 05:05:11,957 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4861273338397344, 'Total loss': 0.4861273338397344} | train loss {'Reaction outcome loss': 0.45890207256635895, 'Total loss': 0.45890207256635895}
2023-01-05 05:05:11,957 INFO:     Found new best model at epoch 4
2023-01-05 05:05:11,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:11,958 INFO:     Epoch: 5
2023-01-05 05:05:14,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4988847181200981, 'Total loss': 0.4988847181200981} | train loss {'Reaction outcome loss': 0.4351637602599837, 'Total loss': 0.4351637602599837}
2023-01-05 05:05:14,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:14,208 INFO:     Epoch: 6
2023-01-05 05:05:16,469 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47656901081403097, 'Total loss': 0.47656901081403097} | train loss {'Reaction outcome loss': 0.41616198117338604, 'Total loss': 0.41616198117338604}
2023-01-05 05:05:16,469 INFO:     Found new best model at epoch 6
2023-01-05 05:05:16,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:16,471 INFO:     Epoch: 7
2023-01-05 05:05:18,734 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48862810532251993, 'Total loss': 0.48862810532251993} | train loss {'Reaction outcome loss': 0.40264458669538516, 'Total loss': 0.40264458669538516}
2023-01-05 05:05:18,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:18,734 INFO:     Epoch: 8
2023-01-05 05:05:20,994 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.501944359143575, 'Total loss': 0.501944359143575} | train loss {'Reaction outcome loss': 0.3915385077268803, 'Total loss': 0.3915385077268803}
2023-01-05 05:05:20,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:20,994 INFO:     Epoch: 9
2023-01-05 05:05:23,244 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4698149969180425, 'Total loss': 0.4698149969180425} | train loss {'Reaction outcome loss': 0.3813714481893576, 'Total loss': 0.3813714481893576}
2023-01-05 05:05:23,244 INFO:     Found new best model at epoch 9
2023-01-05 05:05:23,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:23,245 INFO:     Epoch: 10
2023-01-05 05:05:25,506 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46676304638385774, 'Total loss': 0.46676304638385774} | train loss {'Reaction outcome loss': 0.3691008742903975, 'Total loss': 0.3691008742903975}
2023-01-05 05:05:25,506 INFO:     Found new best model at epoch 10
2023-01-05 05:05:25,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:25,508 INFO:     Epoch: 11
2023-01-05 05:05:27,745 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46303535501162213, 'Total loss': 0.46303535501162213} | train loss {'Reaction outcome loss': 0.35890592360680085, 'Total loss': 0.35890592360680085}
2023-01-05 05:05:27,746 INFO:     Found new best model at epoch 11
2023-01-05 05:05:27,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:27,748 INFO:     Epoch: 12
2023-01-05 05:05:30,009 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48633161385854085, 'Total loss': 0.48633161385854085} | train loss {'Reaction outcome loss': 0.34352682918593613, 'Total loss': 0.34352682918593613}
2023-01-05 05:05:30,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:30,009 INFO:     Epoch: 13
2023-01-05 05:05:32,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45124305884043375, 'Total loss': 0.45124305884043375} | train loss {'Reaction outcome loss': 0.3408521391397369, 'Total loss': 0.3408521391397369}
2023-01-05 05:05:32,257 INFO:     Found new best model at epoch 13
2023-01-05 05:05:32,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:32,258 INFO:     Epoch: 14
2023-01-05 05:05:34,489 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4923462629318237, 'Total loss': 0.4923462629318237} | train loss {'Reaction outcome loss': 0.33690726609590155, 'Total loss': 0.33690726609590155}
2023-01-05 05:05:34,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:34,490 INFO:     Epoch: 15
2023-01-05 05:05:36,752 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47293317317962646, 'Total loss': 0.47293317317962646} | train loss {'Reaction outcome loss': 0.32523451179672586, 'Total loss': 0.32523451179672586}
2023-01-05 05:05:36,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:36,752 INFO:     Epoch: 16
2023-01-05 05:05:38,956 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47300148407618203, 'Total loss': 0.47300148407618203} | train loss {'Reaction outcome loss': 0.3219243066682332, 'Total loss': 0.3219243066682332}
2023-01-05 05:05:38,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:38,956 INFO:     Epoch: 17
2023-01-05 05:05:41,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49688733170429866, 'Total loss': 0.49688733170429866} | train loss {'Reaction outcome loss': 0.32627670331166353, 'Total loss': 0.32627670331166353}
2023-01-05 05:05:41,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:41,224 INFO:     Epoch: 18
2023-01-05 05:05:43,481 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4855166167020798, 'Total loss': 0.4855166167020798} | train loss {'Reaction outcome loss': 0.30979636813974165, 'Total loss': 0.30979636813974165}
2023-01-05 05:05:43,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:43,482 INFO:     Epoch: 19
2023-01-05 05:05:45,746 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49008593956629437, 'Total loss': 0.49008593956629437} | train loss {'Reaction outcome loss': 0.3019378299833751, 'Total loss': 0.3019378299833751}
2023-01-05 05:05:45,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:45,747 INFO:     Epoch: 20
2023-01-05 05:05:47,946 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5087369918823242, 'Total loss': 0.5087369918823242} | train loss {'Reaction outcome loss': 0.29717948234241887, 'Total loss': 0.29717948234241887}
2023-01-05 05:05:47,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:47,947 INFO:     Epoch: 21
2023-01-05 05:05:50,187 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47315913836161294, 'Total loss': 0.47315913836161294} | train loss {'Reaction outcome loss': 0.29708378203213215, 'Total loss': 0.29708378203213215}
2023-01-05 05:05:50,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:50,187 INFO:     Epoch: 22
2023-01-05 05:05:52,446 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49549411137898763, 'Total loss': 0.49549411137898763} | train loss {'Reaction outcome loss': 0.29377798486603895, 'Total loss': 0.29377798486603895}
2023-01-05 05:05:52,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:52,446 INFO:     Epoch: 23
2023-01-05 05:05:54,705 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5081783095995586, 'Total loss': 0.5081783095995586} | train loss {'Reaction outcome loss': 0.28196800575908815, 'Total loss': 0.28196800575908815}
2023-01-05 05:05:54,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:54,705 INFO:     Epoch: 24
2023-01-05 05:05:56,973 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4982403596242269, 'Total loss': 0.4982403596242269} | train loss {'Reaction outcome loss': 0.30046520178354735, 'Total loss': 0.30046520178354735}
2023-01-05 05:05:56,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:56,974 INFO:     Epoch: 25
2023-01-05 05:05:59,225 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.484879440565904, 'Total loss': 0.484879440565904} | train loss {'Reaction outcome loss': 0.27751614005925757, 'Total loss': 0.27751614005925757}
2023-01-05 05:05:59,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:05:59,225 INFO:     Epoch: 26
2023-01-05 05:06:01,467 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4768660227457682, 'Total loss': 0.4768660227457682} | train loss {'Reaction outcome loss': 0.2957282260438238, 'Total loss': 0.2957282260438238}
2023-01-05 05:06:01,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:01,467 INFO:     Epoch: 27
2023-01-05 05:06:03,645 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5199880063533783, 'Total loss': 0.5199880063533783} | train loss {'Reaction outcome loss': 0.2673022805778917, 'Total loss': 0.2673022805778917}
2023-01-05 05:06:03,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:03,646 INFO:     Epoch: 28
2023-01-05 05:06:05,906 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47908547321955364, 'Total loss': 0.47908547321955364} | train loss {'Reaction outcome loss': 0.265038031995283, 'Total loss': 0.265038031995283}
2023-01-05 05:06:05,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:05,907 INFO:     Epoch: 29
2023-01-05 05:06:08,117 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48875178347031273, 'Total loss': 0.48875178347031273} | train loss {'Reaction outcome loss': 0.2603688034485432, 'Total loss': 0.2603688034485432}
2023-01-05 05:06:08,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:08,117 INFO:     Epoch: 30
2023-01-05 05:06:10,368 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4909465730190277, 'Total loss': 0.4909465730190277} | train loss {'Reaction outcome loss': 0.2582165666128698, 'Total loss': 0.2582165666128698}
2023-01-05 05:06:10,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:10,368 INFO:     Epoch: 31
2023-01-05 05:06:12,632 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48772495090961454, 'Total loss': 0.48772495090961454} | train loss {'Reaction outcome loss': 0.2530515605713067, 'Total loss': 0.2530515605713067}
2023-01-05 05:06:12,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:12,632 INFO:     Epoch: 32
2023-01-05 05:06:14,877 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4991072167952855, 'Total loss': 0.4991072167952855} | train loss {'Reaction outcome loss': 0.25499518556466355, 'Total loss': 0.25499518556466355}
2023-01-05 05:06:14,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:14,877 INFO:     Epoch: 33
2023-01-05 05:06:17,139 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5057335933049519, 'Total loss': 0.5057335933049519} | train loss {'Reaction outcome loss': 0.25226503727026284, 'Total loss': 0.25226503727026284}
2023-01-05 05:06:17,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:17,140 INFO:     Epoch: 34
2023-01-05 05:06:19,415 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5231885155042012, 'Total loss': 0.5231885155042012} | train loss {'Reaction outcome loss': 0.24434276048323492, 'Total loss': 0.24434276048323492}
2023-01-05 05:06:19,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:19,416 INFO:     Epoch: 35
2023-01-05 05:06:21,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5091006855169932, 'Total loss': 0.5091006855169932} | train loss {'Reaction outcome loss': 0.24520400430554984, 'Total loss': 0.24520400430554984}
2023-01-05 05:06:21,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:21,670 INFO:     Epoch: 36
2023-01-05 05:06:23,942 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5057219177484512, 'Total loss': 0.5057219177484512} | train loss {'Reaction outcome loss': 0.24670618828521043, 'Total loss': 0.24670618828521043}
2023-01-05 05:06:23,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:23,943 INFO:     Epoch: 37
2023-01-05 05:06:26,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5321996212005615, 'Total loss': 0.5321996212005615} | train loss {'Reaction outcome loss': 0.2407594206692327, 'Total loss': 0.2407594206692327}
2023-01-05 05:06:26,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:26,194 INFO:     Epoch: 38
2023-01-05 05:06:28,453 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49626006682713825, 'Total loss': 0.49626006682713825} | train loss {'Reaction outcome loss': 0.24216930909703174, 'Total loss': 0.24216930909703174}
2023-01-05 05:06:28,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:28,453 INFO:     Epoch: 39
2023-01-05 05:06:30,704 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4925078848997752, 'Total loss': 0.4925078848997752} | train loss {'Reaction outcome loss': 0.23367551316766985, 'Total loss': 0.23367551316766985}
2023-01-05 05:06:30,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:30,704 INFO:     Epoch: 40
2023-01-05 05:06:32,948 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5188535322745641, 'Total loss': 0.5188535322745641} | train loss {'Reaction outcome loss': 0.23375991423465853, 'Total loss': 0.23375991423465853}
2023-01-05 05:06:32,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:32,950 INFO:     Epoch: 41
2023-01-05 05:06:35,207 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49563226600488025, 'Total loss': 0.49563226600488025} | train loss {'Reaction outcome loss': 0.23948740668150265, 'Total loss': 0.23948740668150265}
2023-01-05 05:06:35,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:35,207 INFO:     Epoch: 42
2023-01-05 05:06:37,441 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.493137205640475, 'Total loss': 0.493137205640475} | train loss {'Reaction outcome loss': 0.2275398072302198, 'Total loss': 0.2275398072302198}
2023-01-05 05:06:37,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:37,441 INFO:     Epoch: 43
2023-01-05 05:06:39,706 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5045955240726471, 'Total loss': 0.5045955240726471} | train loss {'Reaction outcome loss': 0.23067714382752613, 'Total loss': 0.23067714382752613}
2023-01-05 05:06:39,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:39,707 INFO:     Epoch: 44
2023-01-05 05:06:41,964 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.493196835120519, 'Total loss': 0.493196835120519} | train loss {'Reaction outcome loss': 0.22500112131846423, 'Total loss': 0.22500112131846423}
2023-01-05 05:06:41,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:41,964 INFO:     Epoch: 45
2023-01-05 05:06:44,202 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4908163954814275, 'Total loss': 0.4908163954814275} | train loss {'Reaction outcome loss': 0.22017684515542013, 'Total loss': 0.22017684515542013}
2023-01-05 05:06:44,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:44,203 INFO:     Epoch: 46
2023-01-05 05:06:46,442 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4883160581191381, 'Total loss': 0.4883160581191381} | train loss {'Reaction outcome loss': 0.22300786732871464, 'Total loss': 0.22300786732871464}
2023-01-05 05:06:46,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:46,442 INFO:     Epoch: 47
2023-01-05 05:06:48,669 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5109155178070068, 'Total loss': 0.5109155178070068} | train loss {'Reaction outcome loss': 0.22174529054546324, 'Total loss': 0.22174529054546324}
2023-01-05 05:06:48,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:48,669 INFO:     Epoch: 48
2023-01-05 05:06:50,885 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4897127230962118, 'Total loss': 0.4897127230962118} | train loss {'Reaction outcome loss': 0.2232857682182035, 'Total loss': 0.2232857682182035}
2023-01-05 05:06:50,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:50,885 INFO:     Epoch: 49
2023-01-05 05:06:53,157 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5525996774435044, 'Total loss': 0.5525996774435044} | train loss {'Reaction outcome loss': 0.21616325407175926, 'Total loss': 0.21616325407175926}
2023-01-05 05:06:53,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:53,158 INFO:     Epoch: 50
2023-01-05 05:06:55,429 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5343525846799214, 'Total loss': 0.5343525846799214} | train loss {'Reaction outcome loss': 0.21838135814080792, 'Total loss': 0.21838135814080792}
2023-01-05 05:06:55,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:55,430 INFO:     Epoch: 51
2023-01-05 05:06:57,652 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.491873973608017, 'Total loss': 0.491873973608017} | train loss {'Reaction outcome loss': 0.21145865869239325, 'Total loss': 0.21145865869239325}
2023-01-05 05:06:57,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:57,652 INFO:     Epoch: 52
2023-01-05 05:06:59,884 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5047235508759816, 'Total loss': 0.5047235508759816} | train loss {'Reaction outcome loss': 0.21178290537858813, 'Total loss': 0.21178290537858813}
2023-01-05 05:06:59,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:06:59,884 INFO:     Epoch: 53
2023-01-05 05:07:02,136 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5486945321162542, 'Total loss': 0.5486945321162542} | train loss {'Reaction outcome loss': 0.21327246747661274, 'Total loss': 0.21327246747661274}
2023-01-05 05:07:02,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:02,136 INFO:     Epoch: 54
2023-01-05 05:07:04,392 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5054726580778758, 'Total loss': 0.5054726580778758} | train loss {'Reaction outcome loss': 0.21059767875577445, 'Total loss': 0.21059767875577445}
2023-01-05 05:07:04,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:04,393 INFO:     Epoch: 55
2023-01-05 05:07:06,606 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5304914643367131, 'Total loss': 0.5304914643367131} | train loss {'Reaction outcome loss': 0.21189334156477582, 'Total loss': 0.21189334156477582}
2023-01-05 05:07:06,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:06,606 INFO:     Epoch: 56
2023-01-05 05:07:08,831 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5319507241249084, 'Total loss': 0.5319507241249084} | train loss {'Reaction outcome loss': 0.23740831646026547, 'Total loss': 0.23740831646026547}
2023-01-05 05:07:08,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:08,832 INFO:     Epoch: 57
2023-01-05 05:07:11,082 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48822232286135353, 'Total loss': 0.48822232286135353} | train loss {'Reaction outcome loss': 0.22485312696654294, 'Total loss': 0.22485312696654294}
2023-01-05 05:07:11,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:11,083 INFO:     Epoch: 58
2023-01-05 05:07:13,322 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5041731536388397, 'Total loss': 0.5041731536388397} | train loss {'Reaction outcome loss': 0.21312989497159107, 'Total loss': 0.21312989497159107}
2023-01-05 05:07:13,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:13,322 INFO:     Epoch: 59
2023-01-05 05:07:15,573 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4986801266670227, 'Total loss': 0.4986801266670227} | train loss {'Reaction outcome loss': 0.21269252999226793, 'Total loss': 0.21269252999226793}
2023-01-05 05:07:15,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:15,574 INFO:     Epoch: 60
2023-01-05 05:07:17,789 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5245066066582997, 'Total loss': 0.5245066066582997} | train loss {'Reaction outcome loss': 0.2126890674766585, 'Total loss': 0.2126890674766585}
2023-01-05 05:07:17,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:17,790 INFO:     Epoch: 61
2023-01-05 05:07:20,034 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49725755155086515, 'Total loss': 0.49725755155086515} | train loss {'Reaction outcome loss': 0.20672953191915175, 'Total loss': 0.20672953191915175}
2023-01-05 05:07:20,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:20,034 INFO:     Epoch: 62
2023-01-05 05:07:22,287 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49704978267351785, 'Total loss': 0.49704978267351785} | train loss {'Reaction outcome loss': 0.20910059910038134, 'Total loss': 0.20910059910038134}
2023-01-05 05:07:22,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:22,287 INFO:     Epoch: 63
2023-01-05 05:07:24,244 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4883135616779327, 'Total loss': 0.4883135616779327} | train loss {'Reaction outcome loss': 0.20192792555114822, 'Total loss': 0.20192792555114822}
2023-01-05 05:07:24,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:24,244 INFO:     Epoch: 64
2023-01-05 05:07:26,085 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5212597668170929, 'Total loss': 0.5212597668170929} | train loss {'Reaction outcome loss': 0.19981670282457187, 'Total loss': 0.19981670282457187}
2023-01-05 05:07:26,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:26,085 INFO:     Epoch: 65
2023-01-05 05:07:28,084 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5529490649700165, 'Total loss': 0.5529490649700165} | train loss {'Reaction outcome loss': 0.19499714138404722, 'Total loss': 0.19499714138404722}
2023-01-05 05:07:28,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:28,085 INFO:     Epoch: 66
2023-01-05 05:07:30,332 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5158863415320715, 'Total loss': 0.5158863415320715} | train loss {'Reaction outcome loss': 0.19863444321811624, 'Total loss': 0.19863444321811624}
2023-01-05 05:07:30,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:30,332 INFO:     Epoch: 67
2023-01-05 05:07:32,523 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5479066173235575, 'Total loss': 0.5479066173235575} | train loss {'Reaction outcome loss': 0.19588690930370078, 'Total loss': 0.19588690930370078}
2023-01-05 05:07:32,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:32,523 INFO:     Epoch: 68
2023-01-05 05:07:34,773 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5084065655867259, 'Total loss': 0.5084065655867259} | train loss {'Reaction outcome loss': 0.198246792778145, 'Total loss': 0.198246792778145}
2023-01-05 05:07:34,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:34,773 INFO:     Epoch: 69
2023-01-05 05:07:37,006 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.475175882379214, 'Total loss': 0.475175882379214} | train loss {'Reaction outcome loss': 0.19349986182667478, 'Total loss': 0.19349986182667478}
2023-01-05 05:07:37,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:37,006 INFO:     Epoch: 70
2023-01-05 05:07:39,235 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48359472254912056, 'Total loss': 0.48359472254912056} | train loss {'Reaction outcome loss': 0.194619255265275, 'Total loss': 0.194619255265275}
2023-01-05 05:07:39,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:39,235 INFO:     Epoch: 71
2023-01-05 05:07:41,453 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5110555469989777, 'Total loss': 0.5110555469989777} | train loss {'Reaction outcome loss': 0.1983680073644264, 'Total loss': 0.1983680073644264}
2023-01-05 05:07:41,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:41,453 INFO:     Epoch: 72
2023-01-05 05:07:43,681 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5063985993464788, 'Total loss': 0.5063985993464788} | train loss {'Reaction outcome loss': 0.1947815284762275, 'Total loss': 0.1947815284762275}
2023-01-05 05:07:43,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:43,681 INFO:     Epoch: 73
2023-01-05 05:07:45,824 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5169466346502304, 'Total loss': 0.5169466346502304} | train loss {'Reaction outcome loss': 0.19261612924679683, 'Total loss': 0.19261612924679683}
2023-01-05 05:07:45,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:45,825 INFO:     Epoch: 74
2023-01-05 05:07:48,093 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46665758490562437, 'Total loss': 0.46665758490562437} | train loss {'Reaction outcome loss': 0.19187868294049648, 'Total loss': 0.19187868294049648}
2023-01-05 05:07:48,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:48,093 INFO:     Epoch: 75
2023-01-05 05:07:50,353 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49502159158388775, 'Total loss': 0.49502159158388775} | train loss {'Reaction outcome loss': 0.19144751594127307, 'Total loss': 0.19144751594127307}
2023-01-05 05:07:50,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:50,353 INFO:     Epoch: 76
2023-01-05 05:07:52,580 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5550564686457317, 'Total loss': 0.5550564686457317} | train loss {'Reaction outcome loss': 0.20062356076432744, 'Total loss': 0.20062356076432744}
2023-01-05 05:07:52,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:52,581 INFO:     Epoch: 77
2023-01-05 05:07:54,747 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5045331696669261, 'Total loss': 0.5045331696669261} | train loss {'Reaction outcome loss': 0.21944135928567013, 'Total loss': 0.21944135928567013}
2023-01-05 05:07:54,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:54,748 INFO:     Epoch: 78
2023-01-05 05:07:56,884 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4894202063481013, 'Total loss': 0.4894202063481013} | train loss {'Reaction outcome loss': 0.1961136436784991, 'Total loss': 0.1961136436784991}
2023-01-05 05:07:56,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:56,884 INFO:     Epoch: 79
2023-01-05 05:07:58,951 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5542037010192871, 'Total loss': 0.5542037010192871} | train loss {'Reaction outcome loss': 0.18694456541022414, 'Total loss': 0.18694456541022414}
2023-01-05 05:07:58,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:07:58,952 INFO:     Epoch: 80
2023-01-05 05:08:01,197 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49300580819447837, 'Total loss': 0.49300580819447837} | train loss {'Reaction outcome loss': 0.18250485812988726, 'Total loss': 0.18250485812988726}
2023-01-05 05:08:01,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:01,197 INFO:     Epoch: 81
2023-01-05 05:08:03,432 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5065338691075643, 'Total loss': 0.5065338691075643} | train loss {'Reaction outcome loss': 0.1851328734976604, 'Total loss': 0.1851328734976604}
2023-01-05 05:08:03,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:03,432 INFO:     Epoch: 82
2023-01-05 05:08:05,681 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5075784345467885, 'Total loss': 0.5075784345467885} | train loss {'Reaction outcome loss': 0.18583411523866453, 'Total loss': 0.18583411523866453}
2023-01-05 05:08:05,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:05,682 INFO:     Epoch: 83
2023-01-05 05:08:07,897 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5444604019323985, 'Total loss': 0.5444604019323985} | train loss {'Reaction outcome loss': 0.184704484620496, 'Total loss': 0.184704484620496}
2023-01-05 05:08:07,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:07,897 INFO:     Epoch: 84
2023-01-05 05:08:10,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48953644633293153, 'Total loss': 0.48953644633293153} | train loss {'Reaction outcome loss': 0.18335045740399358, 'Total loss': 0.18335045740399358}
2023-01-05 05:08:10,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:10,112 INFO:     Epoch: 85
2023-01-05 05:08:12,376 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.520287811756134, 'Total loss': 0.520287811756134} | train loss {'Reaction outcome loss': 0.18126018509855898, 'Total loss': 0.18126018509855898}
2023-01-05 05:08:12,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:12,376 INFO:     Epoch: 86
2023-01-05 05:08:14,535 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5055520713329316, 'Total loss': 0.5055520713329316} | train loss {'Reaction outcome loss': 0.18498449293876573, 'Total loss': 0.18498449293876573}
2023-01-05 05:08:14,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:14,535 INFO:     Epoch: 87
2023-01-05 05:08:16,641 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.512473601102829, 'Total loss': 0.512473601102829} | train loss {'Reaction outcome loss': 0.18245695180516175, 'Total loss': 0.18245695180516175}
2023-01-05 05:08:16,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:16,641 INFO:     Epoch: 88
2023-01-05 05:08:18,758 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5149653557377557, 'Total loss': 0.5149653557377557} | train loss {'Reaction outcome loss': 0.17945997665494517, 'Total loss': 0.17945997665494517}
2023-01-05 05:08:18,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:18,759 INFO:     Epoch: 89
2023-01-05 05:08:21,005 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5234760840733846, 'Total loss': 0.5234760840733846} | train loss {'Reaction outcome loss': 0.1794264427204009, 'Total loss': 0.1794264427204009}
2023-01-05 05:08:21,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:21,006 INFO:     Epoch: 90
2023-01-05 05:08:23,247 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5129469911257426, 'Total loss': 0.5129469911257426} | train loss {'Reaction outcome loss': 0.1811851920036766, 'Total loss': 0.1811851920036766}
2023-01-05 05:08:23,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:23,247 INFO:     Epoch: 91
2023-01-05 05:08:25,466 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4891195197900136, 'Total loss': 0.4891195197900136} | train loss {'Reaction outcome loss': 0.17655127230471512, 'Total loss': 0.17655127230471512}
2023-01-05 05:08:25,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:25,466 INFO:     Epoch: 92
2023-01-05 05:08:27,691 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4937557200590769, 'Total loss': 0.4937557200590769} | train loss {'Reaction outcome loss': 0.17807302072753003, 'Total loss': 0.17807302072753003}
2023-01-05 05:08:27,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:27,692 INFO:     Epoch: 93
2023-01-05 05:08:29,949 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5049152761697769, 'Total loss': 0.5049152761697769} | train loss {'Reaction outcome loss': 0.17902481196232248, 'Total loss': 0.17902481196232248}
2023-01-05 05:08:29,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:29,950 INFO:     Epoch: 94
2023-01-05 05:08:32,150 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5552465935548146, 'Total loss': 0.5552465935548146} | train loss {'Reaction outcome loss': 0.17823558186617025, 'Total loss': 0.17823558186617025}
2023-01-05 05:08:32,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:32,150 INFO:     Epoch: 95
2023-01-05 05:08:34,329 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5123815248409908, 'Total loss': 0.5123815248409908} | train loss {'Reaction outcome loss': 0.17826953354676295, 'Total loss': 0.17826953354676295}
2023-01-05 05:08:34,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:34,329 INFO:     Epoch: 96
2023-01-05 05:08:36,560 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5051924089590708, 'Total loss': 0.5051924089590708} | train loss {'Reaction outcome loss': 0.17971809776729747, 'Total loss': 0.17971809776729747}
2023-01-05 05:08:36,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:36,560 INFO:     Epoch: 97
2023-01-05 05:08:38,753 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4976200414200624, 'Total loss': 0.4976200414200624} | train loss {'Reaction outcome loss': 0.17749880382494218, 'Total loss': 0.17749880382494218}
2023-01-05 05:08:38,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:38,753 INFO:     Epoch: 98
2023-01-05 05:08:40,956 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4670248637596766, 'Total loss': 0.4670248637596766} | train loss {'Reaction outcome loss': 0.17928762987287264, 'Total loss': 0.17928762987287264}
2023-01-05 05:08:40,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:40,956 INFO:     Epoch: 99
2023-01-05 05:08:43,212 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4872763534386953, 'Total loss': 0.4872763534386953} | train loss {'Reaction outcome loss': 0.1737563318400108, 'Total loss': 0.1737563318400108}
2023-01-05 05:08:43,212 INFO:     Best model found after epoch 14 of 100.
2023-01-05 05:08:43,213 INFO:   Done with stage: TRAINING
2023-01-05 05:08:43,213 INFO:   Starting stage: EVALUATION
2023-01-05 05:08:43,348 INFO:   Done with stage: EVALUATION
2023-01-05 05:08:43,348 INFO:   Leaving out SEQ value Fold_9
2023-01-05 05:08:43,360 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 05:08:43,361 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:08:44,006 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:08:44,006 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:08:44,078 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:08:44,078 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:08:44,079 INFO:     No hyperparam tuning for this model
2023-01-05 05:08:44,079 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:08:44,079 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:08:44,079 INFO:     None feature selector for col prot
2023-01-05 05:08:44,079 INFO:     None feature selector for col prot
2023-01-05 05:08:44,080 INFO:     None feature selector for col prot
2023-01-05 05:08:44,080 INFO:     None feature selector for col chem
2023-01-05 05:08:44,080 INFO:     None feature selector for col chem
2023-01-05 05:08:44,080 INFO:     None feature selector for col chem
2023-01-05 05:08:44,080 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:08:44,080 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:08:44,082 INFO:     Number of params in model 72931
2023-01-05 05:08:44,085 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:08:44,085 INFO:   Starting stage: TRAINING
2023-01-05 05:08:44,144 INFO:     Val loss before train {'Reaction outcome loss': 0.9777352293332418, 'Total loss': 0.9777352293332418}
2023-01-05 05:08:44,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:44,145 INFO:     Epoch: 0
2023-01-05 05:08:46,394 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7170265138149261, 'Total loss': 0.7170265138149261} | train loss {'Reaction outcome loss': 0.930137643340867, 'Total loss': 0.930137643340867}
2023-01-05 05:08:46,394 INFO:     Found new best model at epoch 0
2023-01-05 05:08:46,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:46,395 INFO:     Epoch: 1
2023-01-05 05:08:48,620 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5232554972171783, 'Total loss': 0.5232554972171783} | train loss {'Reaction outcome loss': 0.627465825598768, 'Total loss': 0.627465825598768}
2023-01-05 05:08:48,621 INFO:     Found new best model at epoch 1
2023-01-05 05:08:48,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:48,622 INFO:     Epoch: 2
2023-01-05 05:08:50,864 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47905523975690206, 'Total loss': 0.47905523975690206} | train loss {'Reaction outcome loss': 0.5394945161930029, 'Total loss': 0.5394945161930029}
2023-01-05 05:08:50,864 INFO:     Found new best model at epoch 2
2023-01-05 05:08:50,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:50,865 INFO:     Epoch: 3
2023-01-05 05:08:52,982 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4383787115414937, 'Total loss': 0.4383787115414937} | train loss {'Reaction outcome loss': 0.5005367019659152, 'Total loss': 0.5005367019659152}
2023-01-05 05:08:52,982 INFO:     Found new best model at epoch 3
2023-01-05 05:08:52,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:52,983 INFO:     Epoch: 4
2023-01-05 05:08:55,186 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44932167828083036, 'Total loss': 0.44932167828083036} | train loss {'Reaction outcome loss': 0.4728362404360045, 'Total loss': 0.4728362404360045}
2023-01-05 05:08:55,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:55,186 INFO:     Epoch: 5
2023-01-05 05:08:57,316 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40571541686852775, 'Total loss': 0.40571541686852775} | train loss {'Reaction outcome loss': 0.4588503879967375, 'Total loss': 0.4588503879967375}
2023-01-05 05:08:57,317 INFO:     Found new best model at epoch 5
2023-01-05 05:08:57,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:57,318 INFO:     Epoch: 6
2023-01-05 05:08:59,578 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41031333406766257, 'Total loss': 0.41031333406766257} | train loss {'Reaction outcome loss': 0.44006128605131223, 'Total loss': 0.44006128605131223}
2023-01-05 05:08:59,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:08:59,578 INFO:     Epoch: 7
2023-01-05 05:09:01,804 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4027643859386444, 'Total loss': 0.4027643859386444} | train loss {'Reaction outcome loss': 0.41145831894507445, 'Total loss': 0.41145831894507445}
2023-01-05 05:09:01,804 INFO:     Found new best model at epoch 7
2023-01-05 05:09:01,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:01,805 INFO:     Epoch: 8
2023-01-05 05:09:03,991 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4116298089424769, 'Total loss': 0.4116298089424769} | train loss {'Reaction outcome loss': 0.3991403090193922, 'Total loss': 0.3991403090193922}
2023-01-05 05:09:03,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:03,991 INFO:     Epoch: 9
2023-01-05 05:09:06,229 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42251021166642505, 'Total loss': 0.42251021166642505} | train loss {'Reaction outcome loss': 0.3865089404626169, 'Total loss': 0.3865089404626169}
2023-01-05 05:09:06,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:06,229 INFO:     Epoch: 10
2023-01-05 05:09:08,449 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38044284681479135, 'Total loss': 0.38044284681479135} | train loss {'Reaction outcome loss': 0.382068706025113, 'Total loss': 0.382068706025113}
2023-01-05 05:09:08,449 INFO:     Found new best model at epoch 10
2023-01-05 05:09:08,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:08,450 INFO:     Epoch: 11
2023-01-05 05:09:10,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38185905714829765, 'Total loss': 0.38185905714829765} | train loss {'Reaction outcome loss': 0.36945060568699695, 'Total loss': 0.36945060568699695}
2023-01-05 05:09:10,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:10,663 INFO:     Epoch: 12
2023-01-05 05:09:12,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36363023420174917, 'Total loss': 0.36363023420174917} | train loss {'Reaction outcome loss': 0.351445515356634, 'Total loss': 0.351445515356634}
2023-01-05 05:09:12,895 INFO:     Found new best model at epoch 12
2023-01-05 05:09:12,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:12,897 INFO:     Epoch: 13
2023-01-05 05:09:15,128 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3660439521074295, 'Total loss': 0.3660439521074295} | train loss {'Reaction outcome loss': 0.3464884534208239, 'Total loss': 0.3464884534208239}
2023-01-05 05:09:15,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:15,128 INFO:     Epoch: 14
2023-01-05 05:09:17,371 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37400877475738525, 'Total loss': 0.37400877475738525} | train loss {'Reaction outcome loss': 0.3426263034141258, 'Total loss': 0.3426263034141258}
2023-01-05 05:09:17,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:17,371 INFO:     Epoch: 15
2023-01-05 05:09:19,628 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.36808310250441234, 'Total loss': 0.36808310250441234} | train loss {'Reaction outcome loss': 0.3310195268469228, 'Total loss': 0.3310195268469228}
2023-01-05 05:09:19,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:19,628 INFO:     Epoch: 16
2023-01-05 05:09:21,880 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3733945329984029, 'Total loss': 0.3733945329984029} | train loss {'Reaction outcome loss': 0.3249679758534868, 'Total loss': 0.3249679758534868}
2023-01-05 05:09:21,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:21,880 INFO:     Epoch: 17
2023-01-05 05:09:24,096 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38344855010509493, 'Total loss': 0.38344855010509493} | train loss {'Reaction outcome loss': 0.32140450836121326, 'Total loss': 0.32140450836121326}
2023-01-05 05:09:24,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:24,096 INFO:     Epoch: 18
2023-01-05 05:09:26,344 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3762297968069712, 'Total loss': 0.3762297968069712} | train loss {'Reaction outcome loss': 0.31028704025168513, 'Total loss': 0.31028704025168513}
2023-01-05 05:09:26,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:26,344 INFO:     Epoch: 19
2023-01-05 05:09:28,526 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3540917431314786, 'Total loss': 0.3540917431314786} | train loss {'Reaction outcome loss': 0.30758041774422146, 'Total loss': 0.30758041774422146}
2023-01-05 05:09:28,526 INFO:     Found new best model at epoch 19
2023-01-05 05:09:28,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:28,528 INFO:     Epoch: 20
2023-01-05 05:09:30,687 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3518998404343923, 'Total loss': 0.3518998404343923} | train loss {'Reaction outcome loss': 0.2982970247571559, 'Total loss': 0.2982970247571559}
2023-01-05 05:09:30,687 INFO:     Found new best model at epoch 20
2023-01-05 05:09:30,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:30,688 INFO:     Epoch: 21
2023-01-05 05:09:32,937 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37487540940443675, 'Total loss': 0.37487540940443675} | train loss {'Reaction outcome loss': 0.29154572530398215, 'Total loss': 0.29154572530398215}
2023-01-05 05:09:32,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:32,938 INFO:     Epoch: 22
2023-01-05 05:09:35,198 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3821693703532219, 'Total loss': 0.3821693703532219} | train loss {'Reaction outcome loss': 0.28952398291701265, 'Total loss': 0.28952398291701265}
2023-01-05 05:09:35,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:35,198 INFO:     Epoch: 23
2023-01-05 05:09:37,415 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.35139666497707367, 'Total loss': 0.35139666497707367} | train loss {'Reaction outcome loss': 0.2855651380040386, 'Total loss': 0.2855651380040386}
2023-01-05 05:09:37,416 INFO:     Found new best model at epoch 23
2023-01-05 05:09:37,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:37,417 INFO:     Epoch: 24
2023-01-05 05:09:39,669 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3792333642641703, 'Total loss': 0.3792333642641703} | train loss {'Reaction outcome loss': 0.28829945948487823, 'Total loss': 0.28829945948487823}
2023-01-05 05:09:39,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:39,670 INFO:     Epoch: 25
2023-01-05 05:09:41,813 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4215411772330602, 'Total loss': 0.4215411772330602} | train loss {'Reaction outcome loss': 0.28065502399471554, 'Total loss': 0.28065502399471554}
2023-01-05 05:09:41,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:41,814 INFO:     Epoch: 26
2023-01-05 05:09:44,062 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36646568775177, 'Total loss': 0.36646568775177} | train loss {'Reaction outcome loss': 0.2773019583297698, 'Total loss': 0.2773019583297698}
2023-01-05 05:09:44,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:44,063 INFO:     Epoch: 27
2023-01-05 05:09:46,318 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3886743634939194, 'Total loss': 0.3886743634939194} | train loss {'Reaction outcome loss': 0.26813826471763813, 'Total loss': 0.26813826471763813}
2023-01-05 05:09:46,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:46,319 INFO:     Epoch: 28
2023-01-05 05:09:48,511 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3652484690149625, 'Total loss': 0.3652484690149625} | train loss {'Reaction outcome loss': 0.2700915565963943, 'Total loss': 0.2700915565963943}
2023-01-05 05:09:48,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:48,511 INFO:     Epoch: 29
2023-01-05 05:09:50,705 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3843906491994858, 'Total loss': 0.3843906491994858} | train loss {'Reaction outcome loss': 0.2676923494833265, 'Total loss': 0.2676923494833265}
2023-01-05 05:09:50,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:50,705 INFO:     Epoch: 30
2023-01-05 05:09:52,958 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38164642453193665, 'Total loss': 0.38164642453193665} | train loss {'Reaction outcome loss': 0.25952259883174056, 'Total loss': 0.25952259883174056}
2023-01-05 05:09:52,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:52,959 INFO:     Epoch: 31
2023-01-05 05:09:55,212 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38297840356826784, 'Total loss': 0.38297840356826784} | train loss {'Reaction outcome loss': 0.25969792725147167, 'Total loss': 0.25969792725147167}
2023-01-05 05:09:55,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:55,212 INFO:     Epoch: 32
2023-01-05 05:09:57,394 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4041994313398997, 'Total loss': 0.4041994313398997} | train loss {'Reaction outcome loss': 0.24969382195031622, 'Total loss': 0.24969382195031622}
2023-01-05 05:09:57,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:57,394 INFO:     Epoch: 33
2023-01-05 05:09:59,649 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37858013808727264, 'Total loss': 0.37858013808727264} | train loss {'Reaction outcome loss': 0.25153780221176786, 'Total loss': 0.25153780221176786}
2023-01-05 05:09:59,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:09:59,649 INFO:     Epoch: 34
2023-01-05 05:10:01,827 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39452462395032245, 'Total loss': 0.39452462395032245} | train loss {'Reaction outcome loss': 0.2506119619407084, 'Total loss': 0.2506119619407084}
2023-01-05 05:10:01,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:01,827 INFO:     Epoch: 35
2023-01-05 05:10:04,069 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3688379297653834, 'Total loss': 0.3688379297653834} | train loss {'Reaction outcome loss': 0.24869196282942657, 'Total loss': 0.24869196282942657}
2023-01-05 05:10:04,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:04,070 INFO:     Epoch: 36
2023-01-05 05:10:06,329 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37443061272303263, 'Total loss': 0.37443061272303263} | train loss {'Reaction outcome loss': 0.23733404702827524, 'Total loss': 0.23733404702827524}
2023-01-05 05:10:06,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:06,329 INFO:     Epoch: 37
2023-01-05 05:10:08,463 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.422856933871905, 'Total loss': 0.422856933871905} | train loss {'Reaction outcome loss': 0.2437595911796434, 'Total loss': 0.2437595911796434}
2023-01-05 05:10:08,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:08,464 INFO:     Epoch: 38
2023-01-05 05:10:10,632 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3942384501298269, 'Total loss': 0.3942384501298269} | train loss {'Reaction outcome loss': 0.23165438174792274, 'Total loss': 0.23165438174792274}
2023-01-05 05:10:10,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:10,632 INFO:     Epoch: 39
2023-01-05 05:10:12,835 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37646588136752446, 'Total loss': 0.37646588136752446} | train loss {'Reaction outcome loss': 0.23376493705976484, 'Total loss': 0.23376493705976484}
2023-01-05 05:10:12,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:12,836 INFO:     Epoch: 40
2023-01-05 05:10:15,048 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41804729669044416, 'Total loss': 0.41804729669044416} | train loss {'Reaction outcome loss': 0.22989260862532715, 'Total loss': 0.22989260862532715}
2023-01-05 05:10:15,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:15,049 INFO:     Epoch: 41
2023-01-05 05:10:17,249 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37352475424607595, 'Total loss': 0.37352475424607595} | train loss {'Reaction outcome loss': 0.23021756487255712, 'Total loss': 0.23021756487255712}
2023-01-05 05:10:17,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:17,249 INFO:     Epoch: 42
2023-01-05 05:10:19,467 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40430337488651275, 'Total loss': 0.40430337488651275} | train loss {'Reaction outcome loss': 0.22954018546404742, 'Total loss': 0.22954018546404742}
2023-01-05 05:10:19,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:19,467 INFO:     Epoch: 43
2023-01-05 05:10:21,705 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41142169733842215, 'Total loss': 0.41142169733842215} | train loss {'Reaction outcome loss': 0.22863224077888805, 'Total loss': 0.22863224077888805}
2023-01-05 05:10:21,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:21,706 INFO:     Epoch: 44
2023-01-05 05:10:23,931 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4192643016576767, 'Total loss': 0.4192643016576767} | train loss {'Reaction outcome loss': 0.22988220350051683, 'Total loss': 0.22988220350051683}
2023-01-05 05:10:23,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:23,931 INFO:     Epoch: 45
2023-01-05 05:10:26,109 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4051408708095551, 'Total loss': 0.4051408708095551} | train loss {'Reaction outcome loss': 0.2195726007517753, 'Total loss': 0.2195726007517753}
2023-01-05 05:10:26,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:26,109 INFO:     Epoch: 46
2023-01-05 05:10:28,312 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45268942713737487, 'Total loss': 0.45268942713737487} | train loss {'Reaction outcome loss': 0.21995124630410684, 'Total loss': 0.21995124630410684}
2023-01-05 05:10:28,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:28,313 INFO:     Epoch: 47
2023-01-05 05:10:30,491 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3823425491650899, 'Total loss': 0.3823425491650899} | train loss {'Reaction outcome loss': 0.21591481426224599, 'Total loss': 0.21591481426224599}
2023-01-05 05:10:30,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:30,491 INFO:     Epoch: 48
2023-01-05 05:10:32,669 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4030554453531901, 'Total loss': 0.4030554453531901} | train loss {'Reaction outcome loss': 0.21607903760277491, 'Total loss': 0.21607903760277491}
2023-01-05 05:10:32,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:32,669 INFO:     Epoch: 49
2023-01-05 05:10:34,828 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3990886002779007, 'Total loss': 0.3990886002779007} | train loss {'Reaction outcome loss': 0.2157250765265654, 'Total loss': 0.2157250765265654}
2023-01-05 05:10:34,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:34,828 INFO:     Epoch: 50
2023-01-05 05:10:37,080 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39813688695430755, 'Total loss': 0.39813688695430755} | train loss {'Reaction outcome loss': 0.21213202236517184, 'Total loss': 0.21213202236517184}
2023-01-05 05:10:37,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:37,080 INFO:     Epoch: 51
2023-01-05 05:10:39,319 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41446687082449596, 'Total loss': 0.41446687082449596} | train loss {'Reaction outcome loss': 0.22072426306126247, 'Total loss': 0.22072426306126247}
2023-01-05 05:10:39,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:39,320 INFO:     Epoch: 52
2023-01-05 05:10:41,504 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43407823195060097, 'Total loss': 0.43407823195060097} | train loss {'Reaction outcome loss': 0.2126007767412253, 'Total loss': 0.2126007767412253}
2023-01-05 05:10:41,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:41,504 INFO:     Epoch: 53
2023-01-05 05:10:43,740 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4207588384548823, 'Total loss': 0.4207588384548823} | train loss {'Reaction outcome loss': 0.21053437146601145, 'Total loss': 0.21053437146601145}
2023-01-05 05:10:43,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:43,742 INFO:     Epoch: 54
2023-01-05 05:10:45,916 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4313173572222392, 'Total loss': 0.4313173572222392} | train loss {'Reaction outcome loss': 0.20430485139418716, 'Total loss': 0.20430485139418716}
2023-01-05 05:10:45,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:45,917 INFO:     Epoch: 55
2023-01-05 05:10:48,138 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44880878627300264, 'Total loss': 0.44880878627300264} | train loss {'Reaction outcome loss': 0.20159495843952333, 'Total loss': 0.20159495843952333}
2023-01-05 05:10:48,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:48,138 INFO:     Epoch: 56
2023-01-05 05:10:50,403 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3906179351111253, 'Total loss': 0.3906179351111253} | train loss {'Reaction outcome loss': 0.1994907740874518, 'Total loss': 0.1994907740874518}
2023-01-05 05:10:50,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:50,404 INFO:     Epoch: 57
2023-01-05 05:10:52,677 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4281685620546341, 'Total loss': 0.4281685620546341} | train loss {'Reaction outcome loss': 0.20238116227657252, 'Total loss': 0.20238116227657252}
2023-01-05 05:10:52,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:52,678 INFO:     Epoch: 58
2023-01-05 05:10:54,930 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4098123759031296, 'Total loss': 0.4098123759031296} | train loss {'Reaction outcome loss': 0.20373793530608594, 'Total loss': 0.20373793530608594}
2023-01-05 05:10:54,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:54,931 INFO:     Epoch: 59
2023-01-05 05:10:57,202 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41483139026289184, 'Total loss': 0.41483139026289184} | train loss {'Reaction outcome loss': 0.20102327044351379, 'Total loss': 0.20102327044351379}
2023-01-05 05:10:57,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:57,203 INFO:     Epoch: 60
2023-01-05 05:10:59,434 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41801342119773227, 'Total loss': 0.41801342119773227} | train loss {'Reaction outcome loss': 0.1959996929027788, 'Total loss': 0.1959996929027788}
2023-01-05 05:10:59,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:10:59,434 INFO:     Epoch: 61
2023-01-05 05:11:01,680 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4283843850096067, 'Total loss': 0.4283843850096067} | train loss {'Reaction outcome loss': 0.19644947463066142, 'Total loss': 0.19644947463066142}
2023-01-05 05:11:01,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:01,680 INFO:     Epoch: 62
2023-01-05 05:11:03,923 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42680482293168703, 'Total loss': 0.42680482293168703} | train loss {'Reaction outcome loss': 0.1989715245319952, 'Total loss': 0.1989715245319952}
2023-01-05 05:11:03,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:03,924 INFO:     Epoch: 63
2023-01-05 05:11:06,108 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4108620564142863, 'Total loss': 0.4108620564142863} | train loss {'Reaction outcome loss': 0.1968935245776252, 'Total loss': 0.1968935245776252}
2023-01-05 05:11:06,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:06,108 INFO:     Epoch: 64
2023-01-05 05:11:08,343 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3975460668404897, 'Total loss': 0.3975460668404897} | train loss {'Reaction outcome loss': 0.19666202535069938, 'Total loss': 0.19666202535069938}
2023-01-05 05:11:08,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:08,343 INFO:     Epoch: 65
2023-01-05 05:11:10,472 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43347324182589847, 'Total loss': 0.43347324182589847} | train loss {'Reaction outcome loss': 0.20090277370342147, 'Total loss': 0.20090277370342147}
2023-01-05 05:11:10,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:10,472 INFO:     Epoch: 66
2023-01-05 05:11:12,623 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4061599110563596, 'Total loss': 0.4061599110563596} | train loss {'Reaction outcome loss': 0.20985321654934788, 'Total loss': 0.20985321654934788}
2023-01-05 05:11:12,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:12,623 INFO:     Epoch: 67
2023-01-05 05:11:14,889 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40219635168711343, 'Total loss': 0.40219635168711343} | train loss {'Reaction outcome loss': 0.19007995788470525, 'Total loss': 0.19007995788470525}
2023-01-05 05:11:14,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:14,890 INFO:     Epoch: 68
2023-01-05 05:11:17,169 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4289866497119268, 'Total loss': 0.4289866497119268} | train loss {'Reaction outcome loss': 0.18836083355447467, 'Total loss': 0.18836083355447467}
2023-01-05 05:11:17,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:17,169 INFO:     Epoch: 69
2023-01-05 05:11:19,390 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41483085056145985, 'Total loss': 0.41483085056145985} | train loss {'Reaction outcome loss': 0.18648131812396046, 'Total loss': 0.18648131812396046}
2023-01-05 05:11:19,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:19,390 INFO:     Epoch: 70
2023-01-05 05:11:21,659 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4014837404092153, 'Total loss': 0.4014837404092153} | train loss {'Reaction outcome loss': 0.18990643502995913, 'Total loss': 0.18990643502995913}
2023-01-05 05:11:21,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:21,660 INFO:     Epoch: 71
2023-01-05 05:11:23,916 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4418427420159181, 'Total loss': 0.4418427420159181} | train loss {'Reaction outcome loss': 0.21206994319188685, 'Total loss': 0.21206994319188685}
2023-01-05 05:11:23,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:23,917 INFO:     Epoch: 72
2023-01-05 05:11:26,209 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3893870860338211, 'Total loss': 0.3893870860338211} | train loss {'Reaction outcome loss': 0.19473931534161817, 'Total loss': 0.19473931534161817}
2023-01-05 05:11:26,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:26,209 INFO:     Epoch: 73
2023-01-05 05:11:28,508 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4009167303641637, 'Total loss': 0.4009167303641637} | train loss {'Reaction outcome loss': 0.18681465485470666, 'Total loss': 0.18681465485470666}
2023-01-05 05:11:28,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:28,509 INFO:     Epoch: 74
2023-01-05 05:11:30,777 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4127238472302755, 'Total loss': 0.4127238472302755} | train loss {'Reaction outcome loss': 0.17760099293545994, 'Total loss': 0.17760099293545994}
2023-01-05 05:11:30,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:30,777 INFO:     Epoch: 75
2023-01-05 05:11:33,050 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41680029928684237, 'Total loss': 0.41680029928684237} | train loss {'Reaction outcome loss': 0.1831259692232867, 'Total loss': 0.1831259692232867}
2023-01-05 05:11:33,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:33,051 INFO:     Epoch: 76
2023-01-05 05:11:34,992 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4053068558375041, 'Total loss': 0.4053068558375041} | train loss {'Reaction outcome loss': 0.1812325078015393, 'Total loss': 0.1812325078015393}
2023-01-05 05:11:34,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:34,992 INFO:     Epoch: 77
2023-01-05 05:11:36,872 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42207663456598915, 'Total loss': 0.42207663456598915} | train loss {'Reaction outcome loss': 0.18215307817402956, 'Total loss': 0.18215307817402956}
2023-01-05 05:11:36,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:36,873 INFO:     Epoch: 78
2023-01-05 05:11:38,973 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38506136933962504, 'Total loss': 0.38506136933962504} | train loss {'Reaction outcome loss': 0.20343248913928436, 'Total loss': 0.20343248913928436}
2023-01-05 05:11:38,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:38,974 INFO:     Epoch: 79
2023-01-05 05:11:41,232 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39908035174012185, 'Total loss': 0.39908035174012185} | train loss {'Reaction outcome loss': 0.17977182569059855, 'Total loss': 0.17977182569059855}
2023-01-05 05:11:41,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:41,233 INFO:     Epoch: 80
2023-01-05 05:11:43,498 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4642084916432699, 'Total loss': 0.4642084916432699} | train loss {'Reaction outcome loss': 0.17989642236869363, 'Total loss': 0.17989642236869363}
2023-01-05 05:11:43,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:43,499 INFO:     Epoch: 81
2023-01-05 05:11:45,704 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40918463716904324, 'Total loss': 0.40918463716904324} | train loss {'Reaction outcome loss': 0.1775579246129079, 'Total loss': 0.1775579246129079}
2023-01-05 05:11:45,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:45,704 INFO:     Epoch: 82
2023-01-05 05:11:47,960 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4468522757291794, 'Total loss': 0.4468522757291794} | train loss {'Reaction outcome loss': 0.1766293219567371, 'Total loss': 0.1766293219567371}
2023-01-05 05:11:47,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:47,960 INFO:     Epoch: 83
2023-01-05 05:11:50,179 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39132745762666066, 'Total loss': 0.39132745762666066} | train loss {'Reaction outcome loss': 0.17672275033091073, 'Total loss': 0.17672275033091073}
2023-01-05 05:11:50,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:50,180 INFO:     Epoch: 84
2023-01-05 05:11:52,417 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3804872304201126, 'Total loss': 0.3804872304201126} | train loss {'Reaction outcome loss': 0.17793159938984268, 'Total loss': 0.17793159938984268}
2023-01-05 05:11:52,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:52,419 INFO:     Epoch: 85
2023-01-05 05:11:54,653 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4563632806142171, 'Total loss': 0.4563632806142171} | train loss {'Reaction outcome loss': 0.1799273335820307, 'Total loss': 0.1799273335820307}
2023-01-05 05:11:54,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:54,653 INFO:     Epoch: 86
2023-01-05 05:11:56,894 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4333423356215159, 'Total loss': 0.4333423356215159} | train loss {'Reaction outcome loss': 0.19020022632236983, 'Total loss': 0.19020022632236983}
2023-01-05 05:11:56,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:56,894 INFO:     Epoch: 87
2023-01-05 05:11:59,154 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3979731264679382, 'Total loss': 0.3979731264679382} | train loss {'Reaction outcome loss': 0.1821700171498958, 'Total loss': 0.1821700171498958}
2023-01-05 05:11:59,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:11:59,155 INFO:     Epoch: 88
2023-01-05 05:12:01,402 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40957924276590346, 'Total loss': 0.40957924276590346} | train loss {'Reaction outcome loss': 0.20373193942941725, 'Total loss': 0.20373193942941725}
2023-01-05 05:12:01,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:01,402 INFO:     Epoch: 89
2023-01-05 05:12:03,629 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40390942196051277, 'Total loss': 0.40390942196051277} | train loss {'Reaction outcome loss': 0.17594865247593733, 'Total loss': 0.17594865247593733}
2023-01-05 05:12:03,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:03,629 INFO:     Epoch: 90
2023-01-05 05:12:05,947 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42857814182837806, 'Total loss': 0.42857814182837806} | train loss {'Reaction outcome loss': 0.16830703759974247, 'Total loss': 0.16830703759974247}
2023-01-05 05:12:05,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:05,947 INFO:     Epoch: 91
2023-01-05 05:12:08,236 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4108358323574066, 'Total loss': 0.4108358323574066} | train loss {'Reaction outcome loss': 0.16695618070493304, 'Total loss': 0.16695618070493304}
2023-01-05 05:12:08,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:08,236 INFO:     Epoch: 92
2023-01-05 05:12:10,481 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44711924393971764, 'Total loss': 0.44711924393971764} | train loss {'Reaction outcome loss': 0.1717770381314356, 'Total loss': 0.1717770381314356}
2023-01-05 05:12:10,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:10,482 INFO:     Epoch: 93
2023-01-05 05:12:12,689 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4247771461804708, 'Total loss': 0.4247771461804708} | train loss {'Reaction outcome loss': 0.16546399961352226, 'Total loss': 0.16546399961352226}
2023-01-05 05:12:12,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:12,690 INFO:     Epoch: 94
2023-01-05 05:12:14,855 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45483320355415346, 'Total loss': 0.45483320355415346} | train loss {'Reaction outcome loss': 0.17227482954436657, 'Total loss': 0.17227482954436657}
2023-01-05 05:12:14,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:14,855 INFO:     Epoch: 95
2023-01-05 05:12:17,052 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39820420344670615, 'Total loss': 0.39820420344670615} | train loss {'Reaction outcome loss': 0.17037749069319377, 'Total loss': 0.17037749069319377}
2023-01-05 05:12:17,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:17,052 INFO:     Epoch: 96
2023-01-05 05:12:19,222 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41220352947711947, 'Total loss': 0.41220352947711947} | train loss {'Reaction outcome loss': 0.17217357249161147, 'Total loss': 0.17217357249161147}
2023-01-05 05:12:19,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:19,222 INFO:     Epoch: 97
2023-01-05 05:12:21,435 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.439529221256574, 'Total loss': 0.439529221256574} | train loss {'Reaction outcome loss': 0.16866331420369798, 'Total loss': 0.16866331420369798}
2023-01-05 05:12:21,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:21,435 INFO:     Epoch: 98
2023-01-05 05:12:23,625 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4448234309752782, 'Total loss': 0.4448234309752782} | train loss {'Reaction outcome loss': 0.16936559294201975, 'Total loss': 0.16936559294201975}
2023-01-05 05:12:23,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:23,626 INFO:     Epoch: 99
2023-01-05 05:12:25,781 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42800066669782005, 'Total loss': 0.42800066669782005} | train loss {'Reaction outcome loss': 0.17085581151869797, 'Total loss': 0.17085581151869797}
2023-01-05 05:12:25,781 INFO:     Best model found after epoch 24 of 100.
2023-01-05 05:12:25,781 INFO:   Done with stage: TRAINING
2023-01-05 05:12:25,781 INFO:   Starting stage: EVALUATION
2023-01-05 05:12:25,918 INFO:   Done with stage: EVALUATION
2023-01-05 05:12:25,926 INFO:   Leaving out SEQ value Fold_0
2023-01-05 05:12:25,939 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 05:12:25,939 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:12:26,594 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:12:26,595 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:12:26,666 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:12:26,667 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:12:26,667 INFO:     No hyperparam tuning for this model
2023-01-05 05:12:26,667 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:12:26,667 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:12:26,668 INFO:     None feature selector for col prot
2023-01-05 05:12:26,668 INFO:     None feature selector for col prot
2023-01-05 05:12:26,668 INFO:     None feature selector for col prot
2023-01-05 05:12:26,668 INFO:     None feature selector for col chem
2023-01-05 05:12:26,668 INFO:     None feature selector for col chem
2023-01-05 05:12:26,668 INFO:     None feature selector for col chem
2023-01-05 05:12:26,669 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:12:26,669 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:12:26,670 INFO:     Number of params in model 72931
2023-01-05 05:12:26,673 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:12:26,673 INFO:   Starting stage: TRAINING
2023-01-05 05:12:26,735 INFO:     Val loss before train {'Reaction outcome loss': 1.0006135066350301, 'Total loss': 1.0006135066350301}
2023-01-05 05:12:26,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:26,736 INFO:     Epoch: 0
2023-01-05 05:12:28,893 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7967765688896179, 'Total loss': 0.7967765688896179} | train loss {'Reaction outcome loss': 0.9570509162697479, 'Total loss': 0.9570509162697479}
2023-01-05 05:12:28,894 INFO:     Found new best model at epoch 0
2023-01-05 05:12:28,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:28,895 INFO:     Epoch: 1
2023-01-05 05:12:31,059 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5666225145260493, 'Total loss': 0.5666225145260493} | train loss {'Reaction outcome loss': 0.6604319041880378, 'Total loss': 0.6604319041880378}
2023-01-05 05:12:31,059 INFO:     Found new best model at epoch 1
2023-01-05 05:12:31,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:31,060 INFO:     Epoch: 2
2023-01-05 05:12:33,239 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5346620996793111, 'Total loss': 0.5346620996793111} | train loss {'Reaction outcome loss': 0.5399688800429776, 'Total loss': 0.5399688800429776}
2023-01-05 05:12:33,239 INFO:     Found new best model at epoch 2
2023-01-05 05:12:33,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:33,241 INFO:     Epoch: 3
2023-01-05 05:12:35,431 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5074410051107406, 'Total loss': 0.5074410051107406} | train loss {'Reaction outcome loss': 0.49385701272174387, 'Total loss': 0.49385701272174387}
2023-01-05 05:12:35,431 INFO:     Found new best model at epoch 3
2023-01-05 05:12:35,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:35,432 INFO:     Epoch: 4
2023-01-05 05:12:37,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47370614210764567, 'Total loss': 0.47370614210764567} | train loss {'Reaction outcome loss': 0.4588852760783077, 'Total loss': 0.4588852760783077}
2023-01-05 05:12:37,657 INFO:     Found new best model at epoch 4
2023-01-05 05:12:37,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:37,658 INFO:     Epoch: 5
2023-01-05 05:12:39,843 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48897747993469237, 'Total loss': 0.48897747993469237} | train loss {'Reaction outcome loss': 0.43668481223557115, 'Total loss': 0.43668481223557115}
2023-01-05 05:12:39,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:39,843 INFO:     Epoch: 6
2023-01-05 05:12:42,061 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4665204723676046, 'Total loss': 0.4665204723676046} | train loss {'Reaction outcome loss': 0.4237776122660968, 'Total loss': 0.4237776122660968}
2023-01-05 05:12:42,061 INFO:     Found new best model at epoch 6
2023-01-05 05:12:42,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:42,062 INFO:     Epoch: 7
2023-01-05 05:12:44,282 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4782122860352198, 'Total loss': 0.4782122860352198} | train loss {'Reaction outcome loss': 0.4044528872481663, 'Total loss': 0.4044528872481663}
2023-01-05 05:12:44,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:44,282 INFO:     Epoch: 8
2023-01-05 05:12:46,467 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4723517994085948, 'Total loss': 0.4723517994085948} | train loss {'Reaction outcome loss': 0.3928937517704755, 'Total loss': 0.3928937517704755}
2023-01-05 05:12:46,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:46,468 INFO:     Epoch: 9
2023-01-05 05:12:48,685 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5238102316856384, 'Total loss': 0.5238102316856384} | train loss {'Reaction outcome loss': 0.3802417892228513, 'Total loss': 0.3802417892228513}
2023-01-05 05:12:48,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:48,685 INFO:     Epoch: 10
2023-01-05 05:12:50,893 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48945212761561074, 'Total loss': 0.48945212761561074} | train loss {'Reaction outcome loss': 0.3690476172270566, 'Total loss': 0.3690476172270566}
2023-01-05 05:12:50,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:50,893 INFO:     Epoch: 11
2023-01-05 05:12:53,067 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47916253109773, 'Total loss': 0.47916253109773} | train loss {'Reaction outcome loss': 0.3569023502025291, 'Total loss': 0.3569023502025291}
2023-01-05 05:12:53,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:53,067 INFO:     Epoch: 12
2023-01-05 05:12:55,280 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46098170230786006, 'Total loss': 0.46098170230786006} | train loss {'Reaction outcome loss': 0.3532170541584492, 'Total loss': 0.3532170541584492}
2023-01-05 05:12:55,280 INFO:     Found new best model at epoch 12
2023-01-05 05:12:55,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:55,282 INFO:     Epoch: 13
2023-01-05 05:12:57,514 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4498473564783732, 'Total loss': 0.4498473564783732} | train loss {'Reaction outcome loss': 0.3429676700845687, 'Total loss': 0.3429676700845687}
2023-01-05 05:12:57,515 INFO:     Found new best model at epoch 13
2023-01-05 05:12:57,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:57,517 INFO:     Epoch: 14
2023-01-05 05:12:59,697 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48639390915632247, 'Total loss': 0.48639390915632247} | train loss {'Reaction outcome loss': 0.33436725908604853, 'Total loss': 0.33436725908604853}
2023-01-05 05:12:59,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:12:59,697 INFO:     Epoch: 15
2023-01-05 05:13:01,938 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4889483332633972, 'Total loss': 0.4889483332633972} | train loss {'Reaction outcome loss': 0.32657463215019583, 'Total loss': 0.32657463215019583}
2023-01-05 05:13:01,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:01,938 INFO:     Epoch: 16
2023-01-05 05:13:04,084 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4680346230665843, 'Total loss': 0.4680346230665843} | train loss {'Reaction outcome loss': 0.32397446397991075, 'Total loss': 0.32397446397991075}
2023-01-05 05:13:04,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:04,085 INFO:     Epoch: 17
2023-01-05 05:13:06,315 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4549092988173167, 'Total loss': 0.4549092988173167} | train loss {'Reaction outcome loss': 0.31705814309037517, 'Total loss': 0.31705814309037517}
2023-01-05 05:13:06,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:06,315 INFO:     Epoch: 18
2023-01-05 05:13:08,501 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44973064760367076, 'Total loss': 0.44973064760367076} | train loss {'Reaction outcome loss': 0.3136295182698399, 'Total loss': 0.3136295182698399}
2023-01-05 05:13:08,501 INFO:     Found new best model at epoch 18
2023-01-05 05:13:08,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:08,502 INFO:     Epoch: 19
2023-01-05 05:13:10,723 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4612871875365575, 'Total loss': 0.4612871875365575} | train loss {'Reaction outcome loss': 0.2991853393614292, 'Total loss': 0.2991853393614292}
2023-01-05 05:13:10,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:10,723 INFO:     Epoch: 20
2023-01-05 05:13:12,903 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45647809008757273, 'Total loss': 0.45647809008757273} | train loss {'Reaction outcome loss': 0.30141004070258925, 'Total loss': 0.30141004070258925}
2023-01-05 05:13:12,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:12,903 INFO:     Epoch: 21
2023-01-05 05:13:15,152 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48474312921365104, 'Total loss': 0.48474312921365104} | train loss {'Reaction outcome loss': 0.2932148209779802, 'Total loss': 0.2932148209779802}
2023-01-05 05:13:15,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:15,153 INFO:     Epoch: 22
2023-01-05 05:13:17,356 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45284262448549273, 'Total loss': 0.45284262448549273} | train loss {'Reaction outcome loss': 0.29003236872436355, 'Total loss': 0.29003236872436355}
2023-01-05 05:13:17,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:17,357 INFO:     Epoch: 23
2023-01-05 05:13:19,562 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4659596472978592, 'Total loss': 0.4659596472978592} | train loss {'Reaction outcome loss': 0.28268192724807417, 'Total loss': 0.28268192724807417}
2023-01-05 05:13:19,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:19,562 INFO:     Epoch: 24
2023-01-05 05:13:21,804 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4557617341478666, 'Total loss': 0.4557617341478666} | train loss {'Reaction outcome loss': 0.27886057696747085, 'Total loss': 0.27886057696747085}
2023-01-05 05:13:21,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:21,804 INFO:     Epoch: 25
2023-01-05 05:13:24,088 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4589923510948817, 'Total loss': 0.4589923510948817} | train loss {'Reaction outcome loss': 0.2757612294823366, 'Total loss': 0.2757612294823366}
2023-01-05 05:13:24,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:24,088 INFO:     Epoch: 26
2023-01-05 05:13:26,325 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4573411886890729, 'Total loss': 0.4573411886890729} | train loss {'Reaction outcome loss': 0.26893952013040984, 'Total loss': 0.26893952013040984}
2023-01-05 05:13:26,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:26,325 INFO:     Epoch: 27
2023-01-05 05:13:28,494 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4635844816764196, 'Total loss': 0.4635844816764196} | train loss {'Reaction outcome loss': 0.262917188995511, 'Total loss': 0.262917188995511}
2023-01-05 05:13:28,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:28,495 INFO:     Epoch: 28
2023-01-05 05:13:30,727 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4435143892963727, 'Total loss': 0.4435143892963727} | train loss {'Reaction outcome loss': 0.264527207328836, 'Total loss': 0.264527207328836}
2023-01-05 05:13:30,727 INFO:     Found new best model at epoch 28
2023-01-05 05:13:30,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:30,729 INFO:     Epoch: 29
2023-01-05 05:13:32,910 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45174153049786886, 'Total loss': 0.45174153049786886} | train loss {'Reaction outcome loss': 0.2614439488626527, 'Total loss': 0.2614439488626527}
2023-01-05 05:13:32,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:32,912 INFO:     Epoch: 30
2023-01-05 05:13:35,137 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4505277037620544, 'Total loss': 0.4505277037620544} | train loss {'Reaction outcome loss': 0.25367980890220754, 'Total loss': 0.25367980890220754}
2023-01-05 05:13:35,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:35,137 INFO:     Epoch: 31
2023-01-05 05:13:37,382 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4550942594806353, 'Total loss': 0.4550942594806353} | train loss {'Reaction outcome loss': 0.2515030754050308, 'Total loss': 0.2515030754050308}
2023-01-05 05:13:37,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:37,382 INFO:     Epoch: 32
2023-01-05 05:13:39,543 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46337358554204305, 'Total loss': 0.46337358554204305} | train loss {'Reaction outcome loss': 0.250536242363988, 'Total loss': 0.250536242363988}
2023-01-05 05:13:39,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:39,544 INFO:     Epoch: 33
2023-01-05 05:13:41,772 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4572669416666031, 'Total loss': 0.4572669416666031} | train loss {'Reaction outcome loss': 0.24498815619706238, 'Total loss': 0.24498815619706238}
2023-01-05 05:13:41,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:41,773 INFO:     Epoch: 34
2023-01-05 05:13:44,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4686339110136032, 'Total loss': 0.4686339110136032} | train loss {'Reaction outcome loss': 0.24347903208304061, 'Total loss': 0.24347903208304061}
2023-01-05 05:13:44,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:44,008 INFO:     Epoch: 35
2023-01-05 05:13:46,234 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4841674307982127, 'Total loss': 0.4841674307982127} | train loss {'Reaction outcome loss': 0.2406614524971721, 'Total loss': 0.2406614524971721}
2023-01-05 05:13:46,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:46,234 INFO:     Epoch: 36
2023-01-05 05:13:48,472 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4716040074825287, 'Total loss': 0.4716040074825287} | train loss {'Reaction outcome loss': 0.23643871511665793, 'Total loss': 0.23643871511665793}
2023-01-05 05:13:48,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:48,472 INFO:     Epoch: 37
2023-01-05 05:13:50,713 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5095499406258265, 'Total loss': 0.5095499406258265} | train loss {'Reaction outcome loss': 0.23439982700005282, 'Total loss': 0.23439982700005282}
2023-01-05 05:13:50,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:50,713 INFO:     Epoch: 38
2023-01-05 05:13:52,948 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47878140211105347, 'Total loss': 0.47878140211105347} | train loss {'Reaction outcome loss': 0.23426539290451656, 'Total loss': 0.23426539290451656}
2023-01-05 05:13:52,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:52,949 INFO:     Epoch: 39
2023-01-05 05:13:55,188 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4736674944559733, 'Total loss': 0.4736674944559733} | train loss {'Reaction outcome loss': 0.22712222361651652, 'Total loss': 0.22712222361651652}
2023-01-05 05:13:55,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:55,189 INFO:     Epoch: 40
2023-01-05 05:13:57,426 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48411139051119484, 'Total loss': 0.48411139051119484} | train loss {'Reaction outcome loss': 0.22816317056706786, 'Total loss': 0.22816317056706786}
2023-01-05 05:13:57,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:57,426 INFO:     Epoch: 41
2023-01-05 05:13:59,658 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44708350201447805, 'Total loss': 0.44708350201447805} | train loss {'Reaction outcome loss': 0.22076471862349198, 'Total loss': 0.22076471862349198}
2023-01-05 05:13:59,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:13:59,658 INFO:     Epoch: 42
2023-01-05 05:14:01,810 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4838580826918284, 'Total loss': 0.4838580826918284} | train loss {'Reaction outcome loss': 0.22692145277698436, 'Total loss': 0.22692145277698436}
2023-01-05 05:14:01,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:01,810 INFO:     Epoch: 43
2023-01-05 05:14:04,049 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45319835990667345, 'Total loss': 0.45319835990667345} | train loss {'Reaction outcome loss': 0.22194466428545706, 'Total loss': 0.22194466428545706}
2023-01-05 05:14:04,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:04,050 INFO:     Epoch: 44
2023-01-05 05:14:06,227 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5112850079933803, 'Total loss': 0.5112850079933803} | train loss {'Reaction outcome loss': 0.2186938831412716, 'Total loss': 0.2186938831412716}
2023-01-05 05:14:06,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:06,227 INFO:     Epoch: 45
2023-01-05 05:14:08,445 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4906694193681081, 'Total loss': 0.4906694193681081} | train loss {'Reaction outcome loss': 0.2177405067971044, 'Total loss': 0.2177405067971044}
2023-01-05 05:14:08,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:08,445 INFO:     Epoch: 46
2023-01-05 05:14:10,684 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49832375546296437, 'Total loss': 0.49832375546296437} | train loss {'Reaction outcome loss': 0.21739396048424237, 'Total loss': 0.21739396048424237}
2023-01-05 05:14:10,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:10,685 INFO:     Epoch: 47
2023-01-05 05:14:12,869 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5323851098616917, 'Total loss': 0.5323851098616917} | train loss {'Reaction outcome loss': 0.21158098862982308, 'Total loss': 0.21158098862982308}
2023-01-05 05:14:12,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:12,869 INFO:     Epoch: 48
2023-01-05 05:14:15,111 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4702880889177322, 'Total loss': 0.4702880889177322} | train loss {'Reaction outcome loss': 0.21090553904183373, 'Total loss': 0.21090553904183373}
2023-01-05 05:14:15,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:15,111 INFO:     Epoch: 49
2023-01-05 05:14:17,312 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46306503415107725, 'Total loss': 0.46306503415107725} | train loss {'Reaction outcome loss': 0.2112827372404128, 'Total loss': 0.2112827372404128}
2023-01-05 05:14:17,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:17,313 INFO:     Epoch: 50
2023-01-05 05:14:19,563 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4660383274157842, 'Total loss': 0.4660383274157842} | train loss {'Reaction outcome loss': 0.21134980773743595, 'Total loss': 0.21134980773743595}
2023-01-05 05:14:19,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:19,563 INFO:     Epoch: 51
2023-01-05 05:14:21,748 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4651890903711319, 'Total loss': 0.4651890903711319} | train loss {'Reaction outcome loss': 0.20902226865121645, 'Total loss': 0.20902226865121645}
2023-01-05 05:14:21,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:21,748 INFO:     Epoch: 52
2023-01-05 05:14:24,013 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48403466045856475, 'Total loss': 0.48403466045856475} | train loss {'Reaction outcome loss': 0.20503299296527666, 'Total loss': 0.20503299296527666}
2023-01-05 05:14:24,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:24,013 INFO:     Epoch: 53
2023-01-05 05:14:26,333 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4550228014588356, 'Total loss': 0.4550228014588356} | train loss {'Reaction outcome loss': 0.20499719818034312, 'Total loss': 0.20499719818034312}
2023-01-05 05:14:26,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:26,333 INFO:     Epoch: 54
2023-01-05 05:14:28,502 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49533097445964813, 'Total loss': 0.49533097445964813} | train loss {'Reaction outcome loss': 0.20217526588507378, 'Total loss': 0.20217526588507378}
2023-01-05 05:14:28,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:28,503 INFO:     Epoch: 55
2023-01-05 05:14:30,618 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4605223913987478, 'Total loss': 0.4605223913987478} | train loss {'Reaction outcome loss': 0.20340767974224294, 'Total loss': 0.20340767974224294}
2023-01-05 05:14:30,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:30,619 INFO:     Epoch: 56
2023-01-05 05:14:32,803 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4546003915369511, 'Total loss': 0.4546003915369511} | train loss {'Reaction outcome loss': 0.20040046123543034, 'Total loss': 0.20040046123543034}
2023-01-05 05:14:32,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:32,804 INFO:     Epoch: 57
2023-01-05 05:14:34,960 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.493646956483523, 'Total loss': 0.493646956483523} | train loss {'Reaction outcome loss': 0.1978560410793463, 'Total loss': 0.1978560410793463}
2023-01-05 05:14:34,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:34,960 INFO:     Epoch: 58
2023-01-05 05:14:37,175 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4665888864547014, 'Total loss': 0.4665888864547014} | train loss {'Reaction outcome loss': 0.20005513593404942, 'Total loss': 0.20005513593404942}
2023-01-05 05:14:37,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:37,175 INFO:     Epoch: 59
2023-01-05 05:14:39,378 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47109096745649975, 'Total loss': 0.47109096745649975} | train loss {'Reaction outcome loss': 0.1955259190736352, 'Total loss': 0.1955259190736352}
2023-01-05 05:14:39,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:39,379 INFO:     Epoch: 60
2023-01-05 05:14:41,581 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49644153912862143, 'Total loss': 0.49644153912862143} | train loss {'Reaction outcome loss': 0.19716816758193131, 'Total loss': 0.19716816758193131}
2023-01-05 05:14:41,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:41,581 INFO:     Epoch: 61
2023-01-05 05:14:43,703 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44856834212938945, 'Total loss': 0.44856834212938945} | train loss {'Reaction outcome loss': 0.19392994138833652, 'Total loss': 0.19392994138833652}
2023-01-05 05:14:43,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:43,703 INFO:     Epoch: 62
2023-01-05 05:14:45,934 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4725381841262182, 'Total loss': 0.4725381841262182} | train loss {'Reaction outcome loss': 0.19463864949796975, 'Total loss': 0.19463864949796975}
2023-01-05 05:14:45,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:45,936 INFO:     Epoch: 63
2023-01-05 05:14:48,168 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5099970738093058, 'Total loss': 0.5099970738093058} | train loss {'Reaction outcome loss': 0.18979431189644239, 'Total loss': 0.18979431189644239}
2023-01-05 05:14:48,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:48,169 INFO:     Epoch: 64
2023-01-05 05:14:50,419 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48531791965166726, 'Total loss': 0.48531791965166726} | train loss {'Reaction outcome loss': 0.1868721719764948, 'Total loss': 0.1868721719764948}
2023-01-05 05:14:50,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:50,419 INFO:     Epoch: 65
2023-01-05 05:14:52,608 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5348649263381958, 'Total loss': 0.5348649263381958} | train loss {'Reaction outcome loss': 0.18009644020756665, 'Total loss': 0.18009644020756665}
2023-01-05 05:14:52,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:52,609 INFO:     Epoch: 66
2023-01-05 05:14:54,840 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45850370029608406, 'Total loss': 0.45850370029608406} | train loss {'Reaction outcome loss': 0.1891755647634421, 'Total loss': 0.1891755647634421}
2023-01-05 05:14:54,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:54,841 INFO:     Epoch: 67
2023-01-05 05:14:57,095 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5202981809775035, 'Total loss': 0.5202981809775035} | train loss {'Reaction outcome loss': 0.18156259722096751, 'Total loss': 0.18156259722096751}
2023-01-05 05:14:57,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:57,095 INFO:     Epoch: 68
2023-01-05 05:14:59,294 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5208919286727905, 'Total loss': 0.5208919286727905} | train loss {'Reaction outcome loss': 0.18526323808248352, 'Total loss': 0.18526323808248352}
2023-01-05 05:14:59,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:14:59,294 INFO:     Epoch: 69
2023-01-05 05:15:01,533 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5000268069406351, 'Total loss': 0.5000268069406351} | train loss {'Reaction outcome loss': 0.18559460361984415, 'Total loss': 0.18559460361984415}
2023-01-05 05:15:01,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:01,533 INFO:     Epoch: 70
2023-01-05 05:15:03,730 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5248440504074097, 'Total loss': 0.5248440504074097} | train loss {'Reaction outcome loss': 0.18524191234206414, 'Total loss': 0.18524191234206414}
2023-01-05 05:15:03,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:03,730 INFO:     Epoch: 71
2023-01-05 05:15:05,889 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5030831436316172, 'Total loss': 0.5030831436316172} | train loss {'Reaction outcome loss': 0.17800068094932142, 'Total loss': 0.17800068094932142}
2023-01-05 05:15:05,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:05,890 INFO:     Epoch: 72
2023-01-05 05:15:08,023 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5022742589314778, 'Total loss': 0.5022742589314778} | train loss {'Reaction outcome loss': 0.18439829934143673, 'Total loss': 0.18439829934143673}
2023-01-05 05:15:08,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:08,024 INFO:     Epoch: 73
2023-01-05 05:15:10,188 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49335195422172545, 'Total loss': 0.49335195422172545} | train loss {'Reaction outcome loss': 0.1851313537459168, 'Total loss': 0.1851313537459168}
2023-01-05 05:15:10,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:10,188 INFO:     Epoch: 74
2023-01-05 05:15:12,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.514594500263532, 'Total loss': 0.514594500263532} | train loss {'Reaction outcome loss': 0.1816300175723749, 'Total loss': 0.1816300175723749}
2023-01-05 05:15:12,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:12,402 INFO:     Epoch: 75
2023-01-05 05:15:14,607 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4791679660479228, 'Total loss': 0.4791679660479228} | train loss {'Reaction outcome loss': 0.17780484717142137, 'Total loss': 0.17780484717142137}
2023-01-05 05:15:14,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:14,607 INFO:     Epoch: 76
2023-01-05 05:15:16,816 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5208520789941152, 'Total loss': 0.5208520789941152} | train loss {'Reaction outcome loss': 0.1786437066625396, 'Total loss': 0.1786437066625396}
2023-01-05 05:15:16,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:16,817 INFO:     Epoch: 77
2023-01-05 05:15:18,959 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4862871011098226, 'Total loss': 0.4862871011098226} | train loss {'Reaction outcome loss': 0.17663280675051748, 'Total loss': 0.17663280675051748}
2023-01-05 05:15:18,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:18,960 INFO:     Epoch: 78
2023-01-05 05:15:21,165 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5403524984916052, 'Total loss': 0.5403524984916052} | train loss {'Reaction outcome loss': 0.17892603609153498, 'Total loss': 0.17892603609153498}
2023-01-05 05:15:21,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:21,165 INFO:     Epoch: 79
2023-01-05 05:15:23,386 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.504999836285909, 'Total loss': 0.504999836285909} | train loss {'Reaction outcome loss': 0.1714516076000992, 'Total loss': 0.1714516076000992}
2023-01-05 05:15:23,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:23,387 INFO:     Epoch: 80
2023-01-05 05:15:25,568 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5202071348826091, 'Total loss': 0.5202071348826091} | train loss {'Reaction outcome loss': 0.1768268915624052, 'Total loss': 0.1768268915624052}
2023-01-05 05:15:25,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:25,568 INFO:     Epoch: 81
2023-01-05 05:15:27,767 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5126895268758138, 'Total loss': 0.5126895268758138} | train loss {'Reaction outcome loss': 0.17172570842535773, 'Total loss': 0.17172570842535773}
2023-01-05 05:15:27,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:27,767 INFO:     Epoch: 82
2023-01-05 05:15:29,974 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5110005396107833, 'Total loss': 0.5110005396107833} | train loss {'Reaction outcome loss': 0.17547956872459528, 'Total loss': 0.17547956872459528}
2023-01-05 05:15:29,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:29,974 INFO:     Epoch: 83
2023-01-05 05:15:32,135 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4833950047691663, 'Total loss': 0.4833950047691663} | train loss {'Reaction outcome loss': 0.17532782454764212, 'Total loss': 0.17532782454764212}
2023-01-05 05:15:32,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:32,135 INFO:     Epoch: 84
2023-01-05 05:15:34,379 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4997704227765401, 'Total loss': 0.4997704227765401} | train loss {'Reaction outcome loss': 0.1728496759208803, 'Total loss': 0.1728496759208803}
2023-01-05 05:15:34,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:34,379 INFO:     Epoch: 85
2023-01-05 05:15:36,578 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4968604808052381, 'Total loss': 0.4968604808052381} | train loss {'Reaction outcome loss': 0.1763398334839429, 'Total loss': 0.1763398334839429}
2023-01-05 05:15:36,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:36,579 INFO:     Epoch: 86
2023-01-05 05:15:38,771 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4840348932892084, 'Total loss': 0.4840348932892084} | train loss {'Reaction outcome loss': 0.17307894915532673, 'Total loss': 0.17307894915532673}
2023-01-05 05:15:38,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:38,771 INFO:     Epoch: 87
2023-01-05 05:15:40,979 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5011181950569152, 'Total loss': 0.5011181950569152} | train loss {'Reaction outcome loss': 0.17196973849658984, 'Total loss': 0.17196973849658984}
2023-01-05 05:15:40,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:40,980 INFO:     Epoch: 88
2023-01-05 05:15:43,180 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4786861141522725, 'Total loss': 0.4786861141522725} | train loss {'Reaction outcome loss': 0.17241247611827332, 'Total loss': 0.17241247611827332}
2023-01-05 05:15:43,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:43,180 INFO:     Epoch: 89
2023-01-05 05:15:45,368 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4569088558355967, 'Total loss': 0.4569088558355967} | train loss {'Reaction outcome loss': 0.17107614264721527, 'Total loss': 0.17107614264721527}
2023-01-05 05:15:45,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:45,368 INFO:     Epoch: 90
2023-01-05 05:15:47,616 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48407603005568184, 'Total loss': 0.48407603005568184} | train loss {'Reaction outcome loss': 0.16583464384405283, 'Total loss': 0.16583464384405283}
2023-01-05 05:15:47,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:47,617 INFO:     Epoch: 91
2023-01-05 05:15:49,869 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4888843268156052, 'Total loss': 0.4888843268156052} | train loss {'Reaction outcome loss': 0.16911548520030495, 'Total loss': 0.16911548520030495}
2023-01-05 05:15:49,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:49,870 INFO:     Epoch: 92
2023-01-05 05:15:52,097 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48906185825665793, 'Total loss': 0.48906185825665793} | train loss {'Reaction outcome loss': 0.1648980153275885, 'Total loss': 0.1648980153275885}
2023-01-05 05:15:52,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:52,097 INFO:     Epoch: 93
2023-01-05 05:15:54,342 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5033500889937083, 'Total loss': 0.5033500889937083} | train loss {'Reaction outcome loss': 0.16144844422449978, 'Total loss': 0.16144844422449978}
2023-01-05 05:15:54,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:54,343 INFO:     Epoch: 94
2023-01-05 05:15:56,577 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4844814876715342, 'Total loss': 0.4844814876715342} | train loss {'Reaction outcome loss': 0.17248160071181554, 'Total loss': 0.17248160071181554}
2023-01-05 05:15:56,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:56,577 INFO:     Epoch: 95
2023-01-05 05:15:58,787 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48189304371674857, 'Total loss': 0.48189304371674857} | train loss {'Reaction outcome loss': 0.16708161921519107, 'Total loss': 0.16708161921519107}
2023-01-05 05:15:58,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:15:58,787 INFO:     Epoch: 96
2023-01-05 05:16:00,923 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4944501221179962, 'Total loss': 0.4944501221179962} | train loss {'Reaction outcome loss': 0.16791467169082186, 'Total loss': 0.16791467169082186}
2023-01-05 05:16:00,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:00,923 INFO:     Epoch: 97
2023-01-05 05:16:03,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5107250849405924, 'Total loss': 0.5107250849405924} | train loss {'Reaction outcome loss': 0.1745834379239402, 'Total loss': 0.1745834379239402}
2023-01-05 05:16:03,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:03,088 INFO:     Epoch: 98
2023-01-05 05:16:05,279 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48865836958090464, 'Total loss': 0.48865836958090464} | train loss {'Reaction outcome loss': 0.1671869493205182, 'Total loss': 0.1671869493205182}
2023-01-05 05:16:05,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:05,279 INFO:     Epoch: 99
2023-01-05 05:16:07,315 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.531522320707639, 'Total loss': 0.531522320707639} | train loss {'Reaction outcome loss': 0.1639683277381883, 'Total loss': 0.1639683277381883}
2023-01-05 05:16:07,316 INFO:     Best model found after epoch 29 of 100.
2023-01-05 05:16:07,316 INFO:   Done with stage: TRAINING
2023-01-05 05:16:07,316 INFO:   Starting stage: EVALUATION
2023-01-05 05:16:07,459 INFO:   Done with stage: EVALUATION
2023-01-05 05:16:07,459 INFO:   Leaving out SEQ value Fold_1
2023-01-05 05:16:07,472 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 05:16:07,472 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:16:08,117 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:16:08,117 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:16:08,189 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:16:08,190 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:16:08,190 INFO:     No hyperparam tuning for this model
2023-01-05 05:16:08,190 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:16:08,190 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:16:08,191 INFO:     None feature selector for col prot
2023-01-05 05:16:08,191 INFO:     None feature selector for col prot
2023-01-05 05:16:08,191 INFO:     None feature selector for col prot
2023-01-05 05:16:08,191 INFO:     None feature selector for col chem
2023-01-05 05:16:08,191 INFO:     None feature selector for col chem
2023-01-05 05:16:08,191 INFO:     None feature selector for col chem
2023-01-05 05:16:08,192 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:16:08,192 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:16:08,193 INFO:     Number of params in model 72931
2023-01-05 05:16:08,196 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:16:08,196 INFO:   Starting stage: TRAINING
2023-01-05 05:16:08,257 INFO:     Val loss before train {'Reaction outcome loss': 0.9609108805656433, 'Total loss': 0.9609108805656433}
2023-01-05 05:16:08,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:08,257 INFO:     Epoch: 0
2023-01-05 05:16:10,464 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7287513832251231, 'Total loss': 0.7287513832251231} | train loss {'Reaction outcome loss': 0.965418839984106, 'Total loss': 0.965418839984106}
2023-01-05 05:16:10,465 INFO:     Found new best model at epoch 0
2023-01-05 05:16:10,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:10,466 INFO:     Epoch: 1
2023-01-05 05:16:12,654 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44255599776903787, 'Total loss': 0.44255599776903787} | train loss {'Reaction outcome loss': 0.6809600202482698, 'Total loss': 0.6809600202482698}
2023-01-05 05:16:12,655 INFO:     Found new best model at epoch 1
2023-01-05 05:16:12,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:12,656 INFO:     Epoch: 2
2023-01-05 05:16:14,859 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.40080301463603973, 'Total loss': 0.40080301463603973} | train loss {'Reaction outcome loss': 0.5481671486800407, 'Total loss': 0.5481671486800407}
2023-01-05 05:16:14,859 INFO:     Found new best model at epoch 2
2023-01-05 05:16:14,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:14,861 INFO:     Epoch: 3
2023-01-05 05:16:17,079 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.38913945605357486, 'Total loss': 0.38913945605357486} | train loss {'Reaction outcome loss': 0.4989812665861168, 'Total loss': 0.4989812665861168}
2023-01-05 05:16:17,080 INFO:     Found new best model at epoch 3
2023-01-05 05:16:17,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:17,081 INFO:     Epoch: 4
2023-01-05 05:16:19,310 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40750423868497215, 'Total loss': 0.40750423868497215} | train loss {'Reaction outcome loss': 0.4766574509087063, 'Total loss': 0.4766574509087063}
2023-01-05 05:16:19,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:19,310 INFO:     Epoch: 5
2023-01-05 05:16:21,546 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39169748226801554, 'Total loss': 0.39169748226801554} | train loss {'Reaction outcome loss': 0.45279805525973604, 'Total loss': 0.45279805525973604}
2023-01-05 05:16:21,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:21,546 INFO:     Epoch: 6
2023-01-05 05:16:23,742 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37353097796440127, 'Total loss': 0.37353097796440127} | train loss {'Reaction outcome loss': 0.43293303704305447, 'Total loss': 0.43293303704305447}
2023-01-05 05:16:23,742 INFO:     Found new best model at epoch 6
2023-01-05 05:16:23,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:23,744 INFO:     Epoch: 7
2023-01-05 05:16:25,892 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.36423526306947074, 'Total loss': 0.36423526306947074} | train loss {'Reaction outcome loss': 0.42245901553403764, 'Total loss': 0.42245901553403764}
2023-01-05 05:16:25,892 INFO:     Found new best model at epoch 7
2023-01-05 05:16:25,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:25,893 INFO:     Epoch: 8
2023-01-05 05:16:28,090 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3862554808457693, 'Total loss': 0.3862554808457693} | train loss {'Reaction outcome loss': 0.4052336855685755, 'Total loss': 0.4052336855685755}
2023-01-05 05:16:28,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:28,090 INFO:     Epoch: 9
2023-01-05 05:16:30,286 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.382178388039271, 'Total loss': 0.382178388039271} | train loss {'Reaction outcome loss': 0.3902438367570276, 'Total loss': 0.3902438367570276}
2023-01-05 05:16:30,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:30,286 INFO:     Epoch: 10
2023-01-05 05:16:32,451 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3742293765147527, 'Total loss': 0.3742293765147527} | train loss {'Reaction outcome loss': 0.38217309264691324, 'Total loss': 0.38217309264691324}
2023-01-05 05:16:32,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:32,451 INFO:     Epoch: 11
2023-01-05 05:16:34,628 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3996026506026586, 'Total loss': 0.3996026506026586} | train loss {'Reaction outcome loss': 0.37572715289535974, 'Total loss': 0.37572715289535974}
2023-01-05 05:16:34,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:34,628 INFO:     Epoch: 12
2023-01-05 05:16:36,804 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3838030497233073, 'Total loss': 0.3838030497233073} | train loss {'Reaction outcome loss': 0.360623911405221, 'Total loss': 0.360623911405221}
2023-01-05 05:16:36,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:36,805 INFO:     Epoch: 13
2023-01-05 05:16:38,994 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39461923042933145, 'Total loss': 0.39461923042933145} | train loss {'Reaction outcome loss': 0.3489004198884789, 'Total loss': 0.3489004198884789}
2023-01-05 05:16:38,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:38,994 INFO:     Epoch: 14
2023-01-05 05:16:41,217 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3868539571762085, 'Total loss': 0.3868539571762085} | train loss {'Reaction outcome loss': 0.3419997106978308, 'Total loss': 0.3419997106978308}
2023-01-05 05:16:41,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:41,217 INFO:     Epoch: 15
2023-01-05 05:16:43,332 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37799155761798225, 'Total loss': 0.37799155761798225} | train loss {'Reaction outcome loss': 0.3355949568961348, 'Total loss': 0.3355949568961348}
2023-01-05 05:16:43,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:43,332 INFO:     Epoch: 16
2023-01-05 05:16:45,475 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37967368761698406, 'Total loss': 0.37967368761698406} | train loss {'Reaction outcome loss': 0.32588445040441694, 'Total loss': 0.32588445040441694}
2023-01-05 05:16:45,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:45,476 INFO:     Epoch: 17
2023-01-05 05:16:47,644 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3776460905869802, 'Total loss': 0.3776460905869802} | train loss {'Reaction outcome loss': 0.32018982347155556, 'Total loss': 0.32018982347155556}
2023-01-05 05:16:47,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:47,644 INFO:     Epoch: 18
2023-01-05 05:16:49,853 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3842220822970072, 'Total loss': 0.3842220822970072} | train loss {'Reaction outcome loss': 0.30919608050759456, 'Total loss': 0.30919608050759456}
2023-01-05 05:16:49,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:49,854 INFO:     Epoch: 19
2023-01-05 05:16:52,056 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39118976692358653, 'Total loss': 0.39118976692358653} | train loss {'Reaction outcome loss': 0.3061718822153278, 'Total loss': 0.3061718822153278}
2023-01-05 05:16:52,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:52,056 INFO:     Epoch: 20
2023-01-05 05:16:54,194 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3677591890096664, 'Total loss': 0.3677591890096664} | train loss {'Reaction outcome loss': 0.302103848779922, 'Total loss': 0.302103848779922}
2023-01-05 05:16:54,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:54,195 INFO:     Epoch: 21
2023-01-05 05:16:56,391 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36314862469832104, 'Total loss': 0.36314862469832104} | train loss {'Reaction outcome loss': 0.28936719749764206, 'Total loss': 0.28936719749764206}
2023-01-05 05:16:56,391 INFO:     Found new best model at epoch 21
2023-01-05 05:16:56,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:56,392 INFO:     Epoch: 22
2023-01-05 05:16:58,550 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36423001885414125, 'Total loss': 0.36423001885414125} | train loss {'Reaction outcome loss': 0.2877878702549271, 'Total loss': 0.2877878702549271}
2023-01-05 05:16:58,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:16:58,551 INFO:     Epoch: 23
2023-01-05 05:17:00,719 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3543557325998942, 'Total loss': 0.3543557325998942} | train loss {'Reaction outcome loss': 0.28201884751109196, 'Total loss': 0.28201884751109196}
2023-01-05 05:17:00,720 INFO:     Found new best model at epoch 23
2023-01-05 05:17:00,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:00,721 INFO:     Epoch: 24
2023-01-05 05:17:02,930 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40855859716733295, 'Total loss': 0.40855859716733295} | train loss {'Reaction outcome loss': 0.27424616965673343, 'Total loss': 0.27424616965673343}
2023-01-05 05:17:02,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:02,931 INFO:     Epoch: 25
2023-01-05 05:17:05,135 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36771762867768604, 'Total loss': 0.36771762867768604} | train loss {'Reaction outcome loss': 0.2714051915257623, 'Total loss': 0.2714051915257623}
2023-01-05 05:17:05,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:05,135 INFO:     Epoch: 26
2023-01-05 05:17:07,390 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37213927432894706, 'Total loss': 0.37213927432894706} | train loss {'Reaction outcome loss': 0.27061749620861186, 'Total loss': 0.27061749620861186}
2023-01-05 05:17:07,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:07,390 INFO:     Epoch: 27
2023-01-05 05:17:09,570 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.375166180729866, 'Total loss': 0.375166180729866} | train loss {'Reaction outcome loss': 0.2625130378665068, 'Total loss': 0.2625130378665068}
2023-01-05 05:17:09,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:09,570 INFO:     Epoch: 28
2023-01-05 05:17:11,779 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35583629459142685, 'Total loss': 0.35583629459142685} | train loss {'Reaction outcome loss': 0.2591388728537839, 'Total loss': 0.2591388728537839}
2023-01-05 05:17:11,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:11,779 INFO:     Epoch: 29
2023-01-05 05:17:13,946 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.361885154992342, 'Total loss': 0.361885154992342} | train loss {'Reaction outcome loss': 0.25500281485336607, 'Total loss': 0.25500281485336607}
2023-01-05 05:17:13,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:13,947 INFO:     Epoch: 30
2023-01-05 05:17:16,081 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3869139211873213, 'Total loss': 0.3869139211873213} | train loss {'Reaction outcome loss': 0.2536574222775169, 'Total loss': 0.2536574222775169}
2023-01-05 05:17:16,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:16,081 INFO:     Epoch: 31
2023-01-05 05:17:18,310 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3663521945476532, 'Total loss': 0.3663521945476532} | train loss {'Reaction outcome loss': 0.2458119871906745, 'Total loss': 0.2458119871906745}
2023-01-05 05:17:18,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:18,310 INFO:     Epoch: 32
2023-01-05 05:17:20,412 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.352576977511247, 'Total loss': 0.352576977511247} | train loss {'Reaction outcome loss': 0.2433636146478164, 'Total loss': 0.2433636146478164}
2023-01-05 05:17:20,412 INFO:     Found new best model at epoch 32
2023-01-05 05:17:20,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:20,413 INFO:     Epoch: 33
2023-01-05 05:17:22,531 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3467130571603775, 'Total loss': 0.3467130571603775} | train loss {'Reaction outcome loss': 0.23943497985430853, 'Total loss': 0.23943497985430853}
2023-01-05 05:17:22,531 INFO:     Found new best model at epoch 33
2023-01-05 05:17:22,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:22,532 INFO:     Epoch: 34
2023-01-05 05:17:24,743 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38106045722961424, 'Total loss': 0.38106045722961424} | train loss {'Reaction outcome loss': 0.23825277767788905, 'Total loss': 0.23825277767788905}
2023-01-05 05:17:24,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:24,744 INFO:     Epoch: 35
2023-01-05 05:17:26,983 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.32951403905948, 'Total loss': 0.32951403905948} | train loss {'Reaction outcome loss': 0.23555064134490797, 'Total loss': 0.23555064134490797}
2023-01-05 05:17:26,983 INFO:     Found new best model at epoch 35
2023-01-05 05:17:26,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:26,985 INFO:     Epoch: 36
2023-01-05 05:17:29,237 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36264107724030814, 'Total loss': 0.36264107724030814} | train loss {'Reaction outcome loss': 0.23098703162683235, 'Total loss': 0.23098703162683235}
2023-01-05 05:17:29,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:29,237 INFO:     Epoch: 37
2023-01-05 05:17:31,485 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37101646661758425, 'Total loss': 0.37101646661758425} | train loss {'Reaction outcome loss': 0.23326176999566647, 'Total loss': 0.23326176999566647}
2023-01-05 05:17:31,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:31,486 INFO:     Epoch: 38
2023-01-05 05:17:33,747 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34840015868345897, 'Total loss': 0.34840015868345897} | train loss {'Reaction outcome loss': 0.23191282461523574, 'Total loss': 0.23191282461523574}
2023-01-05 05:17:33,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:33,747 INFO:     Epoch: 39
2023-01-05 05:17:35,975 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3521334992100795, 'Total loss': 0.3521334992100795} | train loss {'Reaction outcome loss': 0.2237900062685921, 'Total loss': 0.2237900062685921}
2023-01-05 05:17:35,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:35,975 INFO:     Epoch: 40
2023-01-05 05:17:38,153 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39733294198910396, 'Total loss': 0.39733294198910396} | train loss {'Reaction outcome loss': 0.22507601011639985, 'Total loss': 0.22507601011639985}
2023-01-05 05:17:38,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:38,153 INFO:     Epoch: 41
2023-01-05 05:17:40,353 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38459562361240385, 'Total loss': 0.38459562361240385} | train loss {'Reaction outcome loss': 0.2181163877419336, 'Total loss': 0.2181163877419336}
2023-01-05 05:17:40,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:40,353 INFO:     Epoch: 42
2023-01-05 05:17:42,541 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3779035773128271, 'Total loss': 0.3779035773128271} | train loss {'Reaction outcome loss': 0.2180533988551397, 'Total loss': 0.2180533988551397}
2023-01-05 05:17:42,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:42,541 INFO:     Epoch: 43
2023-01-05 05:17:44,678 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3836487243572871, 'Total loss': 0.3836487243572871} | train loss {'Reaction outcome loss': 0.22244047503167894, 'Total loss': 0.22244047503167894}
2023-01-05 05:17:44,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:44,679 INFO:     Epoch: 44
2023-01-05 05:17:46,873 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38070952941974007, 'Total loss': 0.38070952941974007} | train loss {'Reaction outcome loss': 0.21562672047551734, 'Total loss': 0.21562672047551734}
2023-01-05 05:17:46,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:46,873 INFO:     Epoch: 45
2023-01-05 05:17:49,041 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37072945733865104, 'Total loss': 0.37072945733865104} | train loss {'Reaction outcome loss': 0.21193128581680767, 'Total loss': 0.21193128581680767}
2023-01-05 05:17:49,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:49,041 INFO:     Epoch: 46
2023-01-05 05:17:51,270 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37382785479227704, 'Total loss': 0.37382785479227704} | train loss {'Reaction outcome loss': 0.21467674833350567, 'Total loss': 0.21467674833350567}
2023-01-05 05:17:51,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:51,270 INFO:     Epoch: 47
2023-01-05 05:17:53,487 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34402655841161806, 'Total loss': 0.34402655841161806} | train loss {'Reaction outcome loss': 0.2137109146200994, 'Total loss': 0.2137109146200994}
2023-01-05 05:17:53,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:53,487 INFO:     Epoch: 48
2023-01-05 05:17:55,709 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40005484720071155, 'Total loss': 0.40005484720071155} | train loss {'Reaction outcome loss': 0.2078010365571622, 'Total loss': 0.2078010365571622}
2023-01-05 05:17:55,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:55,710 INFO:     Epoch: 49
2023-01-05 05:17:57,929 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38001506626605985, 'Total loss': 0.38001506626605985} | train loss {'Reaction outcome loss': 0.20561774500096455, 'Total loss': 0.20561774500096455}
2023-01-05 05:17:57,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:17:57,930 INFO:     Epoch: 50
2023-01-05 05:18:00,132 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39421672423680626, 'Total loss': 0.39421672423680626} | train loss {'Reaction outcome loss': 0.20427855193928812, 'Total loss': 0.20427855193928812}
2023-01-05 05:18:00,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:00,133 INFO:     Epoch: 51
2023-01-05 05:18:02,359 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35299255307763816, 'Total loss': 0.35299255307763816} | train loss {'Reaction outcome loss': 0.20686324568458528, 'Total loss': 0.20686324568458528}
2023-01-05 05:18:02,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:02,359 INFO:     Epoch: 52
2023-01-05 05:18:04,600 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3562392601122459, 'Total loss': 0.3562392601122459} | train loss {'Reaction outcome loss': 0.20445918753374737, 'Total loss': 0.20445918753374737}
2023-01-05 05:18:04,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:04,601 INFO:     Epoch: 53
2023-01-05 05:18:06,838 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41589262584845227, 'Total loss': 0.41589262584845227} | train loss {'Reaction outcome loss': 0.20638149833108807, 'Total loss': 0.20638149833108807}
2023-01-05 05:18:06,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:06,839 INFO:     Epoch: 54
2023-01-05 05:18:09,063 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3950661063194275, 'Total loss': 0.3950661063194275} | train loss {'Reaction outcome loss': 0.20280947311757466, 'Total loss': 0.20280947311757466}
2023-01-05 05:18:09,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:09,064 INFO:     Epoch: 55
2023-01-05 05:18:11,200 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3662335415681203, 'Total loss': 0.3662335415681203} | train loss {'Reaction outcome loss': 0.19750210100737137, 'Total loss': 0.19750210100737137}
2023-01-05 05:18:11,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:11,200 INFO:     Epoch: 56
2023-01-05 05:18:13,420 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3546853077908357, 'Total loss': 0.3546853077908357} | train loss {'Reaction outcome loss': 0.19336726940526958, 'Total loss': 0.19336726940526958}
2023-01-05 05:18:13,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:13,421 INFO:     Epoch: 57
2023-01-05 05:18:15,652 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4013276199499766, 'Total loss': 0.4013276199499766} | train loss {'Reaction outcome loss': 0.19802890103242118, 'Total loss': 0.19802890103242118}
2023-01-05 05:18:15,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:15,653 INFO:     Epoch: 58
2023-01-05 05:18:17,884 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3877614731589953, 'Total loss': 0.3877614731589953} | train loss {'Reaction outcome loss': 0.19341556683196362, 'Total loss': 0.19341556683196362}
2023-01-05 05:18:17,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:17,884 INFO:     Epoch: 59
2023-01-05 05:18:20,076 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37781534645085535, 'Total loss': 0.37781534645085535} | train loss {'Reaction outcome loss': 0.19797145035424893, 'Total loss': 0.19797145035424893}
2023-01-05 05:18:20,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:20,077 INFO:     Epoch: 60
2023-01-05 05:18:22,298 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3809025836487611, 'Total loss': 0.3809025836487611} | train loss {'Reaction outcome loss': 0.1915475045545743, 'Total loss': 0.1915475045545743}
2023-01-05 05:18:22,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:22,299 INFO:     Epoch: 61
2023-01-05 05:18:24,490 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3653865839044253, 'Total loss': 0.3653865839044253} | train loss {'Reaction outcome loss': 0.19004855155535452, 'Total loss': 0.19004855155535452}
2023-01-05 05:18:24,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:24,491 INFO:     Epoch: 62
2023-01-05 05:18:26,709 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40014341175556184, 'Total loss': 0.40014341175556184} | train loss {'Reaction outcome loss': 0.18928599059786444, 'Total loss': 0.18928599059786444}
2023-01-05 05:18:26,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:26,709 INFO:     Epoch: 63
2023-01-05 05:18:28,866 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3582467451691628, 'Total loss': 0.3582467451691628} | train loss {'Reaction outcome loss': 0.18903643422633845, 'Total loss': 0.18903643422633845}
2023-01-05 05:18:28,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:28,866 INFO:     Epoch: 64
2023-01-05 05:18:31,101 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36927728578448293, 'Total loss': 0.36927728578448293} | train loss {'Reaction outcome loss': 0.18670486165858777, 'Total loss': 0.18670486165858777}
2023-01-05 05:18:31,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:31,102 INFO:     Epoch: 65
2023-01-05 05:18:33,326 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3971022019783656, 'Total loss': 0.3971022019783656} | train loss {'Reaction outcome loss': 0.19124754414903922, 'Total loss': 0.19124754414903922}
2023-01-05 05:18:33,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:33,326 INFO:     Epoch: 66
2023-01-05 05:18:35,513 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3897405693928401, 'Total loss': 0.3897405693928401} | train loss {'Reaction outcome loss': 0.18612888081156181, 'Total loss': 0.18612888081156181}
2023-01-05 05:18:35,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:35,513 INFO:     Epoch: 67
2023-01-05 05:18:37,674 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3895439644654592, 'Total loss': 0.3895439644654592} | train loss {'Reaction outcome loss': 0.18679318832567868, 'Total loss': 0.18679318832567868}
2023-01-05 05:18:37,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:37,675 INFO:     Epoch: 68
2023-01-05 05:18:39,876 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.360577375938495, 'Total loss': 0.360577375938495} | train loss {'Reaction outcome loss': 0.185787483722299, 'Total loss': 0.185787483722299}
2023-01-05 05:18:39,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:39,876 INFO:     Epoch: 69
2023-01-05 05:18:42,025 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38264434536298114, 'Total loss': 0.38264434536298114} | train loss {'Reaction outcome loss': 0.18845060119753357, 'Total loss': 0.18845060119753357}
2023-01-05 05:18:42,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:42,025 INFO:     Epoch: 70
2023-01-05 05:18:44,158 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4051238904396693, 'Total loss': 0.4051238904396693} | train loss {'Reaction outcome loss': 0.18422616008096016, 'Total loss': 0.18422616008096016}
2023-01-05 05:18:44,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:44,159 INFO:     Epoch: 71
2023-01-05 05:18:46,369 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37198669016361235, 'Total loss': 0.37198669016361235} | train loss {'Reaction outcome loss': 0.18320314948286712, 'Total loss': 0.18320314948286712}
2023-01-05 05:18:46,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:46,369 INFO:     Epoch: 72
2023-01-05 05:18:48,581 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3717480053504308, 'Total loss': 0.3717480053504308} | train loss {'Reaction outcome loss': 0.18843306750297928, 'Total loss': 0.18843306750297928}
2023-01-05 05:18:48,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:48,582 INFO:     Epoch: 73
2023-01-05 05:18:50,791 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4099142940094074, 'Total loss': 0.4099142940094074} | train loss {'Reaction outcome loss': 0.17917101668541904, 'Total loss': 0.17917101668541904}
2023-01-05 05:18:50,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:50,791 INFO:     Epoch: 74
2023-01-05 05:18:53,007 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38737338533004123, 'Total loss': 0.38737338533004123} | train loss {'Reaction outcome loss': 0.17938213808045828, 'Total loss': 0.17938213808045828}
2023-01-05 05:18:53,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:53,008 INFO:     Epoch: 75
2023-01-05 05:18:55,122 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3718656943490108, 'Total loss': 0.3718656943490108} | train loss {'Reaction outcome loss': 0.17845733337540984, 'Total loss': 0.17845733337540984}
2023-01-05 05:18:55,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:55,122 INFO:     Epoch: 76
2023-01-05 05:18:57,346 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4054241475959619, 'Total loss': 0.4054241475959619} | train loss {'Reaction outcome loss': 0.1780949243371658, 'Total loss': 0.1780949243371658}
2023-01-05 05:18:57,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:57,346 INFO:     Epoch: 77
2023-01-05 05:18:59,503 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35164865317444005, 'Total loss': 0.35164865317444005} | train loss {'Reaction outcome loss': 0.1764111616154075, 'Total loss': 0.1764111616154075}
2023-01-05 05:18:59,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:18:59,503 INFO:     Epoch: 78
2023-01-05 05:19:01,633 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4109343349933624, 'Total loss': 0.4109343349933624} | train loss {'Reaction outcome loss': 0.1737807645998049, 'Total loss': 0.1737807645998049}
2023-01-05 05:19:01,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:01,634 INFO:     Epoch: 79
2023-01-05 05:19:03,854 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3667934574186802, 'Total loss': 0.3667934574186802} | train loss {'Reaction outcome loss': 0.18062081623262974, 'Total loss': 0.18062081623262974}
2023-01-05 05:19:03,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:03,854 INFO:     Epoch: 80
2023-01-05 05:19:06,079 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3747151444355647, 'Total loss': 0.3747151444355647} | train loss {'Reaction outcome loss': 0.1769796844807218, 'Total loss': 0.1769796844807218}
2023-01-05 05:19:06,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:06,079 INFO:     Epoch: 81
2023-01-05 05:19:08,280 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3695878103375435, 'Total loss': 0.3695878103375435} | train loss {'Reaction outcome loss': 0.17807549363404732, 'Total loss': 0.17807549363404732}
2023-01-05 05:19:08,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:08,281 INFO:     Epoch: 82
2023-01-05 05:19:10,453 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3734823809315761, 'Total loss': 0.3734823809315761} | train loss {'Reaction outcome loss': 0.17744311845039218, 'Total loss': 0.17744311845039218}
2023-01-05 05:19:10,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:10,454 INFO:     Epoch: 83
2023-01-05 05:19:12,628 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4011064180483421, 'Total loss': 0.4011064180483421} | train loss {'Reaction outcome loss': 0.17808346784820323, 'Total loss': 0.17808346784820323}
2023-01-05 05:19:12,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:12,628 INFO:     Epoch: 84
2023-01-05 05:19:14,848 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3672812151412169, 'Total loss': 0.3672812151412169} | train loss {'Reaction outcome loss': 0.17521723146096635, 'Total loss': 0.17521723146096635}
2023-01-05 05:19:14,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:14,848 INFO:     Epoch: 85
2023-01-05 05:19:17,007 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4121452863017718, 'Total loss': 0.4121452863017718} | train loss {'Reaction outcome loss': 0.17339653926031603, 'Total loss': 0.17339653926031603}
2023-01-05 05:19:17,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:17,007 INFO:     Epoch: 86
2023-01-05 05:19:19,205 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3753216365973155, 'Total loss': 0.3753216365973155} | train loss {'Reaction outcome loss': 0.17127637635752724, 'Total loss': 0.17127637635752724}
2023-01-05 05:19:19,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:19,205 INFO:     Epoch: 87
2023-01-05 05:19:21,401 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3713774969180425, 'Total loss': 0.3713774969180425} | train loss {'Reaction outcome loss': 0.16666767040042432, 'Total loss': 0.16666767040042432}
2023-01-05 05:19:21,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:21,402 INFO:     Epoch: 88
2023-01-05 05:19:23,596 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3668855583605667, 'Total loss': 0.3668855583605667} | train loss {'Reaction outcome loss': 0.16442403517281398, 'Total loss': 0.16442403517281398}
2023-01-05 05:19:23,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:23,597 INFO:     Epoch: 89
2023-01-05 05:19:25,733 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3909028778473536, 'Total loss': 0.3909028778473536} | train loss {'Reaction outcome loss': 0.1692809193862445, 'Total loss': 0.1692809193862445}
2023-01-05 05:19:25,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:25,733 INFO:     Epoch: 90
2023-01-05 05:19:27,883 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3836418519417445, 'Total loss': 0.3836418519417445} | train loss {'Reaction outcome loss': 0.17256931233434722, 'Total loss': 0.17256931233434722}
2023-01-05 05:19:27,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:27,883 INFO:     Epoch: 91
2023-01-05 05:19:30,067 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3956654489040375, 'Total loss': 0.3956654489040375} | train loss {'Reaction outcome loss': 0.1718353812835237, 'Total loss': 0.1718353812835237}
2023-01-05 05:19:30,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:30,067 INFO:     Epoch: 92
2023-01-05 05:19:32,260 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3771322707335154, 'Total loss': 0.3771322707335154} | train loss {'Reaction outcome loss': 0.17601944225918734, 'Total loss': 0.17601944225918734}
2023-01-05 05:19:32,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:32,261 INFO:     Epoch: 93
2023-01-05 05:19:34,459 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3899074832598368, 'Total loss': 0.3899074832598368} | train loss {'Reaction outcome loss': 0.16798758979259065, 'Total loss': 0.16798758979259065}
2023-01-05 05:19:34,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:34,460 INFO:     Epoch: 94
2023-01-05 05:19:36,657 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3542751917305092, 'Total loss': 0.3542751917305092} | train loss {'Reaction outcome loss': 0.1641266227106226, 'Total loss': 0.1641266227106226}
2023-01-05 05:19:36,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:36,657 INFO:     Epoch: 95
2023-01-05 05:19:38,810 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36634150296449663, 'Total loss': 0.36634150296449663} | train loss {'Reaction outcome loss': 0.16522353048514807, 'Total loss': 0.16522353048514807}
2023-01-05 05:19:38,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:38,811 INFO:     Epoch: 96
2023-01-05 05:19:41,031 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3803688928484917, 'Total loss': 0.3803688928484917} | train loss {'Reaction outcome loss': 0.16807375787910853, 'Total loss': 0.16807375787910853}
2023-01-05 05:19:41,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:41,031 INFO:     Epoch: 97
2023-01-05 05:19:43,181 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3878649532794952, 'Total loss': 0.3878649532794952} | train loss {'Reaction outcome loss': 0.1719841185339723, 'Total loss': 0.1719841185339723}
2023-01-05 05:19:43,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:43,181 INFO:     Epoch: 98
2023-01-05 05:19:45,288 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3464090867899358, 'Total loss': 0.3464090867899358} | train loss {'Reaction outcome loss': 0.1694751238286659, 'Total loss': 0.1694751238286659}
2023-01-05 05:19:45,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:45,289 INFO:     Epoch: 99
2023-01-05 05:19:47,502 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37794422407945, 'Total loss': 0.37794422407945} | train loss {'Reaction outcome loss': 0.16969319725675241, 'Total loss': 0.16969319725675241}
2023-01-05 05:19:47,502 INFO:     Best model found after epoch 36 of 100.
2023-01-05 05:19:47,502 INFO:   Done with stage: TRAINING
2023-01-05 05:19:47,502 INFO:   Starting stage: EVALUATION
2023-01-05 05:19:47,649 INFO:   Done with stage: EVALUATION
2023-01-05 05:19:47,649 INFO:   Leaving out SEQ value Fold_2
2023-01-05 05:19:47,662 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 05:19:47,662 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:19:48,306 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:19:48,306 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:19:48,378 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:19:48,378 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:19:48,378 INFO:     No hyperparam tuning for this model
2023-01-05 05:19:48,378 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:19:48,378 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:19:48,379 INFO:     None feature selector for col prot
2023-01-05 05:19:48,379 INFO:     None feature selector for col prot
2023-01-05 05:19:48,379 INFO:     None feature selector for col prot
2023-01-05 05:19:48,379 INFO:     None feature selector for col chem
2023-01-05 05:19:48,380 INFO:     None feature selector for col chem
2023-01-05 05:19:48,380 INFO:     None feature selector for col chem
2023-01-05 05:19:48,380 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:19:48,380 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:19:48,381 INFO:     Number of params in model 72931
2023-01-05 05:19:48,384 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:19:48,384 INFO:   Starting stage: TRAINING
2023-01-05 05:19:48,446 INFO:     Val loss before train {'Reaction outcome loss': 1.0374105413754782, 'Total loss': 1.0374105413754782}
2023-01-05 05:19:48,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:48,446 INFO:     Epoch: 0
2023-01-05 05:19:50,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8016599218050638, 'Total loss': 0.8016599218050638} | train loss {'Reaction outcome loss': 0.9245874175726267, 'Total loss': 0.9245874175726267}
2023-01-05 05:19:50,662 INFO:     Found new best model at epoch 0
2023-01-05 05:19:50,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:50,663 INFO:     Epoch: 1
2023-01-05 05:19:52,786 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5234114050865173, 'Total loss': 0.5234114050865173} | train loss {'Reaction outcome loss': 0.6586983873615405, 'Total loss': 0.6586983873615405}
2023-01-05 05:19:52,787 INFO:     Found new best model at epoch 1
2023-01-05 05:19:52,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:52,788 INFO:     Epoch: 2
2023-01-05 05:19:54,936 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5000119129816691, 'Total loss': 0.5000119129816691} | train loss {'Reaction outcome loss': 0.5464521735026827, 'Total loss': 0.5464521735026827}
2023-01-05 05:19:54,936 INFO:     Found new best model at epoch 2
2023-01-05 05:19:54,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:54,937 INFO:     Epoch: 3
2023-01-05 05:19:57,081 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49051605463027953, 'Total loss': 0.49051605463027953} | train loss {'Reaction outcome loss': 0.499628354537531, 'Total loss': 0.499628354537531}
2023-01-05 05:19:57,081 INFO:     Found new best model at epoch 3
2023-01-05 05:19:57,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:57,083 INFO:     Epoch: 4
2023-01-05 05:19:59,224 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43469107449054717, 'Total loss': 0.43469107449054717} | train loss {'Reaction outcome loss': 0.46334470385115084, 'Total loss': 0.46334470385115084}
2023-01-05 05:19:59,224 INFO:     Found new best model at epoch 4
2023-01-05 05:19:59,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:19:59,226 INFO:     Epoch: 5
2023-01-05 05:20:01,439 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42960025668144225, 'Total loss': 0.42960025668144225} | train loss {'Reaction outcome loss': 0.43978121876716614, 'Total loss': 0.43978121876716614}
2023-01-05 05:20:01,439 INFO:     Found new best model at epoch 5
2023-01-05 05:20:01,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:01,440 INFO:     Epoch: 6
2023-01-05 05:20:03,524 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40451269956926506, 'Total loss': 0.40451269956926506} | train loss {'Reaction outcome loss': 0.4207514340257293, 'Total loss': 0.4207514340257293}
2023-01-05 05:20:03,524 INFO:     Found new best model at epoch 6
2023-01-05 05:20:03,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:03,526 INFO:     Epoch: 7
2023-01-05 05:20:05,731 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42519229650497437, 'Total loss': 0.42519229650497437} | train loss {'Reaction outcome loss': 0.39962633394007313, 'Total loss': 0.39962633394007313}
2023-01-05 05:20:05,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:05,732 INFO:     Epoch: 8
2023-01-05 05:20:07,925 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4260996719201406, 'Total loss': 0.4260996719201406} | train loss {'Reaction outcome loss': 0.3825088998653352, 'Total loss': 0.3825088998653352}
2023-01-05 05:20:07,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:07,926 INFO:     Epoch: 9
2023-01-05 05:20:10,129 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41533384124437966, 'Total loss': 0.41533384124437966} | train loss {'Reaction outcome loss': 0.3724614239926708, 'Total loss': 0.3724614239926708}
2023-01-05 05:20:10,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:10,130 INFO:     Epoch: 10
2023-01-05 05:20:12,153 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.396527228752772, 'Total loss': 0.396527228752772} | train loss {'Reaction outcome loss': 0.36328046249287593, 'Total loss': 0.36328046249287593}
2023-01-05 05:20:12,154 INFO:     Found new best model at epoch 10
2023-01-05 05:20:12,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:12,155 INFO:     Epoch: 11
2023-01-05 05:20:14,369 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3896737076342106, 'Total loss': 0.3896737076342106} | train loss {'Reaction outcome loss': 0.3470634643222133, 'Total loss': 0.3470634643222133}
2023-01-05 05:20:14,370 INFO:     Found new best model at epoch 11
2023-01-05 05:20:14,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:14,371 INFO:     Epoch: 12
2023-01-05 05:20:16,573 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40698307553927104, 'Total loss': 0.40698307553927104} | train loss {'Reaction outcome loss': 0.3387719870878322, 'Total loss': 0.3387719870878322}
2023-01-05 05:20:16,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:16,574 INFO:     Epoch: 13
2023-01-05 05:20:18,662 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3960105448961258, 'Total loss': 0.3960105448961258} | train loss {'Reaction outcome loss': 0.3333142711557585, 'Total loss': 0.3333142711557585}
2023-01-05 05:20:18,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:18,662 INFO:     Epoch: 14
2023-01-05 05:20:20,794 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4033100053668022, 'Total loss': 0.4033100053668022} | train loss {'Reaction outcome loss': 0.3238191494642588, 'Total loss': 0.3238191494642588}
2023-01-05 05:20:20,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:20,794 INFO:     Epoch: 15
2023-01-05 05:20:22,988 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39342962006727855, 'Total loss': 0.39342962006727855} | train loss {'Reaction outcome loss': 0.31826315667631444, 'Total loss': 0.31826315667631444}
2023-01-05 05:20:22,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:22,988 INFO:     Epoch: 16
2023-01-05 05:20:25,193 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41857306063175204, 'Total loss': 0.41857306063175204} | train loss {'Reaction outcome loss': 0.3091388625192466, 'Total loss': 0.3091388625192466}
2023-01-05 05:20:25,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:25,193 INFO:     Epoch: 17
2023-01-05 05:20:27,372 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39531363447507223, 'Total loss': 0.39531363447507223} | train loss {'Reaction outcome loss': 0.30170142882232076, 'Total loss': 0.30170142882232076}
2023-01-05 05:20:27,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:27,373 INFO:     Epoch: 18
2023-01-05 05:20:29,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42952603499094644, 'Total loss': 0.42952603499094644} | train loss {'Reaction outcome loss': 0.29246983877847116, 'Total loss': 0.29246983877847116}
2023-01-05 05:20:29,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:29,568 INFO:     Epoch: 19
2023-01-05 05:20:31,699 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38067606339852017, 'Total loss': 0.38067606339852017} | train loss {'Reaction outcome loss': 0.2870096955379657, 'Total loss': 0.2870096955379657}
2023-01-05 05:20:31,699 INFO:     Found new best model at epoch 19
2023-01-05 05:20:31,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:31,700 INFO:     Epoch: 20
2023-01-05 05:20:33,875 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.408115828037262, 'Total loss': 0.408115828037262} | train loss {'Reaction outcome loss': 0.2831398140075462, 'Total loss': 0.2831398140075462}
2023-01-05 05:20:33,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:33,875 INFO:     Epoch: 21
2023-01-05 05:20:35,946 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40579419732093813, 'Total loss': 0.40579419732093813} | train loss {'Reaction outcome loss': 0.2837890540541758, 'Total loss': 0.2837890540541758}
2023-01-05 05:20:35,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:35,946 INFO:     Epoch: 22
2023-01-05 05:20:38,086 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42919502357641853, 'Total loss': 0.42919502357641853} | train loss {'Reaction outcome loss': 0.2755755548849977, 'Total loss': 0.2755755548849977}
2023-01-05 05:20:38,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:38,086 INFO:     Epoch: 23
2023-01-05 05:20:40,180 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4504934807618459, 'Total loss': 0.4504934807618459} | train loss {'Reaction outcome loss': 0.2725331181199788, 'Total loss': 0.2725331181199788}
2023-01-05 05:20:40,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:40,180 INFO:     Epoch: 24
2023-01-05 05:20:42,333 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4317197442054749, 'Total loss': 0.4317197442054749} | train loss {'Reaction outcome loss': 0.26746476128889846, 'Total loss': 0.26746476128889846}
2023-01-05 05:20:42,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:42,334 INFO:     Epoch: 25
2023-01-05 05:20:44,482 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4066492031017939, 'Total loss': 0.4066492031017939} | train loss {'Reaction outcome loss': 0.2599680103375353, 'Total loss': 0.2599680103375353}
2023-01-05 05:20:44,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:44,484 INFO:     Epoch: 26
2023-01-05 05:20:46,631 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46702434023221334, 'Total loss': 0.46702434023221334} | train loss {'Reaction outcome loss': 0.25327801900981095, 'Total loss': 0.25327801900981095}
2023-01-05 05:20:46,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:46,631 INFO:     Epoch: 27
2023-01-05 05:20:48,793 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42715103228886925, 'Total loss': 0.42715103228886925} | train loss {'Reaction outcome loss': 0.2576532719856149, 'Total loss': 0.2576532719856149}
2023-01-05 05:20:48,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:48,793 INFO:     Epoch: 28
2023-01-05 05:20:50,989 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41667719433705014, 'Total loss': 0.41667719433705014} | train loss {'Reaction outcome loss': 0.24639876512638756, 'Total loss': 0.24639876512638756}
2023-01-05 05:20:50,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:50,990 INFO:     Epoch: 29
2023-01-05 05:20:53,126 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42406505544980366, 'Total loss': 0.42406505544980366} | train loss {'Reaction outcome loss': 0.24225380033172145, 'Total loss': 0.24225380033172145}
2023-01-05 05:20:53,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:53,126 INFO:     Epoch: 30
2023-01-05 05:20:55,305 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43013499975204467, 'Total loss': 0.43013499975204467} | train loss {'Reaction outcome loss': 0.24114557757038912, 'Total loss': 0.24114557757038912}
2023-01-05 05:20:55,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:55,305 INFO:     Epoch: 31
2023-01-05 05:20:57,457 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41410596867402394, 'Total loss': 0.41410596867402394} | train loss {'Reaction outcome loss': 0.23681215752204846, 'Total loss': 0.23681215752204846}
2023-01-05 05:20:57,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:57,457 INFO:     Epoch: 32
2023-01-05 05:20:59,680 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4012616276741028, 'Total loss': 0.4012616276741028} | train loss {'Reaction outcome loss': 0.2387903558598948, 'Total loss': 0.2387903558598948}
2023-01-05 05:20:59,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:20:59,681 INFO:     Epoch: 33
2023-01-05 05:21:01,862 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47515962570905684, 'Total loss': 0.47515962570905684} | train loss {'Reaction outcome loss': 0.23247507000101447, 'Total loss': 0.23247507000101447}
2023-01-05 05:21:01,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:01,862 INFO:     Epoch: 34
2023-01-05 05:21:04,061 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4344531446695328, 'Total loss': 0.4344531446695328} | train loss {'Reaction outcome loss': 0.22561453785953486, 'Total loss': 0.22561453785953486}
2023-01-05 05:21:04,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:04,062 INFO:     Epoch: 35
2023-01-05 05:21:06,252 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46930332978566486, 'Total loss': 0.46930332978566486} | train loss {'Reaction outcome loss': 0.2255871917337619, 'Total loss': 0.2255871917337619}
2023-01-05 05:21:06,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:06,252 INFO:     Epoch: 36
2023-01-05 05:21:08,442 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4456595023473104, 'Total loss': 0.4456595023473104} | train loss {'Reaction outcome loss': 0.2229343646676778, 'Total loss': 0.2229343646676778}
2023-01-05 05:21:08,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:08,442 INFO:     Epoch: 37
2023-01-05 05:21:10,641 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4204860766728719, 'Total loss': 0.4204860766728719} | train loss {'Reaction outcome loss': 0.21715229102908684, 'Total loss': 0.21715229102908684}
2023-01-05 05:21:10,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:10,641 INFO:     Epoch: 38
2023-01-05 05:21:12,763 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4717983196179072, 'Total loss': 0.4717983196179072} | train loss {'Reaction outcome loss': 0.21979080408646612, 'Total loss': 0.21979080408646612}
2023-01-05 05:21:12,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:12,763 INFO:     Epoch: 39
2023-01-05 05:21:14,886 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41909847060839334, 'Total loss': 0.41909847060839334} | train loss {'Reaction outcome loss': 0.2141048125441554, 'Total loss': 0.2141048125441554}
2023-01-05 05:21:14,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:14,887 INFO:     Epoch: 40
2023-01-05 05:21:17,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41621291637420654, 'Total loss': 0.41621291637420654} | train loss {'Reaction outcome loss': 0.2158935806332534, 'Total loss': 0.2158935806332534}
2023-01-05 05:21:17,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:17,090 INFO:     Epoch: 41
2023-01-05 05:21:19,189 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4156095822652181, 'Total loss': 0.4156095822652181} | train loss {'Reaction outcome loss': 0.20672232610589353, 'Total loss': 0.20672232610589353}
2023-01-05 05:21:19,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:19,189 INFO:     Epoch: 42
2023-01-05 05:21:21,314 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38275218959897755, 'Total loss': 0.38275218959897755} | train loss {'Reaction outcome loss': 0.2111074555617142, 'Total loss': 0.2111074555617142}
2023-01-05 05:21:21,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:21,315 INFO:     Epoch: 43
2023-01-05 05:21:23,517 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4364555930097898, 'Total loss': 0.4364555930097898} | train loss {'Reaction outcome loss': 0.20462718830406115, 'Total loss': 0.20462718830406115}
2023-01-05 05:21:23,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:23,517 INFO:     Epoch: 44
2023-01-05 05:21:25,705 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38571461774408816, 'Total loss': 0.38571461774408816} | train loss {'Reaction outcome loss': 0.20154826911819268, 'Total loss': 0.20154826911819268}
2023-01-05 05:21:25,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:25,705 INFO:     Epoch: 45
2023-01-05 05:21:27,892 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4299221247434616, 'Total loss': 0.4299221247434616} | train loss {'Reaction outcome loss': 0.20547814721523397, 'Total loss': 0.20547814721523397}
2023-01-05 05:21:27,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:27,892 INFO:     Epoch: 46
2023-01-05 05:21:30,126 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40372221569220224, 'Total loss': 0.40372221569220224} | train loss {'Reaction outcome loss': 0.199990315390304, 'Total loss': 0.199990315390304}
2023-01-05 05:21:30,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:30,126 INFO:     Epoch: 47
2023-01-05 05:21:32,294 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44631744623184205, 'Total loss': 0.44631744623184205} | train loss {'Reaction outcome loss': 0.19919353583655783, 'Total loss': 0.19919353583655783}
2023-01-05 05:21:32,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:32,294 INFO:     Epoch: 48
2023-01-05 05:21:34,385 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4564798305432002, 'Total loss': 0.4564798305432002} | train loss {'Reaction outcome loss': 0.2014717788906335, 'Total loss': 0.2014717788906335}
2023-01-05 05:21:34,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:34,386 INFO:     Epoch: 49
2023-01-05 05:21:36,521 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40404536525408424, 'Total loss': 0.40404536525408424} | train loss {'Reaction outcome loss': 0.19122332280907245, 'Total loss': 0.19122332280907245}
2023-01-05 05:21:36,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:36,521 INFO:     Epoch: 50
2023-01-05 05:21:38,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39712531547993424, 'Total loss': 0.39712531547993424} | train loss {'Reaction outcome loss': 0.18923724009706966, 'Total loss': 0.18923724009706966}
2023-01-05 05:21:38,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:38,729 INFO:     Epoch: 51
2023-01-05 05:21:40,918 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42559800545374554, 'Total loss': 0.42559800545374554} | train loss {'Reaction outcome loss': 0.19316884328532152, 'Total loss': 0.19316884328532152}
2023-01-05 05:21:40,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:40,918 INFO:     Epoch: 52
2023-01-05 05:21:43,115 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4139265978708863, 'Total loss': 0.4139265978708863} | train loss {'Reaction outcome loss': 0.1916039057275301, 'Total loss': 0.1916039057275301}
2023-01-05 05:21:43,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:43,115 INFO:     Epoch: 53
2023-01-05 05:21:45,315 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43452679067850114, 'Total loss': 0.43452679067850114} | train loss {'Reaction outcome loss': 0.19136883342308697, 'Total loss': 0.19136883342308697}
2023-01-05 05:21:45,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:45,316 INFO:     Epoch: 54
2023-01-05 05:21:47,509 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4392623148858547, 'Total loss': 0.4392623148858547} | train loss {'Reaction outcome loss': 0.1860330124072923, 'Total loss': 0.1860330124072923}
2023-01-05 05:21:47,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:47,510 INFO:     Epoch: 55
2023-01-05 05:21:49,717 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4418239782253901, 'Total loss': 0.4418239782253901} | train loss {'Reaction outcome loss': 0.18485984823759302, 'Total loss': 0.18485984823759302}
2023-01-05 05:21:49,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:49,717 INFO:     Epoch: 56
2023-01-05 05:21:51,889 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45545994440714516, 'Total loss': 0.45545994440714516} | train loss {'Reaction outcome loss': 0.1867274718008578, 'Total loss': 0.1867274718008578}
2023-01-05 05:21:51,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:51,889 INFO:     Epoch: 57
2023-01-05 05:21:54,081 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4414453163743019, 'Total loss': 0.4414453163743019} | train loss {'Reaction outcome loss': 0.18691675244002326, 'Total loss': 0.18691675244002326}
2023-01-05 05:21:54,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:54,082 INFO:     Epoch: 58
2023-01-05 05:21:56,291 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4444440762201945, 'Total loss': 0.4444440762201945} | train loss {'Reaction outcome loss': 0.18275687908169527, 'Total loss': 0.18275687908169527}
2023-01-05 05:21:56,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:56,291 INFO:     Epoch: 59
2023-01-05 05:21:58,500 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4247115592161814, 'Total loss': 0.4247115592161814} | train loss {'Reaction outcome loss': 0.18263471113840923, 'Total loss': 0.18263471113840923}
2023-01-05 05:21:58,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:21:58,501 INFO:     Epoch: 60
2023-01-05 05:22:00,684 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4304763050439457, 'Total loss': 0.4304763050439457} | train loss {'Reaction outcome loss': 0.18101584134671522, 'Total loss': 0.18101584134671522}
2023-01-05 05:22:00,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:00,685 INFO:     Epoch: 61
2023-01-05 05:22:02,799 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41535480245947837, 'Total loss': 0.41535480245947837} | train loss {'Reaction outcome loss': 0.1838805108465172, 'Total loss': 0.1838805108465172}
2023-01-05 05:22:02,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:02,800 INFO:     Epoch: 62
2023-01-05 05:22:04,989 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4551478246847788, 'Total loss': 0.4551478246847788} | train loss {'Reaction outcome loss': 0.18122520092599836, 'Total loss': 0.18122520092599836}
2023-01-05 05:22:04,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:04,990 INFO:     Epoch: 63
2023-01-05 05:22:07,122 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40381281773249306, 'Total loss': 0.40381281773249306} | train loss {'Reaction outcome loss': 0.17984622685286833, 'Total loss': 0.17984622685286833}
2023-01-05 05:22:07,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:07,122 INFO:     Epoch: 64
2023-01-05 05:22:09,298 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4124713937441508, 'Total loss': 0.4124713937441508} | train loss {'Reaction outcome loss': 0.1784318800486377, 'Total loss': 0.1784318800486377}
2023-01-05 05:22:09,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:09,298 INFO:     Epoch: 65
2023-01-05 05:22:11,425 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4786891962091128, 'Total loss': 0.4786891962091128} | train loss {'Reaction outcome loss': 0.1797847173630339, 'Total loss': 0.1797847173630339}
2023-01-05 05:22:11,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:11,425 INFO:     Epoch: 66
2023-01-05 05:22:13,563 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4472561955451965, 'Total loss': 0.4472561955451965} | train loss {'Reaction outcome loss': 0.1761384386074389, 'Total loss': 0.1761384386074389}
2023-01-05 05:22:13,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:13,563 INFO:     Epoch: 67
2023-01-05 05:22:15,745 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4614518980185191, 'Total loss': 0.4614518980185191} | train loss {'Reaction outcome loss': 0.17812749419217014, 'Total loss': 0.17812749419217014}
2023-01-05 05:22:15,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:15,745 INFO:     Epoch: 68
2023-01-05 05:22:17,899 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.445123811562856, 'Total loss': 0.445123811562856} | train loss {'Reaction outcome loss': 0.17675595840342975, 'Total loss': 0.17675595840342975}
2023-01-05 05:22:17,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:17,899 INFO:     Epoch: 69
2023-01-05 05:22:20,058 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44271317025025686, 'Total loss': 0.44271317025025686} | train loss {'Reaction outcome loss': 0.17428694030001923, 'Total loss': 0.17428694030001923}
2023-01-05 05:22:20,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:20,059 INFO:     Epoch: 70
2023-01-05 05:22:22,346 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4872196892897288, 'Total loss': 0.4872196892897288} | train loss {'Reaction outcome loss': 0.1751771637142337, 'Total loss': 0.1751771637142337}
2023-01-05 05:22:22,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:22,346 INFO:     Epoch: 71
2023-01-05 05:22:24,470 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3952959768784543, 'Total loss': 0.3952959768784543} | train loss {'Reaction outcome loss': 0.17374809529817908, 'Total loss': 0.17374809529817908}
2023-01-05 05:22:24,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:24,470 INFO:     Epoch: 72
2023-01-05 05:22:26,629 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4456465497612953, 'Total loss': 0.4456465497612953} | train loss {'Reaction outcome loss': 0.1715231035317112, 'Total loss': 0.1715231035317112}
2023-01-05 05:22:26,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:26,630 INFO:     Epoch: 73
2023-01-05 05:22:28,840 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4259931589166323, 'Total loss': 0.4259931589166323} | train loss {'Reaction outcome loss': 0.17414419149732513, 'Total loss': 0.17414419149732513}
2023-01-05 05:22:28,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:28,840 INFO:     Epoch: 74
2023-01-05 05:22:31,025 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39629440332452454, 'Total loss': 0.39629440332452454} | train loss {'Reaction outcome loss': 0.1729285970288999, 'Total loss': 0.1729285970288999}
2023-01-05 05:22:31,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:31,025 INFO:     Epoch: 75
2023-01-05 05:22:33,119 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4477312952280045, 'Total loss': 0.4477312952280045} | train loss {'Reaction outcome loss': 0.17100379043825767, 'Total loss': 0.17100379043825767}
2023-01-05 05:22:33,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:33,119 INFO:     Epoch: 76
2023-01-05 05:22:35,311 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4180318901936213, 'Total loss': 0.4180318901936213} | train loss {'Reaction outcome loss': 0.16649780024489133, 'Total loss': 0.16649780024489133}
2023-01-05 05:22:35,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:35,311 INFO:     Epoch: 77
2023-01-05 05:22:37,468 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43947788576285046, 'Total loss': 0.43947788576285046} | train loss {'Reaction outcome loss': 0.16432906842594658, 'Total loss': 0.16432906842594658}
2023-01-05 05:22:37,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:37,468 INFO:     Epoch: 78
2023-01-05 05:22:39,596 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43211766133705776, 'Total loss': 0.43211766133705776} | train loss {'Reaction outcome loss': 0.17098632420505985, 'Total loss': 0.17098632420505985}
2023-01-05 05:22:39,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:39,597 INFO:     Epoch: 79
2023-01-05 05:22:41,774 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4645214358965556, 'Total loss': 0.4645214358965556} | train loss {'Reaction outcome loss': 0.16734818050490066, 'Total loss': 0.16734818050490066}
2023-01-05 05:22:41,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:41,775 INFO:     Epoch: 80
2023-01-05 05:22:43,994 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46243300239245094, 'Total loss': 0.46243300239245094} | train loss {'Reaction outcome loss': 0.16571183100246525, 'Total loss': 0.16571183100246525}
2023-01-05 05:22:43,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:43,995 INFO:     Epoch: 81
2023-01-05 05:22:46,217 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4929932822783788, 'Total loss': 0.4929932822783788} | train loss {'Reaction outcome loss': 0.1684983111539945, 'Total loss': 0.1684983111539945}
2023-01-05 05:22:46,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:46,218 INFO:     Epoch: 82
2023-01-05 05:22:48,438 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4380384713411331, 'Total loss': 0.4380384713411331} | train loss {'Reaction outcome loss': 0.16389034078473644, 'Total loss': 0.16389034078473644}
2023-01-05 05:22:48,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:48,438 INFO:     Epoch: 83
2023-01-05 05:22:50,537 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4075091600418091, 'Total loss': 0.4075091600418091} | train loss {'Reaction outcome loss': 0.161882266879934, 'Total loss': 0.161882266879934}
2023-01-05 05:22:50,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:50,537 INFO:     Epoch: 84
2023-01-05 05:22:52,631 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4299940834442774, 'Total loss': 0.4299940834442774} | train loss {'Reaction outcome loss': 0.16424195687681767, 'Total loss': 0.16424195687681767}
2023-01-05 05:22:52,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:52,631 INFO:     Epoch: 85
2023-01-05 05:22:54,840 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43963842689990995, 'Total loss': 0.43963842689990995} | train loss {'Reaction outcome loss': 0.16294800061079573, 'Total loss': 0.16294800061079573}
2023-01-05 05:22:54,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:54,840 INFO:     Epoch: 86
2023-01-05 05:22:56,981 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4142182401691874, 'Total loss': 0.4142182401691874} | train loss {'Reaction outcome loss': 0.16708978003653874, 'Total loss': 0.16708978003653874}
2023-01-05 05:22:56,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:56,982 INFO:     Epoch: 87
2023-01-05 05:22:59,135 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42930993568152187, 'Total loss': 0.42930993568152187} | train loss {'Reaction outcome loss': 0.15885530625267222, 'Total loss': 0.15885530625267222}
2023-01-05 05:22:59,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:22:59,135 INFO:     Epoch: 88
2023-01-05 05:23:01,279 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4154819091161092, 'Total loss': 0.4154819091161092} | train loss {'Reaction outcome loss': 0.15980848205375495, 'Total loss': 0.15980848205375495}
2023-01-05 05:23:01,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:01,279 INFO:     Epoch: 89
2023-01-05 05:23:03,484 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4404896289110184, 'Total loss': 0.4404896289110184} | train loss {'Reaction outcome loss': 0.16172337187866498, 'Total loss': 0.16172337187866498}
2023-01-05 05:23:03,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:03,485 INFO:     Epoch: 90
2023-01-05 05:23:05,609 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43650860488414767, 'Total loss': 0.43650860488414767} | train loss {'Reaction outcome loss': 0.1598411233755468, 'Total loss': 0.1598411233755468}
2023-01-05 05:23:05,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:05,609 INFO:     Epoch: 91
2023-01-05 05:23:07,745 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4412525047858556, 'Total loss': 0.4412525047858556} | train loss {'Reaction outcome loss': 0.15965919365343462, 'Total loss': 0.15965919365343462}
2023-01-05 05:23:07,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:07,745 INFO:     Epoch: 92
2023-01-05 05:23:09,887 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4241863260666529, 'Total loss': 0.4241863260666529} | train loss {'Reaction outcome loss': 0.1575790933845393, 'Total loss': 0.1575790933845393}
2023-01-05 05:23:09,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:09,887 INFO:     Epoch: 93
2023-01-05 05:23:12,100 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4488595684369405, 'Total loss': 0.4488595684369405} | train loss {'Reaction outcome loss': 0.1536027055536139, 'Total loss': 0.1536027055536139}
2023-01-05 05:23:12,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:12,101 INFO:     Epoch: 94
2023-01-05 05:23:14,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42212641139825186, 'Total loss': 0.42212641139825186} | train loss {'Reaction outcome loss': 0.15819081372230887, 'Total loss': 0.15819081372230887}
2023-01-05 05:23:14,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:14,261 INFO:     Epoch: 95
2023-01-05 05:23:16,468 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46310277879238126, 'Total loss': 0.46310277879238126} | train loss {'Reaction outcome loss': 0.16126658167257024, 'Total loss': 0.16126658167257024}
2023-01-05 05:23:16,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:16,469 INFO:     Epoch: 96
2023-01-05 05:23:18,680 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4228291223446528, 'Total loss': 0.4228291223446528} | train loss {'Reaction outcome loss': 0.15532517216487948, 'Total loss': 0.15532517216487948}
2023-01-05 05:23:18,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:18,680 INFO:     Epoch: 97
2023-01-05 05:23:20,912 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4621652166048686, 'Total loss': 0.4621652166048686} | train loss {'Reaction outcome loss': 0.15844229169746663, 'Total loss': 0.15844229169746663}
2023-01-05 05:23:20,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:20,912 INFO:     Epoch: 98
2023-01-05 05:23:23,081 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4270147234201431, 'Total loss': 0.4270147234201431} | train loss {'Reaction outcome loss': 0.1576837085606702, 'Total loss': 0.1576837085606702}
2023-01-05 05:23:23,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:23,081 INFO:     Epoch: 99
2023-01-05 05:23:25,290 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4124207337697347, 'Total loss': 0.4124207337697347} | train loss {'Reaction outcome loss': 0.15684437968104914, 'Total loss': 0.15684437968104914}
2023-01-05 05:23:25,290 INFO:     Best model found after epoch 20 of 100.
2023-01-05 05:23:25,290 INFO:   Done with stage: TRAINING
2023-01-05 05:23:25,290 INFO:   Starting stage: EVALUATION
2023-01-05 05:23:25,444 INFO:   Done with stage: EVALUATION
2023-01-05 05:23:25,444 INFO:   Leaving out SEQ value Fold_3
2023-01-05 05:23:25,457 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 05:23:25,457 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:23:26,096 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:23:26,096 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:23:26,168 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:23:26,168 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:23:26,168 INFO:     No hyperparam tuning for this model
2023-01-05 05:23:26,168 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:23:26,168 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:23:26,169 INFO:     None feature selector for col prot
2023-01-05 05:23:26,169 INFO:     None feature selector for col prot
2023-01-05 05:23:26,169 INFO:     None feature selector for col prot
2023-01-05 05:23:26,170 INFO:     None feature selector for col chem
2023-01-05 05:23:26,170 INFO:     None feature selector for col chem
2023-01-05 05:23:26,170 INFO:     None feature selector for col chem
2023-01-05 05:23:26,170 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:23:26,170 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:23:26,171 INFO:     Number of params in model 72931
2023-01-05 05:23:26,174 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:23:26,175 INFO:   Starting stage: TRAINING
2023-01-05 05:23:26,233 INFO:     Val loss before train {'Reaction outcome loss': 1.050314184029897, 'Total loss': 1.050314184029897}
2023-01-05 05:23:26,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:26,234 INFO:     Epoch: 0
2023-01-05 05:23:28,422 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7579355080922444, 'Total loss': 0.7579355080922444} | train loss {'Reaction outcome loss': 0.9340353087134605, 'Total loss': 0.9340353087134605}
2023-01-05 05:23:28,423 INFO:     Found new best model at epoch 0
2023-01-05 05:23:28,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:28,424 INFO:     Epoch: 1
2023-01-05 05:23:30,640 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.587792432308197, 'Total loss': 0.587792432308197} | train loss {'Reaction outcome loss': 0.6487298564319193, 'Total loss': 0.6487298564319193}
2023-01-05 05:23:30,640 INFO:     Found new best model at epoch 1
2023-01-05 05:23:30,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:30,641 INFO:     Epoch: 2
2023-01-05 05:23:32,849 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4914213001728058, 'Total loss': 0.4914213001728058} | train loss {'Reaction outcome loss': 0.5440612438603909, 'Total loss': 0.5440612438603909}
2023-01-05 05:23:32,850 INFO:     Found new best model at epoch 2
2023-01-05 05:23:32,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:32,852 INFO:     Epoch: 3
2023-01-05 05:23:35,042 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4981535484393438, 'Total loss': 0.4981535484393438} | train loss {'Reaction outcome loss': 0.5004840293069825, 'Total loss': 0.5004840293069825}
2023-01-05 05:23:35,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:35,042 INFO:     Epoch: 4
2023-01-05 05:23:37,224 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49987846314907075, 'Total loss': 0.49987846314907075} | train loss {'Reaction outcome loss': 0.47035298132113296, 'Total loss': 0.47035298132113296}
2023-01-05 05:23:37,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:37,224 INFO:     Epoch: 5
2023-01-05 05:23:39,410 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4772824654976527, 'Total loss': 0.4772824654976527} | train loss {'Reaction outcome loss': 0.44742147262840376, 'Total loss': 0.44742147262840376}
2023-01-05 05:23:39,411 INFO:     Found new best model at epoch 5
2023-01-05 05:23:39,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:39,413 INFO:     Epoch: 6
2023-01-05 05:23:41,615 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4663177529970805, 'Total loss': 0.4663177529970805} | train loss {'Reaction outcome loss': 0.42952072188040635, 'Total loss': 0.42952072188040635}
2023-01-05 05:23:41,615 INFO:     Found new best model at epoch 6
2023-01-05 05:23:41,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:41,617 INFO:     Epoch: 7
2023-01-05 05:23:43,828 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46124742726484935, 'Total loss': 0.46124742726484935} | train loss {'Reaction outcome loss': 0.41977083438286816, 'Total loss': 0.41977083438286816}
2023-01-05 05:23:43,828 INFO:     Found new best model at epoch 7
2023-01-05 05:23:43,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:43,830 INFO:     Epoch: 8
2023-01-05 05:23:46,037 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43052754799524945, 'Total loss': 0.43052754799524945} | train loss {'Reaction outcome loss': 0.39913508616877297, 'Total loss': 0.39913508616877297}
2023-01-05 05:23:46,037 INFO:     Found new best model at epoch 8
2023-01-05 05:23:46,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:46,038 INFO:     Epoch: 9
2023-01-05 05:23:48,245 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4491912811994553, 'Total loss': 0.4491912811994553} | train loss {'Reaction outcome loss': 0.3901638844369972, 'Total loss': 0.3901638844369972}
2023-01-05 05:23:48,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:48,245 INFO:     Epoch: 10
2023-01-05 05:23:50,467 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4220359156529109, 'Total loss': 0.4220359156529109} | train loss {'Reaction outcome loss': 0.376596612597469, 'Total loss': 0.376596612597469}
2023-01-05 05:23:50,467 INFO:     Found new best model at epoch 10
2023-01-05 05:23:50,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:50,468 INFO:     Epoch: 11
2023-01-05 05:23:52,682 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4240288734436035, 'Total loss': 0.4240288734436035} | train loss {'Reaction outcome loss': 0.37244206192447754, 'Total loss': 0.37244206192447754}
2023-01-05 05:23:52,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:52,683 INFO:     Epoch: 12
2023-01-05 05:23:54,916 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4369861384232839, 'Total loss': 0.4369861384232839} | train loss {'Reaction outcome loss': 0.3585829050110204, 'Total loss': 0.3585829050110204}
2023-01-05 05:23:54,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:54,917 INFO:     Epoch: 13
2023-01-05 05:23:57,134 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43453242133061093, 'Total loss': 0.43453242133061093} | train loss {'Reaction outcome loss': 0.3470854059568722, 'Total loss': 0.3470854059568722}
2023-01-05 05:23:57,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:57,135 INFO:     Epoch: 14
2023-01-05 05:23:59,352 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4122899661461512, 'Total loss': 0.4122899661461512} | train loss {'Reaction outcome loss': 0.3442493981688562, 'Total loss': 0.3442493981688562}
2023-01-05 05:23:59,352 INFO:     Found new best model at epoch 14
2023-01-05 05:23:59,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:23:59,353 INFO:     Epoch: 15
2023-01-05 05:24:01,584 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4079339067141215, 'Total loss': 0.4079339067141215} | train loss {'Reaction outcome loss': 0.3314652313226766, 'Total loss': 0.3314652313226766}
2023-01-05 05:24:01,584 INFO:     Found new best model at epoch 15
2023-01-05 05:24:01,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:01,586 INFO:     Epoch: 16
2023-01-05 05:24:03,766 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3845741912722588, 'Total loss': 0.3845741912722588} | train loss {'Reaction outcome loss': 0.3233893941136172, 'Total loss': 0.3233893941136172}
2023-01-05 05:24:03,766 INFO:     Found new best model at epoch 16
2023-01-05 05:24:03,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:03,768 INFO:     Epoch: 17
2023-01-05 05:24:05,994 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39494010706742605, 'Total loss': 0.39494010706742605} | train loss {'Reaction outcome loss': 0.31523007649357304, 'Total loss': 0.31523007649357304}
2023-01-05 05:24:05,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:05,994 INFO:     Epoch: 18
2023-01-05 05:24:08,088 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40739849507808684, 'Total loss': 0.40739849507808684} | train loss {'Reaction outcome loss': 0.3093254152331909, 'Total loss': 0.3093254152331909}
2023-01-05 05:24:08,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:08,090 INFO:     Epoch: 19
2023-01-05 05:24:10,292 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4059147208929062, 'Total loss': 0.4059147208929062} | train loss {'Reaction outcome loss': 0.2996212967066434, 'Total loss': 0.2996212967066434}
2023-01-05 05:24:10,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:10,292 INFO:     Epoch: 20
2023-01-05 05:24:12,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41068559686342876, 'Total loss': 0.41068559686342876} | train loss {'Reaction outcome loss': 0.29938938752170247, 'Total loss': 0.29938938752170247}
2023-01-05 05:24:12,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:12,459 INFO:     Epoch: 21
2023-01-05 05:24:14,684 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40997186601161956, 'Total loss': 0.40997186601161956} | train loss {'Reaction outcome loss': 0.2898883745074272, 'Total loss': 0.2898883745074272}
2023-01-05 05:24:14,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:14,685 INFO:     Epoch: 22
2023-01-05 05:24:16,751 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4086836953957876, 'Total loss': 0.4086836953957876} | train loss {'Reaction outcome loss': 0.28201969449891007, 'Total loss': 0.28201969449891007}
2023-01-05 05:24:16,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:16,751 INFO:     Epoch: 23
2023-01-05 05:24:19,009 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3925467193126678, 'Total loss': 0.3925467193126678} | train loss {'Reaction outcome loss': 0.28277870199649874, 'Total loss': 0.28277870199649874}
2023-01-05 05:24:19,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:19,009 INFO:     Epoch: 24
2023-01-05 05:24:21,264 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39806955456733706, 'Total loss': 0.39806955456733706} | train loss {'Reaction outcome loss': 0.27703775231638095, 'Total loss': 0.27703775231638095}
2023-01-05 05:24:21,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:21,264 INFO:     Epoch: 25
2023-01-05 05:24:23,500 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3928734987974167, 'Total loss': 0.3928734987974167} | train loss {'Reaction outcome loss': 0.26614270620319963, 'Total loss': 0.26614270620319963}
2023-01-05 05:24:23,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:23,501 INFO:     Epoch: 26
2023-01-05 05:24:25,736 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3623459262152513, 'Total loss': 0.3623459262152513} | train loss {'Reaction outcome loss': 0.2662889390612823, 'Total loss': 0.2662889390612823}
2023-01-05 05:24:25,736 INFO:     Found new best model at epoch 26
2023-01-05 05:24:25,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:25,737 INFO:     Epoch: 27
2023-01-05 05:24:27,979 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38949984113375347, 'Total loss': 0.38949984113375347} | train loss {'Reaction outcome loss': 0.26442904850590404, 'Total loss': 0.26442904850590404}
2023-01-05 05:24:27,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:27,980 INFO:     Epoch: 28
2023-01-05 05:24:30,271 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.394287999967734, 'Total loss': 0.394287999967734} | train loss {'Reaction outcome loss': 0.25846625778851284, 'Total loss': 0.25846625778851284}
2023-01-05 05:24:30,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:30,271 INFO:     Epoch: 29
2023-01-05 05:24:32,565 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3786931385596593, 'Total loss': 0.3786931385596593} | train loss {'Reaction outcome loss': 0.25605976875246006, 'Total loss': 0.25605976875246006}
2023-01-05 05:24:32,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:32,565 INFO:     Epoch: 30
2023-01-05 05:24:34,796 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3946544999877612, 'Total loss': 0.3946544999877612} | train loss {'Reaction outcome loss': 0.25369707409319653, 'Total loss': 0.25369707409319653}
2023-01-05 05:24:34,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:34,796 INFO:     Epoch: 31
2023-01-05 05:24:37,012 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38329115013281506, 'Total loss': 0.38329115013281506} | train loss {'Reaction outcome loss': 0.24728453559053204, 'Total loss': 0.24728453559053204}
2023-01-05 05:24:37,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:37,012 INFO:     Epoch: 32
2023-01-05 05:24:39,172 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4026885469754537, 'Total loss': 0.4026885469754537} | train loss {'Reaction outcome loss': 0.24502982951727878, 'Total loss': 0.24502982951727878}
2023-01-05 05:24:39,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:39,173 INFO:     Epoch: 33
2023-01-05 05:24:41,408 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42695750618974365, 'Total loss': 0.42695750618974365} | train loss {'Reaction outcome loss': 0.24178990389961397, 'Total loss': 0.24178990389961397}
2023-01-05 05:24:41,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:41,409 INFO:     Epoch: 34
2023-01-05 05:24:43,651 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4061264413719376, 'Total loss': 0.4061264413719376} | train loss {'Reaction outcome loss': 0.2422188795681526, 'Total loss': 0.2422188795681526}
2023-01-05 05:24:43,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:43,652 INFO:     Epoch: 35
2023-01-05 05:24:45,881 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4316017657518387, 'Total loss': 0.4316017657518387} | train loss {'Reaction outcome loss': 0.2375017572670196, 'Total loss': 0.2375017572670196}
2023-01-05 05:24:45,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:45,881 INFO:     Epoch: 36
2023-01-05 05:24:48,029 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38731158475081123, 'Total loss': 0.38731158475081123} | train loss {'Reaction outcome loss': 0.23589803270288628, 'Total loss': 0.23589803270288628}
2023-01-05 05:24:48,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:48,030 INFO:     Epoch: 37
2023-01-05 05:24:50,218 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37357603112856547, 'Total loss': 0.37357603112856547} | train loss {'Reaction outcome loss': 0.23192425700326036, 'Total loss': 0.23192425700326036}
2023-01-05 05:24:50,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:50,219 INFO:     Epoch: 38
2023-01-05 05:24:52,407 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4208907316128413, 'Total loss': 0.4208907316128413} | train loss {'Reaction outcome loss': 0.22776699820737334, 'Total loss': 0.22776699820737334}
2023-01-05 05:24:52,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:52,407 INFO:     Epoch: 39
2023-01-05 05:24:54,607 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4416421135266622, 'Total loss': 0.4416421135266622} | train loss {'Reaction outcome loss': 0.23284234407011176, 'Total loss': 0.23284234407011176}
2023-01-05 05:24:54,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:54,607 INFO:     Epoch: 40
2023-01-05 05:24:56,820 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41137728095054626, 'Total loss': 0.41137728095054626} | train loss {'Reaction outcome loss': 0.22173713300594666, 'Total loss': 0.22173713300594666}
2023-01-05 05:24:56,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:56,820 INFO:     Epoch: 41
2023-01-05 05:24:58,983 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4259083420038223, 'Total loss': 0.4259083420038223} | train loss {'Reaction outcome loss': 0.2219791786106181, 'Total loss': 0.2219791786106181}
2023-01-05 05:24:58,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:24:58,984 INFO:     Epoch: 42
2023-01-05 05:25:01,188 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3885839616258939, 'Total loss': 0.3885839616258939} | train loss {'Reaction outcome loss': 0.2183351159422067, 'Total loss': 0.2183351159422067}
2023-01-05 05:25:01,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:01,188 INFO:     Epoch: 43
2023-01-05 05:25:03,402 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4028021290898323, 'Total loss': 0.4028021290898323} | train loss {'Reaction outcome loss': 0.2124078425571975, 'Total loss': 0.2124078425571975}
2023-01-05 05:25:03,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:03,403 INFO:     Epoch: 44
2023-01-05 05:25:05,606 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4174197686215242, 'Total loss': 0.4174197686215242} | train loss {'Reaction outcome loss': 0.21589635038258928, 'Total loss': 0.21589635038258928}
2023-01-05 05:25:05,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:05,606 INFO:     Epoch: 45
2023-01-05 05:25:07,794 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42181805670261385, 'Total loss': 0.42181805670261385} | train loss {'Reaction outcome loss': 0.21810619270660148, 'Total loss': 0.21810619270660148}
2023-01-05 05:25:07,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:07,794 INFO:     Epoch: 46
2023-01-05 05:25:09,987 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4302413672208786, 'Total loss': 0.4302413672208786} | train loss {'Reaction outcome loss': 0.20819003954121884, 'Total loss': 0.20819003954121884}
2023-01-05 05:25:09,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:09,987 INFO:     Epoch: 47
2023-01-05 05:25:12,226 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39201950828234355, 'Total loss': 0.39201950828234355} | train loss {'Reaction outcome loss': 0.21292324019528, 'Total loss': 0.21292324019528}
2023-01-05 05:25:12,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:12,227 INFO:     Epoch: 48
2023-01-05 05:25:14,458 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4090177824099859, 'Total loss': 0.4090177824099859} | train loss {'Reaction outcome loss': 0.21238012068027998, 'Total loss': 0.21238012068027998}
2023-01-05 05:25:14,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:14,458 INFO:     Epoch: 49
2023-01-05 05:25:16,687 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4020127693812052, 'Total loss': 0.4020127693812052} | train loss {'Reaction outcome loss': 0.20765217749170795, 'Total loss': 0.20765217749170795}
2023-01-05 05:25:16,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:16,688 INFO:     Epoch: 50
2023-01-05 05:25:18,930 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4259073535601298, 'Total loss': 0.4259073535601298} | train loss {'Reaction outcome loss': 0.20788749840525217, 'Total loss': 0.20788749840525217}
2023-01-05 05:25:18,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:18,930 INFO:     Epoch: 51
2023-01-05 05:25:21,133 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42928523669640223, 'Total loss': 0.42928523669640223} | train loss {'Reaction outcome loss': 0.20733179071795765, 'Total loss': 0.20733179071795765}
2023-01-05 05:25:21,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:21,134 INFO:     Epoch: 52
2023-01-05 05:25:23,377 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4502690573533376, 'Total loss': 0.4502690573533376} | train loss {'Reaction outcome loss': 0.20684409136781945, 'Total loss': 0.20684409136781945}
2023-01-05 05:25:23,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:23,377 INFO:     Epoch: 53
2023-01-05 05:25:25,633 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42729433874289197, 'Total loss': 0.42729433874289197} | train loss {'Reaction outcome loss': 0.20313289567800988, 'Total loss': 0.20313289567800988}
2023-01-05 05:25:25,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:25,633 INFO:     Epoch: 54
2023-01-05 05:25:27,874 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40806059340635936, 'Total loss': 0.40806059340635936} | train loss {'Reaction outcome loss': 0.20208526839141863, 'Total loss': 0.20208526839141863}
2023-01-05 05:25:27,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:27,875 INFO:     Epoch: 55
2023-01-05 05:25:30,086 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4475719004869461, 'Total loss': 0.4475719004869461} | train loss {'Reaction outcome loss': 0.201327637735292, 'Total loss': 0.201327637735292}
2023-01-05 05:25:30,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:30,086 INFO:     Epoch: 56
2023-01-05 05:25:32,264 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45631364385286965, 'Total loss': 0.45631364385286965} | train loss {'Reaction outcome loss': 0.19523431079285422, 'Total loss': 0.19523431079285422}
2023-01-05 05:25:32,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:32,264 INFO:     Epoch: 57
2023-01-05 05:25:34,510 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4423117220401764, 'Total loss': 0.4423117220401764} | train loss {'Reaction outcome loss': 0.19610659525233465, 'Total loss': 0.19610659525233465}
2023-01-05 05:25:34,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:34,510 INFO:     Epoch: 58
2023-01-05 05:25:36,738 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41002177794774375, 'Total loss': 0.41002177794774375} | train loss {'Reaction outcome loss': 0.19910911745969614, 'Total loss': 0.19910911745969614}
2023-01-05 05:25:36,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:36,738 INFO:     Epoch: 59
2023-01-05 05:25:38,960 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44154801418383915, 'Total loss': 0.44154801418383915} | train loss {'Reaction outcome loss': 0.19566702029504643, 'Total loss': 0.19566702029504643}
2023-01-05 05:25:38,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:38,960 INFO:     Epoch: 60
2023-01-05 05:25:41,156 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4371735761562983, 'Total loss': 0.4371735761562983} | train loss {'Reaction outcome loss': 0.19394225730853032, 'Total loss': 0.19394225730853032}
2023-01-05 05:25:41,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:41,157 INFO:     Epoch: 61
2023-01-05 05:25:43,376 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43768841922283175, 'Total loss': 0.43768841922283175} | train loss {'Reaction outcome loss': 0.19408821603827123, 'Total loss': 0.19408821603827123}
2023-01-05 05:25:43,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:43,377 INFO:     Epoch: 62
2023-01-05 05:25:45,609 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45224007268746697, 'Total loss': 0.45224007268746697} | train loss {'Reaction outcome loss': 0.19243372654385973, 'Total loss': 0.19243372654385973}
2023-01-05 05:25:45,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:45,609 INFO:     Epoch: 63
2023-01-05 05:25:47,813 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45385949810345966, 'Total loss': 0.45385949810345966} | train loss {'Reaction outcome loss': 0.19393083388937543, 'Total loss': 0.19393083388937543}
2023-01-05 05:25:47,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:47,813 INFO:     Epoch: 64
2023-01-05 05:25:49,996 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44036354720592497, 'Total loss': 0.44036354720592497} | train loss {'Reaction outcome loss': 0.19130147438170048, 'Total loss': 0.19130147438170048}
2023-01-05 05:25:49,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:49,997 INFO:     Epoch: 65
2023-01-05 05:25:52,174 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4200163662433624, 'Total loss': 0.4200163662433624} | train loss {'Reaction outcome loss': 0.19418899273418272, 'Total loss': 0.19418899273418272}
2023-01-05 05:25:52,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:52,174 INFO:     Epoch: 66
2023-01-05 05:25:54,340 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43784868021806084, 'Total loss': 0.43784868021806084} | train loss {'Reaction outcome loss': 0.19005545361280224, 'Total loss': 0.19005545361280224}
2023-01-05 05:25:54,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:54,340 INFO:     Epoch: 67
2023-01-05 05:25:56,562 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44038488864898684, 'Total loss': 0.44038488864898684} | train loss {'Reaction outcome loss': 0.18385842955419726, 'Total loss': 0.18385842955419726}
2023-01-05 05:25:56,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:56,563 INFO:     Epoch: 68
2023-01-05 05:25:58,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45923335949579874, 'Total loss': 0.45923335949579874} | train loss {'Reaction outcome loss': 0.18502139098038148, 'Total loss': 0.18502139098038148}
2023-01-05 05:25:58,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:25:58,739 INFO:     Epoch: 69
2023-01-05 05:26:00,920 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48542807896931967, 'Total loss': 0.48542807896931967} | train loss {'Reaction outcome loss': 0.18335647583109782, 'Total loss': 0.18335647583109782}
2023-01-05 05:26:00,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:00,921 INFO:     Epoch: 70
2023-01-05 05:26:03,142 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4444883495569229, 'Total loss': 0.4444883495569229} | train loss {'Reaction outcome loss': 0.18030424330240782, 'Total loss': 0.18030424330240782}
2023-01-05 05:26:03,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:03,143 INFO:     Epoch: 71
2023-01-05 05:26:05,340 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41441737363735837, 'Total loss': 0.41441737363735837} | train loss {'Reaction outcome loss': 0.1811280315911846, 'Total loss': 0.1811280315911846}
2023-01-05 05:26:05,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:05,341 INFO:     Epoch: 72
2023-01-05 05:26:07,531 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45327957173188527, 'Total loss': 0.45327957173188527} | train loss {'Reaction outcome loss': 0.18271893839331438, 'Total loss': 0.18271893839331438}
2023-01-05 05:26:07,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:07,532 INFO:     Epoch: 73
2023-01-05 05:26:09,733 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.436219123005867, 'Total loss': 0.436219123005867} | train loss {'Reaction outcome loss': 0.1822020223901274, 'Total loss': 0.1822020223901274}
2023-01-05 05:26:09,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:09,734 INFO:     Epoch: 74
2023-01-05 05:26:11,956 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4380251904328664, 'Total loss': 0.4380251904328664} | train loss {'Reaction outcome loss': 0.17907483058634902, 'Total loss': 0.17907483058634902}
2023-01-05 05:26:11,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:11,956 INFO:     Epoch: 75
2023-01-05 05:26:14,178 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4514690612753232, 'Total loss': 0.4514690612753232} | train loss {'Reaction outcome loss': 0.18141366561099778, 'Total loss': 0.18141366561099778}
2023-01-05 05:26:14,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:14,178 INFO:     Epoch: 76
2023-01-05 05:26:16,416 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46363757997751237, 'Total loss': 0.46363757997751237} | train loss {'Reaction outcome loss': 0.17849015874319105, 'Total loss': 0.17849015874319105}
2023-01-05 05:26:16,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:16,416 INFO:     Epoch: 77
2023-01-05 05:26:18,551 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4380465413133303, 'Total loss': 0.4380465413133303} | train loss {'Reaction outcome loss': 0.17766371428164363, 'Total loss': 0.17766371428164363}
2023-01-05 05:26:18,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:18,551 INFO:     Epoch: 78
2023-01-05 05:26:20,742 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45162785748640694, 'Total loss': 0.45162785748640694} | train loss {'Reaction outcome loss': 0.1791680648372284, 'Total loss': 0.1791680648372284}
2023-01-05 05:26:20,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:20,743 INFO:     Epoch: 79
2023-01-05 05:26:22,937 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43702755570411683, 'Total loss': 0.43702755570411683} | train loss {'Reaction outcome loss': 0.17829326584078645, 'Total loss': 0.17829326584078645}
2023-01-05 05:26:22,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:22,938 INFO:     Epoch: 80
2023-01-05 05:26:25,109 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.432617304349939, 'Total loss': 0.432617304349939} | train loss {'Reaction outcome loss': 0.17407076542068572, 'Total loss': 0.17407076542068572}
2023-01-05 05:26:25,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:25,110 INFO:     Epoch: 81
2023-01-05 05:26:27,346 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4634581059217453, 'Total loss': 0.4634581059217453} | train loss {'Reaction outcome loss': 0.1725785143598642, 'Total loss': 0.1725785143598642}
2023-01-05 05:26:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:27,347 INFO:     Epoch: 82
2023-01-05 05:26:29,520 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45113200737784304, 'Total loss': 0.45113200737784304} | train loss {'Reaction outcome loss': 0.17746381835508956, 'Total loss': 0.17746381835508956}
2023-01-05 05:26:29,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:29,521 INFO:     Epoch: 83
2023-01-05 05:26:31,667 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45900334616502125, 'Total loss': 0.45900334616502125} | train loss {'Reaction outcome loss': 0.17245219994920993, 'Total loss': 0.17245219994920993}
2023-01-05 05:26:31,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:31,667 INFO:     Epoch: 84
2023-01-05 05:26:33,856 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4488487849632899, 'Total loss': 0.4488487849632899} | train loss {'Reaction outcome loss': 0.17034765677424624, 'Total loss': 0.17034765677424624}
2023-01-05 05:26:33,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:33,857 INFO:     Epoch: 85
2023-01-05 05:26:36,084 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43686173458894095, 'Total loss': 0.43686173458894095} | train loss {'Reaction outcome loss': 0.1682993055603392, 'Total loss': 0.1682993055603392}
2023-01-05 05:26:36,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:36,084 INFO:     Epoch: 86
2023-01-05 05:26:38,377 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44881385763486226, 'Total loss': 0.44881385763486226} | train loss {'Reaction outcome loss': 0.17355634643098028, 'Total loss': 0.17355634643098028}
2023-01-05 05:26:38,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:38,377 INFO:     Epoch: 87
2023-01-05 05:26:40,599 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4190175364414851, 'Total loss': 0.4190175364414851} | train loss {'Reaction outcome loss': 0.17198013334133982, 'Total loss': 0.17198013334133982}
2023-01-05 05:26:40,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:40,599 INFO:     Epoch: 88
2023-01-05 05:26:42,746 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41048286606868106, 'Total loss': 0.41048286606868106} | train loss {'Reaction outcome loss': 0.1693769213675528, 'Total loss': 0.1693769213675528}
2023-01-05 05:26:42,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:42,747 INFO:     Epoch: 89
2023-01-05 05:26:44,952 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4300106167793274, 'Total loss': 0.4300106167793274} | train loss {'Reaction outcome loss': 0.1651118817963522, 'Total loss': 0.1651118817963522}
2023-01-05 05:26:44,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:44,952 INFO:     Epoch: 90
2023-01-05 05:26:47,179 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4645351509253184, 'Total loss': 0.4645351509253184} | train loss {'Reaction outcome loss': 0.17412601658449012, 'Total loss': 0.17412601658449012}
2023-01-05 05:26:47,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:47,180 INFO:     Epoch: 91
2023-01-05 05:26:49,372 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4677996769547462, 'Total loss': 0.4677996769547462} | train loss {'Reaction outcome loss': 0.167110786878633, 'Total loss': 0.167110786878633}
2023-01-05 05:26:49,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:49,373 INFO:     Epoch: 92
2023-01-05 05:26:51,611 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43145541350046795, 'Total loss': 0.43145541350046795} | train loss {'Reaction outcome loss': 0.16723390235939492, 'Total loss': 0.16723390235939492}
2023-01-05 05:26:51,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:51,611 INFO:     Epoch: 93
2023-01-05 05:26:53,842 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47334398825963336, 'Total loss': 0.47334398825963336} | train loss {'Reaction outcome loss': 0.17070846908630627, 'Total loss': 0.17070846908630627}
2023-01-05 05:26:53,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:53,843 INFO:     Epoch: 94
2023-01-05 05:26:55,987 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44428619543711345, 'Total loss': 0.44428619543711345} | train loss {'Reaction outcome loss': 0.16756713928070163, 'Total loss': 0.16756713928070163}
2023-01-05 05:26:55,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:55,988 INFO:     Epoch: 95
2023-01-05 05:26:58,211 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4729559481143951, 'Total loss': 0.4729559481143951} | train loss {'Reaction outcome loss': 0.16541366396050383, 'Total loss': 0.16541366396050383}
2023-01-05 05:26:58,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:26:58,212 INFO:     Epoch: 96
2023-01-05 05:27:00,299 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45854374915361407, 'Total loss': 0.45854374915361407} | train loss {'Reaction outcome loss': 0.16739892777239046, 'Total loss': 0.16739892777239046}
2023-01-05 05:27:00,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:00,299 INFO:     Epoch: 97
2023-01-05 05:27:02,136 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4582696795463562, 'Total loss': 0.4582696795463562} | train loss {'Reaction outcome loss': 0.16747484482947167, 'Total loss': 0.16747484482947167}
2023-01-05 05:27:02,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:02,136 INFO:     Epoch: 98
2023-01-05 05:27:03,973 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48592505753040316, 'Total loss': 0.48592505753040316} | train loss {'Reaction outcome loss': 0.16846572416222716, 'Total loss': 0.16846572416222716}
2023-01-05 05:27:03,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:03,974 INFO:     Epoch: 99
2023-01-05 05:27:06,115 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5084840138753255, 'Total loss': 0.5084840138753255} | train loss {'Reaction outcome loss': 0.1638851015519242, 'Total loss': 0.1638851015519242}
2023-01-05 05:27:06,115 INFO:     Best model found after epoch 27 of 100.
2023-01-05 05:27:06,116 INFO:   Done with stage: TRAINING
2023-01-05 05:27:06,116 INFO:   Starting stage: EVALUATION
2023-01-05 05:27:06,258 INFO:   Done with stage: EVALUATION
2023-01-05 05:27:06,258 INFO:   Leaving out SEQ value Fold_4
2023-01-05 05:27:06,271 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 05:27:06,271 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:27:06,927 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:27:06,927 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:27:07,000 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:27:07,000 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:27:07,000 INFO:     No hyperparam tuning for this model
2023-01-05 05:27:07,000 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:27:07,000 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:27:07,001 INFO:     None feature selector for col prot
2023-01-05 05:27:07,001 INFO:     None feature selector for col prot
2023-01-05 05:27:07,001 INFO:     None feature selector for col prot
2023-01-05 05:27:07,002 INFO:     None feature selector for col chem
2023-01-05 05:27:07,002 INFO:     None feature selector for col chem
2023-01-05 05:27:07,002 INFO:     None feature selector for col chem
2023-01-05 05:27:07,002 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:27:07,002 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:27:07,004 INFO:     Number of params in model 72931
2023-01-05 05:27:07,007 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:27:07,007 INFO:   Starting stage: TRAINING
2023-01-05 05:27:07,069 INFO:     Val loss before train {'Reaction outcome loss': 1.0347963889439902, 'Total loss': 1.0347963889439902}
2023-01-05 05:27:07,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:07,069 INFO:     Epoch: 0
2023-01-05 05:27:09,326 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8296722014745076, 'Total loss': 0.8296722014745076} | train loss {'Reaction outcome loss': 0.9619016548356425, 'Total loss': 0.9619016548356425}
2023-01-05 05:27:09,326 INFO:     Found new best model at epoch 0
2023-01-05 05:27:09,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:09,327 INFO:     Epoch: 1
2023-01-05 05:27:11,593 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6079614559809366, 'Total loss': 0.6079614559809366} | train loss {'Reaction outcome loss': 0.6690004968793813, 'Total loss': 0.6690004968793813}
2023-01-05 05:27:11,593 INFO:     Found new best model at epoch 1
2023-01-05 05:27:11,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:11,595 INFO:     Epoch: 2
2023-01-05 05:27:13,857 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6150706529617309, 'Total loss': 0.6150706529617309} | train loss {'Reaction outcome loss': 0.5312781468948302, 'Total loss': 0.5312781468948302}
2023-01-05 05:27:13,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:13,857 INFO:     Epoch: 3
2023-01-05 05:27:16,083 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5406210164229075, 'Total loss': 0.5406210164229075} | train loss {'Reaction outcome loss': 0.48841561317874205, 'Total loss': 0.48841561317874205}
2023-01-05 05:27:16,083 INFO:     Found new best model at epoch 3
2023-01-05 05:27:16,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:16,085 INFO:     Epoch: 4
2023-01-05 05:27:18,347 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.586622550090154, 'Total loss': 0.586622550090154} | train loss {'Reaction outcome loss': 0.4596558392370651, 'Total loss': 0.4596558392370651}
2023-01-05 05:27:18,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:18,348 INFO:     Epoch: 5
2023-01-05 05:27:20,619 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5114571650822958, 'Total loss': 0.5114571650822958} | train loss {'Reaction outcome loss': 0.43459051470894244, 'Total loss': 0.43459051470894244}
2023-01-05 05:27:20,619 INFO:     Found new best model at epoch 5
2023-01-05 05:27:20,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:20,620 INFO:     Epoch: 6
2023-01-05 05:27:22,782 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5020020206769308, 'Total loss': 0.5020020206769308} | train loss {'Reaction outcome loss': 0.41600172151727366, 'Total loss': 0.41600172151727366}
2023-01-05 05:27:22,782 INFO:     Found new best model at epoch 6
2023-01-05 05:27:22,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:22,784 INFO:     Epoch: 7
2023-01-05 05:27:25,042 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5221898188193639, 'Total loss': 0.5221898188193639} | train loss {'Reaction outcome loss': 0.4026744839086429, 'Total loss': 0.4026744839086429}
2023-01-05 05:27:25,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:25,043 INFO:     Epoch: 8
2023-01-05 05:27:27,197 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49265566070874534, 'Total loss': 0.49265566070874534} | train loss {'Reaction outcome loss': 0.3918753284893742, 'Total loss': 0.3918753284893742}
2023-01-05 05:27:27,198 INFO:     Found new best model at epoch 8
2023-01-05 05:27:27,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:27,200 INFO:     Epoch: 9
2023-01-05 05:27:29,461 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.515062257150809, 'Total loss': 0.515062257150809} | train loss {'Reaction outcome loss': 0.37692091654354054, 'Total loss': 0.37692091654354054}
2023-01-05 05:27:29,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:29,462 INFO:     Epoch: 10
2023-01-05 05:27:31,613 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.496232858300209, 'Total loss': 0.496232858300209} | train loss {'Reaction outcome loss': 0.3621874814483233, 'Total loss': 0.3621874814483233}
2023-01-05 05:27:31,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:31,613 INFO:     Epoch: 11
2023-01-05 05:27:33,876 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4788125197092692, 'Total loss': 0.4788125197092692} | train loss {'Reaction outcome loss': 0.3591639893095846, 'Total loss': 0.3591639893095846}
2023-01-05 05:27:33,877 INFO:     Found new best model at epoch 11
2023-01-05 05:27:33,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:33,878 INFO:     Epoch: 12
2023-01-05 05:27:36,063 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5208783666292827, 'Total loss': 0.5208783666292827} | train loss {'Reaction outcome loss': 0.34758835024997214, 'Total loss': 0.34758835024997214}
2023-01-05 05:27:36,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:36,064 INFO:     Epoch: 13
2023-01-05 05:27:38,219 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5349195082982381, 'Total loss': 0.5349195082982381} | train loss {'Reaction outcome loss': 0.33729153504386705, 'Total loss': 0.33729153504386705}
2023-01-05 05:27:38,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:38,219 INFO:     Epoch: 14
2023-01-05 05:27:40,415 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47346078008413317, 'Total loss': 0.47346078008413317} | train loss {'Reaction outcome loss': 0.33479320704399035, 'Total loss': 0.33479320704399035}
2023-01-05 05:27:40,415 INFO:     Found new best model at epoch 14
2023-01-05 05:27:40,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:40,416 INFO:     Epoch: 15
2023-01-05 05:27:42,598 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49331857363382975, 'Total loss': 0.49331857363382975} | train loss {'Reaction outcome loss': 0.3218995236021732, 'Total loss': 0.3218995236021732}
2023-01-05 05:27:42,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:42,598 INFO:     Epoch: 16
2023-01-05 05:27:44,784 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4738063325484594, 'Total loss': 0.4738063325484594} | train loss {'Reaction outcome loss': 0.31445140415795875, 'Total loss': 0.31445140415795875}
2023-01-05 05:27:44,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:44,785 INFO:     Epoch: 17
2023-01-05 05:27:47,050 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4758026321729024, 'Total loss': 0.4758026321729024} | train loss {'Reaction outcome loss': 0.30594164923855544, 'Total loss': 0.30594164923855544}
2023-01-05 05:27:47,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:47,051 INFO:     Epoch: 18
2023-01-05 05:27:49,182 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5178023318449656, 'Total loss': 0.5178023318449656} | train loss {'Reaction outcome loss': 0.29863480945195103, 'Total loss': 0.29863480945195103}
2023-01-05 05:27:49,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:49,182 INFO:     Epoch: 19
2023-01-05 05:27:51,426 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49213024179140724, 'Total loss': 0.49213024179140724} | train loss {'Reaction outcome loss': 0.29977954786929845, 'Total loss': 0.29977954786929845}
2023-01-05 05:27:51,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:51,426 INFO:     Epoch: 20
2023-01-05 05:27:53,661 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5381188243627548, 'Total loss': 0.5381188243627548} | train loss {'Reaction outcome loss': 0.2913262630453071, 'Total loss': 0.2913262630453071}
2023-01-05 05:27:53,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:53,661 INFO:     Epoch: 21
2023-01-05 05:27:55,915 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4825392524401347, 'Total loss': 0.4825392524401347} | train loss {'Reaction outcome loss': 0.28247980624504576, 'Total loss': 0.28247980624504576}
2023-01-05 05:27:55,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:55,915 INFO:     Epoch: 22
2023-01-05 05:27:58,181 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46401281158129376, 'Total loss': 0.46401281158129376} | train loss {'Reaction outcome loss': 0.27822215038785436, 'Total loss': 0.27822215038785436}
2023-01-05 05:27:58,181 INFO:     Found new best model at epoch 22
2023-01-05 05:27:58,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:27:58,182 INFO:     Epoch: 23
2023-01-05 05:28:00,444 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49161754151185355, 'Total loss': 0.49161754151185355} | train loss {'Reaction outcome loss': 0.2774058349618843, 'Total loss': 0.2774058349618843}
2023-01-05 05:28:00,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:00,445 INFO:     Epoch: 24
2023-01-05 05:28:02,654 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47953789432843524, 'Total loss': 0.47953789432843524} | train loss {'Reaction outcome loss': 0.27247630912366755, 'Total loss': 0.27247630912366755}
2023-01-05 05:28:02,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:02,654 INFO:     Epoch: 25
2023-01-05 05:28:04,817 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48249827524026234, 'Total loss': 0.48249827524026234} | train loss {'Reaction outcome loss': 0.2672564664095748, 'Total loss': 0.2672564664095748}
2023-01-05 05:28:04,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:04,818 INFO:     Epoch: 26
2023-01-05 05:28:07,071 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47996577819188435, 'Total loss': 0.47996577819188435} | train loss {'Reaction outcome loss': 0.26469631246980346, 'Total loss': 0.26469631246980346}
2023-01-05 05:28:07,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:07,071 INFO:     Epoch: 27
2023-01-05 05:28:09,297 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4945851405461629, 'Total loss': 0.4945851405461629} | train loss {'Reaction outcome loss': 0.2612930586366555, 'Total loss': 0.2612930586366555}
2023-01-05 05:28:09,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:09,297 INFO:     Epoch: 28
2023-01-05 05:28:11,540 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48453944524129233, 'Total loss': 0.48453944524129233} | train loss {'Reaction outcome loss': 0.25572513253175877, 'Total loss': 0.25572513253175877}
2023-01-05 05:28:11,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:11,540 INFO:     Epoch: 29
2023-01-05 05:28:13,800 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4829073786735535, 'Total loss': 0.4829073786735535} | train loss {'Reaction outcome loss': 0.25221499117488033, 'Total loss': 0.25221499117488033}
2023-01-05 05:28:13,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:13,800 INFO:     Epoch: 30
2023-01-05 05:28:16,059 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5096515069405237, 'Total loss': 0.5096515069405237} | train loss {'Reaction outcome loss': 0.2501665404443007, 'Total loss': 0.2501665404443007}
2023-01-05 05:28:16,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:16,059 INFO:     Epoch: 31
2023-01-05 05:28:18,323 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4791783024867376, 'Total loss': 0.4791783024867376} | train loss {'Reaction outcome loss': 0.24212090143200937, 'Total loss': 0.24212090143200937}
2023-01-05 05:28:18,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:18,324 INFO:     Epoch: 32
2023-01-05 05:28:20,471 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5268886983394623, 'Total loss': 0.5268886983394623} | train loss {'Reaction outcome loss': 0.24296289955396944, 'Total loss': 0.24296289955396944}
2023-01-05 05:28:20,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:20,471 INFO:     Epoch: 33
2023-01-05 05:28:22,652 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4787948230902354, 'Total loss': 0.4787948230902354} | train loss {'Reaction outcome loss': 0.24321784695025386, 'Total loss': 0.24321784695025386}
2023-01-05 05:28:22,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:22,653 INFO:     Epoch: 34
2023-01-05 05:28:24,910 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5135774001479149, 'Total loss': 0.5135774001479149} | train loss {'Reaction outcome loss': 0.23291785320408293, 'Total loss': 0.23291785320408293}
2023-01-05 05:28:24,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:24,911 INFO:     Epoch: 35
2023-01-05 05:28:27,141 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4746315836906433, 'Total loss': 0.4746315836906433} | train loss {'Reaction outcome loss': 0.23379673284986174, 'Total loss': 0.23379673284986174}
2023-01-05 05:28:27,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:27,141 INFO:     Epoch: 36
2023-01-05 05:28:29,401 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47566197911898295, 'Total loss': 0.47566197911898295} | train loss {'Reaction outcome loss': 0.2312055814688494, 'Total loss': 0.2312055814688494}
2023-01-05 05:28:29,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:29,402 INFO:     Epoch: 37
2023-01-05 05:28:31,671 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4926179120937983, 'Total loss': 0.4926179120937983} | train loss {'Reaction outcome loss': 0.23036431684579015, 'Total loss': 0.23036431684579015}
2023-01-05 05:28:31,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:31,672 INFO:     Epoch: 38
2023-01-05 05:28:33,921 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.529092687368393, 'Total loss': 0.529092687368393} | train loss {'Reaction outcome loss': 0.22380444134454436, 'Total loss': 0.22380444134454436}
2023-01-05 05:28:33,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:33,922 INFO:     Epoch: 39
2023-01-05 05:28:36,154 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5067391037940979, 'Total loss': 0.5067391037940979} | train loss {'Reaction outcome loss': 0.2229738080275618, 'Total loss': 0.2229738080275618}
2023-01-05 05:28:36,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:36,154 INFO:     Epoch: 40
2023-01-05 05:28:38,398 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5060303658246994, 'Total loss': 0.5060303658246994} | train loss {'Reaction outcome loss': 0.22034457122187537, 'Total loss': 0.22034457122187537}
2023-01-05 05:28:38,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:38,399 INFO:     Epoch: 41
2023-01-05 05:28:40,665 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5184739192326864, 'Total loss': 0.5184739192326864} | train loss {'Reaction outcome loss': 0.21855375069506225, 'Total loss': 0.21855375069506225}
2023-01-05 05:28:40,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:40,666 INFO:     Epoch: 42
2023-01-05 05:28:42,897 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.506409440934658, 'Total loss': 0.506409440934658} | train loss {'Reaction outcome loss': 0.21808467508001178, 'Total loss': 0.21808467508001178}
2023-01-05 05:28:42,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:42,897 INFO:     Epoch: 43
2023-01-05 05:28:45,090 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5276018559932709, 'Total loss': 0.5276018559932709} | train loss {'Reaction outcome loss': 0.21129631442068286, 'Total loss': 0.21129631442068286}
2023-01-05 05:28:45,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:45,090 INFO:     Epoch: 44
2023-01-05 05:28:47,289 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5028272936741511, 'Total loss': 0.5028272936741511} | train loss {'Reaction outcome loss': 0.2115751710041201, 'Total loss': 0.2115751710041201}
2023-01-05 05:28:47,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:47,289 INFO:     Epoch: 45
2023-01-05 05:28:49,484 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4770055075486501, 'Total loss': 0.4770055075486501} | train loss {'Reaction outcome loss': 0.2133927805490442, 'Total loss': 0.2133927805490442}
2023-01-05 05:28:49,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:49,485 INFO:     Epoch: 46
2023-01-05 05:28:51,668 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4696623663107554, 'Total loss': 0.4696623663107554} | train loss {'Reaction outcome loss': 0.20721336320338482, 'Total loss': 0.20721336320338482}
2023-01-05 05:28:51,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:51,668 INFO:     Epoch: 47
2023-01-05 05:28:53,919 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5054440518220266, 'Total loss': 0.5054440518220266} | train loss {'Reaction outcome loss': 0.20368807051424945, 'Total loss': 0.20368807051424945}
2023-01-05 05:28:53,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:53,920 INFO:     Epoch: 48
2023-01-05 05:28:56,143 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4906613071759542, 'Total loss': 0.4906613071759542} | train loss {'Reaction outcome loss': 0.20245075696534628, 'Total loss': 0.20245075696534628}
2023-01-05 05:28:56,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:56,143 INFO:     Epoch: 49
2023-01-05 05:28:58,421 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4975911388794581, 'Total loss': 0.4975911388794581} | train loss {'Reaction outcome loss': 0.2051306053095023, 'Total loss': 0.2051306053095023}
2023-01-05 05:28:58,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:28:58,421 INFO:     Epoch: 50
2023-01-05 05:29:00,674 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.483709196249644, 'Total loss': 0.483709196249644} | train loss {'Reaction outcome loss': 0.1988647286864233, 'Total loss': 0.1988647286864233}
2023-01-05 05:29:00,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:00,674 INFO:     Epoch: 51
2023-01-05 05:29:02,873 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4855298466980457, 'Total loss': 0.4855298466980457} | train loss {'Reaction outcome loss': 0.2002958753835477, 'Total loss': 0.2002958753835477}
2023-01-05 05:29:02,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:02,873 INFO:     Epoch: 52
2023-01-05 05:29:05,131 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4983921587467194, 'Total loss': 0.4983921587467194} | train loss {'Reaction outcome loss': 0.1965284276777199, 'Total loss': 0.1965284276777199}
2023-01-05 05:29:05,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:05,131 INFO:     Epoch: 53
2023-01-05 05:29:07,400 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5027708897988001, 'Total loss': 0.5027708897988001} | train loss {'Reaction outcome loss': 0.1955063249814973, 'Total loss': 0.1955063249814973}
2023-01-05 05:29:07,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:07,400 INFO:     Epoch: 54
2023-01-05 05:29:09,673 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5274362385272979, 'Total loss': 0.5274362385272979} | train loss {'Reaction outcome loss': 0.19276502900605597, 'Total loss': 0.19276502900605597}
2023-01-05 05:29:09,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:09,674 INFO:     Epoch: 55
2023-01-05 05:29:11,855 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49620407025019325, 'Total loss': 0.49620407025019325} | train loss {'Reaction outcome loss': 0.190597397715714, 'Total loss': 0.190597397715714}
2023-01-05 05:29:11,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:11,855 INFO:     Epoch: 56
2023-01-05 05:29:14,044 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5133452673753103, 'Total loss': 0.5133452673753103} | train loss {'Reaction outcome loss': 0.192812570663243, 'Total loss': 0.192812570663243}
2023-01-05 05:29:14,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:14,045 INFO:     Epoch: 57
2023-01-05 05:29:16,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.530134289463361, 'Total loss': 0.530134289463361} | train loss {'Reaction outcome loss': 0.19086710075151833, 'Total loss': 0.19086710075151833}
2023-01-05 05:29:16,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:16,294 INFO:     Epoch: 58
2023-01-05 05:29:18,553 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5074512322743734, 'Total loss': 0.5074512322743734} | train loss {'Reaction outcome loss': 0.19057029386266178, 'Total loss': 0.19057029386266178}
2023-01-05 05:29:18,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:18,553 INFO:     Epoch: 59
2023-01-05 05:29:20,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5353817681471507, 'Total loss': 0.5353817681471507} | train loss {'Reaction outcome loss': 0.18729271346346782, 'Total loss': 0.18729271346346782}
2023-01-05 05:29:20,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:20,758 INFO:     Epoch: 60
2023-01-05 05:29:22,945 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48916754126548767, 'Total loss': 0.48916754126548767} | train loss {'Reaction outcome loss': 0.1883330305631437, 'Total loss': 0.1883330305631437}
2023-01-05 05:29:22,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:22,945 INFO:     Epoch: 61
2023-01-05 05:29:25,185 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4792701989412308, 'Total loss': 0.4792701989412308} | train loss {'Reaction outcome loss': 0.18307885926364775, 'Total loss': 0.18307885926364775}
2023-01-05 05:29:25,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:25,185 INFO:     Epoch: 62
2023-01-05 05:29:27,448 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5173344711462656, 'Total loss': 0.5173344711462656} | train loss {'Reaction outcome loss': 0.18602566745818092, 'Total loss': 0.18602566745818092}
2023-01-05 05:29:27,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:27,448 INFO:     Epoch: 63
2023-01-05 05:29:29,715 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5443663279215495, 'Total loss': 0.5443663279215495} | train loss {'Reaction outcome loss': 0.18302999381379423, 'Total loss': 0.18302999381379423}
2023-01-05 05:29:29,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:29,716 INFO:     Epoch: 64
2023-01-05 05:29:31,981 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5046451985836029, 'Total loss': 0.5046451985836029} | train loss {'Reaction outcome loss': 0.17844595650163905, 'Total loss': 0.17844595650163905}
2023-01-05 05:29:31,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:31,981 INFO:     Epoch: 65
2023-01-05 05:29:34,193 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5146966010332108, 'Total loss': 0.5146966010332108} | train loss {'Reaction outcome loss': 0.1780294276091408, 'Total loss': 0.1780294276091408}
2023-01-05 05:29:34,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:34,193 INFO:     Epoch: 66
2023-01-05 05:29:36,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5085803305109342, 'Total loss': 0.5085803305109342} | train loss {'Reaction outcome loss': 0.17592963699036235, 'Total loss': 0.17592963699036235}
2023-01-05 05:29:36,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:36,386 INFO:     Epoch: 67
2023-01-05 05:29:38,615 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.509823523958524, 'Total loss': 0.509823523958524} | train loss {'Reaction outcome loss': 0.175140759220098, 'Total loss': 0.175140759220098}
2023-01-05 05:29:38,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:38,615 INFO:     Epoch: 68
2023-01-05 05:29:40,847 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5171805053949357, 'Total loss': 0.5171805053949357} | train loss {'Reaction outcome loss': 0.18089113053983408, 'Total loss': 0.18089113053983408}
2023-01-05 05:29:40,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:40,848 INFO:     Epoch: 69
2023-01-05 05:29:43,073 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5318948820233345, 'Total loss': 0.5318948820233345} | train loss {'Reaction outcome loss': 0.17194205258102138, 'Total loss': 0.17194205258102138}
2023-01-05 05:29:43,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:43,073 INFO:     Epoch: 70
2023-01-05 05:29:45,325 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5318108826875687, 'Total loss': 0.5318108826875687} | train loss {'Reaction outcome loss': 0.17132789078958682, 'Total loss': 0.17132789078958682}
2023-01-05 05:29:45,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:45,325 INFO:     Epoch: 71
2023-01-05 05:29:47,556 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49179251690705617, 'Total loss': 0.49179251690705617} | train loss {'Reaction outcome loss': 0.17465065478511987, 'Total loss': 0.17465065478511987}
2023-01-05 05:29:47,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:47,557 INFO:     Epoch: 72
2023-01-05 05:29:49,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5290782794356346, 'Total loss': 0.5290782794356346} | train loss {'Reaction outcome loss': 0.1694656400991745, 'Total loss': 0.1694656400991745}
2023-01-05 05:29:49,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:49,775 INFO:     Epoch: 73
2023-01-05 05:29:51,978 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5187204062938691, 'Total loss': 0.5187204062938691} | train loss {'Reaction outcome loss': 0.16976988330375847, 'Total loss': 0.16976988330375847}
2023-01-05 05:29:51,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:51,979 INFO:     Epoch: 74
2023-01-05 05:29:54,209 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5406999270121257, 'Total loss': 0.5406999270121257} | train loss {'Reaction outcome loss': 0.16812128563569556, 'Total loss': 0.16812128563569556}
2023-01-05 05:29:54,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:54,210 INFO:     Epoch: 75
2023-01-05 05:29:56,434 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5629339834054311, 'Total loss': 0.5629339834054311} | train loss {'Reaction outcome loss': 0.1661336913356887, 'Total loss': 0.1661336913356887}
2023-01-05 05:29:56,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:56,434 INFO:     Epoch: 76
2023-01-05 05:29:58,689 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5239300280809402, 'Total loss': 0.5239300280809402} | train loss {'Reaction outcome loss': 0.1702139450334658, 'Total loss': 0.1702139450334658}
2023-01-05 05:29:58,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:29:58,690 INFO:     Epoch: 77
2023-01-05 05:30:00,937 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5142928381760915, 'Total loss': 0.5142928381760915} | train loss {'Reaction outcome loss': 0.1664394399937955, 'Total loss': 0.1664394399937955}
2023-01-05 05:30:00,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:00,938 INFO:     Epoch: 78
2023-01-05 05:30:03,159 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5138186742862065, 'Total loss': 0.5138186742862065} | train loss {'Reaction outcome loss': 0.16389536956789152, 'Total loss': 0.16389536956789152}
2023-01-05 05:30:03,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:03,159 INFO:     Epoch: 79
2023-01-05 05:30:05,362 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.508633454144001, 'Total loss': 0.508633454144001} | train loss {'Reaction outcome loss': 0.1702288600216058, 'Total loss': 0.1702288600216058}
2023-01-05 05:30:05,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:05,363 INFO:     Epoch: 80
2023-01-05 05:30:07,614 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.504117633899053, 'Total loss': 0.504117633899053} | train loss {'Reaction outcome loss': 0.1660931213584053, 'Total loss': 0.1660931213584053}
2023-01-05 05:30:07,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:07,615 INFO:     Epoch: 81
2023-01-05 05:30:09,748 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.492713496585687, 'Total loss': 0.492713496585687} | train loss {'Reaction outcome loss': 0.16148047311574437, 'Total loss': 0.16148047311574437}
2023-01-05 05:30:09,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:09,748 INFO:     Epoch: 82
2023-01-05 05:30:11,982 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5193979233503342, 'Total loss': 0.5193979233503342} | train loss {'Reaction outcome loss': 0.16117972415108706, 'Total loss': 0.16117972415108706}
2023-01-05 05:30:11,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:11,982 INFO:     Epoch: 83
2023-01-05 05:30:14,186 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5207038929065069, 'Total loss': 0.5207038929065069} | train loss {'Reaction outcome loss': 0.16015179331720358, 'Total loss': 0.16015179331720358}
2023-01-05 05:30:14,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:14,186 INFO:     Epoch: 84
2023-01-05 05:30:16,361 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5405414551496506, 'Total loss': 0.5405414551496506} | train loss {'Reaction outcome loss': 0.16026437925073966, 'Total loss': 0.16026437925073966}
2023-01-05 05:30:16,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:16,362 INFO:     Epoch: 85
2023-01-05 05:30:18,607 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.514150224129359, 'Total loss': 0.514150224129359} | train loss {'Reaction outcome loss': 0.15963670991139237, 'Total loss': 0.15963670991139237}
2023-01-05 05:30:18,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:18,607 INFO:     Epoch: 86
2023-01-05 05:30:20,816 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5217455794413884, 'Total loss': 0.5217455794413884} | train loss {'Reaction outcome loss': 0.1591614716272761, 'Total loss': 0.1591614716272761}
2023-01-05 05:30:20,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:20,817 INFO:     Epoch: 87
2023-01-05 05:30:23,057 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5101073019206523, 'Total loss': 0.5101073019206523} | train loss {'Reaction outcome loss': 0.15831030061508827, 'Total loss': 0.15831030061508827}
2023-01-05 05:30:23,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:23,058 INFO:     Epoch: 88
2023-01-05 05:30:25,274 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5307940810918808, 'Total loss': 0.5307940810918808} | train loss {'Reaction outcome loss': 0.1571965713981902, 'Total loss': 0.1571965713981902}
2023-01-05 05:30:25,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:25,274 INFO:     Epoch: 89
2023-01-05 05:30:27,457 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5024585562447706, 'Total loss': 0.5024585562447706} | train loss {'Reaction outcome loss': 0.15683243474973507, 'Total loss': 0.15683243474973507}
2023-01-05 05:30:27,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:27,457 INFO:     Epoch: 90
2023-01-05 05:30:29,647 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5604935626188914, 'Total loss': 0.5604935626188914} | train loss {'Reaction outcome loss': 0.154902532094054, 'Total loss': 0.154902532094054}
2023-01-05 05:30:29,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:29,647 INFO:     Epoch: 91
2023-01-05 05:30:31,834 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5433453649282456, 'Total loss': 0.5433453649282456} | train loss {'Reaction outcome loss': 0.1584230338421647, 'Total loss': 0.1584230338421647}
2023-01-05 05:30:31,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:31,835 INFO:     Epoch: 92
2023-01-05 05:30:34,107 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5876244723796844, 'Total loss': 0.5876244723796844} | train loss {'Reaction outcome loss': 0.15410678944170528, 'Total loss': 0.15410678944170528}
2023-01-05 05:30:34,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:34,107 INFO:     Epoch: 93
2023-01-05 05:30:36,319 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5679488917191823, 'Total loss': 0.5679488917191823} | train loss {'Reaction outcome loss': 0.15623925049160522, 'Total loss': 0.15623925049160522}
2023-01-05 05:30:36,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:36,320 INFO:     Epoch: 94
2023-01-05 05:30:38,580 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5184981226921082, 'Total loss': 0.5184981226921082} | train loss {'Reaction outcome loss': 0.15029452342728308, 'Total loss': 0.15029452342728308}
2023-01-05 05:30:38,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:38,580 INFO:     Epoch: 95
2023-01-05 05:30:40,813 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5079653461774191, 'Total loss': 0.5079653461774191} | train loss {'Reaction outcome loss': 0.15374918712894786, 'Total loss': 0.15374918712894786}
2023-01-05 05:30:40,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:40,813 INFO:     Epoch: 96
2023-01-05 05:30:43,031 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5277829676866531, 'Total loss': 0.5277829676866531} | train loss {'Reaction outcome loss': 0.15598537188379719, 'Total loss': 0.15598537188379719}
2023-01-05 05:30:43,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:43,031 INFO:     Epoch: 97
2023-01-05 05:30:45,169 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5212996820608775, 'Total loss': 0.5212996820608775} | train loss {'Reaction outcome loss': 0.1522671649390529, 'Total loss': 0.1522671649390529}
2023-01-05 05:30:45,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:45,169 INFO:     Epoch: 98
2023-01-05 05:30:47,425 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5134642312924067, 'Total loss': 0.5134642312924067} | train loss {'Reaction outcome loss': 0.14804857095118465, 'Total loss': 0.14804857095118465}
2023-01-05 05:30:47,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:47,425 INFO:     Epoch: 99
2023-01-05 05:30:49,710 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5658087591330211, 'Total loss': 0.5658087591330211} | train loss {'Reaction outcome loss': 0.150447276242696, 'Total loss': 0.150447276242696}
2023-01-05 05:30:49,710 INFO:     Best model found after epoch 23 of 100.
2023-01-05 05:30:49,710 INFO:   Done with stage: TRAINING
2023-01-05 05:30:49,710 INFO:   Starting stage: EVALUATION
2023-01-05 05:30:49,839 INFO:   Done with stage: EVALUATION
2023-01-05 05:30:49,839 INFO:   Leaving out SEQ value Fold_5
2023-01-05 05:30:49,852 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 05:30:49,852 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:30:50,508 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:30:50,508 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:30:50,582 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:30:50,582 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:30:50,582 INFO:     No hyperparam tuning for this model
2023-01-05 05:30:50,582 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:30:50,582 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:30:50,583 INFO:     None feature selector for col prot
2023-01-05 05:30:50,583 INFO:     None feature selector for col prot
2023-01-05 05:30:50,583 INFO:     None feature selector for col prot
2023-01-05 05:30:50,584 INFO:     None feature selector for col chem
2023-01-05 05:30:50,584 INFO:     None feature selector for col chem
2023-01-05 05:30:50,584 INFO:     None feature selector for col chem
2023-01-05 05:30:50,584 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:30:50,584 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:30:50,585 INFO:     Number of params in model 72931
2023-01-05 05:30:50,589 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:30:50,589 INFO:   Starting stage: TRAINING
2023-01-05 05:30:50,649 INFO:     Val loss before train {'Reaction outcome loss': 0.8988757729530334, 'Total loss': 0.8988757729530334}
2023-01-05 05:30:50,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:50,649 INFO:     Epoch: 0
2023-01-05 05:30:52,911 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6983850638071696, 'Total loss': 0.6983850638071696} | train loss {'Reaction outcome loss': 0.9255903540750703, 'Total loss': 0.9255903540750703}
2023-01-05 05:30:52,912 INFO:     Found new best model at epoch 0
2023-01-05 05:30:52,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:52,914 INFO:     Epoch: 1
2023-01-05 05:30:55,133 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5367148598035176, 'Total loss': 0.5367148598035176} | train loss {'Reaction outcome loss': 0.6256181634828072, 'Total loss': 0.6256181634828072}
2023-01-05 05:30:55,133 INFO:     Found new best model at epoch 1
2023-01-05 05:30:55,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:55,134 INFO:     Epoch: 2
2023-01-05 05:30:57,002 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48590845465660093, 'Total loss': 0.48590845465660093} | train loss {'Reaction outcome loss': 0.5277301465776423, 'Total loss': 0.5277301465776423}
2023-01-05 05:30:57,002 INFO:     Found new best model at epoch 2
2023-01-05 05:30:57,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:57,004 INFO:     Epoch: 3
2023-01-05 05:30:58,843 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4717428535223007, 'Total loss': 0.4717428535223007} | train loss {'Reaction outcome loss': 0.4863716446212913, 'Total loss': 0.4863716446212913}
2023-01-05 05:30:58,843 INFO:     Found new best model at epoch 3
2023-01-05 05:30:58,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:30:58,844 INFO:     Epoch: 4
2023-01-05 05:31:00,996 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45419334967931113, 'Total loss': 0.45419334967931113} | train loss {'Reaction outcome loss': 0.45886315222466467, 'Total loss': 0.45886315222466467}
2023-01-05 05:31:00,996 INFO:     Found new best model at epoch 4
2023-01-05 05:31:00,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:00,998 INFO:     Epoch: 5
2023-01-05 05:31:03,221 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4698566218217214, 'Total loss': 0.4698566218217214} | train loss {'Reaction outcome loss': 0.44016938019100077, 'Total loss': 0.44016938019100077}
2023-01-05 05:31:03,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:03,221 INFO:     Epoch: 6
2023-01-05 05:31:05,415 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44173071583112083, 'Total loss': 0.44173071583112083} | train loss {'Reaction outcome loss': 0.4245572914554324, 'Total loss': 0.4245572914554324}
2023-01-05 05:31:05,415 INFO:     Found new best model at epoch 6
2023-01-05 05:31:05,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:05,416 INFO:     Epoch: 7
2023-01-05 05:31:07,608 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4365724116563797, 'Total loss': 0.4365724116563797} | train loss {'Reaction outcome loss': 0.41030163702551636, 'Total loss': 0.41030163702551636}
2023-01-05 05:31:07,608 INFO:     Found new best model at epoch 7
2023-01-05 05:31:07,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:07,609 INFO:     Epoch: 8
2023-01-05 05:31:09,833 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43922154704729716, 'Total loss': 0.43922154704729716} | train loss {'Reaction outcome loss': 0.4032667441703783, 'Total loss': 0.4032667441703783}
2023-01-05 05:31:09,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:09,833 INFO:     Epoch: 9
2023-01-05 05:31:12,074 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40916961034139, 'Total loss': 0.40916961034139} | train loss {'Reaction outcome loss': 0.39115635921593606, 'Total loss': 0.39115635921593606}
2023-01-05 05:31:12,074 INFO:     Found new best model at epoch 9
2023-01-05 05:31:12,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:12,075 INFO:     Epoch: 10
2023-01-05 05:31:14,245 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4354340712229411, 'Total loss': 0.4354340712229411} | train loss {'Reaction outcome loss': 0.3863620071365945, 'Total loss': 0.3863620071365945}
2023-01-05 05:31:14,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:14,246 INFO:     Epoch: 11
2023-01-05 05:31:16,465 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4054199675718943, 'Total loss': 0.4054199675718943} | train loss {'Reaction outcome loss': 0.37838766484484343, 'Total loss': 0.37838766484484343}
2023-01-05 05:31:16,465 INFO:     Found new best model at epoch 11
2023-01-05 05:31:16,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:16,467 INFO:     Epoch: 12
2023-01-05 05:31:18,722 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4230762372414271, 'Total loss': 0.4230762372414271} | train loss {'Reaction outcome loss': 0.36416003836944216, 'Total loss': 0.36416003836944216}
2023-01-05 05:31:18,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:18,722 INFO:     Epoch: 13
2023-01-05 05:31:20,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41795378426710766, 'Total loss': 0.41795378426710766} | train loss {'Reaction outcome loss': 0.3554124087902183, 'Total loss': 0.3554124087902183}
2023-01-05 05:31:20,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:20,956 INFO:     Epoch: 14
2023-01-05 05:31:23,132 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43039217392603557, 'Total loss': 0.43039217392603557} | train loss {'Reaction outcome loss': 0.3511182048529494, 'Total loss': 0.3511182048529494}
2023-01-05 05:31:23,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:23,133 INFO:     Epoch: 15
2023-01-05 05:31:25,372 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4124996642271678, 'Total loss': 0.4124996642271678} | train loss {'Reaction outcome loss': 0.3411909465809161, 'Total loss': 0.3411909465809161}
2023-01-05 05:31:25,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:25,372 INFO:     Epoch: 16
2023-01-05 05:31:27,563 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3875465919574102, 'Total loss': 0.3875465919574102} | train loss {'Reaction outcome loss': 0.3355432910716921, 'Total loss': 0.3355432910716921}
2023-01-05 05:31:27,563 INFO:     Found new best model at epoch 16
2023-01-05 05:31:27,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:27,564 INFO:     Epoch: 17
2023-01-05 05:31:29,783 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40296623508135476, 'Total loss': 0.40296623508135476} | train loss {'Reaction outcome loss': 0.3332826719225959, 'Total loss': 0.3332826719225959}
2023-01-05 05:31:29,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:29,784 INFO:     Epoch: 18
2023-01-05 05:31:32,041 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3987600222229958, 'Total loss': 0.3987600222229958} | train loss {'Reaction outcome loss': 0.32136232908209955, 'Total loss': 0.32136232908209955}
2023-01-05 05:31:32,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:32,042 INFO:     Epoch: 19
2023-01-05 05:31:34,251 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41823214789231616, 'Total loss': 0.41823214789231616} | train loss {'Reaction outcome loss': 0.3192094102340485, 'Total loss': 0.3192094102340485}
2023-01-05 05:31:34,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:34,251 INFO:     Epoch: 20
2023-01-05 05:31:36,441 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40900016327699024, 'Total loss': 0.40900016327699024} | train loss {'Reaction outcome loss': 0.3166112160370668, 'Total loss': 0.3166112160370668}
2023-01-05 05:31:36,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:36,442 INFO:     Epoch: 21
2023-01-05 05:31:38,698 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39107903043429054, 'Total loss': 0.39107903043429054} | train loss {'Reaction outcome loss': 0.30687622079081056, 'Total loss': 0.30687622079081056}
2023-01-05 05:31:38,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:38,699 INFO:     Epoch: 22
2023-01-05 05:31:40,932 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39656076232592263, 'Total loss': 0.39656076232592263} | train loss {'Reaction outcome loss': 0.30199150785481027, 'Total loss': 0.30199150785481027}
2023-01-05 05:31:40,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:40,932 INFO:     Epoch: 23
2023-01-05 05:31:43,138 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40170708994070686, 'Total loss': 0.40170708994070686} | train loss {'Reaction outcome loss': 0.2958478465514923, 'Total loss': 0.2958478465514923}
2023-01-05 05:31:43,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:43,139 INFO:     Epoch: 24
2023-01-05 05:31:45,379 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4193196356296539, 'Total loss': 0.4193196356296539} | train loss {'Reaction outcome loss': 0.2918717567052437, 'Total loss': 0.2918717567052437}
2023-01-05 05:31:45,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:45,379 INFO:     Epoch: 25
2023-01-05 05:31:47,600 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3909036487340927, 'Total loss': 0.3909036487340927} | train loss {'Reaction outcome loss': 0.2908130806974986, 'Total loss': 0.2908130806974986}
2023-01-05 05:31:47,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:47,600 INFO:     Epoch: 26
2023-01-05 05:31:49,774 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41747449735800424, 'Total loss': 0.41747449735800424} | train loss {'Reaction outcome loss': 0.28365344718260027, 'Total loss': 0.28365344718260027}
2023-01-05 05:31:49,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:49,774 INFO:     Epoch: 27
2023-01-05 05:31:51,951 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.408076344927152, 'Total loss': 0.408076344927152} | train loss {'Reaction outcome loss': 0.28357059036512666, 'Total loss': 0.28357059036512666}
2023-01-05 05:31:51,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:51,951 INFO:     Epoch: 28
2023-01-05 05:31:54,215 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4036533017953237, 'Total loss': 0.4036533017953237} | train loss {'Reaction outcome loss': 0.27706317988220963, 'Total loss': 0.27706317988220963}
2023-01-05 05:31:54,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:54,215 INFO:     Epoch: 29
2023-01-05 05:31:56,459 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45678356289863586, 'Total loss': 0.45678356289863586} | train loss {'Reaction outcome loss': 0.2761822700877052, 'Total loss': 0.2761822700877052}
2023-01-05 05:31:56,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:56,459 INFO:     Epoch: 30
2023-01-05 05:31:58,662 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41297951837380725, 'Total loss': 0.41297951837380725} | train loss {'Reaction outcome loss': 0.27012534489323947, 'Total loss': 0.27012534489323947}
2023-01-05 05:31:58,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:31:58,663 INFO:     Epoch: 31
2023-01-05 05:32:00,887 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40223591923713686, 'Total loss': 0.40223591923713686} | train loss {'Reaction outcome loss': 0.2643547327550202, 'Total loss': 0.2643547327550202}
2023-01-05 05:32:00,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:00,887 INFO:     Epoch: 32
2023-01-05 05:32:03,136 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40017222265402475, 'Total loss': 0.40017222265402475} | train loss {'Reaction outcome loss': 0.2604525403156608, 'Total loss': 0.2604525403156608}
2023-01-05 05:32:03,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:03,136 INFO:     Epoch: 33
2023-01-05 05:32:05,332 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40306527813275655, 'Total loss': 0.40306527813275655} | train loss {'Reaction outcome loss': 0.2562327025599428, 'Total loss': 0.2562327025599428}
2023-01-05 05:32:05,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:05,333 INFO:     Epoch: 34
2023-01-05 05:32:07,591 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40452646066745124, 'Total loss': 0.40452646066745124} | train loss {'Reaction outcome loss': 0.2525827829332666, 'Total loss': 0.2525827829332666}
2023-01-05 05:32:07,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:07,591 INFO:     Epoch: 35
2023-01-05 05:32:09,827 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4143012324968974, 'Total loss': 0.4143012324968974} | train loss {'Reaction outcome loss': 0.2552333255147138, 'Total loss': 0.2552333255147138}
2023-01-05 05:32:09,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:09,827 INFO:     Epoch: 36
2023-01-05 05:32:12,096 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4242462823788325, 'Total loss': 0.4242462823788325} | train loss {'Reaction outcome loss': 0.24800942363452824, 'Total loss': 0.24800942363452824}
2023-01-05 05:32:12,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:12,096 INFO:     Epoch: 37
2023-01-05 05:32:14,356 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4156223952770233, 'Total loss': 0.4156223952770233} | train loss {'Reaction outcome loss': 0.24892383669956927, 'Total loss': 0.24892383669956927}
2023-01-05 05:32:14,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:14,356 INFO:     Epoch: 38
2023-01-05 05:32:16,624 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41941625277201333, 'Total loss': 0.41941625277201333} | train loss {'Reaction outcome loss': 0.24419007504136983, 'Total loss': 0.24419007504136983}
2023-01-05 05:32:16,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:16,625 INFO:     Epoch: 39
2023-01-05 05:32:18,884 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43134740392367044, 'Total loss': 0.43134740392367044} | train loss {'Reaction outcome loss': 0.242062015411871, 'Total loss': 0.242062015411871}
2023-01-05 05:32:18,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:18,885 INFO:     Epoch: 40
2023-01-05 05:32:21,125 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41336980362733206, 'Total loss': 0.41336980362733206} | train loss {'Reaction outcome loss': 0.23520906483384676, 'Total loss': 0.23520906483384676}
2023-01-05 05:32:21,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:21,126 INFO:     Epoch: 41
2023-01-05 05:32:23,391 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.427219757437706, 'Total loss': 0.427219757437706} | train loss {'Reaction outcome loss': 0.2343534468219276, 'Total loss': 0.2343534468219276}
2023-01-05 05:32:23,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:23,391 INFO:     Epoch: 42
2023-01-05 05:32:25,495 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41924488445123037, 'Total loss': 0.41924488445123037} | train loss {'Reaction outcome loss': 0.22933299773934193, 'Total loss': 0.22933299773934193}
2023-01-05 05:32:25,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:25,495 INFO:     Epoch: 43
2023-01-05 05:32:27,762 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4323854406674703, 'Total loss': 0.4323854406674703} | train loss {'Reaction outcome loss': 0.22714597752842286, 'Total loss': 0.22714597752842286}
2023-01-05 05:32:27,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:27,763 INFO:     Epoch: 44
2023-01-05 05:32:29,961 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40884874562422435, 'Total loss': 0.40884874562422435} | train loss {'Reaction outcome loss': 0.22396449863722392, 'Total loss': 0.22396449863722392}
2023-01-05 05:32:29,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:29,961 INFO:     Epoch: 45
2023-01-05 05:32:32,180 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4184933255116145, 'Total loss': 0.4184933255116145} | train loss {'Reaction outcome loss': 0.22224216740107708, 'Total loss': 0.22224216740107708}
2023-01-05 05:32:32,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:32,181 INFO:     Epoch: 46
2023-01-05 05:32:34,418 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4205268124739329, 'Total loss': 0.4205268124739329} | train loss {'Reaction outcome loss': 0.2195360099674885, 'Total loss': 0.2195360099674885}
2023-01-05 05:32:34,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:34,419 INFO:     Epoch: 47
2023-01-05 05:32:36,668 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4230360825856527, 'Total loss': 0.4230360825856527} | train loss {'Reaction outcome loss': 0.2135711806701893, 'Total loss': 0.2135711806701893}
2023-01-05 05:32:36,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:36,668 INFO:     Epoch: 48
2023-01-05 05:32:38,895 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4548243204752604, 'Total loss': 0.4548243204752604} | train loss {'Reaction outcome loss': 0.21760878948299786, 'Total loss': 0.21760878948299786}
2023-01-05 05:32:38,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:38,895 INFO:     Epoch: 49
2023-01-05 05:32:41,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41677508503198624, 'Total loss': 0.41677508503198624} | train loss {'Reaction outcome loss': 0.21159772855307005, 'Total loss': 0.21159772855307005}
2023-01-05 05:32:41,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:41,113 INFO:     Epoch: 50
2023-01-05 05:32:43,326 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47477505803108216, 'Total loss': 0.47477505803108216} | train loss {'Reaction outcome loss': 0.21626570336991377, 'Total loss': 0.21626570336991377}
2023-01-05 05:32:43,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:43,326 INFO:     Epoch: 51
2023-01-05 05:32:45,541 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4397394930322965, 'Total loss': 0.4397394930322965} | train loss {'Reaction outcome loss': 0.2136930345998075, 'Total loss': 0.2136930345998075}
2023-01-05 05:32:45,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:45,542 INFO:     Epoch: 52
2023-01-05 05:32:47,728 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4492666800816854, 'Total loss': 0.4492666800816854} | train loss {'Reaction outcome loss': 0.20483526664143864, 'Total loss': 0.20483526664143864}
2023-01-05 05:32:47,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:47,729 INFO:     Epoch: 53
2023-01-05 05:32:49,882 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45900327861309054, 'Total loss': 0.45900327861309054} | train loss {'Reaction outcome loss': 0.20918738969100725, 'Total loss': 0.20918738969100725}
2023-01-05 05:32:49,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:49,883 INFO:     Epoch: 54
2023-01-05 05:32:52,138 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43220959305763246, 'Total loss': 0.43220959305763246} | train loss {'Reaction outcome loss': 0.20383464250821176, 'Total loss': 0.20383464250821176}
2023-01-05 05:32:52,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:52,138 INFO:     Epoch: 55
2023-01-05 05:32:54,398 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47472776969273883, 'Total loss': 0.47472776969273883} | train loss {'Reaction outcome loss': 0.19803759266558482, 'Total loss': 0.19803759266558482}
2023-01-05 05:32:54,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:54,399 INFO:     Epoch: 56
2023-01-05 05:32:56,606 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45190344254175824, 'Total loss': 0.45190344254175824} | train loss {'Reaction outcome loss': 0.2014799504221454, 'Total loss': 0.2014799504221454}
2023-01-05 05:32:56,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:56,606 INFO:     Epoch: 57
2023-01-05 05:32:58,866 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4345293089747429, 'Total loss': 0.4345293089747429} | train loss {'Reaction outcome loss': 0.19784351555287621, 'Total loss': 0.19784351555287621}
2023-01-05 05:32:58,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:32:58,866 INFO:     Epoch: 58
2023-01-05 05:33:01,129 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4417207047343254, 'Total loss': 0.4417207047343254} | train loss {'Reaction outcome loss': 0.2010551023260028, 'Total loss': 0.2010551023260028}
2023-01-05 05:33:01,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:01,129 INFO:     Epoch: 59
2023-01-05 05:33:03,371 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4386870185534159, 'Total loss': 0.4386870185534159} | train loss {'Reaction outcome loss': 0.2022750595187775, 'Total loss': 0.2022750595187775}
2023-01-05 05:33:03,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:03,371 INFO:     Epoch: 60
2023-01-05 05:33:05,551 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4755716025829315, 'Total loss': 0.4755716025829315} | train loss {'Reaction outcome loss': 0.19790996277254302, 'Total loss': 0.19790996277254302}
2023-01-05 05:33:05,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:05,551 INFO:     Epoch: 61
2023-01-05 05:33:07,712 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4680485129356384, 'Total loss': 0.4680485129356384} | train loss {'Reaction outcome loss': 0.18848270549025345, 'Total loss': 0.18848270549025345}
2023-01-05 05:33:07,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:07,712 INFO:     Epoch: 62
2023-01-05 05:33:09,942 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44125067492326103, 'Total loss': 0.44125067492326103} | train loss {'Reaction outcome loss': 0.18698009856663886, 'Total loss': 0.18698009856663886}
2023-01-05 05:33:09,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:09,942 INFO:     Epoch: 63
2023-01-05 05:33:12,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4666202376286189, 'Total loss': 0.4666202376286189} | train loss {'Reaction outcome loss': 0.19469204013881405, 'Total loss': 0.19469204013881405}
2023-01-05 05:33:12,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:12,204 INFO:     Epoch: 64
2023-01-05 05:33:14,399 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47177341878414153, 'Total loss': 0.47177341878414153} | train loss {'Reaction outcome loss': 0.1893329556513618, 'Total loss': 0.1893329556513618}
2023-01-05 05:33:14,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:14,400 INFO:     Epoch: 65
2023-01-05 05:33:16,540 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46121672292550403, 'Total loss': 0.46121672292550403} | train loss {'Reaction outcome loss': 0.1857738849918765, 'Total loss': 0.1857738849918765}
2023-01-05 05:33:16,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:16,540 INFO:     Epoch: 66
2023-01-05 05:33:18,760 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42480271955331167, 'Total loss': 0.42480271955331167} | train loss {'Reaction outcome loss': 0.193521088601127, 'Total loss': 0.193521088601127}
2023-01-05 05:33:18,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:18,761 INFO:     Epoch: 67
2023-01-05 05:33:21,035 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46361774603525796, 'Total loss': 0.46361774603525796} | train loss {'Reaction outcome loss': 0.17933211454933354, 'Total loss': 0.17933211454933354}
2023-01-05 05:33:21,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:21,035 INFO:     Epoch: 68
2023-01-05 05:33:23,304 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46030973792076113, 'Total loss': 0.46030973792076113} | train loss {'Reaction outcome loss': 0.18666365982070296, 'Total loss': 0.18666365982070296}
2023-01-05 05:33:23,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:23,304 INFO:     Epoch: 69
2023-01-05 05:33:25,577 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43987249036629994, 'Total loss': 0.43987249036629994} | train loss {'Reaction outcome loss': 0.18121430100637761, 'Total loss': 0.18121430100637761}
2023-01-05 05:33:25,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:25,578 INFO:     Epoch: 70
2023-01-05 05:33:27,842 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4477290337284406, 'Total loss': 0.4477290337284406} | train loss {'Reaction outcome loss': 0.1835854639070586, 'Total loss': 0.1835854639070586}
2023-01-05 05:33:27,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:27,842 INFO:     Epoch: 71
2023-01-05 05:33:30,082 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4747122645378113, 'Total loss': 0.4747122645378113} | train loss {'Reaction outcome loss': 0.1825426135427362, 'Total loss': 0.1825426135427362}
2023-01-05 05:33:30,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:30,082 INFO:     Epoch: 72
2023-01-05 05:33:32,284 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4626791447401047, 'Total loss': 0.4626791447401047} | train loss {'Reaction outcome loss': 0.1726725604990329, 'Total loss': 0.1726725604990329}
2023-01-05 05:33:32,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:32,285 INFO:     Epoch: 73
2023-01-05 05:33:34,543 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4563913275798162, 'Total loss': 0.4563913275798162} | train loss {'Reaction outcome loss': 0.18180980815784165, 'Total loss': 0.18180980815784165}
2023-01-05 05:33:34,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:34,544 INFO:     Epoch: 74
2023-01-05 05:33:36,818 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45730900168418886, 'Total loss': 0.45730900168418886} | train loss {'Reaction outcome loss': 0.1813805677460688, 'Total loss': 0.1813805677460688}
2023-01-05 05:33:36,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:36,818 INFO:     Epoch: 75
2023-01-05 05:33:39,084 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44265485405921934, 'Total loss': 0.44265485405921934} | train loss {'Reaction outcome loss': 0.1751435775097984, 'Total loss': 0.1751435775097984}
2023-01-05 05:33:39,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:39,085 INFO:     Epoch: 76
2023-01-05 05:33:41,351 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4838259289662043, 'Total loss': 0.4838259289662043} | train loss {'Reaction outcome loss': 0.17730864844812813, 'Total loss': 0.17730864844812813}
2023-01-05 05:33:41,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:41,353 INFO:     Epoch: 77
2023-01-05 05:33:43,594 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4477298378944397, 'Total loss': 0.4477298378944397} | train loss {'Reaction outcome loss': 0.17129324041038, 'Total loss': 0.17129324041038}
2023-01-05 05:33:43,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:43,594 INFO:     Epoch: 78
2023-01-05 05:33:45,853 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45441300223271053, 'Total loss': 0.45441300223271053} | train loss {'Reaction outcome loss': 0.1724267089739442, 'Total loss': 0.1724267089739442}
2023-01-05 05:33:45,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:45,853 INFO:     Epoch: 79
2023-01-05 05:33:48,077 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4593665500481923, 'Total loss': 0.4593665500481923} | train loss {'Reaction outcome loss': 0.177795405324804, 'Total loss': 0.177795405324804}
2023-01-05 05:33:48,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:48,078 INFO:     Epoch: 80
2023-01-05 05:33:50,231 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42127103557189305, 'Total loss': 0.42127103557189305} | train loss {'Reaction outcome loss': 0.17018091154035975, 'Total loss': 0.17018091154035975}
2023-01-05 05:33:50,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:50,231 INFO:     Epoch: 81
2023-01-05 05:33:52,418 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.482111464937528, 'Total loss': 0.482111464937528} | train loss {'Reaction outcome loss': 0.17546766133313252, 'Total loss': 0.17546766133313252}
2023-01-05 05:33:52,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:52,418 INFO:     Epoch: 82
2023-01-05 05:33:54,640 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.439333271731933, 'Total loss': 0.439333271731933} | train loss {'Reaction outcome loss': 0.17723970797538274, 'Total loss': 0.17723970797538274}
2023-01-05 05:33:54,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:54,640 INFO:     Epoch: 83
2023-01-05 05:33:56,877 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4386139323314031, 'Total loss': 0.4386139323314031} | train loss {'Reaction outcome loss': 0.16874600946230794, 'Total loss': 0.16874600946230794}
2023-01-05 05:33:56,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:56,878 INFO:     Epoch: 84
2023-01-05 05:33:59,107 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4276928946375847, 'Total loss': 0.4276928946375847} | train loss {'Reaction outcome loss': 0.1687237724413026, 'Total loss': 0.1687237724413026}
2023-01-05 05:33:59,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:33:59,108 INFO:     Epoch: 85
2023-01-05 05:34:01,361 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4432867775360743, 'Total loss': 0.4432867775360743} | train loss {'Reaction outcome loss': 0.16752506424387117, 'Total loss': 0.16752506424387117}
2023-01-05 05:34:01,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:01,362 INFO:     Epoch: 86
2023-01-05 05:34:03,608 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46865705102682115, 'Total loss': 0.46865705102682115} | train loss {'Reaction outcome loss': 0.1719395551958293, 'Total loss': 0.1719395551958293}
2023-01-05 05:34:03,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:03,608 INFO:     Epoch: 87
2023-01-05 05:34:05,869 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48640804638465246, 'Total loss': 0.48640804638465246} | train loss {'Reaction outcome loss': 0.16241362133897194, 'Total loss': 0.16241362133897194}
2023-01-05 05:34:05,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:05,869 INFO:     Epoch: 88
2023-01-05 05:34:08,133 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4575519601504008, 'Total loss': 0.4575519601504008} | train loss {'Reaction outcome loss': 0.16239257676977437, 'Total loss': 0.16239257676977437}
2023-01-05 05:34:08,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:08,133 INFO:     Epoch: 89
2023-01-05 05:34:10,396 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4484671115875244, 'Total loss': 0.4484671115875244} | train loss {'Reaction outcome loss': 0.16778935810772952, 'Total loss': 0.16778935810772952}
2023-01-05 05:34:10,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:10,396 INFO:     Epoch: 90
2023-01-05 05:34:12,621 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4447692106167475, 'Total loss': 0.4447692106167475} | train loss {'Reaction outcome loss': 0.1653930070332591, 'Total loss': 0.1653930070332591}
2023-01-05 05:34:12,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:12,621 INFO:     Epoch: 91
2023-01-05 05:34:14,834 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4587150384982427, 'Total loss': 0.4587150384982427} | train loss {'Reaction outcome loss': 0.17246213703271715, 'Total loss': 0.17246213703271715}
2023-01-05 05:34:14,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:14,834 INFO:     Epoch: 92
2023-01-05 05:34:17,030 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47666302919387815, 'Total loss': 0.47666302919387815} | train loss {'Reaction outcome loss': 0.16425403178962023, 'Total loss': 0.16425403178962023}
2023-01-05 05:34:17,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:17,032 INFO:     Epoch: 93
2023-01-05 05:34:19,271 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4639260361591975, 'Total loss': 0.4639260361591975} | train loss {'Reaction outcome loss': 0.16697778117032688, 'Total loss': 0.16697778117032688}
2023-01-05 05:34:19,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:19,271 INFO:     Epoch: 94
2023-01-05 05:34:21,480 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4666699007153511, 'Total loss': 0.4666699007153511} | train loss {'Reaction outcome loss': 0.16131459267823436, 'Total loss': 0.16131459267823436}
2023-01-05 05:34:21,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:21,480 INFO:     Epoch: 95
2023-01-05 05:34:23,738 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4696103289723396, 'Total loss': 0.4696103289723396} | train loss {'Reaction outcome loss': 0.16637822937654057, 'Total loss': 0.16637822937654057}
2023-01-05 05:34:23,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:23,739 INFO:     Epoch: 96
2023-01-05 05:34:25,977 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4487405627965927, 'Total loss': 0.4487405627965927} | train loss {'Reaction outcome loss': 0.166075701542898, 'Total loss': 0.166075701542898}
2023-01-05 05:34:25,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:25,977 INFO:     Epoch: 97
2023-01-05 05:34:28,219 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4658795764048894, 'Total loss': 0.4658795764048894} | train loss {'Reaction outcome loss': 0.16221195298485755, 'Total loss': 0.16221195298485755}
2023-01-05 05:34:28,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:28,220 INFO:     Epoch: 98
2023-01-05 05:34:30,474 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46443463762601217, 'Total loss': 0.46443463762601217} | train loss {'Reaction outcome loss': 0.16231035025175056, 'Total loss': 0.16231035025175056}
2023-01-05 05:34:30,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:30,475 INFO:     Epoch: 99
2023-01-05 05:34:32,731 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4482127885023753, 'Total loss': 0.4482127885023753} | train loss {'Reaction outcome loss': 0.16399415443056273, 'Total loss': 0.16399415443056273}
2023-01-05 05:34:32,731 INFO:     Best model found after epoch 17 of 100.
2023-01-05 05:34:32,731 INFO:   Done with stage: TRAINING
2023-01-05 05:34:32,732 INFO:   Starting stage: EVALUATION
2023-01-05 05:34:32,861 INFO:   Done with stage: EVALUATION
2023-01-05 05:34:32,861 INFO:   Leaving out SEQ value Fold_6
2023-01-05 05:34:32,874 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 05:34:32,874 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:34:33,534 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:34:33,534 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:34:33,607 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:34:33,607 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:34:33,607 INFO:     No hyperparam tuning for this model
2023-01-05 05:34:33,607 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:34:33,607 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:34:33,608 INFO:     None feature selector for col prot
2023-01-05 05:34:33,608 INFO:     None feature selector for col prot
2023-01-05 05:34:33,608 INFO:     None feature selector for col prot
2023-01-05 05:34:33,608 INFO:     None feature selector for col chem
2023-01-05 05:34:33,608 INFO:     None feature selector for col chem
2023-01-05 05:34:33,608 INFO:     None feature selector for col chem
2023-01-05 05:34:33,609 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:34:33,609 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:34:33,610 INFO:     Number of params in model 72931
2023-01-05 05:34:33,613 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:34:33,613 INFO:   Starting stage: TRAINING
2023-01-05 05:34:33,673 INFO:     Val loss before train {'Reaction outcome loss': 0.9400554656982422, 'Total loss': 0.9400554656982422}
2023-01-05 05:34:33,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:33,674 INFO:     Epoch: 0
2023-01-05 05:34:35,935 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7033462742964427, 'Total loss': 0.7033462742964427} | train loss {'Reaction outcome loss': 0.960892122306118, 'Total loss': 0.960892122306118}
2023-01-05 05:34:35,936 INFO:     Found new best model at epoch 0
2023-01-05 05:34:35,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:35,937 INFO:     Epoch: 1
2023-01-05 05:34:38,141 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49189637005329134, 'Total loss': 0.49189637005329134} | train loss {'Reaction outcome loss': 0.6510353779104212, 'Total loss': 0.6510353779104212}
2023-01-05 05:34:38,141 INFO:     Found new best model at epoch 1
2023-01-05 05:34:38,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:38,143 INFO:     Epoch: 2
2023-01-05 05:34:40,369 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46957091689109803, 'Total loss': 0.46957091689109803} | train loss {'Reaction outcome loss': 0.5390362005801838, 'Total loss': 0.5390362005801838}
2023-01-05 05:34:40,370 INFO:     Found new best model at epoch 2
2023-01-05 05:34:40,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:40,371 INFO:     Epoch: 3
2023-01-05 05:34:42,622 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.424543489019076, 'Total loss': 0.424543489019076} | train loss {'Reaction outcome loss': 0.5011670809467778, 'Total loss': 0.5011670809467778}
2023-01-05 05:34:42,622 INFO:     Found new best model at epoch 3
2023-01-05 05:34:42,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:42,623 INFO:     Epoch: 4
2023-01-05 05:34:44,879 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43244901796181995, 'Total loss': 0.43244901796181995} | train loss {'Reaction outcome loss': 0.470060896491531, 'Total loss': 0.470060896491531}
2023-01-05 05:34:44,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:44,879 INFO:     Epoch: 5
2023-01-05 05:34:47,067 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4125426610310872, 'Total loss': 0.4125426610310872} | train loss {'Reaction outcome loss': 0.4528467003726787, 'Total loss': 0.4528467003726787}
2023-01-05 05:34:47,068 INFO:     Found new best model at epoch 5
2023-01-05 05:34:47,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:47,069 INFO:     Epoch: 6
2023-01-05 05:34:49,243 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39979068040847776, 'Total loss': 0.39979068040847776} | train loss {'Reaction outcome loss': 0.4384548571834926, 'Total loss': 0.4384548571834926}
2023-01-05 05:34:49,244 INFO:     Found new best model at epoch 6
2023-01-05 05:34:49,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:49,245 INFO:     Epoch: 7
2023-01-05 05:34:51,481 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3913611173629761, 'Total loss': 0.3913611173629761} | train loss {'Reaction outcome loss': 0.4226855067569857, 'Total loss': 0.4226855067569857}
2023-01-05 05:34:51,482 INFO:     Found new best model at epoch 7
2023-01-05 05:34:51,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:51,483 INFO:     Epoch: 8
2023-01-05 05:34:53,689 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3748075673977534, 'Total loss': 0.3748075673977534} | train loss {'Reaction outcome loss': 0.4131107802102712, 'Total loss': 0.4131107802102712}
2023-01-05 05:34:53,690 INFO:     Found new best model at epoch 8
2023-01-05 05:34:53,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:53,691 INFO:     Epoch: 9
2023-01-05 05:34:55,835 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37019280989964803, 'Total loss': 0.37019280989964803} | train loss {'Reaction outcome loss': 0.39962149373783534, 'Total loss': 0.39962149373783534}
2023-01-05 05:34:55,835 INFO:     Found new best model at epoch 9
2023-01-05 05:34:55,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:55,836 INFO:     Epoch: 10
2023-01-05 05:34:58,025 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3525754059354464, 'Total loss': 0.3525754059354464} | train loss {'Reaction outcome loss': 0.39456358654189194, 'Total loss': 0.39456358654189194}
2023-01-05 05:34:58,026 INFO:     Found new best model at epoch 10
2023-01-05 05:34:58,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:34:58,027 INFO:     Epoch: 11
2023-01-05 05:35:00,208 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3771026541789373, 'Total loss': 0.3771026541789373} | train loss {'Reaction outcome loss': 0.3880127123708329, 'Total loss': 0.3880127123708329}
2023-01-05 05:35:00,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:00,209 INFO:     Epoch: 12
2023-01-05 05:35:02,421 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3729075709978739, 'Total loss': 0.3729075709978739} | train loss {'Reaction outcome loss': 0.3740288974172587, 'Total loss': 0.3740288974172587}
2023-01-05 05:35:02,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:02,421 INFO:     Epoch: 13
2023-01-05 05:35:04,635 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37704898218313854, 'Total loss': 0.37704898218313854} | train loss {'Reaction outcome loss': 0.3678382604991486, 'Total loss': 0.3678382604991486}
2023-01-05 05:35:04,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:04,635 INFO:     Epoch: 14
2023-01-05 05:35:06,886 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3570171301563581, 'Total loss': 0.3570171301563581} | train loss {'Reaction outcome loss': 0.36056110596398583, 'Total loss': 0.36056110596398583}
2023-01-05 05:35:06,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:06,886 INFO:     Epoch: 15
2023-01-05 05:35:09,082 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.35515874773263933, 'Total loss': 0.35515874773263933} | train loss {'Reaction outcome loss': 0.35256411880254745, 'Total loss': 0.35256411880254745}
2023-01-05 05:35:09,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:09,083 INFO:     Epoch: 16
2023-01-05 05:35:11,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.34175894657770794, 'Total loss': 0.34175894657770794} | train loss {'Reaction outcome loss': 0.34760714928865, 'Total loss': 0.34760714928865}
2023-01-05 05:35:11,297 INFO:     Found new best model at epoch 16
2023-01-05 05:35:11,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:11,299 INFO:     Epoch: 17
2023-01-05 05:35:13,506 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3555563380320867, 'Total loss': 0.3555563380320867} | train loss {'Reaction outcome loss': 0.33740078114537986, 'Total loss': 0.33740078114537986}
2023-01-05 05:35:13,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:13,507 INFO:     Epoch: 18
2023-01-05 05:35:15,658 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.34790763854980467, 'Total loss': 0.34790763854980467} | train loss {'Reaction outcome loss': 0.33469499400161234, 'Total loss': 0.33469499400161234}
2023-01-05 05:35:15,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:15,658 INFO:     Epoch: 19
2023-01-05 05:35:17,860 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.33610581010580065, 'Total loss': 0.33610581010580065} | train loss {'Reaction outcome loss': 0.3281369884145389, 'Total loss': 0.3281369884145389}
2023-01-05 05:35:17,860 INFO:     Found new best model at epoch 19
2023-01-05 05:35:17,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:17,862 INFO:     Epoch: 20
2023-01-05 05:35:20,094 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3492938111225764, 'Total loss': 0.3492938111225764} | train loss {'Reaction outcome loss': 0.32365968933712275, 'Total loss': 0.32365968933712275}
2023-01-05 05:35:20,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:20,094 INFO:     Epoch: 21
2023-01-05 05:35:22,338 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35843045115470884, 'Total loss': 0.35843045115470884} | train loss {'Reaction outcome loss': 0.3139868452338105, 'Total loss': 0.3139868452338105}
2023-01-05 05:35:22,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:22,338 INFO:     Epoch: 22
2023-01-05 05:35:24,483 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34290661588311194, 'Total loss': 0.34290661588311194} | train loss {'Reaction outcome loss': 0.31177680154031795, 'Total loss': 0.31177680154031795}
2023-01-05 05:35:24,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:24,483 INFO:     Epoch: 23
2023-01-05 05:35:26,728 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36606018195549644, 'Total loss': 0.36606018195549644} | train loss {'Reaction outcome loss': 0.3033198534379905, 'Total loss': 0.3033198534379905}
2023-01-05 05:35:26,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:26,729 INFO:     Epoch: 24
2023-01-05 05:35:28,903 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35539083629846574, 'Total loss': 0.35539083629846574} | train loss {'Reaction outcome loss': 0.30043111967481, 'Total loss': 0.30043111967481}
2023-01-05 05:35:28,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:28,905 INFO:     Epoch: 25
2023-01-05 05:35:31,127 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.351755021015803, 'Total loss': 0.351755021015803} | train loss {'Reaction outcome loss': 0.29571634318531637, 'Total loss': 0.29571634318531637}
2023-01-05 05:35:31,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:31,127 INFO:     Epoch: 26
2023-01-05 05:35:33,387 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.374514797826608, 'Total loss': 0.374514797826608} | train loss {'Reaction outcome loss': 0.2932144079612911, 'Total loss': 0.2932144079612911}
2023-01-05 05:35:33,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:33,388 INFO:     Epoch: 27
2023-01-05 05:35:35,535 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.33167781829833987, 'Total loss': 0.33167781829833987} | train loss {'Reaction outcome loss': 0.2865775676060885, 'Total loss': 0.2865775676060885}
2023-01-05 05:35:35,536 INFO:     Found new best model at epoch 27
2023-01-05 05:35:35,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:35,537 INFO:     Epoch: 28
2023-01-05 05:35:37,771 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3541610057155291, 'Total loss': 0.3541610057155291} | train loss {'Reaction outcome loss': 0.2818545586150476, 'Total loss': 0.2818545586150476}
2023-01-05 05:35:37,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:37,771 INFO:     Epoch: 29
2023-01-05 05:35:39,999 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.33715869883696237, 'Total loss': 0.33715869883696237} | train loss {'Reaction outcome loss': 0.2781916940551157, 'Total loss': 0.2781916940551157}
2023-01-05 05:35:39,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:39,999 INFO:     Epoch: 30
2023-01-05 05:35:42,161 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34054093857606255, 'Total loss': 0.34054093857606255} | train loss {'Reaction outcome loss': 0.2754020001268559, 'Total loss': 0.2754020001268559}
2023-01-05 05:35:42,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:42,161 INFO:     Epoch: 31
2023-01-05 05:35:44,426 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3238261520862579, 'Total loss': 0.3238261520862579} | train loss {'Reaction outcome loss': 0.27226664337063955, 'Total loss': 0.27226664337063955}
2023-01-05 05:35:44,426 INFO:     Found new best model at epoch 31
2023-01-05 05:35:44,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:44,428 INFO:     Epoch: 32
2023-01-05 05:35:46,677 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3535318573315938, 'Total loss': 0.3535318573315938} | train loss {'Reaction outcome loss': 0.26617478087060287, 'Total loss': 0.26617478087060287}
2023-01-05 05:35:46,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:46,677 INFO:     Epoch: 33
2023-01-05 05:35:48,901 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3394988228877385, 'Total loss': 0.3394988228877385} | train loss {'Reaction outcome loss': 0.2607680387418408, 'Total loss': 0.2607680387418408}
2023-01-05 05:35:48,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:48,902 INFO:     Epoch: 34
2023-01-05 05:35:51,148 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3651509294907252, 'Total loss': 0.3651509294907252} | train loss {'Reaction outcome loss': 0.2576224256562412, 'Total loss': 0.2576224256562412}
2023-01-05 05:35:51,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:51,148 INFO:     Epoch: 35
2023-01-05 05:35:53,395 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3435586492220561, 'Total loss': 0.3435586492220561} | train loss {'Reaction outcome loss': 0.25158229593981046, 'Total loss': 0.25158229593981046}
2023-01-05 05:35:53,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:53,396 INFO:     Epoch: 36
2023-01-05 05:35:55,668 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3438707192738851, 'Total loss': 0.3438707192738851} | train loss {'Reaction outcome loss': 0.2523003595373476, 'Total loss': 0.2523003595373476}
2023-01-05 05:35:55,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:55,668 INFO:     Epoch: 37
2023-01-05 05:35:57,913 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3362403223911921, 'Total loss': 0.3362403223911921} | train loss {'Reaction outcome loss': 0.24911444339000147, 'Total loss': 0.24911444339000147}
2023-01-05 05:35:57,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:35:57,913 INFO:     Epoch: 38
2023-01-05 05:36:00,179 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3587078720331192, 'Total loss': 0.3587078720331192} | train loss {'Reaction outcome loss': 0.24372786664763726, 'Total loss': 0.24372786664763726}
2023-01-05 05:36:00,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:00,180 INFO:     Epoch: 39
2023-01-05 05:36:02,411 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36522253702084223, 'Total loss': 0.36522253702084223} | train loss {'Reaction outcome loss': 0.24708353519937298, 'Total loss': 0.24708353519937298}
2023-01-05 05:36:02,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:02,411 INFO:     Epoch: 40
2023-01-05 05:36:04,564 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3426119287808736, 'Total loss': 0.3426119287808736} | train loss {'Reaction outcome loss': 0.23820608905398888, 'Total loss': 0.23820608905398888}
2023-01-05 05:36:04,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:04,565 INFO:     Epoch: 41
2023-01-05 05:36:06,822 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34900476535161334, 'Total loss': 0.34900476535161334} | train loss {'Reaction outcome loss': 0.23788968377514652, 'Total loss': 0.23788968377514652}
2023-01-05 05:36:06,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:06,823 INFO:     Epoch: 42
2023-01-05 05:36:09,072 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33717313831051193, 'Total loss': 0.33717313831051193} | train loss {'Reaction outcome loss': 0.23678759997878696, 'Total loss': 0.23678759997878696}
2023-01-05 05:36:09,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:09,073 INFO:     Epoch: 43
2023-01-05 05:36:11,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36239900489648186, 'Total loss': 0.36239900489648186} | train loss {'Reaction outcome loss': 0.23647560797873818, 'Total loss': 0.23647560797873818}
2023-01-05 05:36:11,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:11,298 INFO:     Epoch: 44
2023-01-05 05:36:13,511 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.32414878308773043, 'Total loss': 0.32414878308773043} | train loss {'Reaction outcome loss': 0.2289320607585597, 'Total loss': 0.2289320607585597}
2023-01-05 05:36:13,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:13,511 INFO:     Epoch: 45
2023-01-05 05:36:15,733 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33406580773492656, 'Total loss': 0.33406580773492656} | train loss {'Reaction outcome loss': 0.23054771193904997, 'Total loss': 0.23054771193904997}
2023-01-05 05:36:15,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:15,733 INFO:     Epoch: 46
2023-01-05 05:36:17,903 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.32026319901148476, 'Total loss': 0.32026319901148476} | train loss {'Reaction outcome loss': 0.22633032503433606, 'Total loss': 0.22633032503433606}
2023-01-05 05:36:17,904 INFO:     Found new best model at epoch 46
2023-01-05 05:36:17,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:17,905 INFO:     Epoch: 47
2023-01-05 05:36:20,115 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3354811211427053, 'Total loss': 0.3354811211427053} | train loss {'Reaction outcome loss': 0.22013522976410949, 'Total loss': 0.22013522976410949}
2023-01-05 05:36:20,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:20,116 INFO:     Epoch: 48
2023-01-05 05:36:22,350 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3562563180923462, 'Total loss': 0.3562563180923462} | train loss {'Reaction outcome loss': 0.22213338508475775, 'Total loss': 0.22213338508475775}
2023-01-05 05:36:22,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:22,350 INFO:     Epoch: 49
2023-01-05 05:36:24,593 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34479123204946516, 'Total loss': 0.34479123204946516} | train loss {'Reaction outcome loss': 0.22020475176374835, 'Total loss': 0.22020475176374835}
2023-01-05 05:36:24,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:24,594 INFO:     Epoch: 50
2023-01-05 05:36:26,831 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3362995723883311, 'Total loss': 0.3362995723883311} | train loss {'Reaction outcome loss': 0.21918175875844723, 'Total loss': 0.21918175875844723}
2023-01-05 05:36:26,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:26,831 INFO:     Epoch: 51
2023-01-05 05:36:29,089 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3423326724519332, 'Total loss': 0.3423326724519332} | train loss {'Reaction outcome loss': 0.21961836608308316, 'Total loss': 0.21961836608308316}
2023-01-05 05:36:29,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:29,089 INFO:     Epoch: 52
2023-01-05 05:36:31,167 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3462661921977997, 'Total loss': 0.3462661921977997} | train loss {'Reaction outcome loss': 0.2130707064677124, 'Total loss': 0.2130707064677124}
2023-01-05 05:36:31,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:31,167 INFO:     Epoch: 53
2023-01-05 05:36:33,420 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3286744475364685, 'Total loss': 0.3286744475364685} | train loss {'Reaction outcome loss': 0.21024809765632832, 'Total loss': 0.21024809765632832}
2023-01-05 05:36:33,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:33,421 INFO:     Epoch: 54
2023-01-05 05:36:35,656 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3388159364461899, 'Total loss': 0.3388159364461899} | train loss {'Reaction outcome loss': 0.2088700196292211, 'Total loss': 0.2088700196292211}
2023-01-05 05:36:35,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:35,656 INFO:     Epoch: 55
2023-01-05 05:36:37,888 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3661409338315328, 'Total loss': 0.3661409338315328} | train loss {'Reaction outcome loss': 0.20938385137447596, 'Total loss': 0.20938385137447596}
2023-01-05 05:36:37,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:37,888 INFO:     Epoch: 56
2023-01-05 05:36:40,141 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3260029092431068, 'Total loss': 0.3260029092431068} | train loss {'Reaction outcome loss': 0.2125375130943389, 'Total loss': 0.2125375130943389}
2023-01-05 05:36:40,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:40,141 INFO:     Epoch: 57
2023-01-05 05:36:42,366 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34572585026423136, 'Total loss': 0.34572585026423136} | train loss {'Reaction outcome loss': 0.20460486599657726, 'Total loss': 0.20460486599657726}
2023-01-05 05:36:42,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:42,368 INFO:     Epoch: 58
2023-01-05 05:36:44,506 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3800508946180344, 'Total loss': 0.3800508946180344} | train loss {'Reaction outcome loss': 0.20468488017547648, 'Total loss': 0.20468488017547648}
2023-01-05 05:36:44,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:44,506 INFO:     Epoch: 59
2023-01-05 05:36:46,741 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.32963287631670635, 'Total loss': 0.32963287631670635} | train loss {'Reaction outcome loss': 0.2068489085250813, 'Total loss': 0.2068489085250813}
2023-01-05 05:36:46,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:46,741 INFO:     Epoch: 60
2023-01-05 05:36:48,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3166082481543223, 'Total loss': 0.3166082481543223} | train loss {'Reaction outcome loss': 0.2060188054769478, 'Total loss': 0.2060188054769478}
2023-01-05 05:36:48,957 INFO:     Found new best model at epoch 60
2023-01-05 05:36:48,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:48,958 INFO:     Epoch: 61
2023-01-05 05:36:51,201 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3521886616945267, 'Total loss': 0.3521886616945267} | train loss {'Reaction outcome loss': 0.19813276398994217, 'Total loss': 0.19813276398994217}
2023-01-05 05:36:51,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:51,202 INFO:     Epoch: 62
2023-01-05 05:36:53,466 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3413240482409795, 'Total loss': 0.3413240482409795} | train loss {'Reaction outcome loss': 0.20130221595624562, 'Total loss': 0.20130221595624562}
2023-01-05 05:36:53,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:53,466 INFO:     Epoch: 63
2023-01-05 05:36:55,699 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35127268036206566, 'Total loss': 0.35127268036206566} | train loss {'Reaction outcome loss': 0.19459293507685085, 'Total loss': 0.19459293507685085}
2023-01-05 05:36:55,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:55,699 INFO:     Epoch: 64
2023-01-05 05:36:57,999 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.33649094104766847, 'Total loss': 0.33649094104766847} | train loss {'Reaction outcome loss': 0.2017243735522489, 'Total loss': 0.2017243735522489}
2023-01-05 05:36:57,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:36:57,999 INFO:     Epoch: 65
2023-01-05 05:37:00,307 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34157148202260335, 'Total loss': 0.34157148202260335} | train loss {'Reaction outcome loss': 0.19236675122356048, 'Total loss': 0.19236675122356048}
2023-01-05 05:37:00,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:00,307 INFO:     Epoch: 66
2023-01-05 05:37:02,556 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3383949225147565, 'Total loss': 0.3383949225147565} | train loss {'Reaction outcome loss': 0.19521342856063095, 'Total loss': 0.19521342856063095}
2023-01-05 05:37:02,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:02,557 INFO:     Epoch: 67
2023-01-05 05:37:04,814 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3541059851646423, 'Total loss': 0.3541059851646423} | train loss {'Reaction outcome loss': 0.19448496182768568, 'Total loss': 0.19448496182768568}
2023-01-05 05:37:04,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:04,815 INFO:     Epoch: 68
2023-01-05 05:37:07,078 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33691715200742084, 'Total loss': 0.33691715200742084} | train loss {'Reaction outcome loss': 0.19225187549058226, 'Total loss': 0.19225187549058226}
2023-01-05 05:37:07,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:07,078 INFO:     Epoch: 69
2023-01-05 05:37:09,348 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35937371055285133, 'Total loss': 0.35937371055285133} | train loss {'Reaction outcome loss': 0.18956255237992167, 'Total loss': 0.18956255237992167}
2023-01-05 05:37:09,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:09,349 INFO:     Epoch: 70
2023-01-05 05:37:11,589 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38471640944480895, 'Total loss': 0.38471640944480895} | train loss {'Reaction outcome loss': 0.18983969835073616, 'Total loss': 0.18983969835073616}
2023-01-05 05:37:11,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:11,590 INFO:     Epoch: 71
2023-01-05 05:37:13,827 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32586173464854556, 'Total loss': 0.32586173464854556} | train loss {'Reaction outcome loss': 0.19451246124823385, 'Total loss': 0.19451246124823385}
2023-01-05 05:37:13,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:13,827 INFO:     Epoch: 72
2023-01-05 05:37:16,083 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.354250131547451, 'Total loss': 0.354250131547451} | train loss {'Reaction outcome loss': 0.18917797709603387, 'Total loss': 0.18917797709603387}
2023-01-05 05:37:16,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:16,084 INFO:     Epoch: 73
2023-01-05 05:37:18,292 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33543503781159717, 'Total loss': 0.33543503781159717} | train loss {'Reaction outcome loss': 0.1854606011515947, 'Total loss': 0.1854606011515947}
2023-01-05 05:37:18,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:18,292 INFO:     Epoch: 74
2023-01-05 05:37:20,518 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3710593362649282, 'Total loss': 0.3710593362649282} | train loss {'Reaction outcome loss': 0.1889721894071905, 'Total loss': 0.1889721894071905}
2023-01-05 05:37:20,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:20,519 INFO:     Epoch: 75
2023-01-05 05:37:22,761 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36773377979795135, 'Total loss': 0.36773377979795135} | train loss {'Reaction outcome loss': 0.1879114153045179, 'Total loss': 0.1879114153045179}
2023-01-05 05:37:22,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:22,761 INFO:     Epoch: 76
2023-01-05 05:37:24,987 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.31540733452420683, 'Total loss': 0.31540733452420683} | train loss {'Reaction outcome loss': 0.18831170599786598, 'Total loss': 0.18831170599786598}
2023-01-05 05:37:24,987 INFO:     Found new best model at epoch 76
2023-01-05 05:37:24,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:24,989 INFO:     Epoch: 77
2023-01-05 05:37:27,197 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.34433001751701037, 'Total loss': 0.34433001751701037} | train loss {'Reaction outcome loss': 0.18538781235310575, 'Total loss': 0.18538781235310575}
2023-01-05 05:37:27,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:27,197 INFO:     Epoch: 78
2023-01-05 05:37:29,373 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35452966342369713, 'Total loss': 0.35452966342369713} | train loss {'Reaction outcome loss': 0.1864194904423793, 'Total loss': 0.1864194904423793}
2023-01-05 05:37:29,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:29,373 INFO:     Epoch: 79
2023-01-05 05:37:31,607 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35227314531803133, 'Total loss': 0.35227314531803133} | train loss {'Reaction outcome loss': 0.1843956115349643, 'Total loss': 0.1843956115349643}
2023-01-05 05:37:31,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:31,607 INFO:     Epoch: 80
2023-01-05 05:37:33,786 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35720409055550895, 'Total loss': 0.35720409055550895} | train loss {'Reaction outcome loss': 0.183912380551415, 'Total loss': 0.183912380551415}
2023-01-05 05:37:33,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:33,786 INFO:     Epoch: 81
2023-01-05 05:37:36,057 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.32022987604141234, 'Total loss': 0.32022987604141234} | train loss {'Reaction outcome loss': 0.18200940953648317, 'Total loss': 0.18200940953648317}
2023-01-05 05:37:36,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:36,058 INFO:     Epoch: 82
2023-01-05 05:37:38,225 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3551947772502899, 'Total loss': 0.3551947772502899} | train loss {'Reaction outcome loss': 0.18003128635754223, 'Total loss': 0.18003128635754223}
2023-01-05 05:37:38,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:38,226 INFO:     Epoch: 83
2023-01-05 05:37:40,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3557931810617447, 'Total loss': 0.3557931810617447} | train loss {'Reaction outcome loss': 0.18074849896159845, 'Total loss': 0.18074849896159845}
2023-01-05 05:37:40,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:40,452 INFO:     Epoch: 84
2023-01-05 05:37:42,696 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3630221058924993, 'Total loss': 0.3630221058924993} | train loss {'Reaction outcome loss': 0.17854890789809746, 'Total loss': 0.17854890789809746}
2023-01-05 05:37:42,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:42,696 INFO:     Epoch: 85
2023-01-05 05:37:44,928 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3556481823325157, 'Total loss': 0.3556481823325157} | train loss {'Reaction outcome loss': 0.1841530442331995, 'Total loss': 0.1841530442331995}
2023-01-05 05:37:44,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:44,929 INFO:     Epoch: 86
2023-01-05 05:37:47,160 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33849721600612004, 'Total loss': 0.33849721600612004} | train loss {'Reaction outcome loss': 0.1773870502605308, 'Total loss': 0.1773870502605308}
2023-01-05 05:37:47,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:47,160 INFO:     Epoch: 87
2023-01-05 05:37:49,370 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34727858131130535, 'Total loss': 0.34727858131130535} | train loss {'Reaction outcome loss': 0.17831587404792704, 'Total loss': 0.17831587404792704}
2023-01-05 05:37:49,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:49,370 INFO:     Epoch: 88
2023-01-05 05:37:51,579 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3471703122059504, 'Total loss': 0.3471703122059504} | train loss {'Reaction outcome loss': 0.1806677809213742, 'Total loss': 0.1806677809213742}
2023-01-05 05:37:51,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:51,580 INFO:     Epoch: 89
2023-01-05 05:37:53,776 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3054019237558047, 'Total loss': 0.3054019237558047} | train loss {'Reaction outcome loss': 0.17644155388092791, 'Total loss': 0.17644155388092791}
2023-01-05 05:37:53,777 INFO:     Found new best model at epoch 89
2023-01-05 05:37:53,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:53,778 INFO:     Epoch: 90
2023-01-05 05:37:56,023 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3394175479809443, 'Total loss': 0.3394175479809443} | train loss {'Reaction outcome loss': 0.17975019835379472, 'Total loss': 0.17975019835379472}
2023-01-05 05:37:56,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:56,023 INFO:     Epoch: 91
2023-01-05 05:37:58,242 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3265854944785436, 'Total loss': 0.3265854944785436} | train loss {'Reaction outcome loss': 0.1704801827272407, 'Total loss': 0.1704801827272407}
2023-01-05 05:37:58,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:37:58,243 INFO:     Epoch: 92
2023-01-05 05:38:00,487 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3393414000670115, 'Total loss': 0.3393414000670115} | train loss {'Reaction outcome loss': 0.17608977528793288, 'Total loss': 0.17608977528793288}
2023-01-05 05:38:00,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:00,487 INFO:     Epoch: 93
2023-01-05 05:38:02,755 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34392691518490515, 'Total loss': 0.34392691518490515} | train loss {'Reaction outcome loss': 0.17572123687781582, 'Total loss': 0.17572123687781582}
2023-01-05 05:38:02,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:02,755 INFO:     Epoch: 94
2023-01-05 05:38:05,019 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36389145950476326, 'Total loss': 0.36389145950476326} | train loss {'Reaction outcome loss': 0.17601508136489008, 'Total loss': 0.17601508136489008}
2023-01-05 05:38:05,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:05,019 INFO:     Epoch: 95
2023-01-05 05:38:07,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.365474438170592, 'Total loss': 0.365474438170592} | train loss {'Reaction outcome loss': 0.17285712320350838, 'Total loss': 0.17285712320350838}
2023-01-05 05:38:07,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:07,245 INFO:     Epoch: 96
2023-01-05 05:38:09,427 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3395868202050527, 'Total loss': 0.3395868202050527} | train loss {'Reaction outcome loss': 0.17133872368665487, 'Total loss': 0.17133872368665487}
2023-01-05 05:38:09,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:09,427 INFO:     Epoch: 97
2023-01-05 05:38:11,695 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35773061191042266, 'Total loss': 0.35773061191042266} | train loss {'Reaction outcome loss': 0.1745178096882313, 'Total loss': 0.1745178096882313}
2023-01-05 05:38:11,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:11,696 INFO:     Epoch: 98
2023-01-05 05:38:13,940 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3415530428290367, 'Total loss': 0.3415530428290367} | train loss {'Reaction outcome loss': 0.1674016420779891, 'Total loss': 0.1674016420779891}
2023-01-05 05:38:13,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:13,941 INFO:     Epoch: 99
2023-01-05 05:38:16,208 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36579694151878356, 'Total loss': 0.36579694151878356} | train loss {'Reaction outcome loss': 0.16695019219991908, 'Total loss': 0.16695019219991908}
2023-01-05 05:38:16,208 INFO:     Best model found after epoch 90 of 100.
2023-01-05 05:38:16,208 INFO:   Done with stage: TRAINING
2023-01-05 05:38:16,208 INFO:   Starting stage: EVALUATION
2023-01-05 05:38:16,337 INFO:   Done with stage: EVALUATION
2023-01-05 05:38:16,337 INFO:   Leaving out SEQ value Fold_7
2023-01-05 05:38:16,350 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 05:38:16,350 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:38:16,992 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:38:16,993 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:38:17,065 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:38:17,065 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:38:17,065 INFO:     No hyperparam tuning for this model
2023-01-05 05:38:17,065 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:38:17,065 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:38:17,066 INFO:     None feature selector for col prot
2023-01-05 05:38:17,066 INFO:     None feature selector for col prot
2023-01-05 05:38:17,066 INFO:     None feature selector for col prot
2023-01-05 05:38:17,067 INFO:     None feature selector for col chem
2023-01-05 05:38:17,067 INFO:     None feature selector for col chem
2023-01-05 05:38:17,067 INFO:     None feature selector for col chem
2023-01-05 05:38:17,067 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:38:17,067 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:38:17,069 INFO:     Number of params in model 72931
2023-01-05 05:38:17,072 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:38:17,072 INFO:   Starting stage: TRAINING
2023-01-05 05:38:17,132 INFO:     Val loss before train {'Reaction outcome loss': 0.9891635179519653, 'Total loss': 0.9891635179519653}
2023-01-05 05:38:17,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:17,132 INFO:     Epoch: 0
2023-01-05 05:38:19,295 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7243965903917948, 'Total loss': 0.7243965903917948} | train loss {'Reaction outcome loss': 0.9414351490000095, 'Total loss': 0.9414351490000095}
2023-01-05 05:38:19,295 INFO:     Found new best model at epoch 0
2023-01-05 05:38:19,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:19,296 INFO:     Epoch: 1
2023-01-05 05:38:21,505 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5243921379248301, 'Total loss': 0.5243921379248301} | train loss {'Reaction outcome loss': 0.6396905360239077, 'Total loss': 0.6396905360239077}
2023-01-05 05:38:21,505 INFO:     Found new best model at epoch 1
2023-01-05 05:38:21,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:21,506 INFO:     Epoch: 2
2023-01-05 05:38:23,742 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48015447954336804, 'Total loss': 0.48015447954336804} | train loss {'Reaction outcome loss': 0.5321097644550276, 'Total loss': 0.5321097644550276}
2023-01-05 05:38:23,743 INFO:     Found new best model at epoch 2
2023-01-05 05:38:23,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:23,745 INFO:     Epoch: 3
2023-01-05 05:38:26,004 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4454551458358765, 'Total loss': 0.4454551458358765} | train loss {'Reaction outcome loss': 0.48530886965107833, 'Total loss': 0.48530886965107833}
2023-01-05 05:38:26,004 INFO:     Found new best model at epoch 3
2023-01-05 05:38:26,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:26,005 INFO:     Epoch: 4
2023-01-05 05:38:28,280 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4352039019266764, 'Total loss': 0.4352039019266764} | train loss {'Reaction outcome loss': 0.4547466528114429, 'Total loss': 0.4547466528114429}
2023-01-05 05:38:28,280 INFO:     Found new best model at epoch 4
2023-01-05 05:38:28,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:28,281 INFO:     Epoch: 5
2023-01-05 05:38:30,531 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.440122260649999, 'Total loss': 0.440122260649999} | train loss {'Reaction outcome loss': 0.43191863375880657, 'Total loss': 0.43191863375880657}
2023-01-05 05:38:30,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:30,532 INFO:     Epoch: 6
2023-01-05 05:38:32,781 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4478532612323761, 'Total loss': 0.4478532612323761} | train loss {'Reaction outcome loss': 0.41530961492216545, 'Total loss': 0.41530961492216545}
2023-01-05 05:38:32,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:32,781 INFO:     Epoch: 7
2023-01-05 05:38:35,038 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4261663258075714, 'Total loss': 0.4261663258075714} | train loss {'Reaction outcome loss': 0.398813028090267, 'Total loss': 0.398813028090267}
2023-01-05 05:38:35,038 INFO:     Found new best model at epoch 7
2023-01-05 05:38:35,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:35,039 INFO:     Epoch: 8
2023-01-05 05:38:37,259 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.440908382833004, 'Total loss': 0.440908382833004} | train loss {'Reaction outcome loss': 0.38760381146243333, 'Total loss': 0.38760381146243333}
2023-01-05 05:38:37,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:37,259 INFO:     Epoch: 9
2023-01-05 05:38:39,484 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4121067186196645, 'Total loss': 0.4121067186196645} | train loss {'Reaction outcome loss': 0.3737760546082624, 'Total loss': 0.3737760546082624}
2023-01-05 05:38:39,484 INFO:     Found new best model at epoch 9
2023-01-05 05:38:39,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:39,486 INFO:     Epoch: 10
2023-01-05 05:38:41,724 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4524783581495285, 'Total loss': 0.4524783581495285} | train loss {'Reaction outcome loss': 0.3670487452284954, 'Total loss': 0.3670487452284954}
2023-01-05 05:38:41,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:41,724 INFO:     Epoch: 11
2023-01-05 05:38:43,934 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4169422705968221, 'Total loss': 0.4169422705968221} | train loss {'Reaction outcome loss': 0.35926753618764534, 'Total loss': 0.35926753618764534}
2023-01-05 05:38:43,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:43,935 INFO:     Epoch: 12
2023-01-05 05:38:46,168 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4345580120881399, 'Total loss': 0.4345580120881399} | train loss {'Reaction outcome loss': 0.3473349582767013, 'Total loss': 0.3473349582767013}
2023-01-05 05:38:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:46,168 INFO:     Epoch: 13
2023-01-05 05:38:48,379 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43222874999046323, 'Total loss': 0.43222874999046323} | train loss {'Reaction outcome loss': 0.33960821425764137, 'Total loss': 0.33960821425764137}
2023-01-05 05:38:48,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:48,379 INFO:     Epoch: 14
2023-01-05 05:38:50,601 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4222813139359156, 'Total loss': 0.4222813139359156} | train loss {'Reaction outcome loss': 0.3278464123552887, 'Total loss': 0.3278464123552887}
2023-01-05 05:38:50,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:50,602 INFO:     Epoch: 15
2023-01-05 05:38:52,764 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44925365249315896, 'Total loss': 0.44925365249315896} | train loss {'Reaction outcome loss': 0.32257638665904637, 'Total loss': 0.32257638665904637}
2023-01-05 05:38:52,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:52,764 INFO:     Epoch: 16
2023-01-05 05:38:55,019 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4451535105705261, 'Total loss': 0.4451535105705261} | train loss {'Reaction outcome loss': 0.31865588934681904, 'Total loss': 0.31865588934681904}
2023-01-05 05:38:55,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:55,019 INFO:     Epoch: 17
2023-01-05 05:38:57,289 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43508458534876504, 'Total loss': 0.43508458534876504} | train loss {'Reaction outcome loss': 0.31112218236665, 'Total loss': 0.31112218236665}
2023-01-05 05:38:57,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:57,289 INFO:     Epoch: 18
2023-01-05 05:38:59,534 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44896534581979114, 'Total loss': 0.44896534581979114} | train loss {'Reaction outcome loss': 0.30458523848157926, 'Total loss': 0.30458523848157926}
2023-01-05 05:38:59,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:38:59,535 INFO:     Epoch: 19
2023-01-05 05:39:01,791 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4275288075208664, 'Total loss': 0.4275288075208664} | train loss {'Reaction outcome loss': 0.2973282231212953, 'Total loss': 0.2973282231212953}
2023-01-05 05:39:01,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:01,792 INFO:     Epoch: 20
2023-01-05 05:39:04,002 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4340149094661077, 'Total loss': 0.4340149094661077} | train loss {'Reaction outcome loss': 0.2932893813248145, 'Total loss': 0.2932893813248145}
2023-01-05 05:39:04,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:04,002 INFO:     Epoch: 21
2023-01-05 05:39:06,229 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40288600126902263, 'Total loss': 0.40288600126902263} | train loss {'Reaction outcome loss': 0.28712807654904116, 'Total loss': 0.28712807654904116}
2023-01-05 05:39:06,230 INFO:     Found new best model at epoch 21
2023-01-05 05:39:06,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:06,231 INFO:     Epoch: 22
2023-01-05 05:39:08,497 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4434236069520315, 'Total loss': 0.4434236069520315} | train loss {'Reaction outcome loss': 0.2833068018597601, 'Total loss': 0.2833068018597601}
2023-01-05 05:39:08,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:08,497 INFO:     Epoch: 23
2023-01-05 05:39:10,752 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44215448101361593, 'Total loss': 0.44215448101361593} | train loss {'Reaction outcome loss': 0.2770382009634903, 'Total loss': 0.2770382009634903}
2023-01-05 05:39:10,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:10,752 INFO:     Epoch: 24
2023-01-05 05:39:13,000 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44035682678222654, 'Total loss': 0.44035682678222654} | train loss {'Reaction outcome loss': 0.26899923849514673, 'Total loss': 0.26899923849514673}
2023-01-05 05:39:13,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:13,000 INFO:     Epoch: 25
2023-01-05 05:39:15,269 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4468297282854716, 'Total loss': 0.4468297282854716} | train loss {'Reaction outcome loss': 0.2729655470470444, 'Total loss': 0.2729655470470444}
2023-01-05 05:39:15,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:15,269 INFO:     Epoch: 26
2023-01-05 05:39:17,525 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45508183737595875, 'Total loss': 0.45508183737595875} | train loss {'Reaction outcome loss': 0.26234248185039427, 'Total loss': 0.26234248185039427}
2023-01-05 05:39:17,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:17,525 INFO:     Epoch: 27
2023-01-05 05:39:19,738 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45209856430689493, 'Total loss': 0.45209856430689493} | train loss {'Reaction outcome loss': 0.2629624454687864, 'Total loss': 0.2629624454687864}
2023-01-05 05:39:19,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:19,739 INFO:     Epoch: 28
2023-01-05 05:39:21,863 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4329194446404775, 'Total loss': 0.4329194446404775} | train loss {'Reaction outcome loss': 0.25625294364908113, 'Total loss': 0.25625294364908113}
2023-01-05 05:39:21,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:21,863 INFO:     Epoch: 29
2023-01-05 05:39:24,110 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4453265945116679, 'Total loss': 0.4453265945116679} | train loss {'Reaction outcome loss': 0.25372804968957435, 'Total loss': 0.25372804968957435}
2023-01-05 05:39:24,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:24,110 INFO:     Epoch: 30
2023-01-05 05:39:26,361 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43900045156478884, 'Total loss': 0.43900045156478884} | train loss {'Reaction outcome loss': 0.2491496112533855, 'Total loss': 0.2491496112533855}
2023-01-05 05:39:26,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:26,361 INFO:     Epoch: 31
2023-01-05 05:39:28,620 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.427585198978583, 'Total loss': 0.427585198978583} | train loss {'Reaction outcome loss': 0.24448804976922942, 'Total loss': 0.24448804976922942}
2023-01-05 05:39:28,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:28,620 INFO:     Epoch: 32
2023-01-05 05:39:30,895 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4207310472925504, 'Total loss': 0.4207310472925504} | train loss {'Reaction outcome loss': 0.24595363139568252, 'Total loss': 0.24595363139568252}
2023-01-05 05:39:30,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:30,895 INFO:     Epoch: 33
2023-01-05 05:39:33,168 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4344422002633413, 'Total loss': 0.4344422002633413} | train loss {'Reaction outcome loss': 0.23600990419353388, 'Total loss': 0.23600990419353388}
2023-01-05 05:39:33,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:33,168 INFO:     Epoch: 34
2023-01-05 05:39:35,424 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4328396737575531, 'Total loss': 0.4328396737575531} | train loss {'Reaction outcome loss': 0.23693799509226415, 'Total loss': 0.23693799509226415}
2023-01-05 05:39:35,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:35,425 INFO:     Epoch: 35
2023-01-05 05:39:37,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46183610558509824, 'Total loss': 0.46183610558509824} | train loss {'Reaction outcome loss': 0.2376345875824294, 'Total loss': 0.2376345875824294}
2023-01-05 05:39:37,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:37,706 INFO:     Epoch: 36
2023-01-05 05:39:39,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45901394784450533, 'Total loss': 0.45901394784450533} | train loss {'Reaction outcome loss': 0.2301718981781914, 'Total loss': 0.2301718981781914}
2023-01-05 05:39:39,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:39,954 INFO:     Epoch: 37
2023-01-05 05:39:42,224 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4369241659839948, 'Total loss': 0.4369241659839948} | train loss {'Reaction outcome loss': 0.22915049922225547, 'Total loss': 0.22915049922225547}
2023-01-05 05:39:42,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:42,225 INFO:     Epoch: 38
2023-01-05 05:39:44,387 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4492420881986618, 'Total loss': 0.4492420881986618} | train loss {'Reaction outcome loss': 0.2257307877979285, 'Total loss': 0.2257307877979285}
2023-01-05 05:39:44,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:44,387 INFO:     Epoch: 39
2023-01-05 05:39:46,651 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46757298707962036, 'Total loss': 0.46757298707962036} | train loss {'Reaction outcome loss': 0.2232216553836523, 'Total loss': 0.2232216553836523}
2023-01-05 05:39:46,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:46,651 INFO:     Epoch: 40
2023-01-05 05:39:48,934 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4422826235493024, 'Total loss': 0.4422826235493024} | train loss {'Reaction outcome loss': 0.22513038920581557, 'Total loss': 0.22513038920581557}
2023-01-05 05:39:48,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:48,934 INFO:     Epoch: 41
2023-01-05 05:39:51,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42725489338239037, 'Total loss': 0.42725489338239037} | train loss {'Reaction outcome loss': 0.21848304936198337, 'Total loss': 0.21848304936198337}
2023-01-05 05:39:51,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:51,212 INFO:     Epoch: 42
2023-01-05 05:39:53,465 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4148459662993749, 'Total loss': 0.4148459662993749} | train loss {'Reaction outcome loss': 0.22009379415359306, 'Total loss': 0.22009379415359306}
2023-01-05 05:39:53,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:53,465 INFO:     Epoch: 43
2023-01-05 05:39:55,690 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45967206408580147, 'Total loss': 0.45967206408580147} | train loss {'Reaction outcome loss': 0.21291711822905265, 'Total loss': 0.21291711822905265}
2023-01-05 05:39:55,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:55,691 INFO:     Epoch: 44
2023-01-05 05:39:57,903 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48196137249469756, 'Total loss': 0.48196137249469756} | train loss {'Reaction outcome loss': 0.2148946233409783, 'Total loss': 0.2148946233409783}
2023-01-05 05:39:57,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:39:57,903 INFO:     Epoch: 45
2023-01-05 05:40:00,174 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4223568191130956, 'Total loss': 0.4223568191130956} | train loss {'Reaction outcome loss': 0.21021595848085434, 'Total loss': 0.21021595848085434}
2023-01-05 05:40:00,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:00,174 INFO:     Epoch: 46
2023-01-05 05:40:02,367 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45111285547415414, 'Total loss': 0.45111285547415414} | train loss {'Reaction outcome loss': 0.2125206992857239, 'Total loss': 0.2125206992857239}
2023-01-05 05:40:02,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:02,367 INFO:     Epoch: 47
2023-01-05 05:40:04,636 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4553663323322932, 'Total loss': 0.4553663323322932} | train loss {'Reaction outcome loss': 0.20768403852297943, 'Total loss': 0.20768403852297943}
2023-01-05 05:40:04,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:04,637 INFO:     Epoch: 48
2023-01-05 05:40:06,924 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46584968840082486, 'Total loss': 0.46584968840082486} | train loss {'Reaction outcome loss': 0.20694203898377905, 'Total loss': 0.20694203898377905}
2023-01-05 05:40:06,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:06,924 INFO:     Epoch: 49
2023-01-05 05:40:09,172 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46727619469165804, 'Total loss': 0.46727619469165804} | train loss {'Reaction outcome loss': 0.2050382777181074, 'Total loss': 0.2050382777181074}
2023-01-05 05:40:09,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:09,172 INFO:     Epoch: 50
2023-01-05 05:40:11,360 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4043776959180832, 'Total loss': 0.4043776959180832} | train loss {'Reaction outcome loss': 0.2018577381296063, 'Total loss': 0.2018577381296063}
2023-01-05 05:40:11,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:11,361 INFO:     Epoch: 51
2023-01-05 05:40:13,603 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45431976914405825, 'Total loss': 0.45431976914405825} | train loss {'Reaction outcome loss': 0.2010688525675006, 'Total loss': 0.2010688525675006}
2023-01-05 05:40:13,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:13,603 INFO:     Epoch: 52
2023-01-05 05:40:15,853 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.446744030714035, 'Total loss': 0.446744030714035} | train loss {'Reaction outcome loss': 0.2026204865540139, 'Total loss': 0.2026204865540139}
2023-01-05 05:40:15,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:15,853 INFO:     Epoch: 53
2023-01-05 05:40:18,126 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4707303881645203, 'Total loss': 0.4707303881645203} | train loss {'Reaction outcome loss': 0.19956323366934964, 'Total loss': 0.19956323366934964}
2023-01-05 05:40:18,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:18,127 INFO:     Epoch: 54
2023-01-05 05:40:20,377 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4343620389699936, 'Total loss': 0.4343620389699936} | train loss {'Reaction outcome loss': 0.19713575456170399, 'Total loss': 0.19713575456170399}
2023-01-05 05:40:20,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:20,378 INFO:     Epoch: 55
2023-01-05 05:40:22,626 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45170380771160124, 'Total loss': 0.45170380771160124} | train loss {'Reaction outcome loss': 0.1927077796189148, 'Total loss': 0.1927077796189148}
2023-01-05 05:40:22,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:22,626 INFO:     Epoch: 56
2023-01-05 05:40:24,819 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45704568723837535, 'Total loss': 0.45704568723837535} | train loss {'Reaction outcome loss': 0.19333733912785991, 'Total loss': 0.19333733912785991}
2023-01-05 05:40:24,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:24,819 INFO:     Epoch: 57
2023-01-05 05:40:27,052 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.446665554245313, 'Total loss': 0.446665554245313} | train loss {'Reaction outcome loss': 0.19634447745568648, 'Total loss': 0.19634447745568648}
2023-01-05 05:40:27,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:27,052 INFO:     Epoch: 58
2023-01-05 05:40:29,298 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4313255262871583, 'Total loss': 0.4313255262871583} | train loss {'Reaction outcome loss': 0.19029001326767547, 'Total loss': 0.19029001326767547}
2023-01-05 05:40:29,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:29,299 INFO:     Epoch: 59
2023-01-05 05:40:31,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47514528532822925, 'Total loss': 0.47514528532822925} | train loss {'Reaction outcome loss': 0.18635913053870418, 'Total loss': 0.18635913053870418}
2023-01-05 05:40:31,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:31,571 INFO:     Epoch: 60
2023-01-05 05:40:33,803 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43098090489705404, 'Total loss': 0.43098090489705404} | train loss {'Reaction outcome loss': 0.19070230113066705, 'Total loss': 0.19070230113066705}
2023-01-05 05:40:33,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:33,803 INFO:     Epoch: 61
2023-01-05 05:40:36,066 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46980639100074767, 'Total loss': 0.46980639100074767} | train loss {'Reaction outcome loss': 0.19513391621330153, 'Total loss': 0.19513391621330153}
2023-01-05 05:40:36,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:36,067 INFO:     Epoch: 62
2023-01-05 05:40:38,095 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4710908482472102, 'Total loss': 0.4710908482472102} | train loss {'Reaction outcome loss': 0.18684175914819168, 'Total loss': 0.18684175914819168}
2023-01-05 05:40:38,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:38,095 INFO:     Epoch: 63
2023-01-05 05:40:40,349 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4469675950706005, 'Total loss': 0.4469675950706005} | train loss {'Reaction outcome loss': 0.1915863423678849, 'Total loss': 0.1915863423678849}
2023-01-05 05:40:40,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:40,350 INFO:     Epoch: 64
2023-01-05 05:40:42,620 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49467297991116843, 'Total loss': 0.49467297991116843} | train loss {'Reaction outcome loss': 0.1870726512287767, 'Total loss': 0.1870726512287767}
2023-01-05 05:40:42,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:42,620 INFO:     Epoch: 65
2023-01-05 05:40:44,870 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47259850402673087, 'Total loss': 0.47259850402673087} | train loss {'Reaction outcome loss': 0.18492755844234238, 'Total loss': 0.18492755844234238}
2023-01-05 05:40:44,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:44,871 INFO:     Epoch: 66
2023-01-05 05:40:47,138 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4397035131851832, 'Total loss': 0.4397035131851832} | train loss {'Reaction outcome loss': 0.18611212860497003, 'Total loss': 0.18611212860497003}
2023-01-05 05:40:47,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:47,139 INFO:     Epoch: 67
2023-01-05 05:40:49,289 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46537473102410637, 'Total loss': 0.46537473102410637} | train loss {'Reaction outcome loss': 0.18636901803072609, 'Total loss': 0.18636901803072609}
2023-01-05 05:40:49,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:49,289 INFO:     Epoch: 68
2023-01-05 05:40:51,553 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47576974928379057, 'Total loss': 0.47576974928379057} | train loss {'Reaction outcome loss': 0.18045310751410598, 'Total loss': 0.18045310751410598}
2023-01-05 05:40:51,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:51,553 INFO:     Epoch: 69
2023-01-05 05:40:53,761 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4648764987786611, 'Total loss': 0.4648764987786611} | train loss {'Reaction outcome loss': 0.18667173010233237, 'Total loss': 0.18667173010233237}
2023-01-05 05:40:53,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:53,762 INFO:     Epoch: 70
2023-01-05 05:40:55,956 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49654489556948345, 'Total loss': 0.49654489556948345} | train loss {'Reaction outcome loss': 0.18351817007818755, 'Total loss': 0.18351817007818755}
2023-01-05 05:40:55,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:55,956 INFO:     Epoch: 71
2023-01-05 05:40:58,131 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4757643630107244, 'Total loss': 0.4757643630107244} | train loss {'Reaction outcome loss': 0.1799005034836917, 'Total loss': 0.1799005034836917}
2023-01-05 05:40:58,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:40:58,132 INFO:     Epoch: 72
2023-01-05 05:41:00,395 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46798100223143896, 'Total loss': 0.46798100223143896} | train loss {'Reaction outcome loss': 0.17570411359608873, 'Total loss': 0.17570411359608873}
2023-01-05 05:41:00,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:00,395 INFO:     Epoch: 73
2023-01-05 05:41:02,642 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45542298356691996, 'Total loss': 0.45542298356691996} | train loss {'Reaction outcome loss': 0.17967255943242985, 'Total loss': 0.17967255943242985}
2023-01-05 05:41:02,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:02,643 INFO:     Epoch: 74
2023-01-05 05:41:04,912 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4925379087527593, 'Total loss': 0.4925379087527593} | train loss {'Reaction outcome loss': 0.1831348412401221, 'Total loss': 0.1831348412401221}
2023-01-05 05:41:04,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:04,913 INFO:     Epoch: 75
2023-01-05 05:41:07,183 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46307560180624324, 'Total loss': 0.46307560180624324} | train loss {'Reaction outcome loss': 0.17924771745712748, 'Total loss': 0.17924771745712748}
2023-01-05 05:41:07,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:07,184 INFO:     Epoch: 76
2023-01-05 05:41:09,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4800110091765722, 'Total loss': 0.4800110091765722} | train loss {'Reaction outcome loss': 0.18072738417084683, 'Total loss': 0.18072738417084683}
2023-01-05 05:41:09,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:09,427 INFO:     Epoch: 77
2023-01-05 05:41:11,695 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4938029150168101, 'Total loss': 0.4938029150168101} | train loss {'Reaction outcome loss': 0.17773459281853068, 'Total loss': 0.17773459281853068}
2023-01-05 05:41:11,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:11,695 INFO:     Epoch: 78
2023-01-05 05:41:13,890 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46733327507972716, 'Total loss': 0.46733327507972716} | train loss {'Reaction outcome loss': 0.17463874781087363, 'Total loss': 0.17463874781087363}
2023-01-05 05:41:13,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:13,890 INFO:     Epoch: 79
2023-01-05 05:41:16,044 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4570607384045919, 'Total loss': 0.4570607384045919} | train loss {'Reaction outcome loss': 0.1764146027336778, 'Total loss': 0.1764146027336778}
2023-01-05 05:41:16,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:16,044 INFO:     Epoch: 80
2023-01-05 05:41:18,180 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5068368484576543, 'Total loss': 0.5068368484576543} | train loss {'Reaction outcome loss': 0.1747957761416259, 'Total loss': 0.1747957761416259}
2023-01-05 05:41:18,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:18,180 INFO:     Epoch: 81
2023-01-05 05:41:20,432 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5128362983465194, 'Total loss': 0.5128362983465194} | train loss {'Reaction outcome loss': 0.17468006350772475, 'Total loss': 0.17468006350772475}
2023-01-05 05:41:20,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:20,432 INFO:     Epoch: 82
2023-01-05 05:41:22,695 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49827679097652433, 'Total loss': 0.49827679097652433} | train loss {'Reaction outcome loss': 0.17549906978350038, 'Total loss': 0.17549906978350038}
2023-01-05 05:41:22,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:22,696 INFO:     Epoch: 83
2023-01-05 05:41:24,921 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4838561882575353, 'Total loss': 0.4838561882575353} | train loss {'Reaction outcome loss': 0.1741915492774643, 'Total loss': 0.1741915492774643}
2023-01-05 05:41:24,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:24,922 INFO:     Epoch: 84
2023-01-05 05:41:27,120 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4960133930047353, 'Total loss': 0.4960133930047353} | train loss {'Reaction outcome loss': 0.1748533451539676, 'Total loss': 0.1748533451539676}
2023-01-05 05:41:27,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:27,120 INFO:     Epoch: 85
2023-01-05 05:41:29,385 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47969967921574913, 'Total loss': 0.47969967921574913} | train loss {'Reaction outcome loss': 0.17645390532467017, 'Total loss': 0.17645390532467017}
2023-01-05 05:41:29,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:29,386 INFO:     Epoch: 86
2023-01-05 05:41:31,652 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47497014502684276, 'Total loss': 0.47497014502684276} | train loss {'Reaction outcome loss': 0.17496928635023076, 'Total loss': 0.17496928635023076}
2023-01-05 05:41:31,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:31,652 INFO:     Epoch: 87
2023-01-05 05:41:33,925 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4656845231850942, 'Total loss': 0.4656845231850942} | train loss {'Reaction outcome loss': 0.17473821140260903, 'Total loss': 0.17473821140260903}
2023-01-05 05:41:33,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:33,926 INFO:     Epoch: 88
2023-01-05 05:41:36,171 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49174704949061077, 'Total loss': 0.49174704949061077} | train loss {'Reaction outcome loss': 0.1733931657952334, 'Total loss': 0.1733931657952334}
2023-01-05 05:41:36,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:36,171 INFO:     Epoch: 89
2023-01-05 05:41:38,411 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5033279120922088, 'Total loss': 0.5033279120922088} | train loss {'Reaction outcome loss': 0.17512755943899336, 'Total loss': 0.17512755943899336}
2023-01-05 05:41:38,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:38,411 INFO:     Epoch: 90
2023-01-05 05:41:40,670 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5032003084818523, 'Total loss': 0.5032003084818523} | train loss {'Reaction outcome loss': 0.1692340564729128, 'Total loss': 0.1692340564729128}
2023-01-05 05:41:40,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:40,670 INFO:     Epoch: 91
2023-01-05 05:41:42,931 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4578565925359726, 'Total loss': 0.4578565925359726} | train loss {'Reaction outcome loss': 0.17293732354773833, 'Total loss': 0.17293732354773833}
2023-01-05 05:41:42,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:42,932 INFO:     Epoch: 92
2023-01-05 05:41:45,146 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4606765568256378, 'Total loss': 0.4606765568256378} | train loss {'Reaction outcome loss': 0.17214318128833916, 'Total loss': 0.17214318128833916}
2023-01-05 05:41:45,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:45,146 INFO:     Epoch: 93
2023-01-05 05:41:47,400 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47570859889189404, 'Total loss': 0.47570859889189404} | train loss {'Reaction outcome loss': 0.17204089701471562, 'Total loss': 0.17204089701471562}
2023-01-05 05:41:47,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:47,400 INFO:     Epoch: 94
2023-01-05 05:41:49,637 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4735208948453267, 'Total loss': 0.4735208948453267} | train loss {'Reaction outcome loss': 0.16764473135075414, 'Total loss': 0.16764473135075414}
2023-01-05 05:41:49,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:49,638 INFO:     Epoch: 95
2023-01-05 05:41:51,885 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.437822366754214, 'Total loss': 0.437822366754214} | train loss {'Reaction outcome loss': 0.1707969392239644, 'Total loss': 0.1707969392239644}
2023-01-05 05:41:51,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:51,885 INFO:     Epoch: 96
2023-01-05 05:41:54,152 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4852922757466634, 'Total loss': 0.4852922757466634} | train loss {'Reaction outcome loss': 0.1657349817279982, 'Total loss': 0.1657349817279982}
2023-01-05 05:41:54,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:54,152 INFO:     Epoch: 97
2023-01-05 05:41:56,405 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4622470180193583, 'Total loss': 0.4622470180193583} | train loss {'Reaction outcome loss': 0.1712227687508621, 'Total loss': 0.1712227687508621}
2023-01-05 05:41:56,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:56,405 INFO:     Epoch: 98
2023-01-05 05:41:58,595 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48171561360359194, 'Total loss': 0.48171561360359194} | train loss {'Reaction outcome loss': 0.1676026695653366, 'Total loss': 0.1676026695653366}
2023-01-05 05:41:58,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:41:58,597 INFO:     Epoch: 99
2023-01-05 05:42:00,935 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44741359949111936, 'Total loss': 0.44741359949111936} | train loss {'Reaction outcome loss': 0.1670445367401392, 'Total loss': 0.1670445367401392}
2023-01-05 05:42:00,935 INFO:     Best model found after epoch 22 of 100.
2023-01-05 05:42:00,935 INFO:   Done with stage: TRAINING
2023-01-05 05:42:00,935 INFO:   Starting stage: EVALUATION
2023-01-05 05:42:01,083 INFO:   Done with stage: EVALUATION
2023-01-05 05:42:01,084 INFO:   Leaving out SEQ value Fold_8
2023-01-05 05:42:01,098 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 05:42:01,098 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:42:01,812 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:42:01,812 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:42:01,894 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:42:01,894 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:42:01,895 INFO:     No hyperparam tuning for this model
2023-01-05 05:42:01,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:42:01,895 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:42:01,896 INFO:     None feature selector for col prot
2023-01-05 05:42:01,896 INFO:     None feature selector for col prot
2023-01-05 05:42:01,896 INFO:     None feature selector for col prot
2023-01-05 05:42:01,897 INFO:     None feature selector for col chem
2023-01-05 05:42:01,897 INFO:     None feature selector for col chem
2023-01-05 05:42:01,897 INFO:     None feature selector for col chem
2023-01-05 05:42:01,897 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:42:01,897 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:42:01,899 INFO:     Number of params in model 72931
2023-01-05 05:42:01,902 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:42:01,902 INFO:   Starting stage: TRAINING
2023-01-05 05:42:01,966 INFO:     Val loss before train {'Reaction outcome loss': 1.0301548659801483, 'Total loss': 1.0301548659801483}
2023-01-05 05:42:01,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:01,966 INFO:     Epoch: 0
2023-01-05 05:42:04,254 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7590091745058696, 'Total loss': 0.7590091745058696} | train loss {'Reaction outcome loss': 0.910421174046767, 'Total loss': 0.910421174046767}
2023-01-05 05:42:04,254 INFO:     Found new best model at epoch 0
2023-01-05 05:42:04,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:04,255 INFO:     Epoch: 1
2023-01-05 05:42:06,528 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5395724793275197, 'Total loss': 0.5395724793275197} | train loss {'Reaction outcome loss': 0.6061538631354806, 'Total loss': 0.6061538631354806}
2023-01-05 05:42:06,528 INFO:     Found new best model at epoch 1
2023-01-05 05:42:06,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:06,531 INFO:     Epoch: 2
2023-01-05 05:42:08,773 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4894547541936239, 'Total loss': 0.4894547541936239} | train loss {'Reaction outcome loss': 0.5287540256433243, 'Total loss': 0.5287540256433243}
2023-01-05 05:42:08,773 INFO:     Found new best model at epoch 2
2023-01-05 05:42:08,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:08,775 INFO:     Epoch: 3
2023-01-05 05:42:11,003 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4577348272005717, 'Total loss': 0.4577348272005717} | train loss {'Reaction outcome loss': 0.4877087790926878, 'Total loss': 0.4877087790926878}
2023-01-05 05:42:11,003 INFO:     Found new best model at epoch 3
2023-01-05 05:42:11,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:11,004 INFO:     Epoch: 4
2023-01-05 05:42:13,258 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5107920428117116, 'Total loss': 0.5107920428117116} | train loss {'Reaction outcome loss': 0.46780359255571435, 'Total loss': 0.46780359255571435}
2023-01-05 05:42:13,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:13,258 INFO:     Epoch: 5
2023-01-05 05:42:15,518 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45762896339098613, 'Total loss': 0.45762896339098613} | train loss {'Reaction outcome loss': 0.44590768598727065, 'Total loss': 0.44590768598727065}
2023-01-05 05:42:15,518 INFO:     Found new best model at epoch 5
2023-01-05 05:42:15,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:15,520 INFO:     Epoch: 6
2023-01-05 05:42:17,775 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43968081374963125, 'Total loss': 0.43968081374963125} | train loss {'Reaction outcome loss': 0.42655271395062005, 'Total loss': 0.42655271395062005}
2023-01-05 05:42:17,775 INFO:     Found new best model at epoch 6
2023-01-05 05:42:17,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:17,777 INFO:     Epoch: 7
2023-01-05 05:42:20,017 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4442955066760381, 'Total loss': 0.4442955066760381} | train loss {'Reaction outcome loss': 0.4101274523639331, 'Total loss': 0.4101274523639331}
2023-01-05 05:42:20,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:20,017 INFO:     Epoch: 8
2023-01-05 05:42:22,261 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4583773305018743, 'Total loss': 0.4583773305018743} | train loss {'Reaction outcome loss': 0.3956641411939024, 'Total loss': 0.3956641411939024}
2023-01-05 05:42:22,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:22,262 INFO:     Epoch: 9
2023-01-05 05:42:24,438 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4473644604285558, 'Total loss': 0.4473644604285558} | train loss {'Reaction outcome loss': 0.38557150331835677, 'Total loss': 0.38557150331835677}
2023-01-05 05:42:24,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:24,438 INFO:     Epoch: 10
2023-01-05 05:42:26,669 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45184804300467174, 'Total loss': 0.45184804300467174} | train loss {'Reaction outcome loss': 0.37247831621853106, 'Total loss': 0.37247831621853106}
2023-01-05 05:42:26,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:26,669 INFO:     Epoch: 11
2023-01-05 05:42:28,810 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4674174110094706, 'Total loss': 0.4674174110094706} | train loss {'Reaction outcome loss': 0.3663666290197059, 'Total loss': 0.3663666290197059}
2023-01-05 05:42:28,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:28,810 INFO:     Epoch: 12
2023-01-05 05:42:30,962 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42994163930416107, 'Total loss': 0.42994163930416107} | train loss {'Reaction outcome loss': 0.35881910449995175, 'Total loss': 0.35881910449995175}
2023-01-05 05:42:30,962 INFO:     Found new best model at epoch 12
2023-01-05 05:42:30,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:30,964 INFO:     Epoch: 13
2023-01-05 05:42:33,132 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43786716560522715, 'Total loss': 0.43786716560522715} | train loss {'Reaction outcome loss': 0.3418160561390602, 'Total loss': 0.3418160561390602}
2023-01-05 05:42:33,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:33,132 INFO:     Epoch: 14
2023-01-05 05:42:35,367 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44234066009521483, 'Total loss': 0.44234066009521483} | train loss {'Reaction outcome loss': 0.3375616634441336, 'Total loss': 0.3375616634441336}
2023-01-05 05:42:35,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:35,368 INFO:     Epoch: 15
2023-01-05 05:42:37,477 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42943464120229086, 'Total loss': 0.42943464120229086} | train loss {'Reaction outcome loss': 0.3289146154683872, 'Total loss': 0.3289146154683872}
2023-01-05 05:42:37,477 INFO:     Found new best model at epoch 15
2023-01-05 05:42:37,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:37,479 INFO:     Epoch: 16
2023-01-05 05:42:39,715 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46928203900655113, 'Total loss': 0.46928203900655113} | train loss {'Reaction outcome loss': 0.32017906297025456, 'Total loss': 0.32017906297025456}
2023-01-05 05:42:39,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:39,716 INFO:     Epoch: 17
2023-01-05 05:42:41,940 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43073233366012575, 'Total loss': 0.43073233366012575} | train loss {'Reaction outcome loss': 0.31167728078626367, 'Total loss': 0.31167728078626367}
2023-01-05 05:42:41,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:41,941 INFO:     Epoch: 18
2023-01-05 05:42:44,191 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43678686718146004, 'Total loss': 0.43678686718146004} | train loss {'Reaction outcome loss': 0.3094395878486825, 'Total loss': 0.3094395878486825}
2023-01-05 05:42:44,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:44,191 INFO:     Epoch: 19
2023-01-05 05:42:46,350 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4489540616671244, 'Total loss': 0.4489540616671244} | train loss {'Reaction outcome loss': 0.29851091642231836, 'Total loss': 0.29851091642231836}
2023-01-05 05:42:46,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:46,351 INFO:     Epoch: 20
2023-01-05 05:42:48,577 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4263667454322179, 'Total loss': 0.4263667454322179} | train loss {'Reaction outcome loss': 0.29694377058559523, 'Total loss': 0.29694377058559523}
2023-01-05 05:42:48,578 INFO:     Found new best model at epoch 20
2023-01-05 05:42:48,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:48,579 INFO:     Epoch: 21
2023-01-05 05:42:50,743 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41105926781892776, 'Total loss': 0.41105926781892776} | train loss {'Reaction outcome loss': 0.2868580686431514, 'Total loss': 0.2868580686431514}
2023-01-05 05:42:50,743 INFO:     Found new best model at epoch 21
2023-01-05 05:42:50,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:50,745 INFO:     Epoch: 22
2023-01-05 05:42:52,907 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41733296861251196, 'Total loss': 0.41733296861251196} | train loss {'Reaction outcome loss': 0.28713703118808515, 'Total loss': 0.28713703118808515}
2023-01-05 05:42:52,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:52,907 INFO:     Epoch: 23
2023-01-05 05:42:55,137 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4554290542999903, 'Total loss': 0.4554290542999903} | train loss {'Reaction outcome loss': 0.28208608766269944, 'Total loss': 0.28208608766269944}
2023-01-05 05:42:55,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:55,137 INFO:     Epoch: 24
2023-01-05 05:42:57,310 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4356505592664083, 'Total loss': 0.4356505592664083} | train loss {'Reaction outcome loss': 0.2787493982209559, 'Total loss': 0.2787493982209559}
2023-01-05 05:42:57,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:57,310 INFO:     Epoch: 25
2023-01-05 05:42:59,535 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40606337239344914, 'Total loss': 0.40606337239344914} | train loss {'Reaction outcome loss': 0.27363755254849903, 'Total loss': 0.27363755254849903}
2023-01-05 05:42:59,535 INFO:     Found new best model at epoch 25
2023-01-05 05:42:59,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:42:59,536 INFO:     Epoch: 26
2023-01-05 05:43:01,754 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43898063401381177, 'Total loss': 0.43898063401381177} | train loss {'Reaction outcome loss': 0.2680920334532857, 'Total loss': 0.2680920334532857}
2023-01-05 05:43:01,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:01,754 INFO:     Epoch: 27
2023-01-05 05:43:04,004 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4594958464304606, 'Total loss': 0.4594958464304606} | train loss {'Reaction outcome loss': 0.2704661687849647, 'Total loss': 0.2704661687849647}
2023-01-05 05:43:04,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:04,004 INFO:     Epoch: 28
2023-01-05 05:43:06,224 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42663651605447134, 'Total loss': 0.42663651605447134} | train loss {'Reaction outcome loss': 0.2606791195860744, 'Total loss': 0.2606791195860744}
2023-01-05 05:43:06,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:06,225 INFO:     Epoch: 29
2023-01-05 05:43:08,456 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4336642031868299, 'Total loss': 0.4336642031868299} | train loss {'Reaction outcome loss': 0.2572641191310691, 'Total loss': 0.2572641191310691}
2023-01-05 05:43:08,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:08,456 INFO:     Epoch: 30
2023-01-05 05:43:10,640 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44752797881762185, 'Total loss': 0.44752797881762185} | train loss {'Reaction outcome loss': 0.2522783240874427, 'Total loss': 0.2522783240874427}
2023-01-05 05:43:10,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:10,641 INFO:     Epoch: 31
2023-01-05 05:43:12,822 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4584974110126495, 'Total loss': 0.4584974110126495} | train loss {'Reaction outcome loss': 0.2521793321182911, 'Total loss': 0.2521793321182911}
2023-01-05 05:43:12,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:12,823 INFO:     Epoch: 32
2023-01-05 05:43:15,004 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4215193698803584, 'Total loss': 0.4215193698803584} | train loss {'Reaction outcome loss': 0.2510015484095164, 'Total loss': 0.2510015484095164}
2023-01-05 05:43:15,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:15,004 INFO:     Epoch: 33
2023-01-05 05:43:17,213 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4687998006741206, 'Total loss': 0.4687998006741206} | train loss {'Reaction outcome loss': 0.2442070012436296, 'Total loss': 0.2442070012436296}
2023-01-05 05:43:17,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:17,213 INFO:     Epoch: 34
2023-01-05 05:43:19,417 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4390592356522878, 'Total loss': 0.4390592356522878} | train loss {'Reaction outcome loss': 0.2448701742954933, 'Total loss': 0.2448701742954933}
2023-01-05 05:43:19,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:19,417 INFO:     Epoch: 35
2023-01-05 05:43:21,639 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4363079051176707, 'Total loss': 0.4363079051176707} | train loss {'Reaction outcome loss': 0.23718817706770487, 'Total loss': 0.23718817706770487}
2023-01-05 05:43:21,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:21,639 INFO:     Epoch: 36
2023-01-05 05:43:23,768 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4394028723239899, 'Total loss': 0.4394028723239899} | train loss {'Reaction outcome loss': 0.23829104310159918, 'Total loss': 0.23829104310159918}
2023-01-05 05:43:23,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:23,769 INFO:     Epoch: 37
2023-01-05 05:43:26,009 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44395510057608284, 'Total loss': 0.44395510057608284} | train loss {'Reaction outcome loss': 0.23262987858241926, 'Total loss': 0.23262987858241926}
2023-01-05 05:43:26,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:26,010 INFO:     Epoch: 38
2023-01-05 05:43:28,143 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.480376793940862, 'Total loss': 0.480376793940862} | train loss {'Reaction outcome loss': 0.23351641729419684, 'Total loss': 0.23351641729419684}
2023-01-05 05:43:28,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:28,143 INFO:     Epoch: 39
2023-01-05 05:43:30,309 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4377119957779845, 'Total loss': 0.4377119957779845} | train loss {'Reaction outcome loss': 0.2314922095133658, 'Total loss': 0.2314922095133658}
2023-01-05 05:43:30,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:30,310 INFO:     Epoch: 40
2023-01-05 05:43:32,526 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47475932190815606, 'Total loss': 0.47475932190815606} | train loss {'Reaction outcome loss': 0.22719977101664582, 'Total loss': 0.22719977101664582}
2023-01-05 05:43:32,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:32,526 INFO:     Epoch: 41
2023-01-05 05:43:34,765 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43271656036376954, 'Total loss': 0.43271656036376954} | train loss {'Reaction outcome loss': 0.22588626867717634, 'Total loss': 0.22588626867717634}
2023-01-05 05:43:34,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:34,765 INFO:     Epoch: 42
2023-01-05 05:43:36,984 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4971616486708323, 'Total loss': 0.4971616486708323} | train loss {'Reaction outcome loss': 0.21936701805786277, 'Total loss': 0.21936701805786277}
2023-01-05 05:43:36,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:36,985 INFO:     Epoch: 43
2023-01-05 05:43:39,220 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4534395530819893, 'Total loss': 0.4534395530819893} | train loss {'Reaction outcome loss': 0.22476705064806735, 'Total loss': 0.22476705064806735}
2023-01-05 05:43:39,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:39,220 INFO:     Epoch: 44
2023-01-05 05:43:41,427 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4393844490249952, 'Total loss': 0.4393844490249952} | train loss {'Reaction outcome loss': 0.2254686727032174, 'Total loss': 0.2254686727032174}
2023-01-05 05:43:41,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:41,427 INFO:     Epoch: 45
2023-01-05 05:43:43,573 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5014605740706126, 'Total loss': 0.5014605740706126} | train loss {'Reaction outcome loss': 0.21197012103550192, 'Total loss': 0.21197012103550192}
2023-01-05 05:43:43,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:43,574 INFO:     Epoch: 46
2023-01-05 05:43:45,763 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.480448916554451, 'Total loss': 0.480448916554451} | train loss {'Reaction outcome loss': 0.21685032076100363, 'Total loss': 0.21685032076100363}
2023-01-05 05:43:45,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:45,763 INFO:     Epoch: 47
2023-01-05 05:43:47,949 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4466042424241702, 'Total loss': 0.4466042424241702} | train loss {'Reaction outcome loss': 0.21695949315317792, 'Total loss': 0.21695949315317792}
2023-01-05 05:43:47,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:47,950 INFO:     Epoch: 48
2023-01-05 05:43:50,117 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4770773986975352, 'Total loss': 0.4770773986975352} | train loss {'Reaction outcome loss': 0.21393248079222266, 'Total loss': 0.21393248079222266}
2023-01-05 05:43:50,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:50,117 INFO:     Epoch: 49
2023-01-05 05:43:52,348 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4644108573595683, 'Total loss': 0.4644108573595683} | train loss {'Reaction outcome loss': 0.21698007596670277, 'Total loss': 0.21698007596670277}
2023-01-05 05:43:52,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:52,349 INFO:     Epoch: 50
2023-01-05 05:43:54,565 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49645660221576693, 'Total loss': 0.49645660221576693} | train loss {'Reaction outcome loss': 0.20667031099407995, 'Total loss': 0.20667031099407995}
2023-01-05 05:43:54,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:54,565 INFO:     Epoch: 51
2023-01-05 05:43:56,761 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47858158747355145, 'Total loss': 0.47858158747355145} | train loss {'Reaction outcome loss': 0.208008316036205, 'Total loss': 0.208008316036205}
2023-01-05 05:43:56,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:56,762 INFO:     Epoch: 52
2023-01-05 05:43:58,903 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4810707062482834, 'Total loss': 0.4810707062482834} | train loss {'Reaction outcome loss': 0.20683611799575333, 'Total loss': 0.20683611799575333}
2023-01-05 05:43:58,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:43:58,903 INFO:     Epoch: 53
2023-01-05 05:44:01,124 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4894114077091217, 'Total loss': 0.4894114077091217} | train loss {'Reaction outcome loss': 0.2069658381442954, 'Total loss': 0.2069658381442954}
2023-01-05 05:44:01,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:01,124 INFO:     Epoch: 54
2023-01-05 05:44:03,302 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4472042679786682, 'Total loss': 0.4472042679786682} | train loss {'Reaction outcome loss': 0.206181031359482, 'Total loss': 0.206181031359482}
2023-01-05 05:44:03,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:03,303 INFO:     Epoch: 55
2023-01-05 05:44:05,489 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4787169059117635, 'Total loss': 0.4787169059117635} | train loss {'Reaction outcome loss': 0.20275270291366174, 'Total loss': 0.20275270291366174}
2023-01-05 05:44:05,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:05,489 INFO:     Epoch: 56
2023-01-05 05:44:07,645 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4417821943759918, 'Total loss': 0.4417821943759918} | train loss {'Reaction outcome loss': 0.19923911743328301, 'Total loss': 0.19923911743328301}
2023-01-05 05:44:07,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:07,646 INFO:     Epoch: 57
2023-01-05 05:44:09,789 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46595027049382526, 'Total loss': 0.46595027049382526} | train loss {'Reaction outcome loss': 0.20140108094469095, 'Total loss': 0.20140108094469095}
2023-01-05 05:44:09,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:09,789 INFO:     Epoch: 58
2023-01-05 05:44:12,039 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46055103143056236, 'Total loss': 0.46055103143056236} | train loss {'Reaction outcome loss': 0.19705044999582708, 'Total loss': 0.19705044999582708}
2023-01-05 05:44:12,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:12,040 INFO:     Epoch: 59
2023-01-05 05:44:14,300 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45012264251708983, 'Total loss': 0.45012264251708983} | train loss {'Reaction outcome loss': 0.2019496719067386, 'Total loss': 0.2019496719067386}
2023-01-05 05:44:14,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:14,301 INFO:     Epoch: 60
2023-01-05 05:44:16,537 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49852218056718506, 'Total loss': 0.49852218056718506} | train loss {'Reaction outcome loss': 0.1926418597347708, 'Total loss': 0.1926418597347708}
2023-01-05 05:44:16,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:16,537 INFO:     Epoch: 61
2023-01-05 05:44:18,765 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43469803730646767, 'Total loss': 0.43469803730646767} | train loss {'Reaction outcome loss': 0.19495729750267018, 'Total loss': 0.19495729750267018}
2023-01-05 05:44:18,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:18,765 INFO:     Epoch: 62
2023-01-05 05:44:21,018 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48538311024506886, 'Total loss': 0.48538311024506886} | train loss {'Reaction outcome loss': 0.19055123712500407, 'Total loss': 0.19055123712500407}
2023-01-05 05:44:21,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:21,018 INFO:     Epoch: 63
2023-01-05 05:44:23,218 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48854360977808636, 'Total loss': 0.48854360977808636} | train loss {'Reaction outcome loss': 0.18844157067827716, 'Total loss': 0.18844157067827716}
2023-01-05 05:44:23,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:23,219 INFO:     Epoch: 64
2023-01-05 05:44:25,429 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45861185193061826, 'Total loss': 0.45861185193061826} | train loss {'Reaction outcome loss': 0.1907525762514531, 'Total loss': 0.1907525762514531}
2023-01-05 05:44:25,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:25,430 INFO:     Epoch: 65
2023-01-05 05:44:27,651 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4793390274047852, 'Total loss': 0.4793390274047852} | train loss {'Reaction outcome loss': 0.1844476286413651, 'Total loss': 0.1844476286413651}
2023-01-05 05:44:27,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:27,652 INFO:     Epoch: 66
2023-01-05 05:44:29,870 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4943835765123367, 'Total loss': 0.4943835765123367} | train loss {'Reaction outcome loss': 0.18847653151482996, 'Total loss': 0.18847653151482996}
2023-01-05 05:44:29,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:29,870 INFO:     Epoch: 67
2023-01-05 05:44:32,100 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5238922735055288, 'Total loss': 0.5238922735055288} | train loss {'Reaction outcome loss': 0.18232299847507943, 'Total loss': 0.18232299847507943}
2023-01-05 05:44:32,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:32,101 INFO:     Epoch: 68
2023-01-05 05:44:34,238 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4347575510541598, 'Total loss': 0.4347575510541598} | train loss {'Reaction outcome loss': 0.1833673443383517, 'Total loss': 0.1833673443383517}
2023-01-05 05:44:34,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:34,238 INFO:     Epoch: 69
2023-01-05 05:44:36,477 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49005719323952995, 'Total loss': 0.49005719323952995} | train loss {'Reaction outcome loss': 0.18146180970098036, 'Total loss': 0.18146180970098036}
2023-01-05 05:44:36,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:36,478 INFO:     Epoch: 70
2023-01-05 05:44:38,704 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4790636440118154, 'Total loss': 0.4790636440118154} | train loss {'Reaction outcome loss': 0.1780975476879436, 'Total loss': 0.1780975476879436}
2023-01-05 05:44:38,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:38,704 INFO:     Epoch: 71
2023-01-05 05:44:40,942 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4749037911494573, 'Total loss': 0.4749037911494573} | train loss {'Reaction outcome loss': 0.17510263849539262, 'Total loss': 0.17510263849539262}
2023-01-05 05:44:40,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:40,943 INFO:     Epoch: 72
2023-01-05 05:44:42,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4877376854419708, 'Total loss': 0.4877376854419708} | train loss {'Reaction outcome loss': 0.17844515624558077, 'Total loss': 0.17844515624558077}
2023-01-05 05:44:42,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:42,981 INFO:     Epoch: 73
2023-01-05 05:44:45,208 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4750127305587133, 'Total loss': 0.4750127305587133} | train loss {'Reaction outcome loss': 0.17491838515457445, 'Total loss': 0.17491838515457445}
2023-01-05 05:44:45,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:45,208 INFO:     Epoch: 74
2023-01-05 05:44:47,439 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4944496929645538, 'Total loss': 0.4944496929645538} | train loss {'Reaction outcome loss': 0.1739862580022292, 'Total loss': 0.1739862580022292}
2023-01-05 05:44:47,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:47,440 INFO:     Epoch: 75
2023-01-05 05:44:49,672 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4488152633110682, 'Total loss': 0.4488152633110682} | train loss {'Reaction outcome loss': 0.17685730668315053, 'Total loss': 0.17685730668315053}
2023-01-05 05:44:49,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:49,672 INFO:     Epoch: 76
2023-01-05 05:44:51,929 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48655273814996086, 'Total loss': 0.48655273814996086} | train loss {'Reaction outcome loss': 0.17365760990098988, 'Total loss': 0.17365760990098988}
2023-01-05 05:44:51,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:51,930 INFO:     Epoch: 77
2023-01-05 05:44:54,225 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49743067622184756, 'Total loss': 0.49743067622184756} | train loss {'Reaction outcome loss': 0.17228269400279017, 'Total loss': 0.17228269400279017}
2023-01-05 05:44:54,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:54,226 INFO:     Epoch: 78
2023-01-05 05:44:56,479 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4859494686126709, 'Total loss': 0.4859494686126709} | train loss {'Reaction outcome loss': 0.1716169989633843, 'Total loss': 0.1716169989633843}
2023-01-05 05:44:56,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:56,480 INFO:     Epoch: 79
2023-01-05 05:44:58,696 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49071695407231647, 'Total loss': 0.49071695407231647} | train loss {'Reaction outcome loss': 0.17189543828177845, 'Total loss': 0.17189543828177845}
2023-01-05 05:44:58,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:44:58,696 INFO:     Epoch: 80
2023-01-05 05:45:00,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5288553059101104, 'Total loss': 0.5288553059101104} | train loss {'Reaction outcome loss': 0.16320389480989453, 'Total loss': 0.16320389480989453}
2023-01-05 05:45:00,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:00,937 INFO:     Epoch: 81
2023-01-05 05:45:03,092 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4827863136927287, 'Total loss': 0.4827863136927287} | train loss {'Reaction outcome loss': 0.1662608499954842, 'Total loss': 0.1662608499954842}
2023-01-05 05:45:03,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:03,092 INFO:     Epoch: 82
2023-01-05 05:45:05,230 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4888346016407013, 'Total loss': 0.4888346016407013} | train loss {'Reaction outcome loss': 0.16467625119580623, 'Total loss': 0.16467625119580623}
2023-01-05 05:45:05,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:05,230 INFO:     Epoch: 83
2023-01-05 05:45:07,456 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48919723828633627, 'Total loss': 0.48919723828633627} | train loss {'Reaction outcome loss': 0.16326531799455737, 'Total loss': 0.16326531799455737}
2023-01-05 05:45:07,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:07,456 INFO:     Epoch: 84
2023-01-05 05:45:09,695 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49270913700262703, 'Total loss': 0.49270913700262703} | train loss {'Reaction outcome loss': 0.16465748558806623, 'Total loss': 0.16465748558806623}
2023-01-05 05:45:09,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:09,695 INFO:     Epoch: 85
2023-01-05 05:45:11,882 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47929985721906027, 'Total loss': 0.47929985721906027} | train loss {'Reaction outcome loss': 0.16378304912423186, 'Total loss': 0.16378304912423186}
2023-01-05 05:45:11,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:11,882 INFO:     Epoch: 86
2023-01-05 05:45:14,092 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5013869608441989, 'Total loss': 0.5013869608441989} | train loss {'Reaction outcome loss': 0.16521292726210163, 'Total loss': 0.16521292726210163}
2023-01-05 05:45:14,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:14,093 INFO:     Epoch: 87
2023-01-05 05:45:16,315 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48930096141994, 'Total loss': 0.48930096141994} | train loss {'Reaction outcome loss': 0.16645796448638134, 'Total loss': 0.16645796448638134}
2023-01-05 05:45:16,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:16,315 INFO:     Epoch: 88
2023-01-05 05:45:18,477 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5173307538032532, 'Total loss': 0.5173307538032532} | train loss {'Reaction outcome loss': 0.16130008495304, 'Total loss': 0.16130008495304}
2023-01-05 05:45:18,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:18,477 INFO:     Epoch: 89
2023-01-05 05:45:20,722 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48718493978182476, 'Total loss': 0.48718493978182476} | train loss {'Reaction outcome loss': 0.16739950918109855, 'Total loss': 0.16739950918109855}
2023-01-05 05:45:20,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:20,723 INFO:     Epoch: 90
2023-01-05 05:45:22,922 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5143845776716868, 'Total loss': 0.5143845776716868} | train loss {'Reaction outcome loss': 0.15672217987233053, 'Total loss': 0.15672217987233053}
2023-01-05 05:45:22,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:22,922 INFO:     Epoch: 91
2023-01-05 05:45:25,083 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5329627340038617, 'Total loss': 0.5329627340038617} | train loss {'Reaction outcome loss': 0.16268443197256674, 'Total loss': 0.16268443197256674}
2023-01-05 05:45:25,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:25,083 INFO:     Epoch: 92
2023-01-05 05:45:27,248 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.508411452670892, 'Total loss': 0.508411452670892} | train loss {'Reaction outcome loss': 0.15892403465899618, 'Total loss': 0.15892403465899618}
2023-01-05 05:45:27,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:27,249 INFO:     Epoch: 93
2023-01-05 05:45:29,453 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4973138878742854, 'Total loss': 0.4973138878742854} | train loss {'Reaction outcome loss': 0.15826375451258445, 'Total loss': 0.15826375451258445}
2023-01-05 05:45:29,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:29,453 INFO:     Epoch: 94
2023-01-05 05:45:31,654 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.52961505651474, 'Total loss': 0.52961505651474} | train loss {'Reaction outcome loss': 0.15827323587264622, 'Total loss': 0.15827323587264622}
2023-01-05 05:45:31,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:31,655 INFO:     Epoch: 95
2023-01-05 05:45:33,769 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49115522106488546, 'Total loss': 0.49115522106488546} | train loss {'Reaction outcome loss': 0.15985578271206877, 'Total loss': 0.15985578271206877}
2023-01-05 05:45:33,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:33,770 INFO:     Epoch: 96
2023-01-05 05:45:35,987 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49971214632193245, 'Total loss': 0.49971214632193245} | train loss {'Reaction outcome loss': 0.16121276208525864, 'Total loss': 0.16121276208525864}
2023-01-05 05:45:35,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:35,987 INFO:     Epoch: 97
2023-01-05 05:45:38,158 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5331971218188604, 'Total loss': 0.5331971218188604} | train loss {'Reaction outcome loss': 0.15441480450617678, 'Total loss': 0.15441480450617678}
2023-01-05 05:45:38,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:38,159 INFO:     Epoch: 98
2023-01-05 05:45:40,308 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49530808528264364, 'Total loss': 0.49530808528264364} | train loss {'Reaction outcome loss': 0.15601383553423587, 'Total loss': 0.15601383553423587}
2023-01-05 05:45:40,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:40,308 INFO:     Epoch: 99
2023-01-05 05:45:42,541 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5226867765188217, 'Total loss': 0.5226867765188217} | train loss {'Reaction outcome loss': 0.15807822624724494, 'Total loss': 0.15807822624724494}
2023-01-05 05:45:42,541 INFO:     Best model found after epoch 26 of 100.
2023-01-05 05:45:42,541 INFO:   Done with stage: TRAINING
2023-01-05 05:45:42,541 INFO:   Starting stage: EVALUATION
2023-01-05 05:45:42,683 INFO:   Done with stage: EVALUATION
2023-01-05 05:45:42,683 INFO:   Leaving out SEQ value Fold_9
2023-01-05 05:45:42,696 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 05:45:42,696 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:45:43,349 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:45:43,350 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:45:43,422 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:45:43,423 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:45:43,423 INFO:     No hyperparam tuning for this model
2023-01-05 05:45:43,423 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:45:43,423 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:45:43,423 INFO:     None feature selector for col prot
2023-01-05 05:45:43,424 INFO:     None feature selector for col prot
2023-01-05 05:45:43,424 INFO:     None feature selector for col prot
2023-01-05 05:45:43,424 INFO:     None feature selector for col chem
2023-01-05 05:45:43,424 INFO:     None feature selector for col chem
2023-01-05 05:45:43,424 INFO:     None feature selector for col chem
2023-01-05 05:45:43,424 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:45:43,424 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:45:43,426 INFO:     Number of params in model 72931
2023-01-05 05:45:43,429 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:45:43,429 INFO:   Starting stage: TRAINING
2023-01-05 05:45:43,492 INFO:     Val loss before train {'Reaction outcome loss': 1.0107023517290752, 'Total loss': 1.0107023517290752}
2023-01-05 05:45:43,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:43,492 INFO:     Epoch: 0
2023-01-05 05:45:45,644 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7854166328907013, 'Total loss': 0.7854166328907013} | train loss {'Reaction outcome loss': 0.9547095242617787, 'Total loss': 0.9547095242617787}
2023-01-05 05:45:45,644 INFO:     Found new best model at epoch 0
2023-01-05 05:45:45,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:45,646 INFO:     Epoch: 1
2023-01-05 05:45:47,831 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6081691940625509, 'Total loss': 0.6081691940625509} | train loss {'Reaction outcome loss': 0.6414623248620309, 'Total loss': 0.6414623248620309}
2023-01-05 05:45:47,831 INFO:     Found new best model at epoch 1
2023-01-05 05:45:47,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:47,832 INFO:     Epoch: 2
2023-01-05 05:45:50,023 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5534501989682515, 'Total loss': 0.5534501989682515} | train loss {'Reaction outcome loss': 0.5340348927134798, 'Total loss': 0.5340348927134798}
2023-01-05 05:45:50,024 INFO:     Found new best model at epoch 2
2023-01-05 05:45:50,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:50,025 INFO:     Epoch: 3
2023-01-05 05:45:52,252 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5306497280796368, 'Total loss': 0.5306497280796368} | train loss {'Reaction outcome loss': 0.4926928286103235, 'Total loss': 0.4926928286103235}
2023-01-05 05:45:52,252 INFO:     Found new best model at epoch 3
2023-01-05 05:45:52,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:52,253 INFO:     Epoch: 4
2023-01-05 05:45:54,504 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5196979532639185, 'Total loss': 0.5196979532639185} | train loss {'Reaction outcome loss': 0.45322298090162594, 'Total loss': 0.45322298090162594}
2023-01-05 05:45:54,504 INFO:     Found new best model at epoch 4
2023-01-05 05:45:54,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:54,506 INFO:     Epoch: 5
2023-01-05 05:45:56,711 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.502434355020523, 'Total loss': 0.502434355020523} | train loss {'Reaction outcome loss': 0.4345707344296186, 'Total loss': 0.4345707344296186}
2023-01-05 05:45:56,711 INFO:     Found new best model at epoch 5
2023-01-05 05:45:56,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:56,712 INFO:     Epoch: 6
2023-01-05 05:45:58,969 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4886831521987915, 'Total loss': 0.4886831521987915} | train loss {'Reaction outcome loss': 0.41889605491482856, 'Total loss': 0.41889605491482856}
2023-01-05 05:45:58,969 INFO:     Found new best model at epoch 6
2023-01-05 05:45:58,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:45:58,971 INFO:     Epoch: 7
2023-01-05 05:46:01,128 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.481113741795222, 'Total loss': 0.481113741795222} | train loss {'Reaction outcome loss': 0.39642545092257037, 'Total loss': 0.39642545092257037}
2023-01-05 05:46:01,128 INFO:     Found new best model at epoch 7
2023-01-05 05:46:01,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:01,129 INFO:     Epoch: 8
2023-01-05 05:46:03,346 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4865029752254486, 'Total loss': 0.4865029752254486} | train loss {'Reaction outcome loss': 0.38814621424788365, 'Total loss': 0.38814621424788365}
2023-01-05 05:46:03,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:03,347 INFO:     Epoch: 9
2023-01-05 05:46:05,590 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48664476176102955, 'Total loss': 0.48664476176102955} | train loss {'Reaction outcome loss': 0.3826093668037135, 'Total loss': 0.3826093668037135}
2023-01-05 05:46:05,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:05,590 INFO:     Epoch: 10
2023-01-05 05:46:07,830 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5265993138154348, 'Total loss': 0.5265993138154348} | train loss {'Reaction outcome loss': 0.3763016994394686, 'Total loss': 0.3763016994394686}
2023-01-05 05:46:07,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:07,830 INFO:     Epoch: 11
2023-01-05 05:46:09,982 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4648745745420456, 'Total loss': 0.4648745745420456} | train loss {'Reaction outcome loss': 0.3688720423404289, 'Total loss': 0.3688720423404289}
2023-01-05 05:46:09,982 INFO:     Found new best model at epoch 11
2023-01-05 05:46:09,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:09,984 INFO:     Epoch: 12
2023-01-05 05:46:12,233 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4829808493455251, 'Total loss': 0.4829808493455251} | train loss {'Reaction outcome loss': 0.36335843390839145, 'Total loss': 0.36335843390839145}
2023-01-05 05:46:12,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:12,233 INFO:     Epoch: 13
2023-01-05 05:46:14,420 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4795722554127375, 'Total loss': 0.4795722554127375} | train loss {'Reaction outcome loss': 0.349381262931696, 'Total loss': 0.349381262931696}
2023-01-05 05:46:14,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:14,422 INFO:     Epoch: 14
2023-01-05 05:46:16,619 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4836202124754588, 'Total loss': 0.4836202124754588} | train loss {'Reaction outcome loss': 0.3387799675001061, 'Total loss': 0.3387799675001061}
2023-01-05 05:46:16,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:16,620 INFO:     Epoch: 15
2023-01-05 05:46:18,880 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46535208225250246, 'Total loss': 0.46535208225250246} | train loss {'Reaction outcome loss': 0.33529350946438446, 'Total loss': 0.33529350946438446}
2023-01-05 05:46:18,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:18,881 INFO:     Epoch: 16
2023-01-05 05:46:21,148 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46707272430260977, 'Total loss': 0.46707272430260977} | train loss {'Reaction outcome loss': 0.3277423537025849, 'Total loss': 0.3277423537025849}
2023-01-05 05:46:21,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:21,149 INFO:     Epoch: 17
2023-01-05 05:46:23,332 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4738166530927022, 'Total loss': 0.4738166530927022} | train loss {'Reaction outcome loss': 0.3216243841374492, 'Total loss': 0.3216243841374492}
2023-01-05 05:46:23,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:23,333 INFO:     Epoch: 18
2023-01-05 05:46:25,570 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5263500382502874, 'Total loss': 0.5263500382502874} | train loss {'Reaction outcome loss': 0.31788942928171204, 'Total loss': 0.31788942928171204}
2023-01-05 05:46:25,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:25,571 INFO:     Epoch: 19
2023-01-05 05:46:27,837 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46128010749816895, 'Total loss': 0.46128010749816895} | train loss {'Reaction outcome loss': 0.30847849456282955, 'Total loss': 0.30847849456282955}
2023-01-05 05:46:27,838 INFO:     Found new best model at epoch 19
2023-01-05 05:46:27,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:27,839 INFO:     Epoch: 20
2023-01-05 05:46:30,056 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4637980123360952, 'Total loss': 0.4637980123360952} | train loss {'Reaction outcome loss': 0.2942426098017967, 'Total loss': 0.2942426098017967}
2023-01-05 05:46:30,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:30,056 INFO:     Epoch: 21
2023-01-05 05:46:32,329 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4539030998945236, 'Total loss': 0.4539030998945236} | train loss {'Reaction outcome loss': 0.2967354484793285, 'Total loss': 0.2967354484793285}
2023-01-05 05:46:32,329 INFO:     Found new best model at epoch 21
2023-01-05 05:46:32,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:32,331 INFO:     Epoch: 22
2023-01-05 05:46:34,621 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4728027840455373, 'Total loss': 0.4728027840455373} | train loss {'Reaction outcome loss': 0.29038471162578167, 'Total loss': 0.29038471162578167}
2023-01-05 05:46:34,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:34,622 INFO:     Epoch: 23
2023-01-05 05:46:36,668 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46534959475199383, 'Total loss': 0.46534959475199383} | train loss {'Reaction outcome loss': 0.3106410315334527, 'Total loss': 0.3106410315334527}
2023-01-05 05:46:36,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:36,668 INFO:     Epoch: 24
2023-01-05 05:46:38,522 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46127988000710807, 'Total loss': 0.46127988000710807} | train loss {'Reaction outcome loss': 0.27932802276631846, 'Total loss': 0.27932802276631846}
2023-01-05 05:46:38,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:38,522 INFO:     Epoch: 25
2023-01-05 05:46:40,437 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4738577629129092, 'Total loss': 0.4738577629129092} | train loss {'Reaction outcome loss': 0.2783392411526844, 'Total loss': 0.2783392411526844}
2023-01-05 05:46:40,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:40,437 INFO:     Epoch: 26
2023-01-05 05:46:42,685 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46279639899730685, 'Total loss': 0.46279639899730685} | train loss {'Reaction outcome loss': 0.2749257578271563, 'Total loss': 0.2749257578271563}
2023-01-05 05:46:42,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:42,685 INFO:     Epoch: 27
2023-01-05 05:46:44,908 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4578397850195567, 'Total loss': 0.4578397850195567} | train loss {'Reaction outcome loss': 0.2672373919741021, 'Total loss': 0.2672373919741021}
2023-01-05 05:46:44,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:44,908 INFO:     Epoch: 28
2023-01-05 05:46:47,134 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4880186160405477, 'Total loss': 0.4880186160405477} | train loss {'Reaction outcome loss': 0.2647686425117317, 'Total loss': 0.2647686425117317}
2023-01-05 05:46:47,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:47,135 INFO:     Epoch: 29
2023-01-05 05:46:49,339 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4548139125108719, 'Total loss': 0.4548139125108719} | train loss {'Reaction outcome loss': 0.2585196504285019, 'Total loss': 0.2585196504285019}
2023-01-05 05:46:49,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:49,339 INFO:     Epoch: 30
2023-01-05 05:46:51,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4592516601085663, 'Total loss': 0.4592516601085663} | train loss {'Reaction outcome loss': 0.25788526320020144, 'Total loss': 0.25788526320020144}
2023-01-05 05:46:51,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:51,578 INFO:     Epoch: 31
2023-01-05 05:46:53,795 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4665043403704961, 'Total loss': 0.4665043403704961} | train loss {'Reaction outcome loss': 0.25807356815177784, 'Total loss': 0.25807356815177784}
2023-01-05 05:46:53,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:53,795 INFO:     Epoch: 32
2023-01-05 05:46:56,036 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49024883707364403, 'Total loss': 0.49024883707364403} | train loss {'Reaction outcome loss': 0.25411169753457163, 'Total loss': 0.25411169753457163}
2023-01-05 05:46:56,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:56,036 INFO:     Epoch: 33
2023-01-05 05:46:58,286 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46439199447631835, 'Total loss': 0.46439199447631835} | train loss {'Reaction outcome loss': 0.24975377441539118, 'Total loss': 0.24975377441539118}
2023-01-05 05:46:58,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:46:58,286 INFO:     Epoch: 34
2023-01-05 05:47:00,504 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4536474277575811, 'Total loss': 0.4536474277575811} | train loss {'Reaction outcome loss': 0.24698723798655262, 'Total loss': 0.24698723798655262}
2023-01-05 05:47:00,504 INFO:     Found new best model at epoch 34
2023-01-05 05:47:00,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:00,506 INFO:     Epoch: 35
2023-01-05 05:47:02,690 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4826725393533707, 'Total loss': 0.4826725393533707} | train loss {'Reaction outcome loss': 0.24016734812935087, 'Total loss': 0.24016734812935087}
2023-01-05 05:47:02,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:02,690 INFO:     Epoch: 36
2023-01-05 05:47:04,889 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44725978970527647, 'Total loss': 0.44725978970527647} | train loss {'Reaction outcome loss': 0.23992727086811827, 'Total loss': 0.23992727086811827}
2023-01-05 05:47:04,889 INFO:     Found new best model at epoch 36
2023-01-05 05:47:04,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:04,891 INFO:     Epoch: 37
2023-01-05 05:47:07,132 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4486628899971644, 'Total loss': 0.4486628899971644} | train loss {'Reaction outcome loss': 0.23244783078384437, 'Total loss': 0.23244783078384437}
2023-01-05 05:47:07,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:07,133 INFO:     Epoch: 38
2023-01-05 05:47:09,355 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4505335927009583, 'Total loss': 0.4505335927009583} | train loss {'Reaction outcome loss': 0.23155041750942473, 'Total loss': 0.23155041750942473}
2023-01-05 05:47:09,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:09,355 INFO:     Epoch: 39
2023-01-05 05:47:11,588 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45844841102759043, 'Total loss': 0.45844841102759043} | train loss {'Reaction outcome loss': 0.2302628631055679, 'Total loss': 0.2302628631055679}
2023-01-05 05:47:11,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:11,588 INFO:     Epoch: 40
2023-01-05 05:47:13,776 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4419356147448222, 'Total loss': 0.4419356147448222} | train loss {'Reaction outcome loss': 0.2287851017114746, 'Total loss': 0.2287851017114746}
2023-01-05 05:47:13,777 INFO:     Found new best model at epoch 40
2023-01-05 05:47:13,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:13,778 INFO:     Epoch: 41
2023-01-05 05:47:16,002 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4499443670113881, 'Total loss': 0.4499443670113881} | train loss {'Reaction outcome loss': 0.231004806847109, 'Total loss': 0.231004806847109}
2023-01-05 05:47:16,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:16,002 INFO:     Epoch: 42
2023-01-05 05:47:18,188 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4866849939028422, 'Total loss': 0.4866849939028422} | train loss {'Reaction outcome loss': 0.2281680830680104, 'Total loss': 0.2281680830680104}
2023-01-05 05:47:18,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:18,188 INFO:     Epoch: 43
2023-01-05 05:47:20,387 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4613776435454687, 'Total loss': 0.4613776435454687} | train loss {'Reaction outcome loss': 0.2196458727053866, 'Total loss': 0.2196458727053866}
2023-01-05 05:47:20,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:20,388 INFO:     Epoch: 44
2023-01-05 05:47:22,567 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48485634922981263, 'Total loss': 0.48485634922981263} | train loss {'Reaction outcome loss': 0.21531638978943363, 'Total loss': 0.21531638978943363}
2023-01-05 05:47:22,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:22,567 INFO:     Epoch: 45
2023-01-05 05:47:24,808 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48536029557387034, 'Total loss': 0.48536029557387034} | train loss {'Reaction outcome loss': 0.2353390561943145, 'Total loss': 0.2353390561943145}
2023-01-05 05:47:24,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:24,808 INFO:     Epoch: 46
2023-01-05 05:47:27,017 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4600058535734812, 'Total loss': 0.4600058535734812} | train loss {'Reaction outcome loss': 0.23022996435495283, 'Total loss': 0.23022996435495283}
2023-01-05 05:47:27,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:27,018 INFO:     Epoch: 47
2023-01-05 05:47:29,247 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.456908643245697, 'Total loss': 0.456908643245697} | train loss {'Reaction outcome loss': 0.22667368537720217, 'Total loss': 0.22667368537720217}
2023-01-05 05:47:29,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:29,247 INFO:     Epoch: 48
2023-01-05 05:47:31,406 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4666510840257009, 'Total loss': 0.4666510840257009} | train loss {'Reaction outcome loss': 0.21210994847667503, 'Total loss': 0.21210994847667503}
2023-01-05 05:47:31,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:31,406 INFO:     Epoch: 49
2023-01-05 05:47:33,540 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45762978196144105, 'Total loss': 0.45762978196144105} | train loss {'Reaction outcome loss': 0.20803951407646493, 'Total loss': 0.20803951407646493}
2023-01-05 05:47:33,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:33,540 INFO:     Epoch: 50
2023-01-05 05:47:35,766 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47429946760336555, 'Total loss': 0.47429946760336555} | train loss {'Reaction outcome loss': 0.20548690720064822, 'Total loss': 0.20548690720064822}
2023-01-05 05:47:35,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:35,767 INFO:     Epoch: 51
2023-01-05 05:47:38,025 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4705210308233897, 'Total loss': 0.4705210308233897} | train loss {'Reaction outcome loss': 0.20266790478770597, 'Total loss': 0.20266790478770597}
2023-01-05 05:47:38,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:38,025 INFO:     Epoch: 52
2023-01-05 05:47:40,264 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46219671368598936, 'Total loss': 0.46219671368598936} | train loss {'Reaction outcome loss': 0.20414901266812577, 'Total loss': 0.20414901266812577}
2023-01-05 05:47:40,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:40,265 INFO:     Epoch: 53
2023-01-05 05:47:42,440 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48999014099438987, 'Total loss': 0.48999014099438987} | train loss {'Reaction outcome loss': 0.20048262197456823, 'Total loss': 0.20048262197456823}
2023-01-05 05:47:42,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:42,440 INFO:     Epoch: 54
2023-01-05 05:47:44,691 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4825704058011373, 'Total loss': 0.4825704058011373} | train loss {'Reaction outcome loss': 0.20089667922634954, 'Total loss': 0.20089667922634954}
2023-01-05 05:47:44,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:44,691 INFO:     Epoch: 55
2023-01-05 05:47:46,876 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49847629268964133, 'Total loss': 0.49847629268964133} | train loss {'Reaction outcome loss': 0.2012021528047415, 'Total loss': 0.2012021528047415}
2023-01-05 05:47:46,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:46,877 INFO:     Epoch: 56
2023-01-05 05:47:49,132 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47036637862523395, 'Total loss': 0.47036637862523395} | train loss {'Reaction outcome loss': 0.19575422465403908, 'Total loss': 0.19575422465403908}
2023-01-05 05:47:49,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:49,132 INFO:     Epoch: 57
2023-01-05 05:47:51,363 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.496269420782725, 'Total loss': 0.496269420782725} | train loss {'Reaction outcome loss': 0.195435732738891, 'Total loss': 0.195435732738891}
2023-01-05 05:47:51,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:51,363 INFO:     Epoch: 58
2023-01-05 05:47:53,605 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49849345684051516, 'Total loss': 0.49849345684051516} | train loss {'Reaction outcome loss': 0.19644071507281152, 'Total loss': 0.19644071507281152}
2023-01-05 05:47:53,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:53,605 INFO:     Epoch: 59
2023-01-05 05:47:55,868 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4781299591064453, 'Total loss': 0.4781299591064453} | train loss {'Reaction outcome loss': 0.19284658607843533, 'Total loss': 0.19284658607843533}
2023-01-05 05:47:55,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:55,868 INFO:     Epoch: 60
2023-01-05 05:47:58,101 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5113595932722091, 'Total loss': 0.5113595932722091} | train loss {'Reaction outcome loss': 0.19593070551195854, 'Total loss': 0.19593070551195854}
2023-01-05 05:47:58,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:47:58,102 INFO:     Epoch: 61
2023-01-05 05:48:00,376 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4861760844786962, 'Total loss': 0.4861760844786962} | train loss {'Reaction outcome loss': 0.19233298809693067, 'Total loss': 0.19233298809693067}
2023-01-05 05:48:00,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:00,376 INFO:     Epoch: 62
2023-01-05 05:48:02,561 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47616143623987833, 'Total loss': 0.47616143623987833} | train loss {'Reaction outcome loss': 0.1924883158265046, 'Total loss': 0.1924883158265046}
2023-01-05 05:48:02,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:02,561 INFO:     Epoch: 63
2023-01-05 05:48:04,819 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5486192802588145, 'Total loss': 0.5486192802588145} | train loss {'Reaction outcome loss': 0.1897461446406205, 'Total loss': 0.1897461446406205}
2023-01-05 05:48:04,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:04,820 INFO:     Epoch: 64
2023-01-05 05:48:07,076 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5450863003730774, 'Total loss': 0.5450863003730774} | train loss {'Reaction outcome loss': 0.19180534383401432, 'Total loss': 0.19180534383401432}
2023-01-05 05:48:07,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:07,076 INFO:     Epoch: 65
2023-01-05 05:48:09,323 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5031291902065277, 'Total loss': 0.5031291902065277} | train loss {'Reaction outcome loss': 0.19259450842788362, 'Total loss': 0.19259450842788362}
2023-01-05 05:48:09,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:09,323 INFO:     Epoch: 66
2023-01-05 05:48:11,577 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4853343745072683, 'Total loss': 0.4853343745072683} | train loss {'Reaction outcome loss': 0.18835193127397096, 'Total loss': 0.18835193127397096}
2023-01-05 05:48:11,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:11,578 INFO:     Epoch: 67
2023-01-05 05:48:13,837 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5066378305355708, 'Total loss': 0.5066378305355708} | train loss {'Reaction outcome loss': 0.18217916825138356, 'Total loss': 0.18217916825138356}
2023-01-05 05:48:13,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:13,837 INFO:     Epoch: 68
2023-01-05 05:48:16,103 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49796741753816604, 'Total loss': 0.49796741753816604} | train loss {'Reaction outcome loss': 0.20520702973548052, 'Total loss': 0.20520702973548052}
2023-01-05 05:48:16,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:16,104 INFO:     Epoch: 69
2023-01-05 05:48:18,368 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4928915768861771, 'Total loss': 0.4928915768861771} | train loss {'Reaction outcome loss': 0.1862203527669645, 'Total loss': 0.1862203527669645}
2023-01-05 05:48:18,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:18,369 INFO:     Epoch: 70
2023-01-05 05:48:20,610 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5238140006860097, 'Total loss': 0.5238140006860097} | train loss {'Reaction outcome loss': 0.17958978456399433, 'Total loss': 0.17958978456399433}
2023-01-05 05:48:20,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:20,611 INFO:     Epoch: 71
2023-01-05 05:48:22,868 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45842514087756475, 'Total loss': 0.45842514087756475} | train loss {'Reaction outcome loss': 0.1872990891426815, 'Total loss': 0.1872990891426815}
2023-01-05 05:48:22,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:22,868 INFO:     Epoch: 72
2023-01-05 05:48:25,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48620032469431557, 'Total loss': 0.48620032469431557} | train loss {'Reaction outcome loss': 0.20237548518892162, 'Total loss': 0.20237548518892162}
2023-01-05 05:48:25,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:25,132 INFO:     Epoch: 73
2023-01-05 05:48:27,374 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4851645310719808, 'Total loss': 0.4851645310719808} | train loss {'Reaction outcome loss': 0.1897501057094854, 'Total loss': 0.1897501057094854}
2023-01-05 05:48:27,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:27,375 INFO:     Epoch: 74
2023-01-05 05:48:29,631 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47555917004744214, 'Total loss': 0.47555917004744214} | train loss {'Reaction outcome loss': 0.17866666832416767, 'Total loss': 0.17866666832416767}
2023-01-05 05:48:29,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:29,632 INFO:     Epoch: 75
2023-01-05 05:48:31,767 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5079367697238922, 'Total loss': 0.5079367697238922} | train loss {'Reaction outcome loss': 0.1756218435155039, 'Total loss': 0.1756218435155039}
2023-01-05 05:48:31,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:31,767 INFO:     Epoch: 76
2023-01-05 05:48:34,038 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5024689296881358, 'Total loss': 0.5024689296881358} | train loss {'Reaction outcome loss': 0.17678731331577274, 'Total loss': 0.17678731331577274}
2023-01-05 05:48:34,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:34,039 INFO:     Epoch: 77
2023-01-05 05:48:36,314 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5383926679690679, 'Total loss': 0.5383926679690679} | train loss {'Reaction outcome loss': 0.17683555165548687, 'Total loss': 0.17683555165548687}
2023-01-05 05:48:36,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:36,314 INFO:     Epoch: 78
2023-01-05 05:48:38,532 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5525381147861481, 'Total loss': 0.5525381147861481} | train loss {'Reaction outcome loss': 0.1673311287570117, 'Total loss': 0.1673311287570117}
2023-01-05 05:48:38,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:38,532 INFO:     Epoch: 79
2023-01-05 05:48:40,793 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5392257730166118, 'Total loss': 0.5392257730166118} | train loss {'Reaction outcome loss': 0.1728096806758043, 'Total loss': 0.1728096806758043}
2023-01-05 05:48:40,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:40,794 INFO:     Epoch: 80
2023-01-05 05:48:43,049 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49796582410732904, 'Total loss': 0.49796582410732904} | train loss {'Reaction outcome loss': 0.17403886803810525, 'Total loss': 0.17403886803810525}
2023-01-05 05:48:43,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:43,049 INFO:     Epoch: 81
2023-01-05 05:48:45,316 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49441360036532084, 'Total loss': 0.49441360036532084} | train loss {'Reaction outcome loss': 0.17277238014092133, 'Total loss': 0.17277238014092133}
2023-01-05 05:48:45,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:45,317 INFO:     Epoch: 82
2023-01-05 05:48:47,383 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5255166292190552, 'Total loss': 0.5255166292190552} | train loss {'Reaction outcome loss': 0.1952472404708438, 'Total loss': 0.1952472404708438}
2023-01-05 05:48:47,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:47,384 INFO:     Epoch: 83
2023-01-05 05:48:49,626 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4775903671979904, 'Total loss': 0.4775903671979904} | train loss {'Reaction outcome loss': 0.17494418244113794, 'Total loss': 0.17494418244113794}
2023-01-05 05:48:49,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:49,626 INFO:     Epoch: 84
2023-01-05 05:48:51,892 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.534136493007342, 'Total loss': 0.534136493007342} | train loss {'Reaction outcome loss': 0.1681149618361024, 'Total loss': 0.1681149618361024}
2023-01-05 05:48:51,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:51,892 INFO:     Epoch: 85
2023-01-05 05:48:54,154 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4789426525433858, 'Total loss': 0.4789426525433858} | train loss {'Reaction outcome loss': 0.1719570106394805, 'Total loss': 0.1719570106394805}
2023-01-05 05:48:54,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:54,154 INFO:     Epoch: 86
2023-01-05 05:48:56,390 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.496942005554835, 'Total loss': 0.496942005554835} | train loss {'Reaction outcome loss': 0.16579769846377557, 'Total loss': 0.16579769846377557}
2023-01-05 05:48:56,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:56,390 INFO:     Epoch: 87
2023-01-05 05:48:58,661 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4888042191664378, 'Total loss': 0.4888042191664378} | train loss {'Reaction outcome loss': 0.17312897679854042, 'Total loss': 0.17312897679854042}
2023-01-05 05:48:58,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:48:58,662 INFO:     Epoch: 88
2023-01-05 05:49:00,907 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.484001358350118, 'Total loss': 0.484001358350118} | train loss {'Reaction outcome loss': 0.18049170384588448, 'Total loss': 0.18049170384588448}
2023-01-05 05:49:00,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:00,907 INFO:     Epoch: 89
2023-01-05 05:49:03,168 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45530678033828736, 'Total loss': 0.45530678033828736} | train loss {'Reaction outcome loss': 0.20993583789095283, 'Total loss': 0.20993583789095283}
2023-01-05 05:49:03,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:03,169 INFO:     Epoch: 90
2023-01-05 05:49:05,427 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4652127633492152, 'Total loss': 0.4652127633492152} | train loss {'Reaction outcome loss': 0.18422510428185426, 'Total loss': 0.18422510428185426}
2023-01-05 05:49:05,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:05,428 INFO:     Epoch: 91
2023-01-05 05:49:07,668 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48225533266862236, 'Total loss': 0.48225533266862236} | train loss {'Reaction outcome loss': 0.2061134685822965, 'Total loss': 0.2061134685822965}
2023-01-05 05:49:07,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:07,668 INFO:     Epoch: 92
2023-01-05 05:49:09,909 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47674247771501543, 'Total loss': 0.47674247771501543} | train loss {'Reaction outcome loss': 0.17546669456878325, 'Total loss': 0.17546669456878325}
2023-01-05 05:49:09,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:09,909 INFO:     Epoch: 93
2023-01-05 05:49:12,159 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4678413967291514, 'Total loss': 0.4678413967291514} | train loss {'Reaction outcome loss': 0.17014214751585657, 'Total loss': 0.17014214751585657}
2023-01-05 05:49:12,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:12,159 INFO:     Epoch: 94
2023-01-05 05:49:14,414 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47320723136266074, 'Total loss': 0.47320723136266074} | train loss {'Reaction outcome loss': 0.1918915269214768, 'Total loss': 0.1918915269214768}
2023-01-05 05:49:14,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:14,414 INFO:     Epoch: 95
2023-01-05 05:49:16,676 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4877593497435252, 'Total loss': 0.4877593497435252} | train loss {'Reaction outcome loss': 0.16613075726142953, 'Total loss': 0.16613075726142953}
2023-01-05 05:49:16,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:16,676 INFO:     Epoch: 96
2023-01-05 05:49:18,801 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47792810052633283, 'Total loss': 0.47792810052633283} | train loss {'Reaction outcome loss': 0.16272746619053077, 'Total loss': 0.16272746619053077}
2023-01-05 05:49:18,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:18,802 INFO:     Epoch: 97
2023-01-05 05:49:21,028 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4870289206504822, 'Total loss': 0.4870289206504822} | train loss {'Reaction outcome loss': 0.20261527457931652, 'Total loss': 0.20261527457931652}
2023-01-05 05:49:21,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:21,028 INFO:     Epoch: 98
2023-01-05 05:49:23,261 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4871654133001963, 'Total loss': 0.4871654133001963} | train loss {'Reaction outcome loss': 0.16628115395239243, 'Total loss': 0.16628115395239243}
2023-01-05 05:49:23,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:23,262 INFO:     Epoch: 99
2023-01-05 05:49:25,497 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5354703962802887, 'Total loss': 0.5354703962802887} | train loss {'Reaction outcome loss': 0.15794525033561513, 'Total loss': 0.15794525033561513}
2023-01-05 05:49:25,497 INFO:     Best model found after epoch 41 of 100.
2023-01-05 05:49:25,497 INFO:   Done with stage: TRAINING
2023-01-05 05:49:25,497 INFO:   Starting stage: EVALUATION
2023-01-05 05:49:25,632 INFO:   Done with stage: EVALUATION
2023-01-05 05:49:25,640 INFO:   Leaving out SEQ value Fold_0
2023-01-05 05:49:25,652 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 05:49:25,652 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:49:26,298 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:49:26,298 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:49:26,370 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:49:26,370 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:49:26,370 INFO:     No hyperparam tuning for this model
2023-01-05 05:49:26,370 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:49:26,370 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:49:26,371 INFO:     None feature selector for col prot
2023-01-05 05:49:26,371 INFO:     None feature selector for col prot
2023-01-05 05:49:26,371 INFO:     None feature selector for col prot
2023-01-05 05:49:26,371 INFO:     None feature selector for col chem
2023-01-05 05:49:26,372 INFO:     None feature selector for col chem
2023-01-05 05:49:26,372 INFO:     None feature selector for col chem
2023-01-05 05:49:26,372 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:49:26,372 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:49:26,373 INFO:     Number of params in model 72931
2023-01-05 05:49:26,376 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:49:26,376 INFO:   Starting stage: TRAINING
2023-01-05 05:49:26,435 INFO:     Val loss before train {'Reaction outcome loss': 0.9275495330492656, 'Total loss': 0.9275495330492656}
2023-01-05 05:49:26,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:26,436 INFO:     Epoch: 0
2023-01-05 05:49:28,528 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6830482383569082, 'Total loss': 0.6830482383569082} | train loss {'Reaction outcome loss': 0.9316483907594012, 'Total loss': 0.9316483907594012}
2023-01-05 05:49:28,528 INFO:     Found new best model at epoch 0
2023-01-05 05:49:28,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:28,529 INFO:     Epoch: 1
2023-01-05 05:49:30,712 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.512739269932111, 'Total loss': 0.512739269932111} | train loss {'Reaction outcome loss': 0.6195726280832643, 'Total loss': 0.6195726280832643}
2023-01-05 05:49:30,712 INFO:     Found new best model at epoch 1
2023-01-05 05:49:30,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:30,714 INFO:     Epoch: 2
2023-01-05 05:49:32,932 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4528588205575943, 'Total loss': 0.4528588205575943} | train loss {'Reaction outcome loss': 0.5216699767156721, 'Total loss': 0.5216699767156721}
2023-01-05 05:49:32,932 INFO:     Found new best model at epoch 2
2023-01-05 05:49:32,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:32,933 INFO:     Epoch: 3
2023-01-05 05:49:35,063 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45256829063097637, 'Total loss': 0.45256829063097637} | train loss {'Reaction outcome loss': 0.4842405955949833, 'Total loss': 0.4842405955949833}
2023-01-05 05:49:35,064 INFO:     Found new best model at epoch 3
2023-01-05 05:49:35,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:35,065 INFO:     Epoch: 4
2023-01-05 05:49:37,254 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4282614270846049, 'Total loss': 0.4282614270846049} | train loss {'Reaction outcome loss': 0.4547883536103027, 'Total loss': 0.4547883536103027}
2023-01-05 05:49:37,254 INFO:     Found new best model at epoch 4
2023-01-05 05:49:37,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:37,255 INFO:     Epoch: 5
2023-01-05 05:49:39,457 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3992520809173584, 'Total loss': 0.3992520809173584} | train loss {'Reaction outcome loss': 0.43569815554742003, 'Total loss': 0.43569815554742003}
2023-01-05 05:49:39,458 INFO:     Found new best model at epoch 5
2023-01-05 05:49:39,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:39,459 INFO:     Epoch: 6
2023-01-05 05:49:41,636 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3952921877304713, 'Total loss': 0.3952921877304713} | train loss {'Reaction outcome loss': 0.40895495918404134, 'Total loss': 0.40895495918404134}
2023-01-05 05:49:41,636 INFO:     Found new best model at epoch 6
2023-01-05 05:49:41,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:41,637 INFO:     Epoch: 7
2023-01-05 05:49:43,860 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4009397288163503, 'Total loss': 0.4009397288163503} | train loss {'Reaction outcome loss': 0.39548237168151074, 'Total loss': 0.39548237168151074}
2023-01-05 05:49:43,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:43,860 INFO:     Epoch: 8
2023-01-05 05:49:46,082 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.36681737502415973, 'Total loss': 0.36681737502415973} | train loss {'Reaction outcome loss': 0.38076201059281606, 'Total loss': 0.38076201059281606}
2023-01-05 05:49:46,083 INFO:     Found new best model at epoch 8
2023-01-05 05:49:46,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:46,084 INFO:     Epoch: 9
2023-01-05 05:49:48,255 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3859306467076143, 'Total loss': 0.3859306467076143} | train loss {'Reaction outcome loss': 0.36851852180992983, 'Total loss': 0.36851852180992983}
2023-01-05 05:49:48,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:48,256 INFO:     Epoch: 10
2023-01-05 05:49:50,467 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35688648745417595, 'Total loss': 0.35688648745417595} | train loss {'Reaction outcome loss': 0.36225787297276113, 'Total loss': 0.36225787297276113}
2023-01-05 05:49:50,467 INFO:     Found new best model at epoch 10
2023-01-05 05:49:50,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:50,469 INFO:     Epoch: 11
2023-01-05 05:49:52,676 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36960459053516387, 'Total loss': 0.36960459053516387} | train loss {'Reaction outcome loss': 0.3480760457605893, 'Total loss': 0.3480760457605893}
2023-01-05 05:49:52,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:52,676 INFO:     Epoch: 12
2023-01-05 05:49:54,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3955378532409668, 'Total loss': 0.3955378532409668} | train loss {'Reaction outcome loss': 0.337944434082816, 'Total loss': 0.337944434082816}
2023-01-05 05:49:54,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:54,895 INFO:     Epoch: 13
2023-01-05 05:49:57,058 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36066295156876244, 'Total loss': 0.36066295156876244} | train loss {'Reaction outcome loss': 0.333000209306219, 'Total loss': 0.333000209306219}
2023-01-05 05:49:57,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:57,058 INFO:     Epoch: 14
2023-01-05 05:49:59,273 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.36458806743224464, 'Total loss': 0.36458806743224464} | train loss {'Reaction outcome loss': 0.3231663253034613, 'Total loss': 0.3231663253034613}
2023-01-05 05:49:59,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:49:59,274 INFO:     Epoch: 15
2023-01-05 05:50:01,505 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3587199216087659, 'Total loss': 0.3587199216087659} | train loss {'Reaction outcome loss': 0.31575018423179857, 'Total loss': 0.31575018423179857}
2023-01-05 05:50:01,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:01,506 INFO:     Epoch: 16
2023-01-05 05:50:03,714 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3691176603237788, 'Total loss': 0.3691176603237788} | train loss {'Reaction outcome loss': 0.30543587928658483, 'Total loss': 0.30543587928658483}
2023-01-05 05:50:03,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:03,714 INFO:     Epoch: 17
2023-01-05 05:50:05,962 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3695815791686376, 'Total loss': 0.3695815791686376} | train loss {'Reaction outcome loss': 0.29856432808006383, 'Total loss': 0.29856432808006383}
2023-01-05 05:50:05,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:05,962 INFO:     Epoch: 18
2023-01-05 05:50:08,200 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3628710150718689, 'Total loss': 0.3628710150718689} | train loss {'Reaction outcome loss': 0.28978758727327486, 'Total loss': 0.28978758727327486}
2023-01-05 05:50:08,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:08,200 INFO:     Epoch: 19
2023-01-05 05:50:10,426 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3848369672894478, 'Total loss': 0.3848369672894478} | train loss {'Reaction outcome loss': 0.2878537583697546, 'Total loss': 0.2878537583697546}
2023-01-05 05:50:10,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:10,426 INFO:     Epoch: 20
2023-01-05 05:50:12,660 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37879720628261565, 'Total loss': 0.37879720628261565} | train loss {'Reaction outcome loss': 0.2822894941726734, 'Total loss': 0.2822894941726734}
2023-01-05 05:50:12,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:12,660 INFO:     Epoch: 21
2023-01-05 05:50:14,864 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36340055962403617, 'Total loss': 0.36340055962403617} | train loss {'Reaction outcome loss': 0.2705512463469127, 'Total loss': 0.2705512463469127}
2023-01-05 05:50:14,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:14,866 INFO:     Epoch: 22
2023-01-05 05:50:16,719 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40941797494888305, 'Total loss': 0.40941797494888305} | train loss {'Reaction outcome loss': 0.26808469322582235, 'Total loss': 0.26808469322582235}
2023-01-05 05:50:16,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:16,719 INFO:     Epoch: 23
2023-01-05 05:50:18,561 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3609435717264811, 'Total loss': 0.3609435717264811} | train loss {'Reaction outcome loss': 0.2644159610201072, 'Total loss': 0.2644159610201072}
2023-01-05 05:50:18,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:18,562 INFO:     Epoch: 24
2023-01-05 05:50:20,626 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38708910246690115, 'Total loss': 0.38708910246690115} | train loss {'Reaction outcome loss': 0.25825884343705713, 'Total loss': 0.25825884343705713}
2023-01-05 05:50:20,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:20,626 INFO:     Epoch: 25
2023-01-05 05:50:22,847 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4200869381427765, 'Total loss': 0.4200869381427765} | train loss {'Reaction outcome loss': 0.2570446349158058, 'Total loss': 0.2570446349158058}
2023-01-05 05:50:22,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:22,848 INFO:     Epoch: 26
2023-01-05 05:50:25,080 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40263591408729554, 'Total loss': 0.40263591408729554} | train loss {'Reaction outcome loss': 0.25132724425559555, 'Total loss': 0.25132724425559555}
2023-01-05 05:50:25,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:25,080 INFO:     Epoch: 27
2023-01-05 05:50:27,337 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3690612636506557, 'Total loss': 0.3690612636506557} | train loss {'Reaction outcome loss': 0.25137969984834485, 'Total loss': 0.25137969984834485}
2023-01-05 05:50:27,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:27,337 INFO:     Epoch: 28
2023-01-05 05:50:29,584 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36935799817244214, 'Total loss': 0.36935799817244214} | train loss {'Reaction outcome loss': 0.24546955287030373, 'Total loss': 0.24546955287030373}
2023-01-05 05:50:29,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:29,584 INFO:     Epoch: 29
2023-01-05 05:50:31,801 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41826834877332053, 'Total loss': 0.41826834877332053} | train loss {'Reaction outcome loss': 0.23975879057032157, 'Total loss': 0.23975879057032157}
2023-01-05 05:50:31,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:31,801 INFO:     Epoch: 30
2023-01-05 05:50:33,992 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43003756999969484, 'Total loss': 0.43003756999969484} | train loss {'Reaction outcome loss': 0.23832859682448457, 'Total loss': 0.23832859682448457}
2023-01-05 05:50:33,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:33,992 INFO:     Epoch: 31
2023-01-05 05:50:36,251 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42822367350260415, 'Total loss': 0.42822367350260415} | train loss {'Reaction outcome loss': 0.2310233232032549, 'Total loss': 0.2310233232032549}
2023-01-05 05:50:36,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:36,252 INFO:     Epoch: 32
2023-01-05 05:50:38,496 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3770177016655604, 'Total loss': 0.3770177016655604} | train loss {'Reaction outcome loss': 0.22973941483043436, 'Total loss': 0.22973941483043436}
2023-01-05 05:50:38,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:38,496 INFO:     Epoch: 33
2023-01-05 05:50:40,743 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43774066666762035, 'Total loss': 0.43774066666762035} | train loss {'Reaction outcome loss': 0.22450425666911575, 'Total loss': 0.22450425666911575}
2023-01-05 05:50:40,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:40,743 INFO:     Epoch: 34
2023-01-05 05:50:42,969 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40440321365992227, 'Total loss': 0.40440321365992227} | train loss {'Reaction outcome loss': 0.2264108158015677, 'Total loss': 0.2264108158015677}
2023-01-05 05:50:42,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:42,969 INFO:     Epoch: 35
2023-01-05 05:50:45,187 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4215007541080316, 'Total loss': 0.4215007541080316} | train loss {'Reaction outcome loss': 0.21702952651011437, 'Total loss': 0.21702952651011437}
2023-01-05 05:50:45,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:45,187 INFO:     Epoch: 36
2023-01-05 05:50:47,429 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39378625778481363, 'Total loss': 0.39378625778481363} | train loss {'Reaction outcome loss': 0.217239512577378, 'Total loss': 0.217239512577378}
2023-01-05 05:50:47,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:47,430 INFO:     Epoch: 37
2023-01-05 05:50:49,666 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40423342684904734, 'Total loss': 0.40423342684904734} | train loss {'Reaction outcome loss': 0.21747759081478268, 'Total loss': 0.21747759081478268}
2023-01-05 05:50:49,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:49,666 INFO:     Epoch: 38
2023-01-05 05:50:51,861 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3752870989963412, 'Total loss': 0.3752870989963412} | train loss {'Reaction outcome loss': 0.2127332620638873, 'Total loss': 0.2127332620638873}
2023-01-05 05:50:51,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:51,862 INFO:     Epoch: 39
2023-01-05 05:50:54,113 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3813291231791178, 'Total loss': 0.3813291231791178} | train loss {'Reaction outcome loss': 0.20932804939519215, 'Total loss': 0.20932804939519215}
2023-01-05 05:50:54,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:54,113 INFO:     Epoch: 40
2023-01-05 05:50:56,309 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3852370719114939, 'Total loss': 0.3852370719114939} | train loss {'Reaction outcome loss': 0.2062799846031789, 'Total loss': 0.2062799846031789}
2023-01-05 05:50:56,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:56,309 INFO:     Epoch: 41
2023-01-05 05:50:58,557 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40269051883369683, 'Total loss': 0.40269051883369683} | train loss {'Reaction outcome loss': 0.20288468935145443, 'Total loss': 0.20288468935145443}
2023-01-05 05:50:58,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:50:58,558 INFO:     Epoch: 42
2023-01-05 05:51:00,787 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43121588230133057, 'Total loss': 0.43121588230133057} | train loss {'Reaction outcome loss': 0.2038473623574495, 'Total loss': 0.2038473623574495}
2023-01-05 05:51:00,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:00,788 INFO:     Epoch: 43
2023-01-05 05:51:03,025 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42675425112247467, 'Total loss': 0.42675425112247467} | train loss {'Reaction outcome loss': 0.20122840882681062, 'Total loss': 0.20122840882681062}
2023-01-05 05:51:03,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:03,025 INFO:     Epoch: 44
2023-01-05 05:51:05,195 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3922749569018682, 'Total loss': 0.3922749569018682} | train loss {'Reaction outcome loss': 0.2020135750629805, 'Total loss': 0.2020135750629805}
2023-01-05 05:51:05,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:05,195 INFO:     Epoch: 45
2023-01-05 05:51:07,357 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3734701588749886, 'Total loss': 0.3734701588749886} | train loss {'Reaction outcome loss': 0.19445488045706905, 'Total loss': 0.19445488045706905}
2023-01-05 05:51:07,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:07,357 INFO:     Epoch: 46
2023-01-05 05:51:09,537 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3739564845338464, 'Total loss': 0.3739564845338464} | train loss {'Reaction outcome loss': 0.19544771033926864, 'Total loss': 0.19544771033926864}
2023-01-05 05:51:09,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:09,537 INFO:     Epoch: 47
2023-01-05 05:51:11,728 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40892040481170017, 'Total loss': 0.40892040481170017} | train loss {'Reaction outcome loss': 0.19568010797634774, 'Total loss': 0.19568010797634774}
2023-01-05 05:51:11,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:11,729 INFO:     Epoch: 48
2023-01-05 05:51:13,959 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3799346938729286, 'Total loss': 0.3799346938729286} | train loss {'Reaction outcome loss': 0.19509093031782065, 'Total loss': 0.19509093031782065}
2023-01-05 05:51:13,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:13,959 INFO:     Epoch: 49
2023-01-05 05:51:16,162 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4368050967653592, 'Total loss': 0.4368050967653592} | train loss {'Reaction outcome loss': 0.19342646056380658, 'Total loss': 0.19342646056380658}
2023-01-05 05:51:16,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:16,162 INFO:     Epoch: 50
2023-01-05 05:51:18,362 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3773938941458861, 'Total loss': 0.3773938941458861} | train loss {'Reaction outcome loss': 0.19011028878377043, 'Total loss': 0.19011028878377043}
2023-01-05 05:51:18,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:18,362 INFO:     Epoch: 51
2023-01-05 05:51:20,543 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4221236377954483, 'Total loss': 0.4221236377954483} | train loss {'Reaction outcome loss': 0.18686405920193314, 'Total loss': 0.18686405920193314}
2023-01-05 05:51:20,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:20,543 INFO:     Epoch: 52
2023-01-05 05:51:22,793 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39988050796091557, 'Total loss': 0.39988050796091557} | train loss {'Reaction outcome loss': 0.1846239118668426, 'Total loss': 0.1846239118668426}
2023-01-05 05:51:22,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:22,795 INFO:     Epoch: 53
2023-01-05 05:51:25,041 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3765609418352445, 'Total loss': 0.3765609418352445} | train loss {'Reaction outcome loss': 0.18695437023759823, 'Total loss': 0.18695437023759823}
2023-01-05 05:51:25,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:25,042 INFO:     Epoch: 54
2023-01-05 05:51:27,288 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4409109801054001, 'Total loss': 0.4409109801054001} | train loss {'Reaction outcome loss': 0.1830100506867155, 'Total loss': 0.1830100506867155}
2023-01-05 05:51:27,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:27,288 INFO:     Epoch: 55
2023-01-05 05:51:29,513 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4219332734743754, 'Total loss': 0.4219332734743754} | train loss {'Reaction outcome loss': 0.18480736921744154, 'Total loss': 0.18480736921744154}
2023-01-05 05:51:29,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:29,514 INFO:     Epoch: 56
2023-01-05 05:51:31,723 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42169753909111024, 'Total loss': 0.42169753909111024} | train loss {'Reaction outcome loss': 0.17683436675856365, 'Total loss': 0.17683436675856365}
2023-01-05 05:51:31,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:31,724 INFO:     Epoch: 57
2023-01-05 05:51:33,965 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3961488720883305, 'Total loss': 0.3961488720883305} | train loss {'Reaction outcome loss': 0.175614834037984, 'Total loss': 0.175614834037984}
2023-01-05 05:51:33,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:33,965 INFO:     Epoch: 58
2023-01-05 05:51:36,190 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41343993147214253, 'Total loss': 0.41343993147214253} | train loss {'Reaction outcome loss': 0.1787972849384775, 'Total loss': 0.1787972849384775}
2023-01-05 05:51:36,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:36,190 INFO:     Epoch: 59
2023-01-05 05:51:38,425 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4383787264426549, 'Total loss': 0.4383787264426549} | train loss {'Reaction outcome loss': 0.1778641478966138, 'Total loss': 0.1778641478966138}
2023-01-05 05:51:38,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:38,425 INFO:     Epoch: 60
2023-01-05 05:51:40,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40936246862014136, 'Total loss': 0.40936246862014136} | train loss {'Reaction outcome loss': 0.17731269408787198, 'Total loss': 0.17731269408787198}
2023-01-05 05:51:40,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:40,662 INFO:     Epoch: 61
2023-01-05 05:51:42,924 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4145352323849996, 'Total loss': 0.4145352323849996} | train loss {'Reaction outcome loss': 0.1809802144951431, 'Total loss': 0.1809802144951431}
2023-01-05 05:51:42,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:42,925 INFO:     Epoch: 62
2023-01-05 05:51:45,165 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4631870766480764, 'Total loss': 0.4631870766480764} | train loss {'Reaction outcome loss': 0.16661881085663924, 'Total loss': 0.16661881085663924}
2023-01-05 05:51:45,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:45,165 INFO:     Epoch: 63
2023-01-05 05:51:47,459 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41203976472218834, 'Total loss': 0.41203976472218834} | train loss {'Reaction outcome loss': 0.17041086974962721, 'Total loss': 0.17041086974962721}
2023-01-05 05:51:47,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:47,460 INFO:     Epoch: 64
2023-01-05 05:51:49,721 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4093650688727697, 'Total loss': 0.4093650688727697} | train loss {'Reaction outcome loss': 0.1702001487004581, 'Total loss': 0.1702001487004581}
2023-01-05 05:51:49,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:49,722 INFO:     Epoch: 65
2023-01-05 05:51:51,989 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4476238032182058, 'Total loss': 0.4476238032182058} | train loss {'Reaction outcome loss': 0.17109978155875613, 'Total loss': 0.17109978155875613}
2023-01-05 05:51:51,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:51,991 INFO:     Epoch: 66
2023-01-05 05:51:54,209 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4058939774831136, 'Total loss': 0.4058939774831136} | train loss {'Reaction outcome loss': 0.16978034273484152, 'Total loss': 0.16978034273484152}
2023-01-05 05:51:54,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:54,210 INFO:     Epoch: 67
2023-01-05 05:51:56,424 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37459101974964143, 'Total loss': 0.37459101974964143} | train loss {'Reaction outcome loss': 0.1700518752321106, 'Total loss': 0.1700518752321106}
2023-01-05 05:51:56,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:56,425 INFO:     Epoch: 68
2023-01-05 05:51:58,638 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.407634071012338, 'Total loss': 0.407634071012338} | train loss {'Reaction outcome loss': 0.16992723380088312, 'Total loss': 0.16992723380088312}
2023-01-05 05:51:58,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:51:58,639 INFO:     Epoch: 69
2023-01-05 05:52:00,867 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4237339980434626, 'Total loss': 0.4237339980434626} | train loss {'Reaction outcome loss': 0.16924634452125684, 'Total loss': 0.16924634452125684}
2023-01-05 05:52:00,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:00,867 INFO:     Epoch: 70
2023-01-05 05:52:03,095 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42880880236625674, 'Total loss': 0.42880880236625674} | train loss {'Reaction outcome loss': 0.16774634772231217, 'Total loss': 0.16774634772231217}
2023-01-05 05:52:03,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:03,095 INFO:     Epoch: 71
2023-01-05 05:52:05,313 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4280148426691691, 'Total loss': 0.4280148426691691} | train loss {'Reaction outcome loss': 0.164769212873412, 'Total loss': 0.164769212873412}
2023-01-05 05:52:05,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:05,314 INFO:     Epoch: 72
2023-01-05 05:52:07,482 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3923224821686745, 'Total loss': 0.3923224821686745} | train loss {'Reaction outcome loss': 0.16455340537077634, 'Total loss': 0.16455340537077634}
2023-01-05 05:52:07,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:07,482 INFO:     Epoch: 73
2023-01-05 05:52:09,668 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.387765833378459, 'Total loss': 0.387765833378459} | train loss {'Reaction outcome loss': 0.1641762355004001, 'Total loss': 0.1641762355004001}
2023-01-05 05:52:09,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:09,668 INFO:     Epoch: 74
2023-01-05 05:52:11,873 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4029352093115449, 'Total loss': 0.4029352093115449} | train loss {'Reaction outcome loss': 0.1656857199856936, 'Total loss': 0.1656857199856936}
2023-01-05 05:52:11,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:11,874 INFO:     Epoch: 75
2023-01-05 05:52:14,104 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40417607525984445, 'Total loss': 0.40417607525984445} | train loss {'Reaction outcome loss': 0.16260098886583343, 'Total loss': 0.16260098886583343}
2023-01-05 05:52:14,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:14,104 INFO:     Epoch: 76
2023-01-05 05:52:16,334 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4531717399756114, 'Total loss': 0.4531717399756114} | train loss {'Reaction outcome loss': 0.1620154110388315, 'Total loss': 0.1620154110388315}
2023-01-05 05:52:16,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:16,334 INFO:     Epoch: 77
2023-01-05 05:52:18,543 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4117736926069483, 'Total loss': 0.4117736926069483} | train loss {'Reaction outcome loss': 0.16226432730900844, 'Total loss': 0.16226432730900844}
2023-01-05 05:52:18,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:18,544 INFO:     Epoch: 78
2023-01-05 05:52:20,756 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4198691844396914, 'Total loss': 0.4198691844396914} | train loss {'Reaction outcome loss': 0.16499711805782744, 'Total loss': 0.16499711805782744}
2023-01-05 05:52:20,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:20,756 INFO:     Epoch: 79
2023-01-05 05:52:22,976 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45849902282158533, 'Total loss': 0.45849902282158533} | train loss {'Reaction outcome loss': 0.1609977374714198, 'Total loss': 0.1609977374714198}
2023-01-05 05:52:22,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:22,976 INFO:     Epoch: 80
2023-01-05 05:52:25,238 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4551331172386805, 'Total loss': 0.4551331172386805} | train loss {'Reaction outcome loss': 0.16265927318731027, 'Total loss': 0.16265927318731027}
2023-01-05 05:52:25,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:25,238 INFO:     Epoch: 81
2023-01-05 05:52:27,478 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43368949194749196, 'Total loss': 0.43368949194749196} | train loss {'Reaction outcome loss': 0.16142631664432283, 'Total loss': 0.16142631664432283}
2023-01-05 05:52:27,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:27,479 INFO:     Epoch: 82
2023-01-05 05:52:29,712 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48324005007743837, 'Total loss': 0.48324005007743837} | train loss {'Reaction outcome loss': 0.16128764124380982, 'Total loss': 0.16128764124380982}
2023-01-05 05:52:29,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:29,713 INFO:     Epoch: 83
2023-01-05 05:52:31,956 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45250132692356904, 'Total loss': 0.45250132692356904} | train loss {'Reaction outcome loss': 0.16007402669930507, 'Total loss': 0.16007402669930507}
2023-01-05 05:52:31,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:31,957 INFO:     Epoch: 84
2023-01-05 05:52:34,217 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42346471453395984, 'Total loss': 0.42346471453395984} | train loss {'Reaction outcome loss': 0.156874596841489, 'Total loss': 0.156874596841489}
2023-01-05 05:52:34,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:34,218 INFO:     Epoch: 85
2023-01-05 05:52:36,477 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45887977878252667, 'Total loss': 0.45887977878252667} | train loss {'Reaction outcome loss': 0.16052526455867444, 'Total loss': 0.16052526455867444}
2023-01-05 05:52:36,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:36,477 INFO:     Epoch: 86
2023-01-05 05:52:38,717 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4557898604931931, 'Total loss': 0.4557898604931931} | train loss {'Reaction outcome loss': 0.16053569587153757, 'Total loss': 0.16053569587153757}
2023-01-05 05:52:38,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:38,717 INFO:     Epoch: 87
2023-01-05 05:52:40,988 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45357008576393126, 'Total loss': 0.45357008576393126} | train loss {'Reaction outcome loss': 0.1528958067877005, 'Total loss': 0.1528958067877005}
2023-01-05 05:52:40,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:40,988 INFO:     Epoch: 88
2023-01-05 05:52:43,254 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4458840568860372, 'Total loss': 0.4458840568860372} | train loss {'Reaction outcome loss': 0.154486838009937, 'Total loss': 0.154486838009937}
2023-01-05 05:52:43,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:43,254 INFO:     Epoch: 89
2023-01-05 05:52:45,516 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4367603600025177, 'Total loss': 0.4367603600025177} | train loss {'Reaction outcome loss': 0.1557357814489448, 'Total loss': 0.1557357814489448}
2023-01-05 05:52:45,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:45,516 INFO:     Epoch: 90
2023-01-05 05:52:47,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46008907854557035, 'Total loss': 0.46008907854557035} | train loss {'Reaction outcome loss': 0.15283957078221264, 'Total loss': 0.15283957078221264}
2023-01-05 05:52:47,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:47,766 INFO:     Epoch: 91
2023-01-05 05:52:50,008 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44072129130363463, 'Total loss': 0.44072129130363463} | train loss {'Reaction outcome loss': 0.1540257694359484, 'Total loss': 0.1540257694359484}
2023-01-05 05:52:50,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:50,008 INFO:     Epoch: 92
2023-01-05 05:52:52,242 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42696982572476067, 'Total loss': 0.42696982572476067} | train loss {'Reaction outcome loss': 0.14965464342110602, 'Total loss': 0.14965464342110602}
2023-01-05 05:52:52,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:52,243 INFO:     Epoch: 93
2023-01-05 05:52:54,486 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42437055744230745, 'Total loss': 0.42437055744230745} | train loss {'Reaction outcome loss': 0.15250265866009402, 'Total loss': 0.15250265866009402}
2023-01-05 05:52:54,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:54,486 INFO:     Epoch: 94
2023-01-05 05:52:56,561 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38952485028033457, 'Total loss': 0.38952485028033457} | train loss {'Reaction outcome loss': 0.15015003314100867, 'Total loss': 0.15015003314100867}
2023-01-05 05:52:56,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:56,561 INFO:     Epoch: 95
2023-01-05 05:52:58,805 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45338298579057057, 'Total loss': 0.45338298579057057} | train loss {'Reaction outcome loss': 0.15460212673387075, 'Total loss': 0.15460212673387075}
2023-01-05 05:52:58,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:52:58,805 INFO:     Epoch: 96
2023-01-05 05:53:01,053 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.455011311173439, 'Total loss': 0.455011311173439} | train loss {'Reaction outcome loss': 0.1515929500239032, 'Total loss': 0.1515929500239032}
2023-01-05 05:53:01,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:01,053 INFO:     Epoch: 97
2023-01-05 05:53:03,220 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44114410181840263, 'Total loss': 0.44114410181840263} | train loss {'Reaction outcome loss': 0.15304155633320887, 'Total loss': 0.15304155633320887}
2023-01-05 05:53:03,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:03,221 INFO:     Epoch: 98
2023-01-05 05:53:05,439 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4580402771631877, 'Total loss': 0.4580402771631877} | train loss {'Reaction outcome loss': 0.1508892116109356, 'Total loss': 0.1508892116109356}
2023-01-05 05:53:05,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:05,440 INFO:     Epoch: 99
2023-01-05 05:53:07,688 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4410434663295746, 'Total loss': 0.4410434663295746} | train loss {'Reaction outcome loss': 0.14713574823926845, 'Total loss': 0.14713574823926845}
2023-01-05 05:53:07,688 INFO:     Best model found after epoch 11 of 100.
2023-01-05 05:53:07,688 INFO:   Done with stage: TRAINING
2023-01-05 05:53:07,688 INFO:   Starting stage: EVALUATION
2023-01-05 05:53:07,843 INFO:   Done with stage: EVALUATION
2023-01-05 05:53:07,843 INFO:   Leaving out SEQ value Fold_1
2023-01-05 05:53:07,856 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 05:53:07,856 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:53:08,518 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:53:08,518 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:53:08,592 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:53:08,592 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:53:08,592 INFO:     No hyperparam tuning for this model
2023-01-05 05:53:08,592 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:53:08,592 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:53:08,593 INFO:     None feature selector for col prot
2023-01-05 05:53:08,593 INFO:     None feature selector for col prot
2023-01-05 05:53:08,593 INFO:     None feature selector for col prot
2023-01-05 05:53:08,593 INFO:     None feature selector for col chem
2023-01-05 05:53:08,594 INFO:     None feature selector for col chem
2023-01-05 05:53:08,594 INFO:     None feature selector for col chem
2023-01-05 05:53:08,594 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:53:08,594 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:53:08,595 INFO:     Number of params in model 72931
2023-01-05 05:53:08,599 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:53:08,599 INFO:   Starting stage: TRAINING
2023-01-05 05:53:08,659 INFO:     Val loss before train {'Reaction outcome loss': 0.9530385851860046, 'Total loss': 0.9530385851860046}
2023-01-05 05:53:08,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:08,660 INFO:     Epoch: 0
2023-01-05 05:53:10,918 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7149357775847117, 'Total loss': 0.7149357775847117} | train loss {'Reaction outcome loss': 0.9621562967008918, 'Total loss': 0.9621562967008918}
2023-01-05 05:53:10,919 INFO:     Found new best model at epoch 0
2023-01-05 05:53:10,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:10,921 INFO:     Epoch: 1
2023-01-05 05:53:13,166 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46705143054326376, 'Total loss': 0.46705143054326376} | train loss {'Reaction outcome loss': 0.6874327456211522, 'Total loss': 0.6874327456211522}
2023-01-05 05:53:13,166 INFO:     Found new best model at epoch 1
2023-01-05 05:53:13,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:13,167 INFO:     Epoch: 2
2023-01-05 05:53:15,316 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44462861319382985, 'Total loss': 0.44462861319382985} | train loss {'Reaction outcome loss': 0.5561681285391759, 'Total loss': 0.5561681285391759}
2023-01-05 05:53:15,317 INFO:     Found new best model at epoch 2
2023-01-05 05:53:15,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:15,318 INFO:     Epoch: 3
2023-01-05 05:53:17,562 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3653557668129603, 'Total loss': 0.3653557668129603} | train loss {'Reaction outcome loss': 0.5147939311870693, 'Total loss': 0.5147939311870693}
2023-01-05 05:53:17,562 INFO:     Found new best model at epoch 3
2023-01-05 05:53:17,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:17,563 INFO:     Epoch: 4
2023-01-05 05:53:19,803 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3682228118181229, 'Total loss': 0.3682228118181229} | train loss {'Reaction outcome loss': 0.4823872401331463, 'Total loss': 0.4823872401331463}
2023-01-05 05:53:19,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:19,804 INFO:     Epoch: 5
2023-01-05 05:53:22,053 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.36213463842868804, 'Total loss': 0.36213463842868804} | train loss {'Reaction outcome loss': 0.45563267209451563, 'Total loss': 0.45563267209451563}
2023-01-05 05:53:22,053 INFO:     Found new best model at epoch 5
2023-01-05 05:53:22,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:22,054 INFO:     Epoch: 6
2023-01-05 05:53:24,289 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3484454015890757, 'Total loss': 0.3484454015890757} | train loss {'Reaction outcome loss': 0.43528714727093704, 'Total loss': 0.43528714727093704}
2023-01-05 05:53:24,290 INFO:     Found new best model at epoch 6
2023-01-05 05:53:24,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:24,291 INFO:     Epoch: 7
2023-01-05 05:53:26,549 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3526559213797251, 'Total loss': 0.3526559213797251} | train loss {'Reaction outcome loss': 0.41372135539885857, 'Total loss': 0.41372135539885857}
2023-01-05 05:53:26,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:26,549 INFO:     Epoch: 8
2023-01-05 05:53:28,840 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3316544403632482, 'Total loss': 0.3316544403632482} | train loss {'Reaction outcome loss': 0.403372612693449, 'Total loss': 0.403372612693449}
2023-01-05 05:53:28,840 INFO:     Found new best model at epoch 8
2023-01-05 05:53:28,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:28,842 INFO:     Epoch: 9
2023-01-05 05:53:31,120 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3271505326032639, 'Total loss': 0.3271505326032639} | train loss {'Reaction outcome loss': 0.3877542505625391, 'Total loss': 0.3877542505625391}
2023-01-05 05:53:31,120 INFO:     Found new best model at epoch 9
2023-01-05 05:53:31,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:31,121 INFO:     Epoch: 10
2023-01-05 05:53:33,417 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3108574857314428, 'Total loss': 0.3108574857314428} | train loss {'Reaction outcome loss': 0.3753490837386055, 'Total loss': 0.3753490837386055}
2023-01-05 05:53:33,417 INFO:     Found new best model at epoch 10
2023-01-05 05:53:33,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:33,419 INFO:     Epoch: 11
2023-01-05 05:53:35,715 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.314573584869504, 'Total loss': 0.314573584869504} | train loss {'Reaction outcome loss': 0.3659621846393077, 'Total loss': 0.3659621846393077}
2023-01-05 05:53:35,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:35,715 INFO:     Epoch: 12
2023-01-05 05:53:38,014 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3096563418706258, 'Total loss': 0.3096563418706258} | train loss {'Reaction outcome loss': 0.35518773188338665, 'Total loss': 0.35518773188338665}
2023-01-05 05:53:38,014 INFO:     Found new best model at epoch 12
2023-01-05 05:53:38,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:38,015 INFO:     Epoch: 13
2023-01-05 05:53:40,273 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.31528299252192177, 'Total loss': 0.31528299252192177} | train loss {'Reaction outcome loss': 0.3438188281916354, 'Total loss': 0.3438188281916354}
2023-01-05 05:53:40,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:40,274 INFO:     Epoch: 14
2023-01-05 05:53:42,517 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3256103261063496, 'Total loss': 0.3256103261063496} | train loss {'Reaction outcome loss': 0.33619561726159425, 'Total loss': 0.33619561726159425}
2023-01-05 05:53:42,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:42,517 INFO:     Epoch: 15
2023-01-05 05:53:44,776 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.32348616818586984, 'Total loss': 0.32348616818586984} | train loss {'Reaction outcome loss': 0.3256930116645611, 'Total loss': 0.3256930116645611}
2023-01-05 05:53:44,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:44,776 INFO:     Epoch: 16
2023-01-05 05:53:47,032 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.33190899044275285, 'Total loss': 0.33190899044275285} | train loss {'Reaction outcome loss': 0.31944985472916687, 'Total loss': 0.31944985472916687}
2023-01-05 05:53:47,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:47,033 INFO:     Epoch: 17
2023-01-05 05:53:49,222 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3213215490182241, 'Total loss': 0.3213215490182241} | train loss {'Reaction outcome loss': 0.31729065365817427, 'Total loss': 0.31729065365817427}
2023-01-05 05:53:49,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:49,222 INFO:     Epoch: 18
2023-01-05 05:53:51,461 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3195058524608612, 'Total loss': 0.3195058524608612} | train loss {'Reaction outcome loss': 0.3070281658076892, 'Total loss': 0.3070281658076892}
2023-01-05 05:53:51,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:51,461 INFO:     Epoch: 19
2023-01-05 05:53:53,687 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3177986736098925, 'Total loss': 0.3177986736098925} | train loss {'Reaction outcome loss': 0.3103085881112701, 'Total loss': 0.3103085881112701}
2023-01-05 05:53:53,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:53,688 INFO:     Epoch: 20
2023-01-05 05:53:55,931 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3266905148824056, 'Total loss': 0.3266905148824056} | train loss {'Reaction outcome loss': 0.29921921630845455, 'Total loss': 0.29921921630845455}
2023-01-05 05:53:55,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:55,931 INFO:     Epoch: 21
2023-01-05 05:53:58,089 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.2995398888985316, 'Total loss': 0.2995398888985316} | train loss {'Reaction outcome loss': 0.29014886830029263, 'Total loss': 0.29014886830029263}
2023-01-05 05:53:58,089 INFO:     Found new best model at epoch 21
2023-01-05 05:53:58,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:53:58,091 INFO:     Epoch: 22
2023-01-05 05:54:00,280 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3394078950087229, 'Total loss': 0.3394078950087229} | train loss {'Reaction outcome loss': 0.28873509564267025, 'Total loss': 0.28873509564267025}
2023-01-05 05:54:00,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:00,281 INFO:     Epoch: 23
2023-01-05 05:54:02,533 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3249461834629377, 'Total loss': 0.3249461834629377} | train loss {'Reaction outcome loss': 0.28439006242003756, 'Total loss': 0.28439006242003756}
2023-01-05 05:54:02,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:02,533 INFO:     Epoch: 24
2023-01-05 05:54:04,774 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.32558794766664506, 'Total loss': 0.32558794766664506} | train loss {'Reaction outcome loss': 0.277768160298086, 'Total loss': 0.277768160298086}
2023-01-05 05:54:04,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:04,774 INFO:     Epoch: 25
2023-01-05 05:54:07,047 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3205718626578649, 'Total loss': 0.3205718626578649} | train loss {'Reaction outcome loss': 0.2769291152375458, 'Total loss': 0.2769291152375458}
2023-01-05 05:54:07,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:07,047 INFO:     Epoch: 26
2023-01-05 05:54:09,328 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.32691858559846876, 'Total loss': 0.32691858559846876} | train loss {'Reaction outcome loss': 0.2686420861278137, 'Total loss': 0.2686420861278137}
2023-01-05 05:54:09,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:09,328 INFO:     Epoch: 27
2023-01-05 05:54:11,573 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3395979007085164, 'Total loss': 0.3395979007085164} | train loss {'Reaction outcome loss': 0.2615312388724219, 'Total loss': 0.2615312388724219}
2023-01-05 05:54:11,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:11,573 INFO:     Epoch: 28
2023-01-05 05:54:13,836 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3400949994723002, 'Total loss': 0.3400949994723002} | train loss {'Reaction outcome loss': 0.25986018616461404, 'Total loss': 0.25986018616461404}
2023-01-05 05:54:13,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:13,836 INFO:     Epoch: 29
2023-01-05 05:54:16,083 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35888541241486865, 'Total loss': 0.35888541241486865} | train loss {'Reaction outcome loss': 0.25582808946823554, 'Total loss': 0.25582808946823554}
2023-01-05 05:54:16,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:16,085 INFO:     Epoch: 30
2023-01-05 05:54:18,332 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3218332419792811, 'Total loss': 0.3218332419792811} | train loss {'Reaction outcome loss': 0.2531645220439256, 'Total loss': 0.2531645220439256}
2023-01-05 05:54:18,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:18,332 INFO:     Epoch: 31
2023-01-05 05:54:20,586 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3236025790373484, 'Total loss': 0.3236025790373484} | train loss {'Reaction outcome loss': 0.24666068927949145, 'Total loss': 0.24666068927949145}
2023-01-05 05:54:20,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:20,586 INFO:     Epoch: 32
2023-01-05 05:54:22,811 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3147888739903768, 'Total loss': 0.3147888739903768} | train loss {'Reaction outcome loss': 0.24765492646689832, 'Total loss': 0.24765492646689832}
2023-01-05 05:54:22,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:22,812 INFO:     Epoch: 33
2023-01-05 05:54:25,057 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3187156766653061, 'Total loss': 0.3187156766653061} | train loss {'Reaction outcome loss': 0.23945794389821098, 'Total loss': 0.23945794389821098}
2023-01-05 05:54:25,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:25,058 INFO:     Epoch: 34
2023-01-05 05:54:27,309 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3284477353096008, 'Total loss': 0.3284477353096008} | train loss {'Reaction outcome loss': 0.23871459394530223, 'Total loss': 0.23871459394530223}
2023-01-05 05:54:27,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:27,309 INFO:     Epoch: 35
2023-01-05 05:54:29,543 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.29773392379283903, 'Total loss': 0.29773392379283903} | train loss {'Reaction outcome loss': 0.2374758182406208, 'Total loss': 0.2374758182406208}
2023-01-05 05:54:29,543 INFO:     Found new best model at epoch 35
2023-01-05 05:54:29,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:29,544 INFO:     Epoch: 36
2023-01-05 05:54:31,732 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3084796334306399, 'Total loss': 0.3084796334306399} | train loss {'Reaction outcome loss': 0.23158703043540246, 'Total loss': 0.23158703043540246}
2023-01-05 05:54:31,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:31,732 INFO:     Epoch: 37
2023-01-05 05:54:33,959 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3068587849537531, 'Total loss': 0.3068587849537531} | train loss {'Reaction outcome loss': 0.23000478270008182, 'Total loss': 0.23000478270008182}
2023-01-05 05:54:33,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:33,960 INFO:     Epoch: 38
2023-01-05 05:54:36,195 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3295920650164286, 'Total loss': 0.3295920650164286} | train loss {'Reaction outcome loss': 0.22757625973436738, 'Total loss': 0.22757625973436738}
2023-01-05 05:54:36,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:36,196 INFO:     Epoch: 39
2023-01-05 05:54:38,434 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.31293657918771106, 'Total loss': 0.31293657918771106} | train loss {'Reaction outcome loss': 0.22818001428700602, 'Total loss': 0.22818001428700602}
2023-01-05 05:54:38,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:38,434 INFO:     Epoch: 40
2023-01-05 05:54:40,633 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3095899442831675, 'Total loss': 0.3095899442831675} | train loss {'Reaction outcome loss': 0.22532846331324455, 'Total loss': 0.22532846331324455}
2023-01-05 05:54:40,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:40,633 INFO:     Epoch: 41
2023-01-05 05:54:42,864 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3014116197824478, 'Total loss': 0.3014116197824478} | train loss {'Reaction outcome loss': 0.22747622357586222, 'Total loss': 0.22747622357586222}
2023-01-05 05:54:42,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:42,865 INFO:     Epoch: 42
2023-01-05 05:54:45,087 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.31408772856617967, 'Total loss': 0.31408772856617967} | train loss {'Reaction outcome loss': 0.2186009124342869, 'Total loss': 0.2186009124342869}
2023-01-05 05:54:45,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:45,087 INFO:     Epoch: 43
2023-01-05 05:54:47,309 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.32076093355814617, 'Total loss': 0.32076093355814617} | train loss {'Reaction outcome loss': 0.21962606245108005, 'Total loss': 0.21962606245108005}
2023-01-05 05:54:47,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:47,310 INFO:     Epoch: 44
2023-01-05 05:54:49,560 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.313346762334307, 'Total loss': 0.313346762334307} | train loss {'Reaction outcome loss': 0.2188223434381024, 'Total loss': 0.2188223434381024}
2023-01-05 05:54:49,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:49,561 INFO:     Epoch: 45
2023-01-05 05:54:51,762 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.32694320678710936, 'Total loss': 0.32694320678710936} | train loss {'Reaction outcome loss': 0.21659477446976044, 'Total loss': 0.21659477446976044}
2023-01-05 05:54:51,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:51,763 INFO:     Epoch: 46
2023-01-05 05:54:54,000 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.2974513789017995, 'Total loss': 0.2974513789017995} | train loss {'Reaction outcome loss': 0.215412286477313, 'Total loss': 0.215412286477313}
2023-01-05 05:54:54,000 INFO:     Found new best model at epoch 46
2023-01-05 05:54:54,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:54,001 INFO:     Epoch: 47
2023-01-05 05:54:56,206 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.30802796011169753, 'Total loss': 0.30802796011169753} | train loss {'Reaction outcome loss': 0.210555247501912, 'Total loss': 0.210555247501912}
2023-01-05 05:54:56,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:56,206 INFO:     Epoch: 48
2023-01-05 05:54:58,424 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.29856238812208175, 'Total loss': 0.29856238812208175} | train loss {'Reaction outcome loss': 0.20965682182896095, 'Total loss': 0.20965682182896095}
2023-01-05 05:54:58,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:54:58,425 INFO:     Epoch: 49
2023-01-05 05:55:00,599 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32034748792648315, 'Total loss': 0.32034748792648315} | train loss {'Reaction outcome loss': 0.20792759311840917, 'Total loss': 0.20792759311840917}
2023-01-05 05:55:00,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:00,600 INFO:     Epoch: 50
2023-01-05 05:55:02,815 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3171974708636602, 'Total loss': 0.3171974708636602} | train loss {'Reaction outcome loss': 0.20499831362607052, 'Total loss': 0.20499831362607052}
2023-01-05 05:55:02,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:02,815 INFO:     Epoch: 51
2023-01-05 05:55:05,043 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.31995926747719444, 'Total loss': 0.31995926747719444} | train loss {'Reaction outcome loss': 0.2051960153804317, 'Total loss': 0.2051960153804317}
2023-01-05 05:55:05,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:05,044 INFO:     Epoch: 52
2023-01-05 05:55:07,317 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36187222972512245, 'Total loss': 0.36187222972512245} | train loss {'Reaction outcome loss': 0.20951375279602777, 'Total loss': 0.20951375279602777}
2023-01-05 05:55:07,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:07,317 INFO:     Epoch: 53
2023-01-05 05:55:09,594 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3140705078840256, 'Total loss': 0.3140705078840256} | train loss {'Reaction outcome loss': 0.19590524703529358, 'Total loss': 0.19590524703529358}
2023-01-05 05:55:09,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:09,594 INFO:     Epoch: 54
2023-01-05 05:55:11,830 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.32872476081053414, 'Total loss': 0.32872476081053414} | train loss {'Reaction outcome loss': 0.19879864876151737, 'Total loss': 0.19879864876151737}
2023-01-05 05:55:11,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:11,831 INFO:     Epoch: 55
2023-01-05 05:55:14,067 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35458658436934154, 'Total loss': 0.35458658436934154} | train loss {'Reaction outcome loss': 0.20436574078171793, 'Total loss': 0.20436574078171793}
2023-01-05 05:55:14,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:14,067 INFO:     Epoch: 56
2023-01-05 05:55:16,302 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3214699774980545, 'Total loss': 0.3214699774980545} | train loss {'Reaction outcome loss': 0.19806873579475567, 'Total loss': 0.19806873579475567}
2023-01-05 05:55:16,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:16,302 INFO:     Epoch: 57
2023-01-05 05:55:18,568 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3437202927423641, 'Total loss': 0.3437202927423641} | train loss {'Reaction outcome loss': 0.1982819126089559, 'Total loss': 0.1982819126089559}
2023-01-05 05:55:18,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:18,568 INFO:     Epoch: 58
2023-01-05 05:55:20,833 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.31544760974744956, 'Total loss': 0.31544760974744956} | train loss {'Reaction outcome loss': 0.19439889870951102, 'Total loss': 0.19439889870951102}
2023-01-05 05:55:20,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:20,834 INFO:     Epoch: 59
2023-01-05 05:55:23,078 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35665517499049504, 'Total loss': 0.35665517499049504} | train loss {'Reaction outcome loss': 0.19448767483479132, 'Total loss': 0.19448767483479132}
2023-01-05 05:55:23,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:23,079 INFO:     Epoch: 60
2023-01-05 05:55:25,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.31451087991396587, 'Total loss': 0.31451087991396587} | train loss {'Reaction outcome loss': 0.19274541168697995, 'Total loss': 0.19274541168697995}
2023-01-05 05:55:25,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:25,373 INFO:     Epoch: 61
2023-01-05 05:55:27,632 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.32861735969781875, 'Total loss': 0.32861735969781875} | train loss {'Reaction outcome loss': 0.18671737585801387, 'Total loss': 0.18671737585801387}
2023-01-05 05:55:27,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:27,633 INFO:     Epoch: 62
2023-01-05 05:55:29,911 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.32056861743330956, 'Total loss': 0.32056861743330956} | train loss {'Reaction outcome loss': 0.19498344206924204, 'Total loss': 0.19498344206924204}
2023-01-05 05:55:29,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:29,911 INFO:     Epoch: 63
2023-01-05 05:55:32,174 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.31161069038013617, 'Total loss': 0.31161069038013617} | train loss {'Reaction outcome loss': 0.19099703327460338, 'Total loss': 0.19099703327460338}
2023-01-05 05:55:32,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:32,174 INFO:     Epoch: 64
2023-01-05 05:55:34,416 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3574448997775714, 'Total loss': 0.3574448997775714} | train loss {'Reaction outcome loss': 0.19174402244525016, 'Total loss': 0.19174402244525016}
2023-01-05 05:55:34,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:34,417 INFO:     Epoch: 65
2023-01-05 05:55:36,661 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33932153234879175, 'Total loss': 0.33932153234879175} | train loss {'Reaction outcome loss': 0.18557694654938947, 'Total loss': 0.18557694654938947}
2023-01-05 05:55:36,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:36,661 INFO:     Epoch: 66
2023-01-05 05:55:38,907 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33062927722930907, 'Total loss': 0.33062927722930907} | train loss {'Reaction outcome loss': 0.18821790395644458, 'Total loss': 0.18821790395644458}
2023-01-05 05:55:38,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:38,907 INFO:     Epoch: 67
2023-01-05 05:55:41,142 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3249613945682844, 'Total loss': 0.3249613945682844} | train loss {'Reaction outcome loss': 0.18394960523379056, 'Total loss': 0.18394960523379056}
2023-01-05 05:55:41,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:41,142 INFO:     Epoch: 68
2023-01-05 05:55:43,414 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3269919566810131, 'Total loss': 0.3269919566810131} | train loss {'Reaction outcome loss': 0.18472045011492105, 'Total loss': 0.18472045011492105}
2023-01-05 05:55:43,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:43,414 INFO:     Epoch: 69
2023-01-05 05:55:45,662 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.33195123821496964, 'Total loss': 0.33195123821496964} | train loss {'Reaction outcome loss': 0.1808630711854483, 'Total loss': 0.1808630711854483}
2023-01-05 05:55:45,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:45,662 INFO:     Epoch: 70
2023-01-05 05:55:47,918 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.327292641500632, 'Total loss': 0.327292641500632} | train loss {'Reaction outcome loss': 0.18362083168781912, 'Total loss': 0.18362083168781912}
2023-01-05 05:55:47,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:47,919 INFO:     Epoch: 71
2023-01-05 05:55:50,131 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32403190930684406, 'Total loss': 0.32403190930684406} | train loss {'Reaction outcome loss': 0.18263392322390837, 'Total loss': 0.18263392322390837}
2023-01-05 05:55:50,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:50,131 INFO:     Epoch: 72
2023-01-05 05:55:52,374 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3237148102062444, 'Total loss': 0.3237148102062444} | train loss {'Reaction outcome loss': 0.17920657280954894, 'Total loss': 0.17920657280954894}
2023-01-05 05:55:52,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:52,374 INFO:     Epoch: 73
2023-01-05 05:55:54,645 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37008170535167056, 'Total loss': 0.37008170535167056} | train loss {'Reaction outcome loss': 0.17892346153865113, 'Total loss': 0.17892346153865113}
2023-01-05 05:55:54,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:54,645 INFO:     Epoch: 74
2023-01-05 05:55:56,866 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3642242456475894, 'Total loss': 0.3642242456475894} | train loss {'Reaction outcome loss': 0.17706935622314685, 'Total loss': 0.17706935622314685}
2023-01-05 05:55:56,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:56,866 INFO:     Epoch: 75
2023-01-05 05:55:59,130 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.31688894480466845, 'Total loss': 0.31688894480466845} | train loss {'Reaction outcome loss': 0.17872756615580215, 'Total loss': 0.17872756615580215}
2023-01-05 05:55:59,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:55:59,130 INFO:     Epoch: 76
2023-01-05 05:56:01,405 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3552400439977646, 'Total loss': 0.3552400439977646} | train loss {'Reaction outcome loss': 0.17954513458806995, 'Total loss': 0.17954513458806995}
2023-01-05 05:56:01,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:01,405 INFO:     Epoch: 77
2023-01-05 05:56:03,663 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3476002792517344, 'Total loss': 0.3476002792517344} | train loss {'Reaction outcome loss': 0.17604860242959247, 'Total loss': 0.17604860242959247}
2023-01-05 05:56:03,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:03,664 INFO:     Epoch: 78
2023-01-05 05:56:05,936 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3408047373096148, 'Total loss': 0.3408047373096148} | train loss {'Reaction outcome loss': 0.17365158168449454, 'Total loss': 0.17365158168449454}
2023-01-05 05:56:05,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:05,936 INFO:     Epoch: 79
2023-01-05 05:56:08,191 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38519602914651235, 'Total loss': 0.38519602914651235} | train loss {'Reaction outcome loss': 0.17346167190503464, 'Total loss': 0.17346167190503464}
2023-01-05 05:56:08,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:08,191 INFO:     Epoch: 80
2023-01-05 05:56:10,471 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33670969295005004, 'Total loss': 0.33670969295005004} | train loss {'Reaction outcome loss': 0.1768631491602745, 'Total loss': 0.1768631491602745}
2023-01-05 05:56:10,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:10,471 INFO:     Epoch: 81
2023-01-05 05:56:12,756 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3718716907004515, 'Total loss': 0.3718716907004515} | train loss {'Reaction outcome loss': 0.17343362002042087, 'Total loss': 0.17343362002042087}
2023-01-05 05:56:12,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:12,756 INFO:     Epoch: 82
2023-01-05 05:56:15,011 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36652886737138035, 'Total loss': 0.36652886737138035} | train loss {'Reaction outcome loss': 0.17407076750426506, 'Total loss': 0.17407076750426506}
2023-01-05 05:56:15,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:15,011 INFO:     Epoch: 83
2023-01-05 05:56:17,286 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3351083636283875, 'Total loss': 0.3351083636283875} | train loss {'Reaction outcome loss': 0.17537865148055076, 'Total loss': 0.17537865148055076}
2023-01-05 05:56:17,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:17,287 INFO:     Epoch: 84
2023-01-05 05:56:19,531 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36252519687016804, 'Total loss': 0.36252519687016804} | train loss {'Reaction outcome loss': 0.179882825360749, 'Total loss': 0.179882825360749}
2023-01-05 05:56:19,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:19,531 INFO:     Epoch: 85
2023-01-05 05:56:21,789 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3752697656551997, 'Total loss': 0.3752697656551997} | train loss {'Reaction outcome loss': 0.17255729198945266, 'Total loss': 0.17255729198945266}
2023-01-05 05:56:21,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:21,790 INFO:     Epoch: 86
2023-01-05 05:56:24,037 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3374349571764469, 'Total loss': 0.3374349571764469} | train loss {'Reaction outcome loss': 0.1688987054814496, 'Total loss': 0.1688987054814496}
2023-01-05 05:56:24,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:24,038 INFO:     Epoch: 87
2023-01-05 05:56:26,280 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33097755710283916, 'Total loss': 0.33097755710283916} | train loss {'Reaction outcome loss': 0.16864273367775945, 'Total loss': 0.16864273367775945}
2023-01-05 05:56:26,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:26,280 INFO:     Epoch: 88
2023-01-05 05:56:28,553 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.33873107433319094, 'Total loss': 0.33873107433319094} | train loss {'Reaction outcome loss': 0.1668044533928938, 'Total loss': 0.1668044533928938}
2023-01-05 05:56:28,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:28,553 INFO:     Epoch: 89
2023-01-05 05:56:30,815 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36766632000605265, 'Total loss': 0.36766632000605265} | train loss {'Reaction outcome loss': 0.17170401122489007, 'Total loss': 0.17170401122489007}
2023-01-05 05:56:30,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:30,815 INFO:     Epoch: 90
2023-01-05 05:56:33,036 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3533943608403206, 'Total loss': 0.3533943608403206} | train loss {'Reaction outcome loss': 0.16600387307720083, 'Total loss': 0.16600387307720083}
2023-01-05 05:56:33,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:33,036 INFO:     Epoch: 91
2023-01-05 05:56:35,286 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38142033517360685, 'Total loss': 0.38142033517360685} | train loss {'Reaction outcome loss': 0.16652460695400725, 'Total loss': 0.16652460695400725}
2023-01-05 05:56:35,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:35,287 INFO:     Epoch: 92
2023-01-05 05:56:37,527 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34226464728514355, 'Total loss': 0.34226464728514355} | train loss {'Reaction outcome loss': 0.1664713539716781, 'Total loss': 0.1664713539716781}
2023-01-05 05:56:37,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:37,527 INFO:     Epoch: 93
2023-01-05 05:56:39,761 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3775108953317006, 'Total loss': 0.3775108953317006} | train loss {'Reaction outcome loss': 0.16555309510470306, 'Total loss': 0.16555309510470306}
2023-01-05 05:56:39,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:39,762 INFO:     Epoch: 94
2023-01-05 05:56:42,011 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3551953320701917, 'Total loss': 0.3551953320701917} | train loss {'Reaction outcome loss': 0.16738621223663544, 'Total loss': 0.16738621223663544}
2023-01-05 05:56:42,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:42,012 INFO:     Epoch: 95
2023-01-05 05:56:44,292 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35541247874498366, 'Total loss': 0.35541247874498366} | train loss {'Reaction outcome loss': 0.1641943447298649, 'Total loss': 0.1641943447298649}
2023-01-05 05:56:44,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:44,292 INFO:     Epoch: 96
2023-01-05 05:56:46,557 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3679163336753845, 'Total loss': 0.3679163336753845} | train loss {'Reaction outcome loss': 0.16454682669119677, 'Total loss': 0.16454682669119677}
2023-01-05 05:56:46,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:46,558 INFO:     Epoch: 97
2023-01-05 05:56:48,818 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3659579967459043, 'Total loss': 0.3659579967459043} | train loss {'Reaction outcome loss': 0.16621024208143353, 'Total loss': 0.16621024208143353}
2023-01-05 05:56:48,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:48,819 INFO:     Epoch: 98
2023-01-05 05:56:51,013 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37147114674250287, 'Total loss': 0.37147114674250287} | train loss {'Reaction outcome loss': 0.1673486239003208, 'Total loss': 0.1673486239003208}
2023-01-05 05:56:51,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:51,013 INFO:     Epoch: 99
2023-01-05 05:56:53,269 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3620546579360962, 'Total loss': 0.3620546579360962} | train loss {'Reaction outcome loss': 0.16935427324085014, 'Total loss': 0.16935427324085014}
2023-01-05 05:56:53,269 INFO:     Best model found after epoch 47 of 100.
2023-01-05 05:56:53,269 INFO:   Done with stage: TRAINING
2023-01-05 05:56:53,269 INFO:   Starting stage: EVALUATION
2023-01-05 05:56:53,411 INFO:   Done with stage: EVALUATION
2023-01-05 05:56:53,411 INFO:   Leaving out SEQ value Fold_2
2023-01-05 05:56:53,424 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 05:56:53,424 INFO:   Starting stage: FEATURE SCALING
2023-01-05 05:56:54,072 INFO:   Done with stage: FEATURE SCALING
2023-01-05 05:56:54,073 INFO:   Starting stage: SCALING TARGETS
2023-01-05 05:56:54,146 INFO:   Done with stage: SCALING TARGETS
2023-01-05 05:56:54,146 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:56:54,146 INFO:     No hyperparam tuning for this model
2023-01-05 05:56:54,146 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 05:56:54,146 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 05:56:54,147 INFO:     None feature selector for col prot
2023-01-05 05:56:54,147 INFO:     None feature selector for col prot
2023-01-05 05:56:54,147 INFO:     None feature selector for col prot
2023-01-05 05:56:54,147 INFO:     None feature selector for col chem
2023-01-05 05:56:54,147 INFO:     None feature selector for col chem
2023-01-05 05:56:54,148 INFO:     None feature selector for col chem
2023-01-05 05:56:54,148 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 05:56:54,148 INFO:   Starting stage: BUILD MODEL
2023-01-05 05:56:54,149 INFO:     Number of params in model 72931
2023-01-05 05:56:54,152 INFO:   Done with stage: BUILD MODEL
2023-01-05 05:56:54,152 INFO:   Starting stage: TRAINING
2023-01-05 05:56:54,208 INFO:     Val loss before train {'Reaction outcome loss': 1.0831775665283203, 'Total loss': 1.0831775665283203}
2023-01-05 05:56:54,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:54,209 INFO:     Epoch: 0
2023-01-05 05:56:56,461 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7372125804424285, 'Total loss': 0.7372125804424285} | train loss {'Reaction outcome loss': 0.929842913389792, 'Total loss': 0.929842913389792}
2023-01-05 05:56:56,461 INFO:     Found new best model at epoch 0
2023-01-05 05:56:56,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:56,463 INFO:     Epoch: 1
2023-01-05 05:56:58,731 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5147320071856181, 'Total loss': 0.5147320071856181} | train loss {'Reaction outcome loss': 0.6220291904781176, 'Total loss': 0.6220291904781176}
2023-01-05 05:56:58,732 INFO:     Found new best model at epoch 1
2023-01-05 05:56:58,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:56:58,733 INFO:     Epoch: 2
2023-01-05 05:57:00,968 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4946011245250702, 'Total loss': 0.4946011245250702} | train loss {'Reaction outcome loss': 0.5253812155375878, 'Total loss': 0.5253812155375878}
2023-01-05 05:57:00,968 INFO:     Found new best model at epoch 2
2023-01-05 05:57:00,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:00,970 INFO:     Epoch: 3
2023-01-05 05:57:03,249 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47338518500328064, 'Total loss': 0.47338518500328064} | train loss {'Reaction outcome loss': 0.48320478026458213, 'Total loss': 0.48320478026458213}
2023-01-05 05:57:03,249 INFO:     Found new best model at epoch 3
2023-01-05 05:57:03,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:03,251 INFO:     Epoch: 4
2023-01-05 05:57:05,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47167638937632245, 'Total loss': 0.47167638937632245} | train loss {'Reaction outcome loss': 0.45877771867790085, 'Total loss': 0.45877771867790085}
2023-01-05 05:57:05,324 INFO:     Found new best model at epoch 4
2023-01-05 05:57:05,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:05,325 INFO:     Epoch: 5
2023-01-05 05:57:07,540 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4449355572462082, 'Total loss': 0.4449355572462082} | train loss {'Reaction outcome loss': 0.43807326879629027, 'Total loss': 0.43807326879629027}
2023-01-05 05:57:07,540 INFO:     Found new best model at epoch 5
2023-01-05 05:57:07,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:07,542 INFO:     Epoch: 6
2023-01-05 05:57:09,809 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46563965976238253, 'Total loss': 0.46563965976238253} | train loss {'Reaction outcome loss': 0.41185864617611934, 'Total loss': 0.41185864617611934}
2023-01-05 05:57:09,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:09,810 INFO:     Epoch: 7
2023-01-05 05:57:12,068 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43565685947736105, 'Total loss': 0.43565685947736105} | train loss {'Reaction outcome loss': 0.39816297786445287, 'Total loss': 0.39816297786445287}
2023-01-05 05:57:12,068 INFO:     Found new best model at epoch 7
2023-01-05 05:57:12,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:12,069 INFO:     Epoch: 8
2023-01-05 05:57:14,332 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4599914997816086, 'Total loss': 0.4599914997816086} | train loss {'Reaction outcome loss': 0.38442061075171374, 'Total loss': 0.38442061075171374}
2023-01-05 05:57:14,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:14,332 INFO:     Epoch: 9
2023-01-05 05:57:16,567 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4410863945881526, 'Total loss': 0.4410863945881526} | train loss {'Reaction outcome loss': 0.3734622908949319, 'Total loss': 0.3734622908949319}
2023-01-05 05:57:16,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:16,568 INFO:     Epoch: 10
2023-01-05 05:57:18,810 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4663524220387141, 'Total loss': 0.4663524220387141} | train loss {'Reaction outcome loss': 0.3665994337610544, 'Total loss': 0.3665994337610544}
2023-01-05 05:57:18,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:18,810 INFO:     Epoch: 11
2023-01-05 05:57:21,029 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45803283949693047, 'Total loss': 0.45803283949693047} | train loss {'Reaction outcome loss': 0.35133049501261365, 'Total loss': 0.35133049501261365}
2023-01-05 05:57:21,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:21,029 INFO:     Epoch: 12
2023-01-05 05:57:23,297 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43883820275465646, 'Total loss': 0.43883820275465646} | train loss {'Reaction outcome loss': 0.3497765838325469, 'Total loss': 0.3497765838325469}
2023-01-05 05:57:23,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:23,298 INFO:     Epoch: 13
2023-01-05 05:57:25,541 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4323221266269684, 'Total loss': 0.4323221266269684} | train loss {'Reaction outcome loss': 0.34038882603382936, 'Total loss': 0.34038882603382936}
2023-01-05 05:57:25,541 INFO:     Found new best model at epoch 13
2023-01-05 05:57:25,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:25,542 INFO:     Epoch: 14
2023-01-05 05:57:27,814 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42560843427975975, 'Total loss': 0.42560843427975975} | train loss {'Reaction outcome loss': 0.3428098508089349, 'Total loss': 0.3428098508089349}
2023-01-05 05:57:27,814 INFO:     Found new best model at epoch 14
2023-01-05 05:57:27,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:27,815 INFO:     Epoch: 15
2023-01-05 05:57:30,055 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45387256642182666, 'Total loss': 0.45387256642182666} | train loss {'Reaction outcome loss': 0.33840031656639086, 'Total loss': 0.33840031656639086}
2023-01-05 05:57:30,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:30,056 INFO:     Epoch: 16
2023-01-05 05:57:32,276 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4377991785605749, 'Total loss': 0.4377991785605749} | train loss {'Reaction outcome loss': 0.3262817272241565, 'Total loss': 0.3262817272241565}
2023-01-05 05:57:32,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:32,277 INFO:     Epoch: 17
2023-01-05 05:57:34,553 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43552340467770895, 'Total loss': 0.43552340467770895} | train loss {'Reaction outcome loss': 0.34353754878638015, 'Total loss': 0.34353754878638015}
2023-01-05 05:57:34,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:34,553 INFO:     Epoch: 18
2023-01-05 05:57:36,815 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4246874421834946, 'Total loss': 0.4246874421834946} | train loss {'Reaction outcome loss': 0.32280301626989333, 'Total loss': 0.32280301626989333}
2023-01-05 05:57:36,816 INFO:     Found new best model at epoch 18
2023-01-05 05:57:36,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:36,817 INFO:     Epoch: 19
2023-01-05 05:57:39,101 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44862293601036074, 'Total loss': 0.44862293601036074} | train loss {'Reaction outcome loss': 0.3090382386403887, 'Total loss': 0.3090382386403887}
2023-01-05 05:57:39,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:39,102 INFO:     Epoch: 20
2023-01-05 05:57:41,295 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41533132692178093, 'Total loss': 0.41533132692178093} | train loss {'Reaction outcome loss': 0.30297402463991707, 'Total loss': 0.30297402463991707}
2023-01-05 05:57:41,295 INFO:     Found new best model at epoch 20
2023-01-05 05:57:41,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:41,296 INFO:     Epoch: 21
2023-01-05 05:57:43,569 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4748400628566742, 'Total loss': 0.4748400628566742} | train loss {'Reaction outcome loss': 0.30021874460162246, 'Total loss': 0.30021874460162246}
2023-01-05 05:57:43,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:43,569 INFO:     Epoch: 22
2023-01-05 05:57:45,809 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43924836417039237, 'Total loss': 0.43924836417039237} | train loss {'Reaction outcome loss': 0.2975235290271129, 'Total loss': 0.2975235290271129}
2023-01-05 05:57:45,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:45,810 INFO:     Epoch: 23
2023-01-05 05:57:48,115 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45096572041511535, 'Total loss': 0.45096572041511535} | train loss {'Reaction outcome loss': 0.2991811135257392, 'Total loss': 0.2991811135257392}
2023-01-05 05:57:48,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:48,115 INFO:     Epoch: 24
2023-01-05 05:57:50,463 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44013885259628294, 'Total loss': 0.44013885259628294} | train loss {'Reaction outcome loss': 0.3110821720050729, 'Total loss': 0.3110821720050729}
2023-01-05 05:57:50,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:50,463 INFO:     Epoch: 25
2023-01-05 05:57:52,731 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41701756219069164, 'Total loss': 0.41701756219069164} | train loss {'Reaction outcome loss': 0.284985834621087, 'Total loss': 0.284985834621087}
2023-01-05 05:57:52,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:52,732 INFO:     Epoch: 26
2023-01-05 05:57:54,978 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44000327289104463, 'Total loss': 0.44000327289104463} | train loss {'Reaction outcome loss': 0.28336991785445076, 'Total loss': 0.28336991785445076}
2023-01-05 05:57:54,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:54,978 INFO:     Epoch: 27
2023-01-05 05:57:57,245 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4187264621257782, 'Total loss': 0.4187264621257782} | train loss {'Reaction outcome loss': 0.27821137831863557, 'Total loss': 0.27821137831863557}
2023-01-05 05:57:57,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:57,245 INFO:     Epoch: 28
2023-01-05 05:57:59,502 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42659844557444254, 'Total loss': 0.42659844557444254} | train loss {'Reaction outcome loss': 0.2749136386901491, 'Total loss': 0.2749136386901491}
2023-01-05 05:57:59,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:57:59,502 INFO:     Epoch: 29
2023-01-05 05:58:01,772 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41055042048295337, 'Total loss': 0.41055042048295337} | train loss {'Reaction outcome loss': 0.2693635546201604, 'Total loss': 0.2693635546201604}
2023-01-05 05:58:01,772 INFO:     Found new best model at epoch 29
2023-01-05 05:58:01,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:01,774 INFO:     Epoch: 30
2023-01-05 05:58:04,046 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43080964783827463, 'Total loss': 0.43080964783827463} | train loss {'Reaction outcome loss': 0.2649487027783703, 'Total loss': 0.2649487027783703}
2023-01-05 05:58:04,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:04,047 INFO:     Epoch: 31
2023-01-05 05:58:06,275 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4330465316772461, 'Total loss': 0.4330465316772461} | train loss {'Reaction outcome loss': 0.26187655092824413, 'Total loss': 0.26187655092824413}
2023-01-05 05:58:06,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:06,276 INFO:     Epoch: 32
2023-01-05 05:58:08,535 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44109211017688116, 'Total loss': 0.44109211017688116} | train loss {'Reaction outcome loss': 0.2606948445470113, 'Total loss': 0.2606948445470113}
2023-01-05 05:58:08,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:08,535 INFO:     Epoch: 33
2023-01-05 05:58:10,775 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5056466390689214, 'Total loss': 0.5056466390689214} | train loss {'Reaction outcome loss': 0.25770063953857153, 'Total loss': 0.25770063953857153}
2023-01-05 05:58:10,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:10,775 INFO:     Epoch: 34
2023-01-05 05:58:13,029 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44057972530523937, 'Total loss': 0.44057972530523937} | train loss {'Reaction outcome loss': 0.25405139748624567, 'Total loss': 0.25405139748624567}
2023-01-05 05:58:13,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:13,029 INFO:     Epoch: 35
2023-01-05 05:58:15,308 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4164028416077296, 'Total loss': 0.4164028416077296} | train loss {'Reaction outcome loss': 0.250194399897684, 'Total loss': 0.250194399897684}
2023-01-05 05:58:15,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:15,308 INFO:     Epoch: 36
2023-01-05 05:58:17,524 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4564097623030345, 'Total loss': 0.4564097623030345} | train loss {'Reaction outcome loss': 0.2488872592060732, 'Total loss': 0.2488872592060732}
2023-01-05 05:58:17,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:17,524 INFO:     Epoch: 37
2023-01-05 05:58:19,804 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43880579868952435, 'Total loss': 0.43880579868952435} | train loss {'Reaction outcome loss': 0.2458708886043641, 'Total loss': 0.2458708886043641}
2023-01-05 05:58:19,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:19,804 INFO:     Epoch: 38
2023-01-05 05:58:22,039 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4640340636173884, 'Total loss': 0.4640340636173884} | train loss {'Reaction outcome loss': 0.24324046073741265, 'Total loss': 0.24324046073741265}
2023-01-05 05:58:22,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:22,040 INFO:     Epoch: 39
2023-01-05 05:58:24,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46786365409692127, 'Total loss': 0.46786365409692127} | train loss {'Reaction outcome loss': 0.23807841305118188, 'Total loss': 0.23807841305118188}
2023-01-05 05:58:24,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:24,306 INFO:     Epoch: 40
2023-01-05 05:58:26,575 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4600471297899882, 'Total loss': 0.4600471297899882} | train loss {'Reaction outcome loss': 0.236548339389602, 'Total loss': 0.236548339389602}
2023-01-05 05:58:26,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:26,576 INFO:     Epoch: 41
2023-01-05 05:58:28,843 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4947738985220591, 'Total loss': 0.4947738985220591} | train loss {'Reaction outcome loss': 0.23750969212826178, 'Total loss': 0.23750969212826178}
2023-01-05 05:58:28,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:28,844 INFO:     Epoch: 42
2023-01-05 05:58:31,141 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4857178608576457, 'Total loss': 0.4857178608576457} | train loss {'Reaction outcome loss': 0.2401501516578719, 'Total loss': 0.2401501516578719}
2023-01-05 05:58:31,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:31,142 INFO:     Epoch: 43
2023-01-05 05:58:33,445 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46278795699278513, 'Total loss': 0.46278795699278513} | train loss {'Reaction outcome loss': 0.2552593152470671, 'Total loss': 0.2552593152470671}
2023-01-05 05:58:33,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:33,445 INFO:     Epoch: 44
2023-01-05 05:58:35,726 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4882432023684184, 'Total loss': 0.4882432023684184} | train loss {'Reaction outcome loss': 0.23074600555654784, 'Total loss': 0.23074600555654784}
2023-01-05 05:58:35,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:35,726 INFO:     Epoch: 45
2023-01-05 05:58:37,974 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47634115219116213, 'Total loss': 0.47634115219116213} | train loss {'Reaction outcome loss': 0.2240208565912115, 'Total loss': 0.2240208565912115}
2023-01-05 05:58:37,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:37,975 INFO:     Epoch: 46
2023-01-05 05:58:40,249 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5088861008485158, 'Total loss': 0.5088861008485158} | train loss {'Reaction outcome loss': 0.22774941652280994, 'Total loss': 0.22774941652280994}
2023-01-05 05:58:40,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:40,249 INFO:     Epoch: 47
2023-01-05 05:58:42,532 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.492889279127121, 'Total loss': 0.492889279127121} | train loss {'Reaction outcome loss': 0.22348279622214698, 'Total loss': 0.22348279622214698}
2023-01-05 05:58:42,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:42,532 INFO:     Epoch: 48
2023-01-05 05:58:44,815 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48961939215660094, 'Total loss': 0.48961939215660094} | train loss {'Reaction outcome loss': 0.22280774774908027, 'Total loss': 0.22280774774908027}
2023-01-05 05:58:44,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:44,815 INFO:     Epoch: 49
2023-01-05 05:58:47,102 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4741126241783301, 'Total loss': 0.4741126241783301} | train loss {'Reaction outcome loss': 0.21897591855815626, 'Total loss': 0.21897591855815626}
2023-01-05 05:58:47,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:47,102 INFO:     Epoch: 50
2023-01-05 05:58:49,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5086271151900291, 'Total loss': 0.5086271151900291} | train loss {'Reaction outcome loss': 0.21874809527155553, 'Total loss': 0.21874809527155553}
2023-01-05 05:58:49,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:49,414 INFO:     Epoch: 51
2023-01-05 05:58:51,671 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48273919969797136, 'Total loss': 0.48273919969797136} | train loss {'Reaction outcome loss': 0.21439338181559267, 'Total loss': 0.21439338181559267}
2023-01-05 05:58:51,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:51,672 INFO:     Epoch: 52
2023-01-05 05:58:53,952 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48226662377516427, 'Total loss': 0.48226662377516427} | train loss {'Reaction outcome loss': 0.2176725713713719, 'Total loss': 0.2176725713713719}
2023-01-05 05:58:53,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:53,952 INFO:     Epoch: 53
2023-01-05 05:58:56,233 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5190750161806742, 'Total loss': 0.5190750161806742} | train loss {'Reaction outcome loss': 0.2115365017034228, 'Total loss': 0.2115365017034228}
2023-01-05 05:58:56,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:56,233 INFO:     Epoch: 54
2023-01-05 05:58:58,494 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49172664682070416, 'Total loss': 0.49172664682070416} | train loss {'Reaction outcome loss': 0.2106504201928265, 'Total loss': 0.2106504201928265}
2023-01-05 05:58:58,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:58:58,496 INFO:     Epoch: 55
2023-01-05 05:59:00,780 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4636504451433818, 'Total loss': 0.4636504451433818} | train loss {'Reaction outcome loss': 0.2099501242836055, 'Total loss': 0.2099501242836055}
2023-01-05 05:59:00,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:00,781 INFO:     Epoch: 56
2023-01-05 05:59:03,055 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47048180202643075, 'Total loss': 0.47048180202643075} | train loss {'Reaction outcome loss': 0.21175656627590375, 'Total loss': 0.21175656627590375}
2023-01-05 05:59:03,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:03,055 INFO:     Epoch: 57
2023-01-05 05:59:05,333 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4888274023930232, 'Total loss': 0.4888274023930232} | train loss {'Reaction outcome loss': 0.21016484025544807, 'Total loss': 0.21016484025544807}
2023-01-05 05:59:05,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:05,334 INFO:     Epoch: 58
2023-01-05 05:59:07,593 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49686724742253624, 'Total loss': 0.49686724742253624} | train loss {'Reaction outcome loss': 0.20610778687346348, 'Total loss': 0.20610778687346348}
2023-01-05 05:59:07,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:07,594 INFO:     Epoch: 59
2023-01-05 05:59:09,861 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4892187476158142, 'Total loss': 0.4892187476158142} | train loss {'Reaction outcome loss': 0.21023415921060234, 'Total loss': 0.21023415921060234}
2023-01-05 05:59:09,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:09,861 INFO:     Epoch: 60
2023-01-05 05:59:12,152 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48797458708286284, 'Total loss': 0.48797458708286284} | train loss {'Reaction outcome loss': 0.20731440934363543, 'Total loss': 0.20731440934363543}
2023-01-05 05:59:12,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:12,152 INFO:     Epoch: 61
2023-01-05 05:59:14,409 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4683074374993642, 'Total loss': 0.4683074374993642} | train loss {'Reaction outcome loss': 0.19996252992659455, 'Total loss': 0.19996252992659455}
2023-01-05 05:59:14,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:14,409 INFO:     Epoch: 62
2023-01-05 05:59:16,669 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4859184823930264, 'Total loss': 0.4859184823930264} | train loss {'Reaction outcome loss': 0.1961278653116492, 'Total loss': 0.1961278653116492}
2023-01-05 05:59:16,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:16,669 INFO:     Epoch: 63
2023-01-05 05:59:18,949 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4812840849161148, 'Total loss': 0.4812840849161148} | train loss {'Reaction outcome loss': 0.200032068130974, 'Total loss': 0.200032068130974}
2023-01-05 05:59:18,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:18,950 INFO:     Epoch: 64
2023-01-05 05:59:21,221 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5065662160515785, 'Total loss': 0.5065662160515785} | train loss {'Reaction outcome loss': 0.20074578614389463, 'Total loss': 0.20074578614389463}
2023-01-05 05:59:21,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:21,222 INFO:     Epoch: 65
2023-01-05 05:59:23,503 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4961756646633148, 'Total loss': 0.4961756646633148} | train loss {'Reaction outcome loss': 0.20087797909070723, 'Total loss': 0.20087797909070723}
2023-01-05 05:59:23,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:23,503 INFO:     Epoch: 66
2023-01-05 05:59:25,774 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4639621545871099, 'Total loss': 0.4639621545871099} | train loss {'Reaction outcome loss': 0.20076206131362478, 'Total loss': 0.20076206131362478}
2023-01-05 05:59:25,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:25,774 INFO:     Epoch: 67
2023-01-05 05:59:28,001 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.503182053565979, 'Total loss': 0.503182053565979} | train loss {'Reaction outcome loss': 0.19538954683652054, 'Total loss': 0.19538954683652054}
2023-01-05 05:59:28,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:28,002 INFO:     Epoch: 68
2023-01-05 05:59:30,222 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46061500211556755, 'Total loss': 0.46061500211556755} | train loss {'Reaction outcome loss': 0.19660057920652, 'Total loss': 0.19660057920652}
2023-01-05 05:59:30,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:30,223 INFO:     Epoch: 69
2023-01-05 05:59:32,448 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48694910009702047, 'Total loss': 0.48694910009702047} | train loss {'Reaction outcome loss': 0.19111770472448805, 'Total loss': 0.19111770472448805}
2023-01-05 05:59:32,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:32,448 INFO:     Epoch: 70
2023-01-05 05:59:34,681 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5104623819390933, 'Total loss': 0.5104623819390933} | train loss {'Reaction outcome loss': 0.19444840991417406, 'Total loss': 0.19444840991417406}
2023-01-05 05:59:34,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:34,682 INFO:     Epoch: 71
2023-01-05 05:59:36,963 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5540620307127635, 'Total loss': 0.5540620307127635} | train loss {'Reaction outcome loss': 0.19241660266284863, 'Total loss': 0.19241660266284863}
2023-01-05 05:59:36,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:36,963 INFO:     Epoch: 72
2023-01-05 05:59:39,221 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5090474029382069, 'Total loss': 0.5090474029382069} | train loss {'Reaction outcome loss': 0.19089188760655315, 'Total loss': 0.19089188760655315}
2023-01-05 05:59:39,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:39,221 INFO:     Epoch: 73
2023-01-05 05:59:41,515 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4937316914399465, 'Total loss': 0.4937316914399465} | train loss {'Reaction outcome loss': 0.1889879650249065, 'Total loss': 0.1889879650249065}
2023-01-05 05:59:41,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:41,516 INFO:     Epoch: 74
2023-01-05 05:59:43,806 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.472883794705073, 'Total loss': 0.472883794705073} | train loss {'Reaction outcome loss': 0.187949371581941, 'Total loss': 0.187949371581941}
2023-01-05 05:59:43,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:43,806 INFO:     Epoch: 75
2023-01-05 05:59:46,074 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5111345469951629, 'Total loss': 0.5111345469951629} | train loss {'Reaction outcome loss': 0.1880829169910968, 'Total loss': 0.1880829169910968}
2023-01-05 05:59:46,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:46,075 INFO:     Epoch: 76
2023-01-05 05:59:48,360 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4644940880437692, 'Total loss': 0.4644940880437692} | train loss {'Reaction outcome loss': 0.18936631902065332, 'Total loss': 0.18936631902065332}
2023-01-05 05:59:48,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:48,361 INFO:     Epoch: 77
2023-01-05 05:59:50,622 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4645384361346563, 'Total loss': 0.4645384361346563} | train loss {'Reaction outcome loss': 0.18631771397591312, 'Total loss': 0.18631771397591312}
2023-01-05 05:59:50,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:50,622 INFO:     Epoch: 78
2023-01-05 05:59:52,832 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46966195702552793, 'Total loss': 0.46966195702552793} | train loss {'Reaction outcome loss': 0.18815945733444348, 'Total loss': 0.18815945733444348}
2023-01-05 05:59:52,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:52,832 INFO:     Epoch: 79
2023-01-05 05:59:55,110 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48785094221433006, 'Total loss': 0.48785094221433006} | train loss {'Reaction outcome loss': 0.18956266178250097, 'Total loss': 0.18956266178250097}
2023-01-05 05:59:55,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:55,111 INFO:     Epoch: 80
2023-01-05 05:59:57,354 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5163210690021515, 'Total loss': 0.5163210690021515} | train loss {'Reaction outcome loss': 0.18350671102508795, 'Total loss': 0.18350671102508795}
2023-01-05 05:59:57,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:57,354 INFO:     Epoch: 81
2023-01-05 05:59:59,669 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5313493251800537, 'Total loss': 0.5313493251800537} | train loss {'Reaction outcome loss': 0.18534319363053606, 'Total loss': 0.18534319363053606}
2023-01-05 05:59:59,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 05:59:59,669 INFO:     Epoch: 82
2023-01-05 06:00:01,960 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46871578494707744, 'Total loss': 0.46871578494707744} | train loss {'Reaction outcome loss': 0.18652804627123734, 'Total loss': 0.18652804627123734}
2023-01-05 06:00:01,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:01,961 INFO:     Epoch: 83
2023-01-05 06:00:04,240 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49688416520754497, 'Total loss': 0.49688416520754497} | train loss {'Reaction outcome loss': 0.18560198834714264, 'Total loss': 0.18560198834714264}
2023-01-05 06:00:04,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:04,242 INFO:     Epoch: 84
2023-01-05 06:00:06,526 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4684784951309363, 'Total loss': 0.4684784951309363} | train loss {'Reaction outcome loss': 0.17885537643282526, 'Total loss': 0.17885537643282526}
2023-01-05 06:00:06,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:06,526 INFO:     Epoch: 85
2023-01-05 06:00:08,797 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5125538776318233, 'Total loss': 0.5125538776318233} | train loss {'Reaction outcome loss': 0.17930728043733246, 'Total loss': 0.17930728043733246}
2023-01-05 06:00:08,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:08,797 INFO:     Epoch: 86
2023-01-05 06:00:11,084 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47942394415537515, 'Total loss': 0.47942394415537515} | train loss {'Reaction outcome loss': 0.17897282744735898, 'Total loss': 0.17897282744735898}
2023-01-05 06:00:11,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:11,085 INFO:     Epoch: 87
2023-01-05 06:00:13,355 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4864065028727055, 'Total loss': 0.4864065028727055} | train loss {'Reaction outcome loss': 0.1774899218707224, 'Total loss': 0.1774899218707224}
2023-01-05 06:00:13,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:13,355 INFO:     Epoch: 88
2023-01-05 06:00:15,562 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49323920806248983, 'Total loss': 0.49323920806248983} | train loss {'Reaction outcome loss': 0.18075162859927135, 'Total loss': 0.18075162859927135}
2023-01-05 06:00:15,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:15,563 INFO:     Epoch: 89
2023-01-05 06:00:17,838 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47071998119354247, 'Total loss': 0.47071998119354247} | train loss {'Reaction outcome loss': 0.18135470478143584, 'Total loss': 0.18135470478143584}
2023-01-05 06:00:17,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:17,838 INFO:     Epoch: 90
2023-01-05 06:00:20,105 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4945884202917417, 'Total loss': 0.4945884202917417} | train loss {'Reaction outcome loss': 0.18066774706876723, 'Total loss': 0.18066774706876723}
2023-01-05 06:00:20,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:20,105 INFO:     Epoch: 91
2023-01-05 06:00:22,379 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47175507694482804, 'Total loss': 0.47175507694482804} | train loss {'Reaction outcome loss': 0.1867365433389078, 'Total loss': 0.1867365433389078}
2023-01-05 06:00:22,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:22,380 INFO:     Epoch: 92
2023-01-05 06:00:24,596 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46181853612263996, 'Total loss': 0.46181853612263996} | train loss {'Reaction outcome loss': 0.18042225000133022, 'Total loss': 0.18042225000133022}
2023-01-05 06:00:24,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:24,597 INFO:     Epoch: 93
2023-01-05 06:00:26,875 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48654276529947915, 'Total loss': 0.48654276529947915} | train loss {'Reaction outcome loss': 0.18516034637347425, 'Total loss': 0.18516034637347425}
2023-01-05 06:00:26,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:26,875 INFO:     Epoch: 94
2023-01-05 06:00:29,145 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4956195185581843, 'Total loss': 0.4956195185581843} | train loss {'Reaction outcome loss': 0.17481269777509506, 'Total loss': 0.17481269777509506}
2023-01-05 06:00:29,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:29,146 INFO:     Epoch: 95
2023-01-05 06:00:31,435 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4891112466653188, 'Total loss': 0.4891112466653188} | train loss {'Reaction outcome loss': 0.17298758052601299, 'Total loss': 0.17298758052601299}
2023-01-05 06:00:31,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:31,436 INFO:     Epoch: 96
2023-01-05 06:00:33,703 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5058782696723938, 'Total loss': 0.5058782696723938} | train loss {'Reaction outcome loss': 0.17026234171990784, 'Total loss': 0.17026234171990784}
2023-01-05 06:00:33,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:33,703 INFO:     Epoch: 97
2023-01-05 06:00:35,976 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49675241162379585, 'Total loss': 0.49675241162379585} | train loss {'Reaction outcome loss': 0.1743116036944928, 'Total loss': 0.1743116036944928}
2023-01-05 06:00:35,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:35,976 INFO:     Epoch: 98
2023-01-05 06:00:38,266 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46354046364625295, 'Total loss': 0.46354046364625295} | train loss {'Reaction outcome loss': 0.1699583308524081, 'Total loss': 0.1699583308524081}
2023-01-05 06:00:38,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:38,267 INFO:     Epoch: 99
2023-01-05 06:00:40,544 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5248825401067734, 'Total loss': 0.5248825401067734} | train loss {'Reaction outcome loss': 0.17210243426286953, 'Total loss': 0.17210243426286953}
2023-01-05 06:00:40,545 INFO:     Best model found after epoch 30 of 100.
2023-01-05 06:00:40,546 INFO:   Done with stage: TRAINING
2023-01-05 06:00:40,546 INFO:   Starting stage: EVALUATION
2023-01-05 06:00:40,681 INFO:   Done with stage: EVALUATION
2023-01-05 06:00:40,681 INFO:   Leaving out SEQ value Fold_3
2023-01-05 06:00:40,694 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 06:00:40,694 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:00:41,356 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:00:41,356 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:00:41,430 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:00:41,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:00:41,431 INFO:     No hyperparam tuning for this model
2023-01-05 06:00:41,431 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:00:41,431 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:00:41,431 INFO:     None feature selector for col prot
2023-01-05 06:00:41,432 INFO:     None feature selector for col prot
2023-01-05 06:00:41,432 INFO:     None feature selector for col prot
2023-01-05 06:00:41,432 INFO:     None feature selector for col chem
2023-01-05 06:00:41,432 INFO:     None feature selector for col chem
2023-01-05 06:00:41,432 INFO:     None feature selector for col chem
2023-01-05 06:00:41,432 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:00:41,433 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:00:41,434 INFO:     Number of params in model 72931
2023-01-05 06:00:41,437 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:00:41,438 INFO:   Starting stage: TRAINING
2023-01-05 06:00:41,501 INFO:     Val loss before train {'Reaction outcome loss': 1.093095310529073, 'Total loss': 1.093095310529073}
2023-01-05 06:00:41,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:41,502 INFO:     Epoch: 0
2023-01-05 06:00:43,769 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9149223208427429, 'Total loss': 0.9149223208427429} | train loss {'Reaction outcome loss': 0.9807519311274308, 'Total loss': 0.9807519311274308}
2023-01-05 06:00:43,770 INFO:     Found new best model at epoch 0
2023-01-05 06:00:43,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:43,771 INFO:     Epoch: 1
2023-01-05 06:00:46,047 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6436076700687409, 'Total loss': 0.6436076700687409} | train loss {'Reaction outcome loss': 0.7015573564441064, 'Total loss': 0.7015573564441064}
2023-01-05 06:00:46,047 INFO:     Found new best model at epoch 1
2023-01-05 06:00:46,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:46,049 INFO:     Epoch: 2
2023-01-05 06:00:48,320 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5539399166901906, 'Total loss': 0.5539399166901906} | train loss {'Reaction outcome loss': 0.5612144023922366, 'Total loss': 0.5612144023922366}
2023-01-05 06:00:48,321 INFO:     Found new best model at epoch 2
2023-01-05 06:00:48,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:48,323 INFO:     Epoch: 3
2023-01-05 06:00:50,557 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5347731828689575, 'Total loss': 0.5347731828689575} | train loss {'Reaction outcome loss': 0.5146200549991234, 'Total loss': 0.5146200549991234}
2023-01-05 06:00:50,558 INFO:     Found new best model at epoch 3
2023-01-05 06:00:50,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:50,559 INFO:     Epoch: 4
2023-01-05 06:00:52,841 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5138368388017018, 'Total loss': 0.5138368388017018} | train loss {'Reaction outcome loss': 0.48024487911143166, 'Total loss': 0.48024487911143166}
2023-01-05 06:00:52,841 INFO:     Found new best model at epoch 4
2023-01-05 06:00:52,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:52,843 INFO:     Epoch: 5
2023-01-05 06:00:55,083 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5078411181767781, 'Total loss': 0.5078411181767781} | train loss {'Reaction outcome loss': 0.4579931552238438, 'Total loss': 0.4579931552238438}
2023-01-05 06:00:55,083 INFO:     Found new best model at epoch 5
2023-01-05 06:00:55,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:55,085 INFO:     Epoch: 6
2023-01-05 06:00:57,298 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49670740564664206, 'Total loss': 0.49670740564664206} | train loss {'Reaction outcome loss': 0.44005067985373264, 'Total loss': 0.44005067985373264}
2023-01-05 06:00:57,298 INFO:     Found new best model at epoch 6
2023-01-05 06:00:57,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:57,299 INFO:     Epoch: 7
2023-01-05 06:00:59,540 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4981339693069458, 'Total loss': 0.4981339693069458} | train loss {'Reaction outcome loss': 0.42542481516906316, 'Total loss': 0.42542481516906316}
2023-01-05 06:00:59,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:00:59,540 INFO:     Epoch: 8
2023-01-05 06:01:01,819 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4955534060796102, 'Total loss': 0.4955534060796102} | train loss {'Reaction outcome loss': 0.41427536550116306, 'Total loss': 0.41427536550116306}
2023-01-05 06:01:01,820 INFO:     Found new best model at epoch 8
2023-01-05 06:01:01,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:01,821 INFO:     Epoch: 9
2023-01-05 06:01:04,107 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4776872624953588, 'Total loss': 0.4776872624953588} | train loss {'Reaction outcome loss': 0.4033178986468609, 'Total loss': 0.4033178986468609}
2023-01-05 06:01:04,107 INFO:     Found new best model at epoch 9
2023-01-05 06:01:04,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:04,109 INFO:     Epoch: 10
2023-01-05 06:01:06,386 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4663234064976374, 'Total loss': 0.4663234064976374} | train loss {'Reaction outcome loss': 0.39840226436870685, 'Total loss': 0.39840226436870685}
2023-01-05 06:01:06,386 INFO:     Found new best model at epoch 10
2023-01-05 06:01:06,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:06,388 INFO:     Epoch: 11
2023-01-05 06:01:08,654 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4889660656452179, 'Total loss': 0.4889660656452179} | train loss {'Reaction outcome loss': 0.3891745911641539, 'Total loss': 0.3891745911641539}
2023-01-05 06:01:08,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:08,654 INFO:     Epoch: 12
2023-01-05 06:01:10,929 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46158796151479087, 'Total loss': 0.46158796151479087} | train loss {'Reaction outcome loss': 0.37766746438000404, 'Total loss': 0.37766746438000404}
2023-01-05 06:01:10,931 INFO:     Found new best model at epoch 12
2023-01-05 06:01:10,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:10,932 INFO:     Epoch: 13
2023-01-05 06:01:13,217 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4629808704058329, 'Total loss': 0.4629808704058329} | train loss {'Reaction outcome loss': 0.36879098863658105, 'Total loss': 0.36879098863658105}
2023-01-05 06:01:13,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:13,217 INFO:     Epoch: 14
2023-01-05 06:01:15,256 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46141017278035484, 'Total loss': 0.46141017278035484} | train loss {'Reaction outcome loss': 0.3625822920002711, 'Total loss': 0.3625822920002711}
2023-01-05 06:01:15,257 INFO:     Found new best model at epoch 14
2023-01-05 06:01:15,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:15,258 INFO:     Epoch: 15
2023-01-05 06:01:17,535 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46901556650797527, 'Total loss': 0.46901556650797527} | train loss {'Reaction outcome loss': 0.3553919632176985, 'Total loss': 0.3553919632176985}
2023-01-05 06:01:17,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:17,536 INFO:     Epoch: 16
2023-01-05 06:01:19,809 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4623273752629757, 'Total loss': 0.4623273752629757} | train loss {'Reaction outcome loss': 0.34545732330044976, 'Total loss': 0.34545732330044976}
2023-01-05 06:01:19,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:19,809 INFO:     Epoch: 17
2023-01-05 06:01:22,072 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48088155388832093, 'Total loss': 0.48088155388832093} | train loss {'Reaction outcome loss': 0.33815965100871254, 'Total loss': 0.33815965100871254}
2023-01-05 06:01:22,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:22,072 INFO:     Epoch: 18
2023-01-05 06:01:24,367 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4564785033464432, 'Total loss': 0.4564785033464432} | train loss {'Reaction outcome loss': 0.33013507626626803, 'Total loss': 0.33013507626626803}
2023-01-05 06:01:24,367 INFO:     Found new best model at epoch 18
2023-01-05 06:01:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:24,368 INFO:     Epoch: 19
2023-01-05 06:01:26,655 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4738802621761958, 'Total loss': 0.4738802621761958} | train loss {'Reaction outcome loss': 0.3225658529208622, 'Total loss': 0.3225658529208622}
2023-01-05 06:01:26,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:26,655 INFO:     Epoch: 20
2023-01-05 06:01:28,930 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46381925890843073, 'Total loss': 0.46381925890843073} | train loss {'Reaction outcome loss': 0.3172384202724957, 'Total loss': 0.3172384202724957}
2023-01-05 06:01:28,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:28,931 INFO:     Epoch: 21
2023-01-05 06:01:31,195 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4679249107837677, 'Total loss': 0.4679249107837677} | train loss {'Reaction outcome loss': 0.3097205495586673, 'Total loss': 0.3097205495586673}
2023-01-05 06:01:31,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:31,196 INFO:     Epoch: 22
2023-01-05 06:01:33,408 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4678037544091543, 'Total loss': 0.4678037544091543} | train loss {'Reaction outcome loss': 0.29947288968748803, 'Total loss': 0.29947288968748803}
2023-01-05 06:01:33,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:33,408 INFO:     Epoch: 23
2023-01-05 06:01:35,676 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45546674231688183, 'Total loss': 0.45546674231688183} | train loss {'Reaction outcome loss': 0.30069924707345635, 'Total loss': 0.30069924707345635}
2023-01-05 06:01:35,676 INFO:     Found new best model at epoch 23
2023-01-05 06:01:35,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:35,677 INFO:     Epoch: 24
2023-01-05 06:01:37,956 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4422080983718236, 'Total loss': 0.4422080983718236} | train loss {'Reaction outcome loss': 0.29170676271188195, 'Total loss': 0.29170676271188195}
2023-01-05 06:01:37,956 INFO:     Found new best model at epoch 24
2023-01-05 06:01:37,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:37,957 INFO:     Epoch: 25
2023-01-05 06:01:40,242 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46744378010431925, 'Total loss': 0.46744378010431925} | train loss {'Reaction outcome loss': 0.2881199098478976, 'Total loss': 0.2881199098478976}
2023-01-05 06:01:40,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:40,242 INFO:     Epoch: 26
2023-01-05 06:01:42,509 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4649128874142965, 'Total loss': 0.4649128874142965} | train loss {'Reaction outcome loss': 0.28325755259467533, 'Total loss': 0.28325755259467533}
2023-01-05 06:01:42,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:42,509 INFO:     Epoch: 27
2023-01-05 06:01:44,795 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47506747643152875, 'Total loss': 0.47506747643152875} | train loss {'Reaction outcome loss': 0.2751097812301537, 'Total loss': 0.2751097812301537}
2023-01-05 06:01:44,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:44,795 INFO:     Epoch: 28
2023-01-05 06:01:47,055 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47923565407594043, 'Total loss': 0.47923565407594043} | train loss {'Reaction outcome loss': 0.2735826725923065, 'Total loss': 0.2735826725923065}
2023-01-05 06:01:47,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:47,056 INFO:     Epoch: 29
2023-01-05 06:01:49,330 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4577277342478434, 'Total loss': 0.4577277342478434} | train loss {'Reaction outcome loss': 0.2674801813850206, 'Total loss': 0.2674801813850206}
2023-01-05 06:01:49,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:49,330 INFO:     Epoch: 30
2023-01-05 06:01:51,583 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4813197712103526, 'Total loss': 0.4813197712103526} | train loss {'Reaction outcome loss': 0.26456434172038257, 'Total loss': 0.26456434172038257}
2023-01-05 06:01:51,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:51,583 INFO:     Epoch: 31
2023-01-05 06:01:53,836 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46876577933629354, 'Total loss': 0.46876577933629354} | train loss {'Reaction outcome loss': 0.2655055123900968, 'Total loss': 0.2655055123900968}
2023-01-05 06:01:53,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:53,837 INFO:     Epoch: 32
2023-01-05 06:01:56,100 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4660927971204122, 'Total loss': 0.4660927971204122} | train loss {'Reaction outcome loss': 0.25682450363609055, 'Total loss': 0.25682450363609055}
2023-01-05 06:01:56,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:56,101 INFO:     Epoch: 33
2023-01-05 06:01:58,311 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45658793846766155, 'Total loss': 0.45658793846766155} | train loss {'Reaction outcome loss': 0.25516901527484204, 'Total loss': 0.25516901527484204}
2023-01-05 06:01:58,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:01:58,311 INFO:     Epoch: 34
2023-01-05 06:02:00,507 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4703803131977717, 'Total loss': 0.4703803131977717} | train loss {'Reaction outcome loss': 0.25330126030789013, 'Total loss': 0.25330126030789013}
2023-01-05 06:02:00,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:00,508 INFO:     Epoch: 35
2023-01-05 06:02:02,812 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4572842756907145, 'Total loss': 0.4572842756907145} | train loss {'Reaction outcome loss': 0.24898293841144312, 'Total loss': 0.24898293841144312}
2023-01-05 06:02:02,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:02,813 INFO:     Epoch: 36
2023-01-05 06:02:05,133 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4782139201958974, 'Total loss': 0.4782139201958974} | train loss {'Reaction outcome loss': 0.24392247278234025, 'Total loss': 0.24392247278234025}
2023-01-05 06:02:05,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:05,133 INFO:     Epoch: 37
2023-01-05 06:02:07,445 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49116284151872, 'Total loss': 0.49116284151872} | train loss {'Reaction outcome loss': 0.23849250771614816, 'Total loss': 0.23849250771614816}
2023-01-05 06:02:07,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:07,446 INFO:     Epoch: 38
2023-01-05 06:02:09,727 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46661282181739805, 'Total loss': 0.46661282181739805} | train loss {'Reaction outcome loss': 0.2403517922629481, 'Total loss': 0.2403517922629481}
2023-01-05 06:02:09,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:09,728 INFO:     Epoch: 39
2023-01-05 06:02:12,015 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.467894850174586, 'Total loss': 0.467894850174586} | train loss {'Reaction outcome loss': 0.23780893183573135, 'Total loss': 0.23780893183573135}
2023-01-05 06:02:12,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:12,016 INFO:     Epoch: 40
2023-01-05 06:02:14,303 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4865338842074076, 'Total loss': 0.4865338842074076} | train loss {'Reaction outcome loss': 0.23274868612845792, 'Total loss': 0.23274868612845792}
2023-01-05 06:02:14,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:14,303 INFO:     Epoch: 41
2023-01-05 06:02:16,585 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49215194384257, 'Total loss': 0.49215194384257} | train loss {'Reaction outcome loss': 0.23168923430637442, 'Total loss': 0.23168923430637442}
2023-01-05 06:02:16,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:16,587 INFO:     Epoch: 42
2023-01-05 06:02:18,880 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4820702254772186, 'Total loss': 0.4820702254772186} | train loss {'Reaction outcome loss': 0.22963937240369295, 'Total loss': 0.22963937240369295}
2023-01-05 06:02:18,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:18,880 INFO:     Epoch: 43
2023-01-05 06:02:21,157 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.483093806107839, 'Total loss': 0.483093806107839} | train loss {'Reaction outcome loss': 0.2259545475565086, 'Total loss': 0.2259545475565086}
2023-01-05 06:02:21,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:21,158 INFO:     Epoch: 44
2023-01-05 06:02:23,421 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47593719164530435, 'Total loss': 0.47593719164530435} | train loss {'Reaction outcome loss': 0.22631034880886663, 'Total loss': 0.22631034880886663}
2023-01-05 06:02:23,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:23,422 INFO:     Epoch: 45
2023-01-05 06:02:25,703 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4800724446773529, 'Total loss': 0.4800724446773529} | train loss {'Reaction outcome loss': 0.22702137132371691, 'Total loss': 0.22702137132371691}
2023-01-05 06:02:25,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:25,704 INFO:     Epoch: 46
2023-01-05 06:02:27,993 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5089065810044606, 'Total loss': 0.5089065810044606} | train loss {'Reaction outcome loss': 0.22549195430221278, 'Total loss': 0.22549195430221278}
2023-01-05 06:02:27,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:27,993 INFO:     Epoch: 47
2023-01-05 06:02:30,266 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46785392998717723, 'Total loss': 0.46785392998717723} | train loss {'Reaction outcome loss': 0.21882890119739062, 'Total loss': 0.21882890119739062}
2023-01-05 06:02:30,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:30,266 INFO:     Epoch: 48
2023-01-05 06:02:32,516 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46103897293408713, 'Total loss': 0.46103897293408713} | train loss {'Reaction outcome loss': 0.21972268632025985, 'Total loss': 0.21972268632025985}
2023-01-05 06:02:32,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:32,516 INFO:     Epoch: 49
2023-01-05 06:02:34,815 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4931870321432749, 'Total loss': 0.4931870321432749} | train loss {'Reaction outcome loss': 0.21777313775585397, 'Total loss': 0.21777313775585397}
2023-01-05 06:02:34,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:34,815 INFO:     Epoch: 50
2023-01-05 06:02:37,098 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47902256647745767, 'Total loss': 0.47902256647745767} | train loss {'Reaction outcome loss': 0.21660858747902134, 'Total loss': 0.21660858747902134}
2023-01-05 06:02:37,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:37,099 INFO:     Epoch: 51
2023-01-05 06:02:39,371 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47885143955548604, 'Total loss': 0.47885143955548604} | train loss {'Reaction outcome loss': 0.21113869061008556, 'Total loss': 0.21113869061008556}
2023-01-05 06:02:39,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:39,371 INFO:     Epoch: 52
2023-01-05 06:02:41,626 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46535991529623666, 'Total loss': 0.46535991529623666} | train loss {'Reaction outcome loss': 0.21736378342831048, 'Total loss': 0.21736378342831048}
2023-01-05 06:02:41,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:41,626 INFO:     Epoch: 53
2023-01-05 06:02:43,886 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49352913300196327, 'Total loss': 0.49352913300196327} | train loss {'Reaction outcome loss': 0.21277130354344304, 'Total loss': 0.21277130354344304}
2023-01-05 06:02:43,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:43,886 INFO:     Epoch: 54
2023-01-05 06:02:46,155 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4768070474267006, 'Total loss': 0.4768070474267006} | train loss {'Reaction outcome loss': 0.21145405130422054, 'Total loss': 0.21145405130422054}
2023-01-05 06:02:46,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:46,155 INFO:     Epoch: 55
2023-01-05 06:02:48,444 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4568015955388546, 'Total loss': 0.4568015955388546} | train loss {'Reaction outcome loss': 0.20852992454403674, 'Total loss': 0.20852992454403674}
2023-01-05 06:02:48,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:48,445 INFO:     Epoch: 56
2023-01-05 06:02:50,713 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47419012188911436, 'Total loss': 0.47419012188911436} | train loss {'Reaction outcome loss': 0.21376660983314386, 'Total loss': 0.21376660983314386}
2023-01-05 06:02:50,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:50,713 INFO:     Epoch: 57
2023-01-05 06:02:52,942 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4491795182228088, 'Total loss': 0.4491795182228088} | train loss {'Reaction outcome loss': 0.20272059612709226, 'Total loss': 0.20272059612709226}
2023-01-05 06:02:52,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:52,943 INFO:     Epoch: 58
2023-01-05 06:02:55,215 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47975329160690305, 'Total loss': 0.47975329160690305} | train loss {'Reaction outcome loss': 0.20287547646211865, 'Total loss': 0.20287547646211865}
2023-01-05 06:02:55,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:55,215 INFO:     Epoch: 59
2023-01-05 06:02:57,428 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48285062797367573, 'Total loss': 0.48285062797367573} | train loss {'Reaction outcome loss': 0.20783134047583124, 'Total loss': 0.20783134047583124}
2023-01-05 06:02:57,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:57,428 INFO:     Epoch: 60
2023-01-05 06:02:59,697 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.473825541138649, 'Total loss': 0.473825541138649} | train loss {'Reaction outcome loss': 0.20272152487566505, 'Total loss': 0.20272152487566505}
2023-01-05 06:02:59,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:02:59,698 INFO:     Epoch: 61
2023-01-05 06:03:01,965 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4669989474117756, 'Total loss': 0.4669989474117756} | train loss {'Reaction outcome loss': 0.20130456050498216, 'Total loss': 0.20130456050498216}
2023-01-05 06:03:01,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:01,965 INFO:     Epoch: 62
2023-01-05 06:03:04,253 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.510003807147344, 'Total loss': 0.510003807147344} | train loss {'Reaction outcome loss': 0.19923140253050023, 'Total loss': 0.19923140253050023}
2023-01-05 06:03:04,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:04,253 INFO:     Epoch: 63
2023-01-05 06:03:06,508 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4886990939577421, 'Total loss': 0.4886990939577421} | train loss {'Reaction outcome loss': 0.1986455800268205, 'Total loss': 0.1986455800268205}
2023-01-05 06:03:06,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:06,509 INFO:     Epoch: 64
2023-01-05 06:03:08,766 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46954028407732645, 'Total loss': 0.46954028407732645} | train loss {'Reaction outcome loss': 0.20018601715109058, 'Total loss': 0.20018601715109058}
2023-01-05 06:03:08,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:08,766 INFO:     Epoch: 65
2023-01-05 06:03:11,062 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4861345579226812, 'Total loss': 0.4861345579226812} | train loss {'Reaction outcome loss': 0.2014792094351319, 'Total loss': 0.2014792094351319}
2023-01-05 06:03:11,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:11,062 INFO:     Epoch: 66
2023-01-05 06:03:13,339 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4758458132545153, 'Total loss': 0.4758458132545153} | train loss {'Reaction outcome loss': 0.19528637348465028, 'Total loss': 0.19528637348465028}
2023-01-05 06:03:13,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:13,340 INFO:     Epoch: 67
2023-01-05 06:03:15,624 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5076187372207641, 'Total loss': 0.5076187372207641} | train loss {'Reaction outcome loss': 0.19804753827781457, 'Total loss': 0.19804753827781457}
2023-01-05 06:03:15,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:15,624 INFO:     Epoch: 68
2023-01-05 06:03:17,890 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47178636689980824, 'Total loss': 0.47178636689980824} | train loss {'Reaction outcome loss': 0.18883001456455584, 'Total loss': 0.18883001456455584}
2023-01-05 06:03:17,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:17,890 INFO:     Epoch: 69
2023-01-05 06:03:20,146 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5104153652985891, 'Total loss': 0.5104153652985891} | train loss {'Reaction outcome loss': 0.19231697638684453, 'Total loss': 0.19231697638684453}
2023-01-05 06:03:20,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:20,146 INFO:     Epoch: 70
2023-01-05 06:03:22,410 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5346101472775141, 'Total loss': 0.5346101472775141} | train loss {'Reaction outcome loss': 0.2169224247302644, 'Total loss': 0.2169224247302644}
2023-01-05 06:03:22,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:22,410 INFO:     Epoch: 71
2023-01-05 06:03:24,701 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4698837245504061, 'Total loss': 0.4698837245504061} | train loss {'Reaction outcome loss': 0.19636758639851748, 'Total loss': 0.19636758639851748}
2023-01-05 06:03:24,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:24,701 INFO:     Epoch: 72
2023-01-05 06:03:26,981 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46451502442359927, 'Total loss': 0.46451502442359927} | train loss {'Reaction outcome loss': 0.18612758442759514, 'Total loss': 0.18612758442759514}
2023-01-05 06:03:26,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:26,982 INFO:     Epoch: 73
2023-01-05 06:03:29,244 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4741215318441391, 'Total loss': 0.4741215318441391} | train loss {'Reaction outcome loss': 0.18561114825348815, 'Total loss': 0.18561114825348815}
2023-01-05 06:03:29,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:29,246 INFO:     Epoch: 74
2023-01-05 06:03:31,483 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49663787285486855, 'Total loss': 0.49663787285486855} | train loss {'Reaction outcome loss': 0.19312537901553414, 'Total loss': 0.19312537901553414}
2023-01-05 06:03:31,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:31,484 INFO:     Epoch: 75
2023-01-05 06:03:33,765 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.477773721019427, 'Total loss': 0.477773721019427} | train loss {'Reaction outcome loss': 0.19485314125937503, 'Total loss': 0.19485314125937503}
2023-01-05 06:03:33,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:33,765 INFO:     Epoch: 76
2023-01-05 06:03:36,058 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5069831214845181, 'Total loss': 0.5069831214845181} | train loss {'Reaction outcome loss': 0.19441988981966657, 'Total loss': 0.19441988981966657}
2023-01-05 06:03:36,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:36,059 INFO:     Epoch: 77
2023-01-05 06:03:38,354 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.489512167374293, 'Total loss': 0.489512167374293} | train loss {'Reaction outcome loss': 0.18971575566472998, 'Total loss': 0.18971575566472998}
2023-01-05 06:03:38,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:38,355 INFO:     Epoch: 78
2023-01-05 06:03:40,617 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48902714749177295, 'Total loss': 0.48902714749177295} | train loss {'Reaction outcome loss': 0.186099054099506, 'Total loss': 0.186099054099506}
2023-01-05 06:03:40,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:40,618 INFO:     Epoch: 79
2023-01-05 06:03:42,863 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49815333088239033, 'Total loss': 0.49815333088239033} | train loss {'Reaction outcome loss': 0.18363703655895602, 'Total loss': 0.18363703655895602}
2023-01-05 06:03:42,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:42,863 INFO:     Epoch: 80
2023-01-05 06:03:45,141 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4911089817682902, 'Total loss': 0.4911089817682902} | train loss {'Reaction outcome loss': 0.184803578513337, 'Total loss': 0.184803578513337}
2023-01-05 06:03:45,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:45,142 INFO:     Epoch: 81
2023-01-05 06:03:47,416 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5064585725466411, 'Total loss': 0.5064585725466411} | train loss {'Reaction outcome loss': 0.18910781768010865, 'Total loss': 0.18910781768010865}
2023-01-05 06:03:47,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:47,416 INFO:     Epoch: 82
2023-01-05 06:03:49,679 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49397964080174767, 'Total loss': 0.49397964080174767} | train loss {'Reaction outcome loss': 0.18393419124354757, 'Total loss': 0.18393419124354757}
2023-01-05 06:03:49,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:49,680 INFO:     Epoch: 83
2023-01-05 06:03:51,942 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48591739336649575, 'Total loss': 0.48591739336649575} | train loss {'Reaction outcome loss': 0.18334151447608904, 'Total loss': 0.18334151447608904}
2023-01-05 06:03:51,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:51,943 INFO:     Epoch: 84
2023-01-05 06:03:54,224 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4942860245704651, 'Total loss': 0.4942860245704651} | train loss {'Reaction outcome loss': 0.18171569790549413, 'Total loss': 0.18171569790549413}
2023-01-05 06:03:54,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:54,225 INFO:     Epoch: 85
2023-01-05 06:03:56,510 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5219986359278361, 'Total loss': 0.5219986359278361} | train loss {'Reaction outcome loss': 0.18473808816275594, 'Total loss': 0.18473808816275594}
2023-01-05 06:03:56,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:56,511 INFO:     Epoch: 86
2023-01-05 06:03:58,764 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46373542249202726, 'Total loss': 0.46373542249202726} | train loss {'Reaction outcome loss': 0.1856213609073851, 'Total loss': 0.1856213609073851}
2023-01-05 06:03:58,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:03:58,765 INFO:     Epoch: 87
2023-01-05 06:04:01,059 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5190237065156301, 'Total loss': 0.5190237065156301} | train loss {'Reaction outcome loss': 0.18020982570790997, 'Total loss': 0.18020982570790997}
2023-01-05 06:04:01,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:01,059 INFO:     Epoch: 88
2023-01-05 06:04:03,325 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49929293791453044, 'Total loss': 0.49929293791453044} | train loss {'Reaction outcome loss': 0.1830058262741026, 'Total loss': 0.1830058262741026}
2023-01-05 06:04:03,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:03,326 INFO:     Epoch: 89
2023-01-05 06:04:05,632 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4972785512606303, 'Total loss': 0.4972785512606303} | train loss {'Reaction outcome loss': 0.18348945816978812, 'Total loss': 0.18348945816978812}
2023-01-05 06:04:05,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:05,634 INFO:     Epoch: 90
2023-01-05 06:04:07,929 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4975151389837265, 'Total loss': 0.4975151389837265} | train loss {'Reaction outcome loss': 0.1795373222465033, 'Total loss': 0.1795373222465033}
2023-01-05 06:04:07,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:07,930 INFO:     Epoch: 91
2023-01-05 06:04:10,228 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5041017740964889, 'Total loss': 0.5041017740964889} | train loss {'Reaction outcome loss': 0.18188480454230466, 'Total loss': 0.18188480454230466}
2023-01-05 06:04:10,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:10,228 INFO:     Epoch: 92
2023-01-05 06:04:12,521 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5132582982381185, 'Total loss': 0.5132582982381185} | train loss {'Reaction outcome loss': 0.18084633961531665, 'Total loss': 0.18084633961531665}
2023-01-05 06:04:12,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:12,522 INFO:     Epoch: 93
2023-01-05 06:04:14,779 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5341458996136983, 'Total loss': 0.5341458996136983} | train loss {'Reaction outcome loss': 0.17605324635888278, 'Total loss': 0.17605324635888278}
2023-01-05 06:04:14,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:14,779 INFO:     Epoch: 94
2023-01-05 06:04:17,013 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4836815138657888, 'Total loss': 0.4836815138657888} | train loss {'Reaction outcome loss': 0.17798703622353007, 'Total loss': 0.17798703622353007}
2023-01-05 06:04:17,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:17,013 INFO:     Epoch: 95
2023-01-05 06:04:19,201 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4878529510150353, 'Total loss': 0.4878529510150353} | train loss {'Reaction outcome loss': 0.18170208203778399, 'Total loss': 0.18170208203778399}
2023-01-05 06:04:19,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:19,201 INFO:     Epoch: 96
2023-01-05 06:04:21,419 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4670050879319509, 'Total loss': 0.4670050879319509} | train loss {'Reaction outcome loss': 0.17848386783908357, 'Total loss': 0.17848386783908357}
2023-01-05 06:04:21,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:21,420 INFO:     Epoch: 97
2023-01-05 06:04:23,730 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5132489919662475, 'Total loss': 0.5132489919662475} | train loss {'Reaction outcome loss': 0.18180460989495498, 'Total loss': 0.18180460989495498}
2023-01-05 06:04:23,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:23,730 INFO:     Epoch: 98
2023-01-05 06:04:25,979 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48706595301628114, 'Total loss': 0.48706595301628114} | train loss {'Reaction outcome loss': 0.17259118928632233, 'Total loss': 0.17259118928632233}
2023-01-05 06:04:25,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:25,980 INFO:     Epoch: 99
2023-01-05 06:04:28,235 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5077158898115158, 'Total loss': 0.5077158898115158} | train loss {'Reaction outcome loss': 0.1772895911147751, 'Total loss': 0.1772895911147751}
2023-01-05 06:04:28,236 INFO:     Best model found after epoch 25 of 100.
2023-01-05 06:04:28,236 INFO:   Done with stage: TRAINING
2023-01-05 06:04:28,236 INFO:   Starting stage: EVALUATION
2023-01-05 06:04:28,371 INFO:   Done with stage: EVALUATION
2023-01-05 06:04:28,371 INFO:   Leaving out SEQ value Fold_4
2023-01-05 06:04:28,384 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:04:28,384 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:04:29,040 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:04:29,040 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:04:29,114 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:04:29,115 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:04:29,115 INFO:     No hyperparam tuning for this model
2023-01-05 06:04:29,115 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:04:29,115 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:04:29,115 INFO:     None feature selector for col prot
2023-01-05 06:04:29,116 INFO:     None feature selector for col prot
2023-01-05 06:04:29,116 INFO:     None feature selector for col prot
2023-01-05 06:04:29,116 INFO:     None feature selector for col chem
2023-01-05 06:04:29,116 INFO:     None feature selector for col chem
2023-01-05 06:04:29,116 INFO:     None feature selector for col chem
2023-01-05 06:04:29,116 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:04:29,116 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:04:29,118 INFO:     Number of params in model 72931
2023-01-05 06:04:29,121 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:04:29,121 INFO:   Starting stage: TRAINING
2023-01-05 06:04:29,182 INFO:     Val loss before train {'Reaction outcome loss': 0.9786234219868978, 'Total loss': 0.9786234219868978}
2023-01-05 06:04:29,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:29,182 INFO:     Epoch: 0
2023-01-05 06:04:31,464 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7988485316435496, 'Total loss': 0.7988485316435496} | train loss {'Reaction outcome loss': 0.9402312634223635, 'Total loss': 0.9402312634223635}
2023-01-05 06:04:31,464 INFO:     Found new best model at epoch 0
2023-01-05 06:04:31,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:31,466 INFO:     Epoch: 1
2023-01-05 06:04:33,743 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5934804797172546, 'Total loss': 0.5934804797172546} | train loss {'Reaction outcome loss': 0.6429232613381927, 'Total loss': 0.6429232613381927}
2023-01-05 06:04:33,744 INFO:     Found new best model at epoch 1
2023-01-05 06:04:33,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:33,745 INFO:     Epoch: 2
2023-01-05 06:04:35,991 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5252327740192413, 'Total loss': 0.5252327740192413} | train loss {'Reaction outcome loss': 0.5262555993743752, 'Total loss': 0.5262555993743752}
2023-01-05 06:04:35,992 INFO:     Found new best model at epoch 2
2023-01-05 06:04:35,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:35,993 INFO:     Epoch: 3
2023-01-05 06:04:38,255 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5174901684125265, 'Total loss': 0.5174901684125265} | train loss {'Reaction outcome loss': 0.4792078817364111, 'Total loss': 0.4792078817364111}
2023-01-05 06:04:38,255 INFO:     Found new best model at epoch 3
2023-01-05 06:04:38,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:38,257 INFO:     Epoch: 4
2023-01-05 06:04:40,516 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48581921060880023, 'Total loss': 0.48581921060880023} | train loss {'Reaction outcome loss': 0.4491601873606121, 'Total loss': 0.4491601873606121}
2023-01-05 06:04:40,516 INFO:     Found new best model at epoch 4
2023-01-05 06:04:40,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:40,517 INFO:     Epoch: 5
2023-01-05 06:04:42,736 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4539424161116282, 'Total loss': 0.4539424161116282} | train loss {'Reaction outcome loss': 0.4264623554497419, 'Total loss': 0.4264623554497419}
2023-01-05 06:04:42,737 INFO:     Found new best model at epoch 5
2023-01-05 06:04:42,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:42,738 INFO:     Epoch: 6
2023-01-05 06:04:44,944 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47837351163228353, 'Total loss': 0.47837351163228353} | train loss {'Reaction outcome loss': 0.409849181878868, 'Total loss': 0.409849181878868}
2023-01-05 06:04:44,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:44,944 INFO:     Epoch: 7
2023-01-05 06:04:47,229 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4717909296353658, 'Total loss': 0.4717909296353658} | train loss {'Reaction outcome loss': 0.39463943280683095, 'Total loss': 0.39463943280683095}
2023-01-05 06:04:47,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:47,229 INFO:     Epoch: 8
2023-01-05 06:04:49,522 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48020352721214293, 'Total loss': 0.48020352721214293} | train loss {'Reaction outcome loss': 0.3838352541899853, 'Total loss': 0.3838352541899853}
2023-01-05 06:04:49,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:49,522 INFO:     Epoch: 9
2023-01-05 06:04:51,756 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47219658295313516, 'Total loss': 0.47219658295313516} | train loss {'Reaction outcome loss': 0.3735104599153952, 'Total loss': 0.3735104599153952}
2023-01-05 06:04:51,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:51,756 INFO:     Epoch: 10
2023-01-05 06:04:54,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45811122556527456, 'Total loss': 0.45811122556527456} | train loss {'Reaction outcome loss': 0.3639270041662433, 'Total loss': 0.3639270041662433}
2023-01-05 06:04:54,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:54,031 INFO:     Epoch: 11
2023-01-05 06:04:56,285 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4591996669769287, 'Total loss': 0.4591996669769287} | train loss {'Reaction outcome loss': 0.3532200227844586, 'Total loss': 0.3532200227844586}
2023-01-05 06:04:56,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:56,286 INFO:     Epoch: 12
2023-01-05 06:04:58,552 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48280888398488364, 'Total loss': 0.48280888398488364} | train loss {'Reaction outcome loss': 0.34898227227293627, 'Total loss': 0.34898227227293627}
2023-01-05 06:04:58,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:04:58,552 INFO:     Epoch: 13
2023-01-05 06:05:00,842 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4862558404604594, 'Total loss': 0.4862558404604594} | train loss {'Reaction outcome loss': 0.3403244241130696, 'Total loss': 0.3403244241130696}
2023-01-05 06:05:00,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:00,842 INFO:     Epoch: 14
2023-01-05 06:05:03,105 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47575224240620934, 'Total loss': 0.47575224240620934} | train loss {'Reaction outcome loss': 0.329964928866939, 'Total loss': 0.329964928866939}
2023-01-05 06:05:03,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:03,106 INFO:     Epoch: 15
2023-01-05 06:05:05,395 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4726988735298316, 'Total loss': 0.4726988735298316} | train loss {'Reaction outcome loss': 0.3226168330234311, 'Total loss': 0.3226168330234311}
2023-01-05 06:05:05,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:05,396 INFO:     Epoch: 16
2023-01-05 06:05:07,729 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.477807879447937, 'Total loss': 0.477807879447937} | train loss {'Reaction outcome loss': 0.32238437692611227, 'Total loss': 0.32238437692611227}
2023-01-05 06:05:07,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:07,729 INFO:     Epoch: 17
2023-01-05 06:05:10,090 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46447868943214415, 'Total loss': 0.46447868943214415} | train loss {'Reaction outcome loss': 0.3135329529185803, 'Total loss': 0.3135329529185803}
2023-01-05 06:05:10,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:10,091 INFO:     Epoch: 18
2023-01-05 06:05:12,413 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48188971281051635, 'Total loss': 0.48188971281051635} | train loss {'Reaction outcome loss': 0.30291790231416804, 'Total loss': 0.30291790231416804}
2023-01-05 06:05:12,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:12,414 INFO:     Epoch: 19
2023-01-05 06:05:14,679 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48894052306811014, 'Total loss': 0.48894052306811014} | train loss {'Reaction outcome loss': 0.2966845379772492, 'Total loss': 0.2966845379772492}
2023-01-05 06:05:14,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:14,679 INFO:     Epoch: 20
2023-01-05 06:05:16,960 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47344853977362317, 'Total loss': 0.47344853977362317} | train loss {'Reaction outcome loss': 0.29495716228112845, 'Total loss': 0.29495716228112845}
2023-01-05 06:05:16,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:16,960 INFO:     Epoch: 21
2023-01-05 06:05:19,254 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4695919056733449, 'Total loss': 0.4695919056733449} | train loss {'Reaction outcome loss': 0.28767159125273406, 'Total loss': 0.28767159125273406}
2023-01-05 06:05:19,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:19,255 INFO:     Epoch: 22
2023-01-05 06:05:21,539 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4723946968714396, 'Total loss': 0.4723946968714396} | train loss {'Reaction outcome loss': 0.2824726150999861, 'Total loss': 0.2824726150999861}
2023-01-05 06:05:21,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:21,539 INFO:     Epoch: 23
2023-01-05 06:05:23,812 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4864560862382253, 'Total loss': 0.4864560862382253} | train loss {'Reaction outcome loss': 0.2766515945054133, 'Total loss': 0.2766515945054133}
2023-01-05 06:05:23,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:23,813 INFO:     Epoch: 24
2023-01-05 06:05:25,885 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47896945277849834, 'Total loss': 0.47896945277849834} | train loss {'Reaction outcome loss': 0.2724041541910559, 'Total loss': 0.2724041541910559}
2023-01-05 06:05:25,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:25,886 INFO:     Epoch: 25
2023-01-05 06:05:28,170 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.470058399438858, 'Total loss': 0.470058399438858} | train loss {'Reaction outcome loss': 0.267612587505891, 'Total loss': 0.267612587505891}
2023-01-05 06:05:28,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:28,170 INFO:     Epoch: 26
2023-01-05 06:05:30,451 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4792205293973287, 'Total loss': 0.4792205293973287} | train loss {'Reaction outcome loss': 0.26156531873458344, 'Total loss': 0.26156531873458344}
2023-01-05 06:05:30,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:30,451 INFO:     Epoch: 27
2023-01-05 06:05:32,689 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5112540334463119, 'Total loss': 0.5112540334463119} | train loss {'Reaction outcome loss': 0.2626476418832149, 'Total loss': 0.2626476418832149}
2023-01-05 06:05:32,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:32,689 INFO:     Epoch: 28
2023-01-05 06:05:34,972 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4793124794960022, 'Total loss': 0.4793124794960022} | train loss {'Reaction outcome loss': 0.2543978692849405, 'Total loss': 0.2543978692849405}
2023-01-05 06:05:34,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:34,972 INFO:     Epoch: 29
2023-01-05 06:05:37,206 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4709121684233348, 'Total loss': 0.4709121684233348} | train loss {'Reaction outcome loss': 0.24915020230364068, 'Total loss': 0.24915020230364068}
2023-01-05 06:05:37,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:37,206 INFO:     Epoch: 30
2023-01-05 06:05:39,418 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4672939588626226, 'Total loss': 0.4672939588626226} | train loss {'Reaction outcome loss': 0.24465843914110308, 'Total loss': 0.24465843914110308}
2023-01-05 06:05:39,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:39,419 INFO:     Epoch: 31
2023-01-05 06:05:41,707 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4697532077630361, 'Total loss': 0.4697532077630361} | train loss {'Reaction outcome loss': 0.24614675365899444, 'Total loss': 0.24614675365899444}
2023-01-05 06:05:41,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:41,709 INFO:     Epoch: 32
2023-01-05 06:05:44,034 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4794003963470459, 'Total loss': 0.4794003963470459} | train loss {'Reaction outcome loss': 0.24232689527263496, 'Total loss': 0.24232689527263496}
2023-01-05 06:05:44,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:44,035 INFO:     Epoch: 33
2023-01-05 06:05:46,263 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48496295313040416, 'Total loss': 0.48496295313040416} | train loss {'Reaction outcome loss': 0.23947875673079103, 'Total loss': 0.23947875673079103}
2023-01-05 06:05:46,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:46,263 INFO:     Epoch: 34
2023-01-05 06:05:48,473 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46238847573598224, 'Total loss': 0.46238847573598224} | train loss {'Reaction outcome loss': 0.23839428115784045, 'Total loss': 0.23839428115784045}
2023-01-05 06:05:48,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:48,474 INFO:     Epoch: 35
2023-01-05 06:05:50,753 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4936127374569575, 'Total loss': 0.4936127374569575} | train loss {'Reaction outcome loss': 0.24050312619051134, 'Total loss': 0.24050312619051134}
2023-01-05 06:05:50,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:50,753 INFO:     Epoch: 36
2023-01-05 06:05:53,039 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48595943053563434, 'Total loss': 0.48595943053563434} | train loss {'Reaction outcome loss': 0.23300684026916535, 'Total loss': 0.23300684026916535}
2023-01-05 06:05:53,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:53,039 INFO:     Epoch: 37
2023-01-05 06:05:55,344 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5046311398347219, 'Total loss': 0.5046311398347219} | train loss {'Reaction outcome loss': 0.22796814937131069, 'Total loss': 0.22796814937131069}
2023-01-05 06:05:55,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:55,344 INFO:     Epoch: 38
2023-01-05 06:05:57,636 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4904024352629979, 'Total loss': 0.4904024352629979} | train loss {'Reaction outcome loss': 0.23040487966920495, 'Total loss': 0.23040487966920495}
2023-01-05 06:05:57,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:57,636 INFO:     Epoch: 39
2023-01-05 06:05:59,968 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5194385300079981, 'Total loss': 0.5194385300079981} | train loss {'Reaction outcome loss': 0.22422315009503158, 'Total loss': 0.22422315009503158}
2023-01-05 06:05:59,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:05:59,968 INFO:     Epoch: 40
2023-01-05 06:06:02,250 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48476370771725974, 'Total loss': 0.48476370771725974} | train loss {'Reaction outcome loss': 0.22193619537600973, 'Total loss': 0.22193619537600973}
2023-01-05 06:06:02,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:02,251 INFO:     Epoch: 41
2023-01-05 06:06:04,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5015744914611181, 'Total loss': 0.5015744914611181} | train loss {'Reaction outcome loss': 0.22200040648008834, 'Total loss': 0.22200040648008834}
2023-01-05 06:06:04,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:04,561 INFO:     Epoch: 42
2023-01-05 06:06:06,860 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49062043031056723, 'Total loss': 0.49062043031056723} | train loss {'Reaction outcome loss': 0.21906917453121516, 'Total loss': 0.21906917453121516}
2023-01-05 06:06:06,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:06,860 INFO:     Epoch: 43
2023-01-05 06:06:09,159 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49042785267035166, 'Total loss': 0.49042785267035166} | train loss {'Reaction outcome loss': 0.21607338251472058, 'Total loss': 0.21607338251472058}
2023-01-05 06:06:09,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:09,159 INFO:     Epoch: 44
2023-01-05 06:06:11,473 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48363304138183594, 'Total loss': 0.48363304138183594} | train loss {'Reaction outcome loss': 0.21498905211713987, 'Total loss': 0.21498905211713987}
2023-01-05 06:06:11,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:11,473 INFO:     Epoch: 45
2023-01-05 06:06:13,457 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4829236308733622, 'Total loss': 0.4829236308733622} | train loss {'Reaction outcome loss': 0.21941030276972895, 'Total loss': 0.21941030276972895}
2023-01-05 06:06:13,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:13,458 INFO:     Epoch: 46
2023-01-05 06:06:15,314 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47867720226446786, 'Total loss': 0.47867720226446786} | train loss {'Reaction outcome loss': 0.2069777876326969, 'Total loss': 0.2069777876326969}
2023-01-05 06:06:15,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:15,315 INFO:     Epoch: 47
2023-01-05 06:06:17,313 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.468674240509669, 'Total loss': 0.468674240509669} | train loss {'Reaction outcome loss': 0.2062551867761498, 'Total loss': 0.2062551867761498}
2023-01-05 06:06:17,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:17,314 INFO:     Epoch: 48
2023-01-05 06:06:19,596 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48830197254816693, 'Total loss': 0.48830197254816693} | train loss {'Reaction outcome loss': 0.20693381510957376, 'Total loss': 0.20693381510957376}
2023-01-05 06:06:19,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:19,596 INFO:     Epoch: 49
2023-01-05 06:06:21,878 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4729648048679034, 'Total loss': 0.4729648048679034} | train loss {'Reaction outcome loss': 0.2020554986953843, 'Total loss': 0.2020554986953843}
2023-01-05 06:06:21,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:21,878 INFO:     Epoch: 50
2023-01-05 06:06:24,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45548665784299375, 'Total loss': 0.45548665784299375} | train loss {'Reaction outcome loss': 0.2034960503081391, 'Total loss': 0.2034960503081391}
2023-01-05 06:06:24,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:24,144 INFO:     Epoch: 51
2023-01-05 06:06:26,434 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4812083830436071, 'Total loss': 0.4812083830436071} | train loss {'Reaction outcome loss': 0.20362859340687198, 'Total loss': 0.20362859340687198}
2023-01-05 06:06:26,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:26,434 INFO:     Epoch: 52
2023-01-05 06:06:28,672 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4954724738995234, 'Total loss': 0.4954724738995234} | train loss {'Reaction outcome loss': 0.2057543536412802, 'Total loss': 0.2057543536412802}
2023-01-05 06:06:28,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:28,673 INFO:     Epoch: 53
2023-01-05 06:06:30,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47228935956954954, 'Total loss': 0.47228935956954954} | train loss {'Reaction outcome loss': 0.19751544023396628, 'Total loss': 0.19751544023396628}
2023-01-05 06:06:30,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:30,866 INFO:     Epoch: 54
2023-01-05 06:06:33,162 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4996536900599798, 'Total loss': 0.4996536900599798} | train loss {'Reaction outcome loss': 0.19362211526986817, 'Total loss': 0.19362211526986817}
2023-01-05 06:06:33,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:33,163 INFO:     Epoch: 55
2023-01-05 06:06:35,468 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4940685242414474, 'Total loss': 0.4940685242414474} | train loss {'Reaction outcome loss': 0.19448277084593954, 'Total loss': 0.19448277084593954}
2023-01-05 06:06:35,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:35,468 INFO:     Epoch: 56
2023-01-05 06:06:37,769 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4995261311531067, 'Total loss': 0.4995261311531067} | train loss {'Reaction outcome loss': 0.1984577101456936, 'Total loss': 0.1984577101456936}
2023-01-05 06:06:37,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:37,770 INFO:     Epoch: 57
2023-01-05 06:06:40,055 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47343119482199353, 'Total loss': 0.47343119482199353} | train loss {'Reaction outcome loss': 0.19514046423641515, 'Total loss': 0.19514046423641515}
2023-01-05 06:06:40,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:40,056 INFO:     Epoch: 58
2023-01-05 06:06:42,338 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.50184472600619, 'Total loss': 0.50184472600619} | train loss {'Reaction outcome loss': 0.19316674645532877, 'Total loss': 0.19316674645532877}
2023-01-05 06:06:42,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:42,338 INFO:     Epoch: 59
2023-01-05 06:06:44,643 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46385321592291195, 'Total loss': 0.46385321592291195} | train loss {'Reaction outcome loss': 0.19669973438719981, 'Total loss': 0.19669973438719981}
2023-01-05 06:06:44,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:44,643 INFO:     Epoch: 60
2023-01-05 06:06:46,932 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5038937081893285, 'Total loss': 0.5038937081893285} | train loss {'Reaction outcome loss': 0.1936334525386295, 'Total loss': 0.1936334525386295}
2023-01-05 06:06:46,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:46,933 INFO:     Epoch: 61
2023-01-05 06:06:49,223 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47562816652158896, 'Total loss': 0.47562816652158896} | train loss {'Reaction outcome loss': 0.18770762559510634, 'Total loss': 0.18770762559510634}
2023-01-05 06:06:49,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:49,223 INFO:     Epoch: 62
2023-01-05 06:06:51,510 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4898057460784912, 'Total loss': 0.4898057460784912} | train loss {'Reaction outcome loss': 0.186822740888956, 'Total loss': 0.186822740888956}
2023-01-05 06:06:51,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:51,511 INFO:     Epoch: 63
2023-01-05 06:06:53,793 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4674168994029363, 'Total loss': 0.4674168994029363} | train loss {'Reaction outcome loss': 0.1907012401995945, 'Total loss': 0.1907012401995945}
2023-01-05 06:06:53,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:53,794 INFO:     Epoch: 64
2023-01-05 06:06:56,085 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5220734039942424, 'Total loss': 0.5220734039942424} | train loss {'Reaction outcome loss': 0.18554814813813256, 'Total loss': 0.18554814813813256}
2023-01-05 06:06:56,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:56,085 INFO:     Epoch: 65
2023-01-05 06:06:58,354 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5053796788056691, 'Total loss': 0.5053796788056691} | train loss {'Reaction outcome loss': 0.18342821964227496, 'Total loss': 0.18342821964227496}
2023-01-05 06:06:58,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:06:58,355 INFO:     Epoch: 66
2023-01-05 06:07:00,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5106386999289195, 'Total loss': 0.5106386999289195} | train loss {'Reaction outcome loss': 0.1849791723898602, 'Total loss': 0.1849791723898602}
2023-01-05 06:07:00,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:00,630 INFO:     Epoch: 67
2023-01-05 06:07:02,868 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4755584052453438, 'Total loss': 0.4755584052453438} | train loss {'Reaction outcome loss': 0.18108644165663512, 'Total loss': 0.18108644165663512}
2023-01-05 06:07:02,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:02,868 INFO:     Epoch: 68
2023-01-05 06:07:05,124 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5053965379794438, 'Total loss': 0.5053965379794438} | train loss {'Reaction outcome loss': 0.1829755720564766, 'Total loss': 0.1829755720564766}
2023-01-05 06:07:05,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:05,125 INFO:     Epoch: 69
2023-01-05 06:07:07,384 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49732981125513714, 'Total loss': 0.49732981125513714} | train loss {'Reaction outcome loss': 0.18112217520602344, 'Total loss': 0.18112217520602344}
2023-01-05 06:07:07,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:07,384 INFO:     Epoch: 70
2023-01-05 06:07:09,629 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48719526727994283, 'Total loss': 0.48719526727994283} | train loss {'Reaction outcome loss': 0.1781772325170102, 'Total loss': 0.1781772325170102}
2023-01-05 06:07:09,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:09,629 INFO:     Epoch: 71
2023-01-05 06:07:11,842 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5284827609856924, 'Total loss': 0.5284827609856924} | train loss {'Reaction outcome loss': 0.1806184145208408, 'Total loss': 0.1806184145208408}
2023-01-05 06:07:11,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:11,842 INFO:     Epoch: 72
2023-01-05 06:07:14,153 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4987505485614141, 'Total loss': 0.4987505485614141} | train loss {'Reaction outcome loss': 0.17980140769544867, 'Total loss': 0.17980140769544867}
2023-01-05 06:07:14,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:14,154 INFO:     Epoch: 73
2023-01-05 06:07:16,427 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5009942432244618, 'Total loss': 0.5009942432244618} | train loss {'Reaction outcome loss': 0.17608681118068711, 'Total loss': 0.17608681118068711}
2023-01-05 06:07:16,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:16,427 INFO:     Epoch: 74
2023-01-05 06:07:18,675 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4872363120317459, 'Total loss': 0.4872363120317459} | train loss {'Reaction outcome loss': 0.17629444894686824, 'Total loss': 0.17629444894686824}
2023-01-05 06:07:18,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:18,675 INFO:     Epoch: 75
2023-01-05 06:07:20,916 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4763344466686249, 'Total loss': 0.4763344466686249} | train loss {'Reaction outcome loss': 0.17636062853737644, 'Total loss': 0.17636062853737644}
2023-01-05 06:07:20,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:20,916 INFO:     Epoch: 76
2023-01-05 06:07:23,181 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5182237168153127, 'Total loss': 0.5182237168153127} | train loss {'Reaction outcome loss': 0.17476880854661392, 'Total loss': 0.17476880854661392}
2023-01-05 06:07:23,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:23,181 INFO:     Epoch: 77
2023-01-05 06:07:25,455 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4930918355782827, 'Total loss': 0.4930918355782827} | train loss {'Reaction outcome loss': 0.17679706122053768, 'Total loss': 0.17679706122053768}
2023-01-05 06:07:25,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:25,455 INFO:     Epoch: 78
2023-01-05 06:07:27,717 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5215250283479691, 'Total loss': 0.5215250283479691} | train loss {'Reaction outcome loss': 0.17717244464480436, 'Total loss': 0.17717244464480436}
2023-01-05 06:07:27,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:27,717 INFO:     Epoch: 79
2023-01-05 06:07:30,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48722636500994365, 'Total loss': 0.48722636500994365} | train loss {'Reaction outcome loss': 0.17306149423556128, 'Total loss': 0.17306149423556128}
2023-01-05 06:07:30,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:30,013 INFO:     Epoch: 80
2023-01-05 06:07:32,319 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4887066900730133, 'Total loss': 0.4887066900730133} | train loss {'Reaction outcome loss': 0.17036995009791495, 'Total loss': 0.17036995009791495}
2023-01-05 06:07:32,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:32,319 INFO:     Epoch: 81
2023-01-05 06:07:34,591 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5007692148288091, 'Total loss': 0.5007692148288091} | train loss {'Reaction outcome loss': 0.1692224804644846, 'Total loss': 0.1692224804644846}
2023-01-05 06:07:34,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:34,592 INFO:     Epoch: 82
2023-01-05 06:07:36,895 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5085877895355224, 'Total loss': 0.5085877895355224} | train loss {'Reaction outcome loss': 0.16773930662530154, 'Total loss': 0.16773930662530154}
2023-01-05 06:07:36,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:36,895 INFO:     Epoch: 83
2023-01-05 06:07:39,167 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4893137832482656, 'Total loss': 0.4893137832482656} | train loss {'Reaction outcome loss': 0.16714695022048073, 'Total loss': 0.16714695022048073}
2023-01-05 06:07:39,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:39,167 INFO:     Epoch: 84
2023-01-05 06:07:41,465 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5323628743489583, 'Total loss': 0.5323628743489583} | train loss {'Reaction outcome loss': 0.1652803273101603, 'Total loss': 0.1652803273101603}
2023-01-05 06:07:41,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:41,466 INFO:     Epoch: 85
2023-01-05 06:07:43,760 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.513321069876353, 'Total loss': 0.513321069876353} | train loss {'Reaction outcome loss': 0.16515496022669793, 'Total loss': 0.16515496022669793}
2023-01-05 06:07:43,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:43,760 INFO:     Epoch: 86
2023-01-05 06:07:46,011 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5107452223698298, 'Total loss': 0.5107452223698298} | train loss {'Reaction outcome loss': 0.170051598840726, 'Total loss': 0.170051598840726}
2023-01-05 06:07:46,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:46,011 INFO:     Epoch: 87
2023-01-05 06:07:48,325 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48972898224989575, 'Total loss': 0.48972898224989575} | train loss {'Reaction outcome loss': 0.16631617739171273, 'Total loss': 0.16631617739171273}
2023-01-05 06:07:48,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:48,325 INFO:     Epoch: 88
2023-01-05 06:07:50,610 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5114934414625167, 'Total loss': 0.5114934414625167} | train loss {'Reaction outcome loss': 0.1708985536866939, 'Total loss': 0.1708985536866939}
2023-01-05 06:07:50,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:50,611 INFO:     Epoch: 89
2023-01-05 06:07:52,911 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47661175082127255, 'Total loss': 0.47661175082127255} | train loss {'Reaction outcome loss': 0.16777303902976995, 'Total loss': 0.16777303902976995}
2023-01-05 06:07:52,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:52,911 INFO:     Epoch: 90
2023-01-05 06:07:55,213 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5205742905537287, 'Total loss': 0.5205742905537287} | train loss {'Reaction outcome loss': 0.16753553879188393, 'Total loss': 0.16753553879188393}
2023-01-05 06:07:55,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:55,214 INFO:     Epoch: 91
2023-01-05 06:07:57,488 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4925260196129481, 'Total loss': 0.4925260196129481} | train loss {'Reaction outcome loss': 0.1661353278384016, 'Total loss': 0.1661353278384016}
2023-01-05 06:07:57,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:57,488 INFO:     Epoch: 92
2023-01-05 06:07:59,772 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.501858972509702, 'Total loss': 0.501858972509702} | train loss {'Reaction outcome loss': 0.16610313190772646, 'Total loss': 0.16610313190772646}
2023-01-05 06:07:59,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:07:59,772 INFO:     Epoch: 93
2023-01-05 06:08:02,008 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49980119268099465, 'Total loss': 0.49980119268099465} | train loss {'Reaction outcome loss': 0.16354138021095108, 'Total loss': 0.16354138021095108}
2023-01-05 06:08:02,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:02,008 INFO:     Epoch: 94
2023-01-05 06:08:04,295 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5276132961114247, 'Total loss': 0.5276132961114247} | train loss {'Reaction outcome loss': 0.16421004975154083, 'Total loss': 0.16421004975154083}
2023-01-05 06:08:04,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:04,295 INFO:     Epoch: 95
2023-01-05 06:08:06,556 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5555202960968018, 'Total loss': 0.5555202960968018} | train loss {'Reaction outcome loss': 0.16339031708786525, 'Total loss': 0.16339031708786525}
2023-01-05 06:08:06,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:06,558 INFO:     Epoch: 96
2023-01-05 06:08:08,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48580020864804585, 'Total loss': 0.48580020864804585} | train loss {'Reaction outcome loss': 0.16045490178256044, 'Total loss': 0.16045490178256044}
2023-01-05 06:08:08,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:08,844 INFO:     Epoch: 97
2023-01-05 06:08:11,125 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5045178472995758, 'Total loss': 0.5045178472995758} | train loss {'Reaction outcome loss': 0.16189407263394942, 'Total loss': 0.16189407263394942}
2023-01-05 06:08:11,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:11,125 INFO:     Epoch: 98
2023-01-05 06:08:13,420 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5228416850169499, 'Total loss': 0.5228416850169499} | train loss {'Reaction outcome loss': 0.16014088842923677, 'Total loss': 0.16014088842923677}
2023-01-05 06:08:13,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:13,421 INFO:     Epoch: 99
2023-01-05 06:08:15,703 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5081379423538844, 'Total loss': 0.5081379423538844} | train loss {'Reaction outcome loss': 0.1588222701270604, 'Total loss': 0.1588222701270604}
2023-01-05 06:08:15,703 INFO:     Best model found after epoch 6 of 100.
2023-01-05 06:08:15,703 INFO:   Done with stage: TRAINING
2023-01-05 06:08:15,703 INFO:   Starting stage: EVALUATION
2023-01-05 06:08:15,833 INFO:   Done with stage: EVALUATION
2023-01-05 06:08:15,833 INFO:   Leaving out SEQ value Fold_5
2023-01-05 06:08:15,846 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 06:08:15,846 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:08:16,499 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:08:16,499 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:08:16,572 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:08:16,572 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:08:16,572 INFO:     No hyperparam tuning for this model
2023-01-05 06:08:16,572 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:08:16,572 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:08:16,573 INFO:     None feature selector for col prot
2023-01-05 06:08:16,573 INFO:     None feature selector for col prot
2023-01-05 06:08:16,573 INFO:     None feature selector for col prot
2023-01-05 06:08:16,574 INFO:     None feature selector for col chem
2023-01-05 06:08:16,574 INFO:     None feature selector for col chem
2023-01-05 06:08:16,574 INFO:     None feature selector for col chem
2023-01-05 06:08:16,574 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:08:16,574 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:08:16,576 INFO:     Number of params in model 72931
2023-01-05 06:08:16,579 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:08:16,579 INFO:   Starting stage: TRAINING
2023-01-05 06:08:16,639 INFO:     Val loss before train {'Reaction outcome loss': 0.8593220392862956, 'Total loss': 0.8593220392862956}
2023-01-05 06:08:16,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:16,639 INFO:     Epoch: 0
2023-01-05 06:08:18,899 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7345963517824808, 'Total loss': 0.7345963517824808} | train loss {'Reaction outcome loss': 0.9588706286719245, 'Total loss': 0.9588706286719245}
2023-01-05 06:08:18,899 INFO:     Found new best model at epoch 0
2023-01-05 06:08:18,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:18,900 INFO:     Epoch: 1
2023-01-05 06:08:21,136 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5361663659413656, 'Total loss': 0.5361663659413656} | train loss {'Reaction outcome loss': 0.6516765140160157, 'Total loss': 0.6516765140160157}
2023-01-05 06:08:21,136 INFO:     Found new best model at epoch 1
2023-01-05 06:08:21,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:21,138 INFO:     Epoch: 2
2023-01-05 06:08:23,400 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5130774279435476, 'Total loss': 0.5130774279435476} | train loss {'Reaction outcome loss': 0.545906682519147, 'Total loss': 0.545906682519147}
2023-01-05 06:08:23,400 INFO:     Found new best model at epoch 2
2023-01-05 06:08:23,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:23,402 INFO:     Epoch: 3
2023-01-05 06:08:25,656 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49340416193008424, 'Total loss': 0.49340416193008424} | train loss {'Reaction outcome loss': 0.5127656013861189, 'Total loss': 0.5127656013861189}
2023-01-05 06:08:25,656 INFO:     Found new best model at epoch 3
2023-01-05 06:08:25,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:25,658 INFO:     Epoch: 4
2023-01-05 06:08:27,967 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4750439663728078, 'Total loss': 0.4750439663728078} | train loss {'Reaction outcome loss': 0.4816846671330668, 'Total loss': 0.4816846671330668}
2023-01-05 06:08:27,967 INFO:     Found new best model at epoch 4
2023-01-05 06:08:27,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:27,968 INFO:     Epoch: 5
2023-01-05 06:08:30,242 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4641918996969859, 'Total loss': 0.4641918996969859} | train loss {'Reaction outcome loss': 0.4570585614355811, 'Total loss': 0.4570585614355811}
2023-01-05 06:08:30,242 INFO:     Found new best model at epoch 5
2023-01-05 06:08:30,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:30,244 INFO:     Epoch: 6
2023-01-05 06:08:32,465 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4457567562659582, 'Total loss': 0.4457567562659582} | train loss {'Reaction outcome loss': 0.44119907428857186, 'Total loss': 0.44119907428857186}
2023-01-05 06:08:32,466 INFO:     Found new best model at epoch 6
2023-01-05 06:08:32,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:32,467 INFO:     Epoch: 7
2023-01-05 06:08:34,728 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4374194453159968, 'Total loss': 0.4374194453159968} | train loss {'Reaction outcome loss': 0.42434537353633095, 'Total loss': 0.42434537353633095}
2023-01-05 06:08:34,728 INFO:     Found new best model at epoch 7
2023-01-05 06:08:34,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:34,729 INFO:     Epoch: 8
2023-01-05 06:08:36,956 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4579484979311625, 'Total loss': 0.4579484979311625} | train loss {'Reaction outcome loss': 0.4120377360088547, 'Total loss': 0.4120377360088547}
2023-01-05 06:08:36,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:36,957 INFO:     Epoch: 9
2023-01-05 06:08:39,203 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4256166726350784, 'Total loss': 0.4256166726350784} | train loss {'Reaction outcome loss': 0.39942737467532613, 'Total loss': 0.39942737467532613}
2023-01-05 06:08:39,203 INFO:     Found new best model at epoch 9
2023-01-05 06:08:39,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:39,204 INFO:     Epoch: 10
2023-01-05 06:08:41,430 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42686525781949364, 'Total loss': 0.42686525781949364} | train loss {'Reaction outcome loss': 0.3869923862771396, 'Total loss': 0.3869923862771396}
2023-01-05 06:08:41,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:41,431 INFO:     Epoch: 11
2023-01-05 06:08:43,655 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4317885557810465, 'Total loss': 0.4317885557810465} | train loss {'Reaction outcome loss': 0.3845448068676204, 'Total loss': 0.3845448068676204}
2023-01-05 06:08:43,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:43,656 INFO:     Epoch: 12
2023-01-05 06:08:45,922 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40975107351938883, 'Total loss': 0.40975107351938883} | train loss {'Reaction outcome loss': 0.3686343947846959, 'Total loss': 0.3686343947846959}
2023-01-05 06:08:45,922 INFO:     Found new best model at epoch 12
2023-01-05 06:08:45,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:45,923 INFO:     Epoch: 13
2023-01-05 06:08:48,138 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3999949127435684, 'Total loss': 0.3999949127435684} | train loss {'Reaction outcome loss': 0.3584052043674636, 'Total loss': 0.3584052043674636}
2023-01-05 06:08:48,138 INFO:     Found new best model at epoch 13
2023-01-05 06:08:48,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:48,139 INFO:     Epoch: 14
2023-01-05 06:08:50,388 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4289201368888219, 'Total loss': 0.4289201368888219} | train loss {'Reaction outcome loss': 0.3500795884289011, 'Total loss': 0.3500795884289011}
2023-01-05 06:08:50,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:50,388 INFO:     Epoch: 15
2023-01-05 06:08:52,616 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4118909647067388, 'Total loss': 0.4118909647067388} | train loss {'Reaction outcome loss': 0.34701296571560586, 'Total loss': 0.34701296571560586}
2023-01-05 06:08:52,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:52,617 INFO:     Epoch: 16
2023-01-05 06:08:54,874 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3919259250164032, 'Total loss': 0.3919259250164032} | train loss {'Reaction outcome loss': 0.3356522912309118, 'Total loss': 0.3356522912309118}
2023-01-05 06:08:54,874 INFO:     Found new best model at epoch 16
2023-01-05 06:08:54,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:54,876 INFO:     Epoch: 17
2023-01-05 06:08:57,137 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3807587285836538, 'Total loss': 0.3807587285836538} | train loss {'Reaction outcome loss': 0.33047187937437184, 'Total loss': 0.33047187937437184}
2023-01-05 06:08:57,137 INFO:     Found new best model at epoch 17
2023-01-05 06:08:57,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:57,139 INFO:     Epoch: 18
2023-01-05 06:08:59,407 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3906975775957108, 'Total loss': 0.3906975775957108} | train loss {'Reaction outcome loss': 0.32748480282560755, 'Total loss': 0.32748480282560755}
2023-01-05 06:08:59,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:08:59,407 INFO:     Epoch: 19
2023-01-05 06:09:01,640 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4296906014283498, 'Total loss': 0.4296906014283498} | train loss {'Reaction outcome loss': 0.3127898528736873, 'Total loss': 0.3127898528736873}
2023-01-05 06:09:01,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:01,640 INFO:     Epoch: 20
2023-01-05 06:09:03,873 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4182515501976013, 'Total loss': 0.4182515501976013} | train loss {'Reaction outcome loss': 0.30737230465849386, 'Total loss': 0.30737230465849386}
2023-01-05 06:09:03,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:03,873 INFO:     Epoch: 21
2023-01-05 06:09:06,119 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.426858001947403, 'Total loss': 0.426858001947403} | train loss {'Reaction outcome loss': 0.3032788184886105, 'Total loss': 0.3032788184886105}
2023-01-05 06:09:06,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:06,121 INFO:     Epoch: 22
2023-01-05 06:09:08,371 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46728760600090025, 'Total loss': 0.46728760600090025} | train loss {'Reaction outcome loss': 0.2963448570646944, 'Total loss': 0.2963448570646944}
2023-01-05 06:09:08,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:08,372 INFO:     Epoch: 23
2023-01-05 06:09:10,628 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44764681657155353, 'Total loss': 0.44764681657155353} | train loss {'Reaction outcome loss': 0.2961811427040583, 'Total loss': 0.2961811427040583}
2023-01-05 06:09:10,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:10,628 INFO:     Epoch: 24
2023-01-05 06:09:12,886 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4494568437337875, 'Total loss': 0.4494568437337875} | train loss {'Reaction outcome loss': 0.28688803595239226, 'Total loss': 0.28688803595239226}
2023-01-05 06:09:12,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:12,887 INFO:     Epoch: 25
2023-01-05 06:09:15,143 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4206246574719747, 'Total loss': 0.4206246574719747} | train loss {'Reaction outcome loss': 0.28439145047136033, 'Total loss': 0.28439145047136033}
2023-01-05 06:09:15,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:15,143 INFO:     Epoch: 26
2023-01-05 06:09:17,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4515275994936625, 'Total loss': 0.4515275994936625} | train loss {'Reaction outcome loss': 0.27746981556398154, 'Total loss': 0.27746981556398154}
2023-01-05 06:09:17,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:17,382 INFO:     Epoch: 27
2023-01-05 06:09:19,644 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4511004755894343, 'Total loss': 0.4511004755894343} | train loss {'Reaction outcome loss': 0.27467117850145284, 'Total loss': 0.27467117850145284}
2023-01-05 06:09:19,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:19,644 INFO:     Epoch: 28
2023-01-05 06:09:21,846 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45271907846132914, 'Total loss': 0.45271907846132914} | train loss {'Reaction outcome loss': 0.26943023564008467, 'Total loss': 0.26943023564008467}
2023-01-05 06:09:21,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:21,846 INFO:     Epoch: 29
2023-01-05 06:09:24,100 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43120599587758385, 'Total loss': 0.43120599587758385} | train loss {'Reaction outcome loss': 0.26646147622135435, 'Total loss': 0.26646147622135435}
2023-01-05 06:09:24,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:24,100 INFO:     Epoch: 30
2023-01-05 06:09:26,367 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44504903107881544, 'Total loss': 0.44504903107881544} | train loss {'Reaction outcome loss': 0.26463056352995606, 'Total loss': 0.26463056352995606}
2023-01-05 06:09:26,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:26,368 INFO:     Epoch: 31
2023-01-05 06:09:28,615 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4284117380777995, 'Total loss': 0.4284117380777995} | train loss {'Reaction outcome loss': 0.26133135355410786, 'Total loss': 0.26133135355410786}
2023-01-05 06:09:28,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:28,615 INFO:     Epoch: 32
2023-01-05 06:09:30,868 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44214266041914624, 'Total loss': 0.44214266041914624} | train loss {'Reaction outcome loss': 0.2572970996971113, 'Total loss': 0.2572970996971113}
2023-01-05 06:09:30,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:30,868 INFO:     Epoch: 33
2023-01-05 06:09:33,098 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44669529298941296, 'Total loss': 0.44669529298941296} | train loss {'Reaction outcome loss': 0.2554564835694041, 'Total loss': 0.2554564835694041}
2023-01-05 06:09:33,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:33,098 INFO:     Epoch: 34
2023-01-05 06:09:35,206 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43693463255961734, 'Total loss': 0.43693463255961734} | train loss {'Reaction outcome loss': 0.24849497553396183, 'Total loss': 0.24849497553396183}
2023-01-05 06:09:35,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:35,207 INFO:     Epoch: 35
2023-01-05 06:09:37,449 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4692125340302785, 'Total loss': 0.4692125340302785} | train loss {'Reaction outcome loss': 0.24366601138464072, 'Total loss': 0.24366601138464072}
2023-01-05 06:09:37,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:37,449 INFO:     Epoch: 36
2023-01-05 06:09:39,697 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45058311422665914, 'Total loss': 0.45058311422665914} | train loss {'Reaction outcome loss': 0.24546946246299323, 'Total loss': 0.24546946246299323}
2023-01-05 06:09:39,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:39,697 INFO:     Epoch: 37
2023-01-05 06:09:41,678 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39384679098924, 'Total loss': 0.39384679098924} | train loss {'Reaction outcome loss': 0.24323611603845863, 'Total loss': 0.24323611603845863}
2023-01-05 06:09:41,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:41,680 INFO:     Epoch: 38
2023-01-05 06:09:43,558 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4328774198889732, 'Total loss': 0.4328774198889732} | train loss {'Reaction outcome loss': 0.23764651180346952, 'Total loss': 0.23764651180346952}
2023-01-05 06:09:43,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:43,558 INFO:     Epoch: 39
2023-01-05 06:09:45,585 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43012911776701607, 'Total loss': 0.43012911776701607} | train loss {'Reaction outcome loss': 0.23821969737849422, 'Total loss': 0.23821969737849422}
2023-01-05 06:09:45,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:45,586 INFO:     Epoch: 40
2023-01-05 06:09:47,833 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4083267331123352, 'Total loss': 0.4083267331123352} | train loss {'Reaction outcome loss': 0.23268344045453535, 'Total loss': 0.23268344045453535}
2023-01-05 06:09:47,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:47,834 INFO:     Epoch: 41
2023-01-05 06:09:50,079 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4639353786905607, 'Total loss': 0.4639353786905607} | train loss {'Reaction outcome loss': 0.23066356493989482, 'Total loss': 0.23066356493989482}
2023-01-05 06:09:50,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:50,079 INFO:     Epoch: 42
2023-01-05 06:09:52,255 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41779144406318663, 'Total loss': 0.41779144406318663} | train loss {'Reaction outcome loss': 0.22931079072265947, 'Total loss': 0.22931079072265947}
2023-01-05 06:09:52,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:52,256 INFO:     Epoch: 43
2023-01-05 06:09:54,507 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43253533244132997, 'Total loss': 0.43253533244132997} | train loss {'Reaction outcome loss': 0.22450899918067413, 'Total loss': 0.22450899918067413}
2023-01-05 06:09:54,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:54,508 INFO:     Epoch: 44
2023-01-05 06:09:56,746 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42190851718187333, 'Total loss': 0.42190851718187333} | train loss {'Reaction outcome loss': 0.22255523695209384, 'Total loss': 0.22255523695209384}
2023-01-05 06:09:56,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:56,747 INFO:     Epoch: 45
2023-01-05 06:09:58,978 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41513877709706626, 'Total loss': 0.41513877709706626} | train loss {'Reaction outcome loss': 0.21989426550448593, 'Total loss': 0.21989426550448593}
2023-01-05 06:09:58,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:09:58,978 INFO:     Epoch: 46
2023-01-05 06:10:01,180 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45000116527080536, 'Total loss': 0.45000116527080536} | train loss {'Reaction outcome loss': 0.2218649166629371, 'Total loss': 0.2218649166629371}
2023-01-05 06:10:01,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:01,180 INFO:     Epoch: 47
2023-01-05 06:10:03,370 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4385074694951375, 'Total loss': 0.4385074694951375} | train loss {'Reaction outcome loss': 0.217988875674179, 'Total loss': 0.217988875674179}
2023-01-05 06:10:03,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:03,370 INFO:     Epoch: 48
2023-01-05 06:10:05,524 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4644299934307734, 'Total loss': 0.4644299934307734} | train loss {'Reaction outcome loss': 0.21990979040707767, 'Total loss': 0.21990979040707767}
2023-01-05 06:10:05,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:05,524 INFO:     Epoch: 49
2023-01-05 06:10:07,785 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4260726352532705, 'Total loss': 0.4260726352532705} | train loss {'Reaction outcome loss': 0.210495135549755, 'Total loss': 0.210495135549755}
2023-01-05 06:10:07,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:07,785 INFO:     Epoch: 50
2023-01-05 06:10:09,974 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43355718851089475, 'Total loss': 0.43355718851089475} | train loss {'Reaction outcome loss': 0.21292934972915228, 'Total loss': 0.21292934972915228}
2023-01-05 06:10:09,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:09,974 INFO:     Epoch: 51
2023-01-05 06:10:12,217 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.465461332599322, 'Total loss': 0.465461332599322} | train loss {'Reaction outcome loss': 0.21165758336853427, 'Total loss': 0.21165758336853427}
2023-01-05 06:10:12,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:12,218 INFO:     Epoch: 52
2023-01-05 06:10:14,463 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4186959981918335, 'Total loss': 0.4186959981918335} | train loss {'Reaction outcome loss': 0.2069382733056988, 'Total loss': 0.2069382733056988}
2023-01-05 06:10:14,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:14,463 INFO:     Epoch: 53
2023-01-05 06:10:16,628 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42346782286961876, 'Total loss': 0.42346782286961876} | train loss {'Reaction outcome loss': 0.2082520856719165, 'Total loss': 0.2082520856719165}
2023-01-05 06:10:16,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:16,629 INFO:     Epoch: 54
2023-01-05 06:10:18,877 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46973624428113303, 'Total loss': 0.46973624428113303} | train loss {'Reaction outcome loss': 0.20412307744845748, 'Total loss': 0.20412307744845748}
2023-01-05 06:10:18,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:18,878 INFO:     Epoch: 55
2023-01-05 06:10:21,077 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42797906597455343, 'Total loss': 0.42797906597455343} | train loss {'Reaction outcome loss': 0.20148425751508478, 'Total loss': 0.20148425751508478}
2023-01-05 06:10:21,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:21,078 INFO:     Epoch: 56
2023-01-05 06:10:23,312 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42257626354694366, 'Total loss': 0.42257626354694366} | train loss {'Reaction outcome loss': 0.20439303326114577, 'Total loss': 0.20439303326114577}
2023-01-05 06:10:23,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:23,312 INFO:     Epoch: 57
2023-01-05 06:10:25,595 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4630513181289037, 'Total loss': 0.4630513181289037} | train loss {'Reaction outcome loss': 0.20373604696135234, 'Total loss': 0.20373604696135234}
2023-01-05 06:10:25,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:25,596 INFO:     Epoch: 58
2023-01-05 06:10:27,856 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4024852102001508, 'Total loss': 0.4024852102001508} | train loss {'Reaction outcome loss': 0.20079647707514955, 'Total loss': 0.20079647707514955}
2023-01-05 06:10:27,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:27,856 INFO:     Epoch: 59
2023-01-05 06:10:30,173 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45373530164361, 'Total loss': 0.45373530164361} | train loss {'Reaction outcome loss': 0.20097873481942247, 'Total loss': 0.20097873481942247}
2023-01-05 06:10:30,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:30,173 INFO:     Epoch: 60
2023-01-05 06:10:32,456 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.476510892311732, 'Total loss': 0.476510892311732} | train loss {'Reaction outcome loss': 0.1972835037915077, 'Total loss': 0.1972835037915077}
2023-01-05 06:10:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:32,456 INFO:     Epoch: 61
2023-01-05 06:10:34,668 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4671282132466634, 'Total loss': 0.4671282132466634} | train loss {'Reaction outcome loss': 0.19530713671383304, 'Total loss': 0.19530713671383304}
2023-01-05 06:10:34,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:34,668 INFO:     Epoch: 62
2023-01-05 06:10:36,935 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4398087422053019, 'Total loss': 0.4398087422053019} | train loss {'Reaction outcome loss': 0.19544799386244946, 'Total loss': 0.19544799386244946}
2023-01-05 06:10:36,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:36,936 INFO:     Epoch: 63
2023-01-05 06:10:39,190 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4290664797027906, 'Total loss': 0.4290664797027906} | train loss {'Reaction outcome loss': 0.19525677909272432, 'Total loss': 0.19525677909272432}
2023-01-05 06:10:39,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:39,191 INFO:     Epoch: 64
2023-01-05 06:10:41,452 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4454284330209096, 'Total loss': 0.4454284330209096} | train loss {'Reaction outcome loss': 0.19326724971127934, 'Total loss': 0.19326724971127934}
2023-01-05 06:10:41,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:41,452 INFO:     Epoch: 65
2023-01-05 06:10:43,690 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44268455108006793, 'Total loss': 0.44268455108006793} | train loss {'Reaction outcome loss': 0.1929416910024618, 'Total loss': 0.1929416910024618}
2023-01-05 06:10:43,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:43,690 INFO:     Epoch: 66
2023-01-05 06:10:45,929 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4392213753114144, 'Total loss': 0.4392213753114144} | train loss {'Reaction outcome loss': 0.19255990605039972, 'Total loss': 0.19255990605039972}
2023-01-05 06:10:45,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:45,930 INFO:     Epoch: 67
2023-01-05 06:10:48,183 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42970002194245654, 'Total loss': 0.42970002194245654} | train loss {'Reaction outcome loss': 0.18747099843827914, 'Total loss': 0.18747099843827914}
2023-01-05 06:10:48,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:48,184 INFO:     Epoch: 68
2023-01-05 06:10:50,450 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41917933424313863, 'Total loss': 0.41917933424313863} | train loss {'Reaction outcome loss': 0.18686377575253918, 'Total loss': 0.18686377575253918}
2023-01-05 06:10:50,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:50,451 INFO:     Epoch: 69
2023-01-05 06:10:52,711 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4302295337120692, 'Total loss': 0.4302295337120692} | train loss {'Reaction outcome loss': 0.19139624400621782, 'Total loss': 0.19139624400621782}
2023-01-05 06:10:52,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:52,711 INFO:     Epoch: 70
2023-01-05 06:10:54,947 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45996865729490916, 'Total loss': 0.45996865729490916} | train loss {'Reaction outcome loss': 0.1818917684671707, 'Total loss': 0.1818917684671707}
2023-01-05 06:10:54,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:54,948 INFO:     Epoch: 71
2023-01-05 06:10:57,203 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4514543205499649, 'Total loss': 0.4514543205499649} | train loss {'Reaction outcome loss': 0.18643354832187947, 'Total loss': 0.18643354832187947}
2023-01-05 06:10:57,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:57,203 INFO:     Epoch: 72
2023-01-05 06:10:59,459 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43818132306138674, 'Total loss': 0.43818132306138674} | train loss {'Reaction outcome loss': 0.18265331126273657, 'Total loss': 0.18265331126273657}
2023-01-05 06:10:59,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:10:59,459 INFO:     Epoch: 73
2023-01-05 06:11:01,753 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4316597402095795, 'Total loss': 0.4316597402095795} | train loss {'Reaction outcome loss': 0.18808623415207232, 'Total loss': 0.18808623415207232}
2023-01-05 06:11:01,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:01,753 INFO:     Epoch: 74
2023-01-05 06:11:04,071 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4922840654850006, 'Total loss': 0.4922840654850006} | train loss {'Reaction outcome loss': 0.18531534716446144, 'Total loss': 0.18531534716446144}
2023-01-05 06:11:04,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:04,071 INFO:     Epoch: 75
2023-01-05 06:11:06,366 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4346228539943695, 'Total loss': 0.4346228539943695} | train loss {'Reaction outcome loss': 0.18064693822423472, 'Total loss': 0.18064693822423472}
2023-01-05 06:11:06,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:06,366 INFO:     Epoch: 76
2023-01-05 06:11:08,628 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48515843550364174, 'Total loss': 0.48515843550364174} | train loss {'Reaction outcome loss': 0.18722361216940203, 'Total loss': 0.18722361216940203}
2023-01-05 06:11:08,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:08,629 INFO:     Epoch: 77
2023-01-05 06:11:10,866 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48278702398141227, 'Total loss': 0.48278702398141227} | train loss {'Reaction outcome loss': 0.18387172960193596, 'Total loss': 0.18387172960193596}
2023-01-05 06:11:10,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:10,866 INFO:     Epoch: 78
2023-01-05 06:11:13,107 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43810855100552243, 'Total loss': 0.43810855100552243} | train loss {'Reaction outcome loss': 0.17862268136882217, 'Total loss': 0.17862268136882217}
2023-01-05 06:11:13,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:13,108 INFO:     Epoch: 79
2023-01-05 06:11:15,333 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43316497306029, 'Total loss': 0.43316497306029} | train loss {'Reaction outcome loss': 0.18719780660934582, 'Total loss': 0.18719780660934582}
2023-01-05 06:11:15,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:15,334 INFO:     Epoch: 80
2023-01-05 06:11:17,541 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47307272056738536, 'Total loss': 0.47307272056738536} | train loss {'Reaction outcome loss': 0.17967907948093148, 'Total loss': 0.17967907948093148}
2023-01-05 06:11:17,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:17,541 INFO:     Epoch: 81
2023-01-05 06:11:19,781 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45307980875174203, 'Total loss': 0.45307980875174203} | train loss {'Reaction outcome loss': 0.1794297332470951, 'Total loss': 0.1794297332470951}
2023-01-05 06:11:19,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:19,782 INFO:     Epoch: 82
2023-01-05 06:11:22,028 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4884163955847422, 'Total loss': 0.4884163955847422} | train loss {'Reaction outcome loss': 0.17634186278484817, 'Total loss': 0.17634186278484817}
2023-01-05 06:11:22,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:22,028 INFO:     Epoch: 83
2023-01-05 06:11:24,285 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4266142601768176, 'Total loss': 0.4266142601768176} | train loss {'Reaction outcome loss': 0.1786826221904561, 'Total loss': 0.1786826221904561}
2023-01-05 06:11:24,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:24,286 INFO:     Epoch: 84
2023-01-05 06:11:26,536 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4488946000734965, 'Total loss': 0.4488946000734965} | train loss {'Reaction outcome loss': 0.17752855418956953, 'Total loss': 0.17752855418956953}
2023-01-05 06:11:26,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:26,536 INFO:     Epoch: 85
2023-01-05 06:11:28,791 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4451136344422897, 'Total loss': 0.4451136344422897} | train loss {'Reaction outcome loss': 0.1728634249136858, 'Total loss': 0.1728634249136858}
2023-01-05 06:11:28,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:28,791 INFO:     Epoch: 86
2023-01-05 06:11:31,029 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44634818931420644, 'Total loss': 0.44634818931420644} | train loss {'Reaction outcome loss': 0.17333508693497546, 'Total loss': 0.17333508693497546}
2023-01-05 06:11:31,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:31,030 INFO:     Epoch: 87
2023-01-05 06:11:33,266 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4609744926293691, 'Total loss': 0.4609744926293691} | train loss {'Reaction outcome loss': 0.17083922563202297, 'Total loss': 0.17083922563202297}
2023-01-05 06:11:33,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:33,266 INFO:     Epoch: 88
2023-01-05 06:11:35,518 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5182570030291875, 'Total loss': 0.5182570030291875} | train loss {'Reaction outcome loss': 0.17594718550549426, 'Total loss': 0.17594718550549426}
2023-01-05 06:11:35,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:35,518 INFO:     Epoch: 89
2023-01-05 06:11:37,760 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4627360329031944, 'Total loss': 0.4627360329031944} | train loss {'Reaction outcome loss': 0.17799114330202667, 'Total loss': 0.17799114330202667}
2023-01-05 06:11:37,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:37,761 INFO:     Epoch: 90
2023-01-05 06:11:40,023 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4644238630930583, 'Total loss': 0.4644238630930583} | train loss {'Reaction outcome loss': 0.17158464881944993, 'Total loss': 0.17158464881944993}
2023-01-05 06:11:40,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:40,023 INFO:     Epoch: 91
2023-01-05 06:11:42,267 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4429987827936808, 'Total loss': 0.4429987827936808} | train loss {'Reaction outcome loss': 0.17490305951422583, 'Total loss': 0.17490305951422583}
2023-01-05 06:11:42,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:42,267 INFO:     Epoch: 92
2023-01-05 06:11:44,490 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48688300997018813, 'Total loss': 0.48688300997018813} | train loss {'Reaction outcome loss': 0.1712775528906797, 'Total loss': 0.1712775528906797}
2023-01-05 06:11:44,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:44,491 INFO:     Epoch: 93
2023-01-05 06:11:46,758 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5016529535253843, 'Total loss': 0.5016529535253843} | train loss {'Reaction outcome loss': 0.17168485758363874, 'Total loss': 0.17168485758363874}
2023-01-05 06:11:46,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:46,759 INFO:     Epoch: 94
2023-01-05 06:11:49,097 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49240817030270895, 'Total loss': 0.49240817030270895} | train loss {'Reaction outcome loss': 0.17234095256694043, 'Total loss': 0.17234095256694043}
2023-01-05 06:11:49,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:49,097 INFO:     Epoch: 95
2023-01-05 06:11:51,395 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4575162142515182, 'Total loss': 0.4575162142515182} | train loss {'Reaction outcome loss': 0.17434612949324405, 'Total loss': 0.17434612949324405}
2023-01-05 06:11:51,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:51,396 INFO:     Epoch: 96
2023-01-05 06:11:53,619 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4856235017379125, 'Total loss': 0.4856235017379125} | train loss {'Reaction outcome loss': 0.1740711156421606, 'Total loss': 0.1740711156421606}
2023-01-05 06:11:53,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:53,620 INFO:     Epoch: 97
2023-01-05 06:11:55,867 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44717632134755453, 'Total loss': 0.44717632134755453} | train loss {'Reaction outcome loss': 0.16684915876206363, 'Total loss': 0.16684915876206363}
2023-01-05 06:11:55,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:55,867 INFO:     Epoch: 98
2023-01-05 06:11:58,125 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.435045329729716, 'Total loss': 0.435045329729716} | train loss {'Reaction outcome loss': 0.1697306873168062, 'Total loss': 0.1697306873168062}
2023-01-05 06:11:58,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:11:58,125 INFO:     Epoch: 99
2023-01-05 06:12:00,391 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4697690188884735, 'Total loss': 0.4697690188884735} | train loss {'Reaction outcome loss': 0.17154555911721703, 'Total loss': 0.17154555911721703}
2023-01-05 06:12:00,392 INFO:     Best model found after epoch 18 of 100.
2023-01-05 06:12:00,392 INFO:   Done with stage: TRAINING
2023-01-05 06:12:00,392 INFO:   Starting stage: EVALUATION
2023-01-05 06:12:00,534 INFO:   Done with stage: EVALUATION
2023-01-05 06:12:00,535 INFO:   Leaving out SEQ value Fold_6
2023-01-05 06:12:00,547 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 06:12:00,547 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:12:01,199 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:12:01,199 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:12:01,271 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:12:01,271 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:12:01,271 INFO:     No hyperparam tuning for this model
2023-01-05 06:12:01,271 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:12:01,272 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:12:01,272 INFO:     None feature selector for col prot
2023-01-05 06:12:01,273 INFO:     None feature selector for col prot
2023-01-05 06:12:01,273 INFO:     None feature selector for col prot
2023-01-05 06:12:01,273 INFO:     None feature selector for col chem
2023-01-05 06:12:01,273 INFO:     None feature selector for col chem
2023-01-05 06:12:01,273 INFO:     None feature selector for col chem
2023-01-05 06:12:01,274 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:12:01,274 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:12:01,275 INFO:     Number of params in model 72931
2023-01-05 06:12:01,278 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:12:01,279 INFO:   Starting stage: TRAINING
2023-01-05 06:12:01,338 INFO:     Val loss before train {'Reaction outcome loss': 1.100988753636678, 'Total loss': 1.100988753636678}
2023-01-05 06:12:01,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:01,338 INFO:     Epoch: 0
2023-01-05 06:12:03,577 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7515140533447265, 'Total loss': 0.7515140533447265} | train loss {'Reaction outcome loss': 0.9107742431836251, 'Total loss': 0.9107742431836251}
2023-01-05 06:12:03,577 INFO:     Found new best model at epoch 0
2023-01-05 06:12:03,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:03,579 INFO:     Epoch: 1
2023-01-05 06:12:05,862 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5947432617346445, 'Total loss': 0.5947432617346445} | train loss {'Reaction outcome loss': 0.6053725328200903, 'Total loss': 0.6053725328200903}
2023-01-05 06:12:05,862 INFO:     Found new best model at epoch 1
2023-01-05 06:12:05,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:05,864 INFO:     Epoch: 2
2023-01-05 06:12:08,171 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5871655583381653, 'Total loss': 0.5871655583381653} | train loss {'Reaction outcome loss': 0.5256437843754178, 'Total loss': 0.5256437843754178}
2023-01-05 06:12:08,172 INFO:     Found new best model at epoch 2
2023-01-05 06:12:08,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:08,173 INFO:     Epoch: 3
2023-01-05 06:12:10,506 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5328549404939016, 'Total loss': 0.5328549404939016} | train loss {'Reaction outcome loss': 0.49097877806359597, 'Total loss': 0.49097877806359597}
2023-01-05 06:12:10,506 INFO:     Found new best model at epoch 3
2023-01-05 06:12:10,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:10,508 INFO:     Epoch: 4
2023-01-05 06:12:12,765 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5178471306959788, 'Total loss': 0.5178471306959788} | train loss {'Reaction outcome loss': 0.4645943717532979, 'Total loss': 0.4645943717532979}
2023-01-05 06:12:12,765 INFO:     Found new best model at epoch 4
2023-01-05 06:12:12,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:12,766 INFO:     Epoch: 5
2023-01-05 06:12:15,011 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.491318013270696, 'Total loss': 0.491318013270696} | train loss {'Reaction outcome loss': 0.4433043091506748, 'Total loss': 0.4433043091506748}
2023-01-05 06:12:15,011 INFO:     Found new best model at epoch 5
2023-01-05 06:12:15,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:15,013 INFO:     Epoch: 6
2023-01-05 06:12:17,225 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49499205549558006, 'Total loss': 0.49499205549558006} | train loss {'Reaction outcome loss': 0.4224862452500906, 'Total loss': 0.4224862452500906}
2023-01-05 06:12:17,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:17,226 INFO:     Epoch: 7
2023-01-05 06:12:19,429 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4550321956475576, 'Total loss': 0.4550321956475576} | train loss {'Reaction outcome loss': 0.4119271674763152, 'Total loss': 0.4119271674763152}
2023-01-05 06:12:19,429 INFO:     Found new best model at epoch 7
2023-01-05 06:12:19,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:19,430 INFO:     Epoch: 8
2023-01-05 06:12:21,643 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46522035002708434, 'Total loss': 0.46522035002708434} | train loss {'Reaction outcome loss': 0.397835441998073, 'Total loss': 0.397835441998073}
2023-01-05 06:12:21,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:21,644 INFO:     Epoch: 9
2023-01-05 06:12:23,893 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4502633631229401, 'Total loss': 0.4502633631229401} | train loss {'Reaction outcome loss': 0.3858498996430701, 'Total loss': 0.3858498996430701}
2023-01-05 06:12:23,893 INFO:     Found new best model at epoch 9
2023-01-05 06:12:23,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:23,894 INFO:     Epoch: 10
2023-01-05 06:12:26,152 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47114565372467043, 'Total loss': 0.47114565372467043} | train loss {'Reaction outcome loss': 0.37177834471503457, 'Total loss': 0.37177834471503457}
2023-01-05 06:12:26,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:26,153 INFO:     Epoch: 11
2023-01-05 06:12:28,391 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4934267818927765, 'Total loss': 0.4934267818927765} | train loss {'Reaction outcome loss': 0.36304181797818824, 'Total loss': 0.36304181797818824}
2023-01-05 06:12:28,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:28,391 INFO:     Epoch: 12
2023-01-05 06:12:30,655 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.461650005976359, 'Total loss': 0.461650005976359} | train loss {'Reaction outcome loss': 0.3559606547429885, 'Total loss': 0.3559606547429885}
2023-01-05 06:12:30,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:30,656 INFO:     Epoch: 13
2023-01-05 06:12:32,885 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4806381026903788, 'Total loss': 0.4806381026903788} | train loss {'Reaction outcome loss': 0.34441011912110964, 'Total loss': 0.34441011912110964}
2023-01-05 06:12:32,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:32,885 INFO:     Epoch: 14
2023-01-05 06:12:35,129 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4543936630090078, 'Total loss': 0.4543936630090078} | train loss {'Reaction outcome loss': 0.34096733363338444, 'Total loss': 0.34096733363338444}
2023-01-05 06:12:35,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:35,129 INFO:     Epoch: 15
2023-01-05 06:12:37,388 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49247756898403167, 'Total loss': 0.49247756898403167} | train loss {'Reaction outcome loss': 0.3289168424658723, 'Total loss': 0.3289168424658723}
2023-01-05 06:12:37,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:37,389 INFO:     Epoch: 16
2023-01-05 06:12:39,605 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.457274537285169, 'Total loss': 0.457274537285169} | train loss {'Reaction outcome loss': 0.32460390495293306, 'Total loss': 0.32460390495293306}
2023-01-05 06:12:39,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:39,605 INFO:     Epoch: 17
2023-01-05 06:12:41,877 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4605662226676941, 'Total loss': 0.4605662226676941} | train loss {'Reaction outcome loss': 0.3191703533951616, 'Total loss': 0.3191703533951616}
2023-01-05 06:12:41,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:41,877 INFO:     Epoch: 18
2023-01-05 06:12:44,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45047950943311055, 'Total loss': 0.45047950943311055} | train loss {'Reaction outcome loss': 0.3129191584202833, 'Total loss': 0.3129191584202833}
2023-01-05 06:12:44,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:44,123 INFO:     Epoch: 19
2023-01-05 06:12:46,380 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47469632426897684, 'Total loss': 0.47469632426897684} | train loss {'Reaction outcome loss': 0.30107132753445986, 'Total loss': 0.30107132753445986}
2023-01-05 06:12:46,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:46,381 INFO:     Epoch: 20
2023-01-05 06:12:48,633 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4441287149054309, 'Total loss': 0.4441287149054309} | train loss {'Reaction outcome loss': 0.29624234763871293, 'Total loss': 0.29624234763871293}
2023-01-05 06:12:48,633 INFO:     Found new best model at epoch 20
2023-01-05 06:12:48,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:48,634 INFO:     Epoch: 21
2023-01-05 06:12:50,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4629567166169484, 'Total loss': 0.4629567166169484} | train loss {'Reaction outcome loss': 0.2962657710325805, 'Total loss': 0.2962657710325805}
2023-01-05 06:12:50,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:50,881 INFO:     Epoch: 22
2023-01-05 06:12:53,138 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.511070293188095, 'Total loss': 0.511070293188095} | train loss {'Reaction outcome loss': 0.28247214684556254, 'Total loss': 0.28247214684556254}
2023-01-05 06:12:53,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:53,139 INFO:     Epoch: 23
2023-01-05 06:12:55,374 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46700543761253355, 'Total loss': 0.46700543761253355} | train loss {'Reaction outcome loss': 0.27854363306428925, 'Total loss': 0.27854363306428925}
2023-01-05 06:12:55,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:55,374 INFO:     Epoch: 24
2023-01-05 06:12:57,632 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48344292839368186, 'Total loss': 0.48344292839368186} | train loss {'Reaction outcome loss': 0.27694541202250855, 'Total loss': 0.27694541202250855}
2023-01-05 06:12:57,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:57,633 INFO:     Epoch: 25
2023-01-05 06:12:59,896 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48914782802263895, 'Total loss': 0.48914782802263895} | train loss {'Reaction outcome loss': 0.2685309915015331, 'Total loss': 0.2685309915015331}
2023-01-05 06:12:59,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:12:59,897 INFO:     Epoch: 26
2023-01-05 06:13:02,146 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49159966707229613, 'Total loss': 0.49159966707229613} | train loss {'Reaction outcome loss': 0.27016427228738976, 'Total loss': 0.27016427228738976}
2023-01-05 06:13:02,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:02,146 INFO:     Epoch: 27
2023-01-05 06:13:04,404 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4597892468174299, 'Total loss': 0.4597892468174299} | train loss {'Reaction outcome loss': 0.25873241773482425, 'Total loss': 0.25873241773482425}
2023-01-05 06:13:04,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:04,404 INFO:     Epoch: 28
2023-01-05 06:13:06,640 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5195256412029267, 'Total loss': 0.5195256412029267} | train loss {'Reaction outcome loss': 0.2548814670834349, 'Total loss': 0.2548814670834349}
2023-01-05 06:13:06,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:06,641 INFO:     Epoch: 29
2023-01-05 06:13:08,908 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48010737299919126, 'Total loss': 0.48010737299919126} | train loss {'Reaction outcome loss': 0.2506514062487517, 'Total loss': 0.2506514062487517}
2023-01-05 06:13:08,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:08,908 INFO:     Epoch: 30
2023-01-05 06:13:11,172 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47013940413792926, 'Total loss': 0.47013940413792926} | train loss {'Reaction outcome loss': 0.250654112220138, 'Total loss': 0.250654112220138}
2023-01-05 06:13:11,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:11,172 INFO:     Epoch: 31
2023-01-05 06:13:13,427 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5009140769640604, 'Total loss': 0.5009140769640604} | train loss {'Reaction outcome loss': 0.24523836248741918, 'Total loss': 0.24523836248741918}
2023-01-05 06:13:13,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:13,428 INFO:     Epoch: 32
2023-01-05 06:13:15,656 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4853975872198741, 'Total loss': 0.4853975872198741} | train loss {'Reaction outcome loss': 0.24284889876856144, 'Total loss': 0.24284889876856144}
2023-01-05 06:13:15,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:15,657 INFO:     Epoch: 33
2023-01-05 06:13:17,897 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48488404353459674, 'Total loss': 0.48488404353459674} | train loss {'Reaction outcome loss': 0.2379090224252843, 'Total loss': 0.2379090224252843}
2023-01-05 06:13:17,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:17,898 INFO:     Epoch: 34
2023-01-05 06:13:20,157 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5028565148512523, 'Total loss': 0.5028565148512523} | train loss {'Reaction outcome loss': 0.23357964975029338, 'Total loss': 0.23357964975029338}
2023-01-05 06:13:20,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:20,157 INFO:     Epoch: 35
2023-01-05 06:13:22,364 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48917444547017414, 'Total loss': 0.48917444547017414} | train loss {'Reaction outcome loss': 0.24055543062260082, 'Total loss': 0.24055543062260082}
2023-01-05 06:13:22,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:22,364 INFO:     Epoch: 36
2023-01-05 06:13:24,618 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5091561237970988, 'Total loss': 0.5091561237970988} | train loss {'Reaction outcome loss': 0.2255191065289162, 'Total loss': 0.2255191065289162}
2023-01-05 06:13:24,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:24,618 INFO:     Epoch: 37
2023-01-05 06:13:26,857 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5142119228839874, 'Total loss': 0.5142119228839874} | train loss {'Reaction outcome loss': 0.2171643774669904, 'Total loss': 0.2171643774669904}
2023-01-05 06:13:26,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:26,858 INFO:     Epoch: 38
2023-01-05 06:13:29,057 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.497976952791214, 'Total loss': 0.497976952791214} | train loss {'Reaction outcome loss': 0.22031378768548204, 'Total loss': 0.22031378768548204}
2023-01-05 06:13:29,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:29,057 INFO:     Epoch: 39
2023-01-05 06:13:31,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5220454980929693, 'Total loss': 0.5220454980929693} | train loss {'Reaction outcome loss': 0.21831288830387396, 'Total loss': 0.21831288830387396}
2023-01-05 06:13:31,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:31,305 INFO:     Epoch: 40
2023-01-05 06:13:33,542 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5313243985176086, 'Total loss': 0.5313243985176086} | train loss {'Reaction outcome loss': 0.2118684203933665, 'Total loss': 0.2118684203933665}
2023-01-05 06:13:33,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:33,542 INFO:     Epoch: 41
2023-01-05 06:13:35,790 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49172731339931486, 'Total loss': 0.49172731339931486} | train loss {'Reaction outcome loss': 0.2106053598818707, 'Total loss': 0.2106053598818707}
2023-01-05 06:13:35,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:35,791 INFO:     Epoch: 42
2023-01-05 06:13:38,029 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48859962324301404, 'Total loss': 0.48859962324301404} | train loss {'Reaction outcome loss': 0.20757279430444425, 'Total loss': 0.20757279430444425}
2023-01-05 06:13:38,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:38,029 INFO:     Epoch: 43
2023-01-05 06:13:40,276 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5284418592850367, 'Total loss': 0.5284418592850367} | train loss {'Reaction outcome loss': 0.20893329995660445, 'Total loss': 0.20893329995660445}
2023-01-05 06:13:40,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:40,276 INFO:     Epoch: 44
2023-01-05 06:13:42,416 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5479100108146667, 'Total loss': 0.5479100108146667} | train loss {'Reaction outcome loss': 0.20303855630340595, 'Total loss': 0.20303855630340595}
2023-01-05 06:13:42,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:42,418 INFO:     Epoch: 45
2023-01-05 06:13:44,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.581299078464508, 'Total loss': 0.581299078464508} | train loss {'Reaction outcome loss': 0.2040376130887222, 'Total loss': 0.2040376130887222}
2023-01-05 06:13:44,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:44,542 INFO:     Epoch: 46
2023-01-05 06:13:46,737 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.521547116835912, 'Total loss': 0.521547116835912} | train loss {'Reaction outcome loss': 0.2025092400392115, 'Total loss': 0.2025092400392115}
2023-01-05 06:13:46,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:46,737 INFO:     Epoch: 47
2023-01-05 06:13:49,053 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5082066655158997, 'Total loss': 0.5082066655158997} | train loss {'Reaction outcome loss': 0.19452477493852158, 'Total loss': 0.19452477493852158}
2023-01-05 06:13:49,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:49,054 INFO:     Epoch: 48
2023-01-05 06:13:51,342 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5229943513870239, 'Total loss': 0.5229943513870239} | train loss {'Reaction outcome loss': 0.1962093357602305, 'Total loss': 0.1962093357602305}
2023-01-05 06:13:51,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:51,342 INFO:     Epoch: 49
2023-01-05 06:13:53,552 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5266800423463186, 'Total loss': 0.5266800423463186} | train loss {'Reaction outcome loss': 0.19577549050490445, 'Total loss': 0.19577549050490445}
2023-01-05 06:13:53,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:53,552 INFO:     Epoch: 50
2023-01-05 06:13:55,797 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.533894270658493, 'Total loss': 0.533894270658493} | train loss {'Reaction outcome loss': 0.19813495391345287, 'Total loss': 0.19813495391345287}
2023-01-05 06:13:55,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:55,797 INFO:     Epoch: 51
2023-01-05 06:13:58,067 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5360084811846415, 'Total loss': 0.5360084811846415} | train loss {'Reaction outcome loss': 0.18966266644552296, 'Total loss': 0.18966266644552296}
2023-01-05 06:13:58,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:13:58,067 INFO:     Epoch: 52
2023-01-05 06:14:00,207 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5325699081023534, 'Total loss': 0.5325699081023534} | train loss {'Reaction outcome loss': 0.18742667090134088, 'Total loss': 0.18742667090134088}
2023-01-05 06:14:00,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:00,207 INFO:     Epoch: 53
2023-01-05 06:14:02,490 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.524431053797404, 'Total loss': 0.524431053797404} | train loss {'Reaction outcome loss': 0.19224336436325376, 'Total loss': 0.19224336436325376}
2023-01-05 06:14:02,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:02,491 INFO:     Epoch: 54
2023-01-05 06:14:04,743 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5336910823980967, 'Total loss': 0.5336910823980967} | train loss {'Reaction outcome loss': 0.18107481168381762, 'Total loss': 0.18107481168381762}
2023-01-05 06:14:04,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:04,744 INFO:     Epoch: 55
2023-01-05 06:14:06,977 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.521075310309728, 'Total loss': 0.521075310309728} | train loss {'Reaction outcome loss': 0.1794324683932922, 'Total loss': 0.1794324683932922}
2023-01-05 06:14:06,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:06,978 INFO:     Epoch: 56
2023-01-05 06:14:09,214 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5380732794602712, 'Total loss': 0.5380732794602712} | train loss {'Reaction outcome loss': 0.18462932402534143, 'Total loss': 0.18462932402534143}
2023-01-05 06:14:09,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:09,214 INFO:     Epoch: 57
2023-01-05 06:14:11,465 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5183869689702988, 'Total loss': 0.5183869689702988} | train loss {'Reaction outcome loss': 0.18490968270725383, 'Total loss': 0.18490968270725383}
2023-01-05 06:14:11,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:11,465 INFO:     Epoch: 58
2023-01-05 06:14:13,712 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5433537403742472, 'Total loss': 0.5433537403742472} | train loss {'Reaction outcome loss': 0.17952740278893284, 'Total loss': 0.17952740278893284}
2023-01-05 06:14:13,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:13,712 INFO:     Epoch: 59
2023-01-05 06:14:15,951 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5312893788019816, 'Total loss': 0.5312893788019816} | train loss {'Reaction outcome loss': 0.1773115838997257, 'Total loss': 0.1773115838997257}
2023-01-05 06:14:15,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:15,951 INFO:     Epoch: 60
2023-01-05 06:14:18,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5622124512990315, 'Total loss': 0.5622124512990315} | train loss {'Reaction outcome loss': 0.17946237638156057, 'Total loss': 0.17946237638156057}
2023-01-05 06:14:18,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:18,211 INFO:     Epoch: 61
2023-01-05 06:14:20,422 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5491837938626607, 'Total loss': 0.5491837938626607} | train loss {'Reaction outcome loss': 0.1813734393607784, 'Total loss': 0.1813734393607784}
2023-01-05 06:14:20,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:20,422 INFO:     Epoch: 62
2023-01-05 06:14:22,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5736217220624288, 'Total loss': 0.5736217220624288} | train loss {'Reaction outcome loss': 0.1777804453546802, 'Total loss': 0.1777804453546802}
2023-01-05 06:14:22,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:22,671 INFO:     Epoch: 63
2023-01-05 06:14:24,927 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.544371489683787, 'Total loss': 0.544371489683787} | train loss {'Reaction outcome loss': 0.1763727058393833, 'Total loss': 0.1763727058393833}
2023-01-05 06:14:24,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:24,928 INFO:     Epoch: 64
2023-01-05 06:14:27,181 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.554177118341128, 'Total loss': 0.554177118341128} | train loss {'Reaction outcome loss': 0.17044307825483054, 'Total loss': 0.17044307825483054}
2023-01-05 06:14:27,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:27,182 INFO:     Epoch: 65
2023-01-05 06:14:29,417 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5094207808375358, 'Total loss': 0.5094207808375358} | train loss {'Reaction outcome loss': 0.17199907996077704, 'Total loss': 0.17199907996077704}
2023-01-05 06:14:29,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:29,417 INFO:     Epoch: 66
2023-01-05 06:14:31,673 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5141333182652791, 'Total loss': 0.5141333182652791} | train loss {'Reaction outcome loss': 0.17657112699145308, 'Total loss': 0.17657112699145308}
2023-01-05 06:14:31,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:31,673 INFO:     Epoch: 67
2023-01-05 06:14:33,926 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.567539656162262, 'Total loss': 0.567539656162262} | train loss {'Reaction outcome loss': 0.16981740687349503, 'Total loss': 0.16981740687349503}
2023-01-05 06:14:33,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:33,926 INFO:     Epoch: 68
2023-01-05 06:14:36,159 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5633918484052022, 'Total loss': 0.5633918484052022} | train loss {'Reaction outcome loss': 0.17427363578057864, 'Total loss': 0.17427363578057864}
2023-01-05 06:14:36,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:36,160 INFO:     Epoch: 69
2023-01-05 06:14:38,393 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5530045419931412, 'Total loss': 0.5530045419931412} | train loss {'Reaction outcome loss': 0.16839350938742415, 'Total loss': 0.16839350938742415}
2023-01-05 06:14:38,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:38,394 INFO:     Epoch: 70
2023-01-05 06:14:40,617 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5053138077259064, 'Total loss': 0.5053138077259064} | train loss {'Reaction outcome loss': 0.16414059513255327, 'Total loss': 0.16414059513255327}
2023-01-05 06:14:40,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:40,617 INFO:     Epoch: 71
2023-01-05 06:14:42,869 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5504160424073538, 'Total loss': 0.5504160424073538} | train loss {'Reaction outcome loss': 0.1694365243769452, 'Total loss': 0.1694365243769452}
2023-01-05 06:14:42,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:42,870 INFO:     Epoch: 72
2023-01-05 06:14:45,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5536340256532033, 'Total loss': 0.5536340256532033} | train loss {'Reaction outcome loss': 0.16702371618058873, 'Total loss': 0.16702371618058873}
2023-01-05 06:14:45,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:45,132 INFO:     Epoch: 73
2023-01-05 06:14:47,394 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5522264063358306, 'Total loss': 0.5522264063358306} | train loss {'Reaction outcome loss': 0.16509862090955615, 'Total loss': 0.16509862090955615}
2023-01-05 06:14:47,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:47,394 INFO:     Epoch: 74
2023-01-05 06:14:49,660 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5764227112134298, 'Total loss': 0.5764227112134298} | train loss {'Reaction outcome loss': 0.16802934319251678, 'Total loss': 0.16802934319251678}
2023-01-05 06:14:49,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:49,660 INFO:     Epoch: 75
2023-01-05 06:14:51,903 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5401871939500172, 'Total loss': 0.5401871939500172} | train loss {'Reaction outcome loss': 0.16615777144817492, 'Total loss': 0.16615777144817492}
2023-01-05 06:14:51,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:51,903 INFO:     Epoch: 76
2023-01-05 06:14:54,177 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5822872320810953, 'Total loss': 0.5822872320810953} | train loss {'Reaction outcome loss': 0.16514566728176597, 'Total loss': 0.16514566728176597}
2023-01-05 06:14:54,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:54,178 INFO:     Epoch: 77
2023-01-05 06:14:56,452 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5160260220368703, 'Total loss': 0.5160260220368703} | train loss {'Reaction outcome loss': 0.162454484160239, 'Total loss': 0.162454484160239}
2023-01-05 06:14:56,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:56,453 INFO:     Epoch: 78
2023-01-05 06:14:58,725 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5782486120859782, 'Total loss': 0.5782486120859782} | train loss {'Reaction outcome loss': 0.16102451555287609, 'Total loss': 0.16102451555287609}
2023-01-05 06:14:58,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:14:58,725 INFO:     Epoch: 79
2023-01-05 06:15:00,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5689207365115484, 'Total loss': 0.5689207365115484} | train loss {'Reaction outcome loss': 0.16422389226969017, 'Total loss': 0.16422389226969017}
2023-01-05 06:15:00,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:00,994 INFO:     Epoch: 80
2023-01-05 06:15:03,234 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5443729281425476, 'Total loss': 0.5443729281425476} | train loss {'Reaction outcome loss': 0.16203217440363252, 'Total loss': 0.16203217440363252}
2023-01-05 06:15:03,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:03,234 INFO:     Epoch: 81
2023-01-05 06:15:05,489 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5634807427724202, 'Total loss': 0.5634807427724202} | train loss {'Reaction outcome loss': 0.1599677916831122, 'Total loss': 0.1599677916831122}
2023-01-05 06:15:05,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:05,490 INFO:     Epoch: 82
2023-01-05 06:15:07,753 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5268244773149491, 'Total loss': 0.5268244773149491} | train loss {'Reaction outcome loss': 0.1587531292647287, 'Total loss': 0.1587531292647287}
2023-01-05 06:15:07,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:07,754 INFO:     Epoch: 83
2023-01-05 06:15:09,993 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5797017316023508, 'Total loss': 0.5797017316023508} | train loss {'Reaction outcome loss': 0.16597386745347098, 'Total loss': 0.16597386745347098}
2023-01-05 06:15:09,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:09,993 INFO:     Epoch: 84
2023-01-05 06:15:12,248 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5201470216115316, 'Total loss': 0.5201470216115316} | train loss {'Reaction outcome loss': 0.16073196122487632, 'Total loss': 0.16073196122487632}
2023-01-05 06:15:12,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:12,249 INFO:     Epoch: 85
2023-01-05 06:15:14,502 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5168305194160591, 'Total loss': 0.5168305194160591} | train loss {'Reaction outcome loss': 0.15834667460290175, 'Total loss': 0.15834667460290175}
2023-01-05 06:15:14,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:14,503 INFO:     Epoch: 86
2023-01-05 06:15:16,704 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5542246361573537, 'Total loss': 0.5542246361573537} | train loss {'Reaction outcome loss': 0.15926701602638588, 'Total loss': 0.15926701602638588}
2023-01-05 06:15:16,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:16,704 INFO:     Epoch: 87
2023-01-05 06:15:18,943 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5443686644236246, 'Total loss': 0.5443686644236246} | train loss {'Reaction outcome loss': 0.16256381127208935, 'Total loss': 0.16256381127208935}
2023-01-05 06:15:18,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:18,943 INFO:     Epoch: 88
2023-01-05 06:15:21,171 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5483814458052317, 'Total loss': 0.5483814458052317} | train loss {'Reaction outcome loss': 0.15656994465028956, 'Total loss': 0.15656994465028956}
2023-01-05 06:15:21,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:21,171 INFO:     Epoch: 89
2023-01-05 06:15:23,430 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5317810555299123, 'Total loss': 0.5317810555299123} | train loss {'Reaction outcome loss': 0.15794466625414652, 'Total loss': 0.15794466625414652}
2023-01-05 06:15:23,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:23,430 INFO:     Epoch: 90
2023-01-05 06:15:25,655 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5637421131134033, 'Total loss': 0.5637421131134033} | train loss {'Reaction outcome loss': 0.157489253549185, 'Total loss': 0.157489253549185}
2023-01-05 06:15:25,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:25,656 INFO:     Epoch: 91
2023-01-05 06:15:27,905 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5702902505795161, 'Total loss': 0.5702902505795161} | train loss {'Reaction outcome loss': 0.15505512241758543, 'Total loss': 0.15505512241758543}
2023-01-05 06:15:27,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:27,906 INFO:     Epoch: 92
2023-01-05 06:15:30,145 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5739370266596476, 'Total loss': 0.5739370266596476} | train loss {'Reaction outcome loss': 0.15623521143246455, 'Total loss': 0.15623521143246455}
2023-01-05 06:15:30,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:30,146 INFO:     Epoch: 93
2023-01-05 06:15:32,395 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5063026746114095, 'Total loss': 0.5063026746114095} | train loss {'Reaction outcome loss': 0.15587433694687847, 'Total loss': 0.15587433694687847}
2023-01-05 06:15:32,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:32,395 INFO:     Epoch: 94
2023-01-05 06:15:34,642 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5714976439873377, 'Total loss': 0.5714976439873377} | train loss {'Reaction outcome loss': 0.15640959581326105, 'Total loss': 0.15640959581326105}
2023-01-05 06:15:34,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:34,642 INFO:     Epoch: 95
2023-01-05 06:15:36,865 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5687296787897745, 'Total loss': 0.5687296787897745} | train loss {'Reaction outcome loss': 0.15548736873959557, 'Total loss': 0.15548736873959557}
2023-01-05 06:15:36,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:36,866 INFO:     Epoch: 96
2023-01-05 06:15:39,092 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5364102005958558, 'Total loss': 0.5364102005958558} | train loss {'Reaction outcome loss': 0.15304844136837692, 'Total loss': 0.15304844136837692}
2023-01-05 06:15:39,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:39,092 INFO:     Epoch: 97
2023-01-05 06:15:41,350 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5437556078036626, 'Total loss': 0.5437556078036626} | train loss {'Reaction outcome loss': 0.15341789164621342, 'Total loss': 0.15341789164621342}
2023-01-05 06:15:41,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:41,350 INFO:     Epoch: 98
2023-01-05 06:15:43,615 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5244891837239265, 'Total loss': 0.5244891837239265} | train loss {'Reaction outcome loss': 0.15392807551280974, 'Total loss': 0.15392807551280974}
2023-01-05 06:15:43,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:43,615 INFO:     Epoch: 99
2023-01-05 06:15:45,782 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5503540714581807, 'Total loss': 0.5503540714581807} | train loss {'Reaction outcome loss': 0.15665271784939663, 'Total loss': 0.15665271784939663}
2023-01-05 06:15:45,783 INFO:     Best model found after epoch 21 of 100.
2023-01-05 06:15:45,783 INFO:   Done with stage: TRAINING
2023-01-05 06:15:45,783 INFO:   Starting stage: EVALUATION
2023-01-05 06:15:45,930 INFO:   Done with stage: EVALUATION
2023-01-05 06:15:45,930 INFO:   Leaving out SEQ value Fold_7
2023-01-05 06:15:45,943 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:15:45,943 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:15:46,594 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:15:46,594 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:15:46,668 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:15:46,668 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:15:46,668 INFO:     No hyperparam tuning for this model
2023-01-05 06:15:46,668 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:15:46,668 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:15:46,669 INFO:     None feature selector for col prot
2023-01-05 06:15:46,669 INFO:     None feature selector for col prot
2023-01-05 06:15:46,669 INFO:     None feature selector for col prot
2023-01-05 06:15:46,670 INFO:     None feature selector for col chem
2023-01-05 06:15:46,670 INFO:     None feature selector for col chem
2023-01-05 06:15:46,670 INFO:     None feature selector for col chem
2023-01-05 06:15:46,670 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:15:46,670 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:15:46,672 INFO:     Number of params in model 72931
2023-01-05 06:15:46,675 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:15:46,675 INFO:   Starting stage: TRAINING
2023-01-05 06:15:46,736 INFO:     Val loss before train {'Reaction outcome loss': 0.9879246811072032, 'Total loss': 0.9879246811072032}
2023-01-05 06:15:46,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:46,736 INFO:     Epoch: 0
2023-01-05 06:15:49,027 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7669845779736837, 'Total loss': 0.7669845779736837} | train loss {'Reaction outcome loss': 0.9279656522110481, 'Total loss': 0.9279656522110481}
2023-01-05 06:15:49,028 INFO:     Found new best model at epoch 0
2023-01-05 06:15:49,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:49,030 INFO:     Epoch: 1
2023-01-05 06:15:51,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5743237674236298, 'Total loss': 0.5743237674236298} | train loss {'Reaction outcome loss': 0.6272802970469643, 'Total loss': 0.6272802970469643}
2023-01-05 06:15:51,304 INFO:     Found new best model at epoch 1
2023-01-05 06:15:51,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:51,306 INFO:     Epoch: 2
2023-01-05 06:15:53,525 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5486838887135188, 'Total loss': 0.5486838887135188} | train loss {'Reaction outcome loss': 0.5281967499733832, 'Total loss': 0.5281967499733832}
2023-01-05 06:15:53,525 INFO:     Found new best model at epoch 2
2023-01-05 06:15:53,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:53,526 INFO:     Epoch: 3
2023-01-05 06:15:55,804 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5205750832955043, 'Total loss': 0.5205750832955043} | train loss {'Reaction outcome loss': 0.49079589701731713, 'Total loss': 0.49079589701731713}
2023-01-05 06:15:55,804 INFO:     Found new best model at epoch 3
2023-01-05 06:15:55,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:55,805 INFO:     Epoch: 4
2023-01-05 06:15:58,086 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.503368216753006, 'Total loss': 0.503368216753006} | train loss {'Reaction outcome loss': 0.46033496229442017, 'Total loss': 0.46033496229442017}
2023-01-05 06:15:58,086 INFO:     Found new best model at epoch 4
2023-01-05 06:15:58,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:15:58,088 INFO:     Epoch: 5
2023-01-05 06:16:00,363 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4756724417209625, 'Total loss': 0.4756724417209625} | train loss {'Reaction outcome loss': 0.43173972092273005, 'Total loss': 0.43173972092273005}
2023-01-05 06:16:00,363 INFO:     Found new best model at epoch 5
2023-01-05 06:16:00,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:00,364 INFO:     Epoch: 6
2023-01-05 06:16:02,614 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.488416584332784, 'Total loss': 0.488416584332784} | train loss {'Reaction outcome loss': 0.4114362628397528, 'Total loss': 0.4114362628397528}
2023-01-05 06:16:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:02,615 INFO:     Epoch: 7
2023-01-05 06:16:04,918 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47030433019002277, 'Total loss': 0.47030433019002277} | train loss {'Reaction outcome loss': 0.3936054428992289, 'Total loss': 0.3936054428992289}
2023-01-05 06:16:04,918 INFO:     Found new best model at epoch 7
2023-01-05 06:16:04,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:04,920 INFO:     Epoch: 8
2023-01-05 06:16:07,222 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4537592589855194, 'Total loss': 0.4537592589855194} | train loss {'Reaction outcome loss': 0.3796922014723616, 'Total loss': 0.3796922014723616}
2023-01-05 06:16:07,223 INFO:     Found new best model at epoch 8
2023-01-05 06:16:07,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:07,224 INFO:     Epoch: 9
2023-01-05 06:16:09,490 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47417081594467164, 'Total loss': 0.47417081594467164} | train loss {'Reaction outcome loss': 0.3692828439687133, 'Total loss': 0.3692828439687133}
2023-01-05 06:16:09,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:09,490 INFO:     Epoch: 10
2023-01-05 06:16:11,788 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46312037408351897, 'Total loss': 0.46312037408351897} | train loss {'Reaction outcome loss': 0.3553007125370339, 'Total loss': 0.3553007125370339}
2023-01-05 06:16:11,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:11,788 INFO:     Epoch: 11
2023-01-05 06:16:14,045 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45118598341941835, 'Total loss': 0.45118598341941835} | train loss {'Reaction outcome loss': 0.348048070412035, 'Total loss': 0.348048070412035}
2023-01-05 06:16:14,046 INFO:     Found new best model at epoch 11
2023-01-05 06:16:14,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:14,047 INFO:     Epoch: 12
2023-01-05 06:16:16,340 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43316948811213174, 'Total loss': 0.43316948811213174} | train loss {'Reaction outcome loss': 0.33766645549490565, 'Total loss': 0.33766645549490565}
2023-01-05 06:16:16,340 INFO:     Found new best model at epoch 12
2023-01-05 06:16:16,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:16,342 INFO:     Epoch: 13
2023-01-05 06:16:18,652 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4353243331114451, 'Total loss': 0.4353243331114451} | train loss {'Reaction outcome loss': 0.33217216238702246, 'Total loss': 0.33217216238702246}
2023-01-05 06:16:18,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:18,652 INFO:     Epoch: 14
2023-01-05 06:16:20,943 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4187829554080963, 'Total loss': 0.4187829554080963} | train loss {'Reaction outcome loss': 0.31681747220806267, 'Total loss': 0.31681747220806267}
2023-01-05 06:16:20,944 INFO:     Found new best model at epoch 14
2023-01-05 06:16:20,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:20,945 INFO:     Epoch: 15
2023-01-05 06:16:23,247 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.449906857808431, 'Total loss': 0.449906857808431} | train loss {'Reaction outcome loss': 0.31240259897676614, 'Total loss': 0.31240259897676614}
2023-01-05 06:16:23,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:23,247 INFO:     Epoch: 16
2023-01-05 06:16:25,537 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44512607852617897, 'Total loss': 0.44512607852617897} | train loss {'Reaction outcome loss': 0.3078045305738811, 'Total loss': 0.3078045305738811}
2023-01-05 06:16:25,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:25,537 INFO:     Epoch: 17
2023-01-05 06:16:27,816 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4354438602924347, 'Total loss': 0.4354438602924347} | train loss {'Reaction outcome loss': 0.30481763146414226, 'Total loss': 0.30481763146414226}
2023-01-05 06:16:27,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:27,817 INFO:     Epoch: 18
2023-01-05 06:16:30,103 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43029829263687136, 'Total loss': 0.43029829263687136} | train loss {'Reaction outcome loss': 0.29592552263330035, 'Total loss': 0.29592552263330035}
2023-01-05 06:16:30,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:30,103 INFO:     Epoch: 19
2023-01-05 06:16:32,357 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44299166401227313, 'Total loss': 0.44299166401227313} | train loss {'Reaction outcome loss': 0.2896304033992523, 'Total loss': 0.2896304033992523}
2023-01-05 06:16:32,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:32,357 INFO:     Epoch: 20
2023-01-05 06:16:34,617 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.434110501408577, 'Total loss': 0.434110501408577} | train loss {'Reaction outcome loss': 0.2852212422483665, 'Total loss': 0.2852212422483665}
2023-01-05 06:16:34,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:34,617 INFO:     Epoch: 21
2023-01-05 06:16:36,889 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4427184879779816, 'Total loss': 0.4427184879779816} | train loss {'Reaction outcome loss': 0.28393025666690475, 'Total loss': 0.28393025666690475}
2023-01-05 06:16:36,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:36,891 INFO:     Epoch: 22
2023-01-05 06:16:39,152 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41620130836963654, 'Total loss': 0.41620130836963654} | train loss {'Reaction outcome loss': 0.2745033127628939, 'Total loss': 0.2745033127628939}
2023-01-05 06:16:39,152 INFO:     Found new best model at epoch 22
2023-01-05 06:16:39,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:39,154 INFO:     Epoch: 23
2023-01-05 06:16:41,439 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.440923418601354, 'Total loss': 0.440923418601354} | train loss {'Reaction outcome loss': 0.2763417528182376, 'Total loss': 0.2763417528182376}
2023-01-05 06:16:41,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:41,439 INFO:     Epoch: 24
2023-01-05 06:16:43,715 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4283512271940708, 'Total loss': 0.4283512271940708} | train loss {'Reaction outcome loss': 0.2681967652258245, 'Total loss': 0.2681967652258245}
2023-01-05 06:16:43,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:43,716 INFO:     Epoch: 25
2023-01-05 06:16:45,959 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41492902437845863, 'Total loss': 0.41492902437845863} | train loss {'Reaction outcome loss': 0.26604816952336996, 'Total loss': 0.26604816952336996}
2023-01-05 06:16:45,959 INFO:     Found new best model at epoch 25
2023-01-05 06:16:45,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:45,961 INFO:     Epoch: 26
2023-01-05 06:16:48,248 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4246397286653519, 'Total loss': 0.4246397286653519} | train loss {'Reaction outcome loss': 0.25863098990615957, 'Total loss': 0.25863098990615957}
2023-01-05 06:16:48,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:48,248 INFO:     Epoch: 27
2023-01-05 06:16:50,499 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4014825940132141, 'Total loss': 0.4014825940132141} | train loss {'Reaction outcome loss': 0.2555323544728304, 'Total loss': 0.2555323544728304}
2023-01-05 06:16:50,499 INFO:     Found new best model at epoch 27
2023-01-05 06:16:50,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:50,500 INFO:     Epoch: 28
2023-01-05 06:16:52,796 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40037613759438195, 'Total loss': 0.40037613759438195} | train loss {'Reaction outcome loss': 0.25553544964103386, 'Total loss': 0.25553544964103386}
2023-01-05 06:16:52,796 INFO:     Found new best model at epoch 28
2023-01-05 06:16:52,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:52,798 INFO:     Epoch: 29
2023-01-05 06:16:55,071 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3973526433110237, 'Total loss': 0.3973526433110237} | train loss {'Reaction outcome loss': 0.2518878699841805, 'Total loss': 0.2518878699841805}
2023-01-05 06:16:55,071 INFO:     Found new best model at epoch 29
2023-01-05 06:16:55,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:55,072 INFO:     Epoch: 30
2023-01-05 06:16:57,340 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4427876591682434, 'Total loss': 0.4427876591682434} | train loss {'Reaction outcome loss': 0.2501424416556739, 'Total loss': 0.2501424416556739}
2023-01-05 06:16:57,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:57,341 INFO:     Epoch: 31
2023-01-05 06:16:59,631 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3832786117990812, 'Total loss': 0.3832786117990812} | train loss {'Reaction outcome loss': 0.2507910252807642, 'Total loss': 0.2507910252807642}
2023-01-05 06:16:59,631 INFO:     Found new best model at epoch 31
2023-01-05 06:16:59,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:16:59,633 INFO:     Epoch: 32
2023-01-05 06:17:01,897 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3992975334326426, 'Total loss': 0.3992975334326426} | train loss {'Reaction outcome loss': 0.24550028378648234, 'Total loss': 0.24550028378648234}
2023-01-05 06:17:01,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:01,897 INFO:     Epoch: 33
2023-01-05 06:17:04,210 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4122083276510239, 'Total loss': 0.4122083276510239} | train loss {'Reaction outcome loss': 0.2425625192250263, 'Total loss': 0.2425625192250263}
2023-01-05 06:17:04,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:04,210 INFO:     Epoch: 34
2023-01-05 06:17:06,504 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4431246280670166, 'Total loss': 0.4431246280670166} | train loss {'Reaction outcome loss': 0.23821094646942315, 'Total loss': 0.23821094646942315}
2023-01-05 06:17:06,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:06,504 INFO:     Epoch: 35
2023-01-05 06:17:08,810 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4173073947429657, 'Total loss': 0.4173073947429657} | train loss {'Reaction outcome loss': 0.23657979642037666, 'Total loss': 0.23657979642037666}
2023-01-05 06:17:08,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:08,810 INFO:     Epoch: 36
2023-01-05 06:17:11,090 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44382974207401277, 'Total loss': 0.44382974207401277} | train loss {'Reaction outcome loss': 0.23111505495108636, 'Total loss': 0.23111505495108636}
2023-01-05 06:17:11,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:11,091 INFO:     Epoch: 37
2023-01-05 06:17:13,369 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41160440842310586, 'Total loss': 0.41160440842310586} | train loss {'Reaction outcome loss': 0.22863334137946367, 'Total loss': 0.22863334137946367}
2023-01-05 06:17:13,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:13,370 INFO:     Epoch: 38
2023-01-05 06:17:15,661 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4060880055030187, 'Total loss': 0.4060880055030187} | train loss {'Reaction outcome loss': 0.2317782633127611, 'Total loss': 0.2317782633127611}
2023-01-05 06:17:15,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:15,661 INFO:     Epoch: 39
2023-01-05 06:17:17,922 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4264743775129318, 'Total loss': 0.4264743775129318} | train loss {'Reaction outcome loss': 0.2212280555416423, 'Total loss': 0.2212280555416423}
2023-01-05 06:17:17,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:17,922 INFO:     Epoch: 40
2023-01-05 06:17:20,204 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41895296176274616, 'Total loss': 0.41895296176274616} | train loss {'Reaction outcome loss': 0.22489436544034133, 'Total loss': 0.22489436544034133}
2023-01-05 06:17:20,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:20,205 INFO:     Epoch: 41
2023-01-05 06:17:22,481 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42289004723231, 'Total loss': 0.42289004723231} | train loss {'Reaction outcome loss': 0.2236690677245171, 'Total loss': 0.2236690677245171}
2023-01-05 06:17:22,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:22,481 INFO:     Epoch: 42
2023-01-05 06:17:24,726 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46167987982432046, 'Total loss': 0.46167987982432046} | train loss {'Reaction outcome loss': 0.22229770091547219, 'Total loss': 0.22229770091547219}
2023-01-05 06:17:24,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:24,727 INFO:     Epoch: 43
2023-01-05 06:17:27,004 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4089651385943095, 'Total loss': 0.4089651385943095} | train loss {'Reaction outcome loss': 0.21617745454776158, 'Total loss': 0.21617745454776158}
2023-01-05 06:17:27,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:27,004 INFO:     Epoch: 44
2023-01-05 06:17:29,251 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4399331291516622, 'Total loss': 0.4399331291516622} | train loss {'Reaction outcome loss': 0.2167356108661593, 'Total loss': 0.2167356108661593}
2023-01-05 06:17:29,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:29,251 INFO:     Epoch: 45
2023-01-05 06:17:31,514 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.434794877966245, 'Total loss': 0.434794877966245} | train loss {'Reaction outcome loss': 0.21264102476706143, 'Total loss': 0.21264102476706143}
2023-01-05 06:17:31,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:31,514 INFO:     Epoch: 46
2023-01-05 06:17:33,795 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42523655692736306, 'Total loss': 0.42523655692736306} | train loss {'Reaction outcome loss': 0.21106339413134736, 'Total loss': 0.21106339413134736}
2023-01-05 06:17:33,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:33,796 INFO:     Epoch: 47
2023-01-05 06:17:36,054 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4182608922322591, 'Total loss': 0.4182608922322591} | train loss {'Reaction outcome loss': 0.21063448274709848, 'Total loss': 0.21063448274709848}
2023-01-05 06:17:36,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:36,055 INFO:     Epoch: 48
2023-01-05 06:17:38,345 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4415084669987361, 'Total loss': 0.4415084669987361} | train loss {'Reaction outcome loss': 0.20998000822261997, 'Total loss': 0.20998000822261997}
2023-01-05 06:17:38,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:38,345 INFO:     Epoch: 49
2023-01-05 06:17:40,620 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4257475107908249, 'Total loss': 0.4257475107908249} | train loss {'Reaction outcome loss': 0.2057596000940253, 'Total loss': 0.2057596000940253}
2023-01-05 06:17:40,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:40,620 INFO:     Epoch: 50
2023-01-05 06:17:42,897 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45437379280726115, 'Total loss': 0.45437379280726115} | train loss {'Reaction outcome loss': 0.2115028166911474, 'Total loss': 0.2115028166911474}
2023-01-05 06:17:42,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:42,897 INFO:     Epoch: 51
2023-01-05 06:17:45,172 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44770230253537496, 'Total loss': 0.44770230253537496} | train loss {'Reaction outcome loss': 0.20434600337062178, 'Total loss': 0.20434600337062178}
2023-01-05 06:17:45,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:45,172 INFO:     Epoch: 52
2023-01-05 06:17:47,465 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42819715042908985, 'Total loss': 0.42819715042908985} | train loss {'Reaction outcome loss': 0.20099692869030397, 'Total loss': 0.20099692869030397}
2023-01-05 06:17:47,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:47,465 INFO:     Epoch: 53
2023-01-05 06:17:49,750 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42518521696329115, 'Total loss': 0.42518521696329115} | train loss {'Reaction outcome loss': 0.20221312459228755, 'Total loss': 0.20221312459228755}
2023-01-05 06:17:49,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:49,752 INFO:     Epoch: 54
2023-01-05 06:17:52,034 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4268645609418551, 'Total loss': 0.4268645609418551} | train loss {'Reaction outcome loss': 0.20101649371322097, 'Total loss': 0.20101649371322097}
2023-01-05 06:17:52,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:52,035 INFO:     Epoch: 55
2023-01-05 06:17:54,105 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44178644319375354, 'Total loss': 0.44178644319375354} | train loss {'Reaction outcome loss': 0.19988306405002568, 'Total loss': 0.19988306405002568}
2023-01-05 06:17:54,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:54,105 INFO:     Epoch: 56
2023-01-05 06:17:56,367 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41605740785598755, 'Total loss': 0.41605740785598755} | train loss {'Reaction outcome loss': 0.19996612368400346, 'Total loss': 0.19996612368400346}
2023-01-05 06:17:56,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:56,368 INFO:     Epoch: 57
2023-01-05 06:17:58,657 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43644010623296103, 'Total loss': 0.43644010623296103} | train loss {'Reaction outcome loss': 0.20016089083781527, 'Total loss': 0.20016089083781527}
2023-01-05 06:17:58,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:17:58,658 INFO:     Epoch: 58
2023-01-05 06:18:00,941 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43113364577293395, 'Total loss': 0.43113364577293395} | train loss {'Reaction outcome loss': 0.19932296461953583, 'Total loss': 0.19932296461953583}
2023-01-05 06:18:00,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:00,942 INFO:     Epoch: 59
2023-01-05 06:18:03,234 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44264888564745586, 'Total loss': 0.44264888564745586} | train loss {'Reaction outcome loss': 0.19364792557722393, 'Total loss': 0.19364792557722393}
2023-01-05 06:18:03,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:03,234 INFO:     Epoch: 60
2023-01-05 06:18:05,493 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4252682800094287, 'Total loss': 0.4252682800094287} | train loss {'Reaction outcome loss': 0.19302964303978729, 'Total loss': 0.19302964303978729}
2023-01-05 06:18:05,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:05,493 INFO:     Epoch: 61
2023-01-05 06:18:07,753 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46716863512992857, 'Total loss': 0.46716863512992857} | train loss {'Reaction outcome loss': 0.1975566161954473, 'Total loss': 0.1975566161954473}
2023-01-05 06:18:07,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:07,753 INFO:     Epoch: 62
2023-01-05 06:18:10,027 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4422937388221423, 'Total loss': 0.4422937388221423} | train loss {'Reaction outcome loss': 0.1949594659152498, 'Total loss': 0.1949594659152498}
2023-01-05 06:18:10,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:10,028 INFO:     Epoch: 63
2023-01-05 06:18:12,301 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45570095876852673, 'Total loss': 0.45570095876852673} | train loss {'Reaction outcome loss': 0.19090003638262676, 'Total loss': 0.19090003638262676}
2023-01-05 06:18:12,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:12,301 INFO:     Epoch: 64
2023-01-05 06:18:14,586 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42631831020116806, 'Total loss': 0.42631831020116806} | train loss {'Reaction outcome loss': 0.19108817834299502, 'Total loss': 0.19108817834299502}
2023-01-05 06:18:14,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:14,586 INFO:     Epoch: 65
2023-01-05 06:18:16,807 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44067959214250246, 'Total loss': 0.44067959214250246} | train loss {'Reaction outcome loss': 0.19343939704638957, 'Total loss': 0.19343939704638957}
2023-01-05 06:18:16,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:16,808 INFO:     Epoch: 66
2023-01-05 06:18:19,104 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4458735426266988, 'Total loss': 0.4458735426266988} | train loss {'Reaction outcome loss': 0.18907616425319054, 'Total loss': 0.18907616425319054}
2023-01-05 06:18:19,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:19,105 INFO:     Epoch: 67
2023-01-05 06:18:21,397 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48042591909567517, 'Total loss': 0.48042591909567517} | train loss {'Reaction outcome loss': 0.1907970474945509, 'Total loss': 0.1907970474945509}
2023-01-05 06:18:21,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:21,397 INFO:     Epoch: 68
2023-01-05 06:18:23,635 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4513696193695068, 'Total loss': 0.4513696193695068} | train loss {'Reaction outcome loss': 0.18868594306490857, 'Total loss': 0.18868594306490857}
2023-01-05 06:18:23,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:23,635 INFO:     Epoch: 69
2023-01-05 06:18:25,900 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4406277885039647, 'Total loss': 0.4406277885039647} | train loss {'Reaction outcome loss': 0.18781642674801313, 'Total loss': 0.18781642674801313}
2023-01-05 06:18:25,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:25,901 INFO:     Epoch: 70
2023-01-05 06:18:28,159 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4271140565474828, 'Total loss': 0.4271140565474828} | train loss {'Reaction outcome loss': 0.1870650882657873, 'Total loss': 0.1870650882657873}
2023-01-05 06:18:28,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:28,159 INFO:     Epoch: 71
2023-01-05 06:18:30,439 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4567992389202118, 'Total loss': 0.4567992389202118} | train loss {'Reaction outcome loss': 0.18429144623181665, 'Total loss': 0.18429144623181665}
2023-01-05 06:18:30,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:30,439 INFO:     Epoch: 72
2023-01-05 06:18:32,726 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4242289106051127, 'Total loss': 0.4242289106051127} | train loss {'Reaction outcome loss': 0.1852025278585052, 'Total loss': 0.1852025278585052}
2023-01-05 06:18:32,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:32,726 INFO:     Epoch: 73
2023-01-05 06:18:35,016 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4514453540245692, 'Total loss': 0.4514453540245692} | train loss {'Reaction outcome loss': 0.18422173536197695, 'Total loss': 0.18422173536197695}
2023-01-05 06:18:35,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:35,017 INFO:     Epoch: 74
2023-01-05 06:18:37,308 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4824962000052134, 'Total loss': 0.4824962000052134} | train loss {'Reaction outcome loss': 0.18230057521033965, 'Total loss': 0.18230057521033965}
2023-01-05 06:18:37,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:37,309 INFO:     Epoch: 75
2023-01-05 06:18:39,582 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4427319477001826, 'Total loss': 0.4427319477001826} | train loss {'Reaction outcome loss': 0.18561482984263328, 'Total loss': 0.18561482984263328}
2023-01-05 06:18:39,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:39,583 INFO:     Epoch: 76
2023-01-05 06:18:41,866 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4578770319620768, 'Total loss': 0.4578770319620768} | train loss {'Reaction outcome loss': 0.18106925648062183, 'Total loss': 0.18106925648062183}
2023-01-05 06:18:41,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:41,866 INFO:     Epoch: 77
2023-01-05 06:18:44,153 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4338994105656942, 'Total loss': 0.4338994105656942} | train loss {'Reaction outcome loss': 0.18022350306935367, 'Total loss': 0.18022350306935367}
2023-01-05 06:18:44,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:44,153 INFO:     Epoch: 78
2023-01-05 06:18:46,424 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4278076599041621, 'Total loss': 0.4278076599041621} | train loss {'Reaction outcome loss': 0.18055639471119062, 'Total loss': 0.18055639471119062}
2023-01-05 06:18:46,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:46,424 INFO:     Epoch: 79
2023-01-05 06:18:48,711 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4638332744439443, 'Total loss': 0.4638332744439443} | train loss {'Reaction outcome loss': 0.1811223082758809, 'Total loss': 0.1811223082758809}
2023-01-05 06:18:48,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:48,711 INFO:     Epoch: 80
2023-01-05 06:18:50,944 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4640605390071869, 'Total loss': 0.4640605390071869} | train loss {'Reaction outcome loss': 0.17710476380601417, 'Total loss': 0.17710476380601417}
2023-01-05 06:18:50,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:50,945 INFO:     Epoch: 81
2023-01-05 06:18:53,209 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4483374893665314, 'Total loss': 0.4483374893665314} | train loss {'Reaction outcome loss': 0.1824372268991296, 'Total loss': 0.1824372268991296}
2023-01-05 06:18:53,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:53,209 INFO:     Epoch: 82
2023-01-05 06:18:55,498 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44063442597786584, 'Total loss': 0.44063442597786584} | train loss {'Reaction outcome loss': 0.17410845619152276, 'Total loss': 0.17410845619152276}
2023-01-05 06:18:55,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:55,500 INFO:     Epoch: 83
2023-01-05 06:18:57,743 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44493175894021986, 'Total loss': 0.44493175894021986} | train loss {'Reaction outcome loss': 0.18511063967485128, 'Total loss': 0.18511063967485128}
2023-01-05 06:18:57,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:18:57,743 INFO:     Epoch: 84
2023-01-05 06:19:00,031 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.445157062013944, 'Total loss': 0.445157062013944} | train loss {'Reaction outcome loss': 0.17155469422790118, 'Total loss': 0.17155469422790118}
2023-01-05 06:19:00,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:00,031 INFO:     Epoch: 85
2023-01-05 06:19:02,319 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4489994158347448, 'Total loss': 0.4489994158347448} | train loss {'Reaction outcome loss': 0.17489939991768033, 'Total loss': 0.17489939991768033}
2023-01-05 06:19:02,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:02,320 INFO:     Epoch: 86
2023-01-05 06:19:04,571 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4529534300168355, 'Total loss': 0.4529534300168355} | train loss {'Reaction outcome loss': 0.17007165300804408, 'Total loss': 0.17007165300804408}
2023-01-05 06:19:04,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:04,571 INFO:     Epoch: 87
2023-01-05 06:19:06,857 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4346864158908526, 'Total loss': 0.4346864158908526} | train loss {'Reaction outcome loss': 0.17395356998674652, 'Total loss': 0.17395356998674652}
2023-01-05 06:19:06,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:06,857 INFO:     Epoch: 88
2023-01-05 06:19:09,136 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4366711859901746, 'Total loss': 0.4366711859901746} | train loss {'Reaction outcome loss': 0.1707143823411114, 'Total loss': 0.1707143823411114}
2023-01-05 06:19:09,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:09,136 INFO:     Epoch: 89
2023-01-05 06:19:11,381 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4386010358730952, 'Total loss': 0.4386010358730952} | train loss {'Reaction outcome loss': 0.16838414733052684, 'Total loss': 0.16838414733052684}
2023-01-05 06:19:11,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:11,381 INFO:     Epoch: 90
2023-01-05 06:19:13,665 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45288249949614207, 'Total loss': 0.45288249949614207} | train loss {'Reaction outcome loss': 0.1780789430834864, 'Total loss': 0.1780789430834864}
2023-01-05 06:19:13,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:13,665 INFO:     Epoch: 91
2023-01-05 06:19:15,952 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46498301525910696, 'Total loss': 0.46498301525910696} | train loss {'Reaction outcome loss': 0.16982849857800167, 'Total loss': 0.16982849857800167}
2023-01-05 06:19:15,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:15,953 INFO:     Epoch: 92
2023-01-05 06:19:18,241 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45429693460464476, 'Total loss': 0.45429693460464476} | train loss {'Reaction outcome loss': 0.1683055588770456, 'Total loss': 0.1683055588770456}
2023-01-05 06:19:18,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:18,241 INFO:     Epoch: 93
2023-01-05 06:19:20,557 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44321102102597554, 'Total loss': 0.44321102102597554} | train loss {'Reaction outcome loss': 0.16715962423300806, 'Total loss': 0.16715962423300806}
2023-01-05 06:19:20,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:20,557 INFO:     Epoch: 94
2023-01-05 06:19:22,832 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4756788710753123, 'Total loss': 0.4756788710753123} | train loss {'Reaction outcome loss': 0.17400772422669786, 'Total loss': 0.17400772422669786}
2023-01-05 06:19:22,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:22,833 INFO:     Epoch: 95
2023-01-05 06:19:25,099 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48923234542210897, 'Total loss': 0.48923234542210897} | train loss {'Reaction outcome loss': 0.17274102509620226, 'Total loss': 0.17274102509620226}
2023-01-05 06:19:25,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:25,099 INFO:     Epoch: 96
2023-01-05 06:19:27,388 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4520459840695063, 'Total loss': 0.4520459840695063} | train loss {'Reaction outcome loss': 0.16858244084648868, 'Total loss': 0.16858244084648868}
2023-01-05 06:19:27,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:27,388 INFO:     Epoch: 97
2023-01-05 06:19:29,675 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48617080052693684, 'Total loss': 0.48617080052693684} | train loss {'Reaction outcome loss': 0.1688794836760011, 'Total loss': 0.1688794836760011}
2023-01-05 06:19:29,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:29,675 INFO:     Epoch: 98
2023-01-05 06:19:31,945 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.462404399116834, 'Total loss': 0.462404399116834} | train loss {'Reaction outcome loss': 0.16651215630042154, 'Total loss': 0.16651215630042154}
2023-01-05 06:19:31,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:31,946 INFO:     Epoch: 99
2023-01-05 06:19:34,206 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45414929687976835, 'Total loss': 0.45414929687976835} | train loss {'Reaction outcome loss': 0.16649110723347385, 'Total loss': 0.16649110723347385}
2023-01-05 06:19:34,206 INFO:     Best model found after epoch 32 of 100.
2023-01-05 06:19:34,206 INFO:   Done with stage: TRAINING
2023-01-05 06:19:34,206 INFO:   Starting stage: EVALUATION
2023-01-05 06:19:34,335 INFO:   Done with stage: EVALUATION
2023-01-05 06:19:34,335 INFO:   Leaving out SEQ value Fold_8
2023-01-05 06:19:34,348 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 06:19:34,348 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:19:35,000 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:19:35,000 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:19:35,074 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:19:35,074 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:19:35,074 INFO:     No hyperparam tuning for this model
2023-01-05 06:19:35,074 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:19:35,074 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:19:35,075 INFO:     None feature selector for col prot
2023-01-05 06:19:35,075 INFO:     None feature selector for col prot
2023-01-05 06:19:35,075 INFO:     None feature selector for col prot
2023-01-05 06:19:35,076 INFO:     None feature selector for col chem
2023-01-05 06:19:35,076 INFO:     None feature selector for col chem
2023-01-05 06:19:35,076 INFO:     None feature selector for col chem
2023-01-05 06:19:35,076 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:19:35,076 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:19:35,078 INFO:     Number of params in model 72931
2023-01-05 06:19:35,081 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:19:35,081 INFO:   Starting stage: TRAINING
2023-01-05 06:19:35,142 INFO:     Val loss before train {'Reaction outcome loss': 1.0681988676389058, 'Total loss': 1.0681988676389058}
2023-01-05 06:19:35,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:35,143 INFO:     Epoch: 0
2023-01-05 06:19:37,391 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8432271997133891, 'Total loss': 0.8432271997133891} | train loss {'Reaction outcome loss': 0.9544426213302042, 'Total loss': 0.9544426213302042}
2023-01-05 06:19:37,391 INFO:     Found new best model at epoch 0
2023-01-05 06:19:37,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:37,392 INFO:     Epoch: 1
2023-01-05 06:19:39,673 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5835160573323568, 'Total loss': 0.5835160573323568} | train loss {'Reaction outcome loss': 0.6264902729677896, 'Total loss': 0.6264902729677896}
2023-01-05 06:19:39,674 INFO:     Found new best model at epoch 1
2023-01-05 06:19:39,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:39,675 INFO:     Epoch: 2
2023-01-05 06:19:41,963 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5475527842839559, 'Total loss': 0.5475527842839559} | train loss {'Reaction outcome loss': 0.5437301742047935, 'Total loss': 0.5437301742047935}
2023-01-05 06:19:41,963 INFO:     Found new best model at epoch 2
2023-01-05 06:19:41,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:41,965 INFO:     Epoch: 3
2023-01-05 06:19:44,248 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5290358086427053, 'Total loss': 0.5290358086427053} | train loss {'Reaction outcome loss': 0.5022902170169181, 'Total loss': 0.5022902170169181}
2023-01-05 06:19:44,248 INFO:     Found new best model at epoch 3
2023-01-05 06:19:44,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:44,249 INFO:     Epoch: 4
2023-01-05 06:19:46,527 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4967027465502421, 'Total loss': 0.4967027465502421} | train loss {'Reaction outcome loss': 0.4804242685221244, 'Total loss': 0.4804242685221244}
2023-01-05 06:19:46,527 INFO:     Found new best model at epoch 4
2023-01-05 06:19:46,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:46,528 INFO:     Epoch: 5
2023-01-05 06:19:48,793 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4775619298219681, 'Total loss': 0.4775619298219681} | train loss {'Reaction outcome loss': 0.45587212703611696, 'Total loss': 0.45587212703611696}
2023-01-05 06:19:48,794 INFO:     Found new best model at epoch 5
2023-01-05 06:19:48,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:48,795 INFO:     Epoch: 6
2023-01-05 06:19:51,072 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4805419127146403, 'Total loss': 0.4805419127146403} | train loss {'Reaction outcome loss': 0.4339899008796699, 'Total loss': 0.4339899008796699}
2023-01-05 06:19:51,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:51,072 INFO:     Epoch: 7
2023-01-05 06:19:53,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4510677327712377, 'Total loss': 0.4510677327712377} | train loss {'Reaction outcome loss': 0.4169057829008586, 'Total loss': 0.4169057829008586}
2023-01-05 06:19:53,337 INFO:     Found new best model at epoch 7
2023-01-05 06:19:53,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:53,339 INFO:     Epoch: 8
2023-01-05 06:19:55,617 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44857335289319356, 'Total loss': 0.44857335289319356} | train loss {'Reaction outcome loss': 0.4052562929176982, 'Total loss': 0.4052562929176982}
2023-01-05 06:19:55,617 INFO:     Found new best model at epoch 8
2023-01-05 06:19:55,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:55,619 INFO:     Epoch: 9
2023-01-05 06:19:57,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4499760389328003, 'Total loss': 0.4499760389328003} | train loss {'Reaction outcome loss': 0.39388705671940377, 'Total loss': 0.39388705671940377}
2023-01-05 06:19:57,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:19:57,867 INFO:     Epoch: 10
2023-01-05 06:20:00,125 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4487457851568858, 'Total loss': 0.4487457851568858} | train loss {'Reaction outcome loss': 0.3854695170927659, 'Total loss': 0.3854695170927659}
2023-01-05 06:20:00,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:00,125 INFO:     Epoch: 11
2023-01-05 06:20:02,379 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43625041445096335, 'Total loss': 0.43625041445096335} | train loss {'Reaction outcome loss': 0.37428000237422815, 'Total loss': 0.37428000237422815}
2023-01-05 06:20:02,379 INFO:     Found new best model at epoch 11
2023-01-05 06:20:02,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:02,381 INFO:     Epoch: 12
2023-01-05 06:20:04,666 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4270428240299225, 'Total loss': 0.4270428240299225} | train loss {'Reaction outcome loss': 0.36662036825673305, 'Total loss': 0.36662036825673305}
2023-01-05 06:20:04,666 INFO:     Found new best model at epoch 12
2023-01-05 06:20:04,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:04,668 INFO:     Epoch: 13
2023-01-05 06:20:06,917 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4369718114535014, 'Total loss': 0.4369718114535014} | train loss {'Reaction outcome loss': 0.3600023531841504, 'Total loss': 0.3600023531841504}
2023-01-05 06:20:06,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:06,918 INFO:     Epoch: 14
2023-01-05 06:20:09,179 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4141415814558665, 'Total loss': 0.4141415814558665} | train loss {'Reaction outcome loss': 0.3444347035686445, 'Total loss': 0.3444347035686445}
2023-01-05 06:20:09,179 INFO:     Found new best model at epoch 14
2023-01-05 06:20:09,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:09,180 INFO:     Epoch: 15
2023-01-05 06:20:11,406 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42619122366110485, 'Total loss': 0.42619122366110485} | train loss {'Reaction outcome loss': 0.3401429397728888, 'Total loss': 0.3401429397728888}
2023-01-05 06:20:11,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:11,406 INFO:     Epoch: 16
2023-01-05 06:20:13,653 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4193208575248718, 'Total loss': 0.4193208575248718} | train loss {'Reaction outcome loss': 0.32910043207685585, 'Total loss': 0.32910043207685585}
2023-01-05 06:20:13,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:13,654 INFO:     Epoch: 17
2023-01-05 06:20:15,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41633829375108083, 'Total loss': 0.41633829375108083} | train loss {'Reaction outcome loss': 0.327804395986343, 'Total loss': 0.327804395986343}
2023-01-05 06:20:15,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:15,927 INFO:     Epoch: 18
2023-01-05 06:20:18,162 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39905531853437426, 'Total loss': 0.39905531853437426} | train loss {'Reaction outcome loss': 0.3277942724660903, 'Total loss': 0.3277942724660903}
2023-01-05 06:20:18,163 INFO:     Found new best model at epoch 18
2023-01-05 06:20:18,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:18,164 INFO:     Epoch: 19
2023-01-05 06:20:20,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42082640131314597, 'Total loss': 0.42082640131314597} | train loss {'Reaction outcome loss': 0.3372834278363397, 'Total loss': 0.3372834278363397}
2023-01-05 06:20:20,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:20,415 INFO:     Epoch: 20
2023-01-05 06:20:22,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4058071315288544, 'Total loss': 0.4058071315288544} | train loss {'Reaction outcome loss': 0.3114207569185806, 'Total loss': 0.3114207569185806}
2023-01-05 06:20:22,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:22,609 INFO:     Epoch: 21
2023-01-05 06:20:24,889 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39620668192704517, 'Total loss': 0.39620668192704517} | train loss {'Reaction outcome loss': 0.301586932030277, 'Total loss': 0.301586932030277}
2023-01-05 06:20:24,889 INFO:     Found new best model at epoch 21
2023-01-05 06:20:24,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:24,891 INFO:     Epoch: 22
2023-01-05 06:20:27,185 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4451383670171102, 'Total loss': 0.4451383670171102} | train loss {'Reaction outcome loss': 0.29639344415424956, 'Total loss': 0.29639344415424956}
2023-01-05 06:20:27,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:27,185 INFO:     Epoch: 23
2023-01-05 06:20:29,476 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4225174238284429, 'Total loss': 0.4225174238284429} | train loss {'Reaction outcome loss': 0.2929528849604337, 'Total loss': 0.2929528849604337}
2023-01-05 06:20:29,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:29,476 INFO:     Epoch: 24
2023-01-05 06:20:31,748 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41303508083025614, 'Total loss': 0.41303508083025614} | train loss {'Reaction outcome loss': 0.2883073479389313, 'Total loss': 0.2883073479389313}
2023-01-05 06:20:31,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:31,749 INFO:     Epoch: 25
2023-01-05 06:20:34,016 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42760582168896993, 'Total loss': 0.42760582168896993} | train loss {'Reaction outcome loss': 0.2799297026561006, 'Total loss': 0.2799297026561006}
2023-01-05 06:20:34,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:34,016 INFO:     Epoch: 26
2023-01-05 06:20:36,304 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4316608190536499, 'Total loss': 0.4316608190536499} | train loss {'Reaction outcome loss': 0.29838199289920536, 'Total loss': 0.29838199289920536}
2023-01-05 06:20:36,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:36,304 INFO:     Epoch: 27
2023-01-05 06:20:38,604 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43461891214052834, 'Total loss': 0.43461891214052834} | train loss {'Reaction outcome loss': 0.2868740578465488, 'Total loss': 0.2868740578465488}
2023-01-05 06:20:38,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:38,604 INFO:     Epoch: 28
2023-01-05 06:20:40,891 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4378049025932948, 'Total loss': 0.4378049025932948} | train loss {'Reaction outcome loss': 0.28243332783309283, 'Total loss': 0.28243332783309283}
2023-01-05 06:20:40,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:40,892 INFO:     Epoch: 29
2023-01-05 06:20:43,167 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4306850532690684, 'Total loss': 0.4306850532690684} | train loss {'Reaction outcome loss': 0.2666404008885603, 'Total loss': 0.2666404008885603}
2023-01-05 06:20:43,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:43,168 INFO:     Epoch: 30
2023-01-05 06:20:45,407 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44367019335428876, 'Total loss': 0.44367019335428876} | train loss {'Reaction outcome loss': 0.2626702975285825, 'Total loss': 0.2626702975285825}
2023-01-05 06:20:45,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:45,407 INFO:     Epoch: 31
2023-01-05 06:20:47,670 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4368467877308528, 'Total loss': 0.4368467877308528} | train loss {'Reaction outcome loss': 0.26330716378036584, 'Total loss': 0.26330716378036584}
2023-01-05 06:20:47,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:47,671 INFO:     Epoch: 32
2023-01-05 06:20:49,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.407905051112175, 'Total loss': 0.407905051112175} | train loss {'Reaction outcome loss': 0.2567253208759686, 'Total loss': 0.2567253208759686}
2023-01-05 06:20:49,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:49,938 INFO:     Epoch: 33
2023-01-05 06:20:52,222 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4018129736185074, 'Total loss': 0.4018129736185074} | train loss {'Reaction outcome loss': 0.25547460285040713, 'Total loss': 0.25547460285040713}
2023-01-05 06:20:52,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:52,223 INFO:     Epoch: 34
2023-01-05 06:20:54,520 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.401820196211338, 'Total loss': 0.401820196211338} | train loss {'Reaction outcome loss': 0.2539842875347054, 'Total loss': 0.2539842875347054}
2023-01-05 06:20:54,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:54,520 INFO:     Epoch: 35
2023-01-05 06:20:56,783 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4178886572519938, 'Total loss': 0.4178886572519938} | train loss {'Reaction outcome loss': 0.25069232063664904, 'Total loss': 0.25069232063664904}
2023-01-05 06:20:56,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:56,783 INFO:     Epoch: 36
2023-01-05 06:20:59,063 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4106775651375453, 'Total loss': 0.4106775651375453} | train loss {'Reaction outcome loss': 0.26279172259787825, 'Total loss': 0.26279172259787825}
2023-01-05 06:20:59,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:20:59,063 INFO:     Epoch: 37
2023-01-05 06:21:01,351 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4108845700820287, 'Total loss': 0.4108845700820287} | train loss {'Reaction outcome loss': 0.2664984033773721, 'Total loss': 0.2664984033773721}
2023-01-05 06:21:01,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:01,351 INFO:     Epoch: 38
2023-01-05 06:21:03,627 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4162389079729716, 'Total loss': 0.4162389079729716} | train loss {'Reaction outcome loss': 0.24054050850732575, 'Total loss': 0.24054050850732575}
2023-01-05 06:21:03,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:03,628 INFO:     Epoch: 39
2023-01-05 06:21:05,912 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4268924415111542, 'Total loss': 0.4268924415111542} | train loss {'Reaction outcome loss': 0.24399057230861534, 'Total loss': 0.24399057230861534}
2023-01-05 06:21:05,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:05,912 INFO:     Epoch: 40
2023-01-05 06:21:08,163 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4046102831761042, 'Total loss': 0.4046102831761042} | train loss {'Reaction outcome loss': 0.23968550143425987, 'Total loss': 0.23968550143425987}
2023-01-05 06:21:08,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:08,163 INFO:     Epoch: 41
2023-01-05 06:21:10,407 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40417560338974, 'Total loss': 0.40417560338974} | train loss {'Reaction outcome loss': 0.2325194893958236, 'Total loss': 0.2325194893958236}
2023-01-05 06:21:10,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:10,407 INFO:     Epoch: 42
2023-01-05 06:21:12,670 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4068142771720886, 'Total loss': 0.4068142771720886} | train loss {'Reaction outcome loss': 0.2319122863032069, 'Total loss': 0.2319122863032069}
2023-01-05 06:21:12,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:12,670 INFO:     Epoch: 43
2023-01-05 06:21:14,949 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41715837518374127, 'Total loss': 0.41715837518374127} | train loss {'Reaction outcome loss': 0.23244204394417256, 'Total loss': 0.23244204394417256}
2023-01-05 06:21:14,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:14,949 INFO:     Epoch: 44
2023-01-05 06:21:17,224 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41582507689793907, 'Total loss': 0.41582507689793907} | train loss {'Reaction outcome loss': 0.2335116419583927, 'Total loss': 0.2335116419583927}
2023-01-05 06:21:17,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:17,225 INFO:     Epoch: 45
2023-01-05 06:21:19,465 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4102042814095815, 'Total loss': 0.4102042814095815} | train loss {'Reaction outcome loss': 0.24863316821933223, 'Total loss': 0.24863316821933223}
2023-01-05 06:21:19,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:19,466 INFO:     Epoch: 46
2023-01-05 06:21:21,697 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38956861893335976, 'Total loss': 0.38956861893335976} | train loss {'Reaction outcome loss': 0.2679251523120938, 'Total loss': 0.2679251523120938}
2023-01-05 06:21:21,697 INFO:     Found new best model at epoch 46
2023-01-05 06:21:21,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:21,698 INFO:     Epoch: 47
2023-01-05 06:21:23,943 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3905646095673243, 'Total loss': 0.3905646095673243} | train loss {'Reaction outcome loss': 0.22964965441412682, 'Total loss': 0.22964965441412682}
2023-01-05 06:21:23,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:23,943 INFO:     Epoch: 48
2023-01-05 06:21:26,220 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.403510187069575, 'Total loss': 0.403510187069575} | train loss {'Reaction outcome loss': 0.22822425429204368, 'Total loss': 0.22822425429204368}
2023-01-05 06:21:26,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:26,221 INFO:     Epoch: 49
2023-01-05 06:21:28,497 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40934825042883555, 'Total loss': 0.40934825042883555} | train loss {'Reaction outcome loss': 0.22323333630903516, 'Total loss': 0.22323333630903516}
2023-01-05 06:21:28,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:28,497 INFO:     Epoch: 50
2023-01-05 06:21:30,744 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3883930265903473, 'Total loss': 0.3883930265903473} | train loss {'Reaction outcome loss': 0.2492791742383354, 'Total loss': 0.2492791742383354}
2023-01-05 06:21:30,745 INFO:     Found new best model at epoch 50
2023-01-05 06:21:30,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:30,746 INFO:     Epoch: 51
2023-01-05 06:21:32,962 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41566929121812185, 'Total loss': 0.41566929121812185} | train loss {'Reaction outcome loss': 0.2196802040157111, 'Total loss': 0.2196802040157111}
2023-01-05 06:21:32,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:32,963 INFO:     Epoch: 52
2023-01-05 06:21:35,250 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4011006941397985, 'Total loss': 0.4011006941397985} | train loss {'Reaction outcome loss': 0.22210358864053295, 'Total loss': 0.22210358864053295}
2023-01-05 06:21:35,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:35,250 INFO:     Epoch: 53
2023-01-05 06:21:37,525 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42810895244280495, 'Total loss': 0.42810895244280495} | train loss {'Reaction outcome loss': 0.21743267167872493, 'Total loss': 0.21743267167872493}
2023-01-05 06:21:37,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:37,526 INFO:     Epoch: 54
2023-01-05 06:21:39,798 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39443571319182713, 'Total loss': 0.39443571319182713} | train loss {'Reaction outcome loss': 0.2212996046308536, 'Total loss': 0.2212996046308536}
2023-01-05 06:21:39,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:39,799 INFO:     Epoch: 55
2023-01-05 06:21:42,077 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4097110579411189, 'Total loss': 0.4097110579411189} | train loss {'Reaction outcome loss': 0.2085865514902938, 'Total loss': 0.2085865514902938}
2023-01-05 06:21:42,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:42,078 INFO:     Epoch: 56
2023-01-05 06:21:44,319 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.391873033841451, 'Total loss': 0.391873033841451} | train loss {'Reaction outcome loss': 0.21314604460069636, 'Total loss': 0.21314604460069636}
2023-01-05 06:21:44,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:44,319 INFO:     Epoch: 57
2023-01-05 06:21:46,589 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4052133808533351, 'Total loss': 0.4052133808533351} | train loss {'Reaction outcome loss': 0.21305172194590102, 'Total loss': 0.21305172194590102}
2023-01-05 06:21:46,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:46,589 INFO:     Epoch: 58
2023-01-05 06:21:48,875 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4019154757261276, 'Total loss': 0.4019154757261276} | train loss {'Reaction outcome loss': 0.210209996058346, 'Total loss': 0.210209996058346}
2023-01-05 06:21:48,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:48,876 INFO:     Epoch: 59
2023-01-05 06:21:51,176 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4334092716375987, 'Total loss': 0.4334092716375987} | train loss {'Reaction outcome loss': 0.20792565541805874, 'Total loss': 0.20792565541805874}
2023-01-05 06:21:51,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:51,177 INFO:     Epoch: 60
2023-01-05 06:21:53,467 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41855330566565196, 'Total loss': 0.41855330566565196} | train loss {'Reaction outcome loss': 0.21105005739904617, 'Total loss': 0.21105005739904617}
2023-01-05 06:21:53,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:53,467 INFO:     Epoch: 61
2023-01-05 06:21:55,719 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4127182518442472, 'Total loss': 0.4127182518442472} | train loss {'Reaction outcome loss': 0.21180885306397534, 'Total loss': 0.21180885306397534}
2023-01-05 06:21:55,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:55,720 INFO:     Epoch: 62
2023-01-05 06:21:58,006 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4078425948818525, 'Total loss': 0.4078425948818525} | train loss {'Reaction outcome loss': 0.204203001723753, 'Total loss': 0.204203001723753}
2023-01-05 06:21:58,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:21:58,006 INFO:     Epoch: 63
2023-01-05 06:22:00,288 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4186630964279175, 'Total loss': 0.4186630964279175} | train loss {'Reaction outcome loss': 0.20381293411154058, 'Total loss': 0.20381293411154058}
2023-01-05 06:22:00,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:00,288 INFO:     Epoch: 64
2023-01-05 06:22:02,565 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4298979918162028, 'Total loss': 0.4298979918162028} | train loss {'Reaction outcome loss': 0.20134698529959744, 'Total loss': 0.20134698529959744}
2023-01-05 06:22:02,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:02,566 INFO:     Epoch: 65
2023-01-05 06:22:04,648 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4133406162261963, 'Total loss': 0.4133406162261963} | train loss {'Reaction outcome loss': 0.20388642077048222, 'Total loss': 0.20388642077048222}
2023-01-05 06:22:04,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:04,649 INFO:     Epoch: 66
2023-01-05 06:22:06,875 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.423154616355896, 'Total loss': 0.423154616355896} | train loss {'Reaction outcome loss': 0.19930022348932613, 'Total loss': 0.19930022348932613}
2023-01-05 06:22:06,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:06,875 INFO:     Epoch: 67
2023-01-05 06:22:09,158 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44432432949543, 'Total loss': 0.44432432949543} | train loss {'Reaction outcome loss': 0.1972622934069174, 'Total loss': 0.1972622934069174}
2023-01-05 06:22:09,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:09,159 INFO:     Epoch: 68
2023-01-05 06:22:11,422 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41959357460339863, 'Total loss': 0.41959357460339863} | train loss {'Reaction outcome loss': 0.20067876238982021, 'Total loss': 0.20067876238982021}
2023-01-05 06:22:11,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:11,422 INFO:     Epoch: 69
2023-01-05 06:22:13,704 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4375460247198741, 'Total loss': 0.4375460247198741} | train loss {'Reaction outcome loss': 0.20070695221775037, 'Total loss': 0.20070695221775037}
2023-01-05 06:22:13,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:13,704 INFO:     Epoch: 70
2023-01-05 06:22:16,025 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4253929545482, 'Total loss': 0.4253929545482} | train loss {'Reaction outcome loss': 0.23725108559702293, 'Total loss': 0.23725108559702293}
2023-01-05 06:22:16,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:16,025 INFO:     Epoch: 71
2023-01-05 06:22:18,242 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43448399702707924, 'Total loss': 0.43448399702707924} | train loss {'Reaction outcome loss': 0.20433290051764547, 'Total loss': 0.20433290051764547}
2023-01-05 06:22:18,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:18,243 INFO:     Epoch: 72
2023-01-05 06:22:20,492 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4174437781174978, 'Total loss': 0.4174437781174978} | train loss {'Reaction outcome loss': 0.19574224157691208, 'Total loss': 0.19574224157691208}
2023-01-05 06:22:20,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:20,492 INFO:     Epoch: 73
2023-01-05 06:22:22,744 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4327133302887281, 'Total loss': 0.4327133302887281} | train loss {'Reaction outcome loss': 0.19214401899417693, 'Total loss': 0.19214401899417693}
2023-01-05 06:22:22,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:22,744 INFO:     Epoch: 74
2023-01-05 06:22:25,014 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4045735955238342, 'Total loss': 0.4045735955238342} | train loss {'Reaction outcome loss': 0.18962714159795124, 'Total loss': 0.18962714159795124}
2023-01-05 06:22:25,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:25,015 INFO:     Epoch: 75
2023-01-05 06:22:27,280 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4173883363604546, 'Total loss': 0.4173883363604546} | train loss {'Reaction outcome loss': 0.19135463263913718, 'Total loss': 0.19135463263913718}
2023-01-05 06:22:27,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:27,280 INFO:     Epoch: 76
2023-01-05 06:22:29,536 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4306910107533137, 'Total loss': 0.4306910107533137} | train loss {'Reaction outcome loss': 0.20029932480674292, 'Total loss': 0.20029932480674292}
2023-01-05 06:22:29,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:29,536 INFO:     Epoch: 77
2023-01-05 06:22:31,793 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.414219006896019, 'Total loss': 0.414219006896019} | train loss {'Reaction outcome loss': 0.19559563148726264, 'Total loss': 0.19559563148726264}
2023-01-05 06:22:31,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:31,794 INFO:     Epoch: 78
2023-01-05 06:22:34,058 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3893275648355484, 'Total loss': 0.3893275648355484} | train loss {'Reaction outcome loss': 0.18977169008871567, 'Total loss': 0.18977169008871567}
2023-01-05 06:22:34,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:34,058 INFO:     Epoch: 79
2023-01-05 06:22:36,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41514409792919954, 'Total loss': 0.41514409792919954} | train loss {'Reaction outcome loss': 0.18658156245636864, 'Total loss': 0.18658156245636864}
2023-01-05 06:22:36,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:36,344 INFO:     Epoch: 80
2023-01-05 06:22:38,614 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4137980918089549, 'Total loss': 0.4137980918089549} | train loss {'Reaction outcome loss': 0.18515519441554215, 'Total loss': 0.18515519441554215}
2023-01-05 06:22:38,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:38,614 INFO:     Epoch: 81
2023-01-05 06:22:40,840 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4040202001730601, 'Total loss': 0.4040202001730601} | train loss {'Reaction outcome loss': 0.18301084152746783, 'Total loss': 0.18301084152746783}
2023-01-05 06:22:40,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:40,841 INFO:     Epoch: 82
2023-01-05 06:22:43,104 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3986345410346985, 'Total loss': 0.3986345410346985} | train loss {'Reaction outcome loss': 0.18389315645385912, 'Total loss': 0.18389315645385912}
2023-01-05 06:22:43,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:43,104 INFO:     Epoch: 83
2023-01-05 06:22:45,393 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4125373383363088, 'Total loss': 0.4125373383363088} | train loss {'Reaction outcome loss': 0.1872309884668051, 'Total loss': 0.1872309884668051}
2023-01-05 06:22:45,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:45,394 INFO:     Epoch: 84
2023-01-05 06:22:47,660 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.409725088874499, 'Total loss': 0.409725088874499} | train loss {'Reaction outcome loss': 0.1862946882020628, 'Total loss': 0.1862946882020628}
2023-01-05 06:22:47,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:47,661 INFO:     Epoch: 85
2023-01-05 06:22:49,934 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3931381831566493, 'Total loss': 0.3931381831566493} | train loss {'Reaction outcome loss': 0.1871052456655256, 'Total loss': 0.1871052456655256}
2023-01-05 06:22:49,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:49,934 INFO:     Epoch: 86
2023-01-05 06:22:52,204 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35328433352212113, 'Total loss': 0.35328433352212113} | train loss {'Reaction outcome loss': 0.1817901943223146, 'Total loss': 0.1817901943223146}
2023-01-05 06:22:52,204 INFO:     Found new best model at epoch 86
2023-01-05 06:22:52,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:52,205 INFO:     Epoch: 87
2023-01-05 06:22:54,456 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40557517210642496, 'Total loss': 0.40557517210642496} | train loss {'Reaction outcome loss': 0.18203684362663847, 'Total loss': 0.18203684362663847}
2023-01-05 06:22:54,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:54,456 INFO:     Epoch: 88
2023-01-05 06:22:56,727 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.416666841506958, 'Total loss': 0.416666841506958} | train loss {'Reaction outcome loss': 0.17922876915637997, 'Total loss': 0.17922876915637997}
2023-01-05 06:22:56,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:56,727 INFO:     Epoch: 89
2023-01-05 06:22:59,001 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4136118700106939, 'Total loss': 0.4136118700106939} | train loss {'Reaction outcome loss': 0.18021398198881955, 'Total loss': 0.18021398198881955}
2023-01-05 06:22:59,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:22:59,002 INFO:     Epoch: 90
2023-01-05 06:23:01,299 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.390532565365235, 'Total loss': 0.390532565365235} | train loss {'Reaction outcome loss': 0.1782009904846495, 'Total loss': 0.1782009904846495}
2023-01-05 06:23:01,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:01,301 INFO:     Epoch: 91
2023-01-05 06:23:03,599 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3934353679418564, 'Total loss': 0.3934353679418564} | train loss {'Reaction outcome loss': 0.18004236702193116, 'Total loss': 0.18004236702193116}
2023-01-05 06:23:03,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:03,600 INFO:     Epoch: 92
2023-01-05 06:23:05,848 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40632358690102893, 'Total loss': 0.40632358690102893} | train loss {'Reaction outcome loss': 0.17796101592556215, 'Total loss': 0.17796101592556215}
2023-01-05 06:23:05,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:05,848 INFO:     Epoch: 93
2023-01-05 06:23:08,115 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3893445591131846, 'Total loss': 0.3893445591131846} | train loss {'Reaction outcome loss': 0.17506103623274308, 'Total loss': 0.17506103623274308}
2023-01-05 06:23:08,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:08,116 INFO:     Epoch: 94
2023-01-05 06:23:10,392 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4382430816690127, 'Total loss': 0.4382430816690127} | train loss {'Reaction outcome loss': 0.1749706021256988, 'Total loss': 0.1749706021256988}
2023-01-05 06:23:10,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:10,392 INFO:     Epoch: 95
2023-01-05 06:23:12,673 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4168641279141108, 'Total loss': 0.4168641279141108} | train loss {'Reaction outcome loss': 0.20008610909892435, 'Total loss': 0.20008610909892435}
2023-01-05 06:23:12,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:12,673 INFO:     Epoch: 96
2023-01-05 06:23:14,924 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3961518382032712, 'Total loss': 0.3961518382032712} | train loss {'Reaction outcome loss': 0.18098492165055455, 'Total loss': 0.18098492165055455}
2023-01-05 06:23:14,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:14,925 INFO:     Epoch: 97
2023-01-05 06:23:17,174 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4316132257382075, 'Total loss': 0.4316132257382075} | train loss {'Reaction outcome loss': 0.17470724175454697, 'Total loss': 0.17470724175454697}
2023-01-05 06:23:17,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:17,174 INFO:     Epoch: 98
2023-01-05 06:23:19,436 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4504191304246585, 'Total loss': 0.4504191304246585} | train loss {'Reaction outcome loss': 0.17543027350895, 'Total loss': 0.17543027350895}
2023-01-05 06:23:19,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:19,437 INFO:     Epoch: 99
2023-01-05 06:23:21,642 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4346772902955612, 'Total loss': 0.4346772902955612} | train loss {'Reaction outcome loss': 0.17748277859198794, 'Total loss': 0.17748277859198794}
2023-01-05 06:23:21,643 INFO:     Best model found after epoch 87 of 100.
2023-01-05 06:23:21,643 INFO:   Done with stage: TRAINING
2023-01-05 06:23:21,644 INFO:   Starting stage: EVALUATION
2023-01-05 06:23:21,779 INFO:   Done with stage: EVALUATION
2023-01-05 06:23:21,780 INFO:   Leaving out SEQ value Fold_9
2023-01-05 06:23:21,792 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:23:21,792 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:23:22,452 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:23:22,452 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:23:22,526 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:23:22,526 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:23:22,526 INFO:     No hyperparam tuning for this model
2023-01-05 06:23:22,526 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:23:22,526 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:23:22,527 INFO:     None feature selector for col prot
2023-01-05 06:23:22,527 INFO:     None feature selector for col prot
2023-01-05 06:23:22,527 INFO:     None feature selector for col prot
2023-01-05 06:23:22,527 INFO:     None feature selector for col chem
2023-01-05 06:23:22,528 INFO:     None feature selector for col chem
2023-01-05 06:23:22,528 INFO:     None feature selector for col chem
2023-01-05 06:23:22,528 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:23:22,528 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:23:22,529 INFO:     Number of params in model 72931
2023-01-05 06:23:22,533 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:23:22,533 INFO:   Starting stage: TRAINING
2023-01-05 06:23:22,592 INFO:     Val loss before train {'Reaction outcome loss': 0.9770727276802063, 'Total loss': 0.9770727276802063}
2023-01-05 06:23:22,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:22,593 INFO:     Epoch: 0
2023-01-05 06:23:24,876 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7242776950200399, 'Total loss': 0.7242776950200399} | train loss {'Reaction outcome loss': 0.9244474615861362, 'Total loss': 0.9244474615861362}
2023-01-05 06:23:24,876 INFO:     Found new best model at epoch 0
2023-01-05 06:23:24,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:24,878 INFO:     Epoch: 1
2023-01-05 06:23:27,158 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5672761301199595, 'Total loss': 0.5672761301199595} | train loss {'Reaction outcome loss': 0.6156864570796705, 'Total loss': 0.6156864570796705}
2023-01-05 06:23:27,158 INFO:     Found new best model at epoch 1
2023-01-05 06:23:27,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:27,159 INFO:     Epoch: 2
2023-01-05 06:23:29,419 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5274041930834452, 'Total loss': 0.5274041930834452} | train loss {'Reaction outcome loss': 0.5233572279825968, 'Total loss': 0.5233572279825968}
2023-01-05 06:23:29,419 INFO:     Found new best model at epoch 2
2023-01-05 06:23:29,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:29,420 INFO:     Epoch: 3
2023-01-05 06:23:31,701 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5089274754126867, 'Total loss': 0.5089274754126867} | train loss {'Reaction outcome loss': 0.4858302150715129, 'Total loss': 0.4858302150715129}
2023-01-05 06:23:31,701 INFO:     Found new best model at epoch 3
2023-01-05 06:23:31,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:31,702 INFO:     Epoch: 4
2023-01-05 06:23:33,983 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.481056147813797, 'Total loss': 0.481056147813797} | train loss {'Reaction outcome loss': 0.459028329229527, 'Total loss': 0.459028329229527}
2023-01-05 06:23:33,983 INFO:     Found new best model at epoch 4
2023-01-05 06:23:33,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:33,984 INFO:     Epoch: 5
2023-01-05 06:23:36,262 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4706070959568024, 'Total loss': 0.4706070959568024} | train loss {'Reaction outcome loss': 0.44107349176591915, 'Total loss': 0.44107349176591915}
2023-01-05 06:23:36,263 INFO:     Found new best model at epoch 5
2023-01-05 06:23:36,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:36,265 INFO:     Epoch: 6
2023-01-05 06:23:38,534 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4681033730506897, 'Total loss': 0.4681033730506897} | train loss {'Reaction outcome loss': 0.4265891796361238, 'Total loss': 0.4265891796361238}
2023-01-05 06:23:38,534 INFO:     Found new best model at epoch 6
2023-01-05 06:23:38,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:38,535 INFO:     Epoch: 7
2023-01-05 06:23:40,788 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4495384891827901, 'Total loss': 0.4495384891827901} | train loss {'Reaction outcome loss': 0.41294711513532195, 'Total loss': 0.41294711513532195}
2023-01-05 06:23:40,788 INFO:     Found new best model at epoch 7
2023-01-05 06:23:40,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:40,790 INFO:     Epoch: 8
2023-01-05 06:23:43,075 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45340380469957986, 'Total loss': 0.45340380469957986} | train loss {'Reaction outcome loss': 0.393757392944842, 'Total loss': 0.393757392944842}
2023-01-05 06:23:43,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:43,076 INFO:     Epoch: 9
2023-01-05 06:23:45,371 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4509202500184377, 'Total loss': 0.4509202500184377} | train loss {'Reaction outcome loss': 0.3853292590282884, 'Total loss': 0.3853292590282884}
2023-01-05 06:23:45,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:45,371 INFO:     Epoch: 10
2023-01-05 06:23:47,665 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44304532607396446, 'Total loss': 0.44304532607396446} | train loss {'Reaction outcome loss': 0.37595864920624755, 'Total loss': 0.37595864920624755}
2023-01-05 06:23:47,665 INFO:     Found new best model at epoch 10
2023-01-05 06:23:47,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:47,666 INFO:     Epoch: 11
2023-01-05 06:23:49,955 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44482468366622924, 'Total loss': 0.44482468366622924} | train loss {'Reaction outcome loss': 0.3660074094787832, 'Total loss': 0.3660074094787832}
2023-01-05 06:23:49,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:49,955 INFO:     Epoch: 12
2023-01-05 06:23:52,225 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43852561215559643, 'Total loss': 0.43852561215559643} | train loss {'Reaction outcome loss': 0.3546399576623087, 'Total loss': 0.3546399576623087}
2023-01-05 06:23:52,225 INFO:     Found new best model at epoch 12
2023-01-05 06:23:52,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:52,226 INFO:     Epoch: 13
2023-01-05 06:23:54,514 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4352288991212845, 'Total loss': 0.4352288991212845} | train loss {'Reaction outcome loss': 0.3505790914923275, 'Total loss': 0.3505790914923275}
2023-01-05 06:23:54,515 INFO:     Found new best model at epoch 13
2023-01-05 06:23:54,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:54,516 INFO:     Epoch: 14
2023-01-05 06:23:56,800 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44277796149253845, 'Total loss': 0.44277796149253845} | train loss {'Reaction outcome loss': 0.33996754567330495, 'Total loss': 0.33996754567330495}
2023-01-05 06:23:56,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:56,801 INFO:     Epoch: 15
2023-01-05 06:23:59,107 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43165691594282785, 'Total loss': 0.43165691594282785} | train loss {'Reaction outcome loss': 0.3338355349800432, 'Total loss': 0.3338355349800432}
2023-01-05 06:23:59,107 INFO:     Found new best model at epoch 15
2023-01-05 06:23:59,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:23:59,108 INFO:     Epoch: 16
2023-01-05 06:24:01,400 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4137651910384496, 'Total loss': 0.4137651910384496} | train loss {'Reaction outcome loss': 0.3225983526786312, 'Total loss': 0.3225983526786312}
2023-01-05 06:24:01,401 INFO:     Found new best model at epoch 16
2023-01-05 06:24:01,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:01,402 INFO:     Epoch: 17
2023-01-05 06:24:03,626 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45683969954649606, 'Total loss': 0.45683969954649606} | train loss {'Reaction outcome loss': 0.31965923138527663, 'Total loss': 0.31965923138527663}
2023-01-05 06:24:03,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:03,626 INFO:     Epoch: 18
2023-01-05 06:24:05,911 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4415898819764455, 'Total loss': 0.4415898819764455} | train loss {'Reaction outcome loss': 0.3113797508341526, 'Total loss': 0.3113797508341526}
2023-01-05 06:24:05,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:05,911 INFO:     Epoch: 19
2023-01-05 06:24:08,208 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4463913102944692, 'Total loss': 0.4463913102944692} | train loss {'Reaction outcome loss': 0.30192202938861795, 'Total loss': 0.30192202938861795}
2023-01-05 06:24:08,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:08,208 INFO:     Epoch: 20
2023-01-05 06:24:10,500 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42093494633833567, 'Total loss': 0.42093494633833567} | train loss {'Reaction outcome loss': 0.29839774180835765, 'Total loss': 0.29839774180835765}
2023-01-05 06:24:10,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:10,500 INFO:     Epoch: 21
2023-01-05 06:24:12,804 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4476222078005473, 'Total loss': 0.4476222078005473} | train loss {'Reaction outcome loss': 0.2931370572977118, 'Total loss': 0.2931370572977118}
2023-01-05 06:24:12,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:12,805 INFO:     Epoch: 22
2023-01-05 06:24:15,053 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44235058228174845, 'Total loss': 0.44235058228174845} | train loss {'Reaction outcome loss': 0.28666739667419494, 'Total loss': 0.28666739667419494}
2023-01-05 06:24:15,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:15,053 INFO:     Epoch: 23
2023-01-05 06:24:17,349 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45150638967752454, 'Total loss': 0.45150638967752454} | train loss {'Reaction outcome loss': 0.28006129331940566, 'Total loss': 0.28006129331940566}
2023-01-05 06:24:17,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:17,349 INFO:     Epoch: 24
2023-01-05 06:24:19,615 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43620441655317943, 'Total loss': 0.43620441655317943} | train loss {'Reaction outcome loss': 0.27497144181294775, 'Total loss': 0.27497144181294775}
2023-01-05 06:24:19,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:19,616 INFO:     Epoch: 25
2023-01-05 06:24:21,920 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45387536187966665, 'Total loss': 0.45387536187966665} | train loss {'Reaction outcome loss': 0.27186143364663157, 'Total loss': 0.27186143364663157}
2023-01-05 06:24:21,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:21,920 INFO:     Epoch: 26
2023-01-05 06:24:24,220 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4433078318834305, 'Total loss': 0.4433078318834305} | train loss {'Reaction outcome loss': 0.2645926720761973, 'Total loss': 0.2645926720761973}
2023-01-05 06:24:24,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:24,221 INFO:     Epoch: 27
2023-01-05 06:24:26,451 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45128806233406066, 'Total loss': 0.45128806233406066} | train loss {'Reaction outcome loss': 0.26219995775754273, 'Total loss': 0.26219995775754273}
2023-01-05 06:24:26,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:26,452 INFO:     Epoch: 28
2023-01-05 06:24:28,731 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45198758244514464, 'Total loss': 0.45198758244514464} | train loss {'Reaction outcome loss': 0.25674376653218206, 'Total loss': 0.25674376653218206}
2023-01-05 06:24:28,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:28,731 INFO:     Epoch: 29
2023-01-05 06:24:31,039 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4460547332962354, 'Total loss': 0.4460547332962354} | train loss {'Reaction outcome loss': 0.251038464525923, 'Total loss': 0.251038464525923}
2023-01-05 06:24:31,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:31,039 INFO:     Epoch: 30
2023-01-05 06:24:33,322 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4583658705155055, 'Total loss': 0.4583658705155055} | train loss {'Reaction outcome loss': 0.24640112528947286, 'Total loss': 0.24640112528947286}
2023-01-05 06:24:33,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:33,323 INFO:     Epoch: 31
2023-01-05 06:24:35,614 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45974154969056447, 'Total loss': 0.45974154969056447} | train loss {'Reaction outcome loss': 0.24271650484591614, 'Total loss': 0.24271650484591614}
2023-01-05 06:24:35,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:35,615 INFO:     Epoch: 32
2023-01-05 06:24:37,882 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4484871337811152, 'Total loss': 0.4484871337811152} | train loss {'Reaction outcome loss': 0.24345267737546553, 'Total loss': 0.24345267737546553}
2023-01-05 06:24:37,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:37,882 INFO:     Epoch: 33
2023-01-05 06:24:40,191 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44944388369719185, 'Total loss': 0.44944388369719185} | train loss {'Reaction outcome loss': 0.2423581392756438, 'Total loss': 0.2423581392756438}
2023-01-05 06:24:40,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:40,191 INFO:     Epoch: 34
2023-01-05 06:24:42,491 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45590212345123293, 'Total loss': 0.45590212345123293} | train loss {'Reaction outcome loss': 0.23687789795604208, 'Total loss': 0.23687789795604208}
2023-01-05 06:24:42,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:42,491 INFO:     Epoch: 35
2023-01-05 06:24:44,791 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42969202597935996, 'Total loss': 0.42969202597935996} | train loss {'Reaction outcome loss': 0.23117343154786296, 'Total loss': 0.23117343154786296}
2023-01-05 06:24:44,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:44,791 INFO:     Epoch: 36
2023-01-05 06:24:47,076 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.493300054470698, 'Total loss': 0.493300054470698} | train loss {'Reaction outcome loss': 0.23127171281550335, 'Total loss': 0.23127171281550335}
2023-01-05 06:24:47,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:47,076 INFO:     Epoch: 37
2023-01-05 06:24:49,345 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4368217071983963, 'Total loss': 0.4368217071983963} | train loss {'Reaction outcome loss': 0.22981677193947755, 'Total loss': 0.22981677193947755}
2023-01-05 06:24:49,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:49,347 INFO:     Epoch: 38
2023-01-05 06:24:51,607 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4602653483549754, 'Total loss': 0.4602653483549754} | train loss {'Reaction outcome loss': 0.23078085289804084, 'Total loss': 0.23078085289804084}
2023-01-05 06:24:51,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:51,607 INFO:     Epoch: 39
2023-01-05 06:24:53,889 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47256399393081666, 'Total loss': 0.47256399393081666} | train loss {'Reaction outcome loss': 0.222279822790074, 'Total loss': 0.222279822790074}
2023-01-05 06:24:53,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:53,890 INFO:     Epoch: 40
2023-01-05 06:24:56,181 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45325562357902527, 'Total loss': 0.45325562357902527} | train loss {'Reaction outcome loss': 0.2217296372682179, 'Total loss': 0.2217296372682179}
2023-01-05 06:24:56,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:56,182 INFO:     Epoch: 41
2023-01-05 06:24:58,470 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4659122973680496, 'Total loss': 0.4659122973680496} | train loss {'Reaction outcome loss': 0.21715265215586346, 'Total loss': 0.21715265215586346}
2023-01-05 06:24:58,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:24:58,470 INFO:     Epoch: 42
2023-01-05 06:25:00,740 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4650488058725993, 'Total loss': 0.4650488058725993} | train loss {'Reaction outcome loss': 0.22262484052416864, 'Total loss': 0.22262484052416864}
2023-01-05 06:25:00,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:00,740 INFO:     Epoch: 43
2023-01-05 06:25:03,006 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44332471092542014, 'Total loss': 0.44332471092542014} | train loss {'Reaction outcome loss': 0.2165757617728267, 'Total loss': 0.2165757617728267}
2023-01-05 06:25:03,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:03,007 INFO:     Epoch: 44
2023-01-05 06:25:05,274 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45912206123272575, 'Total loss': 0.45912206123272575} | train loss {'Reaction outcome loss': 0.21291023603764897, 'Total loss': 0.21291023603764897}
2023-01-05 06:25:05,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:05,275 INFO:     Epoch: 45
2023-01-05 06:25:07,559 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48220095038414, 'Total loss': 0.48220095038414} | train loss {'Reaction outcome loss': 0.21094689114079793, 'Total loss': 0.21094689114079793}
2023-01-05 06:25:07,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:07,559 INFO:     Epoch: 46
2023-01-05 06:25:09,827 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49675854841868083, 'Total loss': 0.49675854841868083} | train loss {'Reaction outcome loss': 0.21639734362874058, 'Total loss': 0.21639734362874058}
2023-01-05 06:25:09,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:09,828 INFO:     Epoch: 47
2023-01-05 06:25:12,100 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49213846822579704, 'Total loss': 0.49213846822579704} | train loss {'Reaction outcome loss': 0.20980147102894767, 'Total loss': 0.20980147102894767}
2023-01-05 06:25:12,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:12,101 INFO:     Epoch: 48
2023-01-05 06:25:14,357 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48899731834729515, 'Total loss': 0.48899731834729515} | train loss {'Reaction outcome loss': 0.20495763132584008, 'Total loss': 0.20495763132584008}
2023-01-05 06:25:14,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:14,357 INFO:     Epoch: 49
2023-01-05 06:25:16,644 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5158740212519963, 'Total loss': 0.5158740212519963} | train loss {'Reaction outcome loss': 0.20618382044849307, 'Total loss': 0.20618382044849307}
2023-01-05 06:25:16,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:16,645 INFO:     Epoch: 50
2023-01-05 06:25:18,891 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4491012252867222, 'Total loss': 0.4491012252867222} | train loss {'Reaction outcome loss': 0.2079908854768541, 'Total loss': 0.2079908854768541}
2023-01-05 06:25:18,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:18,892 INFO:     Epoch: 51
2023-01-05 06:25:21,161 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4842435583472252, 'Total loss': 0.4842435583472252} | train loss {'Reaction outcome loss': 0.20302009929159812, 'Total loss': 0.20302009929159812}
2023-01-05 06:25:21,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:21,162 INFO:     Epoch: 52
2023-01-05 06:25:23,431 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5110241860151291, 'Total loss': 0.5110241860151291} | train loss {'Reaction outcome loss': 0.19960914236839714, 'Total loss': 0.19960914236839714}
2023-01-05 06:25:23,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:23,432 INFO:     Epoch: 53
2023-01-05 06:25:25,756 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47416026492913566, 'Total loss': 0.47416026492913566} | train loss {'Reaction outcome loss': 0.2035745910372222, 'Total loss': 0.2035745910372222}
2023-01-05 06:25:25,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:25,757 INFO:     Epoch: 54
2023-01-05 06:25:27,996 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48755401372909546, 'Total loss': 0.48755401372909546} | train loss {'Reaction outcome loss': 0.2022910829589766, 'Total loss': 0.2022910829589766}
2023-01-05 06:25:27,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:27,997 INFO:     Epoch: 55
2023-01-05 06:25:30,278 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.494498743613561, 'Total loss': 0.494498743613561} | train loss {'Reaction outcome loss': 0.19624157205883025, 'Total loss': 0.19624157205883025}
2023-01-05 06:25:30,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:30,278 INFO:     Epoch: 56
2023-01-05 06:25:32,557 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4959501802921295, 'Total loss': 0.4959501802921295} | train loss {'Reaction outcome loss': 0.19401461051756833, 'Total loss': 0.19401461051756833}
2023-01-05 06:25:32,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:32,558 INFO:     Epoch: 57
2023-01-05 06:25:34,817 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.513464230298996, 'Total loss': 0.513464230298996} | train loss {'Reaction outcome loss': 0.19505367684934544, 'Total loss': 0.19505367684934544}
2023-01-05 06:25:34,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:34,817 INFO:     Epoch: 58
2023-01-05 06:25:37,070 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48272880874574187, 'Total loss': 0.48272880874574187} | train loss {'Reaction outcome loss': 0.19253631116358383, 'Total loss': 0.19253631116358383}
2023-01-05 06:25:37,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:37,070 INFO:     Epoch: 59
2023-01-05 06:25:39,353 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5008485992749532, 'Total loss': 0.5008485992749532} | train loss {'Reaction outcome loss': 0.19508351116787495, 'Total loss': 0.19508351116787495}
2023-01-05 06:25:39,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:39,353 INFO:     Epoch: 60
2023-01-05 06:25:41,636 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5202895184357961, 'Total loss': 0.5202895184357961} | train loss {'Reaction outcome loss': 0.1880866614698234, 'Total loss': 0.1880866614698234}
2023-01-05 06:25:41,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:41,636 INFO:     Epoch: 61
2023-01-05 06:25:43,919 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5230588952700297, 'Total loss': 0.5230588952700297} | train loss {'Reaction outcome loss': 0.18870442454444264, 'Total loss': 0.18870442454444264}
2023-01-05 06:25:43,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:43,919 INFO:     Epoch: 62
2023-01-05 06:25:46,196 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5358981490135193, 'Total loss': 0.5358981490135193} | train loss {'Reaction outcome loss': 0.18544798685130176, 'Total loss': 0.18544798685130176}
2023-01-05 06:25:46,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:46,197 INFO:     Epoch: 63
2023-01-05 06:25:48,282 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.518476381401221, 'Total loss': 0.518476381401221} | train loss {'Reaction outcome loss': 0.19371039034388557, 'Total loss': 0.19371039034388557}
2023-01-05 06:25:48,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:48,283 INFO:     Epoch: 64
2023-01-05 06:25:50,154 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.539804556965828, 'Total loss': 0.539804556965828} | train loss {'Reaction outcome loss': 0.18543975951573693, 'Total loss': 0.18543975951573693}
2023-01-05 06:25:50,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:50,154 INFO:     Epoch: 65
2023-01-05 06:25:52,068 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.488407959540685, 'Total loss': 0.488407959540685} | train loss {'Reaction outcome loss': 0.18394964089153154, 'Total loss': 0.18394964089153154}
2023-01-05 06:25:52,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:52,068 INFO:     Epoch: 66
2023-01-05 06:25:54,375 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5081851546963055, 'Total loss': 0.5081851546963055} | train loss {'Reaction outcome loss': 0.18548955016732485, 'Total loss': 0.18548955016732485}
2023-01-05 06:25:54,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:54,375 INFO:     Epoch: 67
2023-01-05 06:25:56,669 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5095142722129822, 'Total loss': 0.5095142722129822} | train loss {'Reaction outcome loss': 0.18365935293372573, 'Total loss': 0.18365935293372573}
2023-01-05 06:25:56,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:56,670 INFO:     Epoch: 68
2023-01-05 06:25:58,966 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5019868652025858, 'Total loss': 0.5019868652025858} | train loss {'Reaction outcome loss': 0.18497266351087321, 'Total loss': 0.18497266351087321}
2023-01-05 06:25:58,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:25:58,966 INFO:     Epoch: 69
2023-01-05 06:26:01,243 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5238733033339182, 'Total loss': 0.5238733033339182} | train loss {'Reaction outcome loss': 0.1812098353886002, 'Total loss': 0.1812098353886002}
2023-01-05 06:26:01,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:01,243 INFO:     Epoch: 70
2023-01-05 06:26:03,523 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5162352979183197, 'Total loss': 0.5162352979183197} | train loss {'Reaction outcome loss': 0.17592287822273503, 'Total loss': 0.17592287822273503}
2023-01-05 06:26:03,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:03,524 INFO:     Epoch: 71
2023-01-05 06:26:05,770 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5219180603822072, 'Total loss': 0.5219180603822072} | train loss {'Reaction outcome loss': 0.18488093076562945, 'Total loss': 0.18488093076562945}
2023-01-05 06:26:05,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:05,771 INFO:     Epoch: 72
2023-01-05 06:26:08,063 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.528121754527092, 'Total loss': 0.528121754527092} | train loss {'Reaction outcome loss': 0.17973199724102062, 'Total loss': 0.17973199724102062}
2023-01-05 06:26:08,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:08,063 INFO:     Epoch: 73
2023-01-05 06:26:10,369 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5078936358292897, 'Total loss': 0.5078936358292897} | train loss {'Reaction outcome loss': 0.1781393267173952, 'Total loss': 0.1781393267173952}
2023-01-05 06:26:10,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:10,369 INFO:     Epoch: 74
2023-01-05 06:26:12,670 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5292693032572667, 'Total loss': 0.5292693032572667} | train loss {'Reaction outcome loss': 0.1752451481986858, 'Total loss': 0.1752451481986858}
2023-01-05 06:26:12,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:12,670 INFO:     Epoch: 75
2023-01-05 06:26:14,725 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.52972498635451, 'Total loss': 0.52972498635451} | train loss {'Reaction outcome loss': 0.17596772908727346, 'Total loss': 0.17596772908727346}
2023-01-05 06:26:14,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:14,725 INFO:     Epoch: 76
2023-01-05 06:26:17,011 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5204976767301559, 'Total loss': 0.5204976767301559} | train loss {'Reaction outcome loss': 0.17524139330275224, 'Total loss': 0.17524139330275224}
2023-01-05 06:26:17,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:17,012 INFO:     Epoch: 77
2023-01-05 06:26:19,299 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5087990045547486, 'Total loss': 0.5087990045547486} | train loss {'Reaction outcome loss': 0.18022807202863403, 'Total loss': 0.18022807202863403}
2023-01-05 06:26:19,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:19,299 INFO:     Epoch: 78
2023-01-05 06:26:21,549 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4951669633388519, 'Total loss': 0.4951669633388519} | train loss {'Reaction outcome loss': 0.17437331137728174, 'Total loss': 0.17437331137728174}
2023-01-05 06:26:21,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:21,549 INFO:     Epoch: 79
2023-01-05 06:26:23,826 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5029133399327596, 'Total loss': 0.5029133399327596} | train loss {'Reaction outcome loss': 0.17244405194189036, 'Total loss': 0.17244405194189036}
2023-01-05 06:26:23,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:23,827 INFO:     Epoch: 80
2023-01-05 06:26:26,094 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.517695082227389, 'Total loss': 0.517695082227389} | train loss {'Reaction outcome loss': 0.17193824820059087, 'Total loss': 0.17193824820059087}
2023-01-05 06:26:26,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:26,096 INFO:     Epoch: 81
2023-01-05 06:26:28,323 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5042400618394216, 'Total loss': 0.5042400618394216} | train loss {'Reaction outcome loss': 0.17183551891952323, 'Total loss': 0.17183551891952323}
2023-01-05 06:26:28,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:28,323 INFO:     Epoch: 82
2023-01-05 06:26:30,587 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5101676642894745, 'Total loss': 0.5101676642894745} | train loss {'Reaction outcome loss': 0.17003378425792048, 'Total loss': 0.17003378425792048}
2023-01-05 06:26:30,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:30,587 INFO:     Epoch: 83
2023-01-05 06:26:32,821 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5526390125354131, 'Total loss': 0.5526390125354131} | train loss {'Reaction outcome loss': 0.16697357785266015, 'Total loss': 0.16697357785266015}
2023-01-05 06:26:32,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:32,822 INFO:     Epoch: 84
2023-01-05 06:26:35,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5301887224117915, 'Total loss': 0.5301887224117915} | train loss {'Reaction outcome loss': 0.1665218297126518, 'Total loss': 0.1665218297126518}
2023-01-05 06:26:35,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:35,082 INFO:     Epoch: 85
2023-01-05 06:26:37,330 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5140038184821606, 'Total loss': 0.5140038184821606} | train loss {'Reaction outcome loss': 0.1667042126801766, 'Total loss': 0.1667042126801766}
2023-01-05 06:26:37,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:37,330 INFO:     Epoch: 86
2023-01-05 06:26:39,545 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5232353925704956, 'Total loss': 0.5232353925704956} | train loss {'Reaction outcome loss': 0.16469631138146731, 'Total loss': 0.16469631138146731}
2023-01-05 06:26:39,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:39,545 INFO:     Epoch: 87
2023-01-05 06:26:41,799 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5449820121129354, 'Total loss': 0.5449820121129354} | train loss {'Reaction outcome loss': 0.16287901793986506, 'Total loss': 0.16287901793986506}
2023-01-05 06:26:41,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:41,799 INFO:     Epoch: 88
2023-01-05 06:26:44,069 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4991165190935135, 'Total loss': 0.4991165190935135} | train loss {'Reaction outcome loss': 0.16722523620762333, 'Total loss': 0.16722523620762333}
2023-01-05 06:26:44,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:44,070 INFO:     Epoch: 89
2023-01-05 06:26:46,377 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5223914007345836, 'Total loss': 0.5223914007345836} | train loss {'Reaction outcome loss': 0.16124232170014013, 'Total loss': 0.16124232170014013}
2023-01-05 06:26:46,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:46,378 INFO:     Epoch: 90
2023-01-05 06:26:48,655 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5294575991729895, 'Total loss': 0.5294575991729895} | train loss {'Reaction outcome loss': 0.1579394402849868, 'Total loss': 0.1579394402849868}
2023-01-05 06:26:48,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:48,655 INFO:     Epoch: 91
2023-01-05 06:26:50,943 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5345511595408122, 'Total loss': 0.5345511595408122} | train loss {'Reaction outcome loss': 0.16425502294210537, 'Total loss': 0.16425502294210537}
2023-01-05 06:26:50,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:50,943 INFO:     Epoch: 92
2023-01-05 06:26:53,183 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.552571572860082, 'Total loss': 0.552571572860082} | train loss {'Reaction outcome loss': 0.16195697182392707, 'Total loss': 0.16195697182392707}
2023-01-05 06:26:53,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:53,183 INFO:     Epoch: 93
2023-01-05 06:26:55,454 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5421037783225378, 'Total loss': 0.5421037783225378} | train loss {'Reaction outcome loss': 0.16122043153963686, 'Total loss': 0.16122043153963686}
2023-01-05 06:26:55,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:55,454 INFO:     Epoch: 94
2023-01-05 06:26:57,732 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5241621633370718, 'Total loss': 0.5241621633370718} | train loss {'Reaction outcome loss': 0.16429722722828227, 'Total loss': 0.16429722722828227}
2023-01-05 06:26:57,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:26:57,733 INFO:     Epoch: 95
2023-01-05 06:27:00,046 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5713338613510132, 'Total loss': 0.5713338613510132} | train loss {'Reaction outcome loss': 0.1567386447633566, 'Total loss': 0.1567386447633566}
2023-01-05 06:27:00,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:00,047 INFO:     Epoch: 96
2023-01-05 06:27:02,345 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49670469562212627, 'Total loss': 0.49670469562212627} | train loss {'Reaction outcome loss': 0.15967192311034897, 'Total loss': 0.15967192311034897}
2023-01-05 06:27:02,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:02,346 INFO:     Epoch: 97
2023-01-05 06:27:04,590 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5316276361544927, 'Total loss': 0.5316276361544927} | train loss {'Reaction outcome loss': 0.16022292692853063, 'Total loss': 0.16022292692853063}
2023-01-05 06:27:04,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:04,590 INFO:     Epoch: 98
2023-01-05 06:27:06,874 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4980695287386576, 'Total loss': 0.4980695287386576} | train loss {'Reaction outcome loss': 0.15505393299388462, 'Total loss': 0.15505393299388462}
2023-01-05 06:27:06,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:06,874 INFO:     Epoch: 99
2023-01-05 06:27:09,219 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.529928962389628, 'Total loss': 0.529928962389628} | train loss {'Reaction outcome loss': 0.15449388411706347, 'Total loss': 0.15449388411706347}
2023-01-05 06:27:09,220 INFO:     Best model found after epoch 17 of 100.
2023-01-05 06:27:09,220 INFO:   Done with stage: TRAINING
2023-01-05 06:27:09,220 INFO:   Starting stage: EVALUATION
2023-01-05 06:27:09,347 INFO:   Done with stage: EVALUATION
2023-01-05 06:27:09,355 INFO:   Leaving out SEQ value Fold_0
2023-01-05 06:27:09,368 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 06:27:09,368 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:27:10,020 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:27:10,020 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:27:10,093 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:27:10,093 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:27:10,093 INFO:     No hyperparam tuning for this model
2023-01-05 06:27:10,093 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:27:10,093 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:27:10,094 INFO:     None feature selector for col prot
2023-01-05 06:27:10,094 INFO:     None feature selector for col prot
2023-01-05 06:27:10,094 INFO:     None feature selector for col prot
2023-01-05 06:27:10,095 INFO:     None feature selector for col chem
2023-01-05 06:27:10,095 INFO:     None feature selector for col chem
2023-01-05 06:27:10,095 INFO:     None feature selector for col chem
2023-01-05 06:27:10,095 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:27:10,095 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:27:10,097 INFO:     Number of params in model 72931
2023-01-05 06:27:10,100 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:27:10,100 INFO:   Starting stage: TRAINING
2023-01-05 06:27:10,163 INFO:     Val loss before train {'Reaction outcome loss': 0.9631885568300883, 'Total loss': 0.9631885568300883}
2023-01-05 06:27:10,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:10,164 INFO:     Epoch: 0
2023-01-05 06:27:12,512 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8008437136809031, 'Total loss': 0.8008437136809031} | train loss {'Reaction outcome loss': 0.9565948362367741, 'Total loss': 0.9565948362367741}
2023-01-05 06:27:12,512 INFO:     Found new best model at epoch 0
2023-01-05 06:27:12,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:12,513 INFO:     Epoch: 1
2023-01-05 06:27:14,829 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5870949308077494, 'Total loss': 0.5870949308077494} | train loss {'Reaction outcome loss': 0.6897145202653348, 'Total loss': 0.6897145202653348}
2023-01-05 06:27:14,829 INFO:     Found new best model at epoch 1
2023-01-05 06:27:14,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:14,831 INFO:     Epoch: 2
2023-01-05 06:27:17,105 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.554450786113739, 'Total loss': 0.554450786113739} | train loss {'Reaction outcome loss': 0.5491724017251661, 'Total loss': 0.5491724017251661}
2023-01-05 06:27:17,106 INFO:     Found new best model at epoch 2
2023-01-05 06:27:17,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:17,107 INFO:     Epoch: 3
2023-01-05 06:27:19,383 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5169949531555176, 'Total loss': 0.5169949531555176} | train loss {'Reaction outcome loss': 0.5014606713303837, 'Total loss': 0.5014606713303837}
2023-01-05 06:27:19,383 INFO:     Found new best model at epoch 3
2023-01-05 06:27:19,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:19,385 INFO:     Epoch: 4
2023-01-05 06:27:21,674 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5620441158612569, 'Total loss': 0.5620441158612569} | train loss {'Reaction outcome loss': 0.47073726257326187, 'Total loss': 0.47073726257326187}
2023-01-05 06:27:21,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:21,675 INFO:     Epoch: 5
2023-01-05 06:27:23,918 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5190718909104665, 'Total loss': 0.5190718909104665} | train loss {'Reaction outcome loss': 0.4557657276712142, 'Total loss': 0.4557657276712142}
2023-01-05 06:27:23,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:23,918 INFO:     Epoch: 6
2023-01-05 06:27:26,208 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5194932520389557, 'Total loss': 0.5194932520389557} | train loss {'Reaction outcome loss': 0.43362450379662326, 'Total loss': 0.43362450379662326}
2023-01-05 06:27:26,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:26,208 INFO:     Epoch: 7
2023-01-05 06:27:28,477 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5020305852095286, 'Total loss': 0.5020305852095286} | train loss {'Reaction outcome loss': 0.41390454474215704, 'Total loss': 0.41390454474215704}
2023-01-05 06:27:28,478 INFO:     Found new best model at epoch 7
2023-01-05 06:27:28,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:28,479 INFO:     Epoch: 8
2023-01-05 06:27:30,773 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5019970496495565, 'Total loss': 0.5019970496495565} | train loss {'Reaction outcome loss': 0.4017984082456678, 'Total loss': 0.4017984082456678}
2023-01-05 06:27:30,773 INFO:     Found new best model at epoch 8
2023-01-05 06:27:30,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:30,774 INFO:     Epoch: 9
2023-01-05 06:27:33,071 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5118324855963389, 'Total loss': 0.5118324855963389} | train loss {'Reaction outcome loss': 0.3896401935675438, 'Total loss': 0.3896401935675438}
2023-01-05 06:27:33,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:33,072 INFO:     Epoch: 10
2023-01-05 06:27:35,326 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5145714382330576, 'Total loss': 0.5145714382330576} | train loss {'Reaction outcome loss': 0.37568964945587696, 'Total loss': 0.37568964945587696}
2023-01-05 06:27:35,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:35,326 INFO:     Epoch: 11
2023-01-05 06:27:37,623 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5020586957534154, 'Total loss': 0.5020586957534154} | train loss {'Reaction outcome loss': 0.3668132042107375, 'Total loss': 0.3668132042107375}
2023-01-05 06:27:37,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:37,624 INFO:     Epoch: 12
2023-01-05 06:27:39,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5187394440174102, 'Total loss': 0.5187394440174102} | train loss {'Reaction outcome loss': 0.3551444745474104, 'Total loss': 0.3551444745474104}
2023-01-05 06:27:39,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:39,896 INFO:     Epoch: 13
2023-01-05 06:27:42,176 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4863102306922277, 'Total loss': 0.4863102306922277} | train loss {'Reaction outcome loss': 0.33930377345414076, 'Total loss': 0.33930377345414076}
2023-01-05 06:27:42,176 INFO:     Found new best model at epoch 13
2023-01-05 06:27:42,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:42,177 INFO:     Epoch: 14
2023-01-05 06:27:44,465 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4870492498079936, 'Total loss': 0.4870492498079936} | train loss {'Reaction outcome loss': 0.32918182059749623, 'Total loss': 0.32918182059749623}
2023-01-05 06:27:44,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:44,466 INFO:     Epoch: 15
2023-01-05 06:27:46,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4734612723191579, 'Total loss': 0.4734612723191579} | train loss {'Reaction outcome loss': 0.32053200696743483, 'Total loss': 0.32053200696743483}
2023-01-05 06:27:46,746 INFO:     Found new best model at epoch 15
2023-01-05 06:27:46,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:46,747 INFO:     Epoch: 16
2023-01-05 06:27:49,034 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.492129377524058, 'Total loss': 0.492129377524058} | train loss {'Reaction outcome loss': 0.3126258260260026, 'Total loss': 0.3126258260260026}
2023-01-05 06:27:49,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:49,034 INFO:     Epoch: 17
2023-01-05 06:27:51,309 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4802460034688314, 'Total loss': 0.4802460034688314} | train loss {'Reaction outcome loss': 0.30695181545308803, 'Total loss': 0.30695181545308803}
2023-01-05 06:27:51,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:51,309 INFO:     Epoch: 18
2023-01-05 06:27:53,569 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46344387034575146, 'Total loss': 0.46344387034575146} | train loss {'Reaction outcome loss': 0.2992939716677411, 'Total loss': 0.2992939716677411}
2023-01-05 06:27:53,569 INFO:     Found new best model at epoch 18
2023-01-05 06:27:53,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:53,571 INFO:     Epoch: 19
2023-01-05 06:27:55,831 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5009080698092778, 'Total loss': 0.5009080698092778} | train loss {'Reaction outcome loss': 0.2934953336320493, 'Total loss': 0.2934953336320493}
2023-01-05 06:27:55,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:55,831 INFO:     Epoch: 20
2023-01-05 06:27:58,096 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47506695489088696, 'Total loss': 0.47506695489088696} | train loss {'Reaction outcome loss': 0.2876164031220179, 'Total loss': 0.2876164031220179}
2023-01-05 06:27:58,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:27:58,097 INFO:     Epoch: 21
2023-01-05 06:28:00,369 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47083525160948436, 'Total loss': 0.47083525160948436} | train loss {'Reaction outcome loss': 0.28258173351945437, 'Total loss': 0.28258173351945437}
2023-01-05 06:28:00,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:00,369 INFO:     Epoch: 22
2023-01-05 06:28:02,637 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4571743677059809, 'Total loss': 0.4571743677059809} | train loss {'Reaction outcome loss': 0.2780307206064564, 'Total loss': 0.2780307206064564}
2023-01-05 06:28:02,637 INFO:     Found new best model at epoch 22
2023-01-05 06:28:02,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:02,638 INFO:     Epoch: 23
2023-01-05 06:28:04,908 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47388305962085725, 'Total loss': 0.47388305962085725} | train loss {'Reaction outcome loss': 0.26510357209717506, 'Total loss': 0.26510357209717506}
2023-01-05 06:28:04,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:04,908 INFO:     Epoch: 24
2023-01-05 06:28:07,200 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4577104955911636, 'Total loss': 0.4577104955911636} | train loss {'Reaction outcome loss': 0.2706841573362117, 'Total loss': 0.2706841573362117}
2023-01-05 06:28:07,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:07,200 INFO:     Epoch: 25
2023-01-05 06:28:09,469 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4531188969810804, 'Total loss': 0.4531188969810804} | train loss {'Reaction outcome loss': 0.26086979558475426, 'Total loss': 0.26086979558475426}
2023-01-05 06:28:09,469 INFO:     Found new best model at epoch 25
2023-01-05 06:28:09,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:09,471 INFO:     Epoch: 26
2023-01-05 06:28:11,752 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4923264781634013, 'Total loss': 0.4923264781634013} | train loss {'Reaction outcome loss': 0.2581811697202046, 'Total loss': 0.2581811697202046}
2023-01-05 06:28:11,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:11,752 INFO:     Epoch: 27
2023-01-05 06:28:13,990 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4862284262975057, 'Total loss': 0.4862284262975057} | train loss {'Reaction outcome loss': 0.2515303525530423, 'Total loss': 0.2515303525530423}
2023-01-05 06:28:13,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:13,992 INFO:     Epoch: 28
2023-01-05 06:28:16,247 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4588805173834165, 'Total loss': 0.4588805173834165} | train loss {'Reaction outcome loss': 0.25278123891305015, 'Total loss': 0.25278123891305015}
2023-01-05 06:28:16,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:16,248 INFO:     Epoch: 29
2023-01-05 06:28:18,512 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45448215703169503, 'Total loss': 0.45448215703169503} | train loss {'Reaction outcome loss': 0.2502063574282911, 'Total loss': 0.2502063574282911}
2023-01-05 06:28:18,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:18,512 INFO:     Epoch: 30
2023-01-05 06:28:20,774 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49842211107412976, 'Total loss': 0.49842211107412976} | train loss {'Reaction outcome loss': 0.24076551271170593, 'Total loss': 0.24076551271170593}
2023-01-05 06:28:20,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:20,775 INFO:     Epoch: 31
2023-01-05 06:28:23,057 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47474894920984906, 'Total loss': 0.47474894920984906} | train loss {'Reaction outcome loss': 0.23885387832811777, 'Total loss': 0.23885387832811777}
2023-01-05 06:28:23,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:23,057 INFO:     Epoch: 32
2023-01-05 06:28:25,330 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4817392999927203, 'Total loss': 0.4817392999927203} | train loss {'Reaction outcome loss': 0.2364428760247656, 'Total loss': 0.2364428760247656}
2023-01-05 06:28:25,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:25,330 INFO:     Epoch: 33
2023-01-05 06:28:27,575 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4485512524843216, 'Total loss': 0.4485512524843216} | train loss {'Reaction outcome loss': 0.23377363889217057, 'Total loss': 0.23377363889217057}
2023-01-05 06:28:27,575 INFO:     Found new best model at epoch 33
2023-01-05 06:28:27,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:27,577 INFO:     Epoch: 34
2023-01-05 06:28:29,863 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.50439672768116, 'Total loss': 0.50439672768116} | train loss {'Reaction outcome loss': 0.2303903858140246, 'Total loss': 0.2303903858140246}
2023-01-05 06:28:29,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:29,863 INFO:     Epoch: 35
2023-01-05 06:28:32,174 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4601041237513224, 'Total loss': 0.4601041237513224} | train loss {'Reaction outcome loss': 0.22801211000533061, 'Total loss': 0.22801211000533061}
2023-01-05 06:28:32,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:32,174 INFO:     Epoch: 36
2023-01-05 06:28:34,485 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44949705004692075, 'Total loss': 0.44949705004692075} | train loss {'Reaction outcome loss': 0.23029223440739705, 'Total loss': 0.23029223440739705}
2023-01-05 06:28:34,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:34,486 INFO:     Epoch: 37
2023-01-05 06:28:36,791 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4635892073313395, 'Total loss': 0.4635892073313395} | train loss {'Reaction outcome loss': 0.22308484006477386, 'Total loss': 0.22308484006477386}
2023-01-05 06:28:36,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:36,791 INFO:     Epoch: 38
2023-01-05 06:28:39,047 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4856758718689283, 'Total loss': 0.4856758718689283} | train loss {'Reaction outcome loss': 0.21995310058506826, 'Total loss': 0.21995310058506826}
2023-01-05 06:28:39,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:39,048 INFO:     Epoch: 39
2023-01-05 06:28:41,312 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.472948116560777, 'Total loss': 0.472948116560777} | train loss {'Reaction outcome loss': 0.21715897733372622, 'Total loss': 0.21715897733372622}
2023-01-05 06:28:41,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:41,313 INFO:     Epoch: 40
2023-01-05 06:28:43,557 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48615288486083347, 'Total loss': 0.48615288486083347} | train loss {'Reaction outcome loss': 0.2169935591293219, 'Total loss': 0.2169935591293219}
2023-01-05 06:28:43,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:43,557 INFO:     Epoch: 41
2023-01-05 06:28:45,794 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47363094886144, 'Total loss': 0.47363094886144} | train loss {'Reaction outcome loss': 0.211585651440528, 'Total loss': 0.211585651440528}
2023-01-05 06:28:45,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:45,794 INFO:     Epoch: 42
2023-01-05 06:28:48,053 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.453172226746877, 'Total loss': 0.453172226746877} | train loss {'Reaction outcome loss': 0.2110213177697058, 'Total loss': 0.2110213177697058}
2023-01-05 06:28:48,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:48,054 INFO:     Epoch: 43
2023-01-05 06:28:50,313 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48633441925048826, 'Total loss': 0.48633441925048826} | train loss {'Reaction outcome loss': 0.21002452851246126, 'Total loss': 0.21002452851246126}
2023-01-05 06:28:50,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:50,314 INFO:     Epoch: 44
2023-01-05 06:28:52,578 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46216440002123516, 'Total loss': 0.46216440002123516} | train loss {'Reaction outcome loss': 0.20740033168075953, 'Total loss': 0.20740033168075953}
2023-01-05 06:28:52,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:52,578 INFO:     Epoch: 45
2023-01-05 06:28:54,858 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4738880217075348, 'Total loss': 0.4738880217075348} | train loss {'Reaction outcome loss': 0.2029093480016762, 'Total loss': 0.2029093480016762}
2023-01-05 06:28:54,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:54,858 INFO:     Epoch: 46
2023-01-05 06:28:57,141 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4693564146757126, 'Total loss': 0.4693564146757126} | train loss {'Reaction outcome loss': 0.20132750602425548, 'Total loss': 0.20132750602425548}
2023-01-05 06:28:57,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:57,142 INFO:     Epoch: 47
2023-01-05 06:28:59,427 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4948389152685801, 'Total loss': 0.4948389152685801} | train loss {'Reaction outcome loss': 0.2054296460987973, 'Total loss': 0.2054296460987973}
2023-01-05 06:28:59,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:28:59,428 INFO:     Epoch: 48
2023-01-05 06:29:01,689 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4708192894856135, 'Total loss': 0.4708192894856135} | train loss {'Reaction outcome loss': 0.20054356685827573, 'Total loss': 0.20054356685827573}
2023-01-05 06:29:01,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:01,689 INFO:     Epoch: 49
2023-01-05 06:29:03,710 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4588153784473737, 'Total loss': 0.4588153784473737} | train loss {'Reaction outcome loss': 0.20270963943144982, 'Total loss': 0.20270963943144982}
2023-01-05 06:29:03,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:03,710 INFO:     Epoch: 50
2023-01-05 06:29:05,598 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49170546730359393, 'Total loss': 0.49170546730359393} | train loss {'Reaction outcome loss': 0.2734331929334102, 'Total loss': 0.2734331929334102}
2023-01-05 06:29:05,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:05,598 INFO:     Epoch: 51
2023-01-05 06:29:07,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4651100248098373, 'Total loss': 0.4651100248098373} | train loss {'Reaction outcome loss': 0.20337572871315954, 'Total loss': 0.20337572871315954}
2023-01-05 06:29:07,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:07,635 INFO:     Epoch: 52
2023-01-05 06:29:09,922 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4481323331594467, 'Total loss': 0.4481323331594467} | train loss {'Reaction outcome loss': 0.19868710438849108, 'Total loss': 0.19868710438849108}
2023-01-05 06:29:09,922 INFO:     Found new best model at epoch 52
2023-01-05 06:29:09,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:09,924 INFO:     Epoch: 53
2023-01-05 06:29:12,166 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48474908371766406, 'Total loss': 0.48474908371766406} | train loss {'Reaction outcome loss': 0.19848885397305308, 'Total loss': 0.19848885397305308}
2023-01-05 06:29:12,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:12,166 INFO:     Epoch: 54
2023-01-05 06:29:14,438 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4809025208155314, 'Total loss': 0.4809025208155314} | train loss {'Reaction outcome loss': 0.19140163720990327, 'Total loss': 0.19140163720990327}
2023-01-05 06:29:14,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:14,438 INFO:     Epoch: 55
2023-01-05 06:29:16,693 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47036990920702615, 'Total loss': 0.47036990920702615} | train loss {'Reaction outcome loss': 0.19015481544083476, 'Total loss': 0.19015481544083476}
2023-01-05 06:29:16,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:16,694 INFO:     Epoch: 56
2023-01-05 06:29:18,946 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4553345501422882, 'Total loss': 0.4553345501422882} | train loss {'Reaction outcome loss': 0.19424685492857321, 'Total loss': 0.19424685492857321}
2023-01-05 06:29:18,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:18,946 INFO:     Epoch: 57
2023-01-05 06:29:21,219 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4373799612124761, 'Total loss': 0.4373799612124761} | train loss {'Reaction outcome loss': 0.19069960406969863, 'Total loss': 0.19069960406969863}
2023-01-05 06:29:21,220 INFO:     Found new best model at epoch 57
2023-01-05 06:29:21,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:21,221 INFO:     Epoch: 58
2023-01-05 06:29:23,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45830046435197197, 'Total loss': 0.45830046435197197} | train loss {'Reaction outcome loss': 0.19021890672814587, 'Total loss': 0.19021890672814587}
2023-01-05 06:29:23,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:23,487 INFO:     Epoch: 59
2023-01-05 06:29:25,751 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42893210450808206, 'Total loss': 0.42893210450808206} | train loss {'Reaction outcome loss': 0.2004742211285992, 'Total loss': 0.2004742211285992}
2023-01-05 06:29:25,751 INFO:     Found new best model at epoch 59
2023-01-05 06:29:25,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:25,752 INFO:     Epoch: 60
2023-01-05 06:29:28,017 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47094611674547193, 'Total loss': 0.47094611674547193} | train loss {'Reaction outcome loss': 0.18749082155620167, 'Total loss': 0.18749082155620167}
2023-01-05 06:29:28,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:28,018 INFO:     Epoch: 61
2023-01-05 06:29:30,285 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4349491397539775, 'Total loss': 0.4349491397539775} | train loss {'Reaction outcome loss': 0.1822061087831558, 'Total loss': 0.1822061087831558}
2023-01-05 06:29:30,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:30,286 INFO:     Epoch: 62
2023-01-05 06:29:32,552 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4195003724346558, 'Total loss': 0.4195003724346558} | train loss {'Reaction outcome loss': 0.1844010448076533, 'Total loss': 0.1844010448076533}
2023-01-05 06:29:32,552 INFO:     Found new best model at epoch 62
2023-01-05 06:29:32,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:32,553 INFO:     Epoch: 63
2023-01-05 06:29:34,811 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.509548443555832, 'Total loss': 0.509548443555832} | train loss {'Reaction outcome loss': 0.18290033945822212, 'Total loss': 0.18290033945822212}
2023-01-05 06:29:34,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:34,811 INFO:     Epoch: 64
2023-01-05 06:29:37,052 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45476361910502117, 'Total loss': 0.45476361910502117} | train loss {'Reaction outcome loss': 0.18196360574971102, 'Total loss': 0.18196360574971102}
2023-01-05 06:29:37,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:37,052 INFO:     Epoch: 65
2023-01-05 06:29:39,315 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46571470697720846, 'Total loss': 0.46571470697720846} | train loss {'Reaction outcome loss': 0.17604217192401056, 'Total loss': 0.17604217192401056}
2023-01-05 06:29:39,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:39,315 INFO:     Epoch: 66
2023-01-05 06:29:41,576 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4340959757566452, 'Total loss': 0.4340959757566452} | train loss {'Reaction outcome loss': 0.18060863705982955, 'Total loss': 0.18060863705982955}
2023-01-05 06:29:41,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:41,576 INFO:     Epoch: 67
2023-01-05 06:29:43,820 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4361864467461904, 'Total loss': 0.4361864467461904} | train loss {'Reaction outcome loss': 0.17920068659873653, 'Total loss': 0.17920068659873653}
2023-01-05 06:29:43,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:43,820 INFO:     Epoch: 68
2023-01-05 06:29:46,098 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47674247026443484, 'Total loss': 0.47674247026443484} | train loss {'Reaction outcome loss': 0.17342628739129726, 'Total loss': 0.17342628739129726}
2023-01-05 06:29:46,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:46,099 INFO:     Epoch: 69
2023-01-05 06:29:48,358 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4492191708025833, 'Total loss': 0.4492191708025833} | train loss {'Reaction outcome loss': 0.17570034517152439, 'Total loss': 0.17570034517152439}
2023-01-05 06:29:48,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:48,358 INFO:     Epoch: 70
2023-01-05 06:29:50,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44809318681557975, 'Total loss': 0.44809318681557975} | train loss {'Reaction outcome loss': 0.1761223647732497, 'Total loss': 0.1761223647732497}
2023-01-05 06:29:50,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:50,648 INFO:     Epoch: 71
2023-01-05 06:29:52,943 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4818848729133606, 'Total loss': 0.4818848729133606} | train loss {'Reaction outcome loss': 0.1832944989871686, 'Total loss': 0.1832944989871686}
2023-01-05 06:29:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:52,944 INFO:     Epoch: 72
2023-01-05 06:29:55,196 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4430506487687429, 'Total loss': 0.4430506487687429} | train loss {'Reaction outcome loss': 0.18009483191754966, 'Total loss': 0.18009483191754966}
2023-01-05 06:29:55,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:55,197 INFO:     Epoch: 73
2023-01-05 06:29:57,475 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47359944780667623, 'Total loss': 0.47359944780667623} | train loss {'Reaction outcome loss': 0.17423032472109207, 'Total loss': 0.17423032472109207}
2023-01-05 06:29:57,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:57,476 INFO:     Epoch: 74
2023-01-05 06:29:59,762 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46280298630396527, 'Total loss': 0.46280298630396527} | train loss {'Reaction outcome loss': 0.17333345574434791, 'Total loss': 0.17333345574434791}
2023-01-05 06:29:59,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:29:59,763 INFO:     Epoch: 75
2023-01-05 06:30:02,056 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43980915198723475, 'Total loss': 0.43980915198723475} | train loss {'Reaction outcome loss': 0.1838931028164552, 'Total loss': 0.1838931028164552}
2023-01-05 06:30:02,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:02,057 INFO:     Epoch: 76
2023-01-05 06:30:04,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46666658806304134, 'Total loss': 0.46666658806304134} | train loss {'Reaction outcome loss': 0.17238707668013006, 'Total loss': 0.17238707668013006}
2023-01-05 06:30:04,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:04,334 INFO:     Epoch: 77
2023-01-05 06:30:06,594 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.482618048787117, 'Total loss': 0.482618048787117} | train loss {'Reaction outcome loss': 0.17196513420091925, 'Total loss': 0.17196513420091925}
2023-01-05 06:30:06,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:06,595 INFO:     Epoch: 78
2023-01-05 06:30:08,879 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46954866747061413, 'Total loss': 0.46954866747061413} | train loss {'Reaction outcome loss': 0.1676768591740098, 'Total loss': 0.1676768591740098}
2023-01-05 06:30:08,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:08,879 INFO:     Epoch: 79
2023-01-05 06:30:11,156 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48328828494995835, 'Total loss': 0.48328828494995835} | train loss {'Reaction outcome loss': 0.17233135706519007, 'Total loss': 0.17233135706519007}
2023-01-05 06:30:11,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:11,157 INFO:     Epoch: 80
2023-01-05 06:30:13,450 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49027136266231536, 'Total loss': 0.49027136266231536} | train loss {'Reaction outcome loss': 0.17547369310910732, 'Total loss': 0.17547369310910732}
2023-01-05 06:30:13,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:13,450 INFO:     Epoch: 81
2023-01-05 06:30:15,748 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4454020937283834, 'Total loss': 0.4454020937283834} | train loss {'Reaction outcome loss': 0.1740278203298289, 'Total loss': 0.1740278203298289}
2023-01-05 06:30:15,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:15,748 INFO:     Epoch: 82
2023-01-05 06:30:18,025 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4892254183689753, 'Total loss': 0.4892254183689753} | train loss {'Reaction outcome loss': 0.1714105090730405, 'Total loss': 0.1714105090730405}
2023-01-05 06:30:18,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:18,025 INFO:     Epoch: 83
2023-01-05 06:30:20,311 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4626308818658193, 'Total loss': 0.4626308818658193} | train loss {'Reaction outcome loss': 0.17054590344280546, 'Total loss': 0.17054590344280546}
2023-01-05 06:30:20,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:20,311 INFO:     Epoch: 84
2023-01-05 06:30:22,587 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5081376314163208, 'Total loss': 0.5081376314163208} | train loss {'Reaction outcome loss': 0.17278904068128517, 'Total loss': 0.17278904068128517}
2023-01-05 06:30:22,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:22,587 INFO:     Epoch: 85
2023-01-05 06:30:24,738 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44495871663093567, 'Total loss': 0.44495871663093567} | train loss {'Reaction outcome loss': 0.17432975977831316, 'Total loss': 0.17432975977831316}
2023-01-05 06:30:24,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:24,738 INFO:     Epoch: 86
2023-01-05 06:30:26,946 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4566783388455709, 'Total loss': 0.4566783388455709} | train loss {'Reaction outcome loss': 0.17296865117817145, 'Total loss': 0.17296865117817145}
2023-01-05 06:30:26,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:26,947 INFO:     Epoch: 87
2023-01-05 06:30:29,213 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45433513522148133, 'Total loss': 0.45433513522148133} | train loss {'Reaction outcome loss': 0.20895915346868013, 'Total loss': 0.20895915346868013}
2023-01-05 06:30:29,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:29,213 INFO:     Epoch: 88
2023-01-05 06:30:31,489 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.472024970750014, 'Total loss': 0.472024970750014} | train loss {'Reaction outcome loss': 0.1711158825327521, 'Total loss': 0.1711158825327521}
2023-01-05 06:30:31,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:31,489 INFO:     Epoch: 89
2023-01-05 06:30:33,744 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4742563803990682, 'Total loss': 0.4742563803990682} | train loss {'Reaction outcome loss': 0.16496743715496437, 'Total loss': 0.16496743715496437}
2023-01-05 06:30:33,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:33,745 INFO:     Epoch: 90
2023-01-05 06:30:36,006 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49667195479075116, 'Total loss': 0.49667195479075116} | train loss {'Reaction outcome loss': 0.16511669839678358, 'Total loss': 0.16511669839678358}
2023-01-05 06:30:36,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:36,006 INFO:     Epoch: 91
2023-01-05 06:30:38,287 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4496179570754369, 'Total loss': 0.4496179570754369} | train loss {'Reaction outcome loss': 0.16583923919571805, 'Total loss': 0.16583923919571805}
2023-01-05 06:30:38,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:38,287 INFO:     Epoch: 92
2023-01-05 06:30:40,548 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5093304812908173, 'Total loss': 0.5093304812908173} | train loss {'Reaction outcome loss': 0.15997646280160982, 'Total loss': 0.15997646280160982}
2023-01-05 06:30:40,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:40,548 INFO:     Epoch: 93
2023-01-05 06:30:42,818 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4611922303835551, 'Total loss': 0.4611922303835551} | train loss {'Reaction outcome loss': 0.16371339849493172, 'Total loss': 0.16371339849493172}
2023-01-05 06:30:42,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:42,818 INFO:     Epoch: 94
2023-01-05 06:30:45,088 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4447345028320948, 'Total loss': 0.4447345028320948} | train loss {'Reaction outcome loss': 0.16429508519249267, 'Total loss': 0.16429508519249267}
2023-01-05 06:30:45,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:45,088 INFO:     Epoch: 95
2023-01-05 06:30:47,367 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5004548370838166, 'Total loss': 0.5004548370838166} | train loss {'Reaction outcome loss': 0.1677061900120242, 'Total loss': 0.1677061900120242}
2023-01-05 06:30:47,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:47,368 INFO:     Epoch: 96
2023-01-05 06:30:49,664 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45958861112594607, 'Total loss': 0.45958861112594607} | train loss {'Reaction outcome loss': 0.1653768827740535, 'Total loss': 0.1653768827740535}
2023-01-05 06:30:49,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:49,665 INFO:     Epoch: 97
2023-01-05 06:30:51,940 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47107917393247284, 'Total loss': 0.47107917393247284} | train loss {'Reaction outcome loss': 0.1719889110494135, 'Total loss': 0.1719889110494135}
2023-01-05 06:30:51,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:51,940 INFO:     Epoch: 98
2023-01-05 06:30:54,176 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47261945058902105, 'Total loss': 0.47261945058902105} | train loss {'Reaction outcome loss': 0.1669636543899643, 'Total loss': 0.1669636543899643}
2023-01-05 06:30:54,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:54,176 INFO:     Epoch: 99
2023-01-05 06:30:56,473 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4641893511017164, 'Total loss': 0.4641893511017164} | train loss {'Reaction outcome loss': 0.16070189018711867, 'Total loss': 0.16070189018711867}
2023-01-05 06:30:56,473 INFO:     Best model found after epoch 63 of 100.
2023-01-05 06:30:56,473 INFO:   Done with stage: TRAINING
2023-01-05 06:30:56,473 INFO:   Starting stage: EVALUATION
2023-01-05 06:30:56,610 INFO:   Done with stage: EVALUATION
2023-01-05 06:30:56,611 INFO:   Leaving out SEQ value Fold_1
2023-01-05 06:30:56,624 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 06:30:56,624 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:30:57,282 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:30:57,283 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:30:57,358 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:30:57,358 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:30:57,358 INFO:     No hyperparam tuning for this model
2023-01-05 06:30:57,358 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:30:57,358 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:30:57,359 INFO:     None feature selector for col prot
2023-01-05 06:30:57,359 INFO:     None feature selector for col prot
2023-01-05 06:30:57,359 INFO:     None feature selector for col prot
2023-01-05 06:30:57,359 INFO:     None feature selector for col chem
2023-01-05 06:30:57,360 INFO:     None feature selector for col chem
2023-01-05 06:30:57,360 INFO:     None feature selector for col chem
2023-01-05 06:30:57,360 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:30:57,360 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:30:57,361 INFO:     Number of params in model 72931
2023-01-05 06:30:57,365 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:30:57,365 INFO:   Starting stage: TRAINING
2023-01-05 06:30:57,426 INFO:     Val loss before train {'Reaction outcome loss': 0.9007474541664123, 'Total loss': 0.9007474541664123}
2023-01-05 06:30:57,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:57,426 INFO:     Epoch: 0
2023-01-05 06:30:59,710 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6808612028757731, 'Total loss': 0.6808612028757731} | train loss {'Reaction outcome loss': 0.9278592073048154, 'Total loss': 0.9278592073048154}
2023-01-05 06:30:59,710 INFO:     Found new best model at epoch 0
2023-01-05 06:30:59,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:30:59,711 INFO:     Epoch: 1
2023-01-05 06:31:02,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4818881352742513, 'Total loss': 0.4818881352742513} | train loss {'Reaction outcome loss': 0.6231982460804052, 'Total loss': 0.6231982460804052}
2023-01-05 06:31:02,059 INFO:     Found new best model at epoch 1
2023-01-05 06:31:02,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:02,060 INFO:     Epoch: 2
2023-01-05 06:31:04,404 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4513280232747396, 'Total loss': 0.4513280232747396} | train loss {'Reaction outcome loss': 0.5327607694797326, 'Total loss': 0.5327607694797326}
2023-01-05 06:31:04,404 INFO:     Found new best model at epoch 2
2023-01-05 06:31:04,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:04,406 INFO:     Epoch: 3
2023-01-05 06:31:06,750 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4359769741694132, 'Total loss': 0.4359769741694132} | train loss {'Reaction outcome loss': 0.4914269803692519, 'Total loss': 0.4914269803692519}
2023-01-05 06:31:06,750 INFO:     Found new best model at epoch 3
2023-01-05 06:31:06,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:06,751 INFO:     Epoch: 4
2023-01-05 06:31:09,084 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39731802940368655, 'Total loss': 0.39731802940368655} | train loss {'Reaction outcome loss': 0.4681478126980094, 'Total loss': 0.4681478126980094}
2023-01-05 06:31:09,085 INFO:     Found new best model at epoch 4
2023-01-05 06:31:09,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:09,087 INFO:     Epoch: 5
2023-01-05 06:31:11,360 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3917038569847743, 'Total loss': 0.3917038569847743} | train loss {'Reaction outcome loss': 0.4424576949382174, 'Total loss': 0.4424576949382174}
2023-01-05 06:31:11,360 INFO:     Found new best model at epoch 5
2023-01-05 06:31:11,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:11,362 INFO:     Epoch: 6
2023-01-05 06:31:13,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40849243104457855, 'Total loss': 0.40849243104457855} | train loss {'Reaction outcome loss': 0.43062652729154716, 'Total loss': 0.43062652729154716}
2023-01-05 06:31:13,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:13,675 INFO:     Epoch: 7
2023-01-05 06:31:15,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3990595976511637, 'Total loss': 0.3990595976511637} | train loss {'Reaction outcome loss': 0.4165159236585748, 'Total loss': 0.4165159236585748}
2023-01-05 06:31:15,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:15,981 INFO:     Epoch: 8
2023-01-05 06:31:18,274 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39705719153086344, 'Total loss': 0.39705719153086344} | train loss {'Reaction outcome loss': 0.4013879189024801, 'Total loss': 0.4013879189024801}
2023-01-05 06:31:18,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:18,274 INFO:     Epoch: 9
2023-01-05 06:31:20,553 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3707432816425959, 'Total loss': 0.3707432816425959} | train loss {'Reaction outcome loss': 0.3979033694623217, 'Total loss': 0.3979033694623217}
2023-01-05 06:31:20,553 INFO:     Found new best model at epoch 9
2023-01-05 06:31:20,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:20,555 INFO:     Epoch: 10
2023-01-05 06:31:22,817 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.36881205836931863, 'Total loss': 0.36881205836931863} | train loss {'Reaction outcome loss': 0.3941501605769862, 'Total loss': 0.3941501605769862}
2023-01-05 06:31:22,817 INFO:     Found new best model at epoch 10
2023-01-05 06:31:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:22,819 INFO:     Epoch: 11
2023-01-05 06:31:25,090 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3421139071385066, 'Total loss': 0.3421139071385066} | train loss {'Reaction outcome loss': 0.3903270492693886, 'Total loss': 0.3903270492693886}
2023-01-05 06:31:25,090 INFO:     Found new best model at epoch 11
2023-01-05 06:31:25,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:25,091 INFO:     Epoch: 12
2023-01-05 06:31:27,355 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3549584070841471, 'Total loss': 0.3549584070841471} | train loss {'Reaction outcome loss': 0.3636607570262387, 'Total loss': 0.3636607570262387}
2023-01-05 06:31:27,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:27,355 INFO:     Epoch: 13
2023-01-05 06:31:29,616 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3672565790514151, 'Total loss': 0.3672565790514151} | train loss {'Reaction outcome loss': 0.3578614660579225, 'Total loss': 0.3578614660579225}
2023-01-05 06:31:29,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:29,616 INFO:     Epoch: 14
2023-01-05 06:31:31,892 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3517749682068825, 'Total loss': 0.3517749682068825} | train loss {'Reaction outcome loss': 0.3493203029063517, 'Total loss': 0.3493203029063517}
2023-01-05 06:31:31,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:31,892 INFO:     Epoch: 15
2023-01-05 06:31:34,156 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3420831585923831, 'Total loss': 0.3420831585923831} | train loss {'Reaction outcome loss': 0.34079803166357614, 'Total loss': 0.34079803166357614}
2023-01-05 06:31:34,156 INFO:     Found new best model at epoch 15
2023-01-05 06:31:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:34,157 INFO:     Epoch: 16
2023-01-05 06:31:36,350 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.34113515516122184, 'Total loss': 0.34113515516122184} | train loss {'Reaction outcome loss': 0.33902092593843525, 'Total loss': 0.33902092593843525}
2023-01-05 06:31:36,350 INFO:     Found new best model at epoch 16
2023-01-05 06:31:36,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:36,352 INFO:     Epoch: 17
2023-01-05 06:31:38,602 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.34584111471970874, 'Total loss': 0.34584111471970874} | train loss {'Reaction outcome loss': 0.3384880903514399, 'Total loss': 0.3384880903514399}
2023-01-05 06:31:38,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:38,603 INFO:     Epoch: 18
2023-01-05 06:31:40,893 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.34795498847961426, 'Total loss': 0.34795498847961426} | train loss {'Reaction outcome loss': 0.3406131018857485, 'Total loss': 0.3406131018857485}
2023-01-05 06:31:40,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:40,893 INFO:     Epoch: 19
2023-01-05 06:31:43,150 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.34624032278855643, 'Total loss': 0.34624032278855643} | train loss {'Reaction outcome loss': 0.3161707272604648, 'Total loss': 0.3161707272604648}
2023-01-05 06:31:43,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:43,150 INFO:     Epoch: 20
2023-01-05 06:31:45,416 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3671541412671407, 'Total loss': 0.3671541412671407} | train loss {'Reaction outcome loss': 0.31421529932919406, 'Total loss': 0.31421529932919406}
2023-01-05 06:31:45,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:45,417 INFO:     Epoch: 21
2023-01-05 06:31:47,701 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3651558960477511, 'Total loss': 0.3651558960477511} | train loss {'Reaction outcome loss': 0.30355903103043314, 'Total loss': 0.30355903103043314}
2023-01-05 06:31:47,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:47,702 INFO:     Epoch: 22
2023-01-05 06:31:49,960 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3761684576670329, 'Total loss': 0.3761684576670329} | train loss {'Reaction outcome loss': 0.29756810318381677, 'Total loss': 0.29756810318381677}
2023-01-05 06:31:49,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:49,960 INFO:     Epoch: 23
2023-01-05 06:31:52,243 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3630672574043274, 'Total loss': 0.3630672574043274} | train loss {'Reaction outcome loss': 0.29034698328536435, 'Total loss': 0.29034698328536435}
2023-01-05 06:31:52,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:52,243 INFO:     Epoch: 24
2023-01-05 06:31:54,521 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.353970227142175, 'Total loss': 0.353970227142175} | train loss {'Reaction outcome loss': 0.29117995971023775, 'Total loss': 0.29117995971023775}
2023-01-05 06:31:54,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:54,521 INFO:     Epoch: 25
2023-01-05 06:31:56,785 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3442676623662313, 'Total loss': 0.3442676623662313} | train loss {'Reaction outcome loss': 0.28390569670422783, 'Total loss': 0.28390569670422783}
2023-01-05 06:31:56,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:56,785 INFO:     Epoch: 26
2023-01-05 06:31:59,069 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3650443106889725, 'Total loss': 0.3650443106889725} | train loss {'Reaction outcome loss': 0.27835304144284, 'Total loss': 0.27835304144284}
2023-01-05 06:31:59,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:31:59,070 INFO:     Epoch: 27
2023-01-05 06:32:01,353 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3630580179393291, 'Total loss': 0.3630580179393291} | train loss {'Reaction outcome loss': 0.2751281488855811, 'Total loss': 0.2751281488855811}
2023-01-05 06:32:01,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:01,353 INFO:     Epoch: 28
2023-01-05 06:32:03,631 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3568119784196218, 'Total loss': 0.3568119784196218} | train loss {'Reaction outcome loss': 0.26904352177972096, 'Total loss': 0.26904352177972096}
2023-01-05 06:32:03,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:03,631 INFO:     Epoch: 29
2023-01-05 06:32:05,929 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41576842168966927, 'Total loss': 0.41576842168966927} | train loss {'Reaction outcome loss': 0.26763925736473093, 'Total loss': 0.26763925736473093}
2023-01-05 06:32:05,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:05,929 INFO:     Epoch: 30
2023-01-05 06:32:08,189 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34898328483104707, 'Total loss': 0.34898328483104707} | train loss {'Reaction outcome loss': 0.2679027373142426, 'Total loss': 0.2679027373142426}
2023-01-05 06:32:08,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:08,190 INFO:     Epoch: 31
2023-01-05 06:32:10,462 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3488735636075338, 'Total loss': 0.3488735636075338} | train loss {'Reaction outcome loss': 0.26022892838775896, 'Total loss': 0.26022892838775896}
2023-01-05 06:32:10,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:10,463 INFO:     Epoch: 32
2023-01-05 06:32:12,738 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3577775071064631, 'Total loss': 0.3577775071064631} | train loss {'Reaction outcome loss': 0.2585513349689975, 'Total loss': 0.2585513349689975}
2023-01-05 06:32:12,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:12,738 INFO:     Epoch: 33
2023-01-05 06:32:14,961 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3975961188475291, 'Total loss': 0.3975961188475291} | train loss {'Reaction outcome loss': 0.24948582487548635, 'Total loss': 0.24948582487548635}
2023-01-05 06:32:14,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:14,963 INFO:     Epoch: 34
2023-01-05 06:32:17,250 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33590100755294167, 'Total loss': 0.33590100755294167} | train loss {'Reaction outcome loss': 0.2520098634802549, 'Total loss': 0.2520098634802549}
2023-01-05 06:32:17,250 INFO:     Found new best model at epoch 34
2023-01-05 06:32:17,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:17,252 INFO:     Epoch: 35
2023-01-05 06:32:19,542 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3683941831191381, 'Total loss': 0.3683941831191381} | train loss {'Reaction outcome loss': 0.24810121797327156, 'Total loss': 0.24810121797327156}
2023-01-05 06:32:19,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:19,542 INFO:     Epoch: 36
2023-01-05 06:32:21,806 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35367268497745197, 'Total loss': 0.35367268497745197} | train loss {'Reaction outcome loss': 0.2474754125190278, 'Total loss': 0.2474754125190278}
2023-01-05 06:32:21,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:21,806 INFO:     Epoch: 37
2023-01-05 06:32:24,084 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3579394062360128, 'Total loss': 0.3579394062360128} | train loss {'Reaction outcome loss': 0.24231190531366115, 'Total loss': 0.24231190531366115}
2023-01-05 06:32:24,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:24,085 INFO:     Epoch: 38
2023-01-05 06:32:26,334 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37949073761701585, 'Total loss': 0.37949073761701585} | train loss {'Reaction outcome loss': 0.24014627408410044, 'Total loss': 0.24014627408410044}
2023-01-05 06:32:26,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:26,334 INFO:     Epoch: 39
2023-01-05 06:32:28,615 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3517560144265493, 'Total loss': 0.3517560144265493} | train loss {'Reaction outcome loss': 0.2364442109963789, 'Total loss': 0.2364442109963789}
2023-01-05 06:32:28,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:28,615 INFO:     Epoch: 40
2023-01-05 06:32:30,915 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34739880859851835, 'Total loss': 0.34739880859851835} | train loss {'Reaction outcome loss': 0.23763594635512572, 'Total loss': 0.23763594635512572}
2023-01-05 06:32:30,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:30,915 INFO:     Epoch: 41
2023-01-05 06:32:33,170 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.363661269346873, 'Total loss': 0.363661269346873} | train loss {'Reaction outcome loss': 0.24101617565168493, 'Total loss': 0.24101617565168493}
2023-01-05 06:32:33,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:33,170 INFO:     Epoch: 42
2023-01-05 06:32:35,498 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35988512337207795, 'Total loss': 0.35988512337207795} | train loss {'Reaction outcome loss': 0.23395031571145292, 'Total loss': 0.23395031571145292}
2023-01-05 06:32:35,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:35,499 INFO:     Epoch: 43
2023-01-05 06:32:37,795 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35947503745555875, 'Total loss': 0.35947503745555875} | train loss {'Reaction outcome loss': 0.23160178151548558, 'Total loss': 0.23160178151548558}
2023-01-05 06:32:37,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:37,796 INFO:     Epoch: 44
2023-01-05 06:32:40,083 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3838057518005371, 'Total loss': 0.3838057518005371} | train loss {'Reaction outcome loss': 0.2269132371011833, 'Total loss': 0.2269132371011833}
2023-01-05 06:32:40,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:40,083 INFO:     Epoch: 45
2023-01-05 06:32:42,358 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3800035019715627, 'Total loss': 0.3800035019715627} | train loss {'Reaction outcome loss': 0.22630254568977523, 'Total loss': 0.22630254568977523}
2023-01-05 06:32:42,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:42,359 INFO:     Epoch: 46
2023-01-05 06:32:44,602 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34061675469080605, 'Total loss': 0.34061675469080605} | train loss {'Reaction outcome loss': 0.22313883736540552, 'Total loss': 0.22313883736540552}
2023-01-05 06:32:44,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:44,603 INFO:     Epoch: 47
2023-01-05 06:32:46,894 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3566675623257955, 'Total loss': 0.3566675623257955} | train loss {'Reaction outcome loss': 0.2413670828808909, 'Total loss': 0.2413670828808909}
2023-01-05 06:32:46,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:46,894 INFO:     Epoch: 48
2023-01-05 06:32:49,175 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36725900595386823, 'Total loss': 0.36725900595386823} | train loss {'Reaction outcome loss': 0.2367062810262196, 'Total loss': 0.2367062810262196}
2023-01-05 06:32:49,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:49,176 INFO:     Epoch: 49
2023-01-05 06:32:51,439 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3436818460623423, 'Total loss': 0.3436818460623423} | train loss {'Reaction outcome loss': 0.22192089347821742, 'Total loss': 0.22192089347821742}
2023-01-05 06:32:51,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:51,440 INFO:     Epoch: 50
2023-01-05 06:32:53,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37148152440786364, 'Total loss': 0.37148152440786364} | train loss {'Reaction outcome loss': 0.21804462255154183, 'Total loss': 0.21804462255154183}
2023-01-05 06:32:53,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:53,729 INFO:     Epoch: 51
2023-01-05 06:32:55,995 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35237341523170473, 'Total loss': 0.35237341523170473} | train loss {'Reaction outcome loss': 0.21834311189561867, 'Total loss': 0.21834311189561867}
2023-01-05 06:32:55,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:55,996 INFO:     Epoch: 52
2023-01-05 06:32:58,277 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36597666814923285, 'Total loss': 0.36597666814923285} | train loss {'Reaction outcome loss': 0.2114371265135191, 'Total loss': 0.2114371265135191}
2023-01-05 06:32:58,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:32:58,277 INFO:     Epoch: 53
2023-01-05 06:33:00,515 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38828232487042746, 'Total loss': 0.38828232487042746} | train loss {'Reaction outcome loss': 0.21299156013613, 'Total loss': 0.21299156013613}
2023-01-05 06:33:00,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:00,515 INFO:     Epoch: 54
2023-01-05 06:33:02,789 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38553806841373445, 'Total loss': 0.38553806841373445} | train loss {'Reaction outcome loss': 0.20833807169000848, 'Total loss': 0.20833807169000848}
2023-01-05 06:33:02,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:02,789 INFO:     Epoch: 55
2023-01-05 06:33:05,032 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36636084914207456, 'Total loss': 0.36636084914207456} | train loss {'Reaction outcome loss': 0.20428445179393326, 'Total loss': 0.20428445179393326}
2023-01-05 06:33:05,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:05,033 INFO:     Epoch: 56
2023-01-05 06:33:07,293 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36201008160909015, 'Total loss': 0.36201008160909015} | train loss {'Reaction outcome loss': 0.2081981691315878, 'Total loss': 0.2081981691315878}
2023-01-05 06:33:07,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:07,294 INFO:     Epoch: 57
2023-01-05 06:33:09,526 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38884882231553397, 'Total loss': 0.38884882231553397} | train loss {'Reaction outcome loss': 0.21816002221780567, 'Total loss': 0.21816002221780567}
2023-01-05 06:33:09,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:09,526 INFO:     Epoch: 58
2023-01-05 06:33:11,770 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36888904521862664, 'Total loss': 0.36888904521862664} | train loss {'Reaction outcome loss': 0.20982142684155458, 'Total loss': 0.20982142684155458}
2023-01-05 06:33:11,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:11,770 INFO:     Epoch: 59
2023-01-05 06:33:14,086 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39486419757207236, 'Total loss': 0.39486419757207236} | train loss {'Reaction outcome loss': 0.23009967846134544, 'Total loss': 0.23009967846134544}
2023-01-05 06:33:14,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:14,086 INFO:     Epoch: 60
2023-01-05 06:33:16,353 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38443725841740767, 'Total loss': 0.38443725841740767} | train loss {'Reaction outcome loss': 0.1960897631896598, 'Total loss': 0.1960897631896598}
2023-01-05 06:33:16,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:16,353 INFO:     Epoch: 61
2023-01-05 06:33:18,613 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36839386423428855, 'Total loss': 0.36839386423428855} | train loss {'Reaction outcome loss': 0.20473379992156127, 'Total loss': 0.20473379992156127}
2023-01-05 06:33:18,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:18,613 INFO:     Epoch: 62
2023-01-05 06:33:20,887 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3935547729333242, 'Total loss': 0.3935547729333242} | train loss {'Reaction outcome loss': 0.20668871079207116, 'Total loss': 0.20668871079207116}
2023-01-05 06:33:20,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:20,889 INFO:     Epoch: 63
2023-01-05 06:33:23,148 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4132965954641501, 'Total loss': 0.4132965954641501} | train loss {'Reaction outcome loss': 0.2006865323894907, 'Total loss': 0.2006865323894907}
2023-01-05 06:33:23,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:23,148 INFO:     Epoch: 64
2023-01-05 06:33:25,420 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39975609083970387, 'Total loss': 0.39975609083970387} | train loss {'Reaction outcome loss': 0.19825091067173492, 'Total loss': 0.19825091067173492}
2023-01-05 06:33:25,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:25,421 INFO:     Epoch: 65
2023-01-05 06:33:27,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3736673131585121, 'Total loss': 0.3736673131585121} | train loss {'Reaction outcome loss': 0.20185588553874328, 'Total loss': 0.20185588553874328}
2023-01-05 06:33:27,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:27,690 INFO:     Epoch: 66
2023-01-05 06:33:29,968 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39076834842562674, 'Total loss': 0.39076834842562674} | train loss {'Reaction outcome loss': 0.20065500588442892, 'Total loss': 0.20065500588442892}
2023-01-05 06:33:29,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:29,968 INFO:     Epoch: 67
2023-01-05 06:33:32,225 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38257831434408823, 'Total loss': 0.38257831434408823} | train loss {'Reaction outcome loss': 0.19503467067978278, 'Total loss': 0.19503467067978278}
2023-01-05 06:33:32,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:32,225 INFO:     Epoch: 68
2023-01-05 06:33:34,477 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.371978231271108, 'Total loss': 0.371978231271108} | train loss {'Reaction outcome loss': 0.196391067360125, 'Total loss': 0.196391067360125}
2023-01-05 06:33:34,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:34,478 INFO:     Epoch: 69
2023-01-05 06:33:36,766 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35884425391753516, 'Total loss': 0.35884425391753516} | train loss {'Reaction outcome loss': 0.19459557962497673, 'Total loss': 0.19459557962497673}
2023-01-05 06:33:36,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:36,767 INFO:     Epoch: 70
2023-01-05 06:33:39,053 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40454081594944, 'Total loss': 0.40454081594944} | train loss {'Reaction outcome loss': 0.1935388342118012, 'Total loss': 0.1935388342118012}
2023-01-05 06:33:39,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:39,053 INFO:     Epoch: 71
2023-01-05 06:33:41,340 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37126329988241197, 'Total loss': 0.37126329988241197} | train loss {'Reaction outcome loss': 0.18649331341578584, 'Total loss': 0.18649331341578584}
2023-01-05 06:33:41,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:41,340 INFO:     Epoch: 72
2023-01-05 06:33:43,611 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3572596475481987, 'Total loss': 0.3572596475481987} | train loss {'Reaction outcome loss': 0.19012885928437437, 'Total loss': 0.19012885928437437}
2023-01-05 06:33:43,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:43,611 INFO:     Epoch: 73
2023-01-05 06:33:45,894 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38489385197559994, 'Total loss': 0.38489385197559994} | train loss {'Reaction outcome loss': 0.1877599219467653, 'Total loss': 0.1877599219467653}
2023-01-05 06:33:45,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:45,894 INFO:     Epoch: 74
2023-01-05 06:33:48,182 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37959426837041976, 'Total loss': 0.37959426837041976} | train loss {'Reaction outcome loss': 0.18580695324192714, 'Total loss': 0.18580695324192714}
2023-01-05 06:33:48,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:48,182 INFO:     Epoch: 75
2023-01-05 06:33:50,447 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3907271722952525, 'Total loss': 0.3907271722952525} | train loss {'Reaction outcome loss': 0.19004561495706224, 'Total loss': 0.19004561495706224}
2023-01-05 06:33:50,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:50,448 INFO:     Epoch: 76
2023-01-05 06:33:52,680 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3850787987311681, 'Total loss': 0.3850787987311681} | train loss {'Reaction outcome loss': 0.1820112764582281, 'Total loss': 0.1820112764582281}
2023-01-05 06:33:52,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:52,681 INFO:     Epoch: 77
2023-01-05 06:33:54,941 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3818728119134903, 'Total loss': 0.3818728119134903} | train loss {'Reaction outcome loss': 0.18421723009843213, 'Total loss': 0.18421723009843213}
2023-01-05 06:33:54,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:54,941 INFO:     Epoch: 78
2023-01-05 06:33:57,199 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3941634476184845, 'Total loss': 0.3941634476184845} | train loss {'Reaction outcome loss': 0.17565396319369556, 'Total loss': 0.17565396319369556}
2023-01-05 06:33:57,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:57,200 INFO:     Epoch: 79
2023-01-05 06:33:59,417 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4175499926010768, 'Total loss': 0.4175499926010768} | train loss {'Reaction outcome loss': 0.1781959224769009, 'Total loss': 0.1781959224769009}
2023-01-05 06:33:59,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:33:59,417 INFO:     Epoch: 80
2023-01-05 06:34:01,709 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3820203458269437, 'Total loss': 0.3820203458269437} | train loss {'Reaction outcome loss': 0.17954090253308252, 'Total loss': 0.17954090253308252}
2023-01-05 06:34:01,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:01,710 INFO:     Epoch: 81
2023-01-05 06:34:03,986 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36815057396888734, 'Total loss': 0.36815057396888734} | train loss {'Reaction outcome loss': 0.17903364001129218, 'Total loss': 0.17903364001129218}
2023-01-05 06:34:03,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:03,987 INFO:     Epoch: 82
2023-01-05 06:34:06,228 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3664331167936325, 'Total loss': 0.3664331167936325} | train loss {'Reaction outcome loss': 0.17582070483215342, 'Total loss': 0.17582070483215342}
2023-01-05 06:34:06,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:06,229 INFO:     Epoch: 83
2023-01-05 06:34:08,502 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38544260859489443, 'Total loss': 0.38544260859489443} | train loss {'Reaction outcome loss': 0.1778498035416925, 'Total loss': 0.1778498035416925}
2023-01-05 06:34:08,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:08,503 INFO:     Epoch: 84
2023-01-05 06:34:10,750 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3762257809440295, 'Total loss': 0.3762257809440295} | train loss {'Reaction outcome loss': 0.1754710867763092, 'Total loss': 0.1754710867763092}
2023-01-05 06:34:10,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:10,750 INFO:     Epoch: 85
2023-01-05 06:34:13,028 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3840836013356845, 'Total loss': 0.3840836013356845} | train loss {'Reaction outcome loss': 0.1699525701983327, 'Total loss': 0.1699525701983327}
2023-01-05 06:34:13,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:13,028 INFO:     Epoch: 86
2023-01-05 06:34:15,311 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38139412899812064, 'Total loss': 0.38139412899812064} | train loss {'Reaction outcome loss': 0.16990883121320952, 'Total loss': 0.16990883121320952}
2023-01-05 06:34:15,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:15,311 INFO:     Epoch: 87
2023-01-05 06:34:17,572 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3851792280872663, 'Total loss': 0.3851792280872663} | train loss {'Reaction outcome loss': 0.17245983520979938, 'Total loss': 0.17245983520979938}
2023-01-05 06:34:17,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:17,573 INFO:     Epoch: 88
2023-01-05 06:34:19,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3541530950771024, 'Total loss': 0.3541530950771024} | train loss {'Reaction outcome loss': 0.1715323922433632, 'Total loss': 0.1715323922433632}
2023-01-05 06:34:19,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:19,852 INFO:     Epoch: 89
2023-01-05 06:34:22,137 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3592062215010325, 'Total loss': 0.3592062215010325} | train loss {'Reaction outcome loss': 0.17028035394780117, 'Total loss': 0.17028035394780117}
2023-01-05 06:34:22,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:22,137 INFO:     Epoch: 90
2023-01-05 06:34:24,433 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3547392502892762, 'Total loss': 0.3547392502892762} | train loss {'Reaction outcome loss': 0.17054326409909307, 'Total loss': 0.17054326409909307}
2023-01-05 06:34:24,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:24,434 INFO:     Epoch: 91
2023-01-05 06:34:26,714 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39914216846227646, 'Total loss': 0.39914216846227646} | train loss {'Reaction outcome loss': 0.16800284001710944, 'Total loss': 0.16800284001710944}
2023-01-05 06:34:26,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:26,715 INFO:     Epoch: 92
2023-01-05 06:34:28,991 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36611314306501297, 'Total loss': 0.36611314306501297} | train loss {'Reaction outcome loss': 0.16813834659528173, 'Total loss': 0.16813834659528173}
2023-01-05 06:34:28,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:28,992 INFO:     Epoch: 93
2023-01-05 06:34:31,275 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3710330054163933, 'Total loss': 0.3710330054163933} | train loss {'Reaction outcome loss': 0.16700670366222714, 'Total loss': 0.16700670366222714}
2023-01-05 06:34:31,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:31,276 INFO:     Epoch: 94
2023-01-05 06:34:33,500 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3939868796772013, 'Total loss': 0.3939868796772013} | train loss {'Reaction outcome loss': 0.1840625613661267, 'Total loss': 0.1840625613661267}
2023-01-05 06:34:33,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:33,501 INFO:     Epoch: 95
2023-01-05 06:34:35,586 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3918966660896937, 'Total loss': 0.3918966660896937} | train loss {'Reaction outcome loss': 0.2049695146063417, 'Total loss': 0.2049695146063417}
2023-01-05 06:34:35,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:35,587 INFO:     Epoch: 96
2023-01-05 06:34:37,863 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3746791919072469, 'Total loss': 0.3746791919072469} | train loss {'Reaction outcome loss': 0.1677584652080322, 'Total loss': 0.1677584652080322}
2023-01-05 06:34:37,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:37,863 INFO:     Epoch: 97
2023-01-05 06:34:40,156 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36622598295410475, 'Total loss': 0.36622598295410475} | train loss {'Reaction outcome loss': 0.16606898757838306, 'Total loss': 0.16606898757838306}
2023-01-05 06:34:40,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:40,157 INFO:     Epoch: 98
2023-01-05 06:34:42,405 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39990382865071294, 'Total loss': 0.39990382865071294} | train loss {'Reaction outcome loss': 0.16097814443924438, 'Total loss': 0.16097814443924438}
2023-01-05 06:34:42,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:42,405 INFO:     Epoch: 99
2023-01-05 06:34:44,644 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39640631626049677, 'Total loss': 0.39640631626049677} | train loss {'Reaction outcome loss': 0.16185055347665658, 'Total loss': 0.16185055347665658}
2023-01-05 06:34:44,644 INFO:     Best model found after epoch 35 of 100.
2023-01-05 06:34:44,644 INFO:   Done with stage: TRAINING
2023-01-05 06:34:44,644 INFO:   Starting stage: EVALUATION
2023-01-05 06:34:44,779 INFO:   Done with stage: EVALUATION
2023-01-05 06:34:44,779 INFO:   Leaving out SEQ value Fold_2
2023-01-05 06:34:44,792 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 06:34:44,792 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:34:45,436 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:34:45,436 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:34:45,509 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:34:45,510 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:34:45,510 INFO:     No hyperparam tuning for this model
2023-01-05 06:34:45,510 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:34:45,510 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:34:45,511 INFO:     None feature selector for col prot
2023-01-05 06:34:45,511 INFO:     None feature selector for col prot
2023-01-05 06:34:45,511 INFO:     None feature selector for col prot
2023-01-05 06:34:45,512 INFO:     None feature selector for col chem
2023-01-05 06:34:45,512 INFO:     None feature selector for col chem
2023-01-05 06:34:45,512 INFO:     None feature selector for col chem
2023-01-05 06:34:45,512 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:34:45,512 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:34:45,513 INFO:     Number of params in model 72931
2023-01-05 06:34:45,517 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:34:45,517 INFO:   Starting stage: TRAINING
2023-01-05 06:34:45,578 INFO:     Val loss before train {'Reaction outcome loss': 1.002641987800598, 'Total loss': 1.002641987800598}
2023-01-05 06:34:45,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:45,578 INFO:     Epoch: 0
2023-01-05 06:34:47,826 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7624950130780538, 'Total loss': 0.7624950130780538} | train loss {'Reaction outcome loss': 0.9424373570183546, 'Total loss': 0.9424373570183546}
2023-01-05 06:34:47,826 INFO:     Found new best model at epoch 0
2023-01-05 06:34:47,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:47,827 INFO:     Epoch: 1
2023-01-05 06:34:50,077 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5347677866617838, 'Total loss': 0.5347677866617838} | train loss {'Reaction outcome loss': 0.619253779799296, 'Total loss': 0.619253779799296}
2023-01-05 06:34:50,077 INFO:     Found new best model at epoch 1
2023-01-05 06:34:50,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:50,079 INFO:     Epoch: 2
2023-01-05 06:34:52,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5595105051994324, 'Total loss': 0.5595105051994324} | train loss {'Reaction outcome loss': 0.544589688912089, 'Total loss': 0.544589688912089}
2023-01-05 06:34:52,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:52,299 INFO:     Epoch: 3
2023-01-05 06:34:54,542 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4664255703488986, 'Total loss': 0.4664255703488986} | train loss {'Reaction outcome loss': 0.5134725270456054, 'Total loss': 0.5134725270456054}
2023-01-05 06:34:54,542 INFO:     Found new best model at epoch 3
2023-01-05 06:34:54,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:54,544 INFO:     Epoch: 4
2023-01-05 06:34:56,776 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46916316350301107, 'Total loss': 0.46916316350301107} | train loss {'Reaction outcome loss': 0.48905555293568825, 'Total loss': 0.48905555293568825}
2023-01-05 06:34:56,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:56,777 INFO:     Epoch: 5
2023-01-05 06:34:58,900 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45638808806737263, 'Total loss': 0.45638808806737263} | train loss {'Reaction outcome loss': 0.47094838486166457, 'Total loss': 0.47094838486166457}
2023-01-05 06:34:58,900 INFO:     Found new best model at epoch 5
2023-01-05 06:34:58,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:34:58,901 INFO:     Epoch: 6
2023-01-05 06:35:01,123 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44828129510084785, 'Total loss': 0.44828129510084785} | train loss {'Reaction outcome loss': 0.45383539361487457, 'Total loss': 0.45383539361487457}
2023-01-05 06:35:01,124 INFO:     Found new best model at epoch 6
2023-01-05 06:35:01,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:01,125 INFO:     Epoch: 7
2023-01-05 06:35:03,359 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46217233737309776, 'Total loss': 0.46217233737309776} | train loss {'Reaction outcome loss': 0.43886717348411075, 'Total loss': 0.43886717348411075}
2023-01-05 06:35:03,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:03,360 INFO:     Epoch: 8
2023-01-05 06:35:05,600 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4428070326646169, 'Total loss': 0.4428070326646169} | train loss {'Reaction outcome loss': 0.4255274583437786, 'Total loss': 0.4255274583437786}
2023-01-05 06:35:05,600 INFO:     Found new best model at epoch 8
2023-01-05 06:35:05,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:05,602 INFO:     Epoch: 9
2023-01-05 06:35:07,836 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4416297694047292, 'Total loss': 0.4416297694047292} | train loss {'Reaction outcome loss': 0.4183899414660306, 'Total loss': 0.4183899414660306}
2023-01-05 06:35:07,836 INFO:     Found new best model at epoch 9
2023-01-05 06:35:07,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:07,837 INFO:     Epoch: 10
2023-01-05 06:35:10,090 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4265819904704889, 'Total loss': 0.4265819904704889} | train loss {'Reaction outcome loss': 0.4038408482756562, 'Total loss': 0.4038408482756562}
2023-01-05 06:35:10,090 INFO:     Found new best model at epoch 10
2023-01-05 06:35:10,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:10,092 INFO:     Epoch: 11
2023-01-05 06:35:12,334 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4366273760795593, 'Total loss': 0.4366273760795593} | train loss {'Reaction outcome loss': 0.39468572582925815, 'Total loss': 0.39468572582925815}
2023-01-05 06:35:12,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:12,334 INFO:     Epoch: 12
2023-01-05 06:35:14,574 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4544402301311493, 'Total loss': 0.4544402301311493} | train loss {'Reaction outcome loss': 0.38672284660963996, 'Total loss': 0.38672284660963996}
2023-01-05 06:35:14,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:14,574 INFO:     Epoch: 13
2023-01-05 06:35:16,804 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4507484982411067, 'Total loss': 0.4507484982411067} | train loss {'Reaction outcome loss': 0.3773769111375967, 'Total loss': 0.3773769111375967}
2023-01-05 06:35:16,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:16,804 INFO:     Epoch: 14
2023-01-05 06:35:19,032 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43734036286671957, 'Total loss': 0.43734036286671957} | train loss {'Reaction outcome loss': 0.3709841629565862, 'Total loss': 0.3709841629565862}
2023-01-05 06:35:19,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:19,032 INFO:     Epoch: 15
2023-01-05 06:35:21,265 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4190711319446564, 'Total loss': 0.4190711319446564} | train loss {'Reaction outcome loss': 0.35933088769661986, 'Total loss': 0.35933088769661986}
2023-01-05 06:35:21,265 INFO:     Found new best model at epoch 15
2023-01-05 06:35:21,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:21,266 INFO:     Epoch: 16
2023-01-05 06:35:23,518 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4130765934785207, 'Total loss': 0.4130765934785207} | train loss {'Reaction outcome loss': 0.3525743550067678, 'Total loss': 0.3525743550067678}
2023-01-05 06:35:23,519 INFO:     Found new best model at epoch 16
2023-01-05 06:35:23,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:23,520 INFO:     Epoch: 17
2023-01-05 06:35:25,770 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43095859289169314, 'Total loss': 0.43095859289169314} | train loss {'Reaction outcome loss': 0.3439505642960432, 'Total loss': 0.3439505642960432}
2023-01-05 06:35:25,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:25,770 INFO:     Epoch: 18
2023-01-05 06:35:27,968 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45796069701512654, 'Total loss': 0.45796069701512654} | train loss {'Reaction outcome loss': 0.3401334000359602, 'Total loss': 0.3401334000359602}
2023-01-05 06:35:27,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:27,969 INFO:     Epoch: 19
2023-01-05 06:35:30,183 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4069525842865308, 'Total loss': 0.4069525842865308} | train loss {'Reaction outcome loss': 0.33399768749671227, 'Total loss': 0.33399768749671227}
2023-01-05 06:35:30,184 INFO:     Found new best model at epoch 19
2023-01-05 06:35:30,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:30,185 INFO:     Epoch: 20
2023-01-05 06:35:32,412 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42311047613620756, 'Total loss': 0.42311047613620756} | train loss {'Reaction outcome loss': 0.32294828461215064, 'Total loss': 0.32294828461215064}
2023-01-05 06:35:32,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:32,412 INFO:     Epoch: 21
2023-01-05 06:35:34,655 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4108062783877055, 'Total loss': 0.4108062783877055} | train loss {'Reaction outcome loss': 0.31859321314910244, 'Total loss': 0.31859321314910244}
2023-01-05 06:35:34,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:34,655 INFO:     Epoch: 22
2023-01-05 06:35:36,890 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44837696651617687, 'Total loss': 0.44837696651617687} | train loss {'Reaction outcome loss': 0.31319936208179516, 'Total loss': 0.31319936208179516}
2023-01-05 06:35:36,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:36,891 INFO:     Epoch: 23
2023-01-05 06:35:39,105 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4182964106400808, 'Total loss': 0.4182964106400808} | train loss {'Reaction outcome loss': 0.30773379561590974, 'Total loss': 0.30773379561590974}
2023-01-05 06:35:39,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:39,107 INFO:     Epoch: 24
2023-01-05 06:35:41,262 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43307641595602037, 'Total loss': 0.43307641595602037} | train loss {'Reaction outcome loss': 0.3025591209860745, 'Total loss': 0.3025591209860745}
2023-01-05 06:35:41,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:41,262 INFO:     Epoch: 25
2023-01-05 06:35:43,453 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40956437985102334, 'Total loss': 0.40956437985102334} | train loss {'Reaction outcome loss': 0.2937124802067711, 'Total loss': 0.2937124802067711}
2023-01-05 06:35:43,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:43,453 INFO:     Epoch: 26
2023-01-05 06:35:45,681 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4117271920045217, 'Total loss': 0.4117271920045217} | train loss {'Reaction outcome loss': 0.29580579205962565, 'Total loss': 0.29580579205962565}
2023-01-05 06:35:45,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:45,682 INFO:     Epoch: 27
2023-01-05 06:35:47,907 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4050546626249949, 'Total loss': 0.4050546626249949} | train loss {'Reaction outcome loss': 0.2857212797219683, 'Total loss': 0.2857212797219683}
2023-01-05 06:35:47,907 INFO:     Found new best model at epoch 27
2023-01-05 06:35:47,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:47,909 INFO:     Epoch: 28
2023-01-05 06:35:50,126 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39612170110146205, 'Total loss': 0.39612170110146205} | train loss {'Reaction outcome loss': 0.2797315099252546, 'Total loss': 0.2797315099252546}
2023-01-05 06:35:50,127 INFO:     Found new best model at epoch 28
2023-01-05 06:35:50,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:50,128 INFO:     Epoch: 29
2023-01-05 06:35:52,351 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4776154359181722, 'Total loss': 0.4776154359181722} | train loss {'Reaction outcome loss': 0.2758533592951034, 'Total loss': 0.2758533592951034}
2023-01-05 06:35:52,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:52,351 INFO:     Epoch: 30
2023-01-05 06:35:54,510 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4345617820819219, 'Total loss': 0.4345617820819219} | train loss {'Reaction outcome loss': 0.279234915641841, 'Total loss': 0.279234915641841}
2023-01-05 06:35:54,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:54,511 INFO:     Epoch: 31
2023-01-05 06:35:56,745 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42449232637882234, 'Total loss': 0.42449232637882234} | train loss {'Reaction outcome loss': 0.26790315246834967, 'Total loss': 0.26790315246834967}
2023-01-05 06:35:56,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:56,745 INFO:     Epoch: 32
2023-01-05 06:35:58,980 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42547743717829384, 'Total loss': 0.42547743717829384} | train loss {'Reaction outcome loss': 0.25999123615133696, 'Total loss': 0.25999123615133696}
2023-01-05 06:35:58,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:35:58,981 INFO:     Epoch: 33
2023-01-05 06:36:01,158 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4292689323425293, 'Total loss': 0.4292689323425293} | train loss {'Reaction outcome loss': 0.2632573598727749, 'Total loss': 0.2632573598727749}
2023-01-05 06:36:01,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:01,158 INFO:     Epoch: 34
2023-01-05 06:36:03,327 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4387413670619329, 'Total loss': 0.4387413670619329} | train loss {'Reaction outcome loss': 0.2561700474539586, 'Total loss': 0.2561700474539586}
2023-01-05 06:36:03,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:03,327 INFO:     Epoch: 35
2023-01-05 06:36:05,543 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41256316006183624, 'Total loss': 0.41256316006183624} | train loss {'Reaction outcome loss': 0.2585089640190131, 'Total loss': 0.2585089640190131}
2023-01-05 06:36:05,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:05,543 INFO:     Epoch: 36
2023-01-05 06:36:07,768 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3956829848388831, 'Total loss': 0.3956829848388831} | train loss {'Reaction outcome loss': 0.2554307572227453, 'Total loss': 0.2554307572227453}
2023-01-05 06:36:07,769 INFO:     Found new best model at epoch 36
2023-01-05 06:36:07,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:07,770 INFO:     Epoch: 37
2023-01-05 06:36:09,995 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39629778390129405, 'Total loss': 0.39629778390129405} | train loss {'Reaction outcome loss': 0.2505021040290044, 'Total loss': 0.2505021040290044}
2023-01-05 06:36:09,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:09,995 INFO:     Epoch: 38
2023-01-05 06:36:12,234 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4006767084201177, 'Total loss': 0.4006767084201177} | train loss {'Reaction outcome loss': 0.24861598785320552, 'Total loss': 0.24861598785320552}
2023-01-05 06:36:12,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:12,235 INFO:     Epoch: 39
2023-01-05 06:36:14,456 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4288673798243205, 'Total loss': 0.4288673798243205} | train loss {'Reaction outcome loss': 0.24013161872998154, 'Total loss': 0.24013161872998154}
2023-01-05 06:36:14,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:14,457 INFO:     Epoch: 40
2023-01-05 06:36:16,682 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4244215140740077, 'Total loss': 0.4244215140740077} | train loss {'Reaction outcome loss': 0.23712116914261752, 'Total loss': 0.23712116914261752}
2023-01-05 06:36:16,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:16,683 INFO:     Epoch: 41
2023-01-05 06:36:18,915 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41998128592967987, 'Total loss': 0.41998128592967987} | train loss {'Reaction outcome loss': 0.23581871672832438, 'Total loss': 0.23581871672832438}
2023-01-05 06:36:18,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:18,915 INFO:     Epoch: 42
2023-01-05 06:36:21,158 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43309896290302274, 'Total loss': 0.43309896290302274} | train loss {'Reaction outcome loss': 0.23295605688517385, 'Total loss': 0.23295605688517385}
2023-01-05 06:36:21,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:21,159 INFO:     Epoch: 43
2023-01-05 06:36:23,404 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4459934249520302, 'Total loss': 0.4459934249520302} | train loss {'Reaction outcome loss': 0.23038869347024668, 'Total loss': 0.23038869347024668}
2023-01-05 06:36:23,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:23,404 INFO:     Epoch: 44
2023-01-05 06:36:25,622 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44663870135943096, 'Total loss': 0.44663870135943096} | train loss {'Reaction outcome loss': 0.23189582835498002, 'Total loss': 0.23189582835498002}
2023-01-05 06:36:25,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:25,622 INFO:     Epoch: 45
2023-01-05 06:36:27,857 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4184166153271993, 'Total loss': 0.4184166153271993} | train loss {'Reaction outcome loss': 0.22908216217237204, 'Total loss': 0.22908216217237204}
2023-01-05 06:36:27,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:27,857 INFO:     Epoch: 46
2023-01-05 06:36:30,054 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42639223535855614, 'Total loss': 0.42639223535855614} | train loss {'Reaction outcome loss': 0.23106630813206694, 'Total loss': 0.23106630813206694}
2023-01-05 06:36:30,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:30,054 INFO:     Epoch: 47
2023-01-05 06:36:32,247 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41566445827484133, 'Total loss': 0.41566445827484133} | train loss {'Reaction outcome loss': 0.22445879519893014, 'Total loss': 0.22445879519893014}
2023-01-05 06:36:32,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:32,248 INFO:     Epoch: 48
2023-01-05 06:36:34,480 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41984817932049434, 'Total loss': 0.41984817932049434} | train loss {'Reaction outcome loss': 0.22137548794413184, 'Total loss': 0.22137548794413184}
2023-01-05 06:36:34,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:34,481 INFO:     Epoch: 49
2023-01-05 06:36:36,665 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40134086161851884, 'Total loss': 0.40134086161851884} | train loss {'Reaction outcome loss': 0.22179463958347084, 'Total loss': 0.22179463958347084}
2023-01-05 06:36:36,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:36,665 INFO:     Epoch: 50
2023-01-05 06:36:38,850 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4713577151298523, 'Total loss': 0.4713577151298523} | train loss {'Reaction outcome loss': 0.2182980517674636, 'Total loss': 0.2182980517674636}
2023-01-05 06:36:38,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:38,850 INFO:     Epoch: 51
2023-01-05 06:36:41,053 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4158330907424291, 'Total loss': 0.4158330907424291} | train loss {'Reaction outcome loss': 0.2189706739491862, 'Total loss': 0.2189706739491862}
2023-01-05 06:36:41,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:41,053 INFO:     Epoch: 52
2023-01-05 06:36:43,261 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4376602579529087, 'Total loss': 0.4376602579529087} | train loss {'Reaction outcome loss': 0.2147646152596522, 'Total loss': 0.2147646152596522}
2023-01-05 06:36:43,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:43,262 INFO:     Epoch: 53
2023-01-05 06:36:45,495 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43796861271063486, 'Total loss': 0.43796861271063486} | train loss {'Reaction outcome loss': 0.21454222127107897, 'Total loss': 0.21454222127107897}
2023-01-05 06:36:45,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:45,496 INFO:     Epoch: 54
2023-01-05 06:36:47,678 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4301305870215098, 'Total loss': 0.4301305870215098} | train loss {'Reaction outcome loss': 0.2135814072261822, 'Total loss': 0.2135814072261822}
2023-01-05 06:36:47,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:47,678 INFO:     Epoch: 55
2023-01-05 06:36:49,873 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38179651548465093, 'Total loss': 0.38179651548465093} | train loss {'Reaction outcome loss': 0.2171133975000069, 'Total loss': 0.2171133975000069}
2023-01-05 06:36:49,874 INFO:     Found new best model at epoch 55
2023-01-05 06:36:49,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:49,876 INFO:     Epoch: 56
2023-01-05 06:36:52,054 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38196586469809213, 'Total loss': 0.38196586469809213} | train loss {'Reaction outcome loss': 0.2154597365039631, 'Total loss': 0.2154597365039631}
2023-01-05 06:36:52,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:52,054 INFO:     Epoch: 57
2023-01-05 06:36:54,292 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42989225387573243, 'Total loss': 0.42989225387573243} | train loss {'Reaction outcome loss': 0.2107672068768102, 'Total loss': 0.2107672068768102}
2023-01-05 06:36:54,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:54,292 INFO:     Epoch: 58
2023-01-05 06:36:56,529 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44574183921019234, 'Total loss': 0.44574183921019234} | train loss {'Reaction outcome loss': 0.2080389164848686, 'Total loss': 0.2080389164848686}
2023-01-05 06:36:56,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:56,530 INFO:     Epoch: 59
2023-01-05 06:36:58,716 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4166033307711283, 'Total loss': 0.4166033307711283} | train loss {'Reaction outcome loss': 0.2104797733473382, 'Total loss': 0.2104797733473382}
2023-01-05 06:36:58,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:36:58,717 INFO:     Epoch: 60
2023-01-05 06:37:00,917 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4195440868536631, 'Total loss': 0.4195440868536631} | train loss {'Reaction outcome loss': 0.20601542105011614, 'Total loss': 0.20601542105011614}
2023-01-05 06:37:00,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:00,918 INFO:     Epoch: 61
2023-01-05 06:37:03,130 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41443140705426534, 'Total loss': 0.41443140705426534} | train loss {'Reaction outcome loss': 0.2025491083212664, 'Total loss': 0.2025491083212664}
2023-01-05 06:37:03,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:03,130 INFO:     Epoch: 62
2023-01-05 06:37:05,351 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3974280635515849, 'Total loss': 0.3974280635515849} | train loss {'Reaction outcome loss': 0.20597772863848182, 'Total loss': 0.20597772863848182}
2023-01-05 06:37:05,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:05,351 INFO:     Epoch: 63
2023-01-05 06:37:07,556 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42837815303355453, 'Total loss': 0.42837815303355453} | train loss {'Reaction outcome loss': 0.19934194081383877, 'Total loss': 0.19934194081383877}
2023-01-05 06:37:07,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:07,557 INFO:     Epoch: 64
2023-01-05 06:37:09,784 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4335330215593179, 'Total loss': 0.4335330215593179} | train loss {'Reaction outcome loss': 0.20103076945756634, 'Total loss': 0.20103076945756634}
2023-01-05 06:37:09,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:09,785 INFO:     Epoch: 65
2023-01-05 06:37:12,016 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42604220513409624, 'Total loss': 0.42604220513409624} | train loss {'Reaction outcome loss': 0.20258565745367996, 'Total loss': 0.20258565745367996}
2023-01-05 06:37:12,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:12,017 INFO:     Epoch: 66
2023-01-05 06:37:14,233 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4939873298009237, 'Total loss': 0.4939873298009237} | train loss {'Reaction outcome loss': 0.1997360350715333, 'Total loss': 0.1997360350715333}
2023-01-05 06:37:14,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:14,233 INFO:     Epoch: 67
2023-01-05 06:37:16,427 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4357373982667923, 'Total loss': 0.4357373982667923} | train loss {'Reaction outcome loss': 0.19904053995447626, 'Total loss': 0.19904053995447626}
2023-01-05 06:37:16,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:16,427 INFO:     Epoch: 68
2023-01-05 06:37:18,687 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.412039519349734, 'Total loss': 0.412039519349734} | train loss {'Reaction outcome loss': 0.19549275673857144, 'Total loss': 0.19549275673857144}
2023-01-05 06:37:18,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:18,687 INFO:     Epoch: 69
2023-01-05 06:37:20,937 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4098290055990219, 'Total loss': 0.4098290055990219} | train loss {'Reaction outcome loss': 0.19632720344827073, 'Total loss': 0.19632720344827073}
2023-01-05 06:37:20,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:20,937 INFO:     Epoch: 70
2023-01-05 06:37:23,167 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4896814833084742, 'Total loss': 0.4896814833084742} | train loss {'Reaction outcome loss': 0.19509025280298561, 'Total loss': 0.19509025280298561}
2023-01-05 06:37:23,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:23,168 INFO:     Epoch: 71
2023-01-05 06:37:25,355 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41944304953018824, 'Total loss': 0.41944304953018824} | train loss {'Reaction outcome loss': 0.2017174093997814, 'Total loss': 0.2017174093997814}
2023-01-05 06:37:25,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:25,355 INFO:     Epoch: 72
2023-01-05 06:37:27,559 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4330048228303591, 'Total loss': 0.4330048228303591} | train loss {'Reaction outcome loss': 0.1999586558629281, 'Total loss': 0.1999586558629281}
2023-01-05 06:37:27,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:27,560 INFO:     Epoch: 73
2023-01-05 06:37:29,790 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42108801468275486, 'Total loss': 0.42108801468275486} | train loss {'Reaction outcome loss': 0.18836944638940462, 'Total loss': 0.18836944638940462}
2023-01-05 06:37:29,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:29,790 INFO:     Epoch: 74
2023-01-05 06:37:32,039 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4471068541208903, 'Total loss': 0.4471068541208903} | train loss {'Reaction outcome loss': 0.18954394539007127, 'Total loss': 0.18954394539007127}
2023-01-05 06:37:32,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:32,040 INFO:     Epoch: 75
2023-01-05 06:37:34,264 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4898125191529592, 'Total loss': 0.4898125191529592} | train loss {'Reaction outcome loss': 0.19254754340049304, 'Total loss': 0.19254754340049304}
2023-01-05 06:37:34,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:34,265 INFO:     Epoch: 76
2023-01-05 06:37:36,473 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3976835901538531, 'Total loss': 0.3976835901538531} | train loss {'Reaction outcome loss': 0.19335823257305965, 'Total loss': 0.19335823257305965}
2023-01-05 06:37:36,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:36,473 INFO:     Epoch: 77
2023-01-05 06:37:38,651 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4274513324101766, 'Total loss': 0.4274513324101766} | train loss {'Reaction outcome loss': 0.18997715954493552, 'Total loss': 0.18997715954493552}
2023-01-05 06:37:38,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:38,651 INFO:     Epoch: 78
2023-01-05 06:37:40,868 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4441240032513936, 'Total loss': 0.4441240032513936} | train loss {'Reaction outcome loss': 0.18858545693668546, 'Total loss': 0.18858545693668546}
2023-01-05 06:37:40,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:40,868 INFO:     Epoch: 79
2023-01-05 06:37:43,059 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4237154920895894, 'Total loss': 0.4237154920895894} | train loss {'Reaction outcome loss': 0.1901048926749985, 'Total loss': 0.1901048926749985}
2023-01-05 06:37:43,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:43,059 INFO:     Epoch: 80
2023-01-05 06:37:45,287 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42577877938747405, 'Total loss': 0.42577877938747405} | train loss {'Reaction outcome loss': 0.18882929263086612, 'Total loss': 0.18882929263086612}
2023-01-05 06:37:45,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:45,288 INFO:     Epoch: 81
2023-01-05 06:37:47,508 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41195202867190045, 'Total loss': 0.41195202867190045} | train loss {'Reaction outcome loss': 0.1842427086566207, 'Total loss': 0.1842427086566207}
2023-01-05 06:37:47,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:47,509 INFO:     Epoch: 82
2023-01-05 06:37:49,701 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4318037094548345, 'Total loss': 0.4318037094548345} | train loss {'Reaction outcome loss': 0.18715351514820683, 'Total loss': 0.18715351514820683}
2023-01-05 06:37:49,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:49,701 INFO:     Epoch: 83
2023-01-05 06:37:51,921 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46635226110617317, 'Total loss': 0.46635226110617317} | train loss {'Reaction outcome loss': 0.1865154237184, 'Total loss': 0.1865154237184}
2023-01-05 06:37:51,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:51,921 INFO:     Epoch: 84
2023-01-05 06:37:54,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41987718145052594, 'Total loss': 0.41987718145052594} | train loss {'Reaction outcome loss': 0.18192799063743095, 'Total loss': 0.18192799063743095}
2023-01-05 06:37:54,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:54,145 INFO:     Epoch: 85
2023-01-05 06:37:56,376 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44830891738335293, 'Total loss': 0.44830891738335293} | train loss {'Reaction outcome loss': 0.1842287999313201, 'Total loss': 0.1842287999313201}
2023-01-05 06:37:56,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:56,377 INFO:     Epoch: 86
2023-01-05 06:37:58,607 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40855993231137594, 'Total loss': 0.40855993231137594} | train loss {'Reaction outcome loss': 0.1828467912930734, 'Total loss': 0.1828467912930734}
2023-01-05 06:37:58,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:37:58,607 INFO:     Epoch: 87
2023-01-05 06:38:00,792 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4246121724446615, 'Total loss': 0.4246121724446615} | train loss {'Reaction outcome loss': 0.18260067128799717, 'Total loss': 0.18260067128799717}
2023-01-05 06:38:00,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:00,793 INFO:     Epoch: 88
2023-01-05 06:38:03,026 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44296106497446697, 'Total loss': 0.44296106497446697} | train loss {'Reaction outcome loss': 0.18201189753135522, 'Total loss': 0.18201189753135522}
2023-01-05 06:38:03,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:03,027 INFO:     Epoch: 89
2023-01-05 06:38:05,271 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45841309825579324, 'Total loss': 0.45841309825579324} | train loss {'Reaction outcome loss': 0.18139958567917347, 'Total loss': 0.18139958567917347}
2023-01-05 06:38:05,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:05,272 INFO:     Epoch: 90
2023-01-05 06:38:07,514 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42291234334309896, 'Total loss': 0.42291234334309896} | train loss {'Reaction outcome loss': 0.1817379525632381, 'Total loss': 0.1817379525632381}
2023-01-05 06:38:07,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:07,515 INFO:     Epoch: 91
2023-01-05 06:38:09,752 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4320592787116766, 'Total loss': 0.4320592787116766} | train loss {'Reaction outcome loss': 0.18180018662117642, 'Total loss': 0.18180018662117642}
2023-01-05 06:38:09,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:09,752 INFO:     Epoch: 92
2023-01-05 06:38:11,963 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4420783132314682, 'Total loss': 0.4420783132314682} | train loss {'Reaction outcome loss': 0.18240378753752945, 'Total loss': 0.18240378753752945}
2023-01-05 06:38:11,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:11,963 INFO:     Epoch: 93
2023-01-05 06:38:14,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3989288414828479, 'Total loss': 0.3989288414828479} | train loss {'Reaction outcome loss': 0.18103463628167815, 'Total loss': 0.18103463628167815}
2023-01-05 06:38:14,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:14,130 INFO:     Epoch: 94
2023-01-05 06:38:16,352 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45123329559961955, 'Total loss': 0.45123329559961955} | train loss {'Reaction outcome loss': 0.1779274683088284, 'Total loss': 0.1779274683088284}
2023-01-05 06:38:16,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:16,353 INFO:     Epoch: 95
2023-01-05 06:38:18,596 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44981855948766075, 'Total loss': 0.44981855948766075} | train loss {'Reaction outcome loss': 0.17729256191115647, 'Total loss': 0.17729256191115647}
2023-01-05 06:38:18,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:18,597 INFO:     Epoch: 96
2023-01-05 06:38:20,833 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42862274348735807, 'Total loss': 0.42862274348735807} | train loss {'Reaction outcome loss': 0.17788159635048567, 'Total loss': 0.17788159635048567}
2023-01-05 06:38:20,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:20,833 INFO:     Epoch: 97
2023-01-05 06:38:23,055 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4727427105108897, 'Total loss': 0.4727427105108897} | train loss {'Reaction outcome loss': 0.18155468738813133, 'Total loss': 0.18155468738813133}
2023-01-05 06:38:23,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:23,055 INFO:     Epoch: 98
2023-01-05 06:38:25,270 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4222676804910103, 'Total loss': 0.4222676804910103} | train loss {'Reaction outcome loss': 0.17866852841034148, 'Total loss': 0.17866852841034148}
2023-01-05 06:38:25,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:25,270 INFO:     Epoch: 99
2023-01-05 06:38:27,496 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41204810293080907, 'Total loss': 0.41204810293080907} | train loss {'Reaction outcome loss': 0.17973210091438022, 'Total loss': 0.17973210091438022}
2023-01-05 06:38:27,496 INFO:     Best model found after epoch 56 of 100.
2023-01-05 06:38:27,496 INFO:   Done with stage: TRAINING
2023-01-05 06:38:27,496 INFO:   Starting stage: EVALUATION
2023-01-05 06:38:27,652 INFO:   Done with stage: EVALUATION
2023-01-05 06:38:27,652 INFO:   Leaving out SEQ value Fold_3
2023-01-05 06:38:27,665 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 06:38:27,665 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:38:28,318 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:38:28,318 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:38:28,391 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:38:28,391 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:38:28,391 INFO:     No hyperparam tuning for this model
2023-01-05 06:38:28,391 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:38:28,391 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:38:28,392 INFO:     None feature selector for col prot
2023-01-05 06:38:28,392 INFO:     None feature selector for col prot
2023-01-05 06:38:28,392 INFO:     None feature selector for col prot
2023-01-05 06:38:28,393 INFO:     None feature selector for col chem
2023-01-05 06:38:28,393 INFO:     None feature selector for col chem
2023-01-05 06:38:28,393 INFO:     None feature selector for col chem
2023-01-05 06:38:28,393 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:38:28,393 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:38:28,394 INFO:     Number of params in model 72931
2023-01-05 06:38:28,398 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:38:28,398 INFO:   Starting stage: TRAINING
2023-01-05 06:38:28,459 INFO:     Val loss before train {'Reaction outcome loss': 1.1002077182133994, 'Total loss': 1.1002077182133994}
2023-01-05 06:38:28,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:28,459 INFO:     Epoch: 0
2023-01-05 06:38:30,699 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7727941294511159, 'Total loss': 0.7727941294511159} | train loss {'Reaction outcome loss': 0.9409091203195142, 'Total loss': 0.9409091203195142}
2023-01-05 06:38:30,699 INFO:     Found new best model at epoch 0
2023-01-05 06:38:30,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:30,701 INFO:     Epoch: 1
2023-01-05 06:38:32,935 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5398480296134949, 'Total loss': 0.5398480296134949} | train loss {'Reaction outcome loss': 0.6246903962644704, 'Total loss': 0.6246903962644704}
2023-01-05 06:38:32,936 INFO:     Found new best model at epoch 1
2023-01-05 06:38:32,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:32,938 INFO:     Epoch: 2
2023-01-05 06:38:35,164 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5064386705557505, 'Total loss': 0.5064386705557505} | train loss {'Reaction outcome loss': 0.5265673937832738, 'Total loss': 0.5265673937832738}
2023-01-05 06:38:35,164 INFO:     Found new best model at epoch 2
2023-01-05 06:38:35,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:35,166 INFO:     Epoch: 3
2023-01-05 06:38:37,370 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5009946008523305, 'Total loss': 0.5009946008523305} | train loss {'Reaction outcome loss': 0.48872383433734357, 'Total loss': 0.48872383433734357}
2023-01-05 06:38:37,370 INFO:     Found new best model at epoch 3
2023-01-05 06:38:37,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:37,372 INFO:     Epoch: 4
2023-01-05 06:38:39,534 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4633351922035217, 'Total loss': 0.4633351922035217} | train loss {'Reaction outcome loss': 0.4651516849704334, 'Total loss': 0.4651516849704334}
2023-01-05 06:38:39,535 INFO:     Found new best model at epoch 4
2023-01-05 06:38:39,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:39,536 INFO:     Epoch: 5
2023-01-05 06:38:41,649 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4969361831744512, 'Total loss': 0.4969361831744512} | train loss {'Reaction outcome loss': 0.4454579644757443, 'Total loss': 0.4454579644757443}
2023-01-05 06:38:41,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:41,650 INFO:     Epoch: 6
2023-01-05 06:38:43,839 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4686124006907145, 'Total loss': 0.4686124006907145} | train loss {'Reaction outcome loss': 0.4317906727924998, 'Total loss': 0.4317906727924998}
2023-01-05 06:38:43,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:43,839 INFO:     Epoch: 7
2023-01-05 06:38:45,900 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44174810250600177, 'Total loss': 0.44174810250600177} | train loss {'Reaction outcome loss': 0.4159803746811138, 'Total loss': 0.4159803746811138}
2023-01-05 06:38:45,900 INFO:     Found new best model at epoch 7
2023-01-05 06:38:45,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:45,902 INFO:     Epoch: 8
2023-01-05 06:38:48,119 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45041597286860147, 'Total loss': 0.45041597286860147} | train loss {'Reaction outcome loss': 0.407345202356247, 'Total loss': 0.407345202356247}
2023-01-05 06:38:48,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:48,120 INFO:     Epoch: 9
2023-01-05 06:38:50,285 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44967833360036213, 'Total loss': 0.44967833360036213} | train loss {'Reaction outcome loss': 0.3928719162940979, 'Total loss': 0.3928719162940979}
2023-01-05 06:38:50,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:50,285 INFO:     Epoch: 10
2023-01-05 06:38:52,508 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4352789719899495, 'Total loss': 0.4352789719899495} | train loss {'Reaction outcome loss': 0.38587795885286647, 'Total loss': 0.38587795885286647}
2023-01-05 06:38:52,509 INFO:     Found new best model at epoch 10
2023-01-05 06:38:52,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:52,510 INFO:     Epoch: 11
2023-01-05 06:38:54,740 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4429491947094599, 'Total loss': 0.4429491947094599} | train loss {'Reaction outcome loss': 0.37154583336022506, 'Total loss': 0.37154583336022506}
2023-01-05 06:38:54,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:54,741 INFO:     Epoch: 12
2023-01-05 06:38:56,986 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44617736140886943, 'Total loss': 0.44617736140886943} | train loss {'Reaction outcome loss': 0.36446143065431463, 'Total loss': 0.36446143065431463}
2023-01-05 06:38:56,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:56,987 INFO:     Epoch: 13
2023-01-05 06:38:59,219 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43150636355082195, 'Total loss': 0.43150636355082195} | train loss {'Reaction outcome loss': 0.3518796877667473, 'Total loss': 0.3518796877667473}
2023-01-05 06:38:59,220 INFO:     Found new best model at epoch 13
2023-01-05 06:38:59,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:38:59,221 INFO:     Epoch: 14
2023-01-05 06:39:01,476 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4603039905428886, 'Total loss': 0.4603039905428886} | train loss {'Reaction outcome loss': 0.34191580760083073, 'Total loss': 0.34191580760083073}
2023-01-05 06:39:01,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:01,477 INFO:     Epoch: 15
2023-01-05 06:39:03,697 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41769225200017296, 'Total loss': 0.41769225200017296} | train loss {'Reaction outcome loss': 0.34018410450857944, 'Total loss': 0.34018410450857944}
2023-01-05 06:39:03,698 INFO:     Found new best model at epoch 15
2023-01-05 06:39:03,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:03,699 INFO:     Epoch: 16
2023-01-05 06:39:05,948 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4336607317129771, 'Total loss': 0.4336607317129771} | train loss {'Reaction outcome loss': 0.33135912039513077, 'Total loss': 0.33135912039513077}
2023-01-05 06:39:05,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:05,948 INFO:     Epoch: 17
2023-01-05 06:39:08,185 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4159631912906965, 'Total loss': 0.4159631912906965} | train loss {'Reaction outcome loss': 0.32272601846564297, 'Total loss': 0.32272601846564297}
2023-01-05 06:39:08,186 INFO:     Found new best model at epoch 17
2023-01-05 06:39:08,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:08,187 INFO:     Epoch: 18
2023-01-05 06:39:10,425 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41332739405333996, 'Total loss': 0.41332739405333996} | train loss {'Reaction outcome loss': 0.31796206588894677, 'Total loss': 0.31796206588894677}
2023-01-05 06:39:10,425 INFO:     Found new best model at epoch 18
2023-01-05 06:39:10,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:10,427 INFO:     Epoch: 19
2023-01-05 06:39:12,643 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39398171864449977, 'Total loss': 0.39398171864449977} | train loss {'Reaction outcome loss': 0.3138323355864775, 'Total loss': 0.3138323355864775}
2023-01-05 06:39:12,643 INFO:     Found new best model at epoch 19
2023-01-05 06:39:12,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:12,644 INFO:     Epoch: 20
2023-01-05 06:39:14,895 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44994519650936127, 'Total loss': 0.44994519650936127} | train loss {'Reaction outcome loss': 0.30037241448335544, 'Total loss': 0.30037241448335544}
2023-01-05 06:39:14,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:14,895 INFO:     Epoch: 21
2023-01-05 06:39:17,145 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40459694402913254, 'Total loss': 0.40459694402913254} | train loss {'Reaction outcome loss': 0.29715291071147054, 'Total loss': 0.29715291071147054}
2023-01-05 06:39:17,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:17,145 INFO:     Epoch: 22
2023-01-05 06:39:19,372 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4075696458419164, 'Total loss': 0.4075696458419164} | train loss {'Reaction outcome loss': 0.2926803060233373, 'Total loss': 0.2926803060233373}
2023-01-05 06:39:19,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:19,373 INFO:     Epoch: 23
2023-01-05 06:39:21,592 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43295383354028066, 'Total loss': 0.43295383354028066} | train loss {'Reaction outcome loss': 0.29042757116945467, 'Total loss': 0.29042757116945467}
2023-01-05 06:39:21,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:21,593 INFO:     Epoch: 24
2023-01-05 06:39:23,800 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4137772172689438, 'Total loss': 0.4137772172689438} | train loss {'Reaction outcome loss': 0.2834065867608544, 'Total loss': 0.2834065867608544}
2023-01-05 06:39:23,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:23,801 INFO:     Epoch: 25
2023-01-05 06:39:26,051 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4299227945506573, 'Total loss': 0.4299227945506573} | train loss {'Reaction outcome loss': 0.2749583568162804, 'Total loss': 0.2749583568162804}
2023-01-05 06:39:26,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:26,052 INFO:     Epoch: 26
2023-01-05 06:39:28,294 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3942060692856709, 'Total loss': 0.3942060692856709} | train loss {'Reaction outcome loss': 0.27354065627134594, 'Total loss': 0.27354065627134594}
2023-01-05 06:39:28,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:28,294 INFO:     Epoch: 27
2023-01-05 06:39:30,540 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3888658533493678, 'Total loss': 0.3888658533493678} | train loss {'Reaction outcome loss': 0.2704414062174484, 'Total loss': 0.2704414062174484}
2023-01-05 06:39:30,540 INFO:     Found new best model at epoch 27
2023-01-05 06:39:30,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:30,542 INFO:     Epoch: 28
2023-01-05 06:39:32,777 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4118914743264516, 'Total loss': 0.4118914743264516} | train loss {'Reaction outcome loss': 0.26342700296717375, 'Total loss': 0.26342700296717375}
2023-01-05 06:39:32,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:32,777 INFO:     Epoch: 29
2023-01-05 06:39:34,988 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41601243913173674, 'Total loss': 0.41601243913173674} | train loss {'Reaction outcome loss': 0.2616888661611124, 'Total loss': 0.2616888661611124}
2023-01-05 06:39:34,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:34,988 INFO:     Epoch: 30
2023-01-05 06:39:37,223 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.383486150080959, 'Total loss': 0.383486150080959} | train loss {'Reaction outcome loss': 0.2536680345110788, 'Total loss': 0.2536680345110788}
2023-01-05 06:39:37,223 INFO:     Found new best model at epoch 30
2023-01-05 06:39:37,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:37,224 INFO:     Epoch: 31
2023-01-05 06:39:39,476 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39591923703749976, 'Total loss': 0.39591923703749976} | train loss {'Reaction outcome loss': 0.25008740626632947, 'Total loss': 0.25008740626632947}
2023-01-05 06:39:39,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:39,476 INFO:     Epoch: 32
2023-01-05 06:39:41,711 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4076782395442327, 'Total loss': 0.4076782395442327} | train loss {'Reaction outcome loss': 0.25245336646633393, 'Total loss': 0.25245336646633393}
2023-01-05 06:39:41,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:41,712 INFO:     Epoch: 33
2023-01-05 06:39:43,963 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4275070915619532, 'Total loss': 0.4275070915619532} | train loss {'Reaction outcome loss': 0.24405934838956134, 'Total loss': 0.24405934838956134}
2023-01-05 06:39:43,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:43,965 INFO:     Epoch: 34
2023-01-05 06:39:46,168 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41088601350784304, 'Total loss': 0.41088601350784304} | train loss {'Reaction outcome loss': 0.2390407949163685, 'Total loss': 0.2390407949163685}
2023-01-05 06:39:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:46,168 INFO:     Epoch: 35
2023-01-05 06:39:48,425 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.403390046954155, 'Total loss': 0.403390046954155} | train loss {'Reaction outcome loss': 0.23327425983820343, 'Total loss': 0.23327425983820343}
2023-01-05 06:39:48,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:48,426 INFO:     Epoch: 36
2023-01-05 06:39:50,655 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45354600648085275, 'Total loss': 0.45354600648085275} | train loss {'Reaction outcome loss': 0.23402738714817486, 'Total loss': 0.23402738714817486}
2023-01-05 06:39:50,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:50,656 INFO:     Epoch: 37
2023-01-05 06:39:52,901 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40555188606182735, 'Total loss': 0.40555188606182735} | train loss {'Reaction outcome loss': 0.22772037457825953, 'Total loss': 0.22772037457825953}
2023-01-05 06:39:52,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:52,901 INFO:     Epoch: 38
2023-01-05 06:39:55,125 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41109407047430674, 'Total loss': 0.41109407047430674} | train loss {'Reaction outcome loss': 0.2293952718459592, 'Total loss': 0.2293952718459592}
2023-01-05 06:39:55,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:55,125 INFO:     Epoch: 39
2023-01-05 06:39:57,337 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4537360618511836, 'Total loss': 0.4537360618511836} | train loss {'Reaction outcome loss': 0.22897827334537058, 'Total loss': 0.22897827334537058}
2023-01-05 06:39:57,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:57,338 INFO:     Epoch: 40
2023-01-05 06:39:59,583 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43965006470680235, 'Total loss': 0.43965006470680235} | train loss {'Reaction outcome loss': 0.2196853795532151, 'Total loss': 0.2196853795532151}
2023-01-05 06:39:59,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:39:59,583 INFO:     Epoch: 41
2023-01-05 06:40:01,807 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45646271904309593, 'Total loss': 0.45646271904309593} | train loss {'Reaction outcome loss': 0.2210386197986528, 'Total loss': 0.2210386197986528}
2023-01-05 06:40:01,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:01,808 INFO:     Epoch: 42
2023-01-05 06:40:04,043 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41017067432403564, 'Total loss': 0.41017067432403564} | train loss {'Reaction outcome loss': 0.22021827698991087, 'Total loss': 0.22021827698991087}
2023-01-05 06:40:04,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:04,044 INFO:     Epoch: 43
2023-01-05 06:40:06,292 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41972433825333916, 'Total loss': 0.41972433825333916} | train loss {'Reaction outcome loss': 0.2161467932886358, 'Total loss': 0.2161467932886358}
2023-01-05 06:40:06,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:06,293 INFO:     Epoch: 44
2023-01-05 06:40:08,508 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4327360878388087, 'Total loss': 0.4327360878388087} | train loss {'Reaction outcome loss': 0.21434095723905028, 'Total loss': 0.21434095723905028}
2023-01-05 06:40:08,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:08,508 INFO:     Epoch: 45
2023-01-05 06:40:10,749 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4349295496940613, 'Total loss': 0.4349295496940613} | train loss {'Reaction outcome loss': 0.2104478642804981, 'Total loss': 0.2104478642804981}
2023-01-05 06:40:10,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:10,749 INFO:     Epoch: 46
2023-01-05 06:40:12,981 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4402560045321782, 'Total loss': 0.4402560045321782} | train loss {'Reaction outcome loss': 0.20685032332432887, 'Total loss': 0.20685032332432887}
2023-01-05 06:40:12,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:12,981 INFO:     Epoch: 47
2023-01-05 06:40:15,208 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42026805877685547, 'Total loss': 0.42026805877685547} | train loss {'Reaction outcome loss': 0.20882417486698754, 'Total loss': 0.20882417486698754}
2023-01-05 06:40:15,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:15,208 INFO:     Epoch: 48
2023-01-05 06:40:17,449 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3942641923824946, 'Total loss': 0.3942641923824946} | train loss {'Reaction outcome loss': 0.20390825944083205, 'Total loss': 0.20390825944083205}
2023-01-05 06:40:17,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:17,449 INFO:     Epoch: 49
2023-01-05 06:40:19,673 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47489650373657544, 'Total loss': 0.47489650373657544} | train loss {'Reaction outcome loss': 0.2066749016981146, 'Total loss': 0.2066749016981146}
2023-01-05 06:40:19,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:19,674 INFO:     Epoch: 50
2023-01-05 06:40:21,920 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47230030993620553, 'Total loss': 0.47230030993620553} | train loss {'Reaction outcome loss': 0.20345412727060463, 'Total loss': 0.20345412727060463}
2023-01-05 06:40:21,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:21,920 INFO:     Epoch: 51
2023-01-05 06:40:24,215 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45749920308589936, 'Total loss': 0.45749920308589936} | train loss {'Reaction outcome loss': 0.2058021258012945, 'Total loss': 0.2058021258012945}
2023-01-05 06:40:24,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:24,216 INFO:     Epoch: 52
2023-01-05 06:40:26,524 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.464706606666247, 'Total loss': 0.464706606666247} | train loss {'Reaction outcome loss': 0.19681000759364603, 'Total loss': 0.19681000759364603}
2023-01-05 06:40:26,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:26,524 INFO:     Epoch: 53
2023-01-05 06:40:28,788 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47678714940945305, 'Total loss': 0.47678714940945305} | train loss {'Reaction outcome loss': 0.1996870336459599, 'Total loss': 0.1996870336459599}
2023-01-05 06:40:28,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:28,788 INFO:     Epoch: 54
2023-01-05 06:40:31,027 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4285837140555183, 'Total loss': 0.4285837140555183} | train loss {'Reaction outcome loss': 0.19683622513688084, 'Total loss': 0.19683622513688084}
2023-01-05 06:40:31,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:31,028 INFO:     Epoch: 55
2023-01-05 06:40:33,204 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42179751296838125, 'Total loss': 0.42179751296838125} | train loss {'Reaction outcome loss': 0.19957479589525953, 'Total loss': 0.19957479589525953}
2023-01-05 06:40:33,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:33,204 INFO:     Epoch: 56
2023-01-05 06:40:35,416 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4172955865816524, 'Total loss': 0.4172955865816524} | train loss {'Reaction outcome loss': 0.1963438657438898, 'Total loss': 0.1963438657438898}
2023-01-05 06:40:35,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:35,416 INFO:     Epoch: 57
2023-01-05 06:40:37,659 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4432828346888224, 'Total loss': 0.4432828346888224} | train loss {'Reaction outcome loss': 0.19415564736440724, 'Total loss': 0.19415564736440724}
2023-01-05 06:40:37,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:37,659 INFO:     Epoch: 58
2023-01-05 06:40:39,885 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41317019003132976, 'Total loss': 0.41317019003132976} | train loss {'Reaction outcome loss': 0.1925721919143442, 'Total loss': 0.1925721919143442}
2023-01-05 06:40:39,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:39,885 INFO:     Epoch: 59
2023-01-05 06:40:42,146 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.408544738466541, 'Total loss': 0.408544738466541} | train loss {'Reaction outcome loss': 0.18795216815525534, 'Total loss': 0.18795216815525534}
2023-01-05 06:40:42,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:42,146 INFO:     Epoch: 60
2023-01-05 06:40:44,370 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4380259171128273, 'Total loss': 0.4380259171128273} | train loss {'Reaction outcome loss': 0.19115112706111587, 'Total loss': 0.19115112706111587}
2023-01-05 06:40:44,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:44,371 INFO:     Epoch: 61
2023-01-05 06:40:46,614 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4204346266264717, 'Total loss': 0.4204346266264717} | train loss {'Reaction outcome loss': 0.1931397507063412, 'Total loss': 0.1931397507063412}
2023-01-05 06:40:46,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:46,614 INFO:     Epoch: 62
2023-01-05 06:40:48,873 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46558537185192106, 'Total loss': 0.46558537185192106} | train loss {'Reaction outcome loss': 0.18990583548741588, 'Total loss': 0.18990583548741588}
2023-01-05 06:40:48,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:48,873 INFO:     Epoch: 63
2023-01-05 06:40:51,129 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4613072544336319, 'Total loss': 0.4613072544336319} | train loss {'Reaction outcome loss': 0.18768309568814465, 'Total loss': 0.18768309568814465}
2023-01-05 06:40:51,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:51,130 INFO:     Epoch: 64
2023-01-05 06:40:53,391 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44426546717683474, 'Total loss': 0.44426546717683474} | train loss {'Reaction outcome loss': 0.1838477318934629, 'Total loss': 0.1838477318934629}
2023-01-05 06:40:53,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:53,391 INFO:     Epoch: 65
2023-01-05 06:40:55,624 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44235530216246843, 'Total loss': 0.44235530216246843} | train loss {'Reaction outcome loss': 0.1802184118122907, 'Total loss': 0.1802184118122907}
2023-01-05 06:40:55,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:55,626 INFO:     Epoch: 66
2023-01-05 06:40:57,865 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42234095335006716, 'Total loss': 0.42234095335006716} | train loss {'Reaction outcome loss': 0.1822392758896155, 'Total loss': 0.1822392758896155}
2023-01-05 06:40:57,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:40:57,865 INFO:     Epoch: 67
2023-01-05 06:41:00,089 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43857020139694214, 'Total loss': 0.43857020139694214} | train loss {'Reaction outcome loss': 0.17833464309518188, 'Total loss': 0.17833464309518188}
2023-01-05 06:41:00,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:00,089 INFO:     Epoch: 68
2023-01-05 06:41:02,338 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4381313236275067, 'Total loss': 0.4381313236275067} | train loss {'Reaction outcome loss': 0.17899629161641606, 'Total loss': 0.17899629161641606}
2023-01-05 06:41:02,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:02,339 INFO:     Epoch: 69
2023-01-05 06:41:04,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46375953356424965, 'Total loss': 0.46375953356424965} | train loss {'Reaction outcome loss': 0.18394373955954266, 'Total loss': 0.18394373955954266}
2023-01-05 06:41:04,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:04,573 INFO:     Epoch: 70
2023-01-05 06:41:06,796 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5102917363246282, 'Total loss': 0.5102917363246282} | train loss {'Reaction outcome loss': 0.17791202758366717, 'Total loss': 0.17791202758366717}
2023-01-05 06:41:06,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:06,796 INFO:     Epoch: 71
2023-01-05 06:41:09,023 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4541902999083201, 'Total loss': 0.4541902999083201} | train loss {'Reaction outcome loss': 0.1755685164787329, 'Total loss': 0.1755685164787329}
2023-01-05 06:41:09,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:09,023 INFO:     Epoch: 72
2023-01-05 06:41:11,269 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45233842978874844, 'Total loss': 0.45233842978874844} | train loss {'Reaction outcome loss': 0.17718366442103886, 'Total loss': 0.17718366442103886}
2023-01-05 06:41:11,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:11,269 INFO:     Epoch: 73
2023-01-05 06:41:13,498 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45474019745985667, 'Total loss': 0.45474019745985667} | train loss {'Reaction outcome loss': 0.17273238895983328, 'Total loss': 0.17273238895983328}
2023-01-05 06:41:13,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:13,498 INFO:     Epoch: 74
2023-01-05 06:41:15,746 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4920614371697108, 'Total loss': 0.4920614371697108} | train loss {'Reaction outcome loss': 0.17400822997079454, 'Total loss': 0.17400822997079454}
2023-01-05 06:41:15,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:15,747 INFO:     Epoch: 75
2023-01-05 06:41:17,984 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4757503379136324, 'Total loss': 0.4757503379136324} | train loss {'Reaction outcome loss': 0.17520291402221166, 'Total loss': 0.17520291402221166}
2023-01-05 06:41:17,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:17,985 INFO:     Epoch: 76
2023-01-05 06:41:20,170 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44469845841328304, 'Total loss': 0.44469845841328304} | train loss {'Reaction outcome loss': 0.17323998430730067, 'Total loss': 0.17323998430730067}
2023-01-05 06:41:20,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:20,171 INFO:     Epoch: 77
2023-01-05 06:41:22,400 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4425938067569708, 'Total loss': 0.4425938067569708} | train loss {'Reaction outcome loss': 0.1736477739555672, 'Total loss': 0.1736477739555672}
2023-01-05 06:41:22,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:22,400 INFO:     Epoch: 78
2023-01-05 06:41:24,640 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4778665194908778, 'Total loss': 0.4778665194908778} | train loss {'Reaction outcome loss': 0.17092420885036957, 'Total loss': 0.17092420885036957}
2023-01-05 06:41:24,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:24,640 INFO:     Epoch: 79
2023-01-05 06:41:26,816 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4412565877040227, 'Total loss': 0.4412565877040227} | train loss {'Reaction outcome loss': 0.17293335991220832, 'Total loss': 0.17293335991220832}
2023-01-05 06:41:26,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:26,817 INFO:     Epoch: 80
2023-01-05 06:41:29,010 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4281129489342372, 'Total loss': 0.4281129489342372} | train loss {'Reaction outcome loss': 0.16511520580818181, 'Total loss': 0.16511520580818181}
2023-01-05 06:41:29,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:29,010 INFO:     Epoch: 81
2023-01-05 06:41:31,168 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4400737972309192, 'Total loss': 0.4400737972309192} | train loss {'Reaction outcome loss': 0.17087099014874205, 'Total loss': 0.17087099014874205}
2023-01-05 06:41:31,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:31,168 INFO:     Epoch: 82
2023-01-05 06:41:33,406 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43699843287467954, 'Total loss': 0.43699843287467954} | train loss {'Reaction outcome loss': 0.17152981714575768, 'Total loss': 0.17152981714575768}
2023-01-05 06:41:33,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:33,408 INFO:     Epoch: 83
2023-01-05 06:41:35,579 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4882526139418284, 'Total loss': 0.4882526139418284} | train loss {'Reaction outcome loss': 0.16453266855521725, 'Total loss': 0.16453266855521725}
2023-01-05 06:41:35,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:35,579 INFO:     Epoch: 84
2023-01-05 06:41:37,805 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47853534917036694, 'Total loss': 0.47853534917036694} | train loss {'Reaction outcome loss': 0.16595686606141805, 'Total loss': 0.16595686606141805}
2023-01-05 06:41:37,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:37,805 INFO:     Epoch: 85
2023-01-05 06:41:40,009 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44782076676686605, 'Total loss': 0.44782076676686605} | train loss {'Reaction outcome loss': 0.16197853466337786, 'Total loss': 0.16197853466337786}
2023-01-05 06:41:40,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:40,010 INFO:     Epoch: 86
2023-01-05 06:41:42,211 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42143974187007793, 'Total loss': 0.42143974187007793} | train loss {'Reaction outcome loss': 0.16548099964032315, 'Total loss': 0.16548099964032315}
2023-01-05 06:41:42,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:42,211 INFO:     Epoch: 87
2023-01-05 06:41:44,405 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46395049393177035, 'Total loss': 0.46395049393177035} | train loss {'Reaction outcome loss': 0.16339354714846094, 'Total loss': 0.16339354714846094}
2023-01-05 06:41:44,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:44,406 INFO:     Epoch: 88
2023-01-05 06:41:46,634 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4385198399424553, 'Total loss': 0.4385198399424553} | train loss {'Reaction outcome loss': 0.16352301117761328, 'Total loss': 0.16352301117761328}
2023-01-05 06:41:46,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:46,635 INFO:     Epoch: 89
2023-01-05 06:41:48,839 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46055283745129905, 'Total loss': 0.46055283745129905} | train loss {'Reaction outcome loss': 0.16171352495697097, 'Total loss': 0.16171352495697097}
2023-01-05 06:41:48,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:48,839 INFO:     Epoch: 90
2023-01-05 06:41:51,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49079078833262124, 'Total loss': 0.49079078833262124} | train loss {'Reaction outcome loss': 0.16303111218960742, 'Total loss': 0.16303111218960742}
2023-01-05 06:41:51,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:51,064 INFO:     Epoch: 91
2023-01-05 06:41:53,273 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48370175758997597, 'Total loss': 0.48370175758997597} | train loss {'Reaction outcome loss': 0.16594930852306286, 'Total loss': 0.16594930852306286}
2023-01-05 06:41:53,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:53,274 INFO:     Epoch: 92
2023-01-05 06:41:55,479 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4303660593926907, 'Total loss': 0.4303660593926907} | train loss {'Reaction outcome loss': 0.16569953778590252, 'Total loss': 0.16569953778590252}
2023-01-05 06:41:55,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:55,480 INFO:     Epoch: 93
2023-01-05 06:41:57,730 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4653870125611623, 'Total loss': 0.4653870125611623} | train loss {'Reaction outcome loss': 0.16076228110724544, 'Total loss': 0.16076228110724544}
2023-01-05 06:41:57,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:57,730 INFO:     Epoch: 94
2023-01-05 06:41:59,953 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45397237930446865, 'Total loss': 0.45397237930446865} | train loss {'Reaction outcome loss': 0.1585104676578675, 'Total loss': 0.1585104676578675}
2023-01-05 06:41:59,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:41:59,953 INFO:     Epoch: 95
2023-01-05 06:42:02,179 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5179673155148824, 'Total loss': 0.5179673155148824} | train loss {'Reaction outcome loss': 0.16278827352607383, 'Total loss': 0.16278827352607383}
2023-01-05 06:42:02,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:02,181 INFO:     Epoch: 96
2023-01-05 06:42:04,402 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4704283793767293, 'Total loss': 0.4704283793767293} | train loss {'Reaction outcome loss': 0.15837014998769822, 'Total loss': 0.15837014998769822}
2023-01-05 06:42:04,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:04,402 INFO:     Epoch: 97
2023-01-05 06:42:06,577 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4605304236213366, 'Total loss': 0.4605304236213366} | train loss {'Reaction outcome loss': 0.16001696534441076, 'Total loss': 0.16001696534441076}
2023-01-05 06:42:06,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:06,577 INFO:     Epoch: 98
2023-01-05 06:42:08,823 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4846620460351308, 'Total loss': 0.4846620460351308} | train loss {'Reaction outcome loss': 0.1579015850574053, 'Total loss': 0.1579015850574053}
2023-01-05 06:42:08,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:08,824 INFO:     Epoch: 99
2023-01-05 06:42:11,062 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4859009842077891, 'Total loss': 0.4859009842077891} | train loss {'Reaction outcome loss': 0.16698113292270095, 'Total loss': 0.16698113292270095}
2023-01-05 06:42:11,063 INFO:     Best model found after epoch 31 of 100.
2023-01-05 06:42:11,063 INFO:   Done with stage: TRAINING
2023-01-05 06:42:11,063 INFO:   Starting stage: EVALUATION
2023-01-05 06:42:11,217 INFO:   Done with stage: EVALUATION
2023-01-05 06:42:11,217 INFO:   Leaving out SEQ value Fold_4
2023-01-05 06:42:11,230 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:42:11,230 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:42:11,884 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:42:11,884 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:42:11,957 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:42:11,958 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:42:11,958 INFO:     No hyperparam tuning for this model
2023-01-05 06:42:11,958 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:42:11,958 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:42:11,959 INFO:     None feature selector for col prot
2023-01-05 06:42:11,959 INFO:     None feature selector for col prot
2023-01-05 06:42:11,959 INFO:     None feature selector for col prot
2023-01-05 06:42:11,959 INFO:     None feature selector for col chem
2023-01-05 06:42:11,959 INFO:     None feature selector for col chem
2023-01-05 06:42:11,959 INFO:     None feature selector for col chem
2023-01-05 06:42:11,960 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:42:11,960 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:42:11,961 INFO:     Number of params in model 72931
2023-01-05 06:42:11,964 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:42:11,964 INFO:   Starting stage: TRAINING
2023-01-05 06:42:12,025 INFO:     Val loss before train {'Reaction outcome loss': 0.9115424553553263, 'Total loss': 0.9115424553553263}
2023-01-05 06:42:12,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:12,026 INFO:     Epoch: 0
2023-01-05 06:42:14,291 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7416285435358684, 'Total loss': 0.7416285435358684} | train loss {'Reaction outcome loss': 0.9463714818446645, 'Total loss': 0.9463714818446645}
2023-01-05 06:42:14,291 INFO:     Found new best model at epoch 0
2023-01-05 06:42:14,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:14,293 INFO:     Epoch: 1
2023-01-05 06:42:16,584 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5486107508341471, 'Total loss': 0.5486107508341471} | train loss {'Reaction outcome loss': 0.6461850677479045, 'Total loss': 0.6461850677479045}
2023-01-05 06:42:16,584 INFO:     Found new best model at epoch 1
2023-01-05 06:42:16,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:16,585 INFO:     Epoch: 2
2023-01-05 06:42:18,838 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5071801692247391, 'Total loss': 0.5071801692247391} | train loss {'Reaction outcome loss': 0.5490977109446853, 'Total loss': 0.5490977109446853}
2023-01-05 06:42:18,838 INFO:     Found new best model at epoch 2
2023-01-05 06:42:18,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:18,840 INFO:     Epoch: 3
2023-01-05 06:42:21,107 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4788587431112925, 'Total loss': 0.4788587431112925} | train loss {'Reaction outcome loss': 0.5097641093851427, 'Total loss': 0.5097641093851427}
2023-01-05 06:42:21,107 INFO:     Found new best model at epoch 3
2023-01-05 06:42:21,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:21,109 INFO:     Epoch: 4
2023-01-05 06:42:23,357 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49160653750101724, 'Total loss': 0.49160653750101724} | train loss {'Reaction outcome loss': 0.48439882663398015, 'Total loss': 0.48439882663398015}
2023-01-05 06:42:23,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:23,357 INFO:     Epoch: 5
2023-01-05 06:42:25,560 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47201787630716957, 'Total loss': 0.47201787630716957} | train loss {'Reaction outcome loss': 0.45853340867839565, 'Total loss': 0.45853340867839565}
2023-01-05 06:42:25,560 INFO:     Found new best model at epoch 5
2023-01-05 06:42:25,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:25,561 INFO:     Epoch: 6
2023-01-05 06:42:27,785 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4707640528678894, 'Total loss': 0.4707640528678894} | train loss {'Reaction outcome loss': 0.4408681948101047, 'Total loss': 0.4408681948101047}
2023-01-05 06:42:27,785 INFO:     Found new best model at epoch 6
2023-01-05 06:42:27,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:27,787 INFO:     Epoch: 7
2023-01-05 06:42:30,003 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44945818185806274, 'Total loss': 0.44945818185806274} | train loss {'Reaction outcome loss': 0.4224627486527612, 'Total loss': 0.4224627486527612}
2023-01-05 06:42:30,003 INFO:     Found new best model at epoch 7
2023-01-05 06:42:30,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:30,004 INFO:     Epoch: 8
2023-01-05 06:42:32,303 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.441220623254776, 'Total loss': 0.441220623254776} | train loss {'Reaction outcome loss': 0.41316228424491436, 'Total loss': 0.41316228424491436}
2023-01-05 06:42:32,303 INFO:     Found new best model at epoch 8
2023-01-05 06:42:32,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:32,304 INFO:     Epoch: 9
2023-01-05 06:42:34,603 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4258240818977356, 'Total loss': 0.4258240818977356} | train loss {'Reaction outcome loss': 0.40295830896184764, 'Total loss': 0.40295830896184764}
2023-01-05 06:42:34,603 INFO:     Found new best model at epoch 9
2023-01-05 06:42:34,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:34,605 INFO:     Epoch: 10
2023-01-05 06:42:36,885 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4435976435740789, 'Total loss': 0.4435976435740789} | train loss {'Reaction outcome loss': 0.3898778307362584, 'Total loss': 0.3898778307362584}
2023-01-05 06:42:36,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:36,886 INFO:     Epoch: 11
2023-01-05 06:42:39,144 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42341359456380206, 'Total loss': 0.42341359456380206} | train loss {'Reaction outcome loss': 0.37724185140554656, 'Total loss': 0.37724185140554656}
2023-01-05 06:42:39,145 INFO:     Found new best model at epoch 11
2023-01-05 06:42:39,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:39,147 INFO:     Epoch: 12
2023-01-05 06:42:41,417 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4253074675798416, 'Total loss': 0.4253074675798416} | train loss {'Reaction outcome loss': 0.3698839114353545, 'Total loss': 0.3698839114353545}
2023-01-05 06:42:41,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:41,417 INFO:     Epoch: 13
2023-01-05 06:42:43,716 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43221455514431, 'Total loss': 0.43221455514431} | train loss {'Reaction outcome loss': 0.36145312185752265, 'Total loss': 0.36145312185752265}
2023-01-05 06:42:43,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:43,717 INFO:     Epoch: 14
2023-01-05 06:42:45,991 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40398087203502653, 'Total loss': 0.40398087203502653} | train loss {'Reaction outcome loss': 0.3536716995202677, 'Total loss': 0.3536716995202677}
2023-01-05 06:42:45,992 INFO:     Found new best model at epoch 14
2023-01-05 06:42:45,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:45,993 INFO:     Epoch: 15
2023-01-05 06:42:48,301 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43048866962393123, 'Total loss': 0.43048866962393123} | train loss {'Reaction outcome loss': 0.34471552434380737, 'Total loss': 0.34471552434380737}
2023-01-05 06:42:48,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:48,301 INFO:     Epoch: 16
2023-01-05 06:42:50,558 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4198821157217026, 'Total loss': 0.4198821157217026} | train loss {'Reaction outcome loss': 0.33878087209342617, 'Total loss': 0.33878087209342617}
2023-01-05 06:42:50,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:50,558 INFO:     Epoch: 17
2023-01-05 06:42:52,774 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41258880992730457, 'Total loss': 0.41258880992730457} | train loss {'Reaction outcome loss': 0.33140114680040184, 'Total loss': 0.33140114680040184}
2023-01-05 06:42:52,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:52,774 INFO:     Epoch: 18
2023-01-05 06:42:54,878 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42693664530913034, 'Total loss': 0.42693664530913034} | train loss {'Reaction outcome loss': 0.3264638180323349, 'Total loss': 0.3264638180323349}
2023-01-05 06:42:54,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:54,878 INFO:     Epoch: 19
2023-01-05 06:42:57,168 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43240393201510113, 'Total loss': 0.43240393201510113} | train loss {'Reaction outcome loss': 0.3202686600642622, 'Total loss': 0.3202686600642622}
2023-01-05 06:42:57,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:57,168 INFO:     Epoch: 20
2023-01-05 06:42:59,477 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41464858055114745, 'Total loss': 0.41464858055114745} | train loss {'Reaction outcome loss': 0.31584092920867973, 'Total loss': 0.31584092920867973}
2023-01-05 06:42:59,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:42:59,478 INFO:     Epoch: 21
2023-01-05 06:43:01,770 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.433450644214948, 'Total loss': 0.433450644214948} | train loss {'Reaction outcome loss': 0.3112649870128623, 'Total loss': 0.3112649870128623}
2023-01-05 06:43:01,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:01,770 INFO:     Epoch: 22
2023-01-05 06:43:04,043 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45824442903200785, 'Total loss': 0.45824442903200785} | train loss {'Reaction outcome loss': 0.3031598036362376, 'Total loss': 0.3031598036362376}
2023-01-05 06:43:04,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:04,043 INFO:     Epoch: 23
2023-01-05 06:43:06,343 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4483731637398402, 'Total loss': 0.4483731637398402} | train loss {'Reaction outcome loss': 0.3013626758802669, 'Total loss': 0.3013626758802669}
2023-01-05 06:43:06,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:06,344 INFO:     Epoch: 24
2023-01-05 06:43:08,635 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4130200117826462, 'Total loss': 0.4130200117826462} | train loss {'Reaction outcome loss': 0.29590164941301844, 'Total loss': 0.29590164941301844}
2023-01-05 06:43:08,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:08,635 INFO:     Epoch: 25
2023-01-05 06:43:10,920 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.419724644223849, 'Total loss': 0.419724644223849} | train loss {'Reaction outcome loss': 0.2931717401673002, 'Total loss': 0.2931717401673002}
2023-01-05 06:43:10,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:10,921 INFO:     Epoch: 26
2023-01-05 06:43:13,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43616000513235725, 'Total loss': 0.43616000513235725} | train loss {'Reaction outcome loss': 0.28855562840827104, 'Total loss': 0.28855562840827104}
2023-01-05 06:43:13,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:13,208 INFO:     Epoch: 27
2023-01-05 06:43:15,452 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43926801681518557, 'Total loss': 0.43926801681518557} | train loss {'Reaction outcome loss': 0.28727333306163444, 'Total loss': 0.28727333306163444}
2023-01-05 06:43:15,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:15,453 INFO:     Epoch: 28
2023-01-05 06:43:17,768 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4227523863315582, 'Total loss': 0.4227523863315582} | train loss {'Reaction outcome loss': 0.27881506955190577, 'Total loss': 0.27881506955190577}
2023-01-05 06:43:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:17,769 INFO:     Epoch: 29
2023-01-05 06:43:20,078 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4263943821191788, 'Total loss': 0.4263943821191788} | train loss {'Reaction outcome loss': 0.28194102845306, 'Total loss': 0.28194102845306}
2023-01-05 06:43:20,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:20,078 INFO:     Epoch: 30
2023-01-05 06:43:22,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43853033185005186, 'Total loss': 0.43853033185005186} | train loss {'Reaction outcome loss': 0.2710444026690528, 'Total loss': 0.2710444026690528}
2023-01-05 06:43:22,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:22,415 INFO:     Epoch: 31
2023-01-05 06:43:24,725 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4303925588726997, 'Total loss': 0.4303925588726997} | train loss {'Reaction outcome loss': 0.27178404663121225, 'Total loss': 0.27178404663121225}
2023-01-05 06:43:24,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:24,725 INFO:     Epoch: 32
2023-01-05 06:43:27,000 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44368281463781994, 'Total loss': 0.44368281463781994} | train loss {'Reaction outcome loss': 0.2652992426353887, 'Total loss': 0.2652992426353887}
2023-01-05 06:43:27,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:27,001 INFO:     Epoch: 33
2023-01-05 06:43:29,303 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4162058432896932, 'Total loss': 0.4162058432896932} | train loss {'Reaction outcome loss': 0.265591463033742, 'Total loss': 0.265591463033742}
2023-01-05 06:43:29,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:29,303 INFO:     Epoch: 34
2023-01-05 06:43:31,598 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47563777764638265, 'Total loss': 0.47563777764638265} | train loss {'Reaction outcome loss': 0.26404389308678117, 'Total loss': 0.26404389308678117}
2023-01-05 06:43:31,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:31,598 INFO:     Epoch: 35
2023-01-05 06:43:33,908 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43735371530056, 'Total loss': 0.43735371530056} | train loss {'Reaction outcome loss': 0.25548876670024456, 'Total loss': 0.25548876670024456}
2023-01-05 06:43:33,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:33,908 INFO:     Epoch: 36
2023-01-05 06:43:36,204 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45547791620095573, 'Total loss': 0.45547791620095573} | train loss {'Reaction outcome loss': 0.25454592782775415, 'Total loss': 0.25454592782775415}
2023-01-05 06:43:36,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:36,205 INFO:     Epoch: 37
2023-01-05 06:43:38,484 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4320673676828543, 'Total loss': 0.4320673676828543} | train loss {'Reaction outcome loss': 0.2526423081365626, 'Total loss': 0.2526423081365626}
2023-01-05 06:43:38,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:38,484 INFO:     Epoch: 38
2023-01-05 06:43:40,742 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46659103631973264, 'Total loss': 0.46659103631973264} | train loss {'Reaction outcome loss': 0.2497922200474229, 'Total loss': 0.2497922200474229}
2023-01-05 06:43:40,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:40,743 INFO:     Epoch: 39
2023-01-05 06:43:43,033 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4780376667777697, 'Total loss': 0.4780376667777697} | train loss {'Reaction outcome loss': 0.244637432496403, 'Total loss': 0.244637432496403}
2023-01-05 06:43:43,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:43,034 INFO:     Epoch: 40
2023-01-05 06:43:45,325 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44309080243110655, 'Total loss': 0.44309080243110655} | train loss {'Reaction outcome loss': 0.24617271711680003, 'Total loss': 0.24617271711680003}
2023-01-05 06:43:45,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:45,327 INFO:     Epoch: 41
2023-01-05 06:43:47,605 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4488076001405716, 'Total loss': 0.4488076001405716} | train loss {'Reaction outcome loss': 0.24156254442536443, 'Total loss': 0.24156254442536443}
2023-01-05 06:43:47,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:47,606 INFO:     Epoch: 42
2023-01-05 06:43:49,883 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46751626978317895, 'Total loss': 0.46751626978317895} | train loss {'Reaction outcome loss': 0.23878402202406945, 'Total loss': 0.23878402202406945}
2023-01-05 06:43:49,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:49,884 INFO:     Epoch: 43
2023-01-05 06:43:52,093 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47798277338345846, 'Total loss': 0.47798277338345846} | train loss {'Reaction outcome loss': 0.2333651446814679, 'Total loss': 0.2333651446814679}
2023-01-05 06:43:52,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:52,094 INFO:     Epoch: 44
2023-01-05 06:43:54,389 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41588510274887086, 'Total loss': 0.41588510274887086} | train loss {'Reaction outcome loss': 0.2340355629323299, 'Total loss': 0.2340355629323299}
2023-01-05 06:43:54,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:54,389 INFO:     Epoch: 45
2023-01-05 06:43:56,675 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4454521775245667, 'Total loss': 0.4454521775245667} | train loss {'Reaction outcome loss': 0.2319843585061629, 'Total loss': 0.2319843585061629}
2023-01-05 06:43:56,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:56,676 INFO:     Epoch: 46
2023-01-05 06:43:58,967 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44837373892466226, 'Total loss': 0.44837373892466226} | train loss {'Reaction outcome loss': 0.2300119698182125, 'Total loss': 0.2300119698182125}
2023-01-05 06:43:58,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:43:58,967 INFO:     Epoch: 47
2023-01-05 06:44:01,249 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4579444855451584, 'Total loss': 0.4579444855451584} | train loss {'Reaction outcome loss': 0.22904764874317154, 'Total loss': 0.22904764874317154}
2023-01-05 06:44:01,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:01,249 INFO:     Epoch: 48
2023-01-05 06:44:03,504 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44565603335698445, 'Total loss': 0.44565603335698445} | train loss {'Reaction outcome loss': 0.22794903549853215, 'Total loss': 0.22794903549853215}
2023-01-05 06:44:03,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:03,504 INFO:     Epoch: 49
2023-01-05 06:44:05,790 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.437323268254598, 'Total loss': 0.437323268254598} | train loss {'Reaction outcome loss': 0.22789169448538807, 'Total loss': 0.22789169448538807}
2023-01-05 06:44:05,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:05,791 INFO:     Epoch: 50
2023-01-05 06:44:08,084 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4168455764651299, 'Total loss': 0.4168455764651299} | train loss {'Reaction outcome loss': 0.2244443118854658, 'Total loss': 0.2244443118854658}
2023-01-05 06:44:08,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:08,084 INFO:     Epoch: 51
2023-01-05 06:44:10,374 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4543296714623769, 'Total loss': 0.4543296714623769} | train loss {'Reaction outcome loss': 0.2208766235805214, 'Total loss': 0.2208766235805214}
2023-01-05 06:44:10,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:10,374 INFO:     Epoch: 52
2023-01-05 06:44:12,663 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4215703586737315, 'Total loss': 0.4215703586737315} | train loss {'Reaction outcome loss': 0.2165009703298876, 'Total loss': 0.2165009703298876}
2023-01-05 06:44:12,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:12,663 INFO:     Epoch: 53
2023-01-05 06:44:14,851 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45529399812221527, 'Total loss': 0.45529399812221527} | train loss {'Reaction outcome loss': 0.21525136351128132, 'Total loss': 0.21525136351128132}
2023-01-05 06:44:14,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:14,852 INFO:     Epoch: 54
2023-01-05 06:44:17,144 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4431192954381307, 'Total loss': 0.4431192954381307} | train loss {'Reaction outcome loss': 0.21467646406391896, 'Total loss': 0.21467646406391896}
2023-01-05 06:44:17,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:17,145 INFO:     Epoch: 55
2023-01-05 06:44:19,443 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43767809520165124, 'Total loss': 0.43767809520165124} | train loss {'Reaction outcome loss': 0.21104041149416125, 'Total loss': 0.21104041149416125}
2023-01-05 06:44:19,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:19,444 INFO:     Epoch: 56
2023-01-05 06:44:21,734 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43208144505818685, 'Total loss': 0.43208144505818685} | train loss {'Reaction outcome loss': 0.21223698944418223, 'Total loss': 0.21223698944418223}
2023-01-05 06:44:21,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:21,735 INFO:     Epoch: 57
2023-01-05 06:44:24,019 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42902851998806, 'Total loss': 0.42902851998806} | train loss {'Reaction outcome loss': 0.21490699263282848, 'Total loss': 0.21490699263282848}
2023-01-05 06:44:24,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:24,019 INFO:     Epoch: 58
2023-01-05 06:44:26,244 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42558245062828065, 'Total loss': 0.42558245062828065} | train loss {'Reaction outcome loss': 0.21304303614442852, 'Total loss': 0.21304303614442852}
2023-01-05 06:44:26,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:26,245 INFO:     Epoch: 59
2023-01-05 06:44:28,533 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4173595423499743, 'Total loss': 0.4173595423499743} | train loss {'Reaction outcome loss': 0.20786210186846743, 'Total loss': 0.20786210186846743}
2023-01-05 06:44:28,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:28,534 INFO:     Epoch: 60
2023-01-05 06:44:30,829 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4302569588025411, 'Total loss': 0.4302569588025411} | train loss {'Reaction outcome loss': 0.20642291909480462, 'Total loss': 0.20642291909480462}
2023-01-05 06:44:30,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:30,829 INFO:     Epoch: 61
2023-01-05 06:44:33,105 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43522620101769766, 'Total loss': 0.43522620101769766} | train loss {'Reaction outcome loss': 0.20934790796818822, 'Total loss': 0.20934790796818822}
2023-01-05 06:44:33,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:33,105 INFO:     Epoch: 62
2023-01-05 06:44:35,382 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43415701339642204, 'Total loss': 0.43415701339642204} | train loss {'Reaction outcome loss': 0.20432189373225512, 'Total loss': 0.20432189373225512}
2023-01-05 06:44:35,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:35,382 INFO:     Epoch: 63
2023-01-05 06:44:37,629 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43700136442979176, 'Total loss': 0.43700136442979176} | train loss {'Reaction outcome loss': 0.2028359691797342, 'Total loss': 0.2028359691797342}
2023-01-05 06:44:37,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:37,630 INFO:     Epoch: 64
2023-01-05 06:44:39,917 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4627288763721784, 'Total loss': 0.4627288763721784} | train loss {'Reaction outcome loss': 0.20518957672721375, 'Total loss': 0.20518957672721375}
2023-01-05 06:44:39,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:39,918 INFO:     Epoch: 65
2023-01-05 06:44:42,203 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44431962867577873, 'Total loss': 0.44431962867577873} | train loss {'Reaction outcome loss': 0.19753820498201607, 'Total loss': 0.19753820498201607}
2023-01-05 06:44:42,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:42,204 INFO:     Epoch: 66
2023-01-05 06:44:44,491 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4456012626489004, 'Total loss': 0.4456012626489004} | train loss {'Reaction outcome loss': 0.19619778439483274, 'Total loss': 0.19619778439483274}
2023-01-05 06:44:44,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:44,491 INFO:     Epoch: 67
2023-01-05 06:44:46,782 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40671006341775257, 'Total loss': 0.40671006341775257} | train loss {'Reaction outcome loss': 0.1981836032687219, 'Total loss': 0.1981836032687219}
2023-01-05 06:44:46,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:46,783 INFO:     Epoch: 68
2023-01-05 06:44:49,034 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44513222575187683, 'Total loss': 0.44513222575187683} | train loss {'Reaction outcome loss': 0.19874088408169924, 'Total loss': 0.19874088408169924}
2023-01-05 06:44:49,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:49,034 INFO:     Epoch: 69
2023-01-05 06:44:51,319 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45909336855014166, 'Total loss': 0.45909336855014166} | train loss {'Reaction outcome loss': 0.19502532878211473, 'Total loss': 0.19502532878211473}
2023-01-05 06:44:51,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:51,320 INFO:     Epoch: 70
2023-01-05 06:44:53,611 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42110060453414916, 'Total loss': 0.42110060453414916} | train loss {'Reaction outcome loss': 0.19758537738493204, 'Total loss': 0.19758537738493204}
2023-01-05 06:44:53,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:53,611 INFO:     Epoch: 71
2023-01-05 06:44:55,898 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42900888323783876, 'Total loss': 0.42900888323783876} | train loss {'Reaction outcome loss': 0.19864151625312354, 'Total loss': 0.19864151625312354}
2023-01-05 06:44:55,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:55,898 INFO:     Epoch: 72
2023-01-05 06:44:58,157 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4463800777991613, 'Total loss': 0.4463800777991613} | train loss {'Reaction outcome loss': 0.1992926077937391, 'Total loss': 0.1992926077937391}
2023-01-05 06:44:58,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:44:58,158 INFO:     Epoch: 73
2023-01-05 06:45:00,440 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44978501548369726, 'Total loss': 0.44978501548369726} | train loss {'Reaction outcome loss': 0.19693481419840658, 'Total loss': 0.19693481419840658}
2023-01-05 06:45:00,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:00,440 INFO:     Epoch: 74
2023-01-05 06:45:02,737 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44364173312981925, 'Total loss': 0.44364173312981925} | train loss {'Reaction outcome loss': 0.19437907751824451, 'Total loss': 0.19437907751824451}
2023-01-05 06:45:02,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:02,737 INFO:     Epoch: 75
2023-01-05 06:45:05,026 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4800629715124766, 'Total loss': 0.4800629715124766} | train loss {'Reaction outcome loss': 0.19002620117328659, 'Total loss': 0.19002620117328659}
2023-01-05 06:45:05,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:05,027 INFO:     Epoch: 76
2023-01-05 06:45:07,322 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43484849532445274, 'Total loss': 0.43484849532445274} | train loss {'Reaction outcome loss': 0.1890604099921129, 'Total loss': 0.1890604099921129}
2023-01-05 06:45:07,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:07,322 INFO:     Epoch: 77
2023-01-05 06:45:09,628 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43654876252015434, 'Total loss': 0.43654876252015434} | train loss {'Reaction outcome loss': 0.18923694180452436, 'Total loss': 0.18923694180452436}
2023-01-05 06:45:09,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:09,629 INFO:     Epoch: 78
2023-01-05 06:45:11,913 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4549508303403854, 'Total loss': 0.4549508303403854} | train loss {'Reaction outcome loss': 0.1903112266138734, 'Total loss': 0.1903112266138734}
2023-01-05 06:45:11,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:11,914 INFO:     Epoch: 79
2023-01-05 06:45:14,188 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47107086330652237, 'Total loss': 0.47107086330652237} | train loss {'Reaction outcome loss': 0.19117064487915283, 'Total loss': 0.19117064487915283}
2023-01-05 06:45:14,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:14,188 INFO:     Epoch: 80
2023-01-05 06:45:16,477 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4507885202765465, 'Total loss': 0.4507885202765465} | train loss {'Reaction outcome loss': 0.1814350472790078, 'Total loss': 0.1814350472790078}
2023-01-05 06:45:16,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:16,477 INFO:     Epoch: 81
2023-01-05 06:45:18,759 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45380042493343353, 'Total loss': 0.45380042493343353} | train loss {'Reaction outcome loss': 0.18598351698530172, 'Total loss': 0.18598351698530172}
2023-01-05 06:45:18,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:18,760 INFO:     Epoch: 82
2023-01-05 06:45:21,061 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43515973488489784, 'Total loss': 0.43515973488489784} | train loss {'Reaction outcome loss': 0.18324606523038786, 'Total loss': 0.18324606523038786}
2023-01-05 06:45:21,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:21,062 INFO:     Epoch: 83
2023-01-05 06:45:23,352 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45696173508961996, 'Total loss': 0.45696173508961996} | train loss {'Reaction outcome loss': 0.18049782280900956, 'Total loss': 0.18049782280900956}
2023-01-05 06:45:23,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:23,353 INFO:     Epoch: 84
2023-01-05 06:45:25,307 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4686355729897817, 'Total loss': 0.4686355729897817} | train loss {'Reaction outcome loss': 0.1810330830359771, 'Total loss': 0.1810330830359771}
2023-01-05 06:45:25,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:25,308 INFO:     Epoch: 85
2023-01-05 06:45:27,169 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4776937107245127, 'Total loss': 0.4776937107245127} | train loss {'Reaction outcome loss': 0.18433640492468104, 'Total loss': 0.18433640492468104}
2023-01-05 06:45:27,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:27,170 INFO:     Epoch: 86
2023-01-05 06:45:29,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4503078947464625, 'Total loss': 0.4503078947464625} | train loss {'Reaction outcome loss': 0.19064431431087991, 'Total loss': 0.19064431431087991}
2023-01-05 06:45:29,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:29,226 INFO:     Epoch: 87
2023-01-05 06:45:31,517 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45588253643363713, 'Total loss': 0.45588253643363713} | train loss {'Reaction outcome loss': 0.1827344742472475, 'Total loss': 0.1827344742472475}
2023-01-05 06:45:31,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:31,517 INFO:     Epoch: 88
2023-01-05 06:45:33,788 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46371739904085796, 'Total loss': 0.46371739904085796} | train loss {'Reaction outcome loss': 0.18205736852788942, 'Total loss': 0.18205736852788942}
2023-01-05 06:45:33,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:33,789 INFO:     Epoch: 89
2023-01-05 06:45:36,072 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4938665191332499, 'Total loss': 0.4938665191332499} | train loss {'Reaction outcome loss': 0.17934125187447034, 'Total loss': 0.17934125187447034}
2023-01-05 06:45:36,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:36,072 INFO:     Epoch: 90
2023-01-05 06:45:38,369 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4604208489259084, 'Total loss': 0.4604208489259084} | train loss {'Reaction outcome loss': 0.1768529188654483, 'Total loss': 0.1768529188654483}
2023-01-05 06:45:38,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:38,370 INFO:     Epoch: 91
2023-01-05 06:45:40,650 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4799603621164958, 'Total loss': 0.4799603621164958} | train loss {'Reaction outcome loss': 0.17532130327606943, 'Total loss': 0.17532130327606943}
2023-01-05 06:45:40,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:40,650 INFO:     Epoch: 92
2023-01-05 06:45:42,931 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49149289429187776, 'Total loss': 0.49149289429187776} | train loss {'Reaction outcome loss': 0.17746488069812852, 'Total loss': 0.17746488069812852}
2023-01-05 06:45:42,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:42,931 INFO:     Epoch: 93
2023-01-05 06:45:45,216 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46253294944763185, 'Total loss': 0.46253294944763185} | train loss {'Reaction outcome loss': 0.17678414029489517, 'Total loss': 0.17678414029489517}
2023-01-05 06:45:45,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:45,216 INFO:     Epoch: 94
2023-01-05 06:45:47,516 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46173444638649624, 'Total loss': 0.46173444638649624} | train loss {'Reaction outcome loss': 0.17488732474052518, 'Total loss': 0.17488732474052518}
2023-01-05 06:45:47,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:47,517 INFO:     Epoch: 95
2023-01-05 06:45:49,813 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45960009296735127, 'Total loss': 0.45960009296735127} | train loss {'Reaction outcome loss': 0.1735912175808734, 'Total loss': 0.1735912175808734}
2023-01-05 06:45:49,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:49,814 INFO:     Epoch: 96
2023-01-05 06:45:52,079 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4858553946018219, 'Total loss': 0.4858553946018219} | train loss {'Reaction outcome loss': 0.17935061250688905, 'Total loss': 0.17935061250688905}
2023-01-05 06:45:52,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:52,079 INFO:     Epoch: 97
2023-01-05 06:45:54,367 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47895046273867287, 'Total loss': 0.47895046273867287} | train loss {'Reaction outcome loss': 0.1783564019854103, 'Total loss': 0.1783564019854103}
2023-01-05 06:45:54,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:54,367 INFO:     Epoch: 98
2023-01-05 06:45:56,621 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46623693803946176, 'Total loss': 0.46623693803946176} | train loss {'Reaction outcome loss': 0.1740610468006333, 'Total loss': 0.1740610468006333}
2023-01-05 06:45:56,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:56,621 INFO:     Epoch: 99
2023-01-05 06:45:58,908 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4571810305118561, 'Total loss': 0.4571810305118561} | train loss {'Reaction outcome loss': 0.1716718967324829, 'Total loss': 0.1716718967324829}
2023-01-05 06:45:58,908 INFO:     Best model found after epoch 15 of 100.
2023-01-05 06:45:58,908 INFO:   Done with stage: TRAINING
2023-01-05 06:45:58,908 INFO:   Starting stage: EVALUATION
2023-01-05 06:45:59,037 INFO:   Done with stage: EVALUATION
2023-01-05 06:45:59,037 INFO:   Leaving out SEQ value Fold_5
2023-01-05 06:45:59,050 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 06:45:59,050 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:45:59,699 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:45:59,700 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:45:59,773 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:45:59,773 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:45:59,773 INFO:     No hyperparam tuning for this model
2023-01-05 06:45:59,773 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:45:59,773 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:45:59,774 INFO:     None feature selector for col prot
2023-01-05 06:45:59,774 INFO:     None feature selector for col prot
2023-01-05 06:45:59,774 INFO:     None feature selector for col prot
2023-01-05 06:45:59,774 INFO:     None feature selector for col chem
2023-01-05 06:45:59,775 INFO:     None feature selector for col chem
2023-01-05 06:45:59,775 INFO:     None feature selector for col chem
2023-01-05 06:45:59,775 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:45:59,775 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:45:59,777 INFO:     Number of params in model 72931
2023-01-05 06:45:59,780 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:45:59,780 INFO:   Starting stage: TRAINING
2023-01-05 06:45:59,840 INFO:     Val loss before train {'Reaction outcome loss': 1.0314980030059815, 'Total loss': 1.0314980030059815}
2023-01-05 06:45:59,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:45:59,840 INFO:     Epoch: 0
2023-01-05 06:46:02,110 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7794340451558431, 'Total loss': 0.7794340451558431} | train loss {'Reaction outcome loss': 0.9084148256883134, 'Total loss': 0.9084148256883134}
2023-01-05 06:46:02,111 INFO:     Found new best model at epoch 0
2023-01-05 06:46:02,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:02,112 INFO:     Epoch: 1
2023-01-05 06:46:04,357 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5569718658924103, 'Total loss': 0.5569718658924103} | train loss {'Reaction outcome loss': 0.608399893463093, 'Total loss': 0.608399893463093}
2023-01-05 06:46:04,358 INFO:     Found new best model at epoch 1
2023-01-05 06:46:04,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:04,360 INFO:     Epoch: 2
2023-01-05 06:46:06,629 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.505961561203003, 'Total loss': 0.505961561203003} | train loss {'Reaction outcome loss': 0.5300140037153759, 'Total loss': 0.5300140037153759}
2023-01-05 06:46:06,630 INFO:     Found new best model at epoch 2
2023-01-05 06:46:06,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:06,631 INFO:     Epoch: 3
2023-01-05 06:46:08,874 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49055249243974686, 'Total loss': 0.49055249243974686} | train loss {'Reaction outcome loss': 0.48683493502818753, 'Total loss': 0.48683493502818753}
2023-01-05 06:46:08,874 INFO:     Found new best model at epoch 3
2023-01-05 06:46:08,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:08,875 INFO:     Epoch: 4
2023-01-05 06:46:11,155 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4756870607535044, 'Total loss': 0.4756870607535044} | train loss {'Reaction outcome loss': 0.459006868873852, 'Total loss': 0.459006868873852}
2023-01-05 06:46:11,155 INFO:     Found new best model at epoch 4
2023-01-05 06:46:11,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:11,157 INFO:     Epoch: 5
2023-01-05 06:46:13,438 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4526275893052419, 'Total loss': 0.4526275893052419} | train loss {'Reaction outcome loss': 0.42811960270152477, 'Total loss': 0.42811960270152477}
2023-01-05 06:46:13,438 INFO:     Found new best model at epoch 5
2023-01-05 06:46:13,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:13,440 INFO:     Epoch: 6
2023-01-05 06:46:15,686 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47224018573760984, 'Total loss': 0.47224018573760984} | train loss {'Reaction outcome loss': 0.4120726210139964, 'Total loss': 0.4120726210139964}
2023-01-05 06:46:15,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:15,687 INFO:     Epoch: 7
2023-01-05 06:46:17,951 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4334403932094574, 'Total loss': 0.4334403932094574} | train loss {'Reaction outcome loss': 0.391121197546268, 'Total loss': 0.391121197546268}
2023-01-05 06:46:17,951 INFO:     Found new best model at epoch 7
2023-01-05 06:46:17,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:17,952 INFO:     Epoch: 8
2023-01-05 06:46:20,155 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4329491506020228, 'Total loss': 0.4329491506020228} | train loss {'Reaction outcome loss': 0.3820156691609508, 'Total loss': 0.3820156691609508}
2023-01-05 06:46:20,156 INFO:     Found new best model at epoch 8
2023-01-05 06:46:20,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:20,157 INFO:     Epoch: 9
2023-01-05 06:46:22,413 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41427280803521477, 'Total loss': 0.41427280803521477} | train loss {'Reaction outcome loss': 0.3717072613156625, 'Total loss': 0.3717072613156625}
2023-01-05 06:46:22,414 INFO:     Found new best model at epoch 9
2023-01-05 06:46:22,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:22,415 INFO:     Epoch: 10
2023-01-05 06:46:24,661 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.423016365369161, 'Total loss': 0.423016365369161} | train loss {'Reaction outcome loss': 0.3585561267270224, 'Total loss': 0.3585561267270224}
2023-01-05 06:46:24,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:24,662 INFO:     Epoch: 11
2023-01-05 06:46:26,905 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41315489212671913, 'Total loss': 0.41315489212671913} | train loss {'Reaction outcome loss': 0.34806587765958624, 'Total loss': 0.34806587765958624}
2023-01-05 06:46:26,905 INFO:     Found new best model at epoch 11
2023-01-05 06:46:26,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:26,907 INFO:     Epoch: 12
2023-01-05 06:46:29,086 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4290202935536703, 'Total loss': 0.4290202935536703} | train loss {'Reaction outcome loss': 0.34126788598016233, 'Total loss': 0.34126788598016233}
2023-01-05 06:46:29,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:29,086 INFO:     Epoch: 13
2023-01-05 06:46:31,301 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42419735292593636, 'Total loss': 0.42419735292593636} | train loss {'Reaction outcome loss': 0.331067739231308, 'Total loss': 0.331067739231308}
2023-01-05 06:46:31,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:31,301 INFO:     Epoch: 14
2023-01-05 06:46:33,549 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42541679938634236, 'Total loss': 0.42541679938634236} | train loss {'Reaction outcome loss': 0.32286694670354366, 'Total loss': 0.32286694670354366}
2023-01-05 06:46:33,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:33,551 INFO:     Epoch: 15
2023-01-05 06:46:35,809 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40372770677010217, 'Total loss': 0.40372770677010217} | train loss {'Reaction outcome loss': 0.320370335852469, 'Total loss': 0.320370335852469}
2023-01-05 06:46:35,809 INFO:     Found new best model at epoch 15
2023-01-05 06:46:35,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:35,810 INFO:     Epoch: 16
2023-01-05 06:46:38,068 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3926618958512942, 'Total loss': 0.3926618958512942} | train loss {'Reaction outcome loss': 0.3070338498393114, 'Total loss': 0.3070338498393114}
2023-01-05 06:46:38,069 INFO:     Found new best model at epoch 16
2023-01-05 06:46:38,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:38,070 INFO:     Epoch: 17
2023-01-05 06:46:40,333 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40480107565720874, 'Total loss': 0.40480107565720874} | train loss {'Reaction outcome loss': 0.306159340796897, 'Total loss': 0.306159340796897}
2023-01-05 06:46:40,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:40,334 INFO:     Epoch: 18
2023-01-05 06:46:42,584 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41619164794683455, 'Total loss': 0.41619164794683455} | train loss {'Reaction outcome loss': 0.30031539962021975, 'Total loss': 0.30031539962021975}
2023-01-05 06:46:42,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:42,584 INFO:     Epoch: 19
2023-01-05 06:46:44,838 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41003684252500533, 'Total loss': 0.41003684252500533} | train loss {'Reaction outcome loss': 0.2901741821237289, 'Total loss': 0.2901741821237289}
2023-01-05 06:46:44,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:44,838 INFO:     Epoch: 20
2023-01-05 06:46:47,074 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4361658682425817, 'Total loss': 0.4361658682425817} | train loss {'Reaction outcome loss': 0.2866311920262928, 'Total loss': 0.2866311920262928}
2023-01-05 06:46:47,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:47,075 INFO:     Epoch: 21
2023-01-05 06:46:49,353 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4165917148192724, 'Total loss': 0.4165917148192724} | train loss {'Reaction outcome loss': 0.2792884552728956, 'Total loss': 0.2792884552728956}
2023-01-05 06:46:49,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:49,353 INFO:     Epoch: 22
2023-01-05 06:46:51,607 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.411211030681928, 'Total loss': 0.411211030681928} | train loss {'Reaction outcome loss': 0.27682214945445965, 'Total loss': 0.27682214945445965}
2023-01-05 06:46:51,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:51,607 INFO:     Epoch: 23
2023-01-05 06:46:53,884 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41913971106211345, 'Total loss': 0.41913971106211345} | train loss {'Reaction outcome loss': 0.2638158758653559, 'Total loss': 0.2638158758653559}
2023-01-05 06:46:53,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:53,885 INFO:     Epoch: 24
2023-01-05 06:46:56,147 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3949991057316462, 'Total loss': 0.3949991057316462} | train loss {'Reaction outcome loss': 0.2619883016730747, 'Total loss': 0.2619883016730747}
2023-01-05 06:46:56,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:56,147 INFO:     Epoch: 25
2023-01-05 06:46:58,427 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39421654840310416, 'Total loss': 0.39421654840310416} | train loss {'Reaction outcome loss': 0.2624724744921074, 'Total loss': 0.2624724744921074}
2023-01-05 06:46:58,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:46:58,428 INFO:     Epoch: 26
2023-01-05 06:47:00,698 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3823480889201164, 'Total loss': 0.3823480889201164} | train loss {'Reaction outcome loss': 0.25804966900252946, 'Total loss': 0.25804966900252946}
2023-01-05 06:47:00,698 INFO:     Found new best model at epoch 26
2023-01-05 06:47:00,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:00,700 INFO:     Epoch: 27
2023-01-05 06:47:02,952 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40790884097417196, 'Total loss': 0.40790884097417196} | train loss {'Reaction outcome loss': 0.24596823100680418, 'Total loss': 0.24596823100680418}
2023-01-05 06:47:02,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:02,952 INFO:     Epoch: 28
2023-01-05 06:47:05,058 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3936741917083661, 'Total loss': 0.3936741917083661} | train loss {'Reaction outcome loss': 0.24045496879920472, 'Total loss': 0.24045496879920472}
2023-01-05 06:47:05,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:05,058 INFO:     Epoch: 29
2023-01-05 06:47:07,317 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3925669565796852, 'Total loss': 0.3925669565796852} | train loss {'Reaction outcome loss': 0.24089273116993207, 'Total loss': 0.24089273116993207}
2023-01-05 06:47:07,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:07,317 INFO:     Epoch: 30
2023-01-05 06:47:09,591 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41690048078695935, 'Total loss': 0.41690048078695935} | train loss {'Reaction outcome loss': 0.23593153412977275, 'Total loss': 0.23593153412977275}
2023-01-05 06:47:09,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:09,592 INFO:     Epoch: 31
2023-01-05 06:47:11,849 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4082654853661855, 'Total loss': 0.4082654853661855} | train loss {'Reaction outcome loss': 0.23486636572918534, 'Total loss': 0.23486636572918534}
2023-01-05 06:47:11,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:11,850 INFO:     Epoch: 32
2023-01-05 06:47:14,075 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4375611491501331, 'Total loss': 0.4375611491501331} | train loss {'Reaction outcome loss': 0.2284392531906819, 'Total loss': 0.2284392531906819}
2023-01-05 06:47:14,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:14,075 INFO:     Epoch: 33
2023-01-05 06:47:16,359 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4398159255584081, 'Total loss': 0.4398159255584081} | train loss {'Reaction outcome loss': 0.22448808362666708, 'Total loss': 0.22448808362666708}
2023-01-05 06:47:16,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:16,360 INFO:     Epoch: 34
2023-01-05 06:47:18,634 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45078213612238566, 'Total loss': 0.45078213612238566} | train loss {'Reaction outcome loss': 0.2257797797856322, 'Total loss': 0.2257797797856322}
2023-01-05 06:47:18,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:18,635 INFO:     Epoch: 35
2023-01-05 06:47:20,854 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41358649233977, 'Total loss': 0.41358649233977} | train loss {'Reaction outcome loss': 0.22174955070032365, 'Total loss': 0.22174955070032365}
2023-01-05 06:47:20,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:20,854 INFO:     Epoch: 36
2023-01-05 06:47:23,100 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4479166646798452, 'Total loss': 0.4479166646798452} | train loss {'Reaction outcome loss': 0.22244930286368314, 'Total loss': 0.22244930286368314}
2023-01-05 06:47:23,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:23,101 INFO:     Epoch: 37
2023-01-05 06:47:25,313 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42710879147052766, 'Total loss': 0.42710879147052766} | train loss {'Reaction outcome loss': 0.21736600247966328, 'Total loss': 0.21736600247966328}
2023-01-05 06:47:25,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:25,313 INFO:     Epoch: 38
2023-01-05 06:47:27,526 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.500939957300822, 'Total loss': 0.500939957300822} | train loss {'Reaction outcome loss': 0.21949752643160578, 'Total loss': 0.21949752643160578}
2023-01-05 06:47:27,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:27,527 INFO:     Epoch: 39
2023-01-05 06:47:29,736 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43360593120257057, 'Total loss': 0.43360593120257057} | train loss {'Reaction outcome loss': 0.2107748830126748, 'Total loss': 0.2107748830126748}
2023-01-05 06:47:29,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:29,737 INFO:     Epoch: 40
2023-01-05 06:47:32,000 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44839944740136467, 'Total loss': 0.44839944740136467} | train loss {'Reaction outcome loss': 0.2089004299236312, 'Total loss': 0.2089004299236312}
2023-01-05 06:47:32,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:32,001 INFO:     Epoch: 41
2023-01-05 06:47:34,321 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4477556417385737, 'Total loss': 0.4477556417385737} | train loss {'Reaction outcome loss': 0.20625650195445674, 'Total loss': 0.20625650195445674}
2023-01-05 06:47:34,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:34,322 INFO:     Epoch: 42
2023-01-05 06:47:36,631 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4195909341176351, 'Total loss': 0.4195909341176351} | train loss {'Reaction outcome loss': 0.20182695375401935, 'Total loss': 0.20182695375401935}
2023-01-05 06:47:36,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:36,631 INFO:     Epoch: 43
2023-01-05 06:47:38,859 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45145132889350253, 'Total loss': 0.45145132889350253} | train loss {'Reaction outcome loss': 0.20555728117520683, 'Total loss': 0.20555728117520683}
2023-01-05 06:47:38,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:38,860 INFO:     Epoch: 44
2023-01-05 06:47:41,098 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43289161324501035, 'Total loss': 0.43289161324501035} | train loss {'Reaction outcome loss': 0.20129068471137843, 'Total loss': 0.20129068471137843}
2023-01-05 06:47:41,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:41,098 INFO:     Epoch: 45
2023-01-05 06:47:43,360 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4460474801560243, 'Total loss': 0.4460474801560243} | train loss {'Reaction outcome loss': 0.20314117541101617, 'Total loss': 0.20314117541101617}
2023-01-05 06:47:43,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:43,360 INFO:     Epoch: 46
2023-01-05 06:47:45,618 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42597882548967997, 'Total loss': 0.42597882548967997} | train loss {'Reaction outcome loss': 0.19683030461484607, 'Total loss': 0.19683030461484607}
2023-01-05 06:47:45,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:45,619 INFO:     Epoch: 47
2023-01-05 06:47:47,821 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4344470024108887, 'Total loss': 0.4344470024108887} | train loss {'Reaction outcome loss': 0.1943548302528156, 'Total loss': 0.1943548302528156}
2023-01-05 06:47:47,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:47,822 INFO:     Epoch: 48
2023-01-05 06:47:50,043 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4406706859668096, 'Total loss': 0.4406706859668096} | train loss {'Reaction outcome loss': 0.19899026618889756, 'Total loss': 0.19899026618889756}
2023-01-05 06:47:50,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:50,043 INFO:     Epoch: 49
2023-01-05 06:47:52,295 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4221506337324778, 'Total loss': 0.4221506337324778} | train loss {'Reaction outcome loss': 0.19842158651224126, 'Total loss': 0.19842158651224126}
2023-01-05 06:47:52,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:52,296 INFO:     Epoch: 50
2023-01-05 06:47:54,533 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.441232564051946, 'Total loss': 0.441232564051946} | train loss {'Reaction outcome loss': 0.18999390947346978, 'Total loss': 0.18999390947346978}
2023-01-05 06:47:54,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:54,533 INFO:     Epoch: 51
2023-01-05 06:47:56,797 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43087358673413595, 'Total loss': 0.43087358673413595} | train loss {'Reaction outcome loss': 0.19149541122036695, 'Total loss': 0.19149541122036695}
2023-01-05 06:47:56,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:56,798 INFO:     Epoch: 52
2023-01-05 06:47:59,072 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45584126114845275, 'Total loss': 0.45584126114845275} | train loss {'Reaction outcome loss': 0.1944399811667356, 'Total loss': 0.1944399811667356}
2023-01-05 06:47:59,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:47:59,072 INFO:     Epoch: 53
2023-01-05 06:48:01,329 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.459959888458252, 'Total loss': 0.459959888458252} | train loss {'Reaction outcome loss': 0.18714870221192276, 'Total loss': 0.18714870221192276}
2023-01-05 06:48:01,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:01,329 INFO:     Epoch: 54
2023-01-05 06:48:03,569 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5146163721879323, 'Total loss': 0.5146163721879323} | train loss {'Reaction outcome loss': 0.18516467984113164, 'Total loss': 0.18516467984113164}
2023-01-05 06:48:03,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:03,569 INFO:     Epoch: 55
2023-01-05 06:48:05,849 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43887612521648406, 'Total loss': 0.43887612521648406} | train loss {'Reaction outcome loss': 0.18929486001848522, 'Total loss': 0.18929486001848522}
2023-01-05 06:48:05,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:05,850 INFO:     Epoch: 56
2023-01-05 06:48:08,125 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5110338181257248, 'Total loss': 0.5110338181257248} | train loss {'Reaction outcome loss': 0.18321226071736293, 'Total loss': 0.18321226071736293}
2023-01-05 06:48:08,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:08,125 INFO:     Epoch: 57
2023-01-05 06:48:10,397 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45575874894857404, 'Total loss': 0.45575874894857404} | train loss {'Reaction outcome loss': 0.1837109047851532, 'Total loss': 0.1837109047851532}
2023-01-05 06:48:10,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:10,397 INFO:     Epoch: 58
2023-01-05 06:48:12,629 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4666323075691859, 'Total loss': 0.4666323075691859} | train loss {'Reaction outcome loss': 0.18308464583199824, 'Total loss': 0.18308464583199824}
2023-01-05 06:48:12,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:12,629 INFO:     Epoch: 59
2023-01-05 06:48:14,892 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47651437322298684, 'Total loss': 0.47651437322298684} | train loss {'Reaction outcome loss': 0.18827725015920552, 'Total loss': 0.18827725015920552}
2023-01-05 06:48:14,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:14,893 INFO:     Epoch: 60
2023-01-05 06:48:17,119 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5062806804974874, 'Total loss': 0.5062806804974874} | train loss {'Reaction outcome loss': 0.18269950418943798, 'Total loss': 0.18269950418943798}
2023-01-05 06:48:17,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:17,119 INFO:     Epoch: 61
2023-01-05 06:48:19,381 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45048593984295926, 'Total loss': 0.45048593984295926} | train loss {'Reaction outcome loss': 0.17888880333774826, 'Total loss': 0.17888880333774826}
2023-01-05 06:48:19,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:19,382 INFO:     Epoch: 62
2023-01-05 06:48:21,648 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45516284306844074, 'Total loss': 0.45516284306844074} | train loss {'Reaction outcome loss': 0.17941503415570806, 'Total loss': 0.17941503415570806}
2023-01-05 06:48:21,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:21,649 INFO:     Epoch: 63
2023-01-05 06:48:23,900 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4616919279098511, 'Total loss': 0.4616919279098511} | train loss {'Reaction outcome loss': 0.17714469790132376, 'Total loss': 0.17714469790132376}
2023-01-05 06:48:23,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:23,900 INFO:     Epoch: 64
2023-01-05 06:48:26,141 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4629882703224818, 'Total loss': 0.4629882703224818} | train loss {'Reaction outcome loss': 0.1761751035092412, 'Total loss': 0.1761751035092412}
2023-01-05 06:48:26,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:26,142 INFO:     Epoch: 65
2023-01-05 06:48:28,161 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5002770185470581, 'Total loss': 0.5002770185470581} | train loss {'Reaction outcome loss': 0.1748935500853253, 'Total loss': 0.1748935500853253}
2023-01-05 06:48:28,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:28,162 INFO:     Epoch: 66
2023-01-05 06:48:30,029 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49346551078682144, 'Total loss': 0.49346551078682144} | train loss {'Reaction outcome loss': 0.17427319711002853, 'Total loss': 0.17427319711002853}
2023-01-05 06:48:30,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:30,029 INFO:     Epoch: 67
2023-01-05 06:48:32,032 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49243946373462677, 'Total loss': 0.49243946373462677} | train loss {'Reaction outcome loss': 0.17400134474814047, 'Total loss': 0.17400134474814047}
2023-01-05 06:48:32,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:32,032 INFO:     Epoch: 68
2023-01-05 06:48:34,275 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4949799507856369, 'Total loss': 0.4949799507856369} | train loss {'Reaction outcome loss': 0.17472224603203146, 'Total loss': 0.17472224603203146}
2023-01-05 06:48:34,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:34,275 INFO:     Epoch: 69
2023-01-05 06:48:36,522 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4631459847092628, 'Total loss': 0.4631459847092628} | train loss {'Reaction outcome loss': 0.17434865002347033, 'Total loss': 0.17434865002347033}
2023-01-05 06:48:36,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:36,522 INFO:     Epoch: 70
2023-01-05 06:48:38,768 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45074732999006906, 'Total loss': 0.45074732999006906} | train loss {'Reaction outcome loss': 0.17837870281604357, 'Total loss': 0.17837870281604357}
2023-01-05 06:48:38,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:38,768 INFO:     Epoch: 71
2023-01-05 06:48:41,015 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44782287180423735, 'Total loss': 0.44782287180423735} | train loss {'Reaction outcome loss': 0.16987424977565604, 'Total loss': 0.16987424977565604}
2023-01-05 06:48:41,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:41,016 INFO:     Epoch: 72
2023-01-05 06:48:43,257 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43017336453000704, 'Total loss': 0.43017336453000704} | train loss {'Reaction outcome loss': 0.16816405777183843, 'Total loss': 0.16816405777183843}
2023-01-05 06:48:43,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:43,257 INFO:     Epoch: 73
2023-01-05 06:48:45,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4683941269914309, 'Total loss': 0.4683941269914309} | train loss {'Reaction outcome loss': 0.17235601895291658, 'Total loss': 0.17235601895291658}
2023-01-05 06:48:45,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:45,495 INFO:     Epoch: 74
2023-01-05 06:48:47,721 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47466893792152404, 'Total loss': 0.47466893792152404} | train loss {'Reaction outcome loss': 0.170611504621695, 'Total loss': 0.170611504621695}
2023-01-05 06:48:47,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:47,722 INFO:     Epoch: 75
2023-01-05 06:48:49,996 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.496574687709411, 'Total loss': 0.496574687709411} | train loss {'Reaction outcome loss': 0.16467255742261935, 'Total loss': 0.16467255742261935}
2023-01-05 06:48:49,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:49,996 INFO:     Epoch: 76
2023-01-05 06:48:52,268 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43359685291846595, 'Total loss': 0.43359685291846595} | train loss {'Reaction outcome loss': 0.1663286886789775, 'Total loss': 0.1663286886789775}
2023-01-05 06:48:52,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:52,268 INFO:     Epoch: 77
2023-01-05 06:48:54,542 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47390731871128083, 'Total loss': 0.47390731871128083} | train loss {'Reaction outcome loss': 0.15970071255871823, 'Total loss': 0.15970071255871823}
2023-01-05 06:48:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:54,542 INFO:     Epoch: 78
2023-01-05 06:48:56,790 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45735949178536733, 'Total loss': 0.45735949178536733} | train loss {'Reaction outcome loss': 0.17370316763170554, 'Total loss': 0.17370316763170554}
2023-01-05 06:48:56,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:56,791 INFO:     Epoch: 79
2023-01-05 06:48:59,032 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4578527311484019, 'Total loss': 0.4578527311484019} | train loss {'Reaction outcome loss': 0.16447610282984965, 'Total loss': 0.16447610282984965}
2023-01-05 06:48:59,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:48:59,032 INFO:     Epoch: 80
2023-01-05 06:49:01,308 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47243046363194785, 'Total loss': 0.47243046363194785} | train loss {'Reaction outcome loss': 0.1654026856540573, 'Total loss': 0.1654026856540573}
2023-01-05 06:49:01,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:01,309 INFO:     Epoch: 81
2023-01-05 06:49:03,586 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.50966224471728, 'Total loss': 0.50966224471728} | train loss {'Reaction outcome loss': 0.16375768940936583, 'Total loss': 0.16375768940936583}
2023-01-05 06:49:03,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:03,587 INFO:     Epoch: 82
2023-01-05 06:49:05,879 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4863873809576035, 'Total loss': 0.4863873809576035} | train loss {'Reaction outcome loss': 0.16082751133859866, 'Total loss': 0.16082751133859866}
2023-01-05 06:49:05,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:05,880 INFO:     Epoch: 83
2023-01-05 06:49:08,139 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4688092629114787, 'Total loss': 0.4688092629114787} | train loss {'Reaction outcome loss': 0.1610785831772063, 'Total loss': 0.1610785831772063}
2023-01-05 06:49:08,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:08,140 INFO:     Epoch: 84
2023-01-05 06:49:10,414 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48474272241195043, 'Total loss': 0.48474272241195043} | train loss {'Reaction outcome loss': 0.16320856785517268, 'Total loss': 0.16320856785517268}
2023-01-05 06:49:10,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:10,415 INFO:     Epoch: 85
2023-01-05 06:49:12,703 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4698292925953865, 'Total loss': 0.4698292925953865} | train loss {'Reaction outcome loss': 0.15938235321727984, 'Total loss': 0.15938235321727984}
2023-01-05 06:49:12,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:12,703 INFO:     Epoch: 86
2023-01-05 06:49:14,969 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4632029742002487, 'Total loss': 0.4632029742002487} | train loss {'Reaction outcome loss': 0.15549440492440803, 'Total loss': 0.15549440492440803}
2023-01-05 06:49:14,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:14,970 INFO:     Epoch: 87
2023-01-05 06:49:17,249 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49677981038888297, 'Total loss': 0.49677981038888297} | train loss {'Reaction outcome loss': 0.15818999668270567, 'Total loss': 0.15818999668270567}
2023-01-05 06:49:17,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:17,249 INFO:     Epoch: 88
2023-01-05 06:49:19,515 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4650071689238151, 'Total loss': 0.4650071689238151} | train loss {'Reaction outcome loss': 0.16066119617809724, 'Total loss': 0.16066119617809724}
2023-01-05 06:49:19,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:19,515 INFO:     Epoch: 89
2023-01-05 06:49:21,770 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5312221427758534, 'Total loss': 0.5312221427758534} | train loss {'Reaction outcome loss': 0.16100564323039385, 'Total loss': 0.16100564323039385}
2023-01-05 06:49:21,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:21,771 INFO:     Epoch: 90
2023-01-05 06:49:24,050 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4929286872347196, 'Total loss': 0.4929286872347196} | train loss {'Reaction outcome loss': 0.1619732315723451, 'Total loss': 0.1619732315723451}
2023-01-05 06:49:24,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:24,051 INFO:     Epoch: 91
2023-01-05 06:49:26,325 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4582370370005568, 'Total loss': 0.4582370370005568} | train loss {'Reaction outcome loss': 0.15772293116829364, 'Total loss': 0.15772293116829364}
2023-01-05 06:49:26,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:26,325 INFO:     Epoch: 92
2023-01-05 06:49:28,599 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4784675826629003, 'Total loss': 0.4784675826629003} | train loss {'Reaction outcome loss': 0.15292774791570965, 'Total loss': 0.15292774791570965}
2023-01-05 06:49:28,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:28,599 INFO:     Epoch: 93
2023-01-05 06:49:30,842 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49690682590007784, 'Total loss': 0.49690682590007784} | train loss {'Reaction outcome loss': 0.1594979818740411, 'Total loss': 0.1594979818740411}
2023-01-05 06:49:30,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:30,842 INFO:     Epoch: 94
2023-01-05 06:49:33,098 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5095420201619466, 'Total loss': 0.5095420201619466} | train loss {'Reaction outcome loss': 0.16102537222335755, 'Total loss': 0.16102537222335755}
2023-01-05 06:49:33,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:33,099 INFO:     Epoch: 95
2023-01-05 06:49:35,342 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5339980692913134, 'Total loss': 0.5339980692913134} | train loss {'Reaction outcome loss': 0.15644622401735425, 'Total loss': 0.15644622401735425}
2023-01-05 06:49:35,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:35,342 INFO:     Epoch: 96
2023-01-05 06:49:37,601 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4985475172599157, 'Total loss': 0.4985475172599157} | train loss {'Reaction outcome loss': 0.1569905780616087, 'Total loss': 0.1569905780616087}
2023-01-05 06:49:37,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:37,602 INFO:     Epoch: 97
2023-01-05 06:49:39,869 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47093876705039295, 'Total loss': 0.47093876705039295} | train loss {'Reaction outcome loss': 0.1497898120450087, 'Total loss': 0.1497898120450087}
2023-01-05 06:49:39,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:39,870 INFO:     Epoch: 98
2023-01-05 06:49:42,121 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45501223150640724, 'Total loss': 0.45501223150640724} | train loss {'Reaction outcome loss': 0.15547638002402372, 'Total loss': 0.15547638002402372}
2023-01-05 06:49:42,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:42,121 INFO:     Epoch: 99
2023-01-05 06:49:44,387 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48415993750095365, 'Total loss': 0.48415993750095365} | train loss {'Reaction outcome loss': 0.15549345849163448, 'Total loss': 0.15549345849163448}
2023-01-05 06:49:44,387 INFO:     Best model found after epoch 27 of 100.
2023-01-05 06:49:44,387 INFO:   Done with stage: TRAINING
2023-01-05 06:49:44,387 INFO:   Starting stage: EVALUATION
2023-01-05 06:49:44,530 INFO:   Done with stage: EVALUATION
2023-01-05 06:49:44,530 INFO:   Leaving out SEQ value Fold_6
2023-01-05 06:49:44,543 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:49:44,543 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:49:45,193 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:49:45,193 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:49:45,268 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:49:45,268 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:49:45,268 INFO:     No hyperparam tuning for this model
2023-01-05 06:49:45,268 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:49:45,268 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:49:45,269 INFO:     None feature selector for col prot
2023-01-05 06:49:45,269 INFO:     None feature selector for col prot
2023-01-05 06:49:45,269 INFO:     None feature selector for col prot
2023-01-05 06:49:45,270 INFO:     None feature selector for col chem
2023-01-05 06:49:45,270 INFO:     None feature selector for col chem
2023-01-05 06:49:45,270 INFO:     None feature selector for col chem
2023-01-05 06:49:45,270 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:49:45,270 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:49:45,272 INFO:     Number of params in model 72931
2023-01-05 06:49:45,275 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:49:45,275 INFO:   Starting stage: TRAINING
2023-01-05 06:49:45,335 INFO:     Val loss before train {'Reaction outcome loss': 1.0189768592516582, 'Total loss': 1.0189768592516582}
2023-01-05 06:49:45,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:45,336 INFO:     Epoch: 0
2023-01-05 06:49:47,607 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7618493656317393, 'Total loss': 0.7618493656317393} | train loss {'Reaction outcome loss': 0.937080863042859, 'Total loss': 0.937080863042859}
2023-01-05 06:49:47,607 INFO:     Found new best model at epoch 0
2023-01-05 06:49:47,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:47,608 INFO:     Epoch: 1
2023-01-05 06:49:49,888 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5304188112417857, 'Total loss': 0.5304188112417857} | train loss {'Reaction outcome loss': 0.6291013576278618, 'Total loss': 0.6291013576278618}
2023-01-05 06:49:49,888 INFO:     Found new best model at epoch 1
2023-01-05 06:49:49,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:49,890 INFO:     Epoch: 2
2023-01-05 06:49:52,174 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4645020087560018, 'Total loss': 0.4645020087560018} | train loss {'Reaction outcome loss': 0.5325797029673408, 'Total loss': 0.5325797029673408}
2023-01-05 06:49:52,175 INFO:     Found new best model at epoch 2
2023-01-05 06:49:52,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:52,176 INFO:     Epoch: 3
2023-01-05 06:49:54,440 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.445649324854215, 'Total loss': 0.445649324854215} | train loss {'Reaction outcome loss': 0.49211910393909425, 'Total loss': 0.49211910393909425}
2023-01-05 06:49:54,440 INFO:     Found new best model at epoch 3
2023-01-05 06:49:54,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:54,441 INFO:     Epoch: 4
2023-01-05 06:49:56,726 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4284268240133921, 'Total loss': 0.4284268240133921} | train loss {'Reaction outcome loss': 0.4632595475184788, 'Total loss': 0.4632595475184788}
2023-01-05 06:49:56,726 INFO:     Found new best model at epoch 4
2023-01-05 06:49:56,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:56,727 INFO:     Epoch: 5
2023-01-05 06:49:58,981 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4204122761885325, 'Total loss': 0.4204122761885325} | train loss {'Reaction outcome loss': 0.4359896239229488, 'Total loss': 0.4359896239229488}
2023-01-05 06:49:58,981 INFO:     Found new best model at epoch 5
2023-01-05 06:49:58,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:49:58,983 INFO:     Epoch: 6
2023-01-05 06:50:01,235 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.400355808933576, 'Total loss': 0.400355808933576} | train loss {'Reaction outcome loss': 0.4164877628053569, 'Total loss': 0.4164877628053569}
2023-01-05 06:50:01,235 INFO:     Found new best model at epoch 6
2023-01-05 06:50:01,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:01,237 INFO:     Epoch: 7
2023-01-05 06:50:03,473 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40009713371594746, 'Total loss': 0.40009713371594746} | train loss {'Reaction outcome loss': 0.40236669676613723, 'Total loss': 0.40236669676613723}
2023-01-05 06:50:03,473 INFO:     Found new best model at epoch 7
2023-01-05 06:50:03,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:03,475 INFO:     Epoch: 8
2023-01-05 06:50:05,713 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41493207812309263, 'Total loss': 0.41493207812309263} | train loss {'Reaction outcome loss': 0.3884856429502422, 'Total loss': 0.3884856429502422}
2023-01-05 06:50:05,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:05,713 INFO:     Epoch: 9
2023-01-05 06:50:07,986 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3960943380991618, 'Total loss': 0.3960943380991618} | train loss {'Reaction outcome loss': 0.37204885576929, 'Total loss': 0.37204885576929}
2023-01-05 06:50:07,986 INFO:     Found new best model at epoch 9
2023-01-05 06:50:07,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:07,987 INFO:     Epoch: 10
2023-01-05 06:50:10,210 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3767310281594594, 'Total loss': 0.3767310281594594} | train loss {'Reaction outcome loss': 0.36245782955781647, 'Total loss': 0.36245782955781647}
2023-01-05 06:50:10,211 INFO:     Found new best model at epoch 10
2023-01-05 06:50:10,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:10,213 INFO:     Epoch: 11
2023-01-05 06:50:12,467 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3943933814764023, 'Total loss': 0.3943933814764023} | train loss {'Reaction outcome loss': 0.3514172098858262, 'Total loss': 0.3514172098858262}
2023-01-05 06:50:12,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:12,467 INFO:     Epoch: 12
2023-01-05 06:50:14,726 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39642730752627053, 'Total loss': 0.39642730752627053} | train loss {'Reaction outcome loss': 0.342614873490609, 'Total loss': 0.342614873490609}
2023-01-05 06:50:14,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:14,726 INFO:     Epoch: 13
2023-01-05 06:50:16,963 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39030500253041583, 'Total loss': 0.39030500253041583} | train loss {'Reaction outcome loss': 0.3360747788168678, 'Total loss': 0.3360747788168678}
2023-01-05 06:50:16,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:16,964 INFO:     Epoch: 14
2023-01-05 06:50:19,225 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38955611884593966, 'Total loss': 0.38955611884593966} | train loss {'Reaction outcome loss': 0.3266610756032303, 'Total loss': 0.3266610756032303}
2023-01-05 06:50:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:19,225 INFO:     Epoch: 15
2023-01-05 06:50:21,491 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3975891520579656, 'Total loss': 0.3975891520579656} | train loss {'Reaction outcome loss': 0.32179256457337835, 'Total loss': 0.32179256457337835}
2023-01-05 06:50:21,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:21,491 INFO:     Epoch: 16
2023-01-05 06:50:23,782 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39267450471719106, 'Total loss': 0.39267450471719106} | train loss {'Reaction outcome loss': 0.3137551349611274, 'Total loss': 0.3137551349611274}
2023-01-05 06:50:23,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:23,782 INFO:     Epoch: 17
2023-01-05 06:50:26,066 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41779419084390007, 'Total loss': 0.41779419084390007} | train loss {'Reaction outcome loss': 0.3124981390359384, 'Total loss': 0.3124981390359384}
2023-01-05 06:50:26,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:26,067 INFO:     Epoch: 18
2023-01-05 06:50:28,329 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3883614977200826, 'Total loss': 0.3883614977200826} | train loss {'Reaction outcome loss': 0.3100036998222236, 'Total loss': 0.3100036998222236}
2023-01-05 06:50:28,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:28,330 INFO:     Epoch: 19
2023-01-05 06:50:30,606 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3905740668376287, 'Total loss': 0.3905740668376287} | train loss {'Reaction outcome loss': 0.2992926209976742, 'Total loss': 0.2992926209976742}
2023-01-05 06:50:30,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:30,606 INFO:     Epoch: 20
2023-01-05 06:50:32,859 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3718783140182495, 'Total loss': 0.3718783140182495} | train loss {'Reaction outcome loss': 0.29583588140320694, 'Total loss': 0.29583588140320694}
2023-01-05 06:50:32,859 INFO:     Found new best model at epoch 20
2023-01-05 06:50:32,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:32,861 INFO:     Epoch: 21
2023-01-05 06:50:35,132 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4001918017864227, 'Total loss': 0.4001918017864227} | train loss {'Reaction outcome loss': 0.29106473735792543, 'Total loss': 0.29106473735792543}
2023-01-05 06:50:35,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:35,132 INFO:     Epoch: 22
2023-01-05 06:50:37,414 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3869568238655726, 'Total loss': 0.3869568238655726} | train loss {'Reaction outcome loss': 0.29004555555995193, 'Total loss': 0.29004555555995193}
2023-01-05 06:50:37,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:37,415 INFO:     Epoch: 23
2023-01-05 06:50:39,645 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3583476126194, 'Total loss': 0.3583476126194} | train loss {'Reaction outcome loss': 0.2819586516717711, 'Total loss': 0.2819586516717711}
2023-01-05 06:50:39,646 INFO:     Found new best model at epoch 23
2023-01-05 06:50:39,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:39,647 INFO:     Epoch: 24
2023-01-05 06:50:41,914 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36887381970882416, 'Total loss': 0.36887381970882416} | train loss {'Reaction outcome loss': 0.27982076296468505, 'Total loss': 0.27982076296468505}
2023-01-05 06:50:41,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:41,914 INFO:     Epoch: 25
2023-01-05 06:50:44,153 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35959984560807545, 'Total loss': 0.35959984560807545} | train loss {'Reaction outcome loss': 0.27859924901075095, 'Total loss': 0.27859924901075095}
2023-01-05 06:50:44,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:44,153 INFO:     Epoch: 26
2023-01-05 06:50:46,442 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37508888890345893, 'Total loss': 0.37508888890345893} | train loss {'Reaction outcome loss': 0.26953269131750623, 'Total loss': 0.26953269131750623}
2023-01-05 06:50:46,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:46,443 INFO:     Epoch: 27
2023-01-05 06:50:48,732 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.375623964269956, 'Total loss': 0.375623964269956} | train loss {'Reaction outcome loss': 0.26906649616382183, 'Total loss': 0.26906649616382183}
2023-01-05 06:50:48,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:48,733 INFO:     Epoch: 28
2023-01-05 06:50:51,035 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3747010091940562, 'Total loss': 0.3747010091940562} | train loss {'Reaction outcome loss': 0.2641968158164502, 'Total loss': 0.2641968158164502}
2023-01-05 06:50:51,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:51,035 INFO:     Epoch: 29
2023-01-05 06:50:53,309 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37135879397392274, 'Total loss': 0.37135879397392274} | train loss {'Reaction outcome loss': 0.2636774830614294, 'Total loss': 0.2636774830614294}
2023-01-05 06:50:53,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:53,309 INFO:     Epoch: 30
2023-01-05 06:50:55,590 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36432317992051444, 'Total loss': 0.36432317992051444} | train loss {'Reaction outcome loss': 0.25879388145214816, 'Total loss': 0.25879388145214816}
2023-01-05 06:50:55,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:55,590 INFO:     Epoch: 31
2023-01-05 06:50:57,835 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37574855585892997, 'Total loss': 0.37574855585892997} | train loss {'Reaction outcome loss': 0.2517016356346947, 'Total loss': 0.2517016356346947}
2023-01-05 06:50:57,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:50:57,836 INFO:     Epoch: 32
2023-01-05 06:51:00,093 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.375619771083196, 'Total loss': 0.375619771083196} | train loss {'Reaction outcome loss': 0.2530841005273459, 'Total loss': 0.2530841005273459}
2023-01-05 06:51:00,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:00,094 INFO:     Epoch: 33
2023-01-05 06:51:02,330 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3436172982056936, 'Total loss': 0.3436172982056936} | train loss {'Reaction outcome loss': 0.25170288405075186, 'Total loss': 0.25170288405075186}
2023-01-05 06:51:02,330 INFO:     Found new best model at epoch 33
2023-01-05 06:51:02,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:02,332 INFO:     Epoch: 34
2023-01-05 06:51:04,620 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3700389434893926, 'Total loss': 0.3700389434893926} | train loss {'Reaction outcome loss': 0.2450382905719728, 'Total loss': 0.2450382905719728}
2023-01-05 06:51:04,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:04,621 INFO:     Epoch: 35
2023-01-05 06:51:06,893 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3652621378501256, 'Total loss': 0.3652621378501256} | train loss {'Reaction outcome loss': 0.24639724176847763, 'Total loss': 0.24639724176847763}
2023-01-05 06:51:06,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:06,893 INFO:     Epoch: 36
2023-01-05 06:51:09,138 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40292688459157944, 'Total loss': 0.40292688459157944} | train loss {'Reaction outcome loss': 0.23982147083009192, 'Total loss': 0.23982147083009192}
2023-01-05 06:51:09,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:09,139 INFO:     Epoch: 37
2023-01-05 06:51:11,415 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3618581155935923, 'Total loss': 0.3618581155935923} | train loss {'Reaction outcome loss': 0.24243945442812537, 'Total loss': 0.24243945442812537}
2023-01-05 06:51:11,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:11,416 INFO:     Epoch: 38
2023-01-05 06:51:13,691 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.374654550353686, 'Total loss': 0.374654550353686} | train loss {'Reaction outcome loss': 0.23821562995952605, 'Total loss': 0.23821562995952605}
2023-01-05 06:51:13,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:13,692 INFO:     Epoch: 39
2023-01-05 06:51:15,777 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36882715274890265, 'Total loss': 0.36882715274890265} | train loss {'Reaction outcome loss': 0.23628375753894826, 'Total loss': 0.23628375753894826}
2023-01-05 06:51:15,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:15,778 INFO:     Epoch: 40
2023-01-05 06:51:18,057 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40966627399126687, 'Total loss': 0.40966627399126687} | train loss {'Reaction outcome loss': 0.23182324056483347, 'Total loss': 0.23182324056483347}
2023-01-05 06:51:18,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:18,057 INFO:     Epoch: 41
2023-01-05 06:51:20,323 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3813534955183665, 'Total loss': 0.3813534955183665} | train loss {'Reaction outcome loss': 0.2275886152121188, 'Total loss': 0.2275886152121188}
2023-01-05 06:51:20,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:20,324 INFO:     Epoch: 42
2023-01-05 06:51:22,680 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37616064846515657, 'Total loss': 0.37616064846515657} | train loss {'Reaction outcome loss': 0.22929790694710364, 'Total loss': 0.22929790694710364}
2023-01-05 06:51:22,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:22,681 INFO:     Epoch: 43
2023-01-05 06:51:24,981 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4214002937078476, 'Total loss': 0.4214002937078476} | train loss {'Reaction outcome loss': 0.22741276081584205, 'Total loss': 0.22741276081584205}
2023-01-05 06:51:24,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:24,981 INFO:     Epoch: 44
2023-01-05 06:51:27,253 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3674330006043116, 'Total loss': 0.3674330006043116} | train loss {'Reaction outcome loss': 0.22156139543206038, 'Total loss': 0.22156139543206038}
2023-01-05 06:51:27,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:27,254 INFO:     Epoch: 45
2023-01-05 06:51:29,551 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42283477981885276, 'Total loss': 0.42283477981885276} | train loss {'Reaction outcome loss': 0.21775024621209485, 'Total loss': 0.21775024621209485}
2023-01-05 06:51:29,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:29,551 INFO:     Epoch: 46
2023-01-05 06:51:31,811 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37009676496187843, 'Total loss': 0.37009676496187843} | train loss {'Reaction outcome loss': 0.21245533909769695, 'Total loss': 0.21245533909769695}
2023-01-05 06:51:31,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:31,811 INFO:     Epoch: 47
2023-01-05 06:51:34,092 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38710264563560487, 'Total loss': 0.38710264563560487} | train loss {'Reaction outcome loss': 0.2180592967634382, 'Total loss': 0.2180592967634382}
2023-01-05 06:51:34,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:34,092 INFO:     Epoch: 48
2023-01-05 06:51:36,375 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3969708502292633, 'Total loss': 0.3969708502292633} | train loss {'Reaction outcome loss': 0.2136336574885685, 'Total loss': 0.2136336574885685}
2023-01-05 06:51:36,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:36,375 INFO:     Epoch: 49
2023-01-05 06:51:38,649 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39082506448030474, 'Total loss': 0.39082506448030474} | train loss {'Reaction outcome loss': 0.21666810805119224, 'Total loss': 0.21666810805119224}
2023-01-05 06:51:38,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:38,650 INFO:     Epoch: 50
2023-01-05 06:51:40,912 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3911758283774058, 'Total loss': 0.3911758283774058} | train loss {'Reaction outcome loss': 0.21059980402643447, 'Total loss': 0.21059980402643447}
2023-01-05 06:51:40,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:40,912 INFO:     Epoch: 51
2023-01-05 06:51:43,213 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40588569020231563, 'Total loss': 0.40588569020231563} | train loss {'Reaction outcome loss': 0.21134697796023763, 'Total loss': 0.21134697796023763}
2023-01-05 06:51:43,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:43,213 INFO:     Epoch: 52
2023-01-05 06:51:45,512 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4025561143954595, 'Total loss': 0.4025561143954595} | train loss {'Reaction outcome loss': 0.21049886732782483, 'Total loss': 0.21049886732782483}
2023-01-05 06:51:45,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:45,512 INFO:     Epoch: 53
2023-01-05 06:51:47,816 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3869332015514374, 'Total loss': 0.3869332015514374} | train loss {'Reaction outcome loss': 0.20629150306449578, 'Total loss': 0.20629150306449578}
2023-01-05 06:51:47,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:47,816 INFO:     Epoch: 54
2023-01-05 06:51:50,104 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40717790921529134, 'Total loss': 0.40717790921529134} | train loss {'Reaction outcome loss': 0.21163675697379164, 'Total loss': 0.21163675697379164}
2023-01-05 06:51:50,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:50,104 INFO:     Epoch: 55
2023-01-05 06:51:52,417 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4063497051596642, 'Total loss': 0.4063497051596642} | train loss {'Reaction outcome loss': 0.20218520385922614, 'Total loss': 0.20218520385922614}
2023-01-05 06:51:52,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:52,418 INFO:     Epoch: 56
2023-01-05 06:51:54,692 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38673269351323447, 'Total loss': 0.38673269351323447} | train loss {'Reaction outcome loss': 0.20219121263816361, 'Total loss': 0.20219121263816361}
2023-01-05 06:51:54,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:54,692 INFO:     Epoch: 57
2023-01-05 06:51:56,977 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42031860252221426, 'Total loss': 0.42031860252221426} | train loss {'Reaction outcome loss': 0.19821118513065045, 'Total loss': 0.19821118513065045}
2023-01-05 06:51:56,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:56,977 INFO:     Epoch: 58
2023-01-05 06:51:59,277 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42759185234705605, 'Total loss': 0.42759185234705605} | train loss {'Reaction outcome loss': 0.19985237257010455, 'Total loss': 0.19985237257010455}
2023-01-05 06:51:59,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:51:59,278 INFO:     Epoch: 59
2023-01-05 06:52:01,546 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44535864889621735, 'Total loss': 0.44535864889621735} | train loss {'Reaction outcome loss': 0.19885577048622205, 'Total loss': 0.19885577048622205}
2023-01-05 06:52:01,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:01,546 INFO:     Epoch: 60
2023-01-05 06:52:03,804 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39835114975770314, 'Total loss': 0.39835114975770314} | train loss {'Reaction outcome loss': 0.19719858064117846, 'Total loss': 0.19719858064117846}
2023-01-05 06:52:03,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:03,805 INFO:     Epoch: 61
2023-01-05 06:52:06,094 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4140540967384974, 'Total loss': 0.4140540967384974} | train loss {'Reaction outcome loss': 0.1976565282677539, 'Total loss': 0.1976565282677539}
2023-01-05 06:52:06,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:06,094 INFO:     Epoch: 62
2023-01-05 06:52:08,361 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4387873709201813, 'Total loss': 0.4387873709201813} | train loss {'Reaction outcome loss': 0.19623828226942502, 'Total loss': 0.19623828226942502}
2023-01-05 06:52:08,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:08,361 INFO:     Epoch: 63
2023-01-05 06:52:10,639 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.409615632891655, 'Total loss': 0.409615632891655} | train loss {'Reaction outcome loss': 0.19409888383969395, 'Total loss': 0.19409888383969395}
2023-01-05 06:52:10,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:10,640 INFO:     Epoch: 64
2023-01-05 06:52:12,876 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4319911651313305, 'Total loss': 0.4319911651313305} | train loss {'Reaction outcome loss': 0.19402346489043226, 'Total loss': 0.19402346489043226}
2023-01-05 06:52:12,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:12,877 INFO:     Epoch: 65
2023-01-05 06:52:15,161 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4048825909694036, 'Total loss': 0.4048825909694036} | train loss {'Reaction outcome loss': 0.19567035259981555, 'Total loss': 0.19567035259981555}
2023-01-05 06:52:15,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:15,161 INFO:     Epoch: 66
2023-01-05 06:52:17,450 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3979432245095571, 'Total loss': 0.3979432245095571} | train loss {'Reaction outcome loss': 0.1858018175009571, 'Total loss': 0.1858018175009571}
2023-01-05 06:52:17,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:17,451 INFO:     Epoch: 67
2023-01-05 06:52:19,722 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4032608777284622, 'Total loss': 0.4032608777284622} | train loss {'Reaction outcome loss': 0.19054402504452514, 'Total loss': 0.19054402504452514}
2023-01-05 06:52:19,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:19,723 INFO:     Epoch: 68
2023-01-05 06:52:22,001 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43910582462946574, 'Total loss': 0.43910582462946574} | train loss {'Reaction outcome loss': 0.18880494973800457, 'Total loss': 0.18880494973800457}
2023-01-05 06:52:22,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:22,001 INFO:     Epoch: 69
2023-01-05 06:52:24,290 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4642154475053151, 'Total loss': 0.4642154475053151} | train loss {'Reaction outcome loss': 0.187972582449686, 'Total loss': 0.187972582449686}
2023-01-05 06:52:24,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:24,290 INFO:     Epoch: 70
2023-01-05 06:52:26,598 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40289203623930614, 'Total loss': 0.40289203623930614} | train loss {'Reaction outcome loss': 0.18989318163077, 'Total loss': 0.18989318163077}
2023-01-05 06:52:26,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:26,598 INFO:     Epoch: 71
2023-01-05 06:52:28,825 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43493218421936036, 'Total loss': 0.43493218421936036} | train loss {'Reaction outcome loss': 0.1828805982935434, 'Total loss': 0.1828805982935434}
2023-01-05 06:52:28,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:28,826 INFO:     Epoch: 72
2023-01-05 06:52:31,128 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4241689493258794, 'Total loss': 0.4241689493258794} | train loss {'Reaction outcome loss': 0.188219443286369, 'Total loss': 0.188219443286369}
2023-01-05 06:52:31,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:31,129 INFO:     Epoch: 73
2023-01-05 06:52:33,447 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44416354993979135, 'Total loss': 0.44416354993979135} | train loss {'Reaction outcome loss': 0.1820279989132678, 'Total loss': 0.1820279989132678}
2023-01-05 06:52:33,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:33,447 INFO:     Epoch: 74
2023-01-05 06:52:35,745 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47702302436033883, 'Total loss': 0.47702302436033883} | train loss {'Reaction outcome loss': 0.18171424166188452, 'Total loss': 0.18171424166188452}
2023-01-05 06:52:35,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:35,747 INFO:     Epoch: 75
2023-01-05 06:52:38,066 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43425122102101643, 'Total loss': 0.43425122102101643} | train loss {'Reaction outcome loss': 0.1801827869105694, 'Total loss': 0.1801827869105694}
2023-01-05 06:52:38,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:38,066 INFO:     Epoch: 76
2023-01-05 06:52:40,403 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44889217416445415, 'Total loss': 0.44889217416445415} | train loss {'Reaction outcome loss': 0.1823775597515143, 'Total loss': 0.1823775597515143}
2023-01-05 06:52:40,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:40,403 INFO:     Epoch: 77
2023-01-05 06:52:42,729 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43503187894821166, 'Total loss': 0.43503187894821166} | train loss {'Reaction outcome loss': 0.18061579421283644, 'Total loss': 0.18061579421283644}
2023-01-05 06:52:42,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:42,729 INFO:     Epoch: 78
2023-01-05 06:52:45,050 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41779295603434247, 'Total loss': 0.41779295603434247} | train loss {'Reaction outcome loss': 0.18020975482330695, 'Total loss': 0.18020975482330695}
2023-01-05 06:52:45,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:45,050 INFO:     Epoch: 79
2023-01-05 06:52:47,353 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42098338703314464, 'Total loss': 0.42098338703314464} | train loss {'Reaction outcome loss': 0.1789249891233681, 'Total loss': 0.1789249891233681}
2023-01-05 06:52:47,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:47,354 INFO:     Epoch: 80
2023-01-05 06:52:49,648 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4291888227065404, 'Total loss': 0.4291888227065404} | train loss {'Reaction outcome loss': 0.1730365577046272, 'Total loss': 0.1730365577046272}
2023-01-05 06:52:49,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:49,649 INFO:     Epoch: 81
2023-01-05 06:52:51,947 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4493668794631958, 'Total loss': 0.4493668794631958} | train loss {'Reaction outcome loss': 0.17622749849528557, 'Total loss': 0.17622749849528557}
2023-01-05 06:52:51,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:51,948 INFO:     Epoch: 82
2023-01-05 06:52:54,182 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4519119928280512, 'Total loss': 0.4519119928280512} | train loss {'Reaction outcome loss': 0.17639883402197046, 'Total loss': 0.17639883402197046}
2023-01-05 06:52:54,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:54,183 INFO:     Epoch: 83
2023-01-05 06:52:56,465 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45770692924658457, 'Total loss': 0.45770692924658457} | train loss {'Reaction outcome loss': 0.17411399510309153, 'Total loss': 0.17411399510309153}
2023-01-05 06:52:56,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:56,465 INFO:     Epoch: 84
2023-01-05 06:52:58,693 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4950528601805369, 'Total loss': 0.4950528601805369} | train loss {'Reaction outcome loss': 0.1752210867318866, 'Total loss': 0.1752210867318866}
2023-01-05 06:52:58,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:52:58,694 INFO:     Epoch: 85
2023-01-05 06:53:00,968 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4595085153977076, 'Total loss': 0.4595085153977076} | train loss {'Reaction outcome loss': 0.1732051602542898, 'Total loss': 0.1732051602542898}
2023-01-05 06:53:00,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:00,969 INFO:     Epoch: 86
2023-01-05 06:53:03,249 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44675076405207315, 'Total loss': 0.44675076405207315} | train loss {'Reaction outcome loss': 0.17687355306012967, 'Total loss': 0.17687355306012967}
2023-01-05 06:53:03,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:03,250 INFO:     Epoch: 87
2023-01-05 06:53:05,515 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43737419148286183, 'Total loss': 0.43737419148286183} | train loss {'Reaction outcome loss': 0.17275719802880438, 'Total loss': 0.17275719802880438}
2023-01-05 06:53:05,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:05,516 INFO:     Epoch: 88
2023-01-05 06:53:07,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4245311886072159, 'Total loss': 0.4245311886072159} | train loss {'Reaction outcome loss': 0.17494488430347307, 'Total loss': 0.17494488430347307}
2023-01-05 06:53:07,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:07,794 INFO:     Epoch: 89
2023-01-05 06:53:10,066 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4218611419200897, 'Total loss': 0.4218611419200897} | train loss {'Reaction outcome loss': 0.16998593758670646, 'Total loss': 0.16998593758670646}
2023-01-05 06:53:10,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:10,066 INFO:     Epoch: 90
2023-01-05 06:53:12,366 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40777159531911217, 'Total loss': 0.40777159531911217} | train loss {'Reaction outcome loss': 0.17056938630969193, 'Total loss': 0.17056938630969193}
2023-01-05 06:53:12,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:12,366 INFO:     Epoch: 91
2023-01-05 06:53:14,653 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4563178529342016, 'Total loss': 0.4563178529342016} | train loss {'Reaction outcome loss': 0.1705097710942372, 'Total loss': 0.1705097710942372}
2023-01-05 06:53:14,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:14,653 INFO:     Epoch: 92
2023-01-05 06:53:16,951 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.437515918413798, 'Total loss': 0.437515918413798} | train loss {'Reaction outcome loss': 0.1660800485464909, 'Total loss': 0.1660800485464909}
2023-01-05 06:53:16,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:16,952 INFO:     Epoch: 93
2023-01-05 06:53:19,232 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41530978083610537, 'Total loss': 0.41530978083610537} | train loss {'Reaction outcome loss': 0.17223660926761555, 'Total loss': 0.17223660926761555}
2023-01-05 06:53:19,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:19,232 INFO:     Epoch: 94
2023-01-05 06:53:21,497 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4303651024897893, 'Total loss': 0.4303651024897893} | train loss {'Reaction outcome loss': 0.16449808178045905, 'Total loss': 0.16449808178045905}
2023-01-05 06:53:21,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:21,498 INFO:     Epoch: 95
2023-01-05 06:53:23,776 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45006906390190127, 'Total loss': 0.45006906390190127} | train loss {'Reaction outcome loss': 0.16407721657104227, 'Total loss': 0.16407721657104227}
2023-01-05 06:53:23,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:23,777 INFO:     Epoch: 96
2023-01-05 06:53:26,058 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44394269287586213, 'Total loss': 0.44394269287586213} | train loss {'Reaction outcome loss': 0.16969146330030602, 'Total loss': 0.16969146330030602}
2023-01-05 06:53:26,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:26,059 INFO:     Epoch: 97
2023-01-05 06:53:28,330 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4870759919285774, 'Total loss': 0.4870759919285774} | train loss {'Reaction outcome loss': 0.16573600808077824, 'Total loss': 0.16573600808077824}
2023-01-05 06:53:28,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:28,330 INFO:     Epoch: 98
2023-01-05 06:53:30,597 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47675718168417613, 'Total loss': 0.47675718168417613} | train loss {'Reaction outcome loss': 0.17163580958647418, 'Total loss': 0.17163580958647418}
2023-01-05 06:53:30,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:30,598 INFO:     Epoch: 99
2023-01-05 06:53:32,874 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4609175463517507, 'Total loss': 0.4609175463517507} | train loss {'Reaction outcome loss': 0.16415119851142546, 'Total loss': 0.16415119851142546}
2023-01-05 06:53:32,874 INFO:     Best model found after epoch 34 of 100.
2023-01-05 06:53:32,875 INFO:   Done with stage: TRAINING
2023-01-05 06:53:32,875 INFO:   Starting stage: EVALUATION
2023-01-05 06:53:33,002 INFO:   Done with stage: EVALUATION
2023-01-05 06:53:33,002 INFO:   Leaving out SEQ value Fold_7
2023-01-05 06:53:33,015 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 06:53:33,015 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:53:33,674 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:53:33,675 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:53:33,749 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:53:33,749 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:53:33,749 INFO:     No hyperparam tuning for this model
2023-01-05 06:53:33,749 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:53:33,749 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:53:33,750 INFO:     None feature selector for col prot
2023-01-05 06:53:33,750 INFO:     None feature selector for col prot
2023-01-05 06:53:33,750 INFO:     None feature selector for col prot
2023-01-05 06:53:33,751 INFO:     None feature selector for col chem
2023-01-05 06:53:33,751 INFO:     None feature selector for col chem
2023-01-05 06:53:33,751 INFO:     None feature selector for col chem
2023-01-05 06:53:33,751 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:53:33,751 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:53:33,753 INFO:     Number of params in model 72931
2023-01-05 06:53:33,756 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:53:33,756 INFO:   Starting stage: TRAINING
2023-01-05 06:53:33,815 INFO:     Val loss before train {'Reaction outcome loss': 1.0160510659217834, 'Total loss': 1.0160510659217834}
2023-01-05 06:53:33,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:33,815 INFO:     Epoch: 0
2023-01-05 06:53:36,085 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7818634808063507, 'Total loss': 0.7818634808063507} | train loss {'Reaction outcome loss': 0.9575645368452107, 'Total loss': 0.9575645368452107}
2023-01-05 06:53:36,086 INFO:     Found new best model at epoch 0
2023-01-05 06:53:36,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:36,087 INFO:     Epoch: 1
2023-01-05 06:53:38,347 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5468173305193583, 'Total loss': 0.5468173305193583} | train loss {'Reaction outcome loss': 0.634994909651443, 'Total loss': 0.634994909651443}
2023-01-05 06:53:38,347 INFO:     Found new best model at epoch 1
2023-01-05 06:53:38,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:38,348 INFO:     Epoch: 2
2023-01-05 06:53:40,596 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5118616263071696, 'Total loss': 0.5118616263071696} | train loss {'Reaction outcome loss': 0.5405066183327768, 'Total loss': 0.5405066183327768}
2023-01-05 06:53:40,597 INFO:     Found new best model at epoch 2
2023-01-05 06:53:40,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:40,598 INFO:     Epoch: 3
2023-01-05 06:53:42,866 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47519236505031587, 'Total loss': 0.47519236505031587} | train loss {'Reaction outcome loss': 0.5061258080311201, 'Total loss': 0.5061258080311201}
2023-01-05 06:53:42,866 INFO:     Found new best model at epoch 3
2023-01-05 06:53:42,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:42,868 INFO:     Epoch: 4
2023-01-05 06:53:45,128 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48694029251734416, 'Total loss': 0.48694029251734416} | train loss {'Reaction outcome loss': 0.4763191926565411, 'Total loss': 0.4763191926565411}
2023-01-05 06:53:45,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:45,129 INFO:     Epoch: 5
2023-01-05 06:53:47,323 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47359897096951803, 'Total loss': 0.47359897096951803} | train loss {'Reaction outcome loss': 0.4608419541040913, 'Total loss': 0.4608419541040913}
2023-01-05 06:53:47,323 INFO:     Found new best model at epoch 5
2023-01-05 06:53:47,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:47,325 INFO:     Epoch: 6
2023-01-05 06:53:49,545 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49715932210286456, 'Total loss': 0.49715932210286456} | train loss {'Reaction outcome loss': 0.44266246157002365, 'Total loss': 0.44266246157002365}
2023-01-05 06:53:49,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:49,545 INFO:     Epoch: 7
2023-01-05 06:53:51,802 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4773707866668701, 'Total loss': 0.4773707866668701} | train loss {'Reaction outcome loss': 0.4313750421150927, 'Total loss': 0.4313750421150927}
2023-01-05 06:53:51,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:51,802 INFO:     Epoch: 8
2023-01-05 06:53:54,063 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44467482368151345, 'Total loss': 0.44467482368151345} | train loss {'Reaction outcome loss': 0.41826468033695907, 'Total loss': 0.41826468033695907}
2023-01-05 06:53:54,064 INFO:     Found new best model at epoch 8
2023-01-05 06:53:54,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:54,065 INFO:     Epoch: 9
2023-01-05 06:53:56,318 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46251395146052043, 'Total loss': 0.46251395146052043} | train loss {'Reaction outcome loss': 0.40776136167858484, 'Total loss': 0.40776136167858484}
2023-01-05 06:53:56,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:56,318 INFO:     Epoch: 10
2023-01-05 06:53:58,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43774588306744894, 'Total loss': 0.43774588306744894} | train loss {'Reaction outcome loss': 0.3947198415975278, 'Total loss': 0.3947198415975278}
2023-01-05 06:53:58,603 INFO:     Found new best model at epoch 10
2023-01-05 06:53:58,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:53:58,605 INFO:     Epoch: 11
2023-01-05 06:54:00,886 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4729505330324173, 'Total loss': 0.4729505330324173} | train loss {'Reaction outcome loss': 0.38462427713057623, 'Total loss': 0.38462427713057623}
2023-01-05 06:54:00,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:00,886 INFO:     Epoch: 12
2023-01-05 06:54:03,159 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.458663405974706, 'Total loss': 0.458663405974706} | train loss {'Reaction outcome loss': 0.3750020626273396, 'Total loss': 0.3750020626273396}
2023-01-05 06:54:03,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:03,159 INFO:     Epoch: 13
2023-01-05 06:54:05,424 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4710580120484034, 'Total loss': 0.4710580120484034} | train loss {'Reaction outcome loss': 0.3660187754067273, 'Total loss': 0.3660187754067273}
2023-01-05 06:54:05,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:05,426 INFO:     Epoch: 14
2023-01-05 06:54:07,647 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4445927719275157, 'Total loss': 0.4445927719275157} | train loss {'Reaction outcome loss': 0.35968277070819255, 'Total loss': 0.35968277070819255}
2023-01-05 06:54:07,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:07,647 INFO:     Epoch: 15
2023-01-05 06:54:09,905 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45313799182573955, 'Total loss': 0.45313799182573955} | train loss {'Reaction outcome loss': 0.3496230501506733, 'Total loss': 0.3496230501506733}
2023-01-05 06:54:09,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:09,905 INFO:     Epoch: 16
2023-01-05 06:54:12,178 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4393599490324656, 'Total loss': 0.4393599490324656} | train loss {'Reaction outcome loss': 0.3417897933979757, 'Total loss': 0.3417897933979757}
2023-01-05 06:54:12,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:12,179 INFO:     Epoch: 17
2023-01-05 06:54:14,461 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45924558540185295, 'Total loss': 0.45924558540185295} | train loss {'Reaction outcome loss': 0.33740789287249534, 'Total loss': 0.33740789287249534}
2023-01-05 06:54:14,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:14,462 INFO:     Epoch: 18
2023-01-05 06:54:16,723 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44068243304888405, 'Total loss': 0.44068243304888405} | train loss {'Reaction outcome loss': 0.33010813271095607, 'Total loss': 0.33010813271095607}
2023-01-05 06:54:16,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:16,723 INFO:     Epoch: 19
2023-01-05 06:54:18,990 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4494036187728246, 'Total loss': 0.4494036187728246} | train loss {'Reaction outcome loss': 0.31973630051374, 'Total loss': 0.31973630051374}
2023-01-05 06:54:18,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:18,990 INFO:     Epoch: 20
2023-01-05 06:54:21,251 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4220301866531372, 'Total loss': 0.4220301866531372} | train loss {'Reaction outcome loss': 0.31760996962067023, 'Total loss': 0.31760996962067023}
2023-01-05 06:54:21,252 INFO:     Found new best model at epoch 20
2023-01-05 06:54:21,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:21,253 INFO:     Epoch: 21
2023-01-05 06:54:23,534 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45136480828126274, 'Total loss': 0.45136480828126274} | train loss {'Reaction outcome loss': 0.3094293838534975, 'Total loss': 0.3094293838534975}
2023-01-05 06:54:23,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:23,534 INFO:     Epoch: 22
2023-01-05 06:54:25,830 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43878156344095864, 'Total loss': 0.43878156344095864} | train loss {'Reaction outcome loss': 0.30162989208306645, 'Total loss': 0.30162989208306645}
2023-01-05 06:54:25,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:25,831 INFO:     Epoch: 23
2023-01-05 06:54:28,105 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4375029106934865, 'Total loss': 0.4375029106934865} | train loss {'Reaction outcome loss': 0.29817410393043114, 'Total loss': 0.29817410393043114}
2023-01-05 06:54:28,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:28,105 INFO:     Epoch: 24
2023-01-05 06:54:30,394 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4429688463608424, 'Total loss': 0.4429688463608424} | train loss {'Reaction outcome loss': 0.29481714942395043, 'Total loss': 0.29481714942395043}
2023-01-05 06:54:30,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:30,394 INFO:     Epoch: 25
2023-01-05 06:54:32,592 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41306592027346295, 'Total loss': 0.41306592027346295} | train loss {'Reaction outcome loss': 0.28782068862704163, 'Total loss': 0.28782068862704163}
2023-01-05 06:54:32,592 INFO:     Found new best model at epoch 25
2023-01-05 06:54:32,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:32,593 INFO:     Epoch: 26
2023-01-05 06:54:34,867 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45996422370274864, 'Total loss': 0.45996422370274864} | train loss {'Reaction outcome loss': 0.2852302506861919, 'Total loss': 0.2852302506861919}
2023-01-05 06:54:34,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:34,868 INFO:     Epoch: 27
2023-01-05 06:54:37,118 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.451167893409729, 'Total loss': 0.451167893409729} | train loss {'Reaction outcome loss': 0.28175353659619495, 'Total loss': 0.28175353659619495}
2023-01-05 06:54:37,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:37,118 INFO:     Epoch: 28
2023-01-05 06:54:39,399 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4358599573373795, 'Total loss': 0.4358599573373795} | train loss {'Reaction outcome loss': 0.26990301788713955, 'Total loss': 0.26990301788713955}
2023-01-05 06:54:39,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:39,399 INFO:     Epoch: 29
2023-01-05 06:54:41,691 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46401097575823463, 'Total loss': 0.46401097575823463} | train loss {'Reaction outcome loss': 0.27315542402438525, 'Total loss': 0.27315542402438525}
2023-01-05 06:54:41,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:41,692 INFO:     Epoch: 30
2023-01-05 06:54:43,951 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45260771016279855, 'Total loss': 0.45260771016279855} | train loss {'Reaction outcome loss': 0.26479154561616025, 'Total loss': 0.26479154561616025}
2023-01-05 06:54:43,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:43,951 INFO:     Epoch: 31
2023-01-05 06:54:46,235 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4702855666478475, 'Total loss': 0.4702855666478475} | train loss {'Reaction outcome loss': 0.2634391821920872, 'Total loss': 0.2634391821920872}
2023-01-05 06:54:46,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:46,235 INFO:     Epoch: 32
2023-01-05 06:54:48,516 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4465298225482305, 'Total loss': 0.4465298225482305} | train loss {'Reaction outcome loss': 0.2585849858928028, 'Total loss': 0.2585849858928028}
2023-01-05 06:54:48,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:48,517 INFO:     Epoch: 33
2023-01-05 06:54:50,741 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4613190174102783, 'Total loss': 0.4613190174102783} | train loss {'Reaction outcome loss': 0.2581656727711216, 'Total loss': 0.2581656727711216}
2023-01-05 06:54:50,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:50,742 INFO:     Epoch: 34
2023-01-05 06:54:53,020 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45516417324543, 'Total loss': 0.45516417324543} | train loss {'Reaction outcome loss': 0.25241446080163715, 'Total loss': 0.25241446080163715}
2023-01-05 06:54:53,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:53,021 INFO:     Epoch: 35
2023-01-05 06:54:55,271 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4403089741865794, 'Total loss': 0.4403089741865794} | train loss {'Reaction outcome loss': 0.24802543011087158, 'Total loss': 0.24802543011087158}
2023-01-05 06:54:55,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:55,271 INFO:     Epoch: 36
2023-01-05 06:54:57,495 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4497316579023997, 'Total loss': 0.4497316579023997} | train loss {'Reaction outcome loss': 0.24480319935626718, 'Total loss': 0.24480319935626718}
2023-01-05 06:54:57,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:57,496 INFO:     Epoch: 37
2023-01-05 06:54:59,733 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.446379683415095, 'Total loss': 0.446379683415095} | train loss {'Reaction outcome loss': 0.24036569944465203, 'Total loss': 0.24036569944465203}
2023-01-05 06:54:59,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:54:59,733 INFO:     Epoch: 38
2023-01-05 06:55:01,950 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45718437284231184, 'Total loss': 0.45718437284231184} | train loss {'Reaction outcome loss': 0.23476289571784034, 'Total loss': 0.23476289571784034}
2023-01-05 06:55:01,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:01,951 INFO:     Epoch: 39
2023-01-05 06:55:04,204 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4715284725030263, 'Total loss': 0.4715284725030263} | train loss {'Reaction outcome loss': 0.23656380915550335, 'Total loss': 0.23656380915550335}
2023-01-05 06:55:04,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:04,204 INFO:     Epoch: 40
2023-01-05 06:55:06,445 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46902623077233635, 'Total loss': 0.46902623077233635} | train loss {'Reaction outcome loss': 0.23646052112123703, 'Total loss': 0.23646052112123703}
2023-01-05 06:55:06,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:06,445 INFO:     Epoch: 41
2023-01-05 06:55:08,637 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45528876086076103, 'Total loss': 0.45528876086076103} | train loss {'Reaction outcome loss': 0.2319487175914301, 'Total loss': 0.2319487175914301}
2023-01-05 06:55:08,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:08,638 INFO:     Epoch: 42
2023-01-05 06:55:10,890 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46947602927684784, 'Total loss': 0.46947602927684784} | train loss {'Reaction outcome loss': 0.23016332069055484, 'Total loss': 0.23016332069055484}
2023-01-05 06:55:10,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:10,892 INFO:     Epoch: 43
2023-01-05 06:55:13,154 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4902669529120127, 'Total loss': 0.4902669529120127} | train loss {'Reaction outcome loss': 0.22569362935021736, 'Total loss': 0.22569362935021736}
2023-01-05 06:55:13,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:13,155 INFO:     Epoch: 44
2023-01-05 06:55:15,349 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44531177083651224, 'Total loss': 0.44531177083651224} | train loss {'Reaction outcome loss': 0.22014873444240554, 'Total loss': 0.22014873444240554}
2023-01-05 06:55:15,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:15,349 INFO:     Epoch: 45
2023-01-05 06:55:17,545 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47336865266164146, 'Total loss': 0.47336865266164146} | train loss {'Reaction outcome loss': 0.22510638939963135, 'Total loss': 0.22510638939963135}
2023-01-05 06:55:17,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:17,546 INFO:     Epoch: 46
2023-01-05 06:55:19,790 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4541721150279045, 'Total loss': 0.4541721150279045} | train loss {'Reaction outcome loss': 0.22090663370888156, 'Total loss': 0.22090663370888156}
2023-01-05 06:55:19,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:19,790 INFO:     Epoch: 47
2023-01-05 06:55:22,036 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46027503808339437, 'Total loss': 0.46027503808339437} | train loss {'Reaction outcome loss': 0.21614929657792573, 'Total loss': 0.21614929657792573}
2023-01-05 06:55:22,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:22,036 INFO:     Epoch: 48
2023-01-05 06:55:24,172 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46587195694446565, 'Total loss': 0.46587195694446565} | train loss {'Reaction outcome loss': 0.21820241799880666, 'Total loss': 0.21820241799880666}
2023-01-05 06:55:24,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:24,172 INFO:     Epoch: 49
2023-01-05 06:55:26,285 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4933783054351807, 'Total loss': 0.4933783054351807} | train loss {'Reaction outcome loss': 0.21407837528291593, 'Total loss': 0.21407837528291593}
2023-01-05 06:55:26,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:26,286 INFO:     Epoch: 50
2023-01-05 06:55:28,578 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4756290609637896, 'Total loss': 0.4756290609637896} | train loss {'Reaction outcome loss': 0.21270193816885513, 'Total loss': 0.21270193816885513}
2023-01-05 06:55:28,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:28,578 INFO:     Epoch: 51
2023-01-05 06:55:30,808 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46431346982717514, 'Total loss': 0.46431346982717514} | train loss {'Reaction outcome loss': 0.2114369527500674, 'Total loss': 0.2114369527500674}
2023-01-05 06:55:30,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:30,809 INFO:     Epoch: 52
2023-01-05 06:55:33,103 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45196928282578785, 'Total loss': 0.45196928282578785} | train loss {'Reaction outcome loss': 0.2069119340353494, 'Total loss': 0.2069119340353494}
2023-01-05 06:55:33,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:33,103 INFO:     Epoch: 53
2023-01-05 06:55:35,308 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4671644459168116, 'Total loss': 0.4671644459168116} | train loss {'Reaction outcome loss': 0.2098644476565482, 'Total loss': 0.2098644476565482}
2023-01-05 06:55:35,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:35,308 INFO:     Epoch: 54
2023-01-05 06:55:37,559 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45216397047042844, 'Total loss': 0.45216397047042844} | train loss {'Reaction outcome loss': 0.20916795110773792, 'Total loss': 0.20916795110773792}
2023-01-05 06:55:37,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:37,559 INFO:     Epoch: 55
2023-01-05 06:55:39,818 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48721345961093904, 'Total loss': 0.48721345961093904} | train loss {'Reaction outcome loss': 0.20704546610451563, 'Total loss': 0.20704546610451563}
2023-01-05 06:55:39,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:39,818 INFO:     Epoch: 56
2023-01-05 06:55:42,090 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4764223953088125, 'Total loss': 0.4764223953088125} | train loss {'Reaction outcome loss': 0.20446976551295187, 'Total loss': 0.20446976551295187}
2023-01-05 06:55:42,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:42,090 INFO:     Epoch: 57
2023-01-05 06:55:44,394 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47227248549461365, 'Total loss': 0.47227248549461365} | train loss {'Reaction outcome loss': 0.2048247624524879, 'Total loss': 0.2048247624524879}
2023-01-05 06:55:44,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:44,394 INFO:     Epoch: 58
2023-01-05 06:55:46,682 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4802348881959915, 'Total loss': 0.4802348881959915} | train loss {'Reaction outcome loss': 0.1997726955501504, 'Total loss': 0.1997726955501504}
2023-01-05 06:55:46,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:46,683 INFO:     Epoch: 59
2023-01-05 06:55:48,978 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4542725076278051, 'Total loss': 0.4542725076278051} | train loss {'Reaction outcome loss': 0.20421913371754252, 'Total loss': 0.20421913371754252}
2023-01-05 06:55:48,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:48,978 INFO:     Epoch: 60
2023-01-05 06:55:51,234 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4681783815224965, 'Total loss': 0.4681783815224965} | train loss {'Reaction outcome loss': 0.20130969787736017, 'Total loss': 0.20130969787736017}
2023-01-05 06:55:51,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:51,234 INFO:     Epoch: 61
2023-01-05 06:55:53,511 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45925489664077757, 'Total loss': 0.45925489664077757} | train loss {'Reaction outcome loss': 0.1984207925827172, 'Total loss': 0.1984207925827172}
2023-01-05 06:55:53,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:53,512 INFO:     Epoch: 62
2023-01-05 06:55:55,802 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4704279581705729, 'Total loss': 0.4704279581705729} | train loss {'Reaction outcome loss': 0.19803640369783132, 'Total loss': 0.19803640369783132}
2023-01-05 06:55:55,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:55,802 INFO:     Epoch: 63
2023-01-05 06:55:58,071 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4894343982140223, 'Total loss': 0.4894343982140223} | train loss {'Reaction outcome loss': 0.1944105447730594, 'Total loss': 0.1944105447730594}
2023-01-05 06:55:58,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:55:58,071 INFO:     Epoch: 64
2023-01-05 06:56:00,352 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46371137698491416, 'Total loss': 0.46371137698491416} | train loss {'Reaction outcome loss': 0.1902088383817877, 'Total loss': 0.1902088383817877}
2023-01-05 06:56:00,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:00,353 INFO:     Epoch: 65
2023-01-05 06:56:02,614 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.461474006374677, 'Total loss': 0.461474006374677} | train loss {'Reaction outcome loss': 0.19408623600170177, 'Total loss': 0.19408623600170177}
2023-01-05 06:56:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:02,614 INFO:     Epoch: 66
2023-01-05 06:56:04,868 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48882040778795877, 'Total loss': 0.48882040778795877} | train loss {'Reaction outcome loss': 0.19144396235433403, 'Total loss': 0.19144396235433403}
2023-01-05 06:56:04,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:04,868 INFO:     Epoch: 67
2023-01-05 06:56:07,152 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4998233755429586, 'Total loss': 0.4998233755429586} | train loss {'Reaction outcome loss': 0.18995467656618154, 'Total loss': 0.18995467656618154}
2023-01-05 06:56:07,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:07,153 INFO:     Epoch: 68
2023-01-05 06:56:09,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45904100835323336, 'Total loss': 0.45904100835323336} | train loss {'Reaction outcome loss': 0.1904874182380198, 'Total loss': 0.1904874182380198}
2023-01-05 06:56:09,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:09,370 INFO:     Epoch: 69
2023-01-05 06:56:11,654 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45953074196974436, 'Total loss': 0.45953074196974436} | train loss {'Reaction outcome loss': 0.1871952395852561, 'Total loss': 0.1871952395852561}
2023-01-05 06:56:11,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:11,654 INFO:     Epoch: 70
2023-01-05 06:56:13,918 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4934682806332906, 'Total loss': 0.4934682806332906} | train loss {'Reaction outcome loss': 0.1936573285192574, 'Total loss': 0.1936573285192574}
2023-01-05 06:56:13,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:13,919 INFO:     Epoch: 71
2023-01-05 06:56:16,165 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47270411054293315, 'Total loss': 0.47270411054293315} | train loss {'Reaction outcome loss': 0.1860921876000691, 'Total loss': 0.1860921876000691}
2023-01-05 06:56:16,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:16,165 INFO:     Epoch: 72
2023-01-05 06:56:18,444 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4815617802242438, 'Total loss': 0.4815617802242438} | train loss {'Reaction outcome loss': 0.1923296563529043, 'Total loss': 0.1923296563529043}
2023-01-05 06:56:18,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:18,444 INFO:     Epoch: 73
2023-01-05 06:56:20,736 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4858282456795375, 'Total loss': 0.4858282456795375} | train loss {'Reaction outcome loss': 0.1859954463482737, 'Total loss': 0.1859954463482737}
2023-01-05 06:56:20,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:20,736 INFO:     Epoch: 74
2023-01-05 06:56:23,006 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.469345822930336, 'Total loss': 0.469345822930336} | train loss {'Reaction outcome loss': 0.18553025245881682, 'Total loss': 0.18553025245881682}
2023-01-05 06:56:23,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:23,007 INFO:     Epoch: 75
2023-01-05 06:56:25,249 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4648889591296514, 'Total loss': 0.4648889591296514} | train loss {'Reaction outcome loss': 0.18527794973285944, 'Total loss': 0.18527794973285944}
2023-01-05 06:56:25,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:25,249 INFO:     Epoch: 76
2023-01-05 06:56:27,476 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4477612813313802, 'Total loss': 0.4477612813313802} | train loss {'Reaction outcome loss': 0.18515897447761107, 'Total loss': 0.18515897447761107}
2023-01-05 06:56:27,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:27,477 INFO:     Epoch: 77
2023-01-05 06:56:29,756 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.438993098338445, 'Total loss': 0.438993098338445} | train loss {'Reaction outcome loss': 0.18303637886050053, 'Total loss': 0.18303637886050053}
2023-01-05 06:56:29,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:29,757 INFO:     Epoch: 78
2023-01-05 06:56:32,001 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47893172899881997, 'Total loss': 0.47893172899881997} | train loss {'Reaction outcome loss': 0.17848635385895573, 'Total loss': 0.17848635385895573}
2023-01-05 06:56:32,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:32,001 INFO:     Epoch: 79
2023-01-05 06:56:34,270 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4775503098964691, 'Total loss': 0.4775503098964691} | train loss {'Reaction outcome loss': 0.1828442117206026, 'Total loss': 0.1828442117206026}
2023-01-05 06:56:34,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:34,271 INFO:     Epoch: 80
2023-01-05 06:56:36,522 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47813138365745544, 'Total loss': 0.47813138365745544} | train loss {'Reaction outcome loss': 0.18117183677865603, 'Total loss': 0.18117183677865603}
2023-01-05 06:56:36,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:36,522 INFO:     Epoch: 81
2023-01-05 06:56:38,798 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4765522708495458, 'Total loss': 0.4765522708495458} | train loss {'Reaction outcome loss': 0.18278073997569644, 'Total loss': 0.18278073997569644}
2023-01-05 06:56:38,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:38,799 INFO:     Epoch: 82
2023-01-05 06:56:41,034 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4393336991469065, 'Total loss': 0.4393336991469065} | train loss {'Reaction outcome loss': 0.18214373083260677, 'Total loss': 0.18214373083260677}
2023-01-05 06:56:41,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:41,034 INFO:     Epoch: 83
2023-01-05 06:56:43,307 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4400020956993103, 'Total loss': 0.4400020956993103} | train loss {'Reaction outcome loss': 0.17692697429289833, 'Total loss': 0.17692697429289833}
2023-01-05 06:56:43,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:43,308 INFO:     Epoch: 84
2023-01-05 06:56:45,540 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4672116001447042, 'Total loss': 0.4672116001447042} | train loss {'Reaction outcome loss': 0.17693768551956446, 'Total loss': 0.17693768551956446}
2023-01-05 06:56:45,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:45,540 INFO:     Epoch: 85
2023-01-05 06:56:47,852 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4694017082452774, 'Total loss': 0.4694017082452774} | train loss {'Reaction outcome loss': 0.178166163970955, 'Total loss': 0.178166163970955}
2023-01-05 06:56:47,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:47,853 INFO:     Epoch: 86
2023-01-05 06:56:50,152 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47682725290457406, 'Total loss': 0.47682725290457406} | train loss {'Reaction outcome loss': 0.17535679755792935, 'Total loss': 0.17535679755792935}
2023-01-05 06:56:50,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:50,152 INFO:     Epoch: 87
2023-01-05 06:56:52,436 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4684833139181137, 'Total loss': 0.4684833139181137} | train loss {'Reaction outcome loss': 0.17819816098356828, 'Total loss': 0.17819816098356828}
2023-01-05 06:56:52,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:52,436 INFO:     Epoch: 88
2023-01-05 06:56:54,720 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46599715054035185, 'Total loss': 0.46599715054035185} | train loss {'Reaction outcome loss': 0.17339966043036445, 'Total loss': 0.17339966043036445}
2023-01-05 06:56:54,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:54,720 INFO:     Epoch: 89
2023-01-05 06:56:56,967 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4725906054178874, 'Total loss': 0.4725906054178874} | train loss {'Reaction outcome loss': 0.17450759282154082, 'Total loss': 0.17450759282154082}
2023-01-05 06:56:56,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:56,967 INFO:     Epoch: 90
2023-01-05 06:56:59,258 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4727169096469879, 'Total loss': 0.4727169096469879} | train loss {'Reaction outcome loss': 0.1747579517797819, 'Total loss': 0.1747579517797819}
2023-01-05 06:56:59,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:56:59,259 INFO:     Epoch: 91
2023-01-05 06:57:01,573 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49927610059579214, 'Total loss': 0.49927610059579214} | train loss {'Reaction outcome loss': 0.17402534090681843, 'Total loss': 0.17402534090681843}
2023-01-05 06:57:01,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:01,574 INFO:     Epoch: 92
2023-01-05 06:57:03,861 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47101930975914, 'Total loss': 0.47101930975914} | train loss {'Reaction outcome loss': 0.17587646542096827, 'Total loss': 0.17587646542096827}
2023-01-05 06:57:03,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:03,862 INFO:     Epoch: 93
2023-01-05 06:57:06,195 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4933790475130081, 'Total loss': 0.4933790475130081} | train loss {'Reaction outcome loss': 0.17097257626232848, 'Total loss': 0.17097257626232848}
2023-01-05 06:57:06,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:06,196 INFO:     Epoch: 94
2023-01-05 06:57:08,535 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4971549689769745, 'Total loss': 0.4971549689769745} | train loss {'Reaction outcome loss': 0.17146102625318543, 'Total loss': 0.17146102625318543}
2023-01-05 06:57:08,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:08,535 INFO:     Epoch: 95
2023-01-05 06:57:10,849 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48653543591499326, 'Total loss': 0.48653543591499326} | train loss {'Reaction outcome loss': 0.16455934376586967, 'Total loss': 0.16455934376586967}
2023-01-05 06:57:10,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:10,850 INFO:     Epoch: 96
2023-01-05 06:57:13,130 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4707762777805328, 'Total loss': 0.4707762777805328} | train loss {'Reaction outcome loss': 0.16987233955601386, 'Total loss': 0.16987233955601386}
2023-01-05 06:57:13,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:13,131 INFO:     Epoch: 97
2023-01-05 06:57:15,396 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5217419157425562, 'Total loss': 0.5217419157425562} | train loss {'Reaction outcome loss': 0.16934248183716075, 'Total loss': 0.16934248183716075}
2023-01-05 06:57:15,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:15,396 INFO:     Epoch: 98
2023-01-05 06:57:17,665 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47281367182731626, 'Total loss': 0.47281367182731626} | train loss {'Reaction outcome loss': 0.1721290683874773, 'Total loss': 0.1721290683874773}
2023-01-05 06:57:17,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:17,665 INFO:     Epoch: 99
2023-01-05 06:57:19,965 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4987571855386098, 'Total loss': 0.4987571855386098} | train loss {'Reaction outcome loss': 0.16412343449776298, 'Total loss': 0.16412343449776298}
2023-01-05 06:57:19,965 INFO:     Best model found after epoch 26 of 100.
2023-01-05 06:57:19,966 INFO:   Done with stage: TRAINING
2023-01-05 06:57:19,966 INFO:   Starting stage: EVALUATION
2023-01-05 06:57:20,097 INFO:   Done with stage: EVALUATION
2023-01-05 06:57:20,097 INFO:   Leaving out SEQ value Fold_8
2023-01-05 06:57:20,110 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 06:57:20,110 INFO:   Starting stage: FEATURE SCALING
2023-01-05 06:57:20,773 INFO:   Done with stage: FEATURE SCALING
2023-01-05 06:57:20,773 INFO:   Starting stage: SCALING TARGETS
2023-01-05 06:57:20,846 INFO:   Done with stage: SCALING TARGETS
2023-01-05 06:57:20,846 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:57:20,846 INFO:     No hyperparam tuning for this model
2023-01-05 06:57:20,846 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 06:57:20,846 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 06:57:20,847 INFO:     None feature selector for col prot
2023-01-05 06:57:20,847 INFO:     None feature selector for col prot
2023-01-05 06:57:20,847 INFO:     None feature selector for col prot
2023-01-05 06:57:20,848 INFO:     None feature selector for col chem
2023-01-05 06:57:20,848 INFO:     None feature selector for col chem
2023-01-05 06:57:20,848 INFO:     None feature selector for col chem
2023-01-05 06:57:20,848 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 06:57:20,848 INFO:   Starting stage: BUILD MODEL
2023-01-05 06:57:20,851 INFO:     Number of params in model 72931
2023-01-05 06:57:20,854 INFO:   Done with stage: BUILD MODEL
2023-01-05 06:57:20,854 INFO:   Starting stage: TRAINING
2023-01-05 06:57:20,913 INFO:     Val loss before train {'Reaction outcome loss': 0.9543125987052917, 'Total loss': 0.9543125987052917}
2023-01-05 06:57:20,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:20,914 INFO:     Epoch: 0
2023-01-05 06:57:23,146 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7534465432167053, 'Total loss': 0.7534465432167053} | train loss {'Reaction outcome loss': 0.9525182669180153, 'Total loss': 0.9525182669180153}
2023-01-05 06:57:23,146 INFO:     Found new best model at epoch 0
2023-01-05 06:57:23,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:23,147 INFO:     Epoch: 1
2023-01-05 06:57:25,316 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5026602844397227, 'Total loss': 0.5026602844397227} | train loss {'Reaction outcome loss': 0.642202336531486, 'Total loss': 0.642202336531486}
2023-01-05 06:57:25,316 INFO:     Found new best model at epoch 1
2023-01-05 06:57:25,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:25,317 INFO:     Epoch: 2
2023-01-05 06:57:27,572 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47038628458976744, 'Total loss': 0.47038628458976744} | train loss {'Reaction outcome loss': 0.518784703238167, 'Total loss': 0.518784703238167}
2023-01-05 06:57:27,572 INFO:     Found new best model at epoch 2
2023-01-05 06:57:27,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:27,573 INFO:     Epoch: 3
2023-01-05 06:57:29,827 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4507750511169434, 'Total loss': 0.4507750511169434} | train loss {'Reaction outcome loss': 0.47451894300697495, 'Total loss': 0.47451894300697495}
2023-01-05 06:57:29,827 INFO:     Found new best model at epoch 3
2023-01-05 06:57:29,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:29,829 INFO:     Epoch: 4
2023-01-05 06:57:32,079 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45122199058532714, 'Total loss': 0.45122199058532714} | train loss {'Reaction outcome loss': 0.4428311071365419, 'Total loss': 0.4428311071365419}
2023-01-05 06:57:32,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:32,079 INFO:     Epoch: 5
2023-01-05 06:57:34,265 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42270297010739644, 'Total loss': 0.42270297010739644} | train loss {'Reaction outcome loss': 0.42383573671979624, 'Total loss': 0.42383573671979624}
2023-01-05 06:57:34,266 INFO:     Found new best model at epoch 5
2023-01-05 06:57:34,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:34,268 INFO:     Epoch: 6
2023-01-05 06:57:36,524 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4202578872442245, 'Total loss': 0.4202578872442245} | train loss {'Reaction outcome loss': 0.40611427584595056, 'Total loss': 0.40611427584595056}
2023-01-05 06:57:36,524 INFO:     Found new best model at epoch 6
2023-01-05 06:57:36,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:36,526 INFO:     Epoch: 7
2023-01-05 06:57:38,736 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4244409581025442, 'Total loss': 0.4244409581025442} | train loss {'Reaction outcome loss': 0.3942521574777843, 'Total loss': 0.3942521574777843}
2023-01-05 06:57:38,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:38,737 INFO:     Epoch: 8
2023-01-05 06:57:40,985 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4086298336585363, 'Total loss': 0.4086298336585363} | train loss {'Reaction outcome loss': 0.3800089869131572, 'Total loss': 0.3800089869131572}
2023-01-05 06:57:40,986 INFO:     Found new best model at epoch 8
2023-01-05 06:57:40,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:40,988 INFO:     Epoch: 9
2023-01-05 06:57:43,245 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40662246346473696, 'Total loss': 0.40662246346473696} | train loss {'Reaction outcome loss': 0.3707115276832215, 'Total loss': 0.3707115276832215}
2023-01-05 06:57:43,245 INFO:     Found new best model at epoch 9
2023-01-05 06:57:43,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:43,246 INFO:     Epoch: 10
2023-01-05 06:57:45,516 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39524619827667873, 'Total loss': 0.39524619827667873} | train loss {'Reaction outcome loss': 0.35052619874477386, 'Total loss': 0.35052619874477386}
2023-01-05 06:57:45,516 INFO:     Found new best model at epoch 10
2023-01-05 06:57:45,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:45,518 INFO:     Epoch: 11
2023-01-05 06:57:47,706 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39952173829078674, 'Total loss': 0.39952173829078674} | train loss {'Reaction outcome loss': 0.34681498417018974, 'Total loss': 0.34681498417018974}
2023-01-05 06:57:47,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:47,706 INFO:     Epoch: 12
2023-01-05 06:57:49,969 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4182571033636729, 'Total loss': 0.4182571033636729} | train loss {'Reaction outcome loss': 0.33690810850719466, 'Total loss': 0.33690810850719466}
2023-01-05 06:57:49,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:49,970 INFO:     Epoch: 13
2023-01-05 06:57:52,232 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3908201495806376, 'Total loss': 0.3908201495806376} | train loss {'Reaction outcome loss': 0.32660915596532997, 'Total loss': 0.32660915596532997}
2023-01-05 06:57:52,233 INFO:     Found new best model at epoch 13
2023-01-05 06:57:52,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:52,234 INFO:     Epoch: 14
2023-01-05 06:57:54,494 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37474216719468434, 'Total loss': 0.37474216719468434} | train loss {'Reaction outcome loss': 0.31687115111055164, 'Total loss': 0.31687115111055164}
2023-01-05 06:57:54,495 INFO:     Found new best model at epoch 14
2023-01-05 06:57:54,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:54,497 INFO:     Epoch: 15
2023-01-05 06:57:56,767 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3632389405121406, 'Total loss': 0.3632389405121406} | train loss {'Reaction outcome loss': 0.3074741018732099, 'Total loss': 0.3074741018732099}
2023-01-05 06:57:56,767 INFO:     Found new best model at epoch 15
2023-01-05 06:57:56,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:56,769 INFO:     Epoch: 16
2023-01-05 06:57:59,015 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37514464060465497, 'Total loss': 0.37514464060465497} | train loss {'Reaction outcome loss': 0.29804983596405843, 'Total loss': 0.29804983596405843}
2023-01-05 06:57:59,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:57:59,015 INFO:     Epoch: 17
2023-01-05 06:58:01,200 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3762879957755407, 'Total loss': 0.3762879957755407} | train loss {'Reaction outcome loss': 0.2930202313093808, 'Total loss': 0.2930202313093808}
2023-01-05 06:58:01,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:01,200 INFO:     Epoch: 18
2023-01-05 06:58:03,457 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4159150034189224, 'Total loss': 0.4159150034189224} | train loss {'Reaction outcome loss': 0.2870026093085099, 'Total loss': 0.2870026093085099}
2023-01-05 06:58:03,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:03,457 INFO:     Epoch: 19
2023-01-05 06:58:05,721 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3897071657081445, 'Total loss': 0.3897071657081445} | train loss {'Reaction outcome loss': 0.28309079265072395, 'Total loss': 0.28309079265072395}
2023-01-05 06:58:05,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:05,721 INFO:     Epoch: 20
2023-01-05 06:58:07,978 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.397899533311526, 'Total loss': 0.397899533311526} | train loss {'Reaction outcome loss': 0.2748034155934396, 'Total loss': 0.2748034155934396}
2023-01-05 06:58:07,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:07,979 INFO:     Epoch: 21
2023-01-05 06:58:10,224 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38564367791016896, 'Total loss': 0.38564367791016896} | train loss {'Reaction outcome loss': 0.26695401452644896, 'Total loss': 0.26695401452644896}
2023-01-05 06:58:10,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:10,225 INFO:     Epoch: 22
2023-01-05 06:58:12,483 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3744348684946696, 'Total loss': 0.3744348684946696} | train loss {'Reaction outcome loss': 0.2612958453378103, 'Total loss': 0.2612958453378103}
2023-01-05 06:58:12,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:12,483 INFO:     Epoch: 23
2023-01-05 06:58:14,707 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.414952423175176, 'Total loss': 0.414952423175176} | train loss {'Reaction outcome loss': 0.25949927159061614, 'Total loss': 0.25949927159061614}
2023-01-05 06:58:14,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:14,707 INFO:     Epoch: 24
2023-01-05 06:58:16,925 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38254677404959997, 'Total loss': 0.38254677404959997} | train loss {'Reaction outcome loss': 0.25256317732923655, 'Total loss': 0.25256317732923655}
2023-01-05 06:58:16,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:16,926 INFO:     Epoch: 25
2023-01-05 06:58:19,193 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3906411970655123, 'Total loss': 0.3906411970655123} | train loss {'Reaction outcome loss': 0.24957822844467675, 'Total loss': 0.24957822844467675}
2023-01-05 06:58:19,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:19,193 INFO:     Epoch: 26
2023-01-05 06:58:21,445 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3821016977230708, 'Total loss': 0.3821016977230708} | train loss {'Reaction outcome loss': 0.2513524742225987, 'Total loss': 0.2513524742225987}
2023-01-05 06:58:21,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:21,446 INFO:     Epoch: 27
2023-01-05 06:58:23,694 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37816068107883133, 'Total loss': 0.37816068107883133} | train loss {'Reaction outcome loss': 0.24334756964749663, 'Total loss': 0.24334756964749663}
2023-01-05 06:58:23,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:23,694 INFO:     Epoch: 28
2023-01-05 06:58:25,948 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4075471128026644, 'Total loss': 0.4075471128026644} | train loss {'Reaction outcome loss': 0.24234251886007996, 'Total loss': 0.24234251886007996}
2023-01-05 06:58:25,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:25,949 INFO:     Epoch: 29
2023-01-05 06:58:28,210 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3671970754861832, 'Total loss': 0.3671970754861832} | train loss {'Reaction outcome loss': 0.2386602815444561, 'Total loss': 0.2386602815444561}
2023-01-05 06:58:28,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:28,210 INFO:     Epoch: 30
2023-01-05 06:58:30,477 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37045316994190214, 'Total loss': 0.37045316994190214} | train loss {'Reaction outcome loss': 0.2300511551069191, 'Total loss': 0.2300511551069191}
2023-01-05 06:58:30,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:30,477 INFO:     Epoch: 31
2023-01-05 06:58:32,739 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4007879396279653, 'Total loss': 0.4007879396279653} | train loss {'Reaction outcome loss': 0.22754320506359973, 'Total loss': 0.22754320506359973}
2023-01-05 06:58:32,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:32,740 INFO:     Epoch: 32
2023-01-05 06:58:34,983 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3947468727827072, 'Total loss': 0.3947468727827072} | train loss {'Reaction outcome loss': 0.2300963376947835, 'Total loss': 0.2300963376947835}
2023-01-05 06:58:34,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:34,984 INFO:     Epoch: 33
2023-01-05 06:58:37,236 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40195375084877016, 'Total loss': 0.40195375084877016} | train loss {'Reaction outcome loss': 0.22244542652917823, 'Total loss': 0.22244542652917823}
2023-01-05 06:58:37,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:37,236 INFO:     Epoch: 34
2023-01-05 06:58:39,394 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3939547379811605, 'Total loss': 0.3939547379811605} | train loss {'Reaction outcome loss': 0.2237626554811523, 'Total loss': 0.2237626554811523}
2023-01-05 06:58:39,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:39,394 INFO:     Epoch: 35
2023-01-05 06:58:41,677 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3810886353254318, 'Total loss': 0.3810886353254318} | train loss {'Reaction outcome loss': 0.22347181892688692, 'Total loss': 0.22347181892688692}
2023-01-05 06:58:41,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:41,677 INFO:     Epoch: 36
2023-01-05 06:58:43,942 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38400485217571256, 'Total loss': 0.38400485217571256} | train loss {'Reaction outcome loss': 0.2182703485685217, 'Total loss': 0.2182703485685217}
2023-01-05 06:58:43,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:43,943 INFO:     Epoch: 37
2023-01-05 06:58:46,222 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39908600052197774, 'Total loss': 0.39908600052197774} | train loss {'Reaction outcome loss': 0.21676990731762055, 'Total loss': 0.21676990731762055}
2023-01-05 06:58:46,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:46,223 INFO:     Epoch: 38
2023-01-05 06:58:48,478 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39651040186484654, 'Total loss': 0.39651040186484654} | train loss {'Reaction outcome loss': 0.20902794134551592, 'Total loss': 0.20902794134551592}
2023-01-05 06:58:48,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:48,478 INFO:     Epoch: 39
2023-01-05 06:58:50,742 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4138555407524109, 'Total loss': 0.4138555407524109} | train loss {'Reaction outcome loss': 0.2098438959555143, 'Total loss': 0.2098438959555143}
2023-01-05 06:58:50,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:50,742 INFO:     Epoch: 40
2023-01-05 06:58:53,009 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4124158650636673, 'Total loss': 0.4124158650636673} | train loss {'Reaction outcome loss': 0.20870015481282977, 'Total loss': 0.20870015481282977}
2023-01-05 06:58:53,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:53,010 INFO:     Epoch: 41
2023-01-05 06:58:55,291 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3763660440842311, 'Total loss': 0.3763660440842311} | train loss {'Reaction outcome loss': 0.20732529820996698, 'Total loss': 0.20732529820996698}
2023-01-05 06:58:55,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:55,292 INFO:     Epoch: 42
2023-01-05 06:58:57,552 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3966270208358765, 'Total loss': 0.3966270208358765} | train loss {'Reaction outcome loss': 0.20433245089081845, 'Total loss': 0.20433245089081845}
2023-01-05 06:58:57,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:57,552 INFO:     Epoch: 43
2023-01-05 06:58:59,784 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.414493161936601, 'Total loss': 0.414493161936601} | train loss {'Reaction outcome loss': 0.19958752506908817, 'Total loss': 0.19958752506908817}
2023-01-05 06:58:59,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:58:59,784 INFO:     Epoch: 44
2023-01-05 06:59:02,054 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4226999759674072, 'Total loss': 0.4226999759674072} | train loss {'Reaction outcome loss': 0.1964442691116519, 'Total loss': 0.1964442691116519}
2023-01-05 06:59:02,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:02,054 INFO:     Epoch: 45
2023-01-05 06:59:04,289 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4557095170021057, 'Total loss': 0.4557095170021057} | train loss {'Reaction outcome loss': 0.19519349165859012, 'Total loss': 0.19519349165859012}
2023-01-05 06:59:04,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:04,289 INFO:     Epoch: 46
2023-01-05 06:59:06,554 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43677906642357506, 'Total loss': 0.43677906642357506} | train loss {'Reaction outcome loss': 0.20035088725428837, 'Total loss': 0.20035088725428837}
2023-01-05 06:59:06,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:06,555 INFO:     Epoch: 47
2023-01-05 06:59:08,801 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43809702893098196, 'Total loss': 0.43809702893098196} | train loss {'Reaction outcome loss': 0.20244790814871336, 'Total loss': 0.20244790814871336}
2023-01-05 06:59:08,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:08,802 INFO:     Epoch: 48
2023-01-05 06:59:11,049 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4129350866811971, 'Total loss': 0.4129350866811971} | train loss {'Reaction outcome loss': 0.19286308009483355, 'Total loss': 0.19286308009483355}
2023-01-05 06:59:11,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:11,049 INFO:     Epoch: 49
2023-01-05 06:59:13,309 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40550054907798766, 'Total loss': 0.40550054907798766} | train loss {'Reaction outcome loss': 0.19633539530183494, 'Total loss': 0.19633539530183494}
2023-01-05 06:59:13,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:13,309 INFO:     Epoch: 50
2023-01-05 06:59:15,541 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4185831964015961, 'Total loss': 0.4185831964015961} | train loss {'Reaction outcome loss': 0.18908319061955126, 'Total loss': 0.18908319061955126}
2023-01-05 06:59:15,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:15,541 INFO:     Epoch: 51
2023-01-05 06:59:17,814 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4445308526357015, 'Total loss': 0.4445308526357015} | train loss {'Reaction outcome loss': 0.18847419016987738, 'Total loss': 0.18847419016987738}
2023-01-05 06:59:17,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:17,814 INFO:     Epoch: 52
2023-01-05 06:59:20,086 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39447345236937204, 'Total loss': 0.39447345236937204} | train loss {'Reaction outcome loss': 0.18450796741815487, 'Total loss': 0.18450796741815487}
2023-01-05 06:59:20,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:20,086 INFO:     Epoch: 53
2023-01-05 06:59:22,345 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41317154665788014, 'Total loss': 0.41317154665788014} | train loss {'Reaction outcome loss': 0.1862777809877574, 'Total loss': 0.1862777809877574}
2023-01-05 06:59:22,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:22,347 INFO:     Epoch: 54
2023-01-05 06:59:24,622 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4453825583060583, 'Total loss': 0.4453825583060583} | train loss {'Reaction outcome loss': 0.1881818373765742, 'Total loss': 0.1881818373765742}
2023-01-05 06:59:24,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:24,622 INFO:     Epoch: 55
2023-01-05 06:59:26,893 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45254872739315033, 'Total loss': 0.45254872739315033} | train loss {'Reaction outcome loss': 0.18834075900678435, 'Total loss': 0.18834075900678435}
2023-01-05 06:59:26,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:26,893 INFO:     Epoch: 56
2023-01-05 06:59:29,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4227554569641749, 'Total loss': 0.4227554569641749} | train loss {'Reaction outcome loss': 0.18289981659393023, 'Total loss': 0.18289981659393023}
2023-01-05 06:59:29,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:29,166 INFO:     Epoch: 57
2023-01-05 06:59:31,441 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4486754258473714, 'Total loss': 0.4486754258473714} | train loss {'Reaction outcome loss': 0.18861741591652814, 'Total loss': 0.18861741591652814}
2023-01-05 06:59:31,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:31,441 INFO:     Epoch: 58
2023-01-05 06:59:33,664 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4496919160087903, 'Total loss': 0.4496919160087903} | train loss {'Reaction outcome loss': 0.18152692242879012, 'Total loss': 0.18152692242879012}
2023-01-05 06:59:33,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:33,665 INFO:     Epoch: 59
2023-01-05 06:59:35,694 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43202516237894695, 'Total loss': 0.43202516237894695} | train loss {'Reaction outcome loss': 0.18307690160947232, 'Total loss': 0.18307690160947232}
2023-01-05 06:59:35,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:35,694 INFO:     Epoch: 60
2023-01-05 06:59:37,947 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42824483613173164, 'Total loss': 0.42824483613173164} | train loss {'Reaction outcome loss': 0.17988435066658595, 'Total loss': 0.17988435066658595}
2023-01-05 06:59:37,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:37,947 INFO:     Epoch: 61
2023-01-05 06:59:40,171 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4293699155251185, 'Total loss': 0.4293699155251185} | train loss {'Reaction outcome loss': 0.18178869986118082, 'Total loss': 0.18178869986118082}
2023-01-05 06:59:40,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:40,172 INFO:     Epoch: 62
2023-01-05 06:59:42,398 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4500013738870621, 'Total loss': 0.4500013738870621} | train loss {'Reaction outcome loss': 0.17726364129658, 'Total loss': 0.17726364129658}
2023-01-05 06:59:42,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:42,399 INFO:     Epoch: 63
2023-01-05 06:59:44,634 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42188070714473724, 'Total loss': 0.42188070714473724} | train loss {'Reaction outcome loss': 0.17850488194529593, 'Total loss': 0.17850488194529593}
2023-01-05 06:59:44,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:44,634 INFO:     Epoch: 64
2023-01-05 06:59:46,878 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42476253807544706, 'Total loss': 0.42476253807544706} | train loss {'Reaction outcome loss': 0.17436783541891263, 'Total loss': 0.17436783541891263}
2023-01-05 06:59:46,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:46,879 INFO:     Epoch: 65
2023-01-05 06:59:49,139 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41077045251925787, 'Total loss': 0.41077045251925787} | train loss {'Reaction outcome loss': 0.17455263397771947, 'Total loss': 0.17455263397771947}
2023-01-05 06:59:49,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:49,139 INFO:     Epoch: 66
2023-01-05 06:59:51,411 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4459206839402517, 'Total loss': 0.4459206839402517} | train loss {'Reaction outcome loss': 0.1740197977594977, 'Total loss': 0.1740197977594977}
2023-01-05 06:59:51,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:51,412 INFO:     Epoch: 67
2023-01-05 06:59:53,677 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.427612167596817, 'Total loss': 0.427612167596817} | train loss {'Reaction outcome loss': 0.17617386336146046, 'Total loss': 0.17617386336146046}
2023-01-05 06:59:53,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:53,678 INFO:     Epoch: 68
2023-01-05 06:59:55,930 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45841255486011506, 'Total loss': 0.45841255486011506} | train loss {'Reaction outcome loss': 0.17411758223834045, 'Total loss': 0.17411758223834045}
2023-01-05 06:59:55,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:55,931 INFO:     Epoch: 69
2023-01-05 06:59:58,191 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4665426671504974, 'Total loss': 0.4665426671504974} | train loss {'Reaction outcome loss': 0.17401106113119283, 'Total loss': 0.17401106113119283}
2023-01-05 06:59:58,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 06:59:58,193 INFO:     Epoch: 70
2023-01-05 07:00:00,468 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41346810658772787, 'Total loss': 0.41346810658772787} | train loss {'Reaction outcome loss': 0.1723691884081566, 'Total loss': 0.1723691884081566}
2023-01-05 07:00:00,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:00,469 INFO:     Epoch: 71
2023-01-05 07:00:02,742 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44154587586720784, 'Total loss': 0.44154587586720784} | train loss {'Reaction outcome loss': 0.17124677762851445, 'Total loss': 0.17124677762851445}
2023-01-05 07:00:02,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:02,742 INFO:     Epoch: 72
2023-01-05 07:00:04,998 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4444346944491068, 'Total loss': 0.4444346944491068} | train loss {'Reaction outcome loss': 0.17052569450898925, 'Total loss': 0.17052569450898925}
2023-01-05 07:00:04,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:04,999 INFO:     Epoch: 73
2023-01-05 07:00:07,256 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41780955890814464, 'Total loss': 0.41780955890814464} | train loss {'Reaction outcome loss': 0.16976864015629148, 'Total loss': 0.16976864015629148}
2023-01-05 07:00:07,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:07,256 INFO:     Epoch: 74
2023-01-05 07:00:09,506 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4212961326042811, 'Total loss': 0.4212961326042811} | train loss {'Reaction outcome loss': 0.16898517827775303, 'Total loss': 0.16898517827775303}
2023-01-05 07:00:09,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:09,506 INFO:     Epoch: 75
2023-01-05 07:00:11,764 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4263863424460093, 'Total loss': 0.4263863424460093} | train loss {'Reaction outcome loss': 0.1662085035265199, 'Total loss': 0.1662085035265199}
2023-01-05 07:00:11,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:11,764 INFO:     Epoch: 76
2023-01-05 07:00:13,996 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4213937242825826, 'Total loss': 0.4213937242825826} | train loss {'Reaction outcome loss': 0.16682612170791594, 'Total loss': 0.16682612170791594}
2023-01-05 07:00:13,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:13,996 INFO:     Epoch: 77
2023-01-05 07:00:16,257 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43392721911271415, 'Total loss': 0.43392721911271415} | train loss {'Reaction outcome loss': 0.17004192277897884, 'Total loss': 0.17004192277897884}
2023-01-05 07:00:16,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:16,257 INFO:     Epoch: 78
2023-01-05 07:00:18,509 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45703022678693134, 'Total loss': 0.45703022678693134} | train loss {'Reaction outcome loss': 0.16613320526870878, 'Total loss': 0.16613320526870878}
2023-01-05 07:00:18,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:18,510 INFO:     Epoch: 79
2023-01-05 07:00:20,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41200309147437414, 'Total loss': 0.41200309147437414} | train loss {'Reaction outcome loss': 0.16667988471156597, 'Total loss': 0.16667988471156597}
2023-01-05 07:00:20,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:20,696 INFO:     Epoch: 80
2023-01-05 07:00:22,901 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40447824597358706, 'Total loss': 0.40447824597358706} | train loss {'Reaction outcome loss': 0.16285653027406738, 'Total loss': 0.16285653027406738}
2023-01-05 07:00:22,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:22,901 INFO:     Epoch: 81
2023-01-05 07:00:25,128 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39572782119115196, 'Total loss': 0.39572782119115196} | train loss {'Reaction outcome loss': 0.16425823800123032, 'Total loss': 0.16425823800123032}
2023-01-05 07:00:25,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:25,128 INFO:     Epoch: 82
2023-01-05 07:00:27,390 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4223139444986979, 'Total loss': 0.4223139444986979} | train loss {'Reaction outcome loss': 0.15933016087710314, 'Total loss': 0.15933016087710314}
2023-01-05 07:00:27,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:27,391 INFO:     Epoch: 83
2023-01-05 07:00:29,654 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4442549963792165, 'Total loss': 0.4442549963792165} | train loss {'Reaction outcome loss': 0.16966302837007238, 'Total loss': 0.16966302837007238}
2023-01-05 07:00:29,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:29,654 INFO:     Epoch: 84
2023-01-05 07:00:31,879 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45297770798206327, 'Total loss': 0.45297770798206327} | train loss {'Reaction outcome loss': 0.16494012692005094, 'Total loss': 0.16494012692005094}
2023-01-05 07:00:31,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:31,879 INFO:     Epoch: 85
2023-01-05 07:00:34,156 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.430194686849912, 'Total loss': 0.430194686849912} | train loss {'Reaction outcome loss': 0.16099755529205512, 'Total loss': 0.16099755529205512}
2023-01-05 07:00:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:34,157 INFO:     Epoch: 86
2023-01-05 07:00:36,433 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45130205949147545, 'Total loss': 0.45130205949147545} | train loss {'Reaction outcome loss': 0.16181056960961734, 'Total loss': 0.16181056960961734}
2023-01-05 07:00:36,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:36,433 INFO:     Epoch: 87
2023-01-05 07:00:38,711 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4401067366202672, 'Total loss': 0.4401067366202672} | train loss {'Reaction outcome loss': 0.16165621762578614, 'Total loss': 0.16165621762578614}
2023-01-05 07:00:38,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:38,711 INFO:     Epoch: 88
2023-01-05 07:00:40,985 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4452937285105387, 'Total loss': 0.4452937285105387} | train loss {'Reaction outcome loss': 0.15972213466128293, 'Total loss': 0.15972213466128293}
2023-01-05 07:00:40,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:40,986 INFO:     Epoch: 89
2023-01-05 07:00:43,233 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43087505996227266, 'Total loss': 0.43087505996227266} | train loss {'Reaction outcome loss': 0.1588966410800842, 'Total loss': 0.1588966410800842}
2023-01-05 07:00:43,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:43,234 INFO:     Epoch: 90
2023-01-05 07:00:45,486 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4639355887969335, 'Total loss': 0.4639355887969335} | train loss {'Reaction outcome loss': 0.16046290059852666, 'Total loss': 0.16046290059852666}
2023-01-05 07:00:45,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:45,486 INFO:     Epoch: 91
2023-01-05 07:00:47,769 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4316785857081413, 'Total loss': 0.4316785857081413} | train loss {'Reaction outcome loss': 0.16539164041474896, 'Total loss': 0.16539164041474896}
2023-01-05 07:00:47,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:47,769 INFO:     Epoch: 92
2023-01-05 07:00:50,041 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43953314423561096, 'Total loss': 0.43953314423561096} | train loss {'Reaction outcome loss': 0.15717461225780638, 'Total loss': 0.15717461225780638}
2023-01-05 07:00:50,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:50,041 INFO:     Epoch: 93
2023-01-05 07:00:52,331 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4351734831929207, 'Total loss': 0.4351734831929207} | train loss {'Reaction outcome loss': 0.15661317485309864, 'Total loss': 0.15661317485309864}
2023-01-05 07:00:52,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:52,331 INFO:     Epoch: 94
2023-01-05 07:00:54,578 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45094450811545056, 'Total loss': 0.45094450811545056} | train loss {'Reaction outcome loss': 0.1610491440366328, 'Total loss': 0.1610491440366328}
2023-01-05 07:00:54,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:54,579 INFO:     Epoch: 95
2023-01-05 07:00:56,836 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45352680385112765, 'Total loss': 0.45352680385112765} | train loss {'Reaction outcome loss': 0.15940348710524885, 'Total loss': 0.15940348710524885}
2023-01-05 07:00:56,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:56,836 INFO:     Epoch: 96
2023-01-05 07:00:59,058 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4482591231664022, 'Total loss': 0.4482591231664022} | train loss {'Reaction outcome loss': 0.1598798908925459, 'Total loss': 0.1598798908925459}
2023-01-05 07:00:59,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:00:59,059 INFO:     Epoch: 97
2023-01-05 07:01:01,306 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4132775396108627, 'Total loss': 0.4132775396108627} | train loss {'Reaction outcome loss': 0.15876781603110696, 'Total loss': 0.15876781603110696}
2023-01-05 07:01:01,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:01,307 INFO:     Epoch: 98
2023-01-05 07:01:03,561 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4579856591920058, 'Total loss': 0.4579856591920058} | train loss {'Reaction outcome loss': 0.15724586624733722, 'Total loss': 0.15724586624733722}
2023-01-05 07:01:03,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:03,561 INFO:     Epoch: 99
2023-01-05 07:01:05,764 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4569222152233124, 'Total loss': 0.4569222152233124} | train loss {'Reaction outcome loss': 0.15851537735510726, 'Total loss': 0.15851537735510726}
2023-01-05 07:01:05,764 INFO:     Best model found after epoch 16 of 100.
2023-01-05 07:01:05,765 INFO:   Done with stage: TRAINING
2023-01-05 07:01:05,765 INFO:   Starting stage: EVALUATION
2023-01-05 07:01:05,905 INFO:   Done with stage: EVALUATION
2023-01-05 07:01:05,905 INFO:   Leaving out SEQ value Fold_9
2023-01-05 07:01:05,918 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 07:01:05,918 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:01:06,577 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:01:06,577 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:01:06,651 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:01:06,651 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:01:06,651 INFO:     No hyperparam tuning for this model
2023-01-05 07:01:06,652 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:01:06,652 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:01:06,652 INFO:     None feature selector for col prot
2023-01-05 07:01:06,652 INFO:     None feature selector for col prot
2023-01-05 07:01:06,653 INFO:     None feature selector for col prot
2023-01-05 07:01:06,653 INFO:     None feature selector for col chem
2023-01-05 07:01:06,653 INFO:     None feature selector for col chem
2023-01-05 07:01:06,653 INFO:     None feature selector for col chem
2023-01-05 07:01:06,653 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:01:06,653 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:01:06,655 INFO:     Number of params in model 72931
2023-01-05 07:01:06,658 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:01:06,658 INFO:   Starting stage: TRAINING
2023-01-05 07:01:06,719 INFO:     Val loss before train {'Reaction outcome loss': 0.8593500177065532, 'Total loss': 0.8593500177065532}
2023-01-05 07:01:06,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:06,719 INFO:     Epoch: 0
2023-01-05 07:01:08,982 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6455956061681112, 'Total loss': 0.6455956061681112} | train loss {'Reaction outcome loss': 0.9408083955088247, 'Total loss': 0.9408083955088247}
2023-01-05 07:01:08,983 INFO:     Found new best model at epoch 0
2023-01-05 07:01:08,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:08,984 INFO:     Epoch: 1
2023-01-05 07:01:11,221 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5450567404429117, 'Total loss': 0.5450567404429117} | train loss {'Reaction outcome loss': 0.6264196647741304, 'Total loss': 0.6264196647741304}
2023-01-05 07:01:11,221 INFO:     Found new best model at epoch 1
2023-01-05 07:01:11,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:11,223 INFO:     Epoch: 2
2023-01-05 07:01:13,504 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.519054326415062, 'Total loss': 0.519054326415062} | train loss {'Reaction outcome loss': 0.5491819019674824, 'Total loss': 0.5491819019674824}
2023-01-05 07:01:13,504 INFO:     Found new best model at epoch 2
2023-01-05 07:01:13,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:13,505 INFO:     Epoch: 3
2023-01-05 07:01:15,782 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49256468613942467, 'Total loss': 0.49256468613942467} | train loss {'Reaction outcome loss': 0.5095040605063903, 'Total loss': 0.5095040605063903}
2023-01-05 07:01:15,783 INFO:     Found new best model at epoch 3
2023-01-05 07:01:15,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:15,784 INFO:     Epoch: 4
2023-01-05 07:01:18,036 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48921847144762676, 'Total loss': 0.48921847144762676} | train loss {'Reaction outcome loss': 0.48737050549863475, 'Total loss': 0.48737050549863475}
2023-01-05 07:01:18,036 INFO:     Found new best model at epoch 4
2023-01-05 07:01:18,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:18,037 INFO:     Epoch: 5
2023-01-05 07:01:20,311 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4636018137137095, 'Total loss': 0.4636018137137095} | train loss {'Reaction outcome loss': 0.4621160832714518, 'Total loss': 0.4621160832714518}
2023-01-05 07:01:20,311 INFO:     Found new best model at epoch 5
2023-01-05 07:01:20,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:20,312 INFO:     Epoch: 6
2023-01-05 07:01:22,593 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4764064610004425, 'Total loss': 0.4764064610004425} | train loss {'Reaction outcome loss': 0.4436428913786093, 'Total loss': 0.4436428913786093}
2023-01-05 07:01:22,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:22,593 INFO:     Epoch: 7
2023-01-05 07:01:24,852 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48190758228302, 'Total loss': 0.48190758228302} | train loss {'Reaction outcome loss': 0.4313134965806231, 'Total loss': 0.4313134965806231}
2023-01-05 07:01:24,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:24,852 INFO:     Epoch: 8
2023-01-05 07:01:27,132 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4508824944496155, 'Total loss': 0.4508824944496155} | train loss {'Reaction outcome loss': 0.4270803047216326, 'Total loss': 0.4270803047216326}
2023-01-05 07:01:27,132 INFO:     Found new best model at epoch 8
2023-01-05 07:01:27,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:27,134 INFO:     Epoch: 9
2023-01-05 07:01:29,393 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44242126047611235, 'Total loss': 0.44242126047611235} | train loss {'Reaction outcome loss': 0.411586768293101, 'Total loss': 0.411586768293101}
2023-01-05 07:01:29,394 INFO:     Found new best model at epoch 9
2023-01-05 07:01:29,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:29,396 INFO:     Epoch: 10
2023-01-05 07:01:31,666 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4452874481678009, 'Total loss': 0.4452874481678009} | train loss {'Reaction outcome loss': 0.39906690657031235, 'Total loss': 0.39906690657031235}
2023-01-05 07:01:31,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:31,666 INFO:     Epoch: 11
2023-01-05 07:01:33,980 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4527891993522644, 'Total loss': 0.4527891993522644} | train loss {'Reaction outcome loss': 0.3909404038683602, 'Total loss': 0.3909404038683602}
2023-01-05 07:01:33,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:33,981 INFO:     Epoch: 12
2023-01-05 07:01:36,295 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4487566019097964, 'Total loss': 0.4487566019097964} | train loss {'Reaction outcome loss': 0.3820203280190699, 'Total loss': 0.3820203280190699}
2023-01-05 07:01:36,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:36,295 INFO:     Epoch: 13
2023-01-05 07:01:38,602 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44624517460664115, 'Total loss': 0.44624517460664115} | train loss {'Reaction outcome loss': 0.37115257449905364, 'Total loss': 0.37115257449905364}
2023-01-05 07:01:38,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:38,603 INFO:     Epoch: 14
2023-01-05 07:01:40,911 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4629933814207713, 'Total loss': 0.4629933814207713} | train loss {'Reaction outcome loss': 0.36885411289624787, 'Total loss': 0.36885411289624787}
2023-01-05 07:01:40,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:40,913 INFO:     Epoch: 15
2023-01-05 07:01:43,209 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41763232549031576, 'Total loss': 0.41763232549031576} | train loss {'Reaction outcome loss': 0.3602837501127367, 'Total loss': 0.3602837501127367}
2023-01-05 07:01:43,209 INFO:     Found new best model at epoch 15
2023-01-05 07:01:43,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:43,211 INFO:     Epoch: 16
2023-01-05 07:01:45,525 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4144255315264066, 'Total loss': 0.4144255315264066} | train loss {'Reaction outcome loss': 0.35198876014255015, 'Total loss': 0.35198876014255015}
2023-01-05 07:01:45,525 INFO:     Found new best model at epoch 16
2023-01-05 07:01:45,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:45,527 INFO:     Epoch: 17
2023-01-05 07:01:47,854 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4401463190714518, 'Total loss': 0.4401463190714518} | train loss {'Reaction outcome loss': 0.3418608239250063, 'Total loss': 0.3418608239250063}
2023-01-05 07:01:47,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:47,855 INFO:     Epoch: 18
2023-01-05 07:01:50,159 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40639592508474986, 'Total loss': 0.40639592508474986} | train loss {'Reaction outcome loss': 0.3358079653085354, 'Total loss': 0.3358079653085354}
2023-01-05 07:01:50,159 INFO:     Found new best model at epoch 18
2023-01-05 07:01:50,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:50,161 INFO:     Epoch: 19
2023-01-05 07:01:52,474 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4198491295178731, 'Total loss': 0.4198491295178731} | train loss {'Reaction outcome loss': 0.33145968989882657, 'Total loss': 0.33145968989882657}
2023-01-05 07:01:52,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:52,475 INFO:     Epoch: 20
2023-01-05 07:01:54,750 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43729964395364124, 'Total loss': 0.43729964395364124} | train loss {'Reaction outcome loss': 0.32298100823099435, 'Total loss': 0.32298100823099435}
2023-01-05 07:01:54,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:54,750 INFO:     Epoch: 21
2023-01-05 07:01:57,043 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4285690367221832, 'Total loss': 0.4285690367221832} | train loss {'Reaction outcome loss': 0.3219567715099572, 'Total loss': 0.3219567715099572}
2023-01-05 07:01:57,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:57,043 INFO:     Epoch: 22
2023-01-05 07:01:59,328 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43378305435180664, 'Total loss': 0.43378305435180664} | train loss {'Reaction outcome loss': 0.3185010562829055, 'Total loss': 0.3185010562829055}
2023-01-05 07:01:59,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:01:59,329 INFO:     Epoch: 23
2023-01-05 07:02:01,628 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40650444800655045, 'Total loss': 0.40650444800655045} | train loss {'Reaction outcome loss': 0.30625084645723394, 'Total loss': 0.30625084645723394}
2023-01-05 07:02:01,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:01,629 INFO:     Epoch: 24
2023-01-05 07:02:03,932 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4397134333848953, 'Total loss': 0.4397134333848953} | train loss {'Reaction outcome loss': 0.3066373339951684, 'Total loss': 0.3066373339951684}
2023-01-05 07:02:03,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:03,933 INFO:     Epoch: 25
2023-01-05 07:02:06,196 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45408004721005757, 'Total loss': 0.45408004721005757} | train loss {'Reaction outcome loss': 0.2990582403441091, 'Total loss': 0.2990582403441091}
2023-01-05 07:02:06,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:06,196 INFO:     Epoch: 26
2023-01-05 07:02:08,496 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41553935011227927, 'Total loss': 0.41553935011227927} | train loss {'Reaction outcome loss': 0.2923915552963849, 'Total loss': 0.2923915552963849}
2023-01-05 07:02:08,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:08,496 INFO:     Epoch: 27
2023-01-05 07:02:10,788 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44323509335517886, 'Total loss': 0.44323509335517886} | train loss {'Reaction outcome loss': 0.2916631497415825, 'Total loss': 0.2916631497415825}
2023-01-05 07:02:10,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:10,788 INFO:     Epoch: 28
2023-01-05 07:02:13,092 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46299804051717125, 'Total loss': 0.46299804051717125} | train loss {'Reaction outcome loss': 0.28956071061455385, 'Total loss': 0.28956071061455385}
2023-01-05 07:02:13,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:13,092 INFO:     Epoch: 29
2023-01-05 07:02:15,354 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4357045362393061, 'Total loss': 0.4357045362393061} | train loss {'Reaction outcome loss': 0.2805329623635495, 'Total loss': 0.2805329623635495}
2023-01-05 07:02:15,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:15,355 INFO:     Epoch: 30
2023-01-05 07:02:17,608 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4385003536939621, 'Total loss': 0.4385003536939621} | train loss {'Reaction outcome loss': 0.2801478801140501, 'Total loss': 0.2801478801140501}
2023-01-05 07:02:17,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:17,609 INFO:     Epoch: 31
2023-01-05 07:02:19,868 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4245883941650391, 'Total loss': 0.4245883941650391} | train loss {'Reaction outcome loss': 0.27425659127829305, 'Total loss': 0.27425659127829305}
2023-01-05 07:02:19,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:19,869 INFO:     Epoch: 32
2023-01-05 07:02:22,018 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47083307802677155, 'Total loss': 0.47083307802677155} | train loss {'Reaction outcome loss': 0.27061396199766047, 'Total loss': 0.27061396199766047}
2023-01-05 07:02:22,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:22,018 INFO:     Epoch: 33
2023-01-05 07:02:24,308 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44802148938179015, 'Total loss': 0.44802148938179015} | train loss {'Reaction outcome loss': 0.2663835250311918, 'Total loss': 0.2663835250311918}
2023-01-05 07:02:24,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:24,309 INFO:     Epoch: 34
2023-01-05 07:02:26,597 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41713802913824716, 'Total loss': 0.41713802913824716} | train loss {'Reaction outcome loss': 0.2654476236646141, 'Total loss': 0.2654476236646141}
2023-01-05 07:02:26,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:26,597 INFO:     Epoch: 35
2023-01-05 07:02:28,852 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4308353235324224, 'Total loss': 0.4308353235324224} | train loss {'Reaction outcome loss': 0.26030738470867437, 'Total loss': 0.26030738470867437}
2023-01-05 07:02:28,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:28,852 INFO:     Epoch: 36
2023-01-05 07:02:31,108 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4338569442431132, 'Total loss': 0.4338569442431132} | train loss {'Reaction outcome loss': 0.2634040727969326, 'Total loss': 0.2634040727969326}
2023-01-05 07:02:31,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:31,108 INFO:     Epoch: 37
2023-01-05 07:02:33,383 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4190811425447464, 'Total loss': 0.4190811425447464} | train loss {'Reaction outcome loss': 0.2554369317065077, 'Total loss': 0.2554369317065077}
2023-01-05 07:02:33,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:33,384 INFO:     Epoch: 38
2023-01-05 07:02:35,669 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42081578969955447, 'Total loss': 0.42081578969955447} | train loss {'Reaction outcome loss': 0.24883139989463215, 'Total loss': 0.24883139989463215}
2023-01-05 07:02:35,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:35,669 INFO:     Epoch: 39
2023-01-05 07:02:37,919 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41945933004220326, 'Total loss': 0.41945933004220326} | train loss {'Reaction outcome loss': 0.24938078938112576, 'Total loss': 0.24938078938112576}
2023-01-05 07:02:37,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:37,920 INFO:     Epoch: 40
2023-01-05 07:02:40,131 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43537778258323667, 'Total loss': 0.43537778258323667} | train loss {'Reaction outcome loss': 0.2457569726685647, 'Total loss': 0.2457569726685647}
2023-01-05 07:02:40,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:40,131 INFO:     Epoch: 41
2023-01-05 07:02:42,370 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.453916934132576, 'Total loss': 0.453916934132576} | train loss {'Reaction outcome loss': 0.24457061113890544, 'Total loss': 0.24457061113890544}
2023-01-05 07:02:42,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:42,371 INFO:     Epoch: 42
2023-01-05 07:02:44,613 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4555722708503405, 'Total loss': 0.4555722708503405} | train loss {'Reaction outcome loss': 0.24102671014730034, 'Total loss': 0.24102671014730034}
2023-01-05 07:02:44,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:44,613 INFO:     Epoch: 43
2023-01-05 07:02:46,840 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4446687201658885, 'Total loss': 0.4446687201658885} | train loss {'Reaction outcome loss': 0.23742942540277642, 'Total loss': 0.23742942540277642}
2023-01-05 07:02:46,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:46,842 INFO:     Epoch: 44
2023-01-05 07:02:49,080 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46723185777664183, 'Total loss': 0.46723185777664183} | train loss {'Reaction outcome loss': 0.23253017952430335, 'Total loss': 0.23253017952430335}
2023-01-05 07:02:49,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:49,080 INFO:     Epoch: 45
2023-01-05 07:02:51,313 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45636633584896724, 'Total loss': 0.45636633584896724} | train loss {'Reaction outcome loss': 0.23262220036762932, 'Total loss': 0.23262220036762932}
2023-01-05 07:02:51,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:51,314 INFO:     Epoch: 46
2023-01-05 07:02:53,529 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4457915599147479, 'Total loss': 0.4457915599147479} | train loss {'Reaction outcome loss': 0.22843312233054358, 'Total loss': 0.22843312233054358}
2023-01-05 07:02:53,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:53,530 INFO:     Epoch: 47
2023-01-05 07:02:55,786 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44336702128251393, 'Total loss': 0.44336702128251393} | train loss {'Reaction outcome loss': 0.23093619063120027, 'Total loss': 0.23093619063120027}
2023-01-05 07:02:55,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:55,787 INFO:     Epoch: 48
2023-01-05 07:02:58,081 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46569029813011487, 'Total loss': 0.46569029813011487} | train loss {'Reaction outcome loss': 0.22419010518313745, 'Total loss': 0.22419010518313745}
2023-01-05 07:02:58,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:02:58,082 INFO:     Epoch: 49
2023-01-05 07:03:00,381 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45918561816215514, 'Total loss': 0.45918561816215514} | train loss {'Reaction outcome loss': 0.22348768319194928, 'Total loss': 0.22348768319194928}
2023-01-05 07:03:00,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:00,382 INFO:     Epoch: 50
2023-01-05 07:03:02,649 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4577109416325887, 'Total loss': 0.4577109416325887} | train loss {'Reaction outcome loss': 0.21791655460661713, 'Total loss': 0.21791655460661713}
2023-01-05 07:03:02,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:02,649 INFO:     Epoch: 51
2023-01-05 07:03:04,900 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4315876230597496, 'Total loss': 0.4315876230597496} | train loss {'Reaction outcome loss': 0.2126700150803915, 'Total loss': 0.2126700150803915}
2023-01-05 07:03:04,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:04,900 INFO:     Epoch: 52
2023-01-05 07:03:07,187 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45692554116249084, 'Total loss': 0.45692554116249084} | train loss {'Reaction outcome loss': 0.2163932860058998, 'Total loss': 0.2163932860058998}
2023-01-05 07:03:07,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:07,188 INFO:     Epoch: 53
2023-01-05 07:03:09,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45702108840147654, 'Total loss': 0.45702108840147654} | train loss {'Reaction outcome loss': 0.21565516690794204, 'Total loss': 0.21565516690794204}
2023-01-05 07:03:09,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:09,476 INFO:     Epoch: 54
2023-01-05 07:03:11,757 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44734116494655607, 'Total loss': 0.44734116494655607} | train loss {'Reaction outcome loss': 0.2183558065881314, 'Total loss': 0.2183558065881314}
2023-01-05 07:03:11,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:11,758 INFO:     Epoch: 55
2023-01-05 07:03:14,042 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4806020696957906, 'Total loss': 0.4806020696957906} | train loss {'Reaction outcome loss': 0.21436705980080076, 'Total loss': 0.21436705980080076}
2023-01-05 07:03:14,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:14,042 INFO:     Epoch: 56
2023-01-05 07:03:16,286 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46489069163799285, 'Total loss': 0.46489069163799285} | train loss {'Reaction outcome loss': 0.21078385106735065, 'Total loss': 0.21078385106735065}
2023-01-05 07:03:16,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:16,286 INFO:     Epoch: 57
2023-01-05 07:03:18,562 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4699695477883021, 'Total loss': 0.4699695477883021} | train loss {'Reaction outcome loss': 0.21078149228951884, 'Total loss': 0.21078149228951884}
2023-01-05 07:03:18,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:18,563 INFO:     Epoch: 58
2023-01-05 07:03:20,851 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4815550814072291, 'Total loss': 0.4815550814072291} | train loss {'Reaction outcome loss': 0.21250757820473898, 'Total loss': 0.21250757820473898}
2023-01-05 07:03:20,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:20,852 INFO:     Epoch: 59
2023-01-05 07:03:23,107 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4362045208613078, 'Total loss': 0.4362045208613078} | train loss {'Reaction outcome loss': 0.20765747711573482, 'Total loss': 0.20765747711573482}
2023-01-05 07:03:23,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:23,108 INFO:     Epoch: 60
2023-01-05 07:03:25,385 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5064992994070053, 'Total loss': 0.5064992994070053} | train loss {'Reaction outcome loss': 0.2107140764002335, 'Total loss': 0.2107140764002335}
2023-01-05 07:03:25,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:25,385 INFO:     Epoch: 61
2023-01-05 07:03:27,633 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47044668594996136, 'Total loss': 0.47044668594996136} | train loss {'Reaction outcome loss': 0.210262948025139, 'Total loss': 0.210262948025139}
2023-01-05 07:03:27,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:27,633 INFO:     Epoch: 62
2023-01-05 07:03:29,902 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4494246537486712, 'Total loss': 0.4494246537486712} | train loss {'Reaction outcome loss': 0.20298520976926338, 'Total loss': 0.20298520976926338}
2023-01-05 07:03:29,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:29,903 INFO:     Epoch: 63
2023-01-05 07:03:32,181 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.493118949731191, 'Total loss': 0.493118949731191} | train loss {'Reaction outcome loss': 0.20825948868121696, 'Total loss': 0.20825948868121696}
2023-01-05 07:03:32,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:32,181 INFO:     Epoch: 64
2023-01-05 07:03:34,452 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.499424942334493, 'Total loss': 0.499424942334493} | train loss {'Reaction outcome loss': 0.20928354014302958, 'Total loss': 0.20928354014302958}
2023-01-05 07:03:34,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:34,452 INFO:     Epoch: 65
2023-01-05 07:03:36,733 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45766419867674507, 'Total loss': 0.45766419867674507} | train loss {'Reaction outcome loss': 0.20407283448678062, 'Total loss': 0.20407283448678062}
2023-01-05 07:03:36,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:36,733 INFO:     Epoch: 66
2023-01-05 07:03:38,961 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4782763570547104, 'Total loss': 0.4782763570547104} | train loss {'Reaction outcome loss': 0.20533484926561588, 'Total loss': 0.20533484926561588}
2023-01-05 07:03:38,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:38,961 INFO:     Epoch: 67
2023-01-05 07:03:41,255 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4842429449160894, 'Total loss': 0.4842429449160894} | train loss {'Reaction outcome loss': 0.20561577526966804, 'Total loss': 0.20561577526966804}
2023-01-05 07:03:41,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:41,255 INFO:     Epoch: 68
2023-01-05 07:03:43,535 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4929536869128545, 'Total loss': 0.4929536869128545} | train loss {'Reaction outcome loss': 0.20239283342674266, 'Total loss': 0.20239283342674266}
2023-01-05 07:03:43,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:43,536 INFO:     Epoch: 69
2023-01-05 07:03:45,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4762654185295105, 'Total loss': 0.4762654185295105} | train loss {'Reaction outcome loss': 0.19747401788050734, 'Total loss': 0.19747401788050734}
2023-01-05 07:03:45,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:45,647 INFO:     Epoch: 70
2023-01-05 07:03:47,864 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.491561629374822, 'Total loss': 0.491561629374822} | train loss {'Reaction outcome loss': 0.1983554151131089, 'Total loss': 0.1983554151131089}
2023-01-05 07:03:47,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:47,864 INFO:     Epoch: 71
2023-01-05 07:03:50,114 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48102780878543855, 'Total loss': 0.48102780878543855} | train loss {'Reaction outcome loss': 0.19743375025777019, 'Total loss': 0.19743375025777019}
2023-01-05 07:03:50,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:50,114 INFO:     Epoch: 72
2023-01-05 07:03:52,424 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4753606816132863, 'Total loss': 0.4753606816132863} | train loss {'Reaction outcome loss': 0.19683593389870674, 'Total loss': 0.19683593389870674}
2023-01-05 07:03:52,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:52,424 INFO:     Epoch: 73
2023-01-05 07:03:54,753 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.450260325272878, 'Total loss': 0.450260325272878} | train loss {'Reaction outcome loss': 0.19333623484489829, 'Total loss': 0.19333623484489829}
2023-01-05 07:03:54,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:54,753 INFO:     Epoch: 74
2023-01-05 07:03:57,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46946099599202473, 'Total loss': 0.46946099599202473} | train loss {'Reaction outcome loss': 0.19495692937248235, 'Total loss': 0.19495692937248235}
2023-01-05 07:03:57,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:57,099 INFO:     Epoch: 75
2023-01-05 07:03:59,378 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.487126886844635, 'Total loss': 0.487126886844635} | train loss {'Reaction outcome loss': 0.19604225454697324, 'Total loss': 0.19604225454697324}
2023-01-05 07:03:59,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:03:59,380 INFO:     Epoch: 76
2023-01-05 07:04:01,610 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46124894022941587, 'Total loss': 0.46124894022941587} | train loss {'Reaction outcome loss': 0.19335612571304026, 'Total loss': 0.19335612571304026}
2023-01-05 07:04:01,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:01,610 INFO:     Epoch: 77
2023-01-05 07:04:03,867 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4784802387158076, 'Total loss': 0.4784802387158076} | train loss {'Reaction outcome loss': 0.1883222377129464, 'Total loss': 0.1883222377129464}
2023-01-05 07:04:03,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:03,868 INFO:     Epoch: 78
2023-01-05 07:04:06,142 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4723431497812271, 'Total loss': 0.4723431497812271} | train loss {'Reaction outcome loss': 0.18757785797885718, 'Total loss': 0.18757785797885718}
2023-01-05 07:04:06,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:06,143 INFO:     Epoch: 79
2023-01-05 07:04:08,429 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47128993620475135, 'Total loss': 0.47128993620475135} | train loss {'Reaction outcome loss': 0.19115252529408797, 'Total loss': 0.19115252529408797}
2023-01-05 07:04:08,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:08,429 INFO:     Epoch: 80
2023-01-05 07:04:10,697 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.474653035402298, 'Total loss': 0.474653035402298} | train loss {'Reaction outcome loss': 0.1873088511150828, 'Total loss': 0.1873088511150828}
2023-01-05 07:04:10,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:10,697 INFO:     Epoch: 81
2023-01-05 07:04:12,968 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4632293830315272, 'Total loss': 0.4632293830315272} | train loss {'Reaction outcome loss': 0.18992740270221062, 'Total loss': 0.18992740270221062}
2023-01-05 07:04:12,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:12,969 INFO:     Epoch: 82
2023-01-05 07:04:15,238 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4794443150361379, 'Total loss': 0.4794443150361379} | train loss {'Reaction outcome loss': 0.18547834923141215, 'Total loss': 0.18547834923141215}
2023-01-05 07:04:15,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:15,239 INFO:     Epoch: 83
2023-01-05 07:04:17,488 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47938302357991536, 'Total loss': 0.47938302357991536} | train loss {'Reaction outcome loss': 0.18463826089734311, 'Total loss': 0.18463826089734311}
2023-01-05 07:04:17,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:17,489 INFO:     Epoch: 84
2023-01-05 07:04:19,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49471375743548074, 'Total loss': 0.49471375743548074} | train loss {'Reaction outcome loss': 0.18706546100999635, 'Total loss': 0.18706546100999635}
2023-01-05 07:04:19,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:19,778 INFO:     Epoch: 85
2023-01-05 07:04:22,053 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4956009715795517, 'Total loss': 0.4956009715795517} | train loss {'Reaction outcome loss': 0.18689209995253367, 'Total loss': 0.18689209995253367}
2023-01-05 07:04:22,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:22,054 INFO:     Epoch: 86
2023-01-05 07:04:24,289 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4986914684375127, 'Total loss': 0.4986914684375127} | train loss {'Reaction outcome loss': 0.18155834914121224, 'Total loss': 0.18155834914121224}
2023-01-05 07:04:24,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:24,289 INFO:     Epoch: 87
2023-01-05 07:04:26,553 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43962651876111825, 'Total loss': 0.43962651876111825} | train loss {'Reaction outcome loss': 0.18624830770134818, 'Total loss': 0.18624830770134818}
2023-01-05 07:04:26,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:26,553 INFO:     Epoch: 88
2023-01-05 07:04:28,850 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48477222124735514, 'Total loss': 0.48477222124735514} | train loss {'Reaction outcome loss': 0.18562296054423502, 'Total loss': 0.18562296054423502}
2023-01-05 07:04:28,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:28,850 INFO:     Epoch: 89
2023-01-05 07:04:31,125 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48876323699951174, 'Total loss': 0.48876323699951174} | train loss {'Reaction outcome loss': 0.179746207799628, 'Total loss': 0.179746207799628}
2023-01-05 07:04:31,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:31,125 INFO:     Epoch: 90
2023-01-05 07:04:33,376 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47389282286167145, 'Total loss': 0.47389282286167145} | train loss {'Reaction outcome loss': 0.1784983381649163, 'Total loss': 0.1784983381649163}
2023-01-05 07:04:33,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:33,376 INFO:     Epoch: 91
2023-01-05 07:04:35,651 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4931469996770223, 'Total loss': 0.4931469996770223} | train loss {'Reaction outcome loss': 0.1846168954513752, 'Total loss': 0.1846168954513752}
2023-01-05 07:04:35,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:35,652 INFO:     Epoch: 92
2023-01-05 07:04:37,900 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47285804748535154, 'Total loss': 0.47285804748535154} | train loss {'Reaction outcome loss': 0.18047743132640523, 'Total loss': 0.18047743132640523}
2023-01-05 07:04:37,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:37,900 INFO:     Epoch: 93
2023-01-05 07:04:40,176 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45415677428245543, 'Total loss': 0.45415677428245543} | train loss {'Reaction outcome loss': 0.17663556963982, 'Total loss': 0.17663556963982}
2023-01-05 07:04:40,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:40,177 INFO:     Epoch: 94
2023-01-05 07:04:42,436 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4987594336271286, 'Total loss': 0.4987594336271286} | train loss {'Reaction outcome loss': 0.18182994325776392, 'Total loss': 0.18182994325776392}
2023-01-05 07:04:42,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:42,437 INFO:     Epoch: 95
2023-01-05 07:04:44,691 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.457064155737559, 'Total loss': 0.457064155737559} | train loss {'Reaction outcome loss': 0.1834515931676495, 'Total loss': 0.1834515931676495}
2023-01-05 07:04:44,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:44,691 INFO:     Epoch: 96
2023-01-05 07:04:46,974 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5231370439132055, 'Total loss': 0.5231370439132055} | train loss {'Reaction outcome loss': 0.18400312450610182, 'Total loss': 0.18400312450610182}
2023-01-05 07:04:46,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:46,974 INFO:     Epoch: 97
2023-01-05 07:04:49,182 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4754511296749115, 'Total loss': 0.4754511296749115} | train loss {'Reaction outcome loss': 0.17616059703984388, 'Total loss': 0.17616059703984388}
2023-01-05 07:04:49,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:49,182 INFO:     Epoch: 98
2023-01-05 07:04:51,422 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49167851607004803, 'Total loss': 0.49167851607004803} | train loss {'Reaction outcome loss': 0.17561403693066446, 'Total loss': 0.17561403693066446}
2023-01-05 07:04:51,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:04:51,423 INFO:     Epoch: 99
2023-01-05 07:04:53,704 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.479186475276947, 'Total loss': 0.479186475276947} | train loss {'Reaction outcome loss': 0.18129947505528207, 'Total loss': 0.18129947505528207}
2023-01-05 07:04:53,704 INFO:     Best model found after epoch 19 of 100.
2023-01-05 07:04:53,705 INFO:   Done with stage: TRAINING
2023-01-05 07:04:53,705 INFO:   Starting stage: EVALUATION
2023-01-05 07:04:53,833 INFO:   Done with stage: EVALUATION
2023-01-05 07:04:53,833 INFO: Done with stage: RUNNING SPLITS
2023-01-05 07:04:53,833 INFO: Starting stage: COMPUTE METRICS
2023-01-05 07:04:55,023 INFO: Done with stage: COMPUTE METRICS
2023-01-05 07:04:55,024 INFO: Starting stage: EXPORT RESULTS
2023-01-05 07:04:55,042 INFO:   Final results averaged over 50 folds: 
2023-01-05 07:04:55,046 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.165647           NaN  0.313967       NaN
2023-01-05 07:04:56,742 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 07:04:56,748 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 07:04:56,749 DEBUG:   interactive is False
2023-01-05 07:04:56,750 DEBUG:   platform is linux
2023-01-05 07:04:56,750 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 07:04:56,932 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 07:04:56,934 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 07:04:57,389 DEBUG:   Loaded backend agg version unknown.
2023-01-05 07:04:57,392 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,392 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,393 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,394 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,395 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,395 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,395 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,395 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,395 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 07:04:57,432 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 07:04:57,432 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,432 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,432 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,433 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,434 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,435 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,435 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 07:04:57,444 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,444 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,445 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 07:04:57,446 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 07:04:57,447 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 07:04:57,447 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 07:04:57,866 INFO: Done with stage: EXPORT RESULTS
2023-01-05 07:04:57,866 INFO: Starting stage: SAVE MODEL
2023-01-05 07:04:57,921 INFO: Done with stage: SAVE MODEL
2023-01-05 07:04:57,921 INFO: Wall time for program:  11198.68 seconds
